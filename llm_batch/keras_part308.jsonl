{"custom_id": "keras#4d59675b65b6733e525286bbd512e9d5a42f3a22", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 12 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 32 | Churn Cumulative: 12508 | Contributors (this commit): 86 | Commits (past 90d): 1 | Contributors (cumulative): 86 | DMM Complexity: None\n\nDIFF:\n@@ -188,19 +188,19 @@ class SpatialDropout2D(Dropout):\n \n     # Arguments\n         rate: float between 0 and 1. Fraction of the input units to drop.\n-        data_format: 'channels_first' or 'channels_last'.\n-            In 'channels_first' mode, the channels dimension\n+        data_format: `'channels_first'` or `'channels_last'`.\n+            In `'channels_first'` mode, the channels dimension\n             (the depth) is at index 1,\n-            in 'channels_last' mode is it at index 3.\n+            in `'channels_last'` mode is it at index 3.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n+            If you never set it, then it will be `'channels_last'`.\n \n     # Input shape\n         4D tensor with shape:\n-        `(samples, channels, rows, cols)` if data_format='channels_first'\n+        `(samples, channels, rows, cols)` if `data_format='channels_first'`\n         or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if data_format='channels_last'.\n+        `(samples, rows, cols, channels)` if `data_format='channels_last'`.\n \n     # Output shape\n         Same as input\n@@ -238,18 +238,18 @@ class SpatialDropout3D(Dropout):\n \n     # Arguments\n         rate: float between 0 and 1. Fraction of the input units to drop.\n-        data_format: 'channels_first' or 'channels_last'.\n-            In 'channels_first' mode, the channels dimension (the depth)\n-            is at index 1, in 'channels_last' mode is it at index 4.\n+        data_format: `'channels_first'` or `'channels_last'`.\n+            In `'channels_first'` mode, the channels dimension (the depth)\n+            is at index 1, in `'channels_last'` mode is it at index 4.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n+            If you never set it, then it will be `'channels_last'`.\n \n     # Input shape\n         5D tensor with shape:\n-        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'\n+        `(samples, channels, dim1, dim2, dim3)` if `data_format='channels_first'`\n         or 5D tensor with shape:\n-        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.\n+        `(samples, dim1, dim2, dim3, channels)` if `data_format='channels_last'`.\n \n     # Output shape\n         Same as input\n@@ -464,17 +464,17 @@ class Flatten(Layer):\n \n     # Arguments\n         data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n+            one of `'channels_last'` (default) or `'channels_first'`.\n             The ordering of the dimensions in the inputs.\n             The purpose of this argument is to preserve weight\n             ordering when switching a model from one data format\n             to another.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `channels_first` corresponds to\n+            `'channels_last'` corresponds to inputs with shape\n+            `(batch, ..., channels)` while `'channels_first'` corresponds to\n             inputs with shape `(batch, channels, ...)`.\n             It defaults to the `image_data_format` value found in your\n             Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n+            If you never set it, then it will be `'channels_last'`.\n \n     # Example\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ecac367b2372b5f2326fcd3ddd11718323427f4e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 23 | Churn Cumulative: 3580 | Contributors (this commit): 30 | Commits (past 90d): 12 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -744,7 +744,9 @@ def save_weights_to_hdf5_group(group, layers):\n     group.attrs['backend'] = K.backend().encode('utf8')\n     group.attrs['keras_version'] = str(keras_version).encode('utf8')\n \n-    for layer in layers:\n+    # Sort model layers by layer name to ensure that group names are strictly\n+    # growing to avoid prefix issues.\n+    for layer in sorted(layers, key=lambda x: x.name):\n         g = group.create_group(layer.name)\n         symbolic_weights = layer.weights\n         weight_values = K.batch_get_value(symbolic_weights)\n\n@@ -80,7 +80,7 @@ def test_sensitivity_metrics():\n     model.evaluate(x, y)\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')\n+@pytest.mark.skipif(True, reason='It is a flaky test, see #13477 for more context.')\n def test_mean_iou():\n     import tensorflow as tf\n     if not tf.__version__.startswith('2.'):\n\n@@ -14,7 +14,7 @@ from keras.engine.saving import preprocess_weights_for_loading\n from keras.models import Model, Sequential\n from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed\n from keras.layers import Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\n-from keras.layers import Conv2D, Flatten\n+from keras.layers import Conv2D, Flatten, Activation\n from keras.layers import Input, InputLayer\n from keras.initializers import Constant\n from keras import optimizers\n@@ -708,6 +708,21 @@ def test_saving_constant_initializer_with_numpy():\n     os.remove(fname)\n \n \n+def test_saving_group_naming_h5py(tmpdir):\n+    \"\"\"Test saving model with layer which name is prefix to a previous layer\n+    name\n+    \"\"\"\n+\n+    input_layer = Input((None, None, 3), name='test_input')\n+    x = Conv2D(1, 1, name='conv1/conv')(input_layer)\n+    x = Activation('relu', name='conv1')(x)\n+\n+    model = Model(inputs=input_layer, outputs=x)\n+    p = tmpdir.mkdir(\"test\").join(\"test.h5\")\n+    model.save_weights(p)\n+    model.load_weights(p)\n+\n+\n def test_save_load_weights_gcs():\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,)))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8946d5240f3b18528d4d34668ee615907879953", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 516 | Contributors (this commit): 18 | Commits (past 90d): 1 | Contributors (cumulative): 18 | DMM Complexity: None\n\nDIFF:\n@@ -56,10 +56,10 @@ def to_categorical(y, num_classes=None, dtype='float32'):\n \n \n def normalize(x, axis=-1, order=2):\n-    \"\"\"Normalizes a Numpy array.\n+    \"\"\"Normalizes a NumPy array.\n \n     # Arguments\n-        x: Numpy array to normalize.\n+        x: NumPy array to normalize.\n         axis: axis along which to normalize.\n         order: Normalization order (e.g. 2 for L2 norm).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a39b6c62d43c25472b2c2476bd2a8983ae4f682", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 479 | Contributors (this commit): 9 | Commits (past 90d): 3 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -70,7 +70,7 @@ target_characters = set()\n with open(data_path, 'r', encoding='utf-8') as f:\n     lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n-    input_text, target_text = line.split('\\t')\n+    input_text, target_text, _ = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n     # for the targets, and \"\\n\" as \"end sequence\" character.\n     target_text = '\\t' + target_text + '\\n'\n\n@@ -33,7 +33,7 @@ target_characters = set()\n with open(data_path, 'r', encoding='utf-8') as f:\n     lines = f.read().split('\\n')\n for line in lines[: min(num_samples, len(lines) - 1)]:\n-    input_text, target_text = line.split('\\t')\n+    input_text, target_text, _ = line.split('\\t')\n     # We use \"tab\" as the \"start sequence\" character\n     # for the targets, and \"\\n\" as \"end sequence\" character.\n     target_text = '\\t' + target_text + '\\n'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b5cb82c689eac0e50522be9d2f55093dadfba24c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 648 | Lines Deleted: 50834 | Files Changed: 141 | Hunks: 455 | Methods Changed: 2038 | Complexity Δ (Sum/Max): -6883/23 | Churn Δ: 51482 | Churn Cumulative: 252294 | Contributors (this commit): 693 | Commits (past 90d): 141 | Contributors (cumulative): 2140 | DMM Complexity: 0.4241493478000718\n\nDIFF:\n@@ -17,6 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n+import keras\n from keras.layers import Lambda, Input, Dense\n from keras.models import Model\n from keras.datasets import mnist\n@@ -186,10 +187,6 @@ if __name__ == '__main__':\n     vae_loss = K.mean(reconstruction_loss + kl_loss)\n     vae.add_loss(vae_loss)\n     vae.compile(optimizer='adam')\n-    vae.summary()\n-    plot_model(vae,\n-               to_file='vae_mlp.png',\n-               show_shapes=True)\n \n     if args.weights:\n         vae.load_weights(args.weights)\n\n@@ -1,5 +1,3 @@\n-from __future__ import absolute_import\r\n-\r\n from . import utils\r\n from . import activations\r\n from . import applications\r\n@@ -23,4 +21,4 @@ from .layers import Input\n from .models import Model\r\n from .models import Sequential\r\n \r\n-__version__ = '2.3.1'\r\n+from tensorflow.keras import __version__\r\n\n@@ -1,239 +1,17 @@\n-\"\"\"Built-in activation functions.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Built-in activation functions.\"\"\"\n \n-import six\n-import warnings\n-from . import backend as K\n-from .utils.generic_utils import deserialize_keras_object\n-from .engine import Layer\n+from tensorflow.keras.activations import softmax\n+from tensorflow.keras.activations import elu\n+from tensorflow.keras.activations import selu\n+from tensorflow.keras.activations import softplus\n+from tensorflow.keras.activations import softsign\n+from tensorflow.keras.activations import relu\n+from tensorflow.keras.activations import tanh\n+from tensorflow.keras.activations import sigmoid\n+from tensorflow.keras.activations import hard_sigmoid\n+from tensorflow.keras.activations import exponential\n+from tensorflow.keras.activations import linear\n \n-\n-def softmax(x, axis=-1):\n-    \"\"\"Softmax activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-        axis: Integer, axis along which the softmax normalization is applied.\n-\n-    # Returns\n-        Tensor, output of softmax transformation.\n-\n-    # Raises\n-        ValueError: In case `dim(x) == 1`.\n-    \"\"\"\n-    ndim = K.ndim(x)\n-    if ndim == 2:\n-        return K.softmax(x)\n-    elif ndim > 2:\n-        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n-        s = K.sum(e, axis=axis, keepdims=True)\n-        return e / s\n-    else:\n-        raise ValueError('Cannot apply softmax to a tensor that is 1D. '\n-                         'Received input: %s' % x)\n-\n-\n-def elu(x, alpha=1.0):\n-    \"\"\"Exponential linear unit.\n-\n-    # Arguments\n-        x: Input tensor.\n-        alpha: A scalar, slope of negative section.\n-\n-    # Returns\n-        The exponential linear activation: `x` if `x > 0` and\n-        `alpha * (exp(x)-1)` if `x < 0`.\n-\n-    # References\n-        - [Fast and Accurate Deep Network Learning by Exponential\n-           Linear Units (ELUs)](https://arxiv.org/abs/1511.07289)\n-    \"\"\"\n-    return K.elu(x, alpha)\n-\n-\n-def selu(x):\n-    \"\"\"Scaled Exponential Linear Unit (SELU).\n-\n-    SELU is equal to: `scale * elu(x, alpha)`, where alpha and scale\n-    are predefined constants. The values of `alpha` and `scale` are\n-    chosen so that the mean and variance of the inputs are preserved\n-    between two consecutive layers as long as the weights are initialized\n-    correctly (see `lecun_normal` initialization) and the number of inputs\n-    is \"large enough\" (see references for more information).\n-\n-    # Arguments\n-        x: A tensor or variable to compute the activation function for.\n-\n-    # Returns\n-       The scaled exponential unit activation: `scale * elu(x, alpha)`.\n-\n-    # Note\n-        - To be used together with the initialization \"lecun_normal\".\n-        - To be used together with the dropout variant \"AlphaDropout\".\n-\n-    # References\n-        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n-    \"\"\"\n-    alpha = 1.6732632423543772848170429916717\n-    scale = 1.0507009873554804934193349852946\n-    return scale * K.elu(x, alpha)\n-\n-\n-def softplus(x):\n-    \"\"\"Softplus activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        The softplus activation: `log(exp(x) + 1)`.\n-    \"\"\"\n-    return K.softplus(x)\n-\n-\n-def softsign(x):\n-    \"\"\"Softsign activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        The softsign activation: `x / (abs(x) + 1)`.\n-    \"\"\"\n-    return K.softsign(x)\n-\n-\n-def relu(x, alpha=0., max_value=None, threshold=0.):\n-    \"\"\"Rectified Linear Unit.\n-\n-    With default values, it returns element-wise `max(x, 0)`.\n-\n-    Otherwise, it follows:\n-    `f(x) = max_value` for `x >= max_value`,\n-    `f(x) = x` for `threshold <= x < max_value`,\n-    `f(x) = alpha * (x - threshold)` otherwise.\n-\n-    # Arguments\n-        x: Input tensor.\n-        alpha: float. Slope of the negative part. Defaults to zero.\n-        max_value: float. Saturation threshold.\n-        threshold: float. Threshold value for thresholded activation.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return K.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n-\n-\n-def tanh(x):\n-    \"\"\"Hyperbolic tangent activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        The hyperbolic activation:\n-        `tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`\n-\n-    \"\"\"\n-    return K.tanh(x)\n-\n-\n-def sigmoid(x):\n-    \"\"\"Sigmoid activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        The sigmoid activation: `1 / (1 + exp(-x))`.\n-    \"\"\"\n-    return K.sigmoid(x)\n-\n-\n-def hard_sigmoid(x):\n-    \"\"\"Hard sigmoid activation function.\n-\n-    Faster to compute than sigmoid activation.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        Hard sigmoid activation:\n-\n-        - `0` if `x < -2.5`\n-        - `1` if `x > 2.5`\n-        - `0.2 * x + 0.5` if `-2.5 <= x <= 2.5`.\n-    \"\"\"\n-    return K.hard_sigmoid(x)\n-\n-\n-def exponential(x):\n-    \"\"\"Exponential (base e) activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        Exponential activation: `exp(x)`.\n-    \"\"\"\n-    return K.exp(x)\n-\n-\n-def linear(x):\n-    \"\"\"Linear (i.e. identity) activation function.\n-\n-    # Arguments\n-        x: Input tensor.\n-\n-    # Returns\n-        Input tensor, unchanged.\n-    \"\"\"\n-    return x\n-\n-\n-def serialize(activation):\n-    return activation.__name__\n-\n-\n-def deserialize(name, custom_objects=None):\n-    return deserialize_keras_object(\n-        name,\n-        module_objects=globals(),\n-        custom_objects=custom_objects,\n-        printable_module_name='activation function')\n-\n-\n-def get(identifier):\n-    \"\"\"Get the `identifier` activation function.\n-\n-    # Arguments\n-        identifier: None or str, name of the function.\n-\n-    # Returns\n-        The activation function, `linear` if `identifier` is None.\n-\n-    # Raises\n-        ValueError if unknown identifier\n-    \"\"\"\n-    if identifier is None:\n-        return linear\n-    if isinstance(identifier, six.string_types):\n-        identifier = str(identifier)\n-        return deserialize(identifier)\n-    elif callable(identifier):\n-        if isinstance(identifier, Layer):\n-            warnings.warn(\n-                'Do not pass a layer instance (such as {identifier}) as the '\n-                'activation argument of another layer. Instead, advanced '\n-                'activation layers should be used just like any other '\n-                'layer in a model.'.format(\n-                    identifier=identifier.__class__.__name__))\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret '\n-                         'activation function identifier:', identifier)\n+from tensorflow.keras.activations import get\n+from tensorflow.keras.activations import serialize\n+from tensorflow.keras.activations import deserialize\n\n@@ -1,27 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from .. import backend\n-from .. import layers\n-from .. import models\n-from .. import utils\n-\n-import keras_applications\n-\n-\n-def keras_modules_injection(base_fun):\n-\n-    def wrapper(*args, **kwargs):\n-        kwargs['backend'] = backend\n-        kwargs['layers'] = layers\n-        kwargs['models'] = models\n-        kwargs['utils'] = utils\n-        return base_fun(*args, **kwargs)\n-\n-    return wrapper\n-\n-\n from .vgg16 import VGG16\n from .vgg19 import VGG19\n from .resnet50 import ResNet50\n\n@@ -1,31 +1,5 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import densenet\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def DenseNet121(*args, **kwargs):\n-    return densenet.DenseNet121(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def DenseNet169(*args, **kwargs):\n-    return densenet.DenseNet169(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def DenseNet201(*args, **kwargs):\n-    return densenet.DenseNet201(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return densenet.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return densenet.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.densenet import DenseNet121\n+from tensorflow.keras.applications.densenet import DenseNet169\n+from tensorflow.keras.applications.densenet import DenseNet201\n+from tensorflow.keras.applications.densenet import decode_predictions\n+from tensorflow.keras.applications.densenet import preprocess_input\n\n@@ -1,19 +1,3 @@\n-\"\"\"Utilities for ImageNet data preprocessing & prediction decoding.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import imagenet_utils\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return imagenet_utils.decode_predictions(\n-        *args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return imagenet_utils.preprocess_input(*args, **kwargs)\n+\"\"\"Utilities for ImageNet data preprocessing & prediction decoding.\"\"\"\n+from tensorflow.keras.applications.imagenet_utils import decode_predictions\n+from tensorflow.keras.applications.imagenet_utils import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import inception_resnet_v2\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def InceptionResNetV2(*args, **kwargs):\n-    return inception_resnet_v2.InceptionResNetV2(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return inception_resnet_v2.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return inception_resnet_v2.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n+from tensorflow.keras.applications.inception_resnet_v2 import decode_predictions\n+from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import inception_v3\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def InceptionV3(*args, **kwargs):\n-    return inception_v3.InceptionV3(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return inception_v3.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return inception_v3.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.inception_v3 import InceptionV3\n+from tensorflow.keras.applications.inception_v3 import decode_predictions\n+from tensorflow.keras.applications.inception_v3 import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import mobilenet\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def MobileNet(*args, **kwargs):\n-    return mobilenet.MobileNet(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return mobilenet.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return mobilenet.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.mobilenet import MobileNet\n+from tensorflow.keras.applications.mobilenet import decode_predictions\n+from tensorflow.keras.applications.mobilenet import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import mobilenet_v2\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def MobileNetV2(*args, **kwargs):\n-    return mobilenet_v2.MobileNetV2(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return mobilenet_v2.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return mobilenet_v2.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n+from tensorflow.keras.applications.mobilenet_v2 import decode_predictions\n+from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n\n@@ -1,26 +1,4 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import nasnet\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def NASNetMobile(*args, **kwargs):\n-    return nasnet.NASNetMobile(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def NASNetLarge(*args, **kwargs):\n-    return nasnet.NASNetLarge(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return nasnet.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return nasnet.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.nasnet import NASNetMobile\n+from tensorflow.keras.applications.nasnet import NASNetLarge\n+from tensorflow.keras.applications.nasnet import decode_predictions\n+from tensorflow.keras.applications.nasnet import preprocess_input\n\n@@ -1,34 +1,5 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-try:\n-    from keras_applications import resnet\n-except:\n-    resnet = None\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def ResNet50(*args, **kwargs):\n-    return resnet.ResNet50(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def ResNet101(*args, **kwargs):\n-    return resnet.ResNet101(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def ResNet152(*args, **kwargs):\n-    return resnet.ResNet152(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return resnet.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return resnet.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.resnet import ResNet50\n+from tensorflow.keras.applications.resnet import ResNet101\n+from tensorflow.keras.applications.resnet import ResNet152\n+from tensorflow.keras.applications.resnet import decode_predictions\n+from tensorflow.keras.applications.resnet import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import resnet50\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def ResNet50(*args, **kwargs):\n-    return resnet50.ResNet50(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return resnet50.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return resnet50.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.resnet import ResNet50\n+from tensorflow.keras.applications.resnet import decode_predictions\n+from tensorflow.keras.applications.resnet import preprocess_input\n\n@@ -1,34 +1,5 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-try:\n-    from keras_applications import resnet_v2\n-except:\n-    resnet_v2 = None\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def ResNet50V2(*args, **kwargs):\n-    return resnet_v2.ResNet50V2(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def ResNet101V2(*args, **kwargs):\n-    return resnet_v2.ResNet101V2(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def ResNet152V2(*args, **kwargs):\n-    return resnet_v2.ResNet152V2(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return resnet_v2.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return resnet_v2.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n+from tensorflow.keras.applications.resnet_v2 import ResNet101V2\n+from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n+from tensorflow.keras.applications.resnet_v2 import decode_predictions\n+from tensorflow.keras.applications.resnet_v2 import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import vgg16\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def VGG16(*args, **kwargs):\n-    return vgg16.VGG16(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return vgg16.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return vgg16.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.vgg16 import VGG16\n+from tensorflow.keras.applications.vgg16 import decode_predictions\n+from tensorflow.keras.applications.vgg16 import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import vgg19\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def VGG19(*args, **kwargs):\n-    return vgg19.VGG19(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return vgg19.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return vgg19.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.vgg19 import VGG19\n+from tensorflow.keras.applications.vgg19 import decode_predictions\n+from tensorflow.keras.applications.vgg19 import preprocess_input\n\n@@ -1,21 +1,3 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from keras_applications import xception\n-from . import keras_modules_injection\n-\n-\n-@keras_modules_injection\n-def Xception(*args, **kwargs):\n-    return xception.Xception(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def decode_predictions(*args, **kwargs):\n-    return xception.decode_predictions(*args, **kwargs)\n-\n-\n-@keras_modules_injection\n-def preprocess_input(*args, **kwargs):\n-    return xception.preprocess_input(*args, **kwargs)\n+from tensorflow.keras.applications.xception import Xception\n+from tensorflow.keras.applications.xception import decode_predictions\n+from tensorflow.keras.applications.xception import preprocess_input\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.backend import *\n\\ No newline at end of file\n\n@@ -1,164 +0,0 @@\n-from .load_backend import epsilon\r\n-from .load_backend import set_epsilon\r\n-from .load_backend import floatx\r\n-from .load_backend import set_floatx\r\n-from .load_backend import cast_to_floatx\r\n-from .load_backend import image_data_format\r\n-from .load_backend import set_image_data_format\r\n-from .load_backend import reset_uids\r\n-from .load_backend import get_uid\r\n-from .load_backend import learning_phase\r\n-from .load_backend import set_learning_phase\r\n-from .load_backend import is_sparse\r\n-from .load_backend import to_dense\r\n-from .load_backend import variable\r\n-from .load_backend import is_variable\r\n-from .load_backend import constant\r\n-from .load_backend import is_keras_tensor\r\n-from .load_backend import is_tensor\r\n-from .load_backend import placeholder\r\n-from .load_backend import is_placeholder\r\n-from .load_backend import shape\r\n-from .load_backend import int_shape\r\n-from .load_backend import ndim\r\n-from .load_backend import dtype\r\n-from .load_backend import eval\r\n-from .load_backend import zeros\r\n-from .load_backend import ones\r\n-from .load_backend import eye\r\n-from .load_backend import zeros_like\r\n-from .load_backend import ones_like\r\n-from .load_backend import identity\r\n-from .load_backend import random_uniform_variable\r\n-from .load_backend import random_normal_variable\r\n-from .load_backend import count_params\r\n-from .load_backend import cast\r\n-from .load_backend import update\r\n-from .load_backend import update_add\r\n-from .load_backend import update_sub\r\n-from .load_backend import moving_average_update\r\n-from .load_backend import dot\r\n-from .load_backend import batch_dot\r\n-from .load_backend import transpose\r\n-from .load_backend import gather\r\n-from .load_backend import max\r\n-from .load_backend import min\r\n-from .load_backend import sum\r\n-from .load_backend import prod\r\n-from .load_backend import cumsum\r\n-from .load_backend import cumprod\r\n-from .load_backend import var\r\n-from .load_backend import std\r\n-from .load_backend import mean\r\n-from .load_backend import any\r\n-from .load_backend import all\r\n-from .load_backend import argmax\r\n-from .load_backend import argmin\r\n-from .load_backend import square\r\n-from .load_backend import abs\r\n-from .load_backend import sqrt\r\n-from .load_backend import exp\r\n-from .load_backend import log\r\n-from .load_backend import logsumexp\r\n-from .load_backend import round\r\n-from .load_backend import sign\r\n-from .load_backend import pow\r\n-from .load_backend import clip\r\n-from .load_backend import equal\r\n-from .load_backend import not_equal\r\n-from .load_backend import greater\r\n-from .load_backend import greater_equal\r\n-from .load_backend import less\r\n-from .load_backend import less_equal\r\n-from .load_backend import maximum\r\n-from .load_backend import minimum\r\n-from .load_backend import sin\r\n-from .load_backend import cos\r\n-from .load_backend import normalize_batch_in_training\r\n-from .load_backend import batch_normalization\r\n-from .load_backend import concatenate\r\n-from .load_backend import reshape\r\n-from .load_backend import permute_dimensions\r\n-from .load_backend import resize_images\r\n-from .load_backend import resize_volumes\r\n-from .load_backend import repeat_elements\r\n-from .load_backend import repeat\r\n-from .load_backend import arange\r\n-from .load_backend import tile\r\n-from .load_backend import flatten\r\n-from .load_backend import batch_flatten\r\n-from .load_backend import expand_dims\r\n-from .load_backend import squeeze\r\n-from .load_backend import temporal_padding\r\n-from .load_backend import spatial_2d_padding\r\n-from .load_backend import spatial_3d_padding\r\n-from .load_backend import stack\r\n-from .load_backend import one_hot\r\n-from .load_backend import reverse\r\n-from .load_backend import slice\r\n-from .load_backend import get_value\r\n-from .load_backend import batch_get_value\r\n-from .load_backend import set_value\r\n-from .load_backend import batch_set_value\r\n-from .load_backend import print_tensor\r\n-from .load_backend import function\r\n-from .load_backend import gradients\r\n-from .load_backend import stop_gradient\r\n-from .load_backend import rnn\r\n-from .load_backend import switch\r\n-from .load_backend import in_train_phase\r\n-from .load_backend import in_test_phase\r\n-from .load_backend import relu\r\n-from .load_backend import elu\r\n-from .load_backend import softmax\r\n-from .load_backend import softplus\r\n-from .load_backend import softsign\r\n-from .load_backend import categorical_crossentropy\r\n-from .load_backend import sparse_categorical_crossentropy\r\n-from .load_backend import binary_crossentropy\r\n-from .load_backend import sigmoid\r\n-from .load_backend import hard_sigmoid\r\n-from .load_backend import tanh\r\n-from .load_backend import dropout\r\n-from .load_backend import l2_normalize\r\n-from .load_backend import in_top_k\r\n-from .load_backend import conv1d\r\n-from .load_backend import separable_conv1d\r\n-from .load_backend import conv2d\r\n-from .load_backend import separable_conv2d\r\n-from .load_backend import conv2d_transpose\r\n-from .load_backend import depthwise_conv2d\r\n-from .load_backend import conv3d\r\n-from .load_backend import conv3d_transpose\r\n-from .load_backend import pool2d\r\n-from .load_backend import pool3d\r\n-from .load_backend import bias_add\r\n-from .load_backend import random_normal\r\n-from .load_backend import random_uniform\r\n-from .load_backend import random_binomial\r\n-from .load_backend import truncated_normal\r\n-from .load_backend import ctc_label_dense_to_sparse\r\n-from .load_backend import ctc_batch_cost\r\n-from .load_backend import ctc_decode\r\n-from .load_backend import map_fn\r\n-from .load_backend import foldl\r\n-from .load_backend import foldr\r\n-from .load_backend import local_conv1d\r\n-from .load_backend import local_conv2d\r\n-from .load_backend import backend\r\n-from .load_backend import normalize_data_format\r\n-from .load_backend import name_scope\r\n-from .load_backend import symbolic\r\n-from .load_backend import eager\r\n-from .load_backend import size\r\n-from .load_backend import control_dependencies\r\n-\r\n-if backend() == 'theano':\r\n-    from .load_backend import pattern_broadcast\r\n-elif backend() == 'tensorflow':\r\n-    from .load_backend import clear_session\r\n-    from .load_backend import manual_variable_initialization\r\n-    from .load_backend import get_session\r\n-    from .load_backend import set_session\r\n-elif backend() == 'cntk':\r\n-    from .load_backend import clear_session\r\n\n@@ -1,2921 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import cntk as C\n-import numpy as np\n-from .common import floatx\n-from .common import epsilon\n-from .common import image_data_format\n-from .common import normalize_data_format\n-from ..utils.generic_utils import transpose_shape\n-from collections import defaultdict\n-from contextlib import contextmanager\n-import warnings\n-\n-\n-C.set_global_option('align_axis', 1)\n-\n-b_any = any\n-py_slice = slice\n-\n-\n-dev = C.device.use_default_device()\n-if dev.type() == 0:\n-    warnings.warn(\n-        'CNTK backend warning: GPU is not detected. '\n-        'CNTK\\'s CPU version is not fully optimized,'\n-        'please run with GPU to get better performance.')\n-\n-# A learning phase is a bool tensor used to run Keras models in\n-# either train mode (learning_phase == 1) or test mode (learning_phase == 0).\n-# LEARNING_PHASE_PLACEHOLDER is the placeholder for dynamic learning phase\n-_LEARNING_PHASE_PLACEHOLDER = C.constant(\n-    shape=(), dtype=np.float32,\n-    value=1.0,\n-    name='_keras_learning_phase')\n-# static learning phase flag, if it is not 0 or 1, we will go with dynamic\n-# learning phase tensor.\n-_LEARNING_PHASE = -1\n-_UID_PREFIXES = defaultdict(int)\n-\n-# cntk doesn't support gradient as symbolic op, to hook up with keras model,\n-# we will create gradient as a constant placeholder, here use this global\n-# map to keep the mapping from grad placeholder to parameter\n-grad_parameter_dict = {}\n-\n-NAME_SCOPE_STACK = []\n-\n-\n-@contextmanager\n-def name_scope(name):\n-    global NAME_SCOPE_STACK\n-    NAME_SCOPE_STACK.append(name)\n-    yield\n-    NAME_SCOPE_STACK.pop()\n-\n-\n-def get_uid(prefix=''):\n-    _UID_PREFIXES[prefix] += 1\n-    return _UID_PREFIXES[prefix]\n-\n-\n-def learning_phase():\n-    # If _LEARNING_PHASE is not 0 or 1, return dynamic learning phase tensor\n-    if _LEARNING_PHASE in {0, 1}:\n-        return _LEARNING_PHASE\n-    else:\n-        return _LEARNING_PHASE_PLACEHOLDER\n-\n-\n-def set_learning_phase(value):\n-    global _LEARNING_PHASE\n-    if value not in {0, 1}:\n-        raise ValueError('CNTK Backend: Set learning phase '\n-                         'with value %s is not supported, '\n-                         'expected 0 or 1.' % value)\n-    _LEARNING_PHASE = value\n-\n-\n-def clear_session():\n-    \"\"\"Reset learning phase flag for cntk backend.\n-    \"\"\"\n-    global _LEARNING_PHASE\n-    global _LEARNING_PHASE_PLACEHOLDER\n-    _LEARNING_PHASE = -1\n-    _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(1.0)\n-\n-\n-def in_train_phase(x, alt, training=None):\n-    global _LEARNING_PHASE\n-    if training is None:\n-        training = learning_phase()\n-        uses_learning_phase = True\n-    else:\n-        uses_learning_phase = False\n-\n-    # CNTK currently don't support cond op, so here we use\n-    # element_select approach as workaround. It may have\n-    # perf issue, will resolve it later with cntk cond op.\n-    if callable(x) and isinstance(x, C.cntk_py.Function) is False:\n-        x = x()\n-    if callable(alt) and isinstance(alt, C.cntk_py.Function) is False:\n-        alt = alt()\n-\n-    if training is True:\n-        x._uses_learning_phase = uses_learning_phase\n-        return x\n-    else:\n-        # if _LEARNING_PHASE is static\n-        if isinstance(training, int) or isinstance(training, bool):\n-            result = x if training == 1 or training is True else alt\n-        else:\n-            result = C.element_select(training, x, alt)\n-        result._uses_learning_phase = uses_learning_phase\n-        return result\n-\n-\n-def in_test_phase(x, alt, training=None):\n-    return in_train_phase(alt, x, training=training)\n-\n-\n-def _convert_string_dtype(dtype):\n-    if dtype == 'float32':\n-        return np.float32\n-    elif dtype == 'float64':\n-        return np.float64\n-    elif dtype == 'float16':\n-        return np.float16\n-    else:\n-        # cntk only running with float,\n-        # try to cast to float to run the model\n-        return np.float32\n-\n-\n-def _convert_dtype_string(dtype):\n-    if dtype == np.float32:\n-        return 'float32'\n-    elif dtype == np.float64:\n-        return 'float64'\n-    elif dtype == np.float16:\n-        return 'float16'\n-    else:\n-        raise ValueError('CNTK Backend: Unsupported dtype: %s. '\n-                         'CNTK only supports float32, float64, and '\n-                         'float16.' % dtype)\n-\n-\n-def variable(value, dtype=None, name=None, constraint=None):\n-    \"\"\"Instantiates a variable and returns it.\n-\n-    # Arguments\n-        value: Numpy array, initial value of the tensor.\n-        dtype: Tensor type.\n-        name: Optional name string for the tensor.\n-        constraint: Optional projection function to be\n-            applied to the variable after an optimizer update.\n-\n-    # Returns\n-        A variable instance (with Keras metadata included).\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-\n-    if name is None:\n-        name = ''\n-\n-    if isinstance(\n-            value,\n-            C.variables.Constant) or isinstance(\n-            value,\n-            C.variables.Parameter):\n-        value = value.value\n-\n-    # we don't support init parameter with symbolic op, so eval it first as\n-    # workaround\n-    if isinstance(value, C.cntk_py.Function):\n-        value = eval(value)\n-\n-    shape = value.shape if hasattr(value, 'shape') else ()\n-    if hasattr(value, 'dtype') and value.dtype != dtype and len(shape) > 0:\n-        value = value.astype(dtype)\n-\n-    # TODO: remove the conversion when cntk supports int32, int64\n-    # https://www.cntk.ai/pythondocs/cntk.variables.html#cntk.variables.Parameter\n-    dtype = 'float32' if 'int' in str(dtype) else dtype\n-\n-    v = C.parameter(shape=shape,\n-                    init=value,\n-                    dtype=dtype,\n-                    name=_prepare_name(name, 'variable'))\n-    v._keras_shape = v.shape\n-    v._uses_learning_phase = False\n-    v.constraint = constraint\n-    return v\n-\n-\n-def is_variable(x):\n-    return isinstance(x, C.variables.Parameter)\n-\n-\n-def bias_add(x, bias, data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    dims = len(x.shape)\n-    if dims > 0 and x.shape[0] == C.InferredDimension:\n-        dims -= 1\n-\n-    bias_dims = len(bias.shape)\n-    if bias_dims != 1 and bias_dims != dims:\n-        raise ValueError('Unexpected bias dimensions %d, '\n-                         'expected 1 or %d dimensions' % (bias_dims, dims))\n-\n-    if dims == 4:\n-        if data_format == 'channels_first':\n-            if bias_dims == 1:\n-                shape = (bias.shape[0], 1, 1, 1)\n-            else:\n-                shape = (bias.shape[3],) + bias.shape[:3]\n-        elif data_format == 'channels_last':\n-            if bias_dims == 1:\n-                shape = (1, 1, 1, bias.shape[0])\n-            else:\n-                shape = bias.shape\n-    elif dims == 3:\n-        if data_format == 'channels_first':\n-            if bias_dims == 1:\n-                shape = (bias.shape[0], 1, 1)\n-            else:\n-                shape = (bias.shape[2],) + bias.shape[:2]\n-        elif data_format == 'channels_last':\n-            if bias_dims == 1:\n-                shape = (1, 1, bias.shape[0])\n-            else:\n-                shape = bias.shape\n-    elif dims == 2:\n-        if data_format == 'channels_first':\n-            if bias_dims == 1:\n-                shape = (bias.shape[0], 1)\n-            else:\n-                shape = (bias.shape[1],) + bias.shape[:1]\n-        elif data_format == 'channels_last':\n-            if bias_dims == 1:\n-                shape = (1, bias.shape[0])\n-            else:\n-                shape = bias.shape\n-    else:\n-        shape = bias.shape\n-    return x + reshape(bias, shape)\n-\n-\n-def eval(x):\n-    if isinstance(x, C.cntk_py.Function):\n-        return x.eval()\n-    elif (isinstance(x, C.variables.Constant) or isinstance(\n-            x, C.variables.Parameter)):\n-        return x.value\n-    else:\n-        raise ValueError('CNTK Backend: `eval` method on '\n-                         '`%s` type is not supported. '\n-                         'CNTK only supports `eval` with '\n-                         '`Function`, `Constant` or '\n-                         '`Parameter`.' % type(x))\n-\n-\n-def placeholder(\n-        shape=None,\n-        ndim=None,\n-        dtype=None,\n-        sparse=False,\n-        name=None,\n-        dynamic_axis_num=1):\n-    if dtype is None:\n-        dtype = floatx()\n-    if not shape:\n-        if ndim:\n-            shape = tuple([None for _ in range(ndim)])\n-\n-    if _get_cntk_version() >= 2.2:\n-        dynamic_dimension = C.FreeDimension\n-    else:\n-        dynamic_dimension = C.InferredDimension\n-\n-    cntk_shape = [dynamic_dimension if s is None else s for s in shape]\n-    cntk_shape = tuple(cntk_shape)\n-\n-    if dynamic_axis_num > len(cntk_shape):\n-        raise ValueError('CNTK backend: creating placeholder with '\n-                         '%d dimension is not supported, at least '\n-                         '%d dimensions are needed.'\n-                         % (len(cntk_shape), dynamic_axis_num))\n-\n-    if name is None:\n-        name = ''\n-\n-    cntk_shape = cntk_shape[dynamic_axis_num:]\n-\n-    x = C.input(\n-        shape=cntk_shape,\n-        dtype=_convert_string_dtype(dtype),\n-        is_sparse=sparse,\n-        name=name)\n-    x._keras_shape = shape\n-    x._uses_learning_phase = False\n-    x._cntk_placeholder = True\n-    return x\n-\n-\n-def is_placeholder(x):\n-    \"\"\"Returns whether `x` is a placeholder.\n-\n-    # Arguments\n-        x: A candidate placeholder.\n-\n-    # Returns\n-        Boolean.\n-    \"\"\"\n-    return hasattr(x, '_cntk_placeholder') and x._cntk_placeholder\n-\n-\n-def is_keras_tensor(x):\n-    if not is_tensor(x):\n-        raise ValueError('Unexpectedly found an instance of type `' +\n-                         str(type(x)) + '`. '\n-                         'Expected a symbolic tensor instance.')\n-    return hasattr(x, '_keras_history')\n-\n-\n-def is_tensor(x):\n-    return isinstance(x, (C.variables.Constant,\n-                          C.variables.Variable,\n-                          C.variables.Parameter,\n-                          C.ops.functions.Function))\n-\n-\n-def shape(x):\n-    shape = list(int_shape(x))\n-    num_dynamic = _get_dynamic_axis_num(x)\n-    non_dyn_shape = []\n-    for i in range(len(x.shape)):\n-        if shape[i + num_dynamic] is None:\n-            non_dyn_shape.append(x.shape[i])\n-        else:\n-            non_dyn_shape.append(shape[i + num_dynamic])\n-    return shape[:num_dynamic] + non_dyn_shape\n-\n-\n-def is_sparse(tensor):\n-    return tensor.is_sparse\n-\n-\n-def int_shape(x):\n-    if hasattr(x, '_keras_shape'):\n-        return x._keras_shape\n-\n-    if hasattr(x, 'shape'):\n-        shape = x.shape\n-    else:\n-        shape = np.array(x).shape\n-\n-    if hasattr(x, 'dynamic_axes'):\n-        dynamic_shape = [None for a in x.dynamic_axes]\n-        shape = tuple(dynamic_shape) + shape\n-    return shape\n-\n-\n-def ndim(x):\n-    shape = int_shape(x)\n-    return len(shape)\n-\n-\n-def _prepare_name(name, default):\n-    prefix = '_'.join(NAME_SCOPE_STACK)\n-    if name is None or name == '':\n-        return prefix + '/' + default\n-    return prefix + '/' + name\n-\n-\n-def constant(value, dtype=None, shape=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if shape is None:\n-        shape = ()\n-    np_value = value * np.ones(shape)\n-    const = C.constant(np_value,\n-                       dtype=dtype,\n-                       name=_prepare_name(name, 'constant'))\n-    const._keras_shape = const.shape\n-    const._uses_learning_phase = False\n-    return const\n-\n-\n-def random_binomial(shape, p=0.0, dtype=None, seed=None):\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e7)\n-    if dtype is None:\n-        dtype = floatx()\n-    else:\n-        dtype = _convert_string_dtype(dtype)\n-\n-    for _ in shape:\n-        if _ is None:\n-            raise ValueError('CNTK Backend: randomness op with '\n-                             'dynamic shape is not supported now. '\n-                             'Please provide fixed dimension '\n-                             'instead of `None`.')\n-    return C.random.bernoulli(shape=shape, dtype=dtype, mean=p, seed=seed)\n-\n-\n-def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n-    for _ in shape:\n-        if _ is None:\n-            raise ValueError('CNTK Backend: randomness op with '\n-                             'dynamic shape is not supported now. '\n-                             'Please provide fixed dimension '\n-                             'instead of `None`.')\n-\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e3)\n-    return C.random.uniform(\n-        shape=shape,\n-        dtype=dtype,\n-        low=minval,\n-        high=maxval,\n-        seed=seed)\n-\n-\n-def random_uniform_variable(shape, low, high,\n-                            dtype=None, name=None, seed=None):\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e3)\n-\n-    if dtype is None:\n-        dtype = floatx()\n-    else:\n-        dtype = _convert_string_dtype(dtype)\n-\n-    if name is None:\n-        name = ''\n-\n-    scale = (high - low) / 2\n-    p = C.parameter(\n-        shape,\n-        init=C.initializer.uniform(\n-            scale,\n-            seed=seed),\n-        dtype=dtype,\n-        name=name)\n-    return variable(value=p.value + low + scale)\n-\n-\n-def random_normal_variable(\n-        shape,\n-        mean,\n-        scale,\n-        dtype=None,\n-        name=None,\n-        seed=None):\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e7)\n-    if dtype is None:\n-        dtype = floatx()\n-    else:\n-        dtype = _convert_string_dtype(dtype)\n-\n-    if name is None:\n-        name = ''\n-\n-    p = C.parameter(\n-        shape=shape,\n-        init=C.initializer.normal(\n-            scale=scale,\n-            seed=seed),\n-        dtype=dtype,\n-        name=name)\n-    return variable(value=p.value + mean)\n-\n-\n-def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    for _ in shape:\n-        if _ is None:\n-            raise ValueError('CNTK Backend: randomness op with '\n-                             'dynamic shape is not supported now. '\n-                             'Please provide fixed dimension '\n-                             'instead of `None`.')\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e3)\n-    return C.random.normal(\n-        shape=shape, mean=mean,\n-        scale=stddev, seed=seed,\n-        dtype=dtype)\n-\n-\n-def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    if dtype is None:\n-        dtype = floatx()\n-    else:\n-        dtype = _convert_string_dtype(dtype)\n-\n-    return C.parameter(\n-        shape, init=C.initializer.truncated_normal(\n-            stddev, seed=seed), dtype=dtype)\n-\n-\n-def dtype(x):\n-    return _convert_dtype_string(x.dtype)\n-\n-\n-def zeros(shape, dtype=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    ctype = _convert_string_dtype(dtype)\n-    return variable(value=np.zeros(shape, ctype), dtype=dtype, name=name)\n-\n-\n-def ones(shape, dtype=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    ctype = _convert_string_dtype(dtype)\n-    return variable(value=np.ones(shape, ctype), dtype=dtype, name=name)\n-\n-\n-def eye(size, dtype=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if isinstance(size, (list, tuple)):\n-        n, m = size\n-    else:\n-        n, m = size, size\n-    return variable(np.eye(n, m), dtype, name)\n-\n-\n-def zeros_like(x, dtype=None, name=None):\n-    name = name or ''\n-    if dtype is None:\n-        dtype = floatx()\n-    return C.cast(C.zeros_like(x, name), dtype)\n-\n-\n-def ones_like(x, dtype=None, name=None):\n-    name = name or ''\n-    if dtype is None:\n-        dtype = floatx()\n-    return C.cast(C.ones_like(x, name), dtype)\n-\n-\n-def count_params(x):\n-    for _ in x.shape:\n-        if _ == C.InferredDimension or _ == C.FreeDimension:\n-            raise ValueError('CNTK backend: `count_params` with dynamic '\n-                             'shape is not supported. Please provide '\n-                             'fixed dimension instead of `None`.')\n-\n-    return np.prod(int_shape(x))\n-\n-\n-def cast(x, dtype):\n-    # cntk calculate everything in float, so don't need case from bool / int\n-    return x\n-\n-\n-def size(x, name=None):\n-    return sum(ones_like(x, name=name))\n-\n-\n-def dot(x, y):\n-    if len(x.shape) > 2 or len(y.shape) > 2:\n-        y_shape = int_shape(y)\n-        if len(y_shape) > 2:\n-            permutation = [len(y_shape) - 2]\n-            permutation += list(range(len(y_shape) - 2))\n-            permutation += [len(y_shape) - 1]\n-            y = C.transpose(y, perm=permutation)\n-        return C.times(x, y, len(y_shape) - 1)\n-    else:\n-        return C.times(x, y)\n-\n-\n-def batch_dot(x, y, axes=None):\n-    x_shape = int_shape(x)\n-    y_shape = int_shape(y)\n-\n-    x_ndim = len(x_shape)\n-    y_ndim = len(y_shape)\n-\n-    if x_ndim < 2 or y_ndim < 2:\n-        raise ValueError('Can not do batch_dot on inputs '\n-                         'with rank < 2. '\n-                         'Received inputs with shapes ' +\n-                         str(x_shape) + ' and ' +\n-                         str(y_shape) + '.')\n-\n-    x_batch_size = x_shape[0]\n-    y_batch_size = y_shape[0]\n-\n-    if x_batch_size is not None and y_batch_size is not None:\n-        if x_batch_size != y_batch_size:\n-            raise ValueError('Can not do batch_dot on inputs '\n-                             'with different batch sizes. '\n-                             'Received inputs with shapes ' +\n-                             str(x_shape) + ' and ' +\n-                             str(y_shape) + '.')\n-\n-    if isinstance(axes, int):\n-        axes = [axes, axes]\n-\n-    if axes is None:\n-        if y_ndim == 2:\n-            axes = [x_ndim - 1, y_ndim - 1]\n-        else:\n-            axes = [x_ndim - 1, y_ndim - 2]\n-\n-    if b_any([isinstance(a, (list, tuple)) for a in axes]):\n-        raise ValueError('Multiple target dimensions are not supported. ' +\n-                         'Expected: None, int, (int, int), ' +\n-                         'Provided: ' + str(axes))\n-\n-    # if tuple, convert to list\n-    axes = list(axes)\n-\n-    # convert negative indices\n-    if axes[0] < 0:\n-        axes[0] += x_ndim\n-    if axes[1] < 0:\n-        axes[1] += y_ndim\n-\n-    if 0 in axes:\n-        raise ValueError('Can not perform batch_dot over axis 0.'\n-                         ' If your inputs are not batched,'\n-                         ' add a dummy batch dimension to your '\n-                         'inputs using K.expand_dims(x, 0)')\n-    d1 = x_shape[axes[0]]\n-    d2 = y_shape[axes[1]]\n-\n-    if d1 is not None and d2 is not None and d1 != d2:\n-        raise ValueError('Can not do batch_dot on inputs with shapes ' +\n-                         str(x_shape) + ' and ' + str(y_shape) +\n-                         ' with axes=' + str(axes) + '. x.shape[%d] != '\n-                         'y.shape[%d] (%d != %d).' % (axes[0], axes[1], d1, d2))\n-\n-    # Input shapes:\n-    # x: (b_size, x1, ..., d, ..., xn)\n-    # y: (b_size, y1, ..., d, ..., yn)\n-    # where d is the dimension to reduce.\n-\n-    # Bring d to the last dimension in x\n-    # x: (b_size, ..., d)\n-\n-    permute_pattern = list(range(x_ndim))\n-    for i in range(axes[0], x_ndim - 1):\n-        permute_pattern[i] = permute_pattern[i + 1]\n-    permute_pattern[-1] = axes[0]\n-\n-    x = permute_dimensions(x, permute_pattern)\n-\n-    # Bring d to the second dimension in y\n-    # y: (b_size, d, ...)\n-    permute_pattern = list(range(y_ndim))\n-\n-    for i in range(axes[1], 1, -1):\n-        permute_pattern[i] = permute_pattern[i - 1]\n-    permute_pattern[1] = axes[1]\n-    y = permute_dimensions(y, permute_pattern)\n-\n-    # Expand to rank 3 if needed\n-    if x_ndim == 2:\n-        x = expand_dims(x, 1)\n-        x_expanded = True\n-    else:\n-        x_expanded = False\n-\n-    if y_ndim == 2:\n-        y = expand_dims(y, -1)\n-        y_expanded = True\n-    else:\n-        y_expanded = False\n-\n-    x_shape = int_shape(x)\n-    y_shape = int_shape(y)\n-\n-    # batch size might be lost at this point\n-    x_batch_size = x_shape[0]\n-    y_batch_size = y_shape[0]\n-\n-    if x_batch_size is None and y_batch_size is None:\n-        dynamic_batch_size = True\n-    elif x_batch_size is not None and y_batch_size is not None:\n-        dynamic_batch_size = False\n-    else:\n-        raise ValueError('Can not perform batch_dot on inputs' +\n-                         ' with both static and dynamic batch sizes.' +\n-                         'You probably attempted to permform the ' +\n-                         'operation on a placeholder and a variable, ' +\n-                         'which is not yet supported on the CNTK backend.')\n-\n-    if dynamic_batch_size:\n-        result = C.times(x, y, output_rank=y_ndim - 2 + int(y_expanded))\n-    else:\n-        result = []\n-\n-        for i in range(x_batch_size):\n-            xi = x[i]\n-            yi = y[i]\n-            if ndim(xi) == ndim(x):  # for older versions of CNTK\n-                xi = squeeze(xi, 0)\n-                yi = squeeze(yi, 0)\n-            result.append(C.times(xi, yi, output_rank=y_ndim - 2 + int(y_expanded)))\n-        result = stack(result, 0)\n-\n-    if x_expanded:\n-        result = squeeze(result, 1)\n-\n-    if y_expanded:\n-        result = squeeze(result, -1)\n-\n-    if ndim(result) == 1:\n-        return expand_dims(result)\n-    return result\n-\n-\n-def transpose(x):\n-    return C.swapaxes(x, 0, 1)\n-\n-\n-def gather(reference, indices):\n-    # There is a bug in cntk gather op which may cause crash.\n-    # We have made a fix but not catched in CNTK 2.1 release.\n-    # Will update with gather op in next release\n-    if _get_cntk_version() >= 2.2:\n-        return C.ops.gather(reference, indices)\n-    else:\n-        num_classes = reference.shape[0]\n-        one_hot_matrix = C.ops.one_hot(indices, num_classes)\n-        return C.times(\n-            one_hot_matrix, reference,\n-            output_rank=len(reference.shape) - 1)\n-\n-\n-def _remove_dims(x, axis, keepdims=False):\n-    if keepdims is False and isinstance(axis, list):\n-        # sequence axis is removed by default, so don't need reshape on it\n-        reduce_axes = []\n-        for a in axis:\n-            if isinstance(a, C.Axis) is False:\n-                reduce_axes.append(a)\n-        return _reshape_dummy_dim(x, reduce_axes)\n-    else:\n-        if isinstance(axis, list):\n-            has_seq = False\n-            for a in axis:\n-                if isinstance(a, C.Axis):\n-                    has_seq = True\n-                    break\n-            if has_seq:\n-                nones = _get_dynamic_axis_num(x)\n-                x = expand_dims(x, nones)\n-        return x\n-\n-\n-def max(x, axis=None, keepdims=False):\n-    axis = _normalize_axis(axis, x)\n-    output = _reduce_on_axis(x, axis, 'reduce_max')\n-\n-    return _remove_dims(output, axis, keepdims)\n-\n-\n-def min(x, axis=None, keepdims=False):\n-    axis = _normalize_axis(axis, x)\n-    output = _reduce_on_axis(x, axis, 'reduce_min')\n-\n-    return _remove_dims(output, axis, keepdims)\n-\n-\n-def sum(x, axis=None, keepdims=False):\n-    axis = _normalize_axis(axis, x)\n-    output = _reduce_on_axis(x, axis, 'reduce_sum')\n-\n-    return _remove_dims(output, axis, keepdims)\n-\n-\n-def prod(x, axis=None, keepdims=False):\n-    axis = _normalize_axis(axis, x)\n-    output = _reduce_on_axis(x, axis, 'reduce_prod')\n-\n-    return _remove_dims(output, axis, keepdims)\n-\n-\n-def logsumexp(x, axis=None, keepdims=False):\n-    return log(sum(exp(x), axis=axis, keepdims=keepdims))\n-\n-\n-def var(x, axis=None, keepdims=False):\n-    m = mean(x, axis, keepdims=True)\n-    devs_squared = C.square(x - m)\n-    return mean(devs_squared, axis=axis, keepdims=keepdims)\n-\n-\n-def std(x, axis=None, keepdims=False):\n-    return C.sqrt(var(x, axis=axis, keepdims=keepdims))\n-\n-\n-def expand_dims(x, axis=-1):\n-    shape = list(int_shape(x))\n-    nones = _get_dynamic_axis_num(x)\n-    index = axis if axis >= 0 else len(shape) + 1\n-    shape.insert(index, 1)\n-    new_shape = shape[nones:]\n-    new_shape = tuple(\n-        [C.InferredDimension if _ is None else _ for _ in new_shape])\n-    result = C.reshape(x, new_shape)\n-    if index < nones:\n-        result._keras_shape = shape\n-    return result\n-\n-\n-def squeeze(x, axis):\n-    if isinstance(axis, tuple):\n-        axis = list(axis)\n-    if not isinstance(axis, list):\n-        axis = [axis]\n-\n-    shape = list(int_shape(x))\n-\n-    _axis = []\n-    for _ in axis:\n-        if isinstance(_, int):\n-            _axis.append(_ if _ >= 0 else _ + len(shape))\n-\n-    if len(_axis) == 0:\n-        return x\n-\n-    nones = _get_dynamic_axis_num(x)\n-    for _ in sorted(_axis, reverse=True):\n-        del shape[_]\n-\n-    new_shape = shape[nones:]\n-\n-    new_shape_temp = []\n-    for _ in new_shape:\n-        if _ == C.FreeDimension:\n-            new_shape_temp.append(C.InferredDimension)\n-        else:\n-            new_shape_temp.append(_)\n-\n-    new_shape = tuple(new_shape_temp)\n-\n-    return C.reshape(x, new_shape)\n-\n-\n-def tile(x, n):\n-    if isinstance(n, int):\n-        n = (n,)\n-    elif isinstance(n, list):\n-        n = tuple(n)\n-\n-    shape = int_shape(x)\n-    num_dynamic_axis = _get_dynamic_axis_num(x)\n-    if len(n) < len(shape):  # Padding the axis\n-        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n-    elif len(n) != len(shape):\n-        raise NotImplementedError\n-\n-    i = num_dynamic_axis\n-    for i, rep in enumerate(n):\n-        if i >= num_dynamic_axis and shape[i] is not None:\n-            tmp = [x] * rep\n-            x = C.splice(*tmp, axis=i - num_dynamic_axis)\n-        i += 1\n-\n-    return x\n-\n-\n-def _normalize_axis(axis, x):\n-    shape = int_shape(x)\n-    ndim = len(shape)\n-\n-    nones = _get_dynamic_axis_num(x)\n-\n-    if nones > ndim:\n-        raise ValueError(\n-            'CNTK Backend: tensor with keras shape: `%s` has '\n-            '%d cntk dynamic axis, this is not expected, please '\n-            'double check the keras shape history.'\n-            % (str(shape), nones))\n-\n-    # Current cntk does not support shape like (1, batch). so using the workaround\n-    # here to mapping the correct axis. Will remove this tricky after we add support\n-    # in native cntk op\n-    cntk_axis = []\n-    dynamic_axis_index = 0\n-    for i in range(ndim):\n-        if shape[i] is None and dynamic_axis_index < nones:\n-            cntk_axis.append(x.dynamic_axes[dynamic_axis_index])\n-            dynamic_axis_index += 1\n-        else:\n-            cntk_axis.append(i - dynamic_axis_index)\n-\n-    if dynamic_axis_index < nones:\n-        i = 0\n-        while dynamic_axis_index < nones:\n-            cntk_axis[i] = x.dynamic_axes[dynamic_axis_index]\n-            i += 1\n-            dynamic_axis_index += 1\n-\n-        while i < len(cntk_axis):\n-            cntk_axis[i] -= nones\n-            i += 1\n-\n-    if isinstance(axis, tuple):\n-        _axis = list(axis)\n-    elif isinstance(axis, int):\n-        _axis = [axis]\n-    elif isinstance(axis, list):\n-        _axis = list(axis)\n-    else:\n-        _axis = axis\n-\n-    if isinstance(_axis, list):\n-        for i, a in enumerate(_axis):\n-            if a is not None and a < 0:\n-                _axis[i] = (a % ndim)\n-            if _axis[i] is not None:\n-                _axis[i] = cntk_axis[_axis[i]]\n-    else:\n-        if _axis is None:\n-            _axis = C.Axis.all_axes()\n-\n-    return _axis\n-\n-\n-def _reshape_dummy_dim(x, axis):\n-    shape = list(x.shape)\n-\n-    _axis = [_ + len(shape) if _ < 0 else _ for _ in axis]\n-\n-    if shape.count(C.InferredDimension) > 1 or shape.count(C.FreeDimension) > 1:\n-        result = x\n-        for index in sorted(_axis, reverse=True):\n-            result = C.reshape(result,\n-                               shape=(),\n-                               begin_axis=index,\n-                               end_axis=index + 1)\n-        return result\n-    else:\n-        for index in sorted(_axis, reverse=True):\n-            del shape[index]\n-\n-        shape = [C.InferredDimension if _ == C.FreeDimension else _ for _ in shape]\n-        return C.reshape(x, shape)\n-\n-\n-def mean(x, axis=None, keepdims=False):\n-    axis = _normalize_axis(axis, x)\n-    output = _reduce_on_axis(x, axis, 'reduce_mean')\n-\n-    return _remove_dims(output, axis, keepdims)\n-\n-\n-def any(x, axis=None, keepdims=False):\n-    reduce_result = sum(x, axis, keepdims=keepdims)\n-    any_matrix = C.element_select(\n-        reduce_result,\n-        ones_like(reduce_result),\n-        zeros_like(reduce_result))\n-    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n-        return C.reduce_sum(any_matrix)\n-    else:\n-        return any_matrix\n-\n-\n-def all(x, axis=None, keepdims=False):\n-    reduce_result = prod(x, axis, keepdims=keepdims)\n-    all_matrix = C.element_select(\n-        reduce_result,\n-        ones_like(reduce_result),\n-        zeros_like(reduce_result))\n-    if len(reduce_result.shape) == 0 and _get_dynamic_axis_num(x) == 0:\n-        return C.reduce_sum(all_matrix)\n-    else:\n-        return all_matrix\n-\n-\n-def classification_error(target, output, axis=-1):\n-    return C.ops.reduce_mean(\n-        C.equal(\n-            argmax(\n-                output,\n-                axis=-1),\n-            argmax(\n-                target,\n-                axis=-1)),\n-        axis=C.Axis.all_axes())\n-\n-\n-def argmax(x, axis=-1):\n-    axis = [axis]\n-    axis = _normalize_axis(axis, x)\n-    output = C.ops.argmax(x, axis=axis[0])\n-    return _reshape_dummy_dim(output, axis)\n-\n-\n-def argmin(x, axis=-1):\n-    axis = [axis]\n-    axis = _normalize_axis(axis, x)\n-    output = C.ops.argmin(x, axis=axis[0])\n-    return _reshape_dummy_dim(output, axis)\n-\n-\n-def square(x):\n-    return C.square(x)\n-\n-\n-def abs(x):\n-    return C.abs(x)\n-\n-\n-def sqrt(x):\n-    return C.sqrt(x)\n-\n-\n-def exp(x):\n-    return C.exp(x)\n-\n-\n-def log(x):\n-    return C.log(x)\n-\n-\n-def round(x):\n-    return C.round(x)\n-\n-\n-def sigmoid(x):\n-    return C.sigmoid(x)\n-\n-\n-def sign(x):\n-    return x / C.abs(x)\n-\n-\n-def pow(x, a):\n-    return C.pow(x, a)\n-\n-\n-def clip(x, min_value, max_value):\n-    if (isinstance(min_value, (int, float)) and\n-            isinstance(max_value, (int, float))):\n-        if max_value < min_value:\n-            max_value = min_value\n-    if min_value is None:\n-        min_value = -np.inf\n-    if max_value is None:\n-        max_value = np.inf\n-    return C.clip(x, min_value, max_value)\n-\n-\n-def binary_crossentropy(target, output, from_logits=False):\n-    if from_logits:\n-        output = C.sigmoid(output)\n-    output = C.clip(output, epsilon(), 1.0 - epsilon())\n-    output = -target * C.log(output) - (1.0 - target) * C.log(1.0 - output)\n-    return output\n-\n-\n-def get_variable_shape(x):\n-    return int_shape(x)\n-\n-\n-def update(x, new_x):\n-    return C.assign(x, new_x)\n-\n-\n-def moving_average_update(variable, value, momentum):\n-    return C.assign(variable, variable * momentum + value * (1. - momentum))\n-\n-\n-def update_add(x, increment):\n-    result = x + increment\n-    return C.assign(x, result)\n-\n-\n-def update_sub(x, decrement):\n-    result = x - decrement\n-    return C.assign(x, result)\n-\n-\n-def gradients(loss, variables):\n-    # cntk does not support gradients as symbolic op,\n-    # to hook up with keras model\n-    # we will return a constant as place holder, the cntk learner will apply\n-    # the gradient during training.\n-    global grad_parameter_dict\n-    if isinstance(variables, list) is False:\n-        variables = [variables]\n-    grads = []\n-    for v in variables:\n-        g = C.constant(0, shape=v.shape, name='keras_grad_placeholder')\n-        grads.append(g)\n-        grad_parameter_dict[g] = v\n-    return grads\n-\n-\n-def equal(x, y):\n-    return C.equal(x, y)\n-\n-\n-def not_equal(x, y):\n-    return C.not_equal(x, y)\n-\n-\n-def greater(x, y):\n-    return C.greater(x, y)\n-\n-\n-def greater_equal(x, y):\n-    return C.greater_equal(x, y)\n-\n-\n-def less(x, y):\n-    return C.less(x, y)\n-\n-\n-def less_equal(x, y):\n-    return C.less_equal(x, y)\n-\n-\n-def maximum(x, y):\n-    return C.element_max(x, y)\n-\n-\n-def minimum(x, y):\n-    return C.element_min(x, y)\n-\n-\n-def sin(x):\n-    return C.sin(x)\n-\n-\n-def cos(x):\n-    return C.cos(x)\n-\n-\n-def normalize_batch_in_training(x, gamma, beta,\n-                                reduction_axes, epsilon=1e-3):\n-    if gamma is None:\n-        if beta is None:\n-            gamma = ones_like(x)\n-        else:\n-            gamma = ones_like(beta)\n-    if beta is None:\n-        if gamma is None:\n-            beta = zeros_like(x)\n-        else:\n-            beta = zeros_like(gamma)\n-\n-    mean, variant = _moments(x, _normalize_axis(reduction_axes, x))\n-\n-    if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n-        normalized = batch_normalization(\n-            x, mean, variant, beta, gamma, epsilon)\n-    else:\n-        # need broadcasting\n-        target_shape = []\n-        x_shape = int_shape(x)\n-        # skip the batch axis\n-        for axis in range(1, ndim(x)):\n-            if axis in reduction_axes:\n-                target_shape.append(1)\n-                if ndim(gamma) > axis:\n-                    gamma = C.reduce_mean(gamma, axis - 1)\n-                    beta = C.reduce_mean(beta, axis - 1)\n-            else:\n-                target_shape.append(x_shape[axis])\n-\n-        broadcast_mean = C.reshape(mean, target_shape)\n-        broadcast_var = C.reshape(variant, target_shape)\n-        broadcast_gamma = C.reshape(gamma, target_shape)\n-        broadcast_beta = C.reshape(beta, target_shape)\n-        normalized = batch_normalization(\n-            x,\n-            broadcast_mean,\n-            broadcast_var,\n-            broadcast_beta,\n-            broadcast_gamma,\n-            epsilon)\n-\n-    return normalized, mean, variant\n-\n-\n-def _moments(x, axes=None, shift=None, keep_dims=False):\n-    _axes = tuple(axes)\n-    if shift is None:\n-        shift = x\n-        # Compute true mean while keeping the dims for proper broadcasting.\n-        for axis in _axes:\n-            shift = C.reduce_mean(shift, axis=axis)\n-\n-    shift = C.stop_gradient(shift)\n-    shifted_mean = C.minus(x, shift)\n-    for axis in _axes:\n-        shifted_mean = C.reduce_mean(shifted_mean, axis=axis)\n-\n-    variance_mean = C.square(C.minus(x, shift))\n-    for axis in _axes:\n-        variance_mean = C.reduce_mean(variance_mean, axis=axis)\n-\n-    variance = C.minus(variance_mean, C.square(shifted_mean))\n-    mean = C.plus(shifted_mean, shift)\n-\n-    if not keep_dims:\n-        mean = squeeze(mean, _axes)\n-        variance = squeeze(variance, _axes)\n-\n-    return mean, variance\n-\n-\n-def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n-    # The mean / var / beta / gamma may be processed by broadcast\n-    # so it may have an extra batch axis with 1, it is not needed\n-    # in cntk, need to remove those dummy axis.\n-    if ndim(mean) == ndim(x) and shape(mean)[0] == 1:\n-        mean = _reshape_dummy_dim(mean, [0])\n-    if ndim(var) == ndim(x) and shape(var)[0] == 1:\n-        var = _reshape_dummy_dim(var, [0])\n-\n-    if gamma is None:\n-        gamma = ones_like(var)\n-    elif ndim(gamma) == ndim(x) and shape(gamma)[0] == 1:\n-        gamma = _reshape_dummy_dim(gamma, [0])\n-\n-    if beta is None:\n-        beta = zeros_like(mean)\n-    elif ndim(beta) == ndim(x) and shape(beta)[0] == 1:\n-        beta = _reshape_dummy_dim(beta, [0])\n-\n-    return (x - mean) / C.sqrt(var + epsilon) * gamma + beta\n-\n-\n-def concatenate(tensors, axis=-1):\n-    if len(tensors) == 0:\n-        return None\n-\n-    axis = [axis]\n-    axis = _normalize_axis(axis, tensors[0])\n-    return C.splice(*tensors, axis=axis[0])\n-\n-\n-def stack(x, axis=0):\n-    x = [expand_dims(t, axis) for t in x]\n-    return concatenate(x, axis)\n-\n-\n-def flatten(x):\n-    return reshape(x, (-1,))\n-\n-\n-def reshape(x, shape):\n-    shape_temp = []\n-    for _ in shape:\n-        if _ == C.FreeDimension:\n-            shape_temp.append(C.InferredDimension)\n-        else:\n-            shape_temp.append(_)\n-\n-    shape = tuple(shape_temp)\n-\n-    if isinstance(x, C.variables.Parameter):\n-        return C.reshape(x, shape)\n-    else:\n-        num_dynamic_axis = _get_dynamic_axis_num(x)\n-\n-        if num_dynamic_axis == 1 and len(shape) > 0 and shape[0] == -1:\n-            # collapse axis with batch axis\n-            if b_any(_ == C.InferredDimension for _ in x.shape) or b_any(\n-                    _ == C.FreeDimension for _ in x.shape):\n-                warnings.warn(\n-                    'Warning: CNTK backend does not support '\n-                    'collapse of batch axis with inferred dimension. '\n-                    'The reshape did not take place.')\n-                return x\n-            return _reshape_batch(x, shape)\n-        else:\n-            # no collapse, then first need to padding the shape\n-            if num_dynamic_axis >= len(shape):\n-                i = 0\n-                while i < len(shape):\n-                    if shape[i] is None or shape[i] == -1:\n-                        i += 1\n-                    else:\n-                        break\n-                shape = tuple([-1 for _ in range(num_dynamic_axis - i)]) + shape\n-\n-            new_shape = list(shape)\n-            new_shape = new_shape[num_dynamic_axis:]\n-            new_shape = [C.InferredDimension if _ is None else _ for _ in new_shape]\n-            return C.reshape(x, new_shape)\n-\n-\n-def permute_dimensions(x, pattern):\n-    dims = len(int_shape(x))\n-    num_dynamic_axis = _get_dynamic_axis_num(x)\n-    if isinstance(pattern, list):\n-        current_layout = [i for i in range(dims)]\n-    else:\n-        current_layout = tuple([i for i in range(dims)])\n-\n-    if (num_dynamic_axis > 0 and\n-            pattern[:num_dynamic_axis] != current_layout[:num_dynamic_axis]):\n-                raise ValueError('CNTK backend: the permute pattern %s '\n-                                 'requested permute on dynamic axis, '\n-                                 'which is not supported. Please do permute '\n-                                 'on static axis.' % pattern)\n-\n-    axis = list(pattern)\n-    axis = axis[num_dynamic_axis:]\n-    axis = _normalize_axis(axis, x)\n-    return C.transpose(x, axis)\n-\n-\n-def resize_images(x, height_factor, width_factor, data_format,\n-                  interpolation='nearest'):\n-    if interpolation == 'nearest':\n-        if data_format == 'channels_first':\n-            output = repeat_elements(x, height_factor, axis=2)\n-            output = repeat_elements(output, width_factor, axis=3)\n-            return output\n-        elif data_format == 'channels_last':\n-            output = repeat_elements(x, height_factor, axis=1)\n-            output = repeat_elements(output, width_factor, axis=2)\n-            return output\n-        else:\n-            raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)\n-    else:\n-        raise NotImplementedError('CNTK only supports `nearest` interpolation.')\n-\n-\n-def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n-    if data_format == 'channels_first':\n-        output = repeat_elements(x, depth_factor, axis=2)\n-        output = repeat_elements(output, height_factor, axis=3)\n-        output = repeat_elements(output, width_factor, axis=4)\n-        return output\n-    elif data_format == 'channels_last':\n-        output = repeat_elements(x, depth_factor, axis=1)\n-        output = repeat_elements(output, height_factor, axis=2)\n-        output = repeat_elements(output, width_factor, axis=3)\n-        return output\n-    else:\n-        raise ValueError('CNTK Backend: Invalid data_format: %s' % data_format)\n-\n-\n-def repeat_elements(x, rep, axis):\n-    axis = _normalize_axis(axis, x)\n-    axis = axis[0]\n-    slices = []\n-    shape = x.shape\n-    i = 0\n-    while i < shape[axis]:\n-        tmp = C.ops.slice(x, axis, i, i + 1)\n-        for _ in range(rep):\n-            slices.append(tmp)\n-        i += 1\n-    return C.splice(*slices, axis=axis)\n-\n-\n-def repeat(x, n):\n-    # this is a workaround for recurrent layer\n-    # if n is inferred dimension,\n-    # we can't figure out how to repeat it in cntk now\n-    # return the same x to take cntk broadcast feature\n-    # to make the recurrent layer work.\n-    # need to be fixed in GA.\n-    if n is C.InferredDimension or n is C.FreeDimension:\n-        return x\n-    index = 1 - _get_dynamic_axis_num(x)\n-    if index < 0 or index > 1:\n-        raise NotImplementedError\n-\n-    new_shape = list(x.shape)\n-    new_shape.insert(index, 1)\n-    new_shape = tuple(new_shape)\n-    x = C.reshape(x, new_shape)\n-    temp = [x] * n\n-    return C.splice(*temp, axis=index)\n-\n-\n-def tanh(x):\n-    return C.tanh(x)\n-\n-\n-def _static_rnn(step_function, inputs, initial_states,\n-                go_backwards=False, mask=None, constants=None,\n-                unroll=False, input_length=None):\n-\n-    shape = int_shape(inputs)\n-    dims = len(shape)\n-\n-    uses_learning_phase = False\n-\n-    if dims < 3:\n-        raise ValueError('Input should be at least 3D.')\n-\n-    # if the second axis is static axis, CNTK will do unroll by default\n-    if shape[1] is None:\n-        raise ValueError('CNTK Backend: the input of static rnn '\n-                         'has shape `%s`, the second axis '\n-                         'is not static. If you want to run '\n-                         'rnn with non-static axis, please try '\n-                         'dynamic rnn with sequence axis.' % shape)\n-    if constants is None:\n-        constants = []\n-\n-    if mask is not None:\n-        mask_shape = int_shape(mask)\n-        if len(mask_shape) == dims - 1:\n-            mask = expand_dims(mask)\n-\n-    nones = _get_dynamic_axis_num(inputs)\n-\n-    states = tuple(initial_states)\n-\n-    outputs = []\n-\n-    time_axis = 1 - nones if nones > 0 else 1\n-\n-    if go_backwards:\n-        i = shape[1] - 1\n-        while i >= 0:\n-            current = C.ops.slice(inputs, time_axis, i, i + 1)\n-            # remove dummy dimension\n-            current = squeeze(current, time_axis)\n-\n-            output, new_states = step_function(\n-                current, tuple(states) + tuple(constants))\n-            if getattr(output, '_uses_learning_phase', False):\n-                uses_learning_phase = True\n-\n-            if mask is not None:\n-                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n-                mask_slice = squeeze(mask_slice, time_axis)\n-                if len(outputs) == 0:\n-                    prev_output = zeros_like(output)\n-                else:\n-                    prev_output = outputs[-1]\n-                output = C.ops.element_select(mask_slice, output, prev_output)\n-\n-                return_states = []\n-                for s, n_s in zip(states, new_states):\n-                    return_states.append(\n-                        C.ops.element_select(\n-                            mask_slice, n_s, s))\n-                new_states = return_states\n-            outputs.append(output)\n-            states = new_states\n-            i -= 1\n-    else:\n-        i = 0\n-        while i < shape[1]:\n-            current = C.ops.slice(inputs, time_axis, i, i + 1)\n-            # remove dummy dimension\n-            current = squeeze(current, 1)\n-\n-            output, new_states = step_function(\n-                current, tuple(states) + tuple(constants))\n-            if getattr(output, '_uses_learning_phase', False):\n-                uses_learning_phase = True\n-\n-            if mask is not None:\n-                mask_slice = C.ops.slice(mask, time_axis, i, i + 1)\n-                mask_slice = squeeze(mask_slice, 1)\n-                if len(outputs) == 0:\n-                    prev_output = zeros_like(output)\n-                else:\n-                    prev_output = outputs[-1]\n-                output = C.ops.element_select(mask_slice, output, prev_output)\n-\n-                return_states = []\n-                for s, n_s in zip(states, new_states):\n-                    return_states.append(\n-                        C.ops.element_select(\n-                            mask_slice, n_s, s))\n-                new_states = return_states\n-            outputs.append(output)\n-            states = new_states[:len(states)]\n-            i += 1\n-\n-    i = 1\n-    # add the time_step axis back\n-    final_output = expand_dims(outputs[0], 1)\n-    last_output = outputs[0]\n-    while i < len(outputs):\n-        # add the time_step axis back\n-        output_slice = expand_dims(outputs[i], 1)\n-        final_output = C.splice(final_output, output_slice, axis=time_axis)\n-        last_output = outputs[i]\n-        i += 1\n-\n-    last_output._uses_learning_phase = uses_learning_phase\n-    return last_output, final_output, states\n-\n-\n-def rnn(step_function, inputs, initial_states,\n-        go_backwards=False, mask=None, constants=None,\n-        unroll=False, input_length=None):\n-\n-    if not unroll and mask is not None:\n-        warnings.warn(\n-            'CNTK Backend only supports accurate masking if '\n-            '`output == new_states[0]` for '\n-            '`output, new_states = step_function(inputs, states)`')\n-\n-    shape = int_shape(inputs)\n-    dims = len(shape)\n-\n-    global uses_learning_phase\n-    uses_learning_phase = False\n-\n-    if dims < 3:\n-        raise ValueError('CNTK Backend: the input of rnn has only rank %d '\n-                         'Need at least rank 3 to run RNN.' % dims)\n-\n-    if _get_dynamic_axis_num(inputs) == 0 or unroll:\n-        return _static_rnn(\n-            step_function,\n-            inputs,\n-            initial_states,\n-            go_backwards,\n-            mask,\n-            constants,\n-            unroll,\n-            input_length)\n-\n-    if constants is None:\n-        constants = []\n-\n-    num_time_step = shape[1]\n-    if num_time_step is None and not has_seq_axis(inputs):\n-        num_time_step = inputs.shape[0]\n-\n-    initial = []\n-    for s in initial_states:\n-        if _get_dynamic_axis_num(s) == 0:\n-            if hasattr(C, 'to_batch'):\n-                initial.append(C.to_batch(s))\n-            else:\n-                initial.append(C.user_function(ConvertToBatch(s)))\n-        else:\n-            initial.append(s)\n-\n-    need_convert = not has_seq_axis(inputs)\n-    if go_backwards and need_convert is False:\n-        raise NotImplementedError(\n-            'CNTK Backend: `go_backwards` is not supported with '\n-            'variable-length sequences. Please specify a '\n-            'static length for your sequences.')\n-\n-    rnn_inputs = inputs\n-    if need_convert:\n-        if go_backwards:\n-            rnn_inputs = reverse(rnn_inputs, 1)\n-\n-        rnn_inputs = C.to_sequence(rnn_inputs)\n-\n-        rnn_constants = []\n-        for constant in constants:\n-            if isinstance(constant, list):\n-                new_c = []\n-                for c in constant:\n-                    if _get_dynamic_axis_num(c) == 1:\n-                        new_c.append(C.sequence.broadcast_as(c, rnn_inputs))\n-                    else:\n-                        new_c.append(c)\n-                rnn_constants.append(new_c)\n-            else:\n-                if _get_dynamic_axis_num(constant) == 1:\n-                    rnn_constants.append(C.sequence.broadcast_as(\n-                        constant,\n-                        rnn_inputs))\n-                else:\n-                    rnn_constants.append(constant)\n-    else:\n-        rnn_constants = constants\n-\n-    if mask is not None and not has_seq_axis(mask):\n-        if go_backwards:\n-            mask = reverse(mask, 1)\n-        if len(int_shape(mask)) == 2:\n-            mask = expand_dims(mask)\n-        mask = C.to_sequence_like(mask, rnn_inputs)\n-\n-    states = tuple(initial)\n-\n-    with C.default_options(axis_offset=1):\n-        def _recurrence(x, states, m):\n-            # create place holder\n-            place_holders = [C.placeholder(\n-                dynamic_axes=x.dynamic_axes) for _ in states]\n-            past_values = []\n-            for s, p in zip(states, place_holders):\n-                past_values.append(C.sequence.past_value(p, s))\n-            new_output, new_states = step_function(\n-                x, tuple(past_values) + tuple(rnn_constants))\n-\n-            if getattr(new_output, '_uses_learning_phase', False):\n-                global uses_learning_phase\n-                uses_learning_phase = True\n-\n-            if m is not None:\n-                new_states_temp = []\n-                for n, s in zip(new_states, past_values):\n-                    new_states_temp.append(C.element_select(m, n, s))\n-\n-                new_states = new_states_temp\n-\n-            n_s = []\n-            for o, p in zip(new_states, place_holders):\n-                n_s.append(o.replace_placeholders({p: o.output}))\n-            if len(n_s) > 0:\n-                new_output = n_s[-1]\n-            return new_output, n_s\n-\n-        final_output, final_states = _recurrence(rnn_inputs, states, mask)\n-        last_output = C.sequence.last(final_output)\n-        last_states = [C.sequence.last(s) for s in final_states]\n-\n-    if need_convert:\n-        final_output = C.sequence.unpack(final_output, 0, no_mask_output=True)\n-        if num_time_step is not None and num_time_step is not C.FreeDimension:\n-            final_output = _reshape_sequence(final_output, num_time_step)\n-\n-    f_stats = []\n-    for l_s, i_s in zip(last_states, initial_states):\n-        if _get_dynamic_axis_num(i_s) == 0 and _get_dynamic_axis_num(l_s) == 1:\n-            if hasattr(C, 'unpack_batch'):\n-                f_stats.append(C.unpack_batch(l_s))\n-            else:\n-                f_stats.append(\n-                    C.user_function(ConvertToStatic(l_s, batch_size=i_s.shape[0])))\n-        else:\n-            f_stats.append(l_s)\n-\n-    last_output._uses_learning_phase = uses_learning_phase\n-    return last_output, final_output, f_stats\n-\n-\n-def has_seq_axis(x):\n-    return hasattr(x, 'dynamic_axes') and len(x.dynamic_axes) > 1\n-\n-\n-def l2_normalize(x, axis=None):\n-    axis = [axis]\n-    axis = _normalize_axis(axis, x)\n-    norm = C.sqrt(C.reduce_sum(C.square(x), axis=axis[0]))\n-    return x / norm\n-\n-\n-def hard_sigmoid(x):\n-    x = (0.2 * x) + 0.5\n-    x = C.clip(x, 0.0, 1.0)\n-    return x\n-\n-\n-def conv1d(x, kernel, strides=1, padding='valid',\n-           data_format=None, dilation_rate=1):\n-    data_format = normalize_data_format(data_format)\n-\n-    if padding == 'causal':\n-        # causal (dilated) convolution:\n-        left_pad = dilation_rate * (kernel.shape[0] - 1)\n-        x = temporal_padding(x, (left_pad, 0))\n-        padding = 'valid'\n-\n-    if data_format == 'channels_last':\n-        x = C.swapaxes(x, 0, 1)\n-\n-    # As of Keras 2.0.0, all kernels are normalized\n-    # on the format `(steps, input_depth, depth)`,\n-    # independently of `data_format`.\n-    # CNTK expects `(depth, input_depth, steps)`.\n-    kernel = C.swapaxes(kernel, 0, 2)\n-\n-    padding = _preprocess_border_mode(padding)\n-\n-    if dev.type() == 0 and dilation_rate != 1:\n-        raise ValueError(\n-            'Dilated convolution on CPU is not supported by CNTK backend. '\n-            'Please set `dilation_rate` to 1. You passed: %s' % (dilation_rate,))\n-\n-    dilation_rate = (1, dilation_rate)\n-\n-    x = C.convolution(\n-        kernel,\n-        x,\n-        strides=strides,\n-        auto_padding=[False, padding],\n-        dilation=dilation_rate)\n-\n-    if data_format == 'channels_last':\n-        x = C.swapaxes(x, 0, 1)\n-    return x\n-\n-\n-def conv2d(x, kernel, strides=(1, 1), padding='valid',\n-           data_format=None, dilation_rate=(1, 1)):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-\n-    if dev.type() == 0 and dilation_rate != (1, 1):\n-        raise ValueError(\n-            'Dilated convolution on CPU is not supported by CNTK backend. '\n-            'Please set `dilation_rate` to (1, 1). '\n-            'You passed: %s' % (dilation_rate,))\n-\n-    dilation_rate = (1,) + dilation_rate\n-\n-    x = C.convolution(kernel,\n-                      x,\n-                      strides,\n-                      auto_padding=[False, padding, padding],\n-                      dilation=dilation_rate)\n-\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n-                     padding='valid', data_format=None, dilation_rate=1):\n-    data_format = normalize_data_format(data_format)\n-    if isinstance(strides, int):\n-        strides = (strides,)\n-    if isinstance(dilation_rate, int):\n-        dilation_rate = (dilation_rate,)\n-\n-    if dilation_rate != (1,):\n-        raise ValueError(\n-            'Dilated separable 1D convolution is currently not supported '\n-            'by CNTK backend. Please set `dilation_rate` to 1. '\n-            'You passed: %s' % (dilation_rate,))\n-\n-    if data_format == 'channels_last':\n-        spatial_start_dim = 2\n-    else:\n-        spatial_start_dim = 3\n-    x = expand_dims(x, spatial_start_dim)\n-    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n-    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n-    strides = (1,) + strides + (1,)\n-    dilation_rate = (1,) + dilation_rate\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n-    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n-                                 (-1, 1) + depthwise_kernel.shape[2:])\n-    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-\n-    x = C.convolution(depthwise_kernel, x,\n-                      strides=strides,\n-                      auto_padding=[False, padding, padding],\n-                      groups=x.shape[0])\n-    x = C.convolution(pointwise_kernel, x,\n-                      strides=(1, 1, 1),\n-                      auto_padding=[False])\n-\n-    x = _postprocess_conv2d_output(x, data_format)\n-    return squeeze(x, spatial_start_dim)\n-\n-\n-def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n-    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n-                                 (-1, 1) + depthwise_kernel.shape[2:])\n-    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-\n-    if dilation_rate == (1, 1):\n-        strides = (1,) + strides\n-        x = C.convolution(depthwise_kernel, x,\n-                          strides=strides,\n-                          auto_padding=[False, padding, padding],\n-                          groups=x.shape[0])\n-        x = C.convolution(pointwise_kernel, x,\n-                          strides=(1, 1, 1),\n-                          auto_padding=[False])\n-    else:\n-        if dilation_rate[0] != dilation_rate[1]:\n-            raise ValueError('CNTK Backend: non-square dilation_rate is '\n-                             'not supported.')\n-        if strides != (1, 1):\n-            raise ValueError('Invalid strides for dilated convolution')\n-        x = C.convolution(depthwise_kernel, x,\n-                          strides=dilation_rate[0],\n-                          auto_padding=[False, padding, padding])\n-        x = C.convolution(pointwise_kernel, x,\n-                          strides=(1, 1, 1),\n-                          auto_padding=[False])\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n-                     data_format=None, dilation_rate=(1, 1)):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_kernel(depthwise_kernel, data_format)\n-    depthwise_kernel = C.reshape(C.transpose(depthwise_kernel, (1, 0, 2, 3)),\n-                                 (-1, 1) + depthwise_kernel.shape[2:])\n-    padding = _preprocess_border_mode(padding)\n-    if dilation_rate == (1, 1):\n-        strides = (1,) + strides\n-        x = C.convolution(depthwise_kernel, x,\n-                          strides=strides,\n-                          auto_padding=[False, padding, padding],\n-                          groups=x.shape[0])\n-    else:\n-        if dilation_rate[0] != dilation_rate[1]:\n-            raise ValueError('CNTK Backend: non-square dilation_rate is '\n-                             'not supported.')\n-        if strides != (1, 1):\n-            raise ValueError('Invalid strides for dilated convolution')\n-        x = C.convolution(depthwise_kernel, x,\n-                          strides=dilation_rate[0],\n-                          auto_padding=[False, padding, padding],\n-                          groups=x.shape[0])\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n-           data_format=None, dilation_rate=(1, 1, 1)):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-\n-    if dev.type() == 0 and dilation_rate != (1, 1, 1):\n-        raise ValueError(\n-            'Dilated convolution on CPU is not supported by CNTK backend. '\n-            'Please set `dilation_rate` to (1, 1, 1). '\n-            'You passed: %s' % (dilation_rate,))\n-\n-    dilation_rate = (1,) + dilation_rate\n-\n-    x = C.convolution(\n-        kernel,\n-        x,\n-        strides,\n-        auto_padding=[False, padding, padding, padding],\n-        dilation=dilation_rate)\n-\n-    return _postprocess_conv3d_output(x, data_format)\n-\n-\n-def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n-                     padding='valid', data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-    strides = (1,) + strides\n-    # cntk output_shape does not include batch axis\n-    output_shape = output_shape[1:]\n-    # in keras2, need handle output shape in different format\n-    if data_format == 'channels_last':\n-        output_shape = transpose_shape(output_shape, 'channels_first',\n-                                       spatial_axes=(0, 1, 2))\n-\n-    x = C.convolution_transpose(\n-        kernel,\n-        x,\n-        strides,\n-        auto_padding=[\n-            False,\n-            padding,\n-            padding,\n-            padding],\n-        output_shape=output_shape)\n-    return _postprocess_conv3d_output(x, data_format)\n-\n-\n-def pool2d(x, pool_size, strides=(1, 1),\n-           padding='valid', data_format=None,\n-           pool_mode='max'):\n-    data_format = normalize_data_format(data_format)\n-\n-    padding = _preprocess_border_mode(padding)\n-    x = _preprocess_conv2d_input(x, data_format)\n-    if pool_mode == 'max':\n-        x = C.pooling(\n-            x,\n-            C.MAX_POOLING,\n-            pool_size,\n-            strides,\n-            auto_padding=[padding])\n-    elif pool_mode == 'avg':\n-        x = C.pooling(\n-            x,\n-            C.AVG_POOLING,\n-            pool_size,\n-            strides,\n-            auto_padding=[padding])\n-    else:\n-        raise ValueError('Invalid pooling mode: ' + str(pool_mode))\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n-           data_format=None, pool_mode='max'):\n-    data_format = normalize_data_format(data_format)\n-\n-    padding = _preprocess_border_mode(padding)\n-\n-    x = _preprocess_conv3d_input(x, data_format)\n-\n-    if pool_mode == 'max':\n-        x = C.pooling(\n-            x,\n-            C.MAX_POOLING,\n-            pool_size,\n-            strides,\n-            auto_padding=[padding])\n-    elif pool_mode == 'avg':\n-        x = C.pooling(\n-            x,\n-            C.AVG_POOLING,\n-            pool_size,\n-            strides,\n-            auto_padding=[padding])\n-    else:\n-        raise ValueError('Invalid pooling mode: ' + str(pool_mode))\n-\n-    return _postprocess_conv3d_output(x, data_format)\n-\n-\n-def relu(x, alpha=0., max_value=None, threshold=0.):\n-\n-    if alpha != 0.:\n-        if threshold != 0.:\n-            negative_part = C.relu(-x + threshold)\n-        else:\n-            negative_part = C.relu(-x)\n-\n-    if threshold != 0.:\n-        x = x * C.greater(x, threshold)\n-    else:\n-        x = C.relu(x)\n-\n-    if max_value is not None:\n-        x = C.clip(x, 0.0, max_value)\n-\n-    if alpha != 0.:\n-        x -= alpha * negative_part\n-\n-    return x\n-\n-\n-def dropout(x, level, noise_shape=None, seed=None):\n-    if level < 0. or level >= 1:\n-        raise ValueError('CNTK Backend: Invalid dropout level %s, '\n-                         'must be in interval [0, 1].' % level)\n-    return C.dropout(x, level)\n-\n-\n-def batch_flatten(x):\n-    # cntk's batch axis is not in shape,\n-    # so just flatten all the dim in x.shape\n-    dim = np.prod(x.shape)\n-    x = C.reshape(x, (-1,))\n-    x._keras_shape = (None, dim)\n-    return x\n-\n-\n-def softmax(x, axis=-1):\n-    return C.softmax(x, axis=axis)\n-\n-\n-def softplus(x):\n-    return C.softplus(x)\n-\n-\n-def softsign(x):\n-    return x / (1 + C.abs(x))\n-\n-\n-def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n-    # Here, unlike other backends, the tensors lack a batch dimension:\n-    axis_without_batch = -1 if axis == -1 else axis - 1\n-    output_dimensions = list(range(len(output.shape)))\n-    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n-        raise ValueError(\n-            '{}{}{}'.format(\n-                'Unexpected channels axis {}. '.format(axis_without_batch),\n-                'Expected to be -1 or one of the axes of `output`, ',\n-                'which has {} dimensions.'.format(len(output.shape))))\n-    # If the channels are not in the last axis, move them to be there:\n-    if axis_without_batch != -1 and axis_without_batch != output_dimensions[-1]:\n-        permutation = output_dimensions[:axis_without_batch]\n-        permutation += output_dimensions[axis_without_batch + 1:]\n-        permutation += [axis_without_batch]\n-        output = C.transpose(output, permutation)\n-        target = C.transpose(target, permutation)\n-    if from_logits:\n-        result = C.cross_entropy_with_softmax(output, target)\n-        # cntk's result shape is (batch, 1), while keras expect (batch, )\n-        return C.reshape(result, ())\n-    else:\n-        # scale preds so that the class probas of each sample sum to 1\n-        output /= C.reduce_sum(output, axis=-1)\n-        # avoid numerical instability with epsilon clipping\n-        output = C.clip(output, epsilon(), 1.0 - epsilon())\n-        return -sum(target * C.log(output), axis=-1)\n-\n-\n-def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n-    # Here, unlike other backends, the tensors lack a batch dimension:\n-    axis_without_batch = -1 if axis == -1 else axis - 1\n-    output_dimensions = list(range(len(output.shape)))\n-    if axis_without_batch != -1 and axis_without_batch not in output_dimensions:\n-        raise ValueError(\n-            '{}{}{}'.format(\n-                'Unexpected channels axis {}. '.format(axis_without_batch),\n-                'Expected to be -1 or one of the axes of `output`, ',\n-                'which has {} dimensions.'.format(len(output.shape))))\n-    target = C.one_hot(target, output.shape[axis_without_batch],\n-                       axis=axis_without_batch)\n-    target = C.reshape(target, output.shape)\n-    return categorical_crossentropy(target, output, from_logits, axis=axis)\n-\n-\n-class Function(object):\n-\n-    def __init__(self, inputs, outputs, updates=[], **kwargs):\n-        self.placeholders = inputs\n-        self.trainer = None\n-        self.unrelated_updates = None\n-        self.updates = updates\n-        if len(updates) > 0:\n-            assert len(outputs) > 0\n-            self.loss = outputs[0]\n-            # need group update by gradient place holder\n-            u_ops = []\n-            unrelated_updates = []\n-            for update in updates:\n-                if isinstance(update, tuple):\n-                    if len(update) != 2:\n-                        raise NotImplementedError\n-                    else:\n-                        u = C.assign(update[0], update[1])\n-                else:\n-                    u = update\n-\n-                if len(u.arguments) == 0:\n-                    u_ops.append(u)\n-                else:\n-                    unrelated_updates.append(u)\n-\n-            update_func = C.combine([u.output for u in u_ops])\n-\n-            grads = update_func.find_all_with_name('keras_grad_placeholder')\n-\n-            u_list = []\n-            p_list = []\n-            for g in grads:\n-                if g in grad_parameter_dict:\n-                    p_list.append(grad_parameter_dict[g])\n-                    u_list.append(g)\n-                else:\n-                    raise ValueError(\n-                        'CNTK backend: when constructing trainer, '\n-                        'found gradient node `%s` which is not '\n-                        'related to any parameters in the model. '\n-                        'Please double check how the gradient node '\n-                        'is constructed.' % g)\n-\n-            if len(u_list) > 0:\n-                learner = C.cntk_py.universal_learner(p_list, u_list, update_func)\n-\n-                criterion = (\n-                    outputs[0],\n-                    outputs[1]) if len(outputs) > 1 else (\n-                    outputs[0],\n-                )\n-                self.trainer = C.trainer.Trainer(\n-                    outputs[0], criterion, [learner])\n-                self.trainer_output = tuple([f.output for f in criterion])\n-            elif len(u_ops) > 0:\n-                unrelated_updates.extend(u_ops)\n-\n-            if len(unrelated_updates) > 0:\n-                self.unrelated_updates = C.combine(\n-                    [_.output for _ in unrelated_updates])\n-\n-        if self.trainer is None:\n-            self.metrics_outputs = [f.output for f in outputs]\n-            self.metrics_func = C.combine(self.metrics_outputs)\n-        # cntk only could handle loss and 1 metric in trainer, for metrics more\n-        # than 2, need manual eval\n-        elif len(outputs) > 2:\n-            self.metrics_outputs = [f.output for f in outputs[2:]]\n-            self.metrics_func = C.combine(self.metrics_outputs)\n-        else:\n-            self.metrics_func = None\n-\n-    @staticmethod\n-    def _is_input_shape_compatible(input, placeholder):\n-        if hasattr(input, 'shape') and hasattr(placeholder, 'shape'):\n-            num_dynamic = get_num_dynamic_axis(placeholder)\n-            input_shape = input.shape[num_dynamic:]\n-            placeholder_shape = placeholder.shape\n-            for i, p in zip(input_shape, placeholder_shape):\n-                if i != p and p != C.InferredDimension and p != C.FreeDimension:\n-                    return False\n-        return True\n-\n-    def __call__(self, inputs):\n-        global _LEARNING_PHASE_PLACEHOLDER\n-        global _LEARNING_PHASE\n-        assert isinstance(inputs, (list, tuple))\n-        feed_dict = {}\n-        for tensor, value in zip(self.placeholders, inputs):\n-            # cntk only support calculate on float, do auto cast here\n-            if (hasattr(value, 'dtype') and\n-               value.dtype != np.float32 and\n-               value.dtype != np.float64):\n-                value = value.astype(np.float32)\n-\n-            if tensor == _LEARNING_PHASE_PLACEHOLDER:\n-                _LEARNING_PHASE_PLACEHOLDER.value = np.asarray(value)\n-            else:\n-                # in current version cntk can't support input with variable\n-                # length. Will support it in next release.\n-                if not self._is_input_shape_compatible(value, tensor):\n-                    raise ValueError(\n-                        'CNTK backend: The placeholder has been resolved '\n-                        'to shape `%s`, but input shape is `%s`. Currently '\n-                        'CNTK can not take variable length inputs. Please '\n-                        'pass inputs that have a static shape.'\n-                        % (str(tensor.shape), str(value.shape)))\n-            feed_dict[tensor] = value\n-\n-        updated = []\n-        if self.trainer is not None:\n-            input_dict = {}\n-            for argument in self.loss.arguments:\n-                if argument in feed_dict:\n-                    input_dict[argument] = feed_dict[argument]\n-                else:\n-                    raise ValueError(\n-                        'CNTK backend: argument %s is not found in inputs. '\n-                        'Please double check the model and inputs in '\n-                        '`train_function`.' % argument.name)\n-\n-            result = self.trainer.train_minibatch(\n-                input_dict, self.trainer_output)\n-\n-            assert(len(result) == 2)\n-            outputs = result[1]\n-            for o in self.trainer_output:\n-                updated.append(outputs[o])\n-\n-        if self.metrics_func is not None:\n-            input_dict = {}\n-            for argument in self.metrics_func.arguments:\n-                if argument in feed_dict:\n-                    input_dict[argument] = feed_dict[argument]\n-                else:\n-                    raise ValueError('CNTK backend: metrics argument %s '\n-                                     'is not found in inputs. Please double '\n-                                     'check the model and inputs.' % argument.name)\n-            # Some ops (like dropout) won't be applied during \"eval\" in cntk.\n-            # They only evaluated in training phase. To make it work, call\n-            # \"forward\" method to let cntk know we want to evaluate them.from\n-            # But the assign ops won't be executed under this mode, that's why\n-            # we need this check.\n-            if (self.unrelated_updates is None and\n-                    (_LEARNING_PHASE_PLACEHOLDER.value == 1.0 or\n-                        _LEARNING_PHASE == 1)):\n-                _, output_values = self.metrics_func.forward(\n-                    input_dict,\n-                    self.metrics_func.outputs,\n-                    (self.metrics_func.outputs[0],),\n-                    as_numpy=False)\n-            else:\n-                output_values = self.metrics_func.eval(input_dict, as_numpy=False)\n-            if isinstance(output_values, dict):\n-                for o in self.metrics_outputs:\n-                    value = output_values[o]\n-                    v = value.asarray()\n-                    updated.append(v)\n-            else:\n-                v = output_values.asarray()\n-                for o in self.metrics_outputs:\n-                    updated.append(v)\n-\n-        if self.unrelated_updates is not None:\n-            input_dict = {}\n-            for argument in self.unrelated_updates.arguments:\n-                if argument in feed_dict:\n-                    input_dict[argument] = feed_dict[argument]\n-                else:\n-                    raise ValueError(\n-                        'CNTK backend: assign ops argument %s '\n-                        'is not found in inputs. Please double '\n-                        'check the model and inputs.' % argument.name)\n-            self.unrelated_updates.eval(input_dict, as_numpy=False)\n-        return updated\n-\n-\n-def function(inputs, outputs, updates=[], **kwargs):\n-    return Function(inputs, outputs, updates=updates, **kwargs)\n-\n-\n-def temporal_padding(x, padding=(1, 1)):\n-    assert len(padding) == 2\n-    num_dynamic_axis = _get_dynamic_axis_num(x)\n-    assert len(x.shape) == 3 - (1 if num_dynamic_axis > 0 else 0)\n-    return pad(x, [padding], 'channels_last', num_dynamic_axis)\n-\n-\n-def _padding(x, pattern, axis):  # pragma: no cover\n-    base_shape = x.shape\n-    if b_any([dim < 0 for dim in base_shape]):\n-        raise ValueError('CNTK Backend: padding input tensor with '\n-                         'shape `%s` contains non-specified dimension, '\n-                         'which is not supported. Please give fixed '\n-                         'dimension to enable padding.' % base_shape)\n-    if pattern[0] > 0:\n-        prefix_shape = list(base_shape)\n-        prefix_shape[axis] = pattern[0]\n-        prefix_shape = tuple(prefix_shape)\n-        x = C.splice(C.constant(value=0, shape=prefix_shape), x, axis=axis)\n-        base_shape = x.shape\n-    if pattern[1] > 0:\n-        postfix_shape = list(base_shape)\n-        postfix_shape[axis] = pattern[1]\n-        postfix_shape = tuple(postfix_shape)\n-        x = C.splice(x, C.constant(value=0, shape=postfix_shape), axis=axis)\n-    return x\n-\n-\n-def pad(x, pad_info, data_format, num_dynamic_axis):\n-    if hasattr(C, 'pad'):\n-        pattern = [list(p) for p in pad_info]\n-        if data_format == 'channels_first':\n-            pattern = [[0, 0]] + pattern\n-        else:\n-            pattern = pattern + [[0, 0]]\n-        if num_dynamic_axis == 0:\n-            pattern = [[0, 0]] + pattern\n-        return C.pad(x, pattern=pattern)\n-    else:  # pragma: no cover\n-        for (a, p) in enumerate(pad_info):\n-            x = _padding(x, p,\n-                         a + (1 if num_dynamic_axis == 0 else 0) +\n-                         (1 if data_format == 'channels_first' else 0))\n-        return x\n-\n-\n-def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n-    assert len(padding) == 2\n-    assert len(padding[0]) == 2\n-    assert len(padding[1]) == 2\n-    data_format = normalize_data_format(data_format)\n-\n-    num_dynamic_axis = _get_dynamic_axis_num(x)\n-    assert len(x.shape) == 4 - (1 if num_dynamic_axis > 0 else 0)\n-    return pad(x, padding, data_format, num_dynamic_axis)\n-\n-\n-def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n-    assert len(padding) == 3\n-    assert len(padding[0]) == 2\n-    assert len(padding[1]) == 2\n-    assert len(padding[2]) == 2\n-    data_format = normalize_data_format(data_format)\n-\n-    num_dynamic_axis = _get_dynamic_axis_num(x)\n-    assert len(x.shape) == 5 - (1 if num_dynamic_axis > 0 else 0)\n-    return pad(x, padding, data_format, num_dynamic_axis)\n-\n-\n-def one_hot(indices, num_classes):\n-    return C.one_hot(indices, num_classes)\n-\n-\n-def get_value(x):\n-    if isinstance(\n-            x,\n-            (C.variables.Parameter, C.variables.Constant)):\n-        return x.value\n-    else:\n-        return eval(x)\n-\n-\n-def batch_get_value(xs):\n-    result = [get_value(x) for x in xs]\n-\n-    return result\n-\n-\n-def set_value(x, value):\n-    if (isinstance(x, C.variables.Parameter) or\n-       isinstance(x, C.variables.Constant)):\n-        if isinstance(value, (float, int)):\n-            value = np.full(x.shape, value, dtype=floatx())\n-        x.value = value\n-    else:\n-        raise NotImplementedError\n-\n-\n-def print_tensor(x, message=''):\n-    return C.user_function(\n-        LambdaFunc(x,\n-                   when=lambda x: True,\n-                   execute=lambda x: print(message)))\n-\n-\n-def batch_set_value(tuples):\n-    for t in tuples:\n-        x = t[0]\n-        value = t[1]\n-        if isinstance(value, np.ndarray) is False:\n-            value = np.asarray(value)\n-        if isinstance(x, C.variables.Parameter):\n-            x.value = value\n-        else:\n-            raise NotImplementedError\n-\n-\n-def stop_gradient(variables):\n-    if isinstance(variables, (list, tuple)):\n-        return map(C.stop_gradient, variables)\n-    else:\n-        return C.stop_gradient(variables)\n-\n-\n-def switch(condition, then_expression, else_expression):\n-    if callable(then_expression):\n-        then_expression = then_expression()\n-    if callable(else_expression):\n-        else_expression = else_expression()\n-    ndim_cond = ndim(condition)\n-    ndim_expr = ndim(then_expression)\n-    if ndim_cond > ndim_expr:\n-        raise ValueError('Rank of condition should be less'\n-                         ' than or equal to rank of then and'\n-                         ' else expressions. ndim(condition)=' +\n-                         str(ndim_cond) + ', ndim(then_expression)'\n-                         '=' + str(ndim_expr))\n-    elif ndim_cond < ndim_expr:\n-        shape_expr = int_shape(then_expression)\n-        ndim_diff = ndim_expr - ndim_cond\n-        for i in range(ndim_diff):\n-            condition = expand_dims(condition)\n-            condition = tile(condition, shape_expr[ndim_cond + i])\n-    return C.element_select(condition,\n-                            then_expression,\n-                            else_expression)\n-\n-\n-def elu(x, alpha=1.):\n-    res = C.elu(x)\n-    if alpha == 1:\n-        return res\n-    else:\n-        return C.element_select(C.greater(x, 0), res, alpha * res)\n-\n-\n-def in_top_k(predictions, targets, k):\n-    _targets = C.one_hot(targets, predictions.shape[-1])\n-    result = [C.classification_error(predictions[i], _targets[i], topN=k)\n-              for i in range(predictions.shape[0])]\n-    result = concatenate(result, axis=-1)\n-    return 1 - C.reshape(result, shape=(-1,))\n-\n-\n-def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n-                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n-    data_format = normalize_data_format(data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    padding = _preprocess_border_mode(padding)\n-    strides = (1,) + strides\n-    # cntk output_shape does not include batch axis\n-    output_shape = output_shape[1:]\n-    # in keras2, need handle output shape in different format\n-    if data_format == 'channels_last':\n-        output_shape = transpose_shape(output_shape, 'channels_first',\n-                                       spatial_axes=(0, 1))\n-\n-    dilation_rate = (1,) + dilation_rate\n-\n-    x = C.convolution_transpose(\n-        kernel,\n-        x,\n-        strides,\n-        auto_padding=[\n-            False,\n-            padding,\n-            padding],\n-        output_shape=output_shape,\n-        dilation=dilation_rate)\n-    return _postprocess_conv2d_output(x, data_format)\n-\n-\n-def identity(x, name=None):\n-    if name is None:\n-        name = '%s_alias' % x.name\n-    return C.alias(x, name=name)\n-\n-\n-def _preprocess_conv2d_input(x, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH input shape: (samples, input_depth, rows, cols)\n-        # TF input shape: (samples, rows, cols, input_depth)\n-        x = C.transpose(x, (2, 0, 1))\n-    return x\n-\n-\n-def _preprocess_conv2d_kernel(kernel, data_format):\n-    # As of Keras 2.0.0, all kernels are normalized\n-    # on the format `(rows, cols, input_depth, depth)`,\n-    # independently of `data_format`.\n-    # CNTK expects `(depth, input_depth, rows, cols)`.\n-    kernel = C.transpose(kernel, (3, 2, 0, 1))\n-    return kernel\n-\n-\n-def _preprocess_border_mode(padding):\n-    if padding == 'same':\n-        padding = True\n-    elif padding == 'valid':\n-        padding = False\n-    else:\n-        raise ValueError('Invalid border mode: ' + str(padding))\n-    return padding\n-\n-\n-def _postprocess_conv2d_output(x, data_format):\n-    if data_format == 'channels_last':\n-        x = C.transpose(x, (1, 2, 0))\n-    return x\n-\n-\n-def _preprocess_conv3d_input(x, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH input shape: (samples, input_depth, conv_dim1, conv_dim2, conv_dim3)\n-        # TF input shape: (samples, conv_dim1, conv_dim2, conv_dim3,\n-        # input_depth)\n-        x = C.transpose(x, (3, 0, 1, 2))\n-    return x\n-\n-\n-def _preprocess_conv3d_kernel(kernel, dim_ordering):\n-    kernel = C.transpose(kernel, (4, 3, 0, 1, 2))\n-    return kernel\n-\n-\n-def _postprocess_conv3d_output(x, dim_ordering):\n-    if dim_ordering == 'channels_last':\n-        x = C.transpose(x, (1, 2, 3, 0))\n-    return x\n-\n-\n-def _get_dynamic_axis_num(x):\n-    if hasattr(x, 'dynamic_axes'):\n-        return len(x.dynamic_axes)\n-    else:\n-        return 0\n-\n-\n-def _contain_seqence_axis(x):\n-    if _get_dynamic_axis_num(x) > 1:\n-        return x.dynamic_axes[1] == C.Axis.default_dynamic_axis()\n-    else:\n-        return False\n-\n-\n-def get_num_dynamic_axis(x):\n-    return _get_dynamic_axis_num(x)\n-\n-\n-def _reduce_on_axis(x, axis, reduce_fun_name):\n-    if isinstance(axis, list):\n-        for a in axis:\n-            if isinstance(a, C.Axis) \\\n-                    and a != C.Axis.default_batch_axis() \\\n-                    and hasattr(C.sequence, reduce_fun_name):\n-                x = getattr(C.sequence, reduce_fun_name)(x, a)\n-            else:\n-                x = getattr(C, reduce_fun_name)(x, a)\n-    else:\n-        x = getattr(C, reduce_fun_name)(x, axis)\n-    return x\n-\n-\n-def _reshape_sequence(x, time_step):\n-    tmp_shape = list(int_shape(x))\n-    tmp_shape[1] = time_step\n-    return reshape(x, tmp_shape)\n-\n-\n-def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    stride = strides[0]\n-    kernel_shape = int_shape(kernel)\n-    output_length, feature_dim, filters = kernel_shape\n-\n-    xs = []\n-    for i in range(output_length):\n-        slice_length = py_slice(i * stride,\n-                                i * stride + kernel_size[0])\n-        xs.append(reshape(inputs[:, slice_length, :],\n-                          (-1, 1, feature_dim)))\n-    x_aggregate = concatenate(xs, axis=1)\n-    # transpose kernel to output_filters first, to apply broadcast\n-    weight = permute_dimensions(kernel, (2, 0, 1))\n-    # Shape: (batch, filters, output_length, input_length * kernel_size)\n-    output = x_aggregate * weight\n-    # Shape: (batch, filters, output_length)\n-    output = sum(output, axis=3)\n-    # Shape: (batch, output_length, filters)\n-    return permute_dimensions(output, (0, 2, 1))\n-\n-\n-def local_conv2d(inputs,\n-                 kernel,\n-                 kernel_size,\n-                 strides,\n-                 output_shape,\n-                 data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    stride_row, stride_col = strides\n-    output_row, output_col = output_shape\n-    kernel_shape = int_shape(kernel)\n-    _, feature_dim, filters = kernel_shape\n-    xs = []\n-\n-    for i in range(output_row):\n-        for j in range(output_col):\n-            slice_row = py_slice(i * stride_row,\n-                                 i * stride_row + kernel_size[0])\n-            slice_col = py_slice(j * stride_col,\n-                                 j * stride_col + kernel_size[1])\n-            if data_format == 'channels_first':\n-                xs.append(reshape(inputs[:, :, slice_row, slice_col],\n-                                  (-1, 1, feature_dim)))\n-            else:\n-                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n-                                  (-1, 1, feature_dim)))\n-    x_aggregate = concatenate(xs, axis=1)\n-    # transpose kernel to put filters first\n-    weight = permute_dimensions(kernel, (2, 0, 1))\n-    # shape: batch, filters, output_length, input_length * kernel_size\n-    output = x_aggregate * weight\n-    # shape: batch, filters, output_length\n-    output = sum(output, axis=3)\n-    # shape: batch, filters, row, col\n-    output = reshape(output,\n-                     (-1, filters, output_row, output_col))\n-\n-    if data_format == 'channels_last':\n-        # shape: batch, row, col, filters\n-        output = permute_dimensions(output, (0, 2, 3, 1))\n-\n-    return output\n-\n-\n-def reverse(x, axes):\n-    if isinstance(axes, int):\n-        axes = [axes]\n-    cntk_axes = _normalize_axis(axes, x)\n-    begin_index = [0 for _ in cntk_axes]\n-    end_index = [0 for _ in cntk_axes]\n-    strides = [-1 for _ in cntk_axes]\n-    return C.slice(x, cntk_axes, begin_index, end_index, strides)\n-\n-\n-def slice(x, start, size):\n-    if not (len(int_shape(x)) == len(start) == len(size)):\n-        raise ValueError('The dimension and the size of indices should match.')\n-    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n-    out._keras_shape = tuple(size)\n-    return out\n-\n-\n-def _reshape_batch(x, shape):\n-    # there is a bug in cntk 2.1's unpack_batch implementation\n-    if hasattr(C, 'unpack_batch') and _get_cntk_version() >= 2.2:\n-        const_a = C.unpack_batch(x)\n-        const_a = C.reshape(const_a, shape)\n-        return C.to_batch(const_a)\n-    else:\n-        return C.user_function(ReshapeBatch(x, shape[1:]))\n-\n-\n-def _get_cntk_version():\n-    version = C.__version__\n-    if version.endswith('+'):\n-        version = version[:-1]\n-    # for hot fix, ignore all the . except the first one.\n-    if len(version) > 2 and version[1] == '.':\n-        version = version[:2] + version[2:].replace('.', '')\n-    try:\n-        return float(version)\n-    except:\n-        warnings.warn(\n-            'CNTK backend warning: CNTK version not detected. '\n-            'Will using CNTK 2.0 GA as default.')\n-        return float(2.0)\n-\n-\n-class ReshapeBatch(C.ops.functions.UserFunction):\n-    def __init__(self, input, shape, name='reshape_with_batch'):\n-        super(ReshapeBatch, self).__init__([input], as_numpy=False, name=name)\n-        self.from_shape = input.shape\n-        self.target_shape = shape\n-\n-    def infer_outputs(self):\n-        batch_axis = C.Axis.default_batch_axis()\n-        return [\n-            C.output_variable(\n-                self.target_shape,\n-                self.inputs[0].dtype,\n-                [batch_axis])]\n-\n-    def forward(self, arguments, device=None, outputs_to_retain=None):\n-        num_element = arguments.shape()[0] * np.prod(np.asarray(self.from_shape))\n-        num_static_element = np.prod(np.asarray(self.target_shape))\n-        num_batch = int(num_element / num_static_element)\n-        result = arguments.data().as_shape((num_batch,) + self.target_shape)\n-        return None, C.cntk_py.Value(result)\n-\n-    def backward(self, state, root_gradients):\n-        grad_array_view = root_gradients.data()\n-        num_element = root_gradients.shape()[0] * np.prod(\n-            np.asarray(self.target_shape))\n-        num_static_element = np.prod(np.asarray(self.from_shape))\n-        num_old_batch = int(num_element / num_static_element)\n-        return C.cntk_py.Value(\n-            grad_array_view.as_shape(\n-                (num_old_batch,) + self.from_shape))\n-\n-\n-class ConvertToBatch(C.ops.functions.UserFunction):\n-    \"\"\"Converts input first axis to CNTK batch axis.\n-\n-    We may introduce this operation in CNTK native\n-    implementation later.\n-\n-    # Arguments\n-        inputs: a cntk variable (parameter/constant)\n-        name: name of this node\n-    \"\"\"\n-\n-    def __init__(self, input, name='convert_to_batch'):\n-        super(ConvertToBatch, self).__init__([input], as_numpy=False, name=name)\n-\n-    def infer_outputs(self):\n-        batch_axis = C.Axis.default_batch_axis()\n-        return [\n-            C.output_variable(\n-                self.inputs[0].shape[1:],\n-                self.inputs[0].dtype,\n-                [batch_axis])]\n-\n-    def forward(self, arguments, device=None, outputs_to_retain=None):\n-        return None, C.cntk_py.Value(arguments.data())\n-\n-    def backward(self, state, root_gradients):\n-        return C.cntk_py.Value(root_gradients.data())\n-\n-\n-class ConvertToStatic(C.ops.functions.UserFunction):\n-    \"\"\"Converts input first axis to CNTK static axis.\n-\n-    We may introduce this operation in CNTK native\n-    implementation later.\n-\n-    # Arguments\n-        inputs: a cntk tensor which has batch axis\n-        batch_size: size of batch axis.\n-        name: name of this node.\n-    \"\"\"\n-\n-    def __init__(self, input, batch_size, name='convert_to_static'):\n-        super(ConvertToStatic, self).__init__([input], as_numpy=False, name=name)\n-        self.target_shape = (batch_size,) + input.shape\n-\n-    def infer_outputs(self):\n-        return [\n-            C.output_variable(\n-                self.target_shape,\n-                self.inputs[0].dtype,\n-                [])]\n-\n-    def forward(self, arguments, device=None, outputs_to_retain=None):\n-        return None, C.cntk_py.Value(arguments.data())\n-\n-    def backward(self, state, root_gradients):\n-        return C.cntk_py.Value(root_gradients.data())\n-\n-\n-class LambdaFunc(C.ops.functions.UserFunction):\n-    def __init__(self,\n-                 arg,\n-                 when=lambda arg: True,\n-                 execute=lambda arg: print(arg),\n-                 name=''):\n-        self.when = when\n-        self.execute = execute\n-\n-        super(LambdaFunc, self).__init__([arg], name=name)\n-\n-    def infer_outputs(self):\n-        return [\n-            C.output_variable(\n-                self.inputs[0].shape,\n-                self.inputs[0].dtype,\n-                self.inputs[0].dynamic_axes)]\n-\n-    def forward(self, argument, device=None, outputs_to_retain=None):\n-        if self.when(argument):\n-            self.execute(argument)\n-\n-        return None, argument\n-\n-    def backward(self, state, root_gradients):\n-        return root_gradients\n-\n-\n-def reset_uids():\n-    global _UID_PREFIXES\n-    _UID_PREFIXES = defaultdict(int)\n-\n-\n-def to_dense(tensor):\n-    raise NotImplementedError\n-\n-\n-def cumsum(x, axis=0):\n-    dim = x.shape[axis]\n-    U = C.constant(np.triu(np.ones((dim, dim))).astype(x.dtype))\n-    if axis != -1:\n-        x = C.swapaxes(x, -1, axis)\n-    out = C.times(x, U)\n-    if axis != -1:\n-        out = C.swapaxes(out, -1, axis)\n-    return out\n-\n-\n-def cumprod(x, axis=0):\n-    shape = x.shape\n-    out = x\n-    for rep in range(shape[axis] - 1):\n-        sliced_shape = list(shape)\n-        sliced_shape[axis] = rep + 1\n-        if axis == 0:\n-            _x = x[rep:(rep + 1)]\n-        elif axis == 1:\n-            _x = x[:, rep:(rep + 1)]\n-        elif axis == 2:\n-            _x = x[:, :, rep:(rep + 1)]\n-        y = concatenate([ones(sliced_shape, dtype=x.dtype),\n-                         repeat_elements(_x, rep=shape[axis] - 1 - rep, axis=axis)],\n-                        axis=axis)\n-        out = C.element_times(out, y)\n-    return out\n-\n-\n-def arange(start, stop=None, step=1, dtype='int32'):\n-    raise NotImplementedError\n-\n-\n-def ctc_label_dense_to_sparse(labels, label_lengths):\n-    raise NotImplementedError\n-\n-\n-def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n-    raise NotImplementedError\n-\n-\n-def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n-               merge_repeated=False):\n-    raise NotImplementedError\n-\n-\n-def map_fn(fn, elems, name=None, dtype=None):\n-    raise NotImplementedError\n-\n-\n-def foldl(fn, elems, initializer=None, name=None):\n-    \"\"\"Reduce `elems` by `fn` combined them from left to right on dimension 0.\n-\n-    # Arguments\n-        fn: Callable that will be called upon each element in `elems`\n-            (and on the optional `initializer`) passed as a second argument.\n-            The first argument passed to `fn` is the accumulator which is the\n-            accumulated value calculated from the preceding invocation of `fn`.\n-            Example For `fn`:\n-            ```python\n-            lambda acc, x: acc + x\n-            ```\n-        elems: Tensor\n-        initializer: (optional) Tensor, the initial value for the accumulator.\n-            In case of None value is provided during the call\n-            the first value is used (`elems[0]`) as `initializer` from `elems`\n-        name: (optional) String, name for the foldl node in the graph.\n-\n-    # Returns\n-        Same type and shape as `initializer`\n-\n-    # Raises:\n-        TypeError: if `fn` is not callable.\n-        TypeError: if `initializer` is neither a tensor nor None value.\n-        TypeError: if `elems` is not a tensor.\n-    \"\"\"\n-    if not callable(fn):\n-        raise TypeError(\"`fn` must be callable.\")\n-    if initializer is not None and not is_tensor(initializer):\n-        raise TypeError(\"`initializer` must be a tensor or None\")\n-    if not is_tensor(elems):\n-        raise TypeError('`elems` must be a tensor')\n-\n-    if initializer is None and shape(elems)[0] > 1:\n-        initializer = elems[0]\n-        elems = elems[1:]\n-    elif initializer is None:\n-        initializer = elems[0]\n-        elems = None\n-\n-    accumulator = initializer\n-    if elems is not None:\n-        for i in range(shape(elems)[0]):\n-            accumulator = fn(accumulator, elems[i])\n-\n-    if name is not None:\n-        accumulator.name = str(name)\n-\n-    return reshape(accumulator, shape(initializer)[1:])\n-\n-\n-def foldr(fn, elems, initializer=None, name=None):\n-    \"\"\"Reduce `elems` by `fn` combined them from right to left on dimension 0.\n-\n-    # Arguments\n-        fn: Callable that will be called upon each element in `elems`\n-            (and on the optional `initializer`) passed as a second argument.\n-            The first argument passed to `fn` is the accumulator which is the\n-            accumulated value calculated from the preceding invocation of `fn`.\n-            Example For `fn`:\n-            ```python\n-            lambda acc, x: acc + x\n-            ```\n-        elems: Tensor\n-        initializer: (optional) Tensor, the initial value for the accumulator.\n-            In case of None value is provided during the call\n-            the last value is used (`elems[-1]`) as `initializer` from `elems`\n-        name: (optional) String, name for the foldr node in the graph.\n-\n-    # Returns\n-        Same type and shape as `initializer`\n-\n-    # Raises:\n-        TypeError: if `fn` is not callable.\n-        TypeError: if `initializer` is neither a tensor nor None value.\n-        TypeError: if `elems` is not a tensor.\n-    \"\"\"\n-    if not callable(fn):\n-        raise TypeError(\"`fn` must be callable.\")\n-    if initializer is not None and not is_tensor(initializer):\n-        raise TypeError(\"`initializer` must be a tensor or None\")\n-    if not is_tensor(elems):\n-        raise TypeError('`elems` must be a tensor')\n-\n-    if initializer is None and shape(elems)[0] > 1:\n-        initializer = elems[-1]\n-        elems = elems[:-1]\n-    elif initializer is None:\n-        initializer = elems[0]\n-        elems = None\n-\n-    accumulator = initializer\n-    if elems is not None:\n-        for i in range(shape(elems)[0]):\n-            accumulator = fn(accumulator, elems[-i])\n-\n-    if name is not None:\n-        accumulator.name = str(name)\n-\n-    return reshape(accumulator, shape(initializer)[1:])\n-\n-\n-def control_dependencies(control_inputs):\n-    @contextmanager\n-    def nullcontextmanager():\n-        yield\n-\n-    return nullcontextmanager()\n\n@@ -1,232 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-\n-# the type of float to use throughout the session.\n-_FLOATX = 'float32'\n-_EPSILON = 1e-7\n-_IMAGE_DATA_FORMAT = 'channels_last'\n-\n-\n-def epsilon():\n-    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n-\n-    # Returns\n-        A float.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.epsilon()\n-        1e-07\n-    ```\n-    \"\"\"\n-    return _EPSILON\n-\n-\n-def set_epsilon(e):\n-    \"\"\"Sets the value of the fuzz factor used in numeric expressions.\n-\n-    # Arguments\n-        e: float. New value of epsilon.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.epsilon()\n-        1e-07\n-        >>> K.set_epsilon(1e-05)\n-        >>> K.epsilon()\n-        1e-05\n-    ```\n-    \"\"\"\n-\n-    global _EPSILON\n-    _EPSILON = float(e)\n-\n-\n-def floatx():\n-    \"\"\"Returns the default float type, as a string.\n-    (e.g. 'float16', 'float32', 'float64').\n-\n-    # Returns\n-        String, the current default float type.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.floatx()\n-        'float32'\n-    ```\n-    \"\"\"\n-    return _FLOATX\n-\n-\n-def set_floatx(floatx):\n-    \"\"\"Sets the default float type.\n-\n-    # Arguments\n-        floatx: String, 'float16', 'float32', or 'float64'.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.floatx()\n-        'float32'\n-        >>> K.set_floatx('float16')\n-        >>> K.floatx()\n-        'float16'\n-    ```\n-    \"\"\"\n-    global _FLOATX\n-    if floatx not in {'float16', 'float32', 'float64'}:\n-        raise ValueError('Unknown floatx type: ' + str(floatx))\n-    _FLOATX = str(floatx)\n-\n-\n-def cast_to_floatx(x):\n-    \"\"\"Cast a Numpy array to the default Keras float type.\n-\n-    # Arguments\n-        x: Numpy array.\n-\n-    # Returns\n-        The same Numpy array, cast to its new type.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.floatx()\n-        'float32'\n-        >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n-        >>> arr.dtype\n-        dtype('float64')\n-        >>> new_arr = K.cast_to_floatx(arr)\n-        >>> new_arr\n-        array([ 1.,  2.], dtype=float32)\n-        >>> new_arr.dtype\n-        dtype('float32')\n-    ```\n-    \"\"\"\n-    return np.asarray(x, dtype=_FLOATX)\n-\n-\n-def image_data_format():\n-    \"\"\"Returns the default image data format convention.\n-\n-    # Returns\n-        A string, either `'channels_first'` or `'channels_last'`\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.image_data_format()\n-        'channels_first'\n-    ```\n-    \"\"\"\n-    return _IMAGE_DATA_FORMAT\n-\n-\n-def set_image_data_format(data_format):\n-    \"\"\"Sets the value of the data format convention.\n-\n-    # Arguments\n-        data_format: string. `'channels_first'` or `'channels_last'`.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.image_data_format()\n-        'channels_first'\n-        >>> K.set_image_data_format('channels_last')\n-        >>> K.image_data_format()\n-        'channels_last'\n-    ```\n-    \"\"\"\n-    global _IMAGE_DATA_FORMAT\n-    if data_format not in {'channels_last', 'channels_first'}:\n-        raise ValueError('Unknown data_format:', data_format)\n-    _IMAGE_DATA_FORMAT = str(data_format)\n-\n-\n-def normalize_data_format(value):\n-    \"\"\"Checks that the value correspond to a valid data format.\n-\n-    # Arguments\n-        value: String or None. `'channels_first'` or `'channels_last'`.\n-\n-    # Returns\n-        A string, either `'channels_first'` or `'channels_last'`\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.normalize_data_format(None)\n-        'channels_first'\n-        >>> K.normalize_data_format('channels_last')\n-        'channels_last'\n-    ```\n-\n-    # Raises\n-        ValueError: if `value` or the global `data_format` invalid.\n-    \"\"\"\n-    if value is None:\n-        value = image_data_format()\n-    data_format = value.lower()\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('The `data_format` argument must be one of '\n-                         '\"channels_first\", \"channels_last\". Received: ' +\n-                         str(value))\n-    return data_format\n-\n-\n-def symbolic(func):\n-    \"\"\"Dummy decorator used in TensorFlow 2.0 to enter the Keras graph.\"\"\"\n-    return func\n-\n-\n-def eager(func):\n-    \"\"\"Dummy decorator used in TensorFlow 2.0 to exit the Keras graph.\"\"\"\n-    return func\n-\n-\n-# Legacy methods\n-\n-def set_image_dim_ordering(dim_ordering):\n-    \"\"\"Legacy setter for `image_data_format`.\n-\n-    # Arguments\n-        dim_ordering: string. `tf` or `th`.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.image_data_format()\n-        'channels_first'\n-        >>> K.set_image_data_format('channels_last')\n-        >>> K.image_data_format()\n-        'channels_last'\n-    ```\n-\n-    # Raises\n-        ValueError: if `dim_ordering` is invalid.\n-    \"\"\"\n-    global _IMAGE_DATA_FORMAT\n-    if dim_ordering not in {'tf', 'th'}:\n-        raise ValueError('Unknown dim_ordering:', dim_ordering)\n-    if dim_ordering == 'th':\n-        data_format = 'channels_first'\n-    else:\n-        data_format = 'channels_last'\n-    _IMAGE_DATA_FORMAT = data_format\n-\n-\n-def image_dim_ordering():\n-    \"\"\"Legacy getter for `image_data_format`.\n-\n-    # Returns\n-        string, one of `'th'`, `'tf'`\n-    \"\"\"\n-    if _IMAGE_DATA_FORMAT == 'channels_first':\n-        return 'th'\n-    else:\n-        return 'tf'\n\n@@ -1,124 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import print_function\n-import os\n-import json\n-import sys\n-import importlib\n-from .common import epsilon\n-from .common import floatx\n-from .common import set_epsilon\n-from .common import set_floatx\n-from .common import cast_to_floatx\n-from .common import image_data_format\n-from .common import set_image_data_format\n-from .common import normalize_data_format\n-from .common import symbolic, eager\n-\n-# Set Keras base dir path given KERAS_HOME env variable, if applicable.\n-# Otherwise either ~/.keras or /tmp.\n-if 'KERAS_HOME' in os.environ:\n-    _keras_dir = os.environ.get('KERAS_HOME')\n-else:\n-    _keras_base_dir = os.path.expanduser('~')\n-    if not os.access(_keras_base_dir, os.W_OK):\n-        _keras_base_dir = '/tmp'\n-    _keras_dir = os.path.join(_keras_base_dir, '.keras')\n-\n-# Default backend: TensorFlow.\n-_BACKEND = 'tensorflow'\n-\n-# Attempt to read Keras config file.\n-_config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n-if os.path.exists(_config_path):\n-    try:\n-        with open(_config_path) as f:\n-            _config = json.load(f)\n-    except ValueError:\n-        _config = {}\n-    _floatx = _config.get('floatx', floatx())\n-    assert _floatx in {'float16', 'float32', 'float64'}\n-    _epsilon = _config.get('epsilon', epsilon())\n-    assert isinstance(_epsilon, float)\n-    _backend = _config.get('backend', _BACKEND)\n-    _image_data_format = _config.get('image_data_format',\n-                                     image_data_format())\n-    assert _image_data_format in {'channels_last', 'channels_first'}\n-\n-    set_floatx(_floatx)\n-    set_epsilon(_epsilon)\n-    set_image_data_format(_image_data_format)\n-    _BACKEND = _backend\n-\n-# Save config file, if possible.\n-if not os.path.exists(_keras_dir):\n-    try:\n-        os.makedirs(_keras_dir)\n-    except OSError:\n-        # Except permission denied and potential race conditions\n-        # in multi-threaded environments.\n-        pass\n-\n-if not os.path.exists(_config_path):\n-    _config = {\n-        'floatx': floatx(),\n-        'epsilon': epsilon(),\n-        'backend': _BACKEND,\n-        'image_data_format': image_data_format()\n-    }\n-    try:\n-        with open(_config_path, 'w') as f:\n-            f.write(json.dumps(_config, indent=4))\n-    except IOError:\n-        # Except permission denied.\n-        pass\n-\n-# Set backend based on KERAS_BACKEND flag, if applicable.\n-if 'KERAS_BACKEND' in os.environ:\n-    _backend = os.environ['KERAS_BACKEND']\n-    if _backend:\n-        _BACKEND = _backend\n-\n-# Import backend functions.\n-if _BACKEND == 'cntk':\n-    sys.stderr.write('Using CNTK backend\\n')\n-    from .cntk_backend import *\n-elif _BACKEND == 'theano':\n-    sys.stderr.write('Using Theano backend.\\n')\n-    from .theano_backend import *\n-elif _BACKEND == 'tensorflow':\n-    sys.stderr.write('Using TensorFlow backend.\\n')\n-    from .tensorflow_backend import *\n-else:\n-    # Try and load external backend.\n-    try:\n-        backend_module = importlib.import_module(_BACKEND)\n-        entries = backend_module.__dict__\n-        # Check if valid backend.\n-        # Module is a valid backend if it has the required entries.\n-        required_entries = ['placeholder', 'variable', 'function']\n-        for e in required_entries:\n-            if e not in entries:\n-                raise ValueError('Invalid backend. Missing required entry : ' + e)\n-        namespace = globals()\n-        for k, v in entries.items():\n-            # Make sure we don't override any entries from common, such as epsilon.\n-            if k not in namespace:\n-                namespace[k] = v\n-        sys.stderr.write('Using ' + _BACKEND + ' backend.\\n')\n-    except ImportError:\n-        raise ValueError('Unable to import backend : ' + str(_BACKEND))\n-\n-\n-def backend():\n-    \"\"\"Returns the name of the current backend (e.g. \"tensorflow\").\n-\n-    # Returns\n-        String, the name of the backend Keras is currently using.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.backend()\n-        'tensorflow'\n-    ```\n-    \"\"\"\n-    return _BACKEND\n\n@@ -1,768 +0,0 @@\n-\"\"\"Utilities for backend functionality checks.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-import scipy.signal as signal\n-import scipy as sp\n-from .common import floatx\n-from keras.utils.generic_utils import transpose_shape\n-from keras.utils import to_categorical\n-\n-\n-def normalize_conv(func):\n-    def wrapper(*args, **kwargs):\n-        x = args[0]\n-        w = args[1]\n-        if x.ndim == 3:\n-            w = np.flipud(w)\n-            w = np.transpose(w, (1, 2, 0))\n-            if kwargs['data_format'] == 'channels_last':\n-                x = np.transpose(x, (0, 2, 1))\n-        elif x.ndim == 4:\n-            w = np.fliplr(np.flipud(w))\n-            w = np.transpose(w, (2, 3, 0, 1))\n-            if kwargs['data_format'] == 'channels_last':\n-                x = np.transpose(x, (0, 3, 1, 2))\n-        else:\n-            w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n-            w = np.transpose(w, (3, 4, 0, 1, 2))\n-            if kwargs['data_format'] == 'channels_last':\n-                x = np.transpose(x, (0, 4, 1, 2, 3))\n-\n-        dilation_rate = kwargs.pop('dilation_rate', 1)\n-        if isinstance(dilation_rate, int):\n-            dilation_rate = (dilation_rate,) * (x.ndim - 2)\n-        for (i, d) in enumerate(dilation_rate):\n-            if d > 1:\n-                for j in range(w.shape[2 + i] - 1):\n-                    w = np.insert(w, 2 * j + 1, 0, axis=2 + i)\n-\n-        y = func(x, w, **kwargs)\n-\n-        if kwargs['data_format'] == 'channels_last':\n-            if y.ndim == 3:\n-                y = np.transpose(y, (0, 2, 1))\n-            elif y.ndim == 4:\n-                y = np.transpose(y, (0, 2, 3, 1))\n-            else:\n-                y = np.transpose(y, (0, 2, 3, 4, 1))\n-\n-        return y\n-\n-    return wrapper\n-\n-\n-@normalize_conv\n-def conv(x, w, padding, data_format):\n-    y = []\n-    for i in range(x.shape[0]):\n-        _y = []\n-        for j in range(w.shape[1]):\n-            __y = []\n-            for k in range(w.shape[0]):\n-                __y.append(signal.convolve(x[i, k], w[k, j], mode=padding))\n-            _y.append(np.sum(np.stack(__y, axis=-1), axis=-1))\n-        y.append(_y)\n-    y = np.array(y)\n-    return y\n-\n-\n-@normalize_conv\n-def depthwise_conv(x, w, padding, data_format):\n-    y = []\n-    for i in range(x.shape[0]):\n-        _y = []\n-        for j in range(w.shape[0]):\n-            __y = []\n-            for k in range(w.shape[1]):\n-                __y.append(signal.convolve(x[i, j], w[j, k], mode=padding))\n-            _y.append(np.stack(__y, axis=0))\n-        y.append(np.concatenate(_y, axis=0))\n-    y = np.array(y)\n-    return y\n-\n-\n-def separable_conv(x, w1, w2, padding, data_format):\n-    x2 = depthwise_conv(x, w1, padding=padding, data_format=data_format)\n-    return conv(x2, w2, padding=padding, data_format=data_format)\n-\n-\n-def conv_transpose(x, w, output_shape, padding, data_format, dilation_rate=1):\n-    if x.ndim == 4:\n-        w = np.fliplr(np.flipud(w))\n-        w = np.transpose(w, (0, 1, 3, 2))\n-    else:\n-        w = np.flip(np.fliplr(np.flipud(w)), axis=2)\n-        w = np.transpose(w, (0, 1, 2, 4, 3))\n-\n-    if isinstance(dilation_rate, int):\n-        dilation_rate = (dilation_rate,) * (x.ndim - 2)\n-    for (i, d) in enumerate(dilation_rate):\n-        if d > 1:\n-            for j in range(w.shape[i] - 1):\n-                w = np.insert(w, 2 * j + 1, 0, axis=i)\n-\n-    return conv(x, w, padding=padding, data_format=data_format)\n-\n-\n-conv1d = conv\n-conv2d = conv\n-conv3d = conv\n-depthwise_conv2d = depthwise_conv\n-separable_conv1d = separable_conv\n-separable_conv2d = separable_conv\n-conv2d_transpose = conv_transpose\n-conv3d_transpose = conv_transpose\n-\n-\n-def pool(x, pool_size, strides, padding, data_format, pool_mode):\n-    if data_format == 'channels_last':\n-        if x.ndim == 3:\n-            x = np.transpose(x, (0, 2, 1))\n-        elif x.ndim == 4:\n-            x = np.transpose(x, (0, 3, 1, 2))\n-        else:\n-            x = np.transpose(x, (0, 4, 1, 2, 3))\n-\n-    if padding == 'same':\n-        pad = [(0, 0), (0, 0)] + [(s // 2, s // 2) for s in pool_size]\n-        x = np.pad(x, pad, 'constant', constant_values=-np.inf)\n-\n-    # indexing trick\n-    x = np.pad(x, [(0, 0), (0, 0)] + [(0, 1) for _ in pool_size],\n-               'constant', constant_values=0)\n-\n-    if x.ndim == 3:\n-        y = [x[:, :, k:k1:strides[0]]\n-             for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0))]\n-    elif x.ndim == 4:\n-        y = []\n-        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n-            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n-                y.append(x[:, :, k:k1:strides[0], l:l1:strides[1]])\n-    else:\n-        y = []\n-        for (k, k1) in zip(range(pool_size[0]), range(-pool_size[0], 0)):\n-            for (l, l1) in zip(range(pool_size[1]), range(-pool_size[1], 0)):\n-                for (m, m1) in zip(range(pool_size[2]), range(-pool_size[2], 0)):\n-                    y.append(x[:,\n-                               :,\n-                               k:k1:strides[0],\n-                               l:l1:strides[1],\n-                               m:m1:strides[2]])\n-    y = np.stack(y, axis=-1)\n-    if pool_mode == 'avg':\n-        y = np.mean(np.ma.masked_invalid(y), axis=-1).data\n-    elif pool_mode == 'max':\n-        y = np.max(y, axis=-1)\n-\n-    if data_format == 'channels_last':\n-        if y.ndim == 3:\n-            y = np.transpose(y, (0, 2, 1))\n-        elif y.ndim == 4:\n-            y = np.transpose(y, (0, 2, 3, 1))\n-        else:\n-            y = np.transpose(y, (0, 2, 3, 4, 1))\n-\n-    return y\n-\n-\n-pool2d = pool\n-pool3d = pool\n-\n-\n-def bias_add(x, y, data_format):\n-    if data_format == 'channels_first':\n-        if y.ndim > 1:\n-            y = np.reshape(y, y.shape[::-1])\n-        for _ in range(x.ndim - y.ndim - 1):\n-            y = np.expand_dims(y, -1)\n-    else:\n-        for _ in range(x.ndim - y.ndim - 1):\n-            y = np.expand_dims(y, 0)\n-    return x + y\n-\n-\n-def rnn(step_function, inputs, initial_states,\n-        go_backwards=False, mask=None, constants=None,\n-        unroll=False, input_length=None):\n-\n-    if constants is None:\n-        constants = []\n-\n-    output_sample, _ = step_function(inputs[:, 0], initial_states + constants)\n-    if mask is not None:\n-        if mask.dtype != np.bool:\n-            mask = mask.astype(np.bool)\n-        if mask.shape != inputs.shape[:2]:\n-            raise ValueError(\n-                'mask should have `shape=(samples, time)`, '\n-                'got {}'.format(mask.shape))\n-\n-        def expand_mask(mask_, x):\n-            # expand mask so that `mask[:, t].ndim == x.ndim`\n-            while mask_.ndim < x.ndim + 1:\n-                mask_ = np.expand_dims(mask_, axis=-1)\n-            return mask_\n-        output_mask = expand_mask(mask, output_sample)\n-        states_masks = [expand_mask(mask, state) for state in initial_states]\n-\n-    if input_length is None:\n-        input_length = inputs.shape[1]\n-    assert input_length == inputs.shape[1]\n-    time_index = range(input_length)\n-    if go_backwards:\n-        time_index = time_index[::-1]\n-\n-    outputs = []\n-    states_tm1 = initial_states  # tm1 means \"t minus one\" as in \"previous timestep\"\n-    output_tm1 = np.zeros(output_sample.shape)\n-    for t in time_index:\n-        output_t, states_t = step_function(inputs[:, t], states_tm1 + constants)\n-        if mask is not None:\n-            output_t = np.where(output_mask[:, t], output_t, output_tm1)\n-            states_t = [np.where(state_mask[:, t], state_t, state_tm1)\n-                        for state_mask, state_t, state_tm1\n-                        in zip(states_masks, states_t, states_tm1)]\n-        outputs.append(output_t)\n-        states_tm1 = states_t\n-        output_tm1 = output_t\n-\n-    return outputs[-1], np.stack(outputs, axis=1), states_tm1\n-\n-\n-_LEARNING_PHASE = True\n-\n-\n-def learning_phase():\n-    return _LEARNING_PHASE\n-\n-\n-def set_learning_phase(value):\n-    global _LEARNING_PHASE\n-    _LEARNING_PHASE = value\n-\n-\n-def in_train_phase(x, alt, training=None):\n-    if training is None:\n-        training = learning_phase()\n-\n-    if training is 1 or training is True:\n-        if callable(x):\n-            return x()\n-        else:\n-            return x\n-    else:\n-        if callable(alt):\n-            return alt()\n-        else:\n-            return alt\n-\n-\n-def in_test_phase(x, alt, training=None):\n-    return in_train_phase(alt, x, training=training)\n-\n-\n-def relu(x, alpha=0., max_value=None, threshold=0.):\n-    if max_value is None:\n-        max_value = np.inf\n-    above_threshold = x * (x >= threshold)\n-    above_threshold = np.clip(above_threshold, 0.0, max_value)\n-    below_threshold = alpha * (x - threshold) * (x < threshold)\n-    return below_threshold + above_threshold\n-\n-\n-def switch(condition, then_expression, else_expression):\n-    cond_float = condition.astype(floatx())\n-    while cond_float.ndim < then_expression.ndim:\n-        cond_float = cond_float[..., np.newaxis]\n-    return cond_float * then_expression + (1 - cond_float) * else_expression\n-\n-\n-def softplus(x):\n-    return np.log(1. + np.exp(x))\n-\n-\n-def softsign(x):\n-    return x / (1 + np.abs(x))\n-\n-\n-def elu(x, alpha=1.):\n-    return x * (x > 0) + alpha * (np.exp(x) - 1.) * (x < 0)\n-\n-\n-def sigmoid(x):\n-    return 1. / (1. + np.exp(-x))\n-\n-\n-def hard_sigmoid(x):\n-    y = 0.2 * x + 0.5\n-    return np.clip(y, 0, 1)\n-\n-\n-def tanh(x):\n-    return np.tanh(x)\n-\n-\n-def softmax(x, axis=-1):\n-    y = np.exp(x - np.max(x, axis, keepdims=True))\n-    return y / np.sum(y, axis, keepdims=True)\n-\n-\n-def l2_normalize(x, axis=-1):\n-    y = np.max(np.sum(x ** 2, axis, keepdims=True), axis, keepdims=True)\n-    return x / np.sqrt(y)\n-\n-\n-def in_top_k(predictions, targets, k):\n-    top_k = np.argsort(-predictions)[:, :k]\n-    targets = targets.reshape(-1, 1)\n-    return np.any(targets == top_k, axis=-1)\n-\n-\n-def binary_crossentropy(target, output, from_logits=False):\n-    if not from_logits:\n-        output = np.clip(output, 1e-7, 1 - 1e-7)\n-        output = np.log(output / (1 - output))\n-    return (target * -np.log(sigmoid(output)) +\n-            (1 - target) * -np.log(1 - sigmoid(output)))\n-\n-\n-def categorical_crossentropy(target, output, from_logits=False):\n-    if from_logits:\n-        output = softmax(output)\n-    else:\n-        output /= output.sum(axis=-1, keepdims=True)\n-    output = np.clip(output, 1e-7, 1 - 1e-7)\n-    return np.sum(target * -np.log(output), axis=-1, keepdims=False)\n-\n-\n-def max(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.max(x, axis=axis, keepdims=keepdims)\n-\n-\n-def min(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.min(x, axis=axis, keepdims=keepdims)\n-\n-\n-def mean(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.mean(x, axis=axis, keepdims=keepdims)\n-\n-\n-def var(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.var(x, axis=axis, keepdims=keepdims)\n-\n-\n-def std(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.std(x, axis=axis, keepdims=keepdims)\n-\n-\n-def logsumexp(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return sp.special.logsumexp(x, axis=axis, keepdims=keepdims)\n-\n-\n-def sum(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.sum(x, axis=axis, keepdims=keepdims)\n-\n-\n-def prod(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.prod(x, axis=axis, keepdims=keepdims)\n-\n-\n-def cumsum(x, axis=0):\n-    return np.cumsum(x, axis=axis)\n-\n-\n-def cumprod(x, axis=0):\n-    return np.cumprod(x, axis=axis)\n-\n-\n-def any(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.any(x, axis=axis, keepdims=keepdims)\n-\n-\n-def all(x, axis=None, keepdims=False):\n-    if isinstance(axis, list):\n-        axis = tuple(axis)\n-    return np.all(x, axis=axis, keepdims=keepdims)\n-\n-\n-def argmax(x, axis=-1):\n-    return np.argmax(x, axis=axis)\n-\n-\n-def argmin(x, axis=-1):\n-    return np.argmin(x, axis=axis)\n-\n-\n-def sqrt(x):\n-    y = np.sqrt(x)\n-    y[np.isnan(y)] = 0.\n-    return y\n-\n-\n-def pow(x, a=1.):\n-    return np.power(x, a)\n-\n-\n-def clip(x, min_value, max_value):\n-    return np.clip(x, min_value, max_value)\n-\n-\n-def concatenate(tensors, axis=-1):\n-    return np.concatenate(tensors, axis)\n-\n-\n-def permute_dimensions(x, pattern):\n-    return np.transpose(x, pattern)\n-\n-\n-def reshape(x, shape):\n-    return np.reshape(x, shape)\n-\n-\n-def repeat_elements(x, rep, axis):\n-    return np.repeat(x, rep, axis=axis)\n-\n-\n-def repeat(x, n):\n-    y = np.expand_dims(x, 1)\n-    y = np.repeat(y, n, axis=1)\n-    return y\n-\n-\n-def temporal_padding(x, padding=(1, 1)):\n-    return np.pad(x, [(0, 0), padding, (0, 0)], mode='constant')\n-\n-\n-def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n-    all_dims_padding = ((0, 0),) + padding + ((0, 0),)\n-    all_dims_padding = transpose_shape(all_dims_padding, data_format,\n-                                       spatial_axes=(1, 2))\n-    return np.pad(x, all_dims_padding, mode='constant')\n-\n-\n-def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n-    all_dims_padding = ((0, 0),) + padding + ((0, 0),)\n-    all_dims_padding = transpose_shape(all_dims_padding, data_format,\n-                                       spatial_axes=(1, 2, 3))\n-    return np.pad(x, all_dims_padding, mode='constant')\n-\n-\n-def tile(x, n):\n-    return np.tile(x, n)\n-\n-\n-def arange(start, stop=None, step=1, dtype='int32'):\n-    return np.arange(start, stop, step, dtype)\n-\n-\n-def flatten(x):\n-    return np.reshape(x, (-1,))\n-\n-\n-def batch_flatten(x):\n-    return np.reshape(x, (x.shape[0], -1))\n-\n-\n-def gather(reference, indices):\n-    return reference[indices]\n-\n-\n-def eval(x):\n-    return x\n-\n-\n-def get_value(x):\n-    return x\n-\n-\n-def count_params(x):\n-    return x.size\n-\n-\n-def int_shape(x):\n-    return x.shape\n-\n-\n-def get_variable_shape(x):\n-    return int_shape(x)\n-\n-\n-def dtype(x):\n-    return x.dtype.name\n-\n-\n-def constant(value, dtype=None, shape=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if shape is None:\n-        shape = ()\n-    np_value = value * np.ones(shape)\n-    np_value.astype(dtype)\n-    return np_value\n-\n-\n-def print_tensor(x, message=''):\n-    print(x, message)\n-    return x\n-\n-\n-def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001):\n-    return ((x - mean) / sqrt(var + epsilon)) * gamma + beta\n-\n-\n-def dot(x, y):\n-    return np.dot(x, y)\n-\n-\n-def batch_dot(x, y, axes=None):\n-    if x.ndim < 2 or y.ndim < 2:\n-        raise ValueError('Batch dot requires inputs of rank 2 or more.')\n-\n-    if isinstance(axes, int):\n-        axes = [axes, axes]\n-    elif isinstance(axes, tuple):\n-        axes = list(axes)\n-\n-    if axes is None:\n-        if y.ndim == 2:\n-            axes = [x.ndim - 1, y.ndim - 1]\n-        else:\n-            axes = [x.ndim - 1, y.ndim - 2]\n-\n-    if any([isinstance(a, (list, tuple)) for a in axes]):\n-        raise ValueError('Multiple target dimensions are not supported. ' +\n-                         'Expected: None, int, (int, int), ' +\n-                         'Provided: ' + str(axes))\n-\n-    # Handle negative axes\n-    if axes[0] < 0:\n-        axes[0] += x.ndim\n-    if axes[1] < 0:\n-        axes[1] += y.ndim\n-\n-    if 0 in axes:\n-        raise ValueError('Can not perform batch dot over axis 0.')\n-\n-    if x.shape[0] != y.shape[0]:\n-        raise ValueError('Can not perform batch dot on inputs'\n-                         ' with different batch sizes.')\n-\n-    d1 = x.shape[axes[0]]\n-    d2 = y.shape[axes[1]]\n-    if d1 != d2:\n-        raise ValueError('Can not do batch_dot on inputs with shapes ' +\n-                         str(x.shape) + ' and ' + str(y.shape) +\n-                         ' with axes=' + str(axes) + '. x.shape[%d] != '\n-                         'y.shape[%d] (%d != %d).' % (axes[0], axes[1], d1, d2))\n-\n-    result = []\n-    axes = [axes[0] - 1, axes[1] - 1]  # ignore batch dimension\n-    for xi, yi in zip(x, y):\n-        result.append(np.tensordot(xi, yi, axes))\n-    result = np.array(result)\n-\n-    if result.ndim == 1:\n-        result = np.expand_dims(result, -1)\n-\n-    return result\n-\n-\n-def transpose(x):\n-    return np.transpose(x)\n-\n-\n-def reverse(x, axes):\n-    if isinstance(axes, list):\n-        axes = tuple(axes)\n-    return np.flip(x, axes)\n-\n-\n-py_slice = slice\n-\n-\n-def slice(x, start, size):\n-    slices = [py_slice(i, i + j) for i, j in zip(start, size)]\n-    return x[tuple(slices)]\n-\n-\n-def variable(value, dtype=None, name=None, constraint=None):\n-    if constraint is not None:\n-        raise TypeError(\"Constraint must be None when \"\n-                        \"using the NumPy backend.\")\n-    return np.array(value, dtype)\n-\n-\n-def dropout(x, level, noise_shape=None, seed=None):\n-    if noise_shape is None:\n-        noise_shape = x.shape\n-    if learning_phase():\n-        noise = np.random.choice([0, 1],\n-                                 noise_shape,\n-                                 replace=True,\n-                                 p=[level, 1 - level])\n-        return x * noise / (1 - level)\n-    else:\n-        return x\n-\n-\n-def equal(x, y):\n-    return x == y\n-\n-\n-def not_equal(x, y):\n-    return x != y\n-\n-\n-def greater(x, y):\n-    return x > y\n-\n-\n-def greater_equal(x, y):\n-    return x >= y\n-\n-\n-def less(x, y):\n-    return x < y\n-\n-\n-def less_equal(x, y):\n-    return x <= y\n-\n-\n-def maximum(x, y):\n-    return np.maximum(x, y)\n-\n-\n-def minimum(x, y):\n-    return np.minimum(x, y)\n-\n-\n-def ndim(x):\n-    return x.ndim\n-\n-\n-def random_uniform_variable(shape, low, high, dtype=None, name=None, seed=None):\n-    return (high - low) * np.random.random(shape).astype(dtype) + low\n-\n-\n-def random_normal_variable(shape, mean, scale, dtype=None, name=None, seed=None):\n-    return scale * np.random.randn(*shape).astype(dtype) + mean\n-\n-\n-def zeros(shape, dtype=floatx(), name=None):\n-    return np.zeros(shape, dtype=dtype)\n-\n-\n-def zeros_like(x, dtype=floatx(), name=None):\n-    return np.zeros_like(x, dtype=dtype)\n-\n-\n-def ones(shape, dtype=floatx(), name=None):\n-    return np.ones(shape, dtype=dtype)\n-\n-\n-def ones_like(x, dtype=floatx(), name=None):\n-    return np.ones_like(x, dtype=dtype)\n-\n-\n-def eye(size, dtype=None, name=None):\n-    if isinstance(size, (list, tuple)):\n-        n, m = size\n-    else:\n-        n, m = size, size\n-    return np.eye(n, m, dtype=dtype)\n-\n-\n-def resize_images(x, height_factor, width_factor, data_format):\n-    if data_format == 'channels_first':\n-        x = repeat_elements(x, height_factor, axis=2)\n-        x = repeat_elements(x, width_factor, axis=3)\n-    elif data_format == 'channels_last':\n-        x = repeat_elements(x, height_factor, axis=1)\n-        x = repeat_elements(x, width_factor, axis=2)\n-    return x\n-\n-\n-def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n-    if data_format == 'channels_first':\n-        x = repeat_elements(x, depth_factor, axis=2)\n-        x = repeat_elements(x, height_factor, axis=3)\n-        x = repeat_elements(x, width_factor, axis=4)\n-    elif data_format == 'channels_last':\n-        x = repeat_elements(x, depth_factor, axis=1)\n-        x = repeat_elements(x, height_factor, axis=2)\n-        x = repeat_elements(x, width_factor, axis=3)\n-    return x\n-\n-\n-def one_hot(indices, num_classes):\n-    return to_categorical(indices, num_classes)\n-\n-\n-def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n-               merge_repeated=False):\n-    num_samples = y_pred.shape[0]\n-    num_classes = y_pred.shape[-1]\n-    log_prob = np.zeros((num_samples, 1))\n-    decoded_dense = -np.ones_like(y_pred[..., 0])\n-    decoded_length = np.zeros((num_samples,), dtype=np.int)\n-    if greedy:\n-        for i in range(num_samples):\n-            prob = y_pred[i]\n-            length = input_length[i]\n-            decoded = np.argmax(prob[:length], axis=-1)\n-            log_prob[i] = -np.sum(np.log(prob[np.arange(length), decoded]))\n-            decoded = _remove_repeats(decoded)\n-            decoded = _remove_blanks(decoded, num_classes)\n-            decoded_length[i] = len(decoded)\n-            decoded_dense[i, :len(decoded)] = decoded\n-        return decoded_dense[:, :np.max(decoded_length)], log_prob\n-    else:\n-        raise NotImplementedError\n-\n-\n-def _remove_repeats(inds):\n-    is_not_repeat = np.insert(np.diff(inds).astype(np.bool), 0, True)\n-    return inds[is_not_repeat]\n-\n-\n-def _remove_blanks(inds, num_classes):\n-    return inds[inds < (num_classes - 1)]\n-\n-\n-def stack(x, axis=0):\n-    return np.stack(x, axis=axis)\n-\n-\n-square = np.square\n-abs = np.abs\n-exp = np.exp\n-log = np.log\n-round = np.round\n-sign = np.sign\n-expand_dims = np.expand_dims\n-squeeze = np.squeeze\n-cos = np.cos\n-sin = np.sin\n\n@@ -1,4603 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import tensorflow as tf\n-from tensorflow.python.eager import context\n-from tensorflow.python.framework import device as tfdev\n-from tensorflow.python.framework import ops as tf_ops\n-from tensorflow.python.ops import image_ops as tf_image_ops\n-from tensorflow.python.ops import math_ops as tf_math_ops\n-from tensorflow.python.ops import state_ops as tf_state_ops\n-from tensorflow.python.keras import backend as tf_keras_backend\n-from tensorflow.python.keras.utils import tf_utils\n-from tensorflow.python.ops import functional_ops\n-from tensorflow.python.ops import ctc_ops as ctc\n-from .common import floatx, epsilon, image_data_format\n-\n-import sys\n-import functools\n-import threading\n-\n-import numpy as np\n-from distutils.version import StrictVersion\n-\n-from ..utils.generic_utils import transpose_shape\n-\n-py_all = all\n-py_any = any\n-py_sum = sum\n-py_slice = slice\n-\n-# INTERNAL UTILS\n-\n-# This list holds the available devices.\n-# It is populated when `_get_available_gpus()` is called for the first time.\n-# We assume our devices don't change during our lifetime.\n-_LOCAL_DEVICES = None\n-\n-_SYMBOLIC_SCOPE = threading.local()\n-_SYMBOLIC_SCOPE.value = True\n-_LEARNING_PHASE_CACHE = {}\n-\n-\n-def _is_tf_1():\n-    return tf.__version__.startswith('1.')\n-\n-# Set initial config\n-tf_keras_backend.set_floatx(floatx())\n-tf_keras_backend.set_epsilon(epsilon())\n-tf_keras_backend.set_image_data_format(image_data_format())\n-\n-\n-# Private TF Keras utils\n-get_graph = tf_keras_backend.get_graph\n-# learning_phase_scope = tf_keras_backend.learning_phase_scope  # TODO\n-name_scope = tf.name_scope\n-\n-\n-def symbolic(func):\n-    \"\"\"Decorator used in TensorFlow 2.0 to enter the Keras graph.\n-\n-    # Arguments\n-        func: Function to decorate.\n-\n-    # Returns\n-        Decorated function.\n-    \"\"\"\n-    if _is_tf_1():\n-        return func\n-\n-    @functools.wraps(func)\n-    def symbolic_fn_wrapper(*args, **kwargs):\n-        if _SYMBOLIC_SCOPE.value:\n-            with get_graph().as_default():\n-                return func(*args, **kwargs)\n-        else:\n-            return func(*args, **kwargs)\n-    return symbolic_fn_wrapper\n-\n-\n-def is_symbolic(x):\n-    return isinstance(x, tf.Tensor) and hasattr(x, 'op')\n-\n-\n-def eager(func):\n-    \"\"\"Decorator used in TensorFlow 2.0 to exit the Keras graph.\n-\n-    # Arguments\n-        func: Function to decorate.\n-\n-    # Returns\n-        Decorated function.\n-    \"\"\"\n-    if _is_tf_1():\n-        return func\n-\n-    global _SYMBOLIC_SCOPE\n-\n-    @functools.wraps(func)\n-    def eager_fn_wrapper(*args, **kwargs):\n-        prev_value = _SYMBOLIC_SCOPE.value\n-        try:\n-            _SYMBOLIC_SCOPE.value = False\n-            with context.eager_mode():\n-                out = func(*args, **kwargs)\n-        finally:\n-            _SYMBOLIC_SCOPE.value = prev_value\n-        return out\n-    return eager_fn_wrapper\n-\n-\n-def _has_compat_v1():\n-    if hasattr(tf, 'compat') and hasattr(tf.compat, 'v1'):\n-        return True\n-    return False\n-\n-\n-def get_uid(prefix=''):\n-    \"\"\"Provides a unique UID given a string prefix.\n-\n-    # Arguments\n-        prefix: string.\n-\n-    # Returns\n-        An integer.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.get_uid('dense')\n-        1\n-        >>> keras.backend.get_uid('dense')\n-        2\n-    ```\n-\n-    \"\"\"\n-    return tf_keras_backend.get_uid(prefix)\n-\n-\n-def manual_variable_initialization(value):\n-    \"\"\"Sets the manual variable initialization flag.\n-\n-    This boolean flag determines whether\n-    variables should be initialized\n-    as they are instantiated (default), or if\n-    the user should handle the initialization.\n-\n-    # Arguments\n-        value: Python boolean.\n-    \"\"\"\n-    tf_keras_backend.manual_variable_initialization(value)\n-\n-\n-def epsilon():\n-    \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n-\n-    # Returns\n-        A float.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.epsilon()\n-        1e-07\n-    ```\n-    \"\"\"\n-    return tf_keras_backend.epsilon()\n-\n-\n-def reset_uids():\n-    \"\"\"Resets graph identifiers.\"\"\"\n-    tf_keras_backend.reset_uids()\n-\n-\n-def set_epsilon(e):\n-    \"\"\"Sets the value of the fuzz factor used in numeric expressions.\n-\n-    # Arguments\n-        e: float. New value of epsilon.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.epsilon()\n-        1e-07\n-        >>> K.set_epsilon(1e-05)\n-        >>> K.epsilon()\n-        1e-05\n-    ```\n-    \"\"\"\n-    tf_keras_backend.set_epsilon(e)\n-\n-\n-def floatx():\n-    \"\"\"Returns the default float type, as a string.\n-    (e.g. 'float16', 'float32', 'float64').\n-\n-    # Returns\n-        String, the current default float type.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.floatx()\n-        'float32'\n-    ```\n-    \"\"\"\n-    return tf_keras_backend.floatx()\n-\n-\n-def set_floatx(floatx):\n-    \"\"\"Sets the default float type.\n-\n-    # Arguments\n-        floatx: String, 'float16', 'float32', or 'float64'.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.floatx()\n-        'float32'\n-        >>> K.set_floatx('float16')\n-        >>> K.floatx()\n-        'float16'\n-    ```\n-    \"\"\"\n-    tf_keras_backend.set_floatx(floatx)\n-\n-\n-def cast_to_floatx(x):\n-    \"\"\"Cast a Numpy array to the default Keras float type.\n-\n-    # Arguments\n-        x: Numpy array.\n-\n-    # Returns\n-        The same Numpy array, cast to its new type.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.floatx()\n-        'float32'\n-        >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n-        >>> arr.dtype\n-        dtype('float64')\n-        >>> new_arr = K.cast_to_floatx(arr)\n-        >>> new_arr\n-        array([ 1.,  2.], dtype=float32)\n-        >>> new_arr.dtype\n-        dtype('float32')\n-    ```\n-    \"\"\"\n-    return tf_keras_backend.cast_to_floatx(x)\n-\n-\n-def image_data_format():\n-    \"\"\"Returns the default image data format convention.\n-\n-    # Returns\n-        A string, either `'channels_first'` or `'channels_last'`\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.image_data_format()\n-        'channels_first'\n-    ```\n-    \"\"\"\n-    return tf_keras_backend.image_data_format()\n-\n-\n-def set_image_data_format(data_format):\n-    \"\"\"Sets the value of the data format convention.\n-\n-    # Arguments\n-        data_format: string. `'channels_first'` or `'channels_last'`.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.image_data_format()\n-        'channels_first'\n-        >>> K.set_image_data_format('channels_last')\n-        >>> K.image_data_format()\n-        'channels_last'\n-    ```\n-    \"\"\"\n-    tf_keras_backend.set_image_data_format(data_format)\n-\n-\n-def normalize_data_format(value):\n-    \"\"\"Checks that the value correspond to a valid data format.\n-\n-    # Arguments\n-        value: String or None. `'channels_first'` or `'channels_last'`.\n-\n-    # Returns\n-        A string, either `'channels_first'` or `'channels_last'`\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.normalize_data_format(None)\n-        'channels_first'\n-        >>> K.normalize_data_format('channels_last')\n-        'channels_last'\n-    ```\n-\n-    # Raises\n-        ValueError: if `value` or the global `data_format` invalid.\n-    \"\"\"\n-    if value is None:\n-        value = image_data_format()\n-    data_format = value.lower()\n-    if data_format not in {'channels_first', 'channels_last'}:\n-        raise ValueError('The `data_format` argument must be one of '\n-                         '\"channels_first\", \"channels_last\". Received: ' +\n-                         str(value))\n-    return data_format\n-\n-\n-@symbolic\n-def learning_phase():\n-    \"\"\"Returns the learning phase flag.\n-\n-    The learning phase flag is a bool tensor (0 = test, 1 = train)\n-    to be passed as input to any Keras function\n-    that uses a different behavior at train time and test time.\n-\n-    # Returns\n-        Learning phase (scalar integer tensor or Python integer).\n-    \"\"\"\n-    lp = tf_keras_backend.learning_phase()\n-    if _is_tf_1():\n-        return lp\n-    else:\n-        if isinstance(lp, int):\n-            return lp\n-        if id(lp) in _LEARNING_PHASE_CACHE:\n-            return _LEARNING_PHASE_CACHE[id(lp)]\n-        with name_scope(''):\n-            int_lp = tf.cast(lp, 'int32', name='learning_phase')\n-        _LEARNING_PHASE_CACHE[id(lp)] = int_lp\n-        return int_lp\n-\n-\n-@symbolic\n-def set_learning_phase(value):\n-    \"\"\"Sets the learning phase to a fixed value.\n-\n-    # Arguments\n-        value: Learning phase value, either 0 or 1 (integers).\n-\n-    # Raises\n-        ValueError: if `value` is neither `0` nor `1`.\n-    \"\"\"\n-    tf_keras_backend.set_learning_phase(value)\n-\n-\n-def get_session():\n-    \"\"\"Returns the TF session to be used by the backend.\n-\n-    If a default TensorFlow session is available, we will return it.\n-\n-    Else, we will return the global Keras session.\n-\n-    If no global Keras session exists at this point:\n-    we will create a new global session.\n-\n-    Note that you can manually set the global session\n-    via `K.set_session(sess)`.\n-\n-    # Returns\n-        A TensorFlow session.\n-\n-    # Raises\n-        RuntimeError: if no session is available\n-            (e.g. when using TensorFlow 2.0).\n-    \"\"\"\n-    if not _is_tf_1():\n-        raise RuntimeError(\n-            '`get_session` is not available '\n-            'when using TensorFlow 2.0.')\n-    if tf.executing_eagerly():\n-        raise RuntimeError(\n-            '`get_session` is not available when '\n-            'TensorFlow is executing eagerly.')\n-    return tf_keras_backend.get_session()\n-\n-\n-def set_session(session):\n-    \"\"\"Sets the global TensorFlow session.\n-\n-    # Arguments\n-        session: A TF Session.\n-\n-    # Raises\n-        RuntimeError: if no session is available\n-            (e.g. when using TensorFlow 2.0).\n-    \"\"\"\n-    if not _is_tf_1():\n-        raise RuntimeError(\n-            '`set_session` is not available '\n-            'when using TensorFlow 2.0.')\n-    if tf.executing_eagerly():\n-        raise RuntimeError(\n-            '`set_session` is not available when '\n-            'TensorFlow is executing eagerly.')\n-    tf_keras_backend.set_session(session)\n-\n-\n-def clear_session():\n-    \"\"\"Destroys the current Keras graph and creates a new one.\n-\n-    Useful to avoid clutter from old models / layers.\n-    \"\"\"\n-    tf_keras_backend.clear_session()\n-    global _LEARNING_PHASE_CACHE\n-    _LEARNING_PHASE_CACHE = {}\n-\n-\n-def v1_variable_initialization():\n-    session = get_session()\n-    with session.graph.as_default():\n-        variables = tf.global_variables()\n-        candidate_vars = []\n-        for v in variables:\n-            if not getattr(v, '_keras_initialized', False):\n-                candidate_vars.append(v)\n-        if candidate_vars:\n-            # This step is expensive, so we only run it on variables\n-            # not already marked as initialized.\n-            is_initialized = session.run(\n-                [tf.is_variable_initialized(v) for v in candidate_vars])\n-            uninitialized_vars = []\n-            for flag, v in zip(is_initialized, candidate_vars):\n-                if not flag:\n-                    uninitialized_vars.append(v)\n-                v._keras_initialized = True\n-            if uninitialized_vars:\n-                session.run(tf.variables_initializer(uninitialized_vars))\n-\n-\n-# DEVICE MANIPULATION AND PROBING\n-\n-class _TfDeviceCaptureOp(object):\n-    \"\"\"Class for capturing the TF device scope.\"\"\"\n-\n-    def __init__(self):\n-        # NOTE(robieta): This differs from tf.keras in that self.device is a\n-        # DeviceSpec rather than a string. This is done for compatibility\n-        # with a range of TensorFlow versions.\n-        self.device = None\n-\n-    def _set_device(self, device):\n-        \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n-        self.device = device\n-\n-    def _set_device_from_string(self, device_str):\n-        self.device = tfdev.DeviceSpec.from_string(device_str)\n-\n-\n-def _get_current_tf_device():\n-    \"\"\"Return explicit device of current context, otherwise returns `None`.\n-\n-    # Returns\n-        If the current device scope is explicitly set, it returns a string with\n-        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n-        return `None`.\n-    \"\"\"\n-    g = get_graph()\n-    op = _TfDeviceCaptureOp()\n-    g._apply_device_functions(op)\n-    return op.device\n-\n-\n-def _is_current_explicit_device(device_type):\n-    \"\"\"Check if the current device is explicitly set on the device type specified.\n-\n-    # Arguments\n-        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n-\n-    # Returns\n-        A boolean indicating if the current device\n-        scope is explicitly set on the device type.\n-\n-    # Raises\n-        ValueError: If the `device_type` string indicates an unsupported device.\n-    \"\"\"\n-    device_type = device_type.lower()\n-    if device_type not in ['cpu', 'gpu']:\n-        raise ValueError('`device_type` should be either \"cpu\" or \"gpu\".')\n-    device = _get_current_tf_device()\n-    return (device is not None and device.device_type.lower() == device_type)\n-\n-\n-def _get_available_gpus():\n-    \"\"\"Get a list of available gpu devices (formatted as strings).\n-\n-    # Returns\n-        A list of available GPU devices.\n-    \"\"\"\n-    global _LOCAL_DEVICES\n-    if _LOCAL_DEVICES is None:\n-        if _is_tf_1():\n-            devices = get_session().list_devices()\n-            _LOCAL_DEVICES = [x.name for x in devices]\n-        else:\n-            _LOCAL_DEVICES = tf.config.experimental_list_devices()\n-    return [x for x in _LOCAL_DEVICES if 'device:gpu' in x.lower()]\n-\n-\n-def _has_nchw_support():\n-    \"\"\"Check whether the current scope supports NCHW ops.\n-\n-    TensorFlow does not support NCHW on CPU.\n-    Therefore we check if we are not explicitly put on\n-    CPU, and have GPUs available.\n-    In this case there will be soft-placing on the GPU device.\n-\n-    # Returns\n-        bool: if the current scope device placement would support nchw\n-    \"\"\"\n-    explicitly_on_cpu = _is_current_explicit_device('cpu')\n-    gpus_available = len(_get_available_gpus()) > 0\n-    return (not explicitly_on_cpu and gpus_available)\n-\n-\n-# VARIABLE MANIPULATION\n-\n-@symbolic\n-def _to_tensor(x, dtype):\n-    \"\"\"Convert the input `x` to a tensor of type `dtype`.\n-\n-    # Arguments\n-        x: An object to be converted (numpy array, list, tensors).\n-        dtype: The destination type.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.convert_to_tensor(x, dtype=dtype)\n-\n-\n-def is_sparse(tensor):\n-    \"\"\"Returns whether a tensor is a sparse tensor.\n-\n-    # Arguments\n-        tensor: A tensor instance.\n-\n-    # Returns\n-        A boolean.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> a = K.placeholder((2, 2), sparse=False)\n-        >>> print(K.is_sparse(a))\n-        False\n-        >>> b = K.placeholder((2, 2), sparse=True)\n-        >>> print(K.is_sparse(b))\n-        True\n-    ```\n-    \"\"\"\n-    return isinstance(tensor, tf.SparseTensor)\n-\n-\n-@symbolic\n-def to_dense(tensor):\n-    \"\"\"Converts a sparse tensor into a dense tensor and returns it.\n-\n-    # Arguments\n-        tensor: A tensor instance (potentially sparse).\n-\n-    # Returns\n-        A dense tensor.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> b = K.placeholder((2, 2), sparse=True)\n-        >>> print(K.is_sparse(b))\n-        True\n-        >>> c = K.to_dense(b)\n-        >>> print(K.is_sparse(c))\n-        False\n-    ```\n-    \"\"\"\n-    if is_sparse(tensor):\n-        return tf.sparse.to_dense(tensor)\n-    else:\n-        return tensor\n-\n-\n-def variable(value, dtype=None, name=None, constraint=None):\n-    \"\"\"Instantiates a variable and returns it.\n-\n-    # Arguments\n-        value: Numpy array, initial value of the tensor.\n-        dtype: Tensor type.\n-        name: Optional name string for the tensor.\n-        constraint: Optional projection function to be\n-            applied to the variable after an optimizer update.\n-\n-    # Returns\n-        A variable instance (with Keras metadata included).\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> val = np.array([[1, 2], [3, 4]])\n-        >>> kvar = K.variable(value=val, dtype='float64', name='example_var')\n-        >>> K.dtype(kvar)\n-        'float64'\n-        >>> print(kvar)\n-        example_var\n-        >>> K.eval(kvar)\n-        array([[ 1.,  2.],\n-               [ 3.,  4.]])\n-    ```\n-    \"\"\"\n-    v = tf_keras_backend.variable(\n-        value, dtype=dtype, name=name, constraint=constraint)\n-    if hasattr(value, 'tocoo'):\n-        v._keras_shape = value.tocoo().shape\n-    elif isinstance(value, np.ndarray):\n-        v._keras_shape = value.shape\n-    elif hasattr(value, 'shape'):\n-        v._keras_shape = int_shape(value)\n-    v._uses_learning_phase = False\n-    return v\n-\n-\n-def is_variable(x):\n-    return isinstance(x, tf.Variable)\n-\n-\n-def constant(value, dtype=None, shape=None, name=None):\n-    \"\"\"Creates a constant tensor.\n-\n-    # Arguments\n-        value: A constant value (or list)\n-        dtype: The type of the elements of the resulting tensor.\n-        shape: Optional dimensions of resulting tensor.\n-        name: Optional name for the tensor.\n-\n-    # Returns\n-        A Constant Tensor.\n-    \"\"\"\n-    with tf_ops.init_scope():\n-        return tf_keras_backend.constant(\n-            value, dtype=dtype, shape=shape, name=name)\n-\n-\n-def is_keras_tensor(x):\n-    \"\"\"Returns whether `x` is a Keras tensor.\n-\n-    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n-    (`Layer` class) or by `Input`.\n-\n-    # Arguments\n-        x: A candidate tensor.\n-\n-    # Returns\n-        A boolean: Whether the argument is a Keras tensor.\n-\n-    # Raises\n-        ValueError: In case `x` is not a symbolic tensor.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> from keras.layers import Input, Dense\n-        >>> np_var = numpy.array([1, 2])\n-        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n-        ValueError\n-        >>> k_var = tf.placeholder('float32', shape=(1,1))\n-        >>> # A variable indirectly created outside of keras is not a Keras tensor.\n-        >>> K.is_keras_tensor(k_var)\n-        False\n-        >>> keras_var = K.variable(np_var)\n-        >>> # A variable created with the keras backend is not a Keras tensor.\n-        >>> K.is_keras_tensor(keras_var)\n-        False\n-        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n-        >>> # A placeholder is not a Keras tensor.\n-        >>> K.is_keras_tensor(keras_placeholder)\n-        False\n-        >>> keras_input = Input([10])\n-        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n-        True\n-        >>> keras_layer_output = Dense(10)(keras_input)\n-        >>> # Any Keras layer output is a Keras tensor.\n-        >>> K.is_keras_tensor(keras_layer_output)\n-        True\n-    ```\n-    \"\"\"\n-    if not is_tensor(x):\n-        raise ValueError('Unexpectedly found an instance of type `' +\n-                         str(type(x)) + '`. '\n-                         'Expected a symbolic tensor instance.')\n-    return hasattr(x, '_keras_history')\n-\n-\n-def is_tensor(x):\n-    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)\n-\n-\n-@symbolic\n-def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n-    \"\"\"Instantiates a placeholder tensor and returns it.\n-\n-    # Arguments\n-        shape: Shape of the placeholder\n-            (integer tuple, may include `None` entries).\n-        ndim: Number of axes of the tensor.\n-            At least one of {`shape`, `ndim`} must be specified.\n-            If both are specified, `shape` is used.\n-        dtype: Placeholder type.\n-        sparse: Boolean, whether the placeholder should have a sparse type.\n-        name: Optional name string for the placeholder.\n-\n-    # Returns\n-        Tensor instance (with Keras metadata included).\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> input_ph = K.placeholder(shape=(2, 4, 5))\n-        >>> input_ph._keras_shape\n-        (2, 4, 5)\n-        >>> input_ph\n-        <tf.Tensor 'Placeholder_4:0' shape=(2, 4, 5) dtype=float32>\n-    ```\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    x = tf_keras_backend.placeholder(\n-        shape=shape, ndim=ndim, dtype=dtype, sparse=sparse, name=name)\n-    if shape is None:\n-        if ndim is not None:\n-            shape = tuple(None for _ in range(ndim))\n-    x._keras_shape = shape\n-    x._uses_learning_phase = False\n-    return x\n-\n-\n-@symbolic\n-def is_placeholder(x):\n-    \"\"\"Returns whether `x` is a placeholder.\n-\n-    # Arguments\n-        x: A candidate placeholder.\n-\n-    # Returns\n-        Boolean.\n-    \"\"\"\n-    try:\n-        return x.op.type == 'Placeholder'\n-    except AttributeError:\n-        return False\n-\n-\n-def shape(x):\n-    \"\"\"Returns the symbolic shape of a tensor or variable.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-\n-    # Returns\n-        A symbolic shape (which is itself a tensor).\n-\n-    # Examples\n-    ```python\n-        # TensorFlow example\n-        >>> from keras import backend as K\n-        >>> tf_session = K.get_session()\n-        >>> val = np.array([[1, 2], [3, 4]])\n-        >>> kvar = K.variable(value=val)\n-        >>> inputs = keras.backend.placeholder(shape=(2, 4, 5))\n-        >>> K.shape(kvar)\n-        <tf.Tensor 'Shape_8:0' shape=(2,) dtype=int32>\n-        >>> K.shape(inputs)\n-        <tf.Tensor 'Shape_9:0' shape=(3,) dtype=int32>\n-        # To get integer shape (Instead, you can use K.int_shape(x))\n-        >>> K.shape(kvar).eval(session=tf_session)\n-        array([2, 2], dtype=int32)\n-        >>> K.shape(inputs).eval(session=tf_session)\n-        array([2, 4, 5], dtype=int32)\n-    ```\n-    \"\"\"\n-    return tf.shape(x)\n-\n-\n-def int_shape(x):\n-    \"\"\"Returns the shape of tensor or variable as a tuple of int or None entries.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tuple of integers (or None entries).\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> inputs = K.placeholder(shape=(2, 4, 5))\n-        >>> K.int_shape(inputs)\n-        (2, 4, 5)\n-        >>> val = np.array([[1, 2], [3, 4]])\n-        >>> kvar = K.variable(value=val)\n-        >>> K.int_shape(kvar)\n-        (2, 2)\n-    ```\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    if hasattr(x, '_keras_shape'):\n-        return x._keras_shape\n-    try:\n-        if isinstance(x.shape, tuple):\n-            return x.shape\n-        return tuple(x.shape.as_list())\n-    except ValueError:\n-        return None\n-\n-\n-def ndim(x):\n-    \"\"\"Returns the number of axes in a tensor, as an integer.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        Integer (scalar), number of axes.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> inputs = K.placeholder(shape=(2, 4, 5))\n-        >>> val = np.array([[1, 2], [3, 4]])\n-        >>> kvar = K.variable(value=val)\n-        >>> K.ndim(inputs)\n-        3\n-        >>> K.ndim(kvar)\n-        2\n-    ```\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return x.shape.rank\n-\n-\n-def size(x, name=None):\n-    \"\"\"Returns the size of a tensor.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        name: A name for the operation (optional).\n-\n-    # Returns\n-        Size of the tensor.\n-\n-    # Examples\n-    ```python\n-    >>> from keras import backend as K\n-    >>> val = np.array([[1, 2], [3, 4]])\n-    >>> kvar = K.variable(value=val)\n-    >>> K.size(inputs)\n-    <tf.Tensor: id=9, shape=(), dtype=int32, numpy=4>\n-    ```\n-\n-    \"\"\"\n-    if is_symbolic(x):\n-        with get_graph().as_default():\n-            return tf.size(x)\n-    return tf.size(x, name=name)\n-\n-\n-def dtype(x):\n-    \"\"\"Returns the dtype of a Keras tensor or variable, as a string.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        String, dtype of `x`.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.dtype(K.placeholder(shape=(2,4,5)))\n-        'float32'\n-        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float32'))\n-        'float32'\n-        >>> K.dtype(K.placeholder(shape=(2,4,5), dtype='float64'))\n-        'float64'\n-        # Keras variable\n-        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]))\n-        >>> K.dtype(kvar)\n-        'float32_ref'\n-        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n-        >>> K.dtype(kvar)\n-        'float32_ref'\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    return x.dtype.base_dtype.name\n-\n-\n-def eval(x):\n-    \"\"\"Evaluates the value of a tensor.\n-\n-    # Arguments\n-        x: A tensor.\n-\n-    # Returns\n-        A Numpy array.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n-        >>> K.eval(kvar)\n-        array([[ 1.,  2.],\n-               [ 3.,  4.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if _is_tf_1():\n-        return to_dense(x).eval(session=get_session())\n-    if hasattr(x, 'numpy'):\n-        with context.eager_mode():\n-            return x.numpy()\n-    eval_fn = function([], [x])\n-    return eval_fn([])[0]\n-\n-\n-def zeros(shape, dtype=None, name=None):\n-    \"\"\"Instantiates an all-zeros variable and returns it.\n-\n-    # Arguments\n-        shape: Tuple of integers, shape of returned Keras variable\n-        dtype: String, data type of returned Keras variable\n-        name: String, name of returned Keras variable\n-\n-    # Returns\n-        A variable (including Keras metadata), filled with `0.0`.\n-        Note that if `shape` was symbolic, we cannot return a variable,\n-        and will return a dynamically-shaped tensor instead.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.zeros((3,4))\n-        >>> K.eval(kvar)\n-        array([[ 0.,  0.,  0.,  0.],\n-               [ 0.,  0.,  0.,  0.],\n-               [ 0.,  0.,  0.,  0.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    with tf_ops.init_scope():\n-        v = tf.zeros(shape=shape, dtype=dtype, name=name)\n-        if py_all(v.shape.as_list()):\n-            return variable(v, dtype=dtype, name=name)\n-        return v\n-\n-\n-def ones(shape, dtype=None, name=None):\n-    \"\"\"Instantiates an all-ones variable and returns it.\n-\n-    # Arguments\n-        shape: Tuple of integers, shape of returned Keras variable.\n-        dtype: String, data type of returned Keras variable.\n-        name: String, name of returned Keras variable.\n-\n-    # Returns\n-        A Keras variable, filled with `1.0`.\n-        Note that if `shape` was symbolic, we cannot return a variable,\n-        and will return a dynamically-shaped tensor instead.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.ones((3,4))\n-        >>> K.eval(kvar)\n-        array([[ 1.,  1.,  1.,  1.],\n-               [ 1.,  1.,  1.,  1.],\n-               [ 1.,  1.,  1.,  1.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    with tf_ops.init_scope():\n-        v = tf.ones(shape=shape, dtype=dtype, name=name)\n-        if py_all(v.shape.as_list()):\n-            return variable(v, dtype=dtype, name=name)\n-        return v\n-\n-\n-def eye(size, dtype=None, name=None):\n-    \"\"\"Instantiate an identity matrix and returns it.\n-\n-    # Arguments\n-        size: Tuple, number of rows and columns. If Integer, number of rows.\n-        dtype: String, data type of returned Keras variable.\n-        name: String, name of returned Keras variable.\n-\n-    # Returns\n-        A Keras variable, an identity matrix.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> K.eval(K.eye(3))\n-        array([[ 1.,  0.,  0.],\n-               [ 0.,  1.,  0.],\n-               [ 0.,  0.,  1.]], dtype=float32)\n-        >>> K.eval(K.eye((2, 3)))\n-        array([[1., 0., 0.],\n-               [0., 1., 0.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if isinstance(size, (list, tuple)):\n-        n, m = size\n-    else:\n-        n, m = size, size\n-    with tf_ops.init_scope():\n-        return tf.eye(n, m, dtype=dtype, name=name)\n-\n-\n-@symbolic\n-def zeros_like(x, dtype=None, name=None):\n-    \"\"\"Instantiates an all-zeros variable of the same shape as another tensor.\n-\n-    # Arguments\n-        x: Keras variable or Keras tensor.\n-        dtype: String, dtype of returned Keras variable.\n-             None uses the dtype of x.\n-        name: String, name for the variable to create.\n-\n-    # Returns\n-        A Keras variable with the shape of x filled with zeros.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.variable(np.random.random((2,3)))\n-        >>> kvar_zeros = K.zeros_like(kvar)\n-        >>> K.eval(kvar_zeros)\n-        array([[ 0.,  0.,  0.],\n-               [ 0.,  0.,  0.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    return tf.zeros_like(x, dtype=dtype, name=name)\n-\n-\n-@symbolic\n-def ones_like(x, dtype=None, name=None):\n-    \"\"\"Instantiates an all-ones variable of the same shape as another tensor.\n-\n-    # Arguments\n-        x: Keras variable or tensor.\n-        dtype: String, dtype of returned Keras variable.\n-             None uses the dtype of x.\n-        name: String, name for the variable to create.\n-\n-    # Returns\n-        A Keras variable with the shape of x filled with ones.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.variable(np.random.random((2,3)))\n-        >>> kvar_ones = K.ones_like(kvar)\n-        >>> K.eval(kvar_ones)\n-        array([[ 1.,  1.,  1.],\n-               [ 1.,  1.,  1.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    return tf.ones_like(x, dtype=dtype, name=name)\n-\n-\n-@symbolic\n-def identity(x, name=None):\n-    \"\"\"Returns a tensor with the same content as the input tensor.\n-\n-    # Arguments\n-        x: The input tensor.\n-        name: String, name for the variable to create.\n-\n-    # Returns\n-        A tensor of the same shape, type and content.\n-    \"\"\"\n-    return tf.identity(x, name)\n-\n-\n-def random_uniform_variable(shape, low, high,\n-                            dtype=None,\n-                            name=None,\n-                            seed=None):\n-    \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n-\n-    # Arguments\n-        shape: Tuple of integers, shape of returned Keras variable.\n-        low: Float, lower boundary of the output interval.\n-        high: Float, upper boundary of the output interval.\n-        dtype: String, dtype of returned Keras variable.\n-        name: String, name of returned Keras variable.\n-        seed: Integer, random seed.\n-\n-    # Returns\n-        A Keras variable, filled with drawn samples.\n-\n-    # Example\n-    ```python\n-        # TensorFlow example\n-        >>> kvar = K.random_uniform_variable((2,3), 0, 1)\n-        >>> kvar\n-        <tensorflow.python.ops.variables.Variable object at 0x10ab40b10>\n-        >>> K.eval(kvar)\n-        array([[ 0.10940075,  0.10047495,  0.476143  ],\n-               [ 0.66137183,  0.00869417,  0.89220798]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e8)\n-    with tf_ops.init_scope():\n-        value = tf.random_uniform_initializer(\n-            low, high, seed=seed)(shape, dtype=dtype)\n-        return variable(value, dtype=dtype, name=name)\n-\n-\n-def random_normal_variable(shape, mean, scale, dtype=None,\n-                           name=None, seed=None):\n-    \"\"\"Instantiates a variable with values drawn from a normal distribution.\n-\n-    # Arguments\n-        shape: Tuple of integers, shape of returned Keras variable.\n-        mean: Float, mean of the normal distribution.\n-        scale: Float, standard deviation of the normal distribution.\n-        dtype: String, dtype of returned Keras variable.\n-        name: String, name of returned Keras variable.\n-        seed: Integer, random seed.\n-\n-    # Returns\n-        A Keras variable, filled with drawn samples.\n-\n-    # Example\n-    ```python\n-        # TensorFlow example\n-        >>> kvar = K.random_normal_variable((2,3), 0, 1)\n-        >>> kvar\n-        <tensorflow.python.ops.variables.Variable object at 0x10ab12dd0>\n-        >>> K.eval(kvar)\n-        array([[ 1.19591331,  0.68685907, -0.63814116],\n-               [ 0.92629528,  0.28055015,  1.70484698]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        # ensure that randomness is conditioned by the Numpy RNG\n-        seed = np.random.randint(10e8)\n-    with tf_ops.init_scope():\n-        value = tf.random_normal_initializer(\n-            mean, scale, seed=seed)(shape, dtype=dtype)\n-        return variable(value, dtype=dtype, name=name)\n-\n-\n-def count_params(x):\n-    \"\"\"Returns the static number of elements in a Keras variable or tensor.\n-\n-    # Arguments\n-        x: Keras variable or tensor.\n-\n-    # Returns\n-        Integer, the number of elements in `x`, i.e., the product of the\n-        array's static dimensions.\n-\n-    # Example\n-    ```python\n-        >>> kvar = K.zeros((2,3))\n-        >>> K.count_params(kvar)\n-        6\n-        >>> K.eval(kvar)\n-        array([[ 0.,  0.,  0.],\n-               [ 0.,  0.,  0.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    return np.prod(int_shape(x))\n-\n-\n-def cast(x, dtype):\n-    \"\"\"Casts a tensor to a different dtype and returns it.\n-\n-    You can cast a Keras variable but it still returns a Keras tensor.\n-\n-    # Arguments\n-        x: Keras tensor (or variable).\n-        dtype: String, either (`'float16'`, `'float32'`, or `'float64'`).\n-\n-    # Returns\n-        Keras tensor with dtype `dtype`.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> input = K.placeholder((2, 3), dtype='float32')\n-        >>> input\n-        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n-        # It doesn't work in-place as below.\n-        >>> K.cast(input, dtype='float16')\n-        <tf.Tensor 'Cast_1:0' shape=(2, 3) dtype=float16>\n-        >>> input\n-        <tf.Tensor 'Placeholder_2:0' shape=(2, 3) dtype=float32>\n-        # you need to assign it.\n-        >>> input = K.cast(input, dtype='float16')\n-        >>> input\n-        <tf.Tensor 'Cast_2:0' shape=(2, 3) dtype=float16>\n-    ```\n-    \"\"\"\n-    return tf.cast(x, dtype)\n-\n-\n-# UPDATES OPS\n-\n-\n-def update(x, new_x):\n-    \"\"\"Update the value of `x` to `new_x`.\n-\n-    # Arguments\n-        x: A `Variable`.\n-        new_x: A tensor of same shape as `x`.\n-\n-    # Returns\n-        The variable `x` updated.\n-    \"\"\"\n-    return tf_state_ops.assign(x, new_x)\n-\n-\n-def update_add(x, increment):\n-    \"\"\"Update the value of `x` by adding `increment`.\n-\n-    # Arguments\n-        x: A `Variable`.\n-        increment: A tensor of same shape as `x`.\n-\n-    # Returns\n-        The variable `x` updated.\n-    \"\"\"\n-    return tf_state_ops.assign_add(x, increment)\n-\n-\n-def update_sub(x, decrement):\n-    \"\"\"Update the value of `x` by subtracting `decrement`.\n-\n-    # Arguments\n-        x: A `Variable`.\n-        decrement: A tensor of same shape as `x`.\n-\n-    # Returns\n-        The variable `x` updated.\n-    \"\"\"\n-    return tf_state_ops.assign_sub(x, decrement)\n-\n-\n-@symbolic\n-def moving_average_update(x, value, momentum):\n-    \"\"\"Compute the moving average of a variable.\n-\n-    # Arguments\n-        x: A `Variable`.\n-        value: A tensor with the same shape as `x`.\n-        momentum: The moving average momentum.\n-\n-    # Returns\n-        An operation to update the variable.\n-    \"\"\"\n-    with tf_ops.colocate_with(x):\n-        decay = tf_ops.convert_to_tensor(1.0 - momentum)\n-        if decay.dtype != x.dtype.base_dtype:\n-            decay = tf_math_ops.cast(decay, x.dtype.base_dtype)\n-        update_delta = (x - tf_math_ops.cast(value, x.dtype)) * decay\n-        return tf_state_ops.assign_sub(x, update_delta)\n-\n-\n-# LINEAR ALGEBRA\n-\n-def dot(x, y):\n-    \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n-\n-    When attempting to multiply a nD tensor\n-    with a nD tensor, it reproduces the Theano behavior.\n-    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A tensor, dot product of `x` and `y`.\n-\n-    # Examples\n-    ```python\n-        # dot product between tensors\n-        >>> x = K.placeholder(shape=(2, 3))\n-        >>> y = K.placeholder(shape=(3, 4))\n-        >>> xy = K.dot(x, y)\n-        >>> xy\n-        <tf.Tensor 'MatMul_9:0' shape=(2, 4) dtype=float32>\n-    ```\n-\n-    ```python\n-        # dot product between tensors\n-        >>> x = K.placeholder(shape=(32, 28, 3))\n-        >>> y = K.placeholder(shape=(3, 4))\n-        >>> xy = K.dot(x, y)\n-        >>> xy\n-        <tf.Tensor 'MatMul_9:0' shape=(32, 28, 4) dtype=float32>\n-    ```\n-\n-    ```python\n-        # Theano-like behavior example\n-        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n-        >>> y = K.ones((4, 3, 5))\n-        >>> xy = K.dot(x, y)\n-        >>> K.int_shape(xy)\n-        (2, 4, 5)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n-        x_shape = []\n-        for i, s in zip(int_shape(x), tf.unstack(tf.shape(x))):\n-            if i is not None:\n-                x_shape.append(i)\n-            else:\n-                x_shape.append(s)\n-        x_shape = tuple(x_shape)\n-        y_shape = []\n-        for i, s in zip(int_shape(y), tf.unstack(tf.shape(y))):\n-            if i is not None:\n-                y_shape.append(i)\n-            else:\n-                y_shape.append(s)\n-        y_shape = tuple(y_shape)\n-        y_permute_dim = list(range(ndim(y)))\n-        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n-        xt = tf.reshape(x, [-1, x_shape[-1]])\n-        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n-        return tf.reshape(tf.matmul(xt, yt),\n-                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n-    if is_sparse(x):\n-        out = tf.sparse.sparse_dense_matmul(x, y)\n-    else:\n-        out = tf.matmul(x, y)\n-    return out\n-\n-\n-def batch_dot(x, y, axes=None):\n-    \"\"\"Batchwise dot product.\n-\n-    `batch_dot` is used to compute dot product of `x` and `y` when\n-    `x` and `y` are data in batches, i.e. in a shape of\n-    `(batch_size, :)`.\n-    `batch_dot` results in a tensor or variable with less dimensions\n-    than the input. If the number of dimensions is reduced to 1,\n-    we use `expand_dims` to make sure that ndim is at least 2.\n-\n-    # Arguments\n-        x: Keras tensor or variable with `ndim >= 2`.\n-        y: Keras tensor or variable with `ndim >= 2`.\n-        axes: int or tuple(int, int). Target dimensions to be reduced.\n-\n-    # Returns\n-        A tensor with shape equal to the concatenation of `x`'s shape\n-        (less the dimension that was summed over) and `y`'s shape\n-        (less the batch dimension and the dimension that was summed over).\n-        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n-\n-    # Examples\n-        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n-        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n-        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n-        elements.\n-\n-        Pseudocode:\n-        ```\n-        inner_products = []\n-        for xi, yi in zip(x, y):\n-            inner_products.append(xi.dot(yi))\n-        result = stack(inner_products)\n-        ```\n-\n-        Shape inference:\n-        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n-        If `axes` is (1, 2), to find the output shape of resultant tensor,\n-            loop through each dimension in `x`'s shape and `y`'s shape:\n-\n-        * `x.shape[0]` : 100 : append to output shape\n-        * `x.shape[1]` : 20 : do not append to output shape,\n-            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n-        * `y.shape[0]` : 100 : do not append to output shape,\n-            always ignore first dimension of `y`\n-        * `y.shape[1]` : 30 : append to output shape\n-        * `y.shape[2]` : 20 : do not append to output shape,\n-            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n-        `output_shape` = `(100, 30)`\n-\n-    ```python\n-        >>> x_batch = K.ones(shape=(32, 20, 1))\n-        >>> y_batch = K.ones(shape=(32, 30, 20))\n-        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=(1, 2))\n-        >>> K.int_shape(xy_batch_dot)\n-        (32, 1, 30)\n-    ```\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    x_shape = int_shape(x)\n-    y_shape = int_shape(y)\n-\n-    x_ndim = len(x_shape)\n-    y_ndim = len(y_shape)\n-\n-    if x_ndim < 2 or y_ndim < 2:\n-        raise ValueError('Can not do batch_dot on inputs '\n-                         'with rank < 2. '\n-                         'Received inputs with shapes ' +\n-                         str(x_shape) + ' and ' +\n-                         str(y_shape) + '.')\n-\n-    x_batch_size = x_shape[0]\n-    y_batch_size = y_shape[0]\n-\n-    if x_batch_size is not None and y_batch_size is not None:\n-        if x_batch_size != y_batch_size:\n-            raise ValueError('Can not do batch_dot on inputs '\n-                             'with different batch sizes. '\n-                             'Received inputs with shapes ' +\n-                             str(x_shape) + ' and ' +\n-                             str(y_shape) + '.')\n-\n-    if isinstance(axes, int):\n-        axes = [axes, axes]\n-\n-    if axes is None:\n-        if y_ndim == 2:\n-            axes = [x_ndim - 1, y_ndim - 1]\n-        else:\n-            axes = [x_ndim - 1, y_ndim - 2]\n-\n-    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n-        raise ValueError('Multiple target dimensions are not supported. ' +\n-                         'Expected: None, int, (int, int), ' +\n-                         'Provided: ' + str(axes))\n-\n-    # if tuple, convert to list.\n-    axes = list(axes)\n-\n-    # convert negative indices.\n-    if axes[0] < 0:\n-        axes[0] += x_ndim\n-    if axes[1] < 0:\n-        axes[1] += y_ndim\n-\n-    # sanity checks\n-    if 0 in axes:\n-        raise ValueError('Can not perform batch_dot over axis 0.'\n-                         'If your inputs are not batched,'\n-                         ' add a dummy batch dimension to your '\n-                         'inputs using K.expand_dims(x, 0)')\n-\n-    a0, a1 = axes\n-    d1 = x_shape[a0]\n-    d2 = y_shape[a1]\n-\n-    if d1 is not None and d2 is not None and d1 != d2:\n-        raise ValueError('Can not do batch_dot on inputs with shapes ' +\n-                         str(x_shape) + ' and ' + str(y_shape) +\n-                         ' with axes=' + str(axes) + '. x.shape[%d] != '\n-                         'y.shape[%d] (%d != %d).' % (axes[0], axes[1], d1, d2))\n-\n-    # backup ndims. Need them later.\n-    orig_x_ndim = x_ndim\n-    orig_y_ndim = y_ndim\n-\n-    # if rank is 2, expand to 3.\n-    if x_ndim == 2:\n-        x = tf.expand_dims(x, 1)\n-        a0 += 1\n-        x_ndim += 1\n-    if y_ndim == 2:\n-        y = tf.expand_dims(y, 2)\n-        y_ndim += 1\n-\n-    # bring x's dimension to be reduced to last axis.\n-    if a0 != x_ndim - 1:\n-        pattern = list(range(x_ndim))\n-        for i in range(a0, x_ndim - 1):\n-            pattern[i] = pattern[i + 1]\n-        pattern[-1] = a0\n-        x = tf.transpose(x, pattern)\n-\n-    # bring y's dimension to be reduced to axis 1.\n-    if a1 != 1:\n-        pattern = list(range(y_ndim))\n-        for i in range(a1, 1, -1):\n-            pattern[i] = pattern[i - 1]\n-        pattern[1] = a1\n-        y = tf.transpose(y, pattern)\n-\n-    # normalize both inputs to rank 3.\n-    if x_ndim > 3:\n-        # squash middle dimensions of x.\n-        x_shape = shape(x)\n-        x_mid_dims = x_shape[1:-1]\n-        x_squashed_dim = tf.reduce_prod(x_mid_dims)\n-        x_squashed_shape = tf.stack([x_shape[0], x_squashed_dim, x_shape[-1]])\n-        x = tf.reshape(x, x_squashed_shape)\n-        x_squashed = True\n-    else:\n-        x_squashed = False\n-\n-    if y_ndim > 3:\n-        # squash trailing dimensions of y.\n-        y_shape = shape(y)\n-        y_trail_dims = y_shape[2:]\n-        y_squashed_dim = tf.reduce_prod(y_trail_dims)\n-        y_squashed_shape = tf.stack([y_shape[0], y_shape[1], y_squashed_dim])\n-        y = tf.reshape(y, y_squashed_shape)\n-        y_squashed = True\n-    else:\n-        y_squashed = False\n-\n-    result = tf.matmul(x, y)\n-\n-    # if inputs were squashed, we have to reshape the matmul output.\n-    output_shape = tf.shape(result)\n-    do_reshape = False\n-\n-    if x_squashed:\n-        output_shape = tf.concat([output_shape[:1],\n-                                  x_mid_dims,\n-                                  output_shape[-1:]], 0)\n-        do_reshape = True\n-\n-    if y_squashed:\n-        output_shape = tf.concat([output_shape[:-1], y_trail_dims], 0)\n-        do_reshape = True\n-\n-    if do_reshape:\n-        result = tf.reshape(result, output_shape)\n-\n-    # if the inputs were originally rank 2, we remove the added 1 dim.\n-    if orig_x_ndim == 2:\n-        result = tf.squeeze(result, 1)\n-    elif orig_y_ndim == 2:\n-        result = tf.squeeze(result, -1)\n-\n-    return result\n-\n-\n-def transpose(x):\n-    \"\"\"Transposes a tensor and returns it.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-\n-    # Examples\n-    ```python\n-        >>> var = K.variable([[1, 2, 3], [4, 5, 6]])\n-        >>> K.eval(var)\n-        array([[ 1.,  2.,  3.],\n-               [ 4.,  5.,  6.]], dtype=float32)\n-        >>> var_transposed = K.transpose(var)\n-        >>> K.eval(var_transposed)\n-        array([[ 1.,  4.],\n-               [ 2.,  5.],\n-               [ 3.,  6.]], dtype=float32)\n-    ```\n-\n-    ```python\n-        >>> inputs = K.placeholder((2, 3))\n-        >>> inputs\n-        <tf.Tensor 'Placeholder_11:0' shape=(2, 3) dtype=float32>\n-        >>> input_transposed = K.transpose(inputs)\n-        >>> input_transposed\n-        <tf.Tensor 'transpose_4:0' shape=(3, 2) dtype=float32>\n-\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.transpose(x)\n-\n-\n-def gather(reference, indices):\n-    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n-\n-    # Arguments\n-        reference: A tensor.\n-        indices: An integer tensor of indices.\n-\n-    # Returns\n-        A tensor of same type as `reference`.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.nn.embedding_lookup(reference, indices)\n-\n-\n-# ELEMENT-WISE OPERATIONS\n-\n-\n-def max(x, axis=None, keepdims=False):\n-    \"\"\"Maximum value in a tensor.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to find maximum values. If `None` (default), finds the\n-            maximum over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with maximum values of `x`.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.reduce_max(x, axis, keepdims)\n-\n-\n-def min(x, axis=None, keepdims=False):\n-    \"\"\"Minimum value in a tensor.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to find minimum values. If `None` (default), finds the\n-            minimum over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with miminum values of `x`.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.reduce_min(x, axis, keepdims)\n-\n-\n-def sum(x, axis=None, keepdims=False):\n-    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to sum over. If `None` (default), sums over all\n-            dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with sum of `x`.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.reduce_sum(x, axis, keepdims)\n-\n-\n-def prod(x, axis=None, keepdims=False):\n-    \"\"\"Multiplies the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the product. If `None` (default), computes\n-            the product over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with the product of elements of `x`.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.reduce_prod(x, axis, keepdims)\n-\n-\n-def cumsum(x, axis=0):\n-    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer, the axis to compute the sum.\n-\n-    # Returns\n-        A tensor of the cumulative sum of values of `x` along `axis`.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf_math_ops.cumsum(x, axis=axis)\n-\n-\n-def cumprod(x, axis=0):\n-    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer, the axis to compute the product.\n-\n-    # Returns\n-        A tensor of the cumulative product of values of `x` along `axis`.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf_math_ops.cumprod(x, axis=axis)\n-\n-\n-def var(x, axis=None, keepdims=False):\n-    \"\"\"Variance of a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the variance. If `None` (default), computes\n-            the variance over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with the variance of elements of `x`.\n-    {{np_implementation}}\n-    \"\"\"\n-    if x.dtype.base_dtype == tf.bool:\n-        x = tf.cast(x, floatx())\n-    m = tf.reduce_mean(x, axis, True)\n-    devs_squared = tf.square(x - m)\n-    return tf.reduce_mean(devs_squared,\n-                          axis,\n-                          keepdims)\n-\n-\n-def std(x, axis=None, keepdims=False):\n-    \"\"\"Standard deviation of a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the standard deviation. If `None` (default),\n-            computes the standard deviation over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`,\n-            the reduced dimension is retained with length 1.\n-\n-    # Returns\n-        A tensor with the standard deviation of elements of `x`.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.sqrt(var(x, axis=axis, keepdims=keepdims))\n-\n-\n-def mean(x, axis=None, keepdims=False):\n-    \"\"\"Mean of a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the mean. If `None` (default), computes\n-            the mean over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1 for each entry in `axis`. If `keepdims` is `True`,\n-            the reduced dimensions are retained with length 1.\n-\n-    # Returns\n-        A tensor with the mean of elements of `x`.\n-    {{np_implementation}}\n-    \"\"\"\n-    if x.dtype.base_dtype == tf.bool:\n-        x = tf.cast(x, floatx())\n-    return tf.reduce_mean(x, axis, keepdims)\n-\n-\n-def any(x, axis=None, keepdims=False):\n-    \"\"\"Bitwise reduction (logical OR).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the logical or. If `None` (default), computes\n-            the logical or over all dimensions.\n-        keepdims: whether the drop or broadcast the reduction axes.\n-\n-    # Returns\n-        A uint8 tensor (0s and 1s).\n-    {{np_implementation}}\n-    \"\"\"\n-    x = tf.cast(x, tf.bool)\n-    return tf.reduce_any(x, axis, keepdims)\n-\n-\n-def all(x, axis=None, keepdims=False):\n-    \"\"\"Bitwise reduction (logical AND).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the logical and. If `None` (default), computes\n-            the logical and over all dimensions.\n-        keepdims: whether the drop or broadcast the reduction axes.\n-\n-    # Returns\n-        A uint8 tensor (0s and 1s).\n-    {{np_implementation}}\n-    \"\"\"\n-    x = tf.cast(x, tf.bool)\n-    return tf.reduce_all(x, axis, keepdims)\n-\n-\n-def argmax(x, axis=-1):\n-    \"\"\"Returns the index of the maximum value along an axis.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        axis: axis along which to perform the reduction.\n-\n-    # Returns\n-        A tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.argmax(x, axis)\n-\n-\n-def argmin(x, axis=-1):\n-    \"\"\"Returns the index of the minimum value along an axis.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        axis: axis along which to perform the reduction.\n-\n-    # Returns\n-        A tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.argmin(x, axis)\n-\n-\n-def square(x):\n-    \"\"\"Element-wise square.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.square(x)\n-\n-\n-def abs(x):\n-    \"\"\"Element-wise absolute value.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.abs(x)\n-\n-\n-def sqrt(x):\n-    \"\"\"Element-wise square root.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    zero = _to_tensor(0., x.dtype.base_dtype)\n-    inf = _to_tensor(np.inf, x.dtype.base_dtype)\n-    x = tf.clip_by_value(x, zero, inf)\n-    return tf.sqrt(x)\n-\n-\n-def exp(x):\n-    \"\"\"Element-wise exponential.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.exp(x)\n-\n-\n-def log(x):\n-    \"\"\"Element-wise log.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf_math_ops.log(x)\n-\n-\n-def logsumexp(x, axis=None, keepdims=False):\n-    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n-\n-    This function is more numerically stable than log(sum(exp(x))).\n-    It avoids overflows caused by taking the exp of large inputs and\n-    underflows caused by taking the log of small inputs.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: axis: An integer or list of integers in [-rank(x), rank(x)),\n-            the axes to compute the logsumexp. If `None` (default), computes\n-            the logsumexp over all dimensions.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`, the reduced dimension is\n-            retained with length 1.\n-\n-    # Returns\n-        The reduced tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.reduce_logsumexp(x, axis, keepdims)\n-\n-\n-def round(x):\n-    \"\"\"Element-wise rounding to the closest integer.\n-\n-    In case of tie, the rounding mode used is \"half to even\".\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.round(x)\n-\n-\n-def sign(x):\n-    \"\"\"Element-wise sign.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.sign(x)\n-\n-\n-def pow(x, a):\n-    \"\"\"Element-wise exponentiation.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        a: Python integer.\n-\n-    # Returns\n-        A tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.pow(x, a)\n-\n-\n-def clip(x, min_value, max_value):\n-    \"\"\"Element-wise value clipping.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        min_value: Python float, integer or tensor.\n-        max_value: Python float, integer or tensor.\n-\n-    # Returns\n-        A tensor.\n-    {{np_implementation}}\n-    \"\"\"\n-    if (isinstance(min_value, (int, float)) and\n-            isinstance(max_value, (int, float))):\n-        if max_value < min_value:\n-            max_value = min_value\n-    if min_value is None:\n-        min_value = -np.inf\n-    if max_value is None:\n-        max_value = np.inf\n-    return tf.clip_by_value(x, min_value, max_value)\n-\n-\n-def equal(x, y):\n-    \"\"\"Element-wise equality between two tensors.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.equal(x, y)\n-\n-\n-def not_equal(x, y):\n-    \"\"\"Element-wise inequality between two tensors.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.not_equal(x, y)\n-\n-\n-def greater(x, y):\n-    \"\"\"Element-wise truth value of (x > y).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.greater(x, y)\n-\n-\n-def greater_equal(x, y):\n-    \"\"\"Element-wise truth value of (x >= y).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.greater_equal(x, y)\n-\n-\n-def less(x, y):\n-    \"\"\"Element-wise truth value of (x < y).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.less(x, y)\n-\n-\n-def less_equal(x, y):\n-    \"\"\"Element-wise truth value of (x <= y).\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A bool tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.less_equal(x, y)\n-\n-\n-def maximum(x, y):\n-    \"\"\"Element-wise maximum of two tensors.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.maximum(x, y)\n-\n-\n-def minimum(x, y):\n-    \"\"\"Element-wise minimum of two tensors.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        y: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.minimum(x, y)\n-\n-\n-def sin(x):\n-    \"\"\"Computes sin of x element-wise.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.sin(x)\n-\n-\n-def cos(x):\n-    \"\"\"Computes cos of x element-wise.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.cos(x)\n-\n-\n-def _regular_normalize_batch_in_training(x, gamma, beta,\n-                                         reduction_axes, epsilon=1e-3):\n-    \"\"\"Non-fused version of `normalize_batch_in_training`.\n-\n-    # Arguments\n-        x: Input tensor or variable.\n-        gamma: Tensor by which to scale the input.\n-        beta: Tensor with which to center the input.\n-        reduction_axes: iterable of integers,\n-            axes over which to normalize.\n-        epsilon: Fuzz factor.\n-\n-    # Returns\n-        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n-    \"\"\"\n-    mean, var = tf.nn.moments(x, reduction_axes,\n-                              None, None, False)\n-    normed = tf.nn.batch_normalization(x, mean, var,\n-                                       beta, gamma,\n-                                       epsilon)\n-    return normed, mean, var\n-\n-\n-def _broadcast_normalize_batch_in_training(x, gamma, beta,\n-                                           reduction_axes, epsilon=1e-3):\n-    \"\"\"Non-fused, broadcast version of `normalize_batch_in_training`.\n-\n-    # Arguments\n-        x: Input tensor or variable.\n-        gamma: Tensor by which to scale the input.\n-        beta: Tensor with which to center the input.\n-        reduction_axes: iterable of integers,\n-            axes over which to normalize.\n-        epsilon: Fuzz factor.\n-\n-    # Returns\n-        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n-    \"\"\"\n-    mean, var = tf.nn.moments(x, reduction_axes,\n-                              None, None, False)\n-    target_shape = []\n-    for axis in range(ndim(x)):\n-        if axis in reduction_axes:\n-            target_shape.append(1)\n-        else:\n-            target_shape.append(tf.shape(x)[axis])\n-    target_shape = tf.stack(target_shape)\n-\n-    broadcast_mean = tf.reshape(mean, target_shape)\n-    broadcast_var = tf.reshape(var, target_shape)\n-    if gamma is None:\n-        broadcast_gamma = None\n-    else:\n-        broadcast_gamma = tf.reshape(gamma, target_shape)\n-    if beta is None:\n-        broadcast_beta = None\n-    else:\n-        broadcast_beta = tf.reshape(beta, target_shape)\n-\n-    normed = tf.nn.batch_normalization(\n-        x,\n-        broadcast_mean,\n-        broadcast_var,\n-        broadcast_beta,\n-        broadcast_gamma,\n-        epsilon)\n-    return normed, mean, var\n-\n-\n-def _fused_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n-                                       epsilon=1e-3):\n-    \"\"\"Fused version of `normalize_batch_in_training`.\n-\n-    # Arguments\n-        x: Input tensor or variable.\n-        gamma: Tensor by which to scale the input.\n-        beta: Tensor with which to center the input.\n-        reduction_axes: iterable of integers,\n-            axes over which to normalize.\n-        epsilon: Fuzz factor.\n-\n-    # Returns\n-        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n-    \"\"\"\n-    if list(reduction_axes) == [0, 1, 2]:\n-        normalization_axis = 3\n-        tf_data_format = 'NHWC'\n-    else:\n-        normalization_axis = 1\n-        tf_data_format = 'NCHW'\n-\n-    if gamma is None:\n-        gamma = tf.constant(1.0,\n-                            dtype=x.dtype,\n-                            shape=[x.shape[normalization_axis]])\n-    if beta is None:\n-        beta = tf.constant(0.0,\n-                           dtype=x.dtype,\n-                           shape=[x.shape[normalization_axis]])\n-\n-    if gamma.dtype != tf.float32:\n-        gamma = tf.cast(gamma, tf.float32)\n-    if beta.dtype != tf.float32:\n-        beta = tf.cast(beta, tf.float32)\n-\n-    if _has_compat_v1:\n-        fused_batch_norm = tf.compat.v1.nn.fused_batch_norm\n-    else:\n-        fused_batch_norm = tf.nn.fused_batch_norm\n-    return fused_batch_norm(\n-        x,\n-        gamma,\n-        beta,\n-        epsilon=epsilon,\n-        data_format=tf_data_format)\n-\n-\n-def normalize_batch_in_training(x, gamma, beta,\n-                                reduction_axes, epsilon=1e-3):\n-    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n-\n-    # Arguments\n-        x: Input tensor or variable.\n-        gamma: Tensor by which to scale the input.\n-        beta: Tensor with which to center the input.\n-        reduction_axes: iterable of integers,\n-            axes over which to normalize.\n-        epsilon: Fuzz factor.\n-\n-    # Returns\n-        A tuple length of 3, `(normalized_tensor, mean, variance)`.\n-    \"\"\"\n-    if (ndim(x) == 4 and\n-            list(reduction_axes) in [[0, 1, 2], [0, 2, 3]] and\n-            _is_tf_1()):\n-        if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\n-            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n-                                                          reduction_axes,\n-                                                          epsilon=epsilon)\n-        return _fused_normalize_batch_in_training(\n-            x, gamma, beta, reduction_axes,\n-            epsilon=epsilon)\n-    else:\n-        if sorted(reduction_axes) == list(range(ndim(x)))[:-1]:\n-            return _regular_normalize_batch_in_training(x, gamma, beta,\n-                                                        reduction_axes,\n-                                                        epsilon=epsilon)\n-        else:\n-            return _broadcast_normalize_batch_in_training(x, gamma, beta,\n-                                                          reduction_axes,\n-                                                          epsilon=epsilon)\n-\n-\n-def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n-    \"\"\"Applies batch normalization on x given mean, var, beta and gamma.\n-\n-    I.e. returns:\n-    `output = (x - mean) / sqrt(var + epsilon) * gamma + beta`\n-\n-    # Arguments\n-        x: Input tensor or variable.\n-        mean: Mean of batch.\n-        var: Variance of batch.\n-        beta: Tensor with which to center the input.\n-        gamma: Tensor by which to scale the input.\n-        axis: Integer, the axis that should be normalized.\n-            (typically the features axis).\n-        epsilon: Fuzz factor.\n-\n-    # Returns\n-        A tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    if ndim(x) == 4:\n-        # The CPU implementation of FusedBatchNorm only support NHWC\n-        if axis == 1 or axis == -3:\n-            tf_data_format = 'NCHW'\n-        elif axis == 3 or axis == -1:\n-            tf_data_format = 'NHWC'\n-        else:\n-            tf_data_format = None\n-\n-        if ((tf_data_format == 'NHWC' or\n-                (tf_data_format == 'NCHW' and\n-                 _has_nchw_support())) and\n-                _is_tf_1()):\n-            # The mean / var / beta / gamma may be processed by broadcast\n-            # so it may have extra axes with 1,\n-            # it is not needed and should be removed\n-            if ndim(mean) > 1:\n-                mean = tf.reshape(mean, [-1])\n-            if ndim(var) > 1:\n-                var = tf.reshape(var, [-1])\n-            if beta is None:\n-                beta = zeros_like(mean)\n-            elif ndim(beta) > 1:\n-                beta = tf.reshape(beta, [-1])\n-            if gamma is None:\n-                gamma = ones_like(mean)\n-            elif ndim(gamma) > 1:\n-                gamma = tf.reshape(gamma, [-1])\n-\n-            if gamma.dtype != tf.float32:\n-                gamma = tf.cast(gamma, tf.float32)\n-            if beta.dtype != tf.float32:\n-                beta = tf.cast(beta, tf.float32)\n-            if mean.dtype != tf.float32:\n-                mean = tf.cast(mean, tf.float32)\n-            if var.dtype != tf.float32:\n-                var = tf.cast(var, tf.float32)\n-\n-            if _has_compat_v1:\n-                fused_batch_norm = tf.compat.v1.nn.fused_batch_norm\n-            else:\n-                fused_batch_norm = tf.nn.fused_batch_norm\n-\n-            y, _, _ = fused_batch_norm(\n-                x,\n-                gamma,\n-                beta,\n-                epsilon=epsilon,\n-                mean=mean,\n-                variance=var,\n-                data_format=tf_data_format,\n-                is_training=False\n-            )\n-            return y\n-    # default\n-    return tf.nn.batch_normalization(x, mean, var, beta, gamma, epsilon)\n-\n-\n-# SHAPE OPERATIONS\n-\n-def concatenate(tensors, axis=-1):\n-    \"\"\"Concatenates a list of tensors alongside the specified axis.\n-\n-    # Arguments\n-        tensors: list of tensors to concatenate.\n-        axis: concatenation axis.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    if axis < 0:\n-        rank = ndim(tensors[0])\n-        if rank:\n-            axis %= rank\n-        else:\n-            axis = 0\n-    if py_all([is_sparse(x) for x in tensors]):\n-        return tf.sparse.concat(axis, tensors)\n-    else:\n-        return tf.concat([to_dense(x) for x in tensors], axis)\n-\n-\n-def reshape(x, shape):\n-    \"\"\"Reshapes a tensor to the specified shape.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        shape: Target shape tuple.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.reshape(x, shape)\n-\n-\n-def permute_dimensions(x, pattern):\n-    \"\"\"Permutes axes in a tensor.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        pattern: A tuple of\n-            dimension indices, e.g. `(0, 2, 1)`.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    return tf.transpose(x, perm=pattern)\n-\n-\n-def resize_images(x,\n-                  height_factor,\n-                  width_factor,\n-                  data_format,\n-                  interpolation='nearest'):\n-    \"\"\"Resizes the images contained in a 4D tensor.\n-\n-    # Arguments\n-        x: Tensor or variable to resize.\n-        height_factor: Positive integer.\n-        width_factor: Positive integer.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-        interpolation: A string, one of `nearest` or `bilinear`.\n-\n-    # Returns\n-        A tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is\n-        neither `\"channels_last\"` or `\"channels_first\"`.\n-    \"\"\"\n-    if data_format == 'channels_first':\n-        rows, cols = 2, 3\n-    else:\n-        rows, cols = 1, 2\n-\n-    original_shape = int_shape(x)\n-    new_shape = tf.shape(x)[rows:cols + 1]\n-    new_shape *= tf.constant(np.array([height_factor, width_factor],\n-                             dtype='int32'))\n-    if data_format == 'channels_first':\n-        x = permute_dimensions(x, [0, 2, 3, 1])\n-    if interpolation == 'nearest':\n-        x = tf_image_ops.resize_nearest_neighbor(x, new_shape)\n-    elif interpolation == 'bilinear':\n-        x = tf_image_ops.resize_bilinear(x, new_shape)\n-    else:\n-        raise ValueError('interpolation should be one '\n-                         'of \"nearest\" or \"bilinear\".')\n-    if data_format == 'channels_first':\n-        x = permute_dimensions(x, [0, 3, 1, 2])\n-\n-    if original_shape[rows] is None:\n-        new_height = None\n-    else:\n-        new_height = original_shape[rows] * height_factor\n-\n-    if original_shape[cols] is None:\n-        new_width = None\n-    else:\n-        new_width = original_shape[cols] * width_factor\n-\n-    output_shape = (None, new_height, new_width, None)\n-    x.set_shape(transpose_shape(output_shape, data_format,\n-                                spatial_axes=(1, 2)))\n-    return x\n-\n-\n-def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n-    \"\"\"Resizes the volume contained in a 5D tensor.\n-\n-    # Arguments\n-        x: Tensor or variable to resize.\n-        depth_factor: Positive integer.\n-        height_factor: Positive integer.\n-        width_factor: Positive integer.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-\n-    # Returns\n-        A tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is\n-        neither `\"channels_last\"` or `\"channels_first\"`.\n-    \"\"\"\n-    if data_format == 'channels_first':\n-        output = repeat_elements(x, depth_factor, axis=2)\n-        output = repeat_elements(output, height_factor, axis=3)\n-        output = repeat_elements(output, width_factor, axis=4)\n-        return output\n-    elif data_format == 'channels_last':\n-        output = repeat_elements(x, depth_factor, axis=1)\n-        output = repeat_elements(output, height_factor, axis=2)\n-        output = repeat_elements(output, width_factor, axis=3)\n-        return output\n-    else:\n-        raise ValueError('Unknown data_format: ' + str(data_format))\n-\n-\n-def repeat_elements(x, rep, axis):\n-    \"\"\"Repeats the elements of a tensor along an axis, like `np.repeat`.\n-\n-    If `x` has shape `(s1, s2, s3)` and `axis` is `1`, the output\n-    will have shape `(s1, s2 * rep, s3)`.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        rep: Python integer, number of times to repeat.\n-        axis: Axis along which to repeat.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    x_shape = x.shape.as_list()\n-    # For static axis\n-    if x_shape[axis] is not None:\n-        # slices along the repeat axis\n-        splits = tf.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)\n-        # repeat each slice the given number of reps\n-        x_rep = [s for s in splits for _ in range(rep)]\n-        return concatenate(x_rep, axis)\n-\n-    # Here we use tf.tile to mimic behavior of np.repeat so that\n-    # we can handle dynamic shapes (that include None).\n-    # To do that, we need an auxiliary axis to repeat elements along\n-    # it and then merge them along the desired axis.\n-\n-    # Repeating\n-    auxiliary_axis = axis + 1\n-    x_shape = tf.shape(x)\n-    x_rep = tf.expand_dims(x, axis=auxiliary_axis)\n-    reps = np.ones(len(x.shape) + 1)\n-    reps[auxiliary_axis] = rep\n-    x_rep = tf.tile(x_rep, reps)\n-\n-    # Merging\n-    reps = np.delete(reps, auxiliary_axis)\n-    reps[axis] = rep\n-    reps = tf.constant(reps, dtype='int32')\n-    x_shape = x_shape * reps\n-    x_rep = tf.reshape(x_rep, x_shape)\n-\n-    # Fix shape representation\n-    x_shape = x.shape.as_list()\n-    x_rep.set_shape(x_shape)\n-    x_rep._keras_shape = tuple(x_shape)\n-    return x_rep\n-\n-\n-def repeat(x, n):\n-    \"\"\"Repeats a 2D tensor.\n-\n-    if `x` has shape (samples, dim) and `n` is `2`,\n-    the output will have shape `(samples, 2, dim)`.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        n: Python integer, number of times to repeat.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    assert ndim(x) == 2\n-    x = tf.expand_dims(x, 1)\n-    pattern = tf.stack([1, n, 1])\n-    return tf.tile(x, pattern)\n-\n-\n-def arange(start, stop=None, step=1, dtype='int32'):\n-    \"\"\"Creates a 1D tensor containing a sequence of integers.\n-\n-    The function arguments use the same convention as\n-    Theano's arange: if only one argument is provided,\n-    it is in fact the \"stop\" argument and \"start\" is 0.\n-\n-    The default type of the returned tensor is `'int32'` to\n-    match TensorFlow's default.\n-\n-    # Arguments\n-        start: Start value.\n-        stop: Stop value.\n-        step: Difference between two successive values.\n-        dtype: Integer dtype to use.\n-\n-    # Returns\n-        An integer tensor.\n-\n-    \"\"\"\n-    # Match the behavior of numpy and Theano by returning an empty sequence.\n-    if stop is None:\n-        try:\n-            if start < 0:\n-                start = 0\n-        except TypeError:\n-            # Handle case where start is a tensor\n-            start = tf.cond(start < 0,\n-                            true_fn=lambda: tf.constant(0, dtype=start.dtype),\n-                            false_fn=lambda: start)\n-\n-    result = tf.range(start, limit=stop, delta=step, name='arange')\n-    if dtype != 'int32':\n-        result = cast(result, dtype)\n-    return result\n-\n-\n-def tile(x, n):\n-    \"\"\"Creates a tensor by tiling `x` by `n`.\n-\n-    # Arguments\n-        x: A tensor or variable\n-        n: A list of integer. The length must be the same as the number of\n-            dimensions in `x`.\n-\n-    # Returns\n-        A tiled tensor.\n-\n-    # Example\n-    ```python\n-        >>> from keras import backend as K\n-        >>> kvar = K.variable(np.random.random((2, 3)))\n-        >>> kvar_tile = K.tile(K.eye(2), (2, 3))\n-        >>> K.eval(kvar_tile)\n-        array([[1., 0., 1., 0., 1., 0.],\n-               [0., 1., 0., 1., 0., 1.],\n-               [1., 0., 1., 0., 1., 0.],\n-               [0., 1., 0., 1., 0., 1.]], dtype=float32)\n-    ```\n-    {{np_implementation}}\n-    \"\"\"\n-    if isinstance(n, int):\n-        n = (n,)\n-    elif isinstance(n, list):\n-        n = tuple(n)\n-\n-    shape = int_shape(x)\n-    if not is_tensor(n):\n-        if len(n) < len(shape):  # Padding the axis\n-            n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n-        elif len(n) != len(shape):\n-            raise NotImplementedError\n-\n-    return tf.tile(x, n)\n-\n-\n-def flatten(x):\n-    \"\"\"Flatten a tensor.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-\n-    # Returns\n-        A tensor, reshaped into 1-D\n-    \"\"\"\n-    return tf.reshape(x, [-1])\n-\n-\n-def batch_flatten(x):\n-    \"\"\"Turn a nD tensor into a 2D tensor with same 0th dimension.\n-\n-    In other words, it flattens each data samples of a batch.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-\n-    # Returns\n-        A tensor.\n-    \"\"\"\n-    x = tf.reshape(\n-        x, tf.stack([-1, prod(shape(x)[1:])],\n-                    name='stack_' + str(np.random.randint(1e4))))\n-    return x\n-\n-\n-def expand_dims(x, axis=-1):\n-    \"\"\"Adds a 1-sized dimension at index \"axis\".\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: Position where to add a new axis.\n-\n-    # Returns\n-        A tensor with expanded dimensions.\n-    \"\"\"\n-    return tf.expand_dims(x, axis)\n-\n-\n-def squeeze(x, axis):\n-    \"\"\"Removes a 1-dimension from the tensor at index \"axis\".\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: Axis to drop.\n-\n-    # Returns\n-        A tensor with the same data as `x` but reduced dimensions.\n-    \"\"\"\n-    return tf.squeeze(x, [axis])\n-\n-\n-def temporal_padding(x, padding=(1, 1)):\n-    \"\"\"Pads the middle dimension of a 3D tensor.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        padding: Tuple of 2 integers, how many zeros to\n-            add at the start and end of dim 1.\n-\n-    # Returns\n-        A padded 3D tensor.\n-    \"\"\"\n-    assert len(padding) == 2\n-    pattern = [[0, 0], [padding[0], padding[1]], [0, 0]]\n-    return tf.pad(x, pattern)\n-\n-\n-def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n-    \"\"\"Pads the 2nd and 3rd dimensions of a 4D tensor.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        padding: Tuple of 2 tuples, padding pattern.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-\n-    # Returns\n-        A padded 4D tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is\n-        neither `\"channels_last\"` or `\"channels_first\"`.\n-    \"\"\"\n-    assert len(padding) == 2\n-    assert len(padding[0]) == 2\n-    assert len(padding[1]) == 2\n-    data_format = normalize_data_format(data_format)\n-\n-    pattern = [[0, 0],\n-               list(padding[0]),\n-               list(padding[1]),\n-               [0, 0]]\n-    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2))\n-    return tf.pad(x, pattern)\n-\n-\n-def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n-    \"\"\"Pads 5D tensor with zeros along the depth, height, width dimensions.\n-\n-    Pads these dimensions with respectively\n-    \"padding[0]\", \"padding[1]\" and \"padding[2]\" zeros left and right.\n-\n-    For 'channels_last' data_format,\n-    the 2nd, 3rd and 4th dimension will be padded.\n-    For 'channels_first' data_format,\n-    the 3rd, 4th and 5th dimension will be padded.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-        padding: Tuple of 3 tuples, padding pattern.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-\n-    # Returns\n-        A padded 5D tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is\n-        neither `\"channels_last\"` or `\"channels_first\"`.\n-\n-    \"\"\"\n-    assert len(padding) == 3\n-    assert len(padding[0]) == 2\n-    assert len(padding[1]) == 2\n-    assert len(padding[2]) == 2\n-    data_format = normalize_data_format(data_format)\n-\n-    pattern = [\n-        [0, 0],\n-        [padding[0][0], padding[0][1]],\n-        [padding[1][0], padding[1][1]],\n-        [padding[2][0], padding[2][1]],\n-        [0, 0]\n-    ]\n-    pattern = transpose_shape(pattern, data_format, spatial_axes=(1, 2, 3))\n-\n-    return tf.pad(x, pattern)\n-\n-\n-def stack(x, axis=0):\n-    \"\"\"Stacks a list of rank `R` tensors into a rank `R+1` tensor.\n-\n-    # Arguments\n-        x: List of tensors.\n-        axis: Axis along which to perform stacking.\n-\n-    # Returns\n-        A tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    return tf.stack(x, axis=axis)\n-\n-\n-def one_hot(indices, num_classes):\n-    \"\"\"Computes the one-hot representation of an integer tensor.\n-\n-    # Arguments\n-        indices: nD integer tensor of shape\n-            `(batch_size, dim1, dim2, ... dim(n-1))`\n-        num_classes: Integer, number of classes to consider.\n-\n-    # Returns\n-        (n + 1)D one hot representation of the input\n-        with shape `(batch_size, dim1, dim2, ... dim(n-1), num_classes)`\n-    \"\"\"\n-    return tf.one_hot(indices, depth=num_classes, axis=-1)\n-\n-\n-def reverse(x, axes):\n-    \"\"\"Reverses a tensor along the specified axes.\n-\n-    # Arguments\n-        x: Tensor to reverse.\n-        axes: Integer or iterable of integers.\n-            Axes to reverse.\n-\n-    # Returns\n-        A tensor.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    if isinstance(axes, int):\n-        axes = [axes]\n-    return tf.reverse(x, axes)\n-\n-\n-def slice(x, start, size):\n-    \"\"\"Extracts a slice from a tensor.\n-\n-    # Arguments\n-        x: Input tensor.\n-        start: Integer list/tuple or tensor\n-            indicating the start indices of the slice\n-            along each axis.\n-        size: Integer list/tuple or tensor\n-            indicating how many dimensions to slice\n-            along each axis.\n-\n-    # Returns\n-        A sliced tensor:\n-        ```python\n-        new_x = x[start[0]: start[0] + size[0], ..., start[-1]: start[-1] + size[-1]]\n-        ```\n-\n-    # Raises\n-        ValueError: if the dimension and the size of indices mismatches.\n-\n-    {{np_implementation}}\n-    \"\"\"\n-    x_shape = int_shape(x)\n-    if (x_shape is not None) and (x_shape[0] is not None):\n-        len_start = int_shape(start)[0] if is_tensor(start) else len(start)\n-        len_size = int_shape(size)[0] if is_tensor(size) else len(size)\n-        if not (len(int_shape(x)) == len_start == len_size):\n-            raise ValueError('The dimension and the size of indices should match.')\n-    return tf.slice(x, start, size)\n-\n-\n-# VALUE MANIPULATION\n-\n-\n-def get_value(x):\n-    \"\"\"Returns the value of a variable.\n-\n-    # Arguments\n-        x: input variable.\n-\n-    # Returns\n-        A Numpy array.\n-    \"\"\"\n-    if _is_tf_1():\n-        return x.eval(session=get_session())\n-    else:\n-        return x.numpy()\n-\n-\n-def batch_get_value(ops):\n-    \"\"\"Returns the value of more than one tensor variable.\n-\n-    # Arguments\n-        ops: list of ops to run.\n-\n-    # Returns\n-        A list of Numpy arrays.\n-    \"\"\"\n-    return tf_keras_backend.batch_get_value(ops)\n-\n-\n-def set_value(x, value):\n-    \"\"\"Sets the value of a variable, from a Numpy array.\n-\n-    # Arguments\n-        x: Variable to set to a new value.\n-        value: Value to set the tensor to, as a Numpy array\n-            (of the same shape).\n-    \"\"\"\n-    tf_keras_backend.set_value(x, value)\n-\n-\n-def batch_set_value(tuples):\n-    \"\"\"Sets the values of many tensor variables at once.\n-\n-    # Arguments\n-        tuples: a list of tuples `(tensor, value)`.\n-            `value` should be a Numpy array.\n-    \"\"\"\n-    tf_keras_backend.batch_set_value(tuples)\n-\n-\n-def get_variable_shape(x):\n-    \"\"\"Returns the shape of a variable.\n-\n-    # Arguments\n-        x: A variable.\n-\n-    # Returns\n-        A tuple of integers.\n-    \"\"\"\n-    return int_shape(x)\n-\n-\n-@symbolic\n-def print_tensor(x, message=''):\n-    \"\"\"Prints `message` and the tensor value when evaluated.\n-\n-    Note that `print_tensor` returns a new tensor identical to `x`\n-    which should be used in the following code. Otherwise the\n-    print operation is not taken into account during evaluation.\n-\n-    # Example\n-\n-    ```python\n-        >>> x = K.print_tensor(x, message=\"x is: \")\n-    ```\n-\n-    # Arguments\n-        x: Tensor to print.\n-        message: Message to print jointly with the tensor.\n-\n-    # Returns\n-        The same tensor `x`, unchanged.\n-    \"\"\"\n-    op = tf.print(message, x, output_stream=sys.stdout)\n-    with tf.control_dependencies([op]):\n-        return tf.identity(x)\n-\n@@ -1,2994 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from collections import defaultdict\n-from contextlib import contextmanager\n-import theano\n-from theano import tensor as T\n-from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n-from theano.tensor.signal import pool\n-from theano.printing import Print\n-from theano.ifelse import ifelse\n-try:\n-    import theano.sparse as th_sparse_module\n-except ImportError:\n-    th_sparse_module = None\n-try:\n-    from theano.tensor.nnet.nnet import softsign as T_softsign\n-except ImportError:\n-    from theano.sandbox.softsign import softsign as T_softsign\n-\n-import numpy as np\n-from .common import floatx\n-from .common import epsilon\n-from .common import normalize_data_format\n-from ..utils.generic_utils import transpose_shape\n-from ..utils.generic_utils import has_arg\n-# Legacy functions\n-from .common import set_image_dim_ordering, image_dim_ordering\n-\n-py_all = all\n-py_any = any\n-py_sum = sum\n-py_slice = slice\n-\n-\n-# INTERNAL UTILS\n-theano.config.floatX = floatx()\n-# 0 = test, 1 = train\n-_LEARNING_PHASE = T.scalar(dtype='uint8', name='keras_learning_phase')\n-_UID_PREFIXES = defaultdict(int)\n-\n-\n-def learning_phase():\n-    # False = test, True = train\n-    return _LEARNING_PHASE\n-\n-\n-def set_learning_phase(value):\n-    global _LEARNING_PHASE\n-    if value not in {0, 1}:\n-        raise ValueError('Expected learning phase to be '\n-                         '0 or 1.')\n-    _LEARNING_PHASE = value\n-\n-\n-def get_uid(prefix=''):\n-    \"\"\"Provides a unique UID given a string prefix.\n-\n-    # Arguments\n-        prefix: string.\n-\n-    # Returns\n-        An integer.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.get_uid('dense')\n-        1\n-        >>> keras.backend.get_uid('dense')\n-        2\n-    ```\n-\n-    \"\"\"\n-    _UID_PREFIXES[prefix] += 1\n-    return _UID_PREFIXES[prefix]\n-\n-\n-def reset_uids():\n-    global _UID_PREFIXES\n-    _UID_PREFIXES = defaultdict(int)\n-\n-\n-# VARIABLE MANIPULATION\n-\n-\n-def _assert_sparse_module():\n-    if not th_sparse_module:\n-        raise ImportError(\"Failed to import theano.sparse\\n\"\n-                          \"You probably need to pip install nose-parameterized\")\n-\n-\n-def is_sparse(tensor):\n-    return th_sparse_module and isinstance(tensor.type, th_sparse_module.SparseType)\n-\n-\n-def to_dense(tensor):\n-    if is_sparse(tensor):\n-        return th_sparse_module.dense_from_sparse(tensor)\n-    else:\n-        return tensor\n-\n-\n-NAME_SCOPE_STACK = []\n-\n-\n-@contextmanager\n-def name_scope(name):\n-    global NAME_SCOPE_STACK\n-    NAME_SCOPE_STACK.append(name)\n-    yield\n-    NAME_SCOPE_STACK.pop()\n-\n-\n-def _prepare_name(name, default):\n-    prefix = '/'.join(NAME_SCOPE_STACK)\n-    if name is None:\n-        return prefix + '/' + default\n-    return prefix + '/' + name\n-\n-\n-def variable(value, dtype=None, name=None, constraint=None):\n-    \"\"\"Instantiates a variable and returns it.\n-\n-    # Arguments\n-        value: Numpy array, initial value of the tensor.\n-        dtype: Tensor type.\n-        name: Optional name string for the tensor.\n-        constraint: Optional projection function to be\n-            applied to the variable after an optimizer update.\n-\n-    # Returns\n-        A variable instance (with Keras metadata included).\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if hasattr(value, 'tocoo'):\n-        _assert_sparse_module()\n-        variable = th_sparse_module.as_sparse_variable(\n-            value, name=_prepare_name(name, 'variable'))\n-    else:\n-        if isinstance(value, (theano.tensor.TensorVariable,\n-                              theano.tensor.sharedvar.TensorSharedVariable,\n-                              theano.tensor.TensorConstant)):\n-            # Support for RandomStreams().normal(), .uniform().\n-            value = value.eval()\n-        value = np.asarray(value, dtype=dtype)\n-        variable = theano.shared(value=value,\n-                                 name=_prepare_name(name, 'variable'),\n-                                 strict=False)\n-    variable._keras_shape = value.shape\n-    variable._uses_learning_phase = False\n-    variable.constraint = constraint\n-    return variable\n-\n-\n-def is_variable(x):\n-    return isinstance(x, theano.tensor.sharedvar.TensorSharedVariable)\n-\n-\n-def constant(value, dtype=None, shape=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if shape is None:\n-        shape = ()\n-    if not is_tensor(value):\n-        value = np.array(value)\n-        if len(value.shape) == 0:\n-            value = value * np.ones(shape)\n-        if shape and value.shape != shape:\n-            value = np.reshape(value, shape)\n-    const = T.constant(value,\n-                       dtype=dtype,\n-                       name=_prepare_name(name, 'constant'))\n-    const._keras_shape = shape\n-    const._uses_learning_phase = False\n-    return const\n-\n-\n-def is_keras_tensor(x):\n-    \"\"\"Returns whether `x` is a Keras tensor.\n-\n-    A \"Keras tensor\" is a tensor that was returned by a Keras layer,\n-    (`Layer` class) or by `Input`.\n-\n-    # Arguments\n-        x: A candidate tensor.\n-\n-    # Returns\n-        A boolean: Whether the argument is a Keras tensor.\n-\n-    # Raises\n-        ValueError: In case `x` is not a symbolic tensor.\n-\n-    # Examples\n-    ```python\n-        >>> from keras import backend as K\n-        >>> from keras.layers import Input, Dense\n-        >>> np_var = numpy.array([1, 2])\n-        >>> K.is_keras_tensor(np_var) # A numpy array is not a symbolic tensor.\n-        ValueError\n-        >>> k_var = tf.placeholder('float32', shape=(1,1))\n-        >>> # A variable indirectly created outside of keras is not a Keras tensor.\n-        >>> K.is_keras_tensor(k_var)\n-        False\n-        >>> keras_var = K.variable(np_var)\n-        >>> # A variable created with the keras backend is not a Keras tensor.\n-        >>> K.is_keras_tensor(keras_var)\n-        False\n-        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n-        >>> # A placeholder is not a Keras tensor.\n-        >>> K.is_keras_tensor(keras_placeholder)\n-        False\n-        >>> keras_input = Input([10])\n-        >>> K.is_keras_tensor(keras_input) # An Input is a Keras tensor.\n-        True\n-        >>> keras_layer_output = Dense(10)(keras_input)\n-        >>> # Any Keras layer output is a Keras tensor.\n-        >>> K.is_keras_tensor(keras_layer_output)\n-        True\n-    ```\n-    \"\"\"\n-    if not is_tensor(x):\n-        raise ValueError('Unexpectedly found an instance of type `' +\n-                         str(type(x)) + '`. '\n-                         'Expected a symbolic tensor instance.')\n-    return hasattr(x, '_keras_history')\n-\n-\n-def is_tensor(x):\n-    return isinstance(x, (T.TensorVariable,\n-                          T.sharedvar.TensorSharedVariable,\n-                          T.TensorConstant))\n-\n-\n-def placeholder(shape=None, ndim=None, dtype=None, sparse=False, name=None):\n-    \"\"\"Instantiate an input data placeholder variable.\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if shape is None and ndim is None:\n-        raise ValueError('Specify either a shape or ndim value.')\n-    if shape is not None:\n-        ndim = len(shape)\n-    else:\n-        shape = tuple([None for _ in range(ndim)])\n-\n-    name = _prepare_name(name, 'placeholder')\n-    broadcast = (False,) * ndim\n-    if sparse:\n-        _assert_sparse_module()\n-        x = th_sparse_module.csr_matrix(name=name, dtype=dtype)\n-    else:\n-        x = T.TensorType(dtype, broadcast)(name)\n-    x._keras_shape = shape\n-    x._uses_learning_phase = False\n-    x._theano_placeholder = True\n-    return x\n-\n-\n-def is_placeholder(x):\n-    \"\"\"Returns whether `x` is a placeholder.\n-\n-    # Arguments\n-        x: A candidate placeholder.\n-\n-    # Returns\n-        Boolean.\n-    \"\"\"\n-    return hasattr(x, '_theano_placeholder') and x._theano_placeholder\n-\n-\n-def shape(x):\n-    \"\"\"Returns the shape of a tensor.\n-\n-    Warning: type returned will be different for\n-    Theano backend (Theano tensor type) and TF backend (TF TensorShape).\n-    \"\"\"\n-    return x.shape\n-\n-\n-def int_shape(x):\n-    \"\"\"Returns the shape of a Keras tensor or a Keras variable as a tuple of\n-    integers or None entries.\n-\n-    # Arguments\n-        x: Tensor or variable.\n-\n-    # Returns\n-        A tuple of integers (or None entries).\n-    \"\"\"\n-    if hasattr(x, '_keras_shape'):\n-        return x._keras_shape\n-    else:\n-        return None\n-\n-\n-def ndim(x):\n-    return x.ndim\n-\n-\n-def dtype(x):\n-    return x.dtype\n-\n-\n-def eval(x):\n-    \"\"\"Returns the value of a tensor.\n-    \"\"\"\n-    return to_dense(x).eval()\n-\n-\n-def zeros(shape, dtype=None, name=None):\n-    \"\"\"Instantiates an all-zeros variable.\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    return variable(np.zeros(shape), dtype, name)\n-\n-\n-def ones(shape, dtype=None, name=None):\n-    \"\"\"Instantiates an all-ones variable.\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    return variable(np.ones(shape), dtype, name)\n-\n-\n-def eye(size, dtype=None, name=None):\n-    \"\"\"Instantiates an identity matrix.\n-    \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    if isinstance(size, (list, tuple)):\n-        n, m = size\n-    else:\n-        n, m = size, size\n-    return variable(np.eye(n, m), dtype, name)\n-\n-\n-def ones_like(x, dtype=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    return T.ones_like(x, dtype=dtype)\n-\n-\n-def zeros_like(x, dtype=None, name=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    return T.zeros_like(x, dtype=dtype)\n-\n-\n-def identity(x, name=None):\n-    \"\"\"Returns a tensor with the same content as the input tensor.\n-\n-    # Arguments\n-        x: The input tensor.\n-        name: String, name for the variable to create.\n-\n-    # Returns\n-        A tensor of the same shape, type and content.\n-    \"\"\"\n-    return x.copy(name=name)\n-\n-\n-def random_uniform_variable(shape, low, high, dtype=None, name=None):\n-    return variable(np.random.uniform(low=low, high=high, size=shape),\n-                    dtype=dtype, name=name)\n-\n-\n-def random_normal_variable(shape, mean, scale, dtype=None, name=None):\n-    return variable(np.random.normal(loc=0.0, scale=scale, size=shape),\n-                    dtype=dtype, name=name)\n-\n-\n-def count_params(x):\n-    \"\"\"Returns the number of scalars in a tensor.\n-\n-    Return: numpy integer.\n-    \"\"\"\n-    # We don't want those compilation to show up in Theano profiler.\n-    f = theano.function([], x.shape, profile=False)\n-    return np.prod(f())\n-\n-\n-def cast(x, dtype):\n-    return T.cast(x, dtype)\n-\n-\n-def size(x, name=None):\n-    \"\"\"Returns the size of a tensor.\n-    # Arguments\n-        x: The input tensor.\n-        name: A name for the operation (optional).\n-    # Returns\n-        Size of the tensor.\n-    ```\n-    \"\"\"\n-    return sum(ones_like(x, name=name))\n-\n-\n-# UPDATES OPS\n-\n-\n-def update(x, new_x):\n-    return (x, new_x)\n-\n-\n-def update_add(x, increment):\n-    return (x, x + increment)\n-\n-\n-def update_sub(x, decrement):\n-    return (x, x - decrement)\n-\n-\n-def moving_average_update(variable, value, momentum):\n-    return (variable, variable * momentum + value * (1. - momentum))\n-\n-\n-# LINEAR ALGEBRA\n-\n-\"\"\"\n-Assumed overridden:\n-+, -, /, *, +=, -=, *=, /=\n-\"\"\"\n-\n-\n-def dot(x, y):\n-    if is_sparse(x):\n-        out = th_sparse_module.basic.structured_dot(x, y)\n-    else:\n-        out = T.dot(x, y)\n-    if hasattr(x, '_keras_shape') and hasattr(y, '_keras_shape'):\n-        x_shape = list(x._keras_shape)\n-        y_shape = list(y._keras_shape)\n-        if len(x_shape) > 0:\n-            x_shape.pop()\n-        if len(y_shape) == 1:\n-            y_shape.pop()\n-        elif len(y_shape) > 1:\n-            y_shape.pop(-2)\n-        out._keras_shape = tuple(x_shape + y_shape)\n-    return out\n-\n-\n-def batch_dot(x, y, axes=None):\n-    \"\"\"Batchwise dot product.\n-\n-    batch_dot results in a tensor with less dimensions than the input.\n-    If the number of dimensions is reduced to 1, we use `expand_dims` to\n-    make sure that ndim is at least 2.\n-\n-    # Arguments\n-        x, y: tensors with ndim >= 2\n-        axes: list (or single) int with target dimensions\n-\n-    # Returns\n-        A tensor with shape equal to the concatenation of x's shape\n-        (less the dimension that was summed over) and y's shape\n-        (less the batch dimension and the dimension that was summed over).\n-        If the final rank is 1, we reshape it to (batch_size, 1).\n-\n-    # Examples\n-        Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]\n-        batch_dot(x, y, axes=1) = [[17, 53]] which is the main diagonal\n-        of x.dot(y.T), although we never have to calculate the off-diagonal\n-        elements.\n-\n-        Shape inference:\n-        Let x's shape be (100, 20) and y's shape be (100, 30, 20).\n-        If dot_axes is (1, 2), to find the output shape of resultant tensor,\n-            loop through each dimension in x's shape and y's shape:\n-        x.shape[0] : 100 : append to output shape\n-        x.shape[1] : 20 : do not append to output shape,\n-            dimension 1 of x has been summed over. (dot_axes[0] = 1)\n-        y.shape[0] : 100 : do not append to output shape,\n-            always ignore first dimension of y\n-        y.shape[1] : 30 : append to output shape\n-        y.shape[2] : 20 : do not append to output shape,\n-            dimension 2 of y has been summed over. (dot_axes[1] = 2)\n-\n-        output_shape = (100, 30)\n-    \"\"\"\n-    if isinstance(axes, int):\n-        axes = (axes, axes)\n-    if axes is None:\n-        # behaves like tf.batch_matmul as default\n-        if y.ndim == 2:\n-            axes = [x.ndim - 1, y.ndim - 1]\n-        else:\n-            axes = [x.ndim - 1, y.ndim - 2]\n-    if py_any([isinstance(a, (list, tuple)) for a in axes]):\n-        raise ValueError('Multiple target dimensions are not supported. ' +\n-                         'Expected: None, int, (int, int), ' +\n-                         'Provided: ' + str(axes))\n-    if isinstance(axes, tuple):\n-        axes = list(axes)\n-\n-    if 0 in axes:\n-        raise ValueError('Can not perform batch_dot over axis 0.'\n-                         'If your inputs are not batched,'\n-                         ' add a dummy batch dimension to your '\n-                         'inputs using K.expand_dims(x, 0)')\n-\n-    out = T.batched_tensordot(x, y, axes=axes)\n-    if ndim(out) == 1:\n-        out = expand_dims(out, 1)\n-\n-    if hasattr(x, '_keras_shape') and hasattr(y, '_keras_shape'):\n-        shape = []\n-        for axis in range(len(x._keras_shape)):\n-            if axis != axes[0]:\n-                shape.append(x._keras_shape[axis])\n-        for axis in range(1, len(y._keras_shape)):\n-            if axis != axes[1]:\n-                shape.append(y._keras_shape[axis])\n-        if len(shape) == 1:\n-            shape.append(1)     # Expand dims if ndim == 1\n-        out._keras_shape = tuple(shape)\n-    return out\n-\n-\n-def transpose(x):\n-    y = T.transpose(x)\n-    if hasattr(x, '_keras_shape'):\n-        y._keras_shape = tuple(reversed(x._keras_shape))\n-    return y\n-\n-\n-def gather(reference, indices):\n-    \"\"\"Retrieves the elements of indices `indices` in the tensor `reference`.\n-\n-    # Arguments\n-        reference: A tensor.\n-        indices: An integer tensor of indices.\n-\n-    # Returns\n-        A tensor of same type as `reference`.\n-    \"\"\"\n-    y = reference[indices]\n-    if hasattr(reference, '_keras_shape') and hasattr(indices, '_keras_shape'):\n-        y._keras_shape = indices._keras_shape + reference._keras_shape[1:]\n-    return y\n-\n-\n-# ELEMENT-WISE OPERATIONS\n-\n-\n-def max(x, axis=None, keepdims=False):\n-    return T.max(x, axis=axis, keepdims=keepdims)\n-\n-\n-def min(x, axis=None, keepdims=False):\n-    return T.min(x, axis=axis, keepdims=keepdims)\n-\n-\n-def sum(x, axis=None, keepdims=False):\n-    \"\"\"Sum of the values in a tensor, alongside the specified axis.\n-    \"\"\"\n-    return T.sum(x, axis=axis, keepdims=keepdims)\n-\n-\n-def prod(x, axis=None, keepdims=False):\n-    \"\"\"Multiply the values in a tensor, alongside the specified axis.\n-    \"\"\"\n-    return T.prod(x, axis=axis, keepdims=keepdims)\n-\n-\n-def cumsum(x, axis=0):\n-    \"\"\"Cumulative sum of the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer, the axis to compute the sum.\n-\n-    # Returns\n-        A tensor of the cumulative sum of values of `x` along `axis`.\n-    \"\"\"\n-    return T.extra_ops.cumsum(x, axis=axis)\n-\n-\n-def cumprod(x, axis=0):\n-    \"\"\"Cumulative product of the values in a tensor, alongside the specified axis.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer, the axis to compute the product.\n-\n-    # Returns\n-        A tensor of the cumulative product of values of `x` along `axis`.\n-    \"\"\"\n-    return T.extra_ops.cumprod(x, axis=axis)\n-\n-\n-def mean(x, axis=None, keepdims=False):\n-    \"\"\"Mean of a tensor, alongside the specified axis.\n-    \"\"\"\n-    dtype = None\n-    # bool is available since theano v0.9dev\n-    if 'int' in x.dtype or x.dtype == 'bool':\n-        dtype = floatx()\n-    return T.mean(x, axis=axis, keepdims=keepdims, dtype=dtype)\n-\n-\n-def std(x, axis=None, keepdims=False):\n-    return T.std(x, axis=axis, keepdims=keepdims)\n-\n-\n-def var(x, axis=None, keepdims=False):\n-    return T.var(x, axis=axis, keepdims=keepdims)\n-\n-\n-def any(x, axis=None, keepdims=False):\n-    \"\"\"Bitwise reduction (logical OR).\n-    \"\"\"\n-    y = T.any(x, axis=axis, keepdims=keepdims)\n-    y = _set_keras_shape_for_reduction(x, y, axis, keepdims)\n-    return y\n-\n-\n-def all(x, axis=None, keepdims=False):\n-    \"\"\"Bitwise reduction (logical AND).\n-    \"\"\"\n-    y = T.all(x, axis=axis, keepdims=keepdims)\n-    y = _set_keras_shape_for_reduction(x, y, axis, keepdims)\n-    return y\n-\n-\n-def _set_keras_shape_for_reduction(x, y, axis, keepdims):\n-    if hasattr(x, '_keras_shape'):\n-        if axis is None:\n-            y._keras_shape = (1,) * len(x._keras_shape) if keepdims else (1,)\n-        else:\n-            if isinstance(axis, int):\n-                axis_list = [axis]\n-            else:\n-                axis_list = list(set(int(a) for a in axis))\n-            keras_shape_list = list(x._keras_shape)\n-            if keepdims:\n-                for a in axis_list:\n-                    keras_shape_list[a] = 1\n-            else:\n-                for a in axis_list[::-1]:\n-                    keras_shape_list.pop(a)\n-                if not keras_shape_list:\n-                    keras_shape_list = (1,)\n-            y._keras_shape = tuple(keras_shape_list)\n-    return y\n-\n-\n-def argmax(x, axis=-1):\n-    return T.argmax(x, axis=axis, keepdims=False)\n-\n-\n-def argmin(x, axis=-1):\n-    return T.argmin(x, axis=axis, keepdims=False)\n-\n-\n-def square(x):\n-    return T.sqr(x)\n-\n-\n-def abs(x):\n-    return T.abs_(x)\n-\n-\n-def sqrt(x):\n-    x = T.clip(x, 0., np.inf)\n-    return T.sqrt(x)\n-\n-\n-def exp(x):\n-    return T.exp(x)\n-\n-\n-def log(x):\n-    return T.log(x)\n-\n-\n-def logsumexp(x, axis=None, keepdims=False):\n-    \"\"\"Computes log(sum(exp(elements across dimensions of a tensor))).\n-\n-    This function is more numerically stable than log(sum(exp(x))).\n-    It avoids overflows caused by taking the exp of large inputs and\n-    underflows caused by taking the log of small inputs.\n-\n-    # Arguments\n-        x: A tensor or variable.\n-        axis: An integer, the axis to reduce over.\n-        keepdims: A boolean, whether to keep the dimensions or not.\n-            If `keepdims` is `False`, the rank of the tensor is reduced\n-            by 1. If `keepdims` is `True`, the reduced dimension is\n-            retained with length 1.\n-\n-    # Returns\n-        The reduced tensor.\n-    \"\"\"\n-    # Theano has a built-in optimization for logsumexp\n-    # (see https://github.com/Theano/Theano/pull/4736)\n-    # so we can just write the expression directly:\n-    return T.log(T.sum(T.exp(x), axis=axis, keepdims=keepdims))\n-\n-\n-def round(x):\n-    return T.round(x, mode='half_to_even')\n-\n-\n-def sign(x):\n-    return T.sgn(x)\n-\n-\n-def pow(x, a):\n-    return T.pow(x, a)\n-\n-\n-def clip(x, min_value, max_value):\n-    if (isinstance(min_value, (int, float)) and\n-            isinstance(max_value, (int, float))):\n-        if max_value < min_value:\n-            max_value = min_value\n-    if min_value is None:\n-        min_value = -np.inf\n-    if max_value is None:\n-        max_value = np.inf\n-    return T.clip(x, min_value, max_value)\n-\n-\n-def equal(x, y):\n-    return T.eq(x, y)\n-\n-\n-def not_equal(x, y):\n-    z = T.neq(x, y)\n-    if hasattr(x, '_keras_shape'):\n-        z._keras_shape = x._keras_shape\n-    elif hasattr(y, '_keras_shape'):\n-        z._keras_shape = y._keras_shape\n-    return z\n-\n-\n-def greater(x, y):\n-    return T.gt(x, y)\n-\n-\n-def greater_equal(x, y):\n-    return T.ge(x, y)\n-\n-\n-def less(x, y):\n-    return T.lt(x, y)\n-\n-\n-def less_equal(x, y):\n-    return T.le(x, y)\n-\n-\n-def maximum(x, y):\n-    return T.maximum(x, y)\n-\n-\n-def minimum(x, y):\n-    return T.minimum(x, y)\n-\n-\n-def sin(x):\n-    return T.sin(x)\n-\n-\n-def cos(x):\n-    return T.cos(x)\n-\n-\n-def normalize_batch_in_training(x, gamma, beta,\n-                                reduction_axes, epsilon=1e-3):\n-    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n-    \"\"\"\n-    # TODO remove this if statement when Theano without\n-    # T.nnet.bn.batch_normalization_train is deprecated\n-    if not hasattr(T.nnet.bn, 'batch_normalization_train'):\n-        return _old_normalize_batch_in_training(\n-            x, gamma, beta, reduction_axes, epsilon)\n-\n-    if gamma is None:\n-        if beta is None:\n-            gamma = ones_like(x)\n-        else:\n-            gamma = ones_like(beta)\n-    if beta is None:\n-        if gamma is None:\n-            beta = zeros_like(x)\n-        beta = zeros_like(gamma)\n-\n-    normed, mean, stdinv = T.nnet.bn.batch_normalization_train(\n-        x, gamma, beta, reduction_axes, epsilon)\n-\n-    return normed, mean, T.inv(stdinv ** 2)\n-\n-\n-def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n-    \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n-    \"\"\"\n-    # TODO remove this if statement when Theano without\n-    # T.nnet.bn.batch_normalization_test is deprecated\n-    if not hasattr(T.nnet.bn, 'batch_normalization_test'):\n-        return _old_batch_normalization(x, mean, var, beta, gamma, epsilon)\n-\n-    if gamma is None:\n-        gamma = ones_like(var)\n-    if beta is None:\n-        beta = zeros_like(mean)\n-\n-    if mean.ndim == 1:\n-        # based on TensorFlow's default: normalize along rightmost dimension\n-        reduction_axes = list(range(x.ndim - 1))\n-    else:\n-        reduction_axes = [i for i in range(x.ndim) if mean.broadcastable[i]]\n-\n-    return T.nnet.bn.batch_normalization_test(\n-        x, gamma, beta, mean, var, reduction_axes, epsilon)\n-\n-\n-# TODO remove this function when Theano without\n-# T.nnet.bn.batch_normalization_train is deprecated\n-def _old_normalize_batch_in_training(x, gamma, beta, reduction_axes,\n-                                     epsilon=1e-3):  # pragma: no cover\n-    \"\"\"Computes mean and std for batch then apply batch_normalization on batch.\n-    \"\"\"\n-    if gamma is None:\n-        gamma = ones_like(x)\n-    if beta is None:\n-        beta = zeros_like(x)\n-\n-    dev = theano.config.device\n-    use_cudnn = (ndim(x) < 5 and\n-                 reduction_axes == [0, 2, 3] and\n-                 (dev.startswith('cuda') or dev.startswith('gpu')))\n-    if use_cudnn:\n-        broadcast_beta = beta.dimshuffle('x', 0, 'x', 'x')\n-        broadcast_gamma = gamma.dimshuffle('x', 0, 'x', 'x')\n-        try:\n-            trained = theano.sandbox.cuda.dnn.dnn_batch_normalization_train(\n-                x, broadcast_gamma, broadcast_beta, 'spatial', epsilon)\n-            normed, mean, stdinv = trained\n-            normed = theano.tensor.as_tensor_variable(normed)\n-            mean = theano.tensor.as_tensor_variable(mean)\n-            stdinv = theano.tensor.as_tensor_variable(stdinv)\n-            var = T.inv(stdinv ** 2)\n-            return normed, T.flatten(mean), T.flatten(var)\n-        except AttributeError:\n-            pass\n-\n-    var = x.var(reduction_axes)\n-    mean = x.mean(reduction_axes)\n-\n-    target_shape = []\n-    for axis in range(ndim(x)):\n-        if axis in reduction_axes:\n-            target_shape.append(1)\n-        else:\n-            target_shape.append(x.shape[axis])\n-    target_shape = T.stack(*target_shape)\n-\n-    broadcast_mean = T.reshape(mean, target_shape)\n-    broadcast_var = T.reshape(var, target_shape)\n-    broadcast_beta = T.reshape(beta, target_shape)\n-    broadcast_gamma = T.reshape(gamma, target_shape)\n-    normed = batch_normalization(x, broadcast_mean, broadcast_var,\n-                                 broadcast_beta, broadcast_gamma,\n-                                 epsilon)\n-    return normed, mean, var\n-\n-\n-# TODO remove this if statement when Theano without\n-# T.nnet.bn.batch_normalization_test is deprecated\n-def _old_batch_normalization(x, mean, var, beta, gamma,\n-                             epsilon=1e-3):  # pragma: no cover\n-    \"\"\"Apply batch normalization on x given mean, var, beta and gamma.\n-    \"\"\"\n-    if gamma is None:\n-        gamma = ones_like(var)\n-    if beta is None:\n-        beta = zeros_like(mean)\n-\n-    if mean.ndim == 1 and x.ndim > 1:\n-        # in TensorFlow's batch_normalization, if the parameters are vectors\n-        # the batch normalization should be applied along the rightmost axis.\n-        # Theano expects the parameters to always have x.ndim dimensions.\n-        shuffle_pattern = ['x'] * (x.ndim - 1) + [0]\n-        mean = mean.dimshuffle(shuffle_pattern)\n-        var = var.dimshuffle(shuffle_pattern)\n-        beta = beta.dimshuffle(shuffle_pattern)\n-        gamma = gamma.dimshuffle(shuffle_pattern)\n-\n-    ndim = x.ndim\n-    dev = theano.config.device\n-    use_cudnn = ndim < 5 and (dev.startswith('cuda') or dev.startswith('gpu'))\n-    if use_cudnn:\n-        try:\n-            axis = mean.broadcastable.index(False)\n-            if axis != 1:\n-                shuffle_pattern = list(range(ndim))\n-                shuffle_pattern[1] = shuffle_pattern[axis]\n-                shuffle_pattern[axis] = 1\n-                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n-                    x.dimshuffle(shuffle_pattern),\n-                    gamma.dimshuffle(shuffle_pattern),\n-                    beta.dimshuffle(shuffle_pattern),\n-                    mean.dimshuffle(shuffle_pattern),\n-                    var.dimshuffle(shuffle_pattern),\n-                    'spatial', epsilon).dimshuffle(shuffle_pattern)\n-            else:\n-                result = theano.sandbox.cuda.dnn.dnn_batch_normalization_test(\n-                    x, gamma, beta, mean, var, 'spatial', epsilon)\n-            return theano.tensor.as_tensor_variable(result)\n-        except AttributeError:\n-            pass\n-        except ValueError:\n-            pass\n-    return T.nnet.bn.batch_normalization(x, gamma, beta, mean, sqrt(var + epsilon),\n-                                         mode='high_mem')\n-\n-\n-# SHAPE OPERATIONS\n-\n-def concatenate(tensors, axis=-1):\n-    if py_all([is_sparse(x) for x in tensors]):\n-        axis = axis % ndim(tensors[0])\n-        if axis == 0:\n-            output = th_sparse_module.basic.vstack(tensors, format='csr')\n-        elif axis == 1:\n-            output = th_sparse_module.basic.hstack(tensors, format='csr')\n-        else:\n-            raise ValueError('Invalid concat axis for sparse matrix:', axis)\n-    else:\n-        output = T.concatenate([to_dense(x) for x in tensors], axis=axis)\n-\n-    if py_all([hasattr(tensor, '_keras_shape') for tensor in tensors]):\n-        input_shapes = [tensor._keras_shape for tensor in tensors]\n-        output_shape = list(input_shapes[0])\n-        for shape in input_shapes[1:]:\n-            if output_shape[axis] is None or shape[axis] is None:\n-                output_shape[axis] = None\n-                break\n-            output_shape[axis] += shape[axis]\n-        output._keras_shape = tuple(output_shape)\n-\n-    return output\n-\n-\n-def reshape(x, shape):\n-    y = T.reshape(x, shape)\n-    shape = tuple(x if isinstance(x, int) and x > 0 else None for x in shape)\n-    y._keras_shape = shape\n-    if hasattr(x, '_uses_learning_phase'):\n-        y._uses_learning_phase = x._uses_learning_phase\n-    else:\n-        y._uses_learning_phase = False\n-    return y\n-\n-\n-def permute_dimensions(x, pattern):\n-    \"\"\"Transpose dimensions.\n-\n-    pattern should be a tuple or list of\n-    dimension indices, e.g. [0, 2, 1].\n-    \"\"\"\n-    pattern = tuple(pattern)\n-    y = x.dimshuffle(pattern)\n-    if hasattr(x, '_keras_shape'):\n-        y._keras_shape = tuple(np.asarray(x._keras_shape)[list(pattern)])\n-    return y\n-\n-\n-def repeat_elements(x, rep, axis):\n-    \"\"\"Repeat the elements of a tensor along an axis, like np.repeat.\n-\n-    If x has shape (s1, s2, s3) and axis=1, the output\n-    will have shape (s1, s2 * rep, s3).\n-    \"\"\"\n-    y = T.repeat(x, rep, axis=axis)\n-    if hasattr(x, '_keras_shape'):\n-        y._keras_shape = list(x._keras_shape)\n-        repeat_dim = x._keras_shape[axis]\n-        if repeat_dim is not None:\n-                y._keras_shape[axis] = repeat_dim * rep\n-        y._keras_shape = tuple(y._keras_shape)\n-    return y\n-\n-\n-def resize_images(x,\n-                  height_factor,\n-                  width_factor,\n-                  data_format,\n-                  interpolation='nearest'):\n-    \"\"\"Resize the images contained in a 4D tensor of shape\n-    - [batch, channels, height, width] (for 'channels_first' data_format)\n-    - [batch, height, width, channels] (for 'channels_last' data_format)\n-    by a factor of (height_factor, width_factor). Both factors should be\n-    positive integers.\n-    \"\"\"\n-    if data_format == 'channels_first':\n-        axis_1 = 2\n-        axis_2 = 3\n-    elif data_format == 'channels_last':\n-        axis_1 = 1\n-        axis_2 = 2\n-    else:\n-        raise ValueError('Invalid data_format:', data_format)\n-\n-    if interpolation == 'nearest':\n-        output = repeat_elements(x, height_factor, axis=axis_1)\n-        output = repeat_elements(output, width_factor, axis=axis_2)\n-    elif interpolation == 'bilinear':\n-        if not (height_factor == width_factor == 2):\n-            raise NotImplementedError(\n-                'Bilinear upscaling with factors other than (2, 2)'\n-                'is not available when using the Theano backend.')\n-        if data_format == 'channels_last':\n-            output = permute_dimensions(x, [0, 3, 1, 2])\n-        else:\n-            output = x\n-        output = T.nnet.abstract_conv.bilinear_upsampling(output,\n-                                                          ratio=height_factor)\n-        if data_format == 'channels_last':\n-            output = permute_dimensions(output, [0, 2, 3, 1])\n-        if hasattr(x, '_keras_shape'):\n-            output._keras_shape = list(x._keras_shape)\n-            output._keras_shape[axis_1] *= height_factor\n-            output._keras_shape[axis_2] *= width_factor\n-            output._keras_shape = tuple(output._keras_shape)\n-    else:\n-        raise ValueError('interpolation should be one of \"nearest\" or \"bilinear\".')\n-\n-    return output\n-\n-\n-def resize_volumes(x, depth_factor, height_factor, width_factor, data_format):\n-    \"\"\"Resize the volume contained in a 5D tensor of shape\n-    - [batch, channels, depth, height, width] (for 'channels_first' data_format)\n-    - [batch, depth, height, width, channels] (for 'channels_last' data_format)\n-    by a factor of (depth_factor, height_factor, width_factor).\n-    Both factors should be positive integers.\n-    \"\"\"\n-    if data_format == 'channels_first':\n-        output = repeat_elements(x, depth_factor, axis=2)\n-        output = repeat_elements(output, height_factor, axis=3)\n-        output = repeat_elements(output, width_factor, axis=4)\n-        return output\n-    elif data_format == 'channels_last':\n-        output = repeat_elements(x, depth_factor, axis=1)\n-        output = repeat_elements(output, height_factor, axis=2)\n-        output = repeat_elements(output, width_factor, axis=3)\n-        return output\n-    else:\n-        raise ValueError('Invalid data_format:', data_format)\n-\n-\n-def repeat(x, n):\n-    \"\"\"Repeat a 2D tensor.\n-\n-    If x has shape (samples, dim) and n=2,\n-    the output will have shape (samples, 2, dim).\n-    \"\"\"\n-    assert x.ndim == 2\n-    y = x.dimshuffle((0, 'x', 1))\n-    y = T.extra_ops.repeat(y, n, axis=1)\n-    if hasattr(x, '_keras_shape'):\n-        shape = list(x._keras_shape)\n-        shape.insert(1, n)\n-        y._keras_shape = tuple(shape)\n-\n-    return y\n-\n-\n-def arange(start, stop=None, step=1, dtype='int32'):\n-    \"\"\"Creates a 1-D tensor containing a sequence of integers.\n-\n-    The function arguments use the same convention as\n-    Theano's arange: if only one argument is provided,\n-    it is in fact the \"stop\" argument.\n-\n-    The default type of the returned tensor is 'int32' to\n-    match TensorFlow's default.\n-    \"\"\"\n-    return T.arange(start, stop=stop, step=step, dtype=dtype)\n-\n-\n-def tile(x, n):\n-    if isinstance(n, int):\n-        n = (n,)\n-    elif isinstance(n, list):\n-        n = tuple(n)\n-\n-    y = T.tile(x, n, ndim=x.ndim)\n-    shape = int_shape(x)\n-    if shape is None:\n-        return y\n-    elif isinstance(n, tuple) and len(n) < len(shape):  # Padding the axis\n-        n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n-    elif isinstance(n, tuple) and len(n) != len(shape):\n-        raise NotImplementedError\n-\n-    if isinstance(n, tuple):\n-        y._keras_shape = tuple([None if a is None else a * b\n-                                for (a, b) in zip(shape, n)])\n-    return y\n-\n-\n-def flatten(x):\n-    y = T.flatten(x)\n-    if hasattr(x, '_keras_shape'):\n-        if None in x._keras_shape:\n-            y._keras_shape = (None,)\n-        else:\n-            y._keras_shape = (np.prod(x._keras_shape), )\n-    return y\n-\n-\n-def batch_flatten(x):\n-    \"\"\"Turn a n-D tensor into a 2D tensor where\n-    the first dimension is conserved.\n-    \"\"\"\n-    y = T.reshape(x, (x.shape[0], T.prod(x.shape[1:])))\n-    if hasattr(x, '_keras_shape'):\n-        if None in x._keras_shape[1:]:\n-            y._keras_shape = (x._keras_shape[0], None)\n-        else:\n-            y._keras_shape = (x._keras_shape[0], np.prod(x._keras_shape[1:]))\n-    return y\n-\n-\n-def expand_dims(x, axis=-1):\n-    \"\"\"Add a 1-sized dimension at index \"dim\".\n-    \"\"\"\n-    pattern = [i for i in range(x.type.ndim)]\n-    if axis < 0:\n-        if x.type.ndim == 0:\n-            axis = 0\n-        else:\n-            axis = axis % x.type.ndim + 1\n-    pattern.insert(axis, 'x')\n-    y = x.dimshuffle(pattern)\n-    if hasattr(x, '_keras_shape'):\n-        shape = list(x._keras_shape)\n-        shape.insert(axis, 1)\n-        y._keras_shape = tuple(shape)\n-    return y\n-\n-\n-def squeeze(x, axis):\n-    \"\"\"Remove a 1-dimension from the tensor at index \"axis\".\n-    \"\"\"\n-    shape = list(x.shape)\n-    shape.pop(axis)\n-    y = T.reshape(x, tuple(shape))\n-    if hasattr(x, '_keras_shape'):\n-        kshape = list(x._keras_shape)\n-        kshape.pop(axis)\n-        y._keras_shape = tuple(kshape)\n-    return y\n-\n-\n-def temporal_padding(x, padding=(1, 1)):\n-    \"\"\"Pad the middle dimension of a 3D tensor\n-    with \"padding\" zeros left and right.\n-\n-    Apologies for the inane API, but Theano makes this\n-    really hard.\n-    \"\"\"\n-    assert len(padding) == 2\n-    input_shape = x.shape\n-    output_shape = (input_shape[0],\n-                    input_shape[1] + padding[0] + padding[1],\n-                    input_shape[2])\n-    output = T.zeros(output_shape)\n-    result = T.set_subtensor(output[:, padding[0]:x.shape[1] + padding[0], :], x)\n-    if hasattr(x, '_keras_shape'):\n-        result._keras_shape = (x._keras_shape[0],\n-                               x._keras_shape[1] + py_sum(padding),\n-                               x._keras_shape[2])\n-    return result\n-\n-\n-def spatial_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n-    \"\"\"Pad the 2nd and 3rd dimensions of a 4D tensor\n-    with \"padding[0]\" and \"padding[1]\" (resp.) zeros left and right.\n-    \"\"\"\n-    assert len(padding) == 2\n-    assert len(padding[0]) == 2\n-    assert len(padding[1]) == 2\n-    top_pad, bottom_pad = padding[0]\n-    left_pad, right_pad = padding[1]\n-    data_format = normalize_data_format(data_format)\n-\n-    input_shape = x.shape\n-    if data_format == 'channels_first':\n-        output_shape = (input_shape[0],\n-                        input_shape[1],\n-                        input_shape[2] + top_pad + bottom_pad,\n-                        input_shape[3] + left_pad + right_pad)\n-        output = T.zeros(output_shape)\n-        indices = (py_slice(None),\n-                   py_slice(None),\n-                   py_slice(top_pad, input_shape[2] + top_pad),\n-                   py_slice(left_pad, input_shape[3] + left_pad))\n-\n-    else:\n-        output_shape = (input_shape[0],\n-                        input_shape[1] + top_pad + bottom_pad,\n-                        input_shape[2] + left_pad + right_pad,\n-                        input_shape[3])\n-        output = T.zeros(output_shape)\n-        indices = (py_slice(None),\n-                   py_slice(top_pad, input_shape[1] + top_pad),\n-                   py_slice(left_pad, input_shape[2] + left_pad),\n-                   py_slice(None))\n-    y = T.set_subtensor(output[indices], x)\n-    if hasattr(x, '_keras_shape'):\n-        if data_format == 'channels_first':\n-            if x._keras_shape[2] is not None:\n-                h = x._keras_shape[2] + top_pad + bottom_pad\n-            else:\n-                h = None\n-            if x._keras_shape[3] is not None:\n-                w = x._keras_shape[3] + left_pad + right_pad\n-            else:\n-                w = None\n-            output_keras_shape = (x._keras_shape[0],\n-                                  x._keras_shape[1],\n-                                  h,\n-                                  w)\n-        else:\n-            if x._keras_shape[1] is not None:\n-                h = x._keras_shape[1] + top_pad + bottom_pad\n-            else:\n-                h = None\n-            if x._keras_shape[2] is not None:\n-                w = x._keras_shape[2] + left_pad + right_pad\n-            else:\n-                w = None\n-            output_keras_shape = (x._keras_shape[0],\n-                                  h,\n-                                  w,\n-                                  x._keras_shape[3])\n-        y._keras_shape = output_keras_shape\n-    return y\n-\n-\n-def spatial_3d_padding(x, padding=((1, 1), (1, 1), (1, 1)), data_format=None):\n-    \"\"\"Pad the 2nd, 3rd and 4th dimensions of a 5D tensor\n-    with \"padding[0]\", \"padding[1]\" and \"padding[2]\" (resp.) zeros left and right.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    input_shape = x.shape\n-    if data_format == 'channels_first':\n-        output_shape = (input_shape[0],\n-                        input_shape[1],\n-                        input_shape[2] + padding[0][0] + padding[0][1],\n-                        input_shape[3] + padding[1][0] + padding[1][1],\n-                        input_shape[4] + padding[2][0] + padding[2][1])\n-        output = T.zeros(output_shape)\n-        indices = (py_slice(None),\n-                   py_slice(None),\n-                   py_slice(padding[0][0], input_shape[2] + padding[0][0]),\n-                   py_slice(padding[1][0], input_shape[3] + padding[1][0]),\n-                   py_slice(padding[2][0], input_shape[4] + padding[2][0]))\n-\n-    else:\n-        output_shape = (input_shape[0],\n-                        input_shape[1] + padding[0][0] + padding[0][1],\n-                        input_shape[2] + padding[1][0] + padding[1][1],\n-                        input_shape[3] + padding[2][0] + padding[2][1],\n-                        input_shape[4])\n-        output = T.zeros(output_shape)\n-        indices = (py_slice(None),\n-                   py_slice(padding[0][0], input_shape[1] + padding[0][0]),\n-                   py_slice(padding[1][0], input_shape[2] + padding[1][0]),\n-                   py_slice(padding[2][0], input_shape[3] + padding[2][0]),\n-                   py_slice(None))\n-    y = T.set_subtensor(output[indices], x)\n-    if hasattr(x, '_keras_shape'):\n-        if data_format == 'channels_first':\n-            if x._keras_shape[2] is not None:\n-                h = x._keras_shape[2] + padding[0][0] + padding[0][1]\n-            else:\n-                h = None\n-            if x._keras_shape[3] is not None:\n-                w = x._keras_shape[3] + padding[1][0] + padding[1][1]\n-            else:\n-                w = None\n-            if x._keras_shape[4] is not None:\n-                d = x._keras_shape[4] + padding[2][0] + padding[2][1]\n-            else:\n-                d = None\n-            output_keras_shape = (x._keras_shape[0],\n-                                  x._keras_shape[1],\n-                                  h,\n-                                  w,\n-                                  d)\n-        else:\n-            if x._keras_shape[1] is not None:\n-                h = x._keras_shape[1] + padding[0][0] + padding[0][1]\n-            else:\n-                h = None\n-            if x._keras_shape[2] is not None:\n-                w = x._keras_shape[2] + padding[1][0] + padding[1][1]\n-            else:\n-                w = None\n-            if x._keras_shape[3] is not None:\n-                d = x._keras_shape[3] + padding[2][0] + padding[2][1]\n-            else:\n-                d = None\n-            output_keras_shape = (x._keras_shape[0],\n-                                  h,\n-                                  w,\n-                                  d,\n-                                  x._keras_shape[4])\n-        y._keras_shape = output_keras_shape\n-    return y\n-\n-\n-def stack(x, axis=0):\n-    return T.stack(x, axis=axis)\n-\n-\n-def one_hot(indices, num_classes):\n-    \"\"\"Input: nD integer tensor of shape (batch_size, dim1, dim2, ... dim(n-1))\n-    Output: (n + 1)D one hot representation of the input\n-    with shape (batch_size, dim1, dim2, ... dim(n-1), num_classes)\n-    \"\"\"\n-    input_shape = tuple((indices.shape[i] for i in range(indices.ndim)))\n-    indices = T.flatten(indices)\n-    oh = T.extra_ops.to_one_hot(indices, num_classes)\n-    oh = T.reshape(oh, input_shape + (num_classes,))\n-    return oh\n-\n-\n-def reverse(x, axes):\n-    \"\"\"Reverse a tensor along the specified axes\n-    \"\"\"\n-    if isinstance(axes, int):\n-        axes = [axes]\n-    elif isinstance(axes, tuple):\n-        axes = list(axes)\n-    for i in range(len(axes)):\n-        if axes[i] == -1:\n-            axes[i] = x.ndim - 1\n-    slices = []\n-    for i in range(x.ndim):\n-        if i in axes:\n-            slices.append(py_slice(None, None, -1))\n-        else:\n-            slices.append(py_slice(None, None, None))\n-    return x[slices]\n-\n-\n-def slice(x, start, size):\n-    if not (len(int_shape(x)) == len(start) == len(size)):\n-        raise ValueError('The dimension and the size of indices should match.')\n-    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n-    out._keras_shape = tuple(size)\n-    return out\n-\n-\n-def pattern_broadcast(x, broadcastable):\n-    return T.patternbroadcast(x, broadcastable)\n-\n-# VALUE MANIPULATION\n-\n-\n-def get_value(x):\n-    if not hasattr(x, 'get_value'):\n-        raise TypeError('`get_value` can only be called on a variable. '\n-                        'If you have an expression instead, use `eval()`.')\n-    return x.get_value()\n-\n-\n-def batch_get_value(xs):\n-    \"\"\"Returns the value of more than one tensor variable,\n-    as a list of Numpy arrays.\n-    \"\"\"\n-    return [get_value(x) for x in xs]\n-\n-\n-def set_value(x, value):\n-    x.set_value(np.asarray(value, dtype=x.dtype))\n-\n-\n-def batch_set_value(tuples):\n-    for x, value in tuples:\n-        x.set_value(np.asarray(value, dtype=x.dtype))\n-\n-\n-def get_variable_shape(x):\n-    return x.get_value(borrow=True, return_internal_type=True).shape\n-\n-\n-def print_tensor(x, message=''):\n-    \"\"\"Print the message & the tensor when evaluated & return the same tensor.\n-    \"\"\"\n-    p_op = Print(message)\n-    return p_op(x)\n-\n-\n-# GRAPH MANIPULATION\n-\n-class Function(object):\n-\n-    def __init__(self, inputs, outputs, updates=[], name=None, **kwargs):\n-        unique_variables_to_update = {}\n-        for v, nv in updates:\n-            if v not in unique_variables_to_update:\n-                unique_variables_to_update[v] = nv\n-        updates = unique_variables_to_update.items()\n-        self.outputs = outputs\n-        self.function = theano.function(inputs, outputs, updates=updates,\n-                                        allow_input_downcast=True,\n-                                        on_unused_input='ignore',\n-                                        name=name,\n-                                        **kwargs)\n-        self._metrics = [x for x in outputs if hasattr(x, '_is_metric')]\n-        self._metrics_function = theano.function(\n-            [], self._metrics,\n-            name=name + '_metrics' if name else None)\n-        self.name = name\n-\n-    def __call__(self, inputs):\n-        assert isinstance(inputs, (list, tuple))\n-        outputs = self.function(*inputs)\n-        if self._metrics:\n-            metrics = self._metrics_function()\n-        i = 0\n-        j = 0\n-        for x in self.outputs:\n-            if hasattr(x, '_is_metric'):\n-                v = metrics[j]\n-                outputs[i] = v\n-                j += 1\n-            i += 1\n-        return outputs\n-\n-\n-def _raise_invalid_arg(key):\n-    msg = 'Invalid argument \"%s\" passed to K.function with Theano backend' % key\n-    raise ValueError(msg)\n-\n-\n-def function(inputs, outputs, updates=[], **kwargs):\n-    if len(kwargs) > 0:\n-        for key in kwargs.keys():\n-            if not has_arg(theano.function, key, True):\n-                _raise_invalid_arg(key)\n-    return Function(inputs, outputs, updates=updates, **kwargs)\n-\n-\n-def gradients(loss, variables):\n-    return T.grad(loss, variables)\n-\n-\n-def stop_gradient(variables):\n-    \"\"\"Returns `variables` but with zero gradient w.r.t. every other variable.\n-\n-    # Arguments\n-        variables: tensor or list of tensors to consider constant with respect\n-            to any other variable.\n-\n-    # Returns\n-        A single tensor or a list of tensors (depending on the passed argument)\n-            that has constant gradient with respect to any other variable.\n-    \"\"\"\n-    if isinstance(variables, (list, tuple)):\n-        return map(theano.gradient.disconnected_grad, variables)\n-    else:\n-        return theano.gradient.disconnected_grad(variables)\n-\n-\n-# CONTROL FLOW\n-\n-def rnn(step_function, inputs, initial_states,\n-        go_backwards=False, mask=None, constants=None,\n-        unroll=False, input_length=None):\n-    \"\"\"Iterates over the time dimension of a tensor.\n-\n-    # Arguments\n-        step_function:\n-            Parameters:\n-                inputs: Tensor with shape (samples, ...) (no time dimension),\n-                    representing input for the batch of samples at a certain\n-                    time step.\n-                states: List of tensors.\n-            Returns:\n-                outputs: Tensor with shape (samples, ...) (no time dimension),\n-                new_states: List of tensors, same length and shapes\n-                    as 'states'.\n-        inputs: Tensor of temporal data of shape (samples, time, ...)\n-            (at least 3D).\n-        initial_states: Tensor with shape (samples, ...) (no time dimension),\n-            containing the initial values for the states used in\n-            the step function.\n-        go_backwards: Boolean. If True, do the iteration over the time\n-            dimension in reverse order and return the reversed sequence.\n-        mask: Binary tensor with shape (samples, time),\n-            with a zero for every element that is masked.\n-        constants: A list of constant values passed at each step.\n-        unroll: Whether to unroll the RNN or to use a symbolic loop\n-            (`while_loop` or `scan` depending on backend).\n-        input_length: Static number of timesteps in the input.\n-            Must be specified if using `unroll`.\n-\n-    # Returns\n-        A tuple (last_output, outputs, new_states).\n-\n-        last_output: The latest output of the rnn, of shape `(samples, ...)`\n-        outputs: Tensor with shape `(samples, time, ...)` where each\n-            entry `outputs[s, t]` is the output of the step function\n-            at time `t` for sample `s`.\n-        new_states: List of tensors, latest states returned by\n-            the step function, of shape `(samples, ...)`.\n-    \"\"\"\n-    ndim = inputs.ndim\n-    assert ndim >= 3, 'Input should be at least 3D.'\n-\n-    if unroll:\n-        if input_length is None:\n-            raise ValueError('When specifying `unroll=True`, '\n-                             'an `input_length` '\n-                             'must be provided to `rnn`.')\n-        if input_length == 1:\n-            raise ValueError('`input_length=1` is not'\n-                             ' supported when `unroll=True`.')\n-\n-    axes = [1, 0] + list(range(2, ndim))\n-    inputs = inputs.dimshuffle(axes)\n-\n-    if constants is None:\n-        constants = []\n-\n-    global uses_learning_phase\n-    uses_learning_phase = False\n-\n-    if mask is not None:\n-        if mask.ndim != 2:\n-            raise ValueError(\n-                'mask should have `shape=(samples, time)`, '\n-                'got {}'.format(mask.shape))\n-        mask = mask.dimshuffle([1, 0])\n-\n-        def get_matching_mask(mask_t, ref_tensor_t):\n-            # tf.where needs its condition tensor\n-            # to be the same shape as its two\n-            # result tensors\n-            ndim = ref_tensor_t.ndim\n-            for _ in range(ndim - 1):\n-                mask_t = expand_dims(mask_t)\n-            add_shape = ref_tensor_t.shape[1:]\n-            reps = T.concatenate([[1], add_shape], 0)\n-            return T.tile(mask_t, reps, ndim=ndim)\n-\n-        if unroll:\n-            indices = list(range(input_length))\n-            if go_backwards:\n-                indices = indices[::-1]\n-\n-            successive_outputs = []\n-            successive_states = []\n-            states = initial_states\n-            for i in indices:\n-                output, new_states = step_function(inputs[i], states + constants)\n-                if getattr(output, '_uses_learning_phase', False):\n-                    uses_learning_phase = True\n-\n-                if len(successive_outputs) == 0:\n-                    prev_output = zeros_like(output)\n-                else:\n-                    prev_output = successive_outputs[-1]\n-\n-                output_mask = get_matching_mask(mask[i], output)\n-                output = T.switch(output_mask, output, prev_output)\n-                kept_states = []\n-                for state, new_state in zip(states, new_states):\n-                    state_mask = get_matching_mask(mask[i], state)\n-                    kept_states.append(T.switch(state_mask, new_state, state))\n-                states = kept_states\n-\n-                successive_outputs.append(output)\n-                successive_states.append(states)\n-\n-            outputs = T.stack(*successive_outputs)\n-            states = []\n-            for i in range(len(successive_states[-1])):\n-                new_states = []\n-                for states_at_step in successive_states:\n-                    new_states.append(states_at_step[i])\n-                states.append(T.stack(*new_states))\n-        else:\n-            # build an all-zero tensor of shape (samples, output_dim)\n-            initial_output = step_function(inputs[0], initial_states + constants)\n-            initial_output = initial_output[0] * 0\n-            # Theano gets confused by broadcasting patterns in the scan op\n-            initial_output = T.unbroadcast(initial_output, 0, 1)\n-            if len(initial_states) > 0:\n-                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n-\n-            def _step(inputs, mask, output_tm1, *states):\n-                outputs, new_states = step_function(inputs, states)\n-                if getattr(outputs, '_uses_learning_phase', False):\n-                    global uses_learning_phase\n-                    uses_learning_phase = True\n-                # output previous output if masked.\n-                output_mask = get_matching_mask(mask, outputs)\n-                outputs = T.switch(output_mask, outputs, output_tm1)\n-                return_states = []\n-                for state, new_state in zip(states, new_states):\n-                    state_mask = get_matching_mask(mask, state)\n-                    return_states.append(T.switch(state_mask, new_state, state))\n-                return [outputs] + return_states\n-\n-            results, _ = theano.scan(\n-                _step,\n-                sequences=[inputs, mask],\n-                outputs_info=[initial_output] + initial_states,\n-                non_sequences=constants,\n-                go_backwards=go_backwards)\n-\n-            # deal with Theano API inconsistency\n-            if isinstance(results, list):\n-                outputs = results[0]\n-                states = results[1:]\n-            else:\n-                outputs = results\n-                states = []\n-    else:\n-        if unroll:\n-            indices = list(range(input_length))\n-            if go_backwards:\n-                indices = indices[::-1]\n-\n-            successive_outputs = []\n-            successive_states = []\n-            states = initial_states\n-            for i in indices:\n-                outputs, states = step_function(inputs[i], states + constants)\n-                if getattr(outputs, '_uses_learning_phase', False):\n-                    uses_learning_phase = True\n-                successive_outputs.append(outputs)\n-                successive_states.append(states)\n-            outputs = T.stack(*successive_outputs)\n-            states = []\n-            for i in range(len(successive_states[-1])):\n-                states.append(T.stack(\n-                    *[states_at_step[i] for states_at_step in successive_states]))\n-\n-        else:\n-            def _step(inputs, *states):\n-                outputs, new_states = step_function(inputs, states)\n-                if getattr(outputs, '_uses_learning_phase', False):\n-                    global uses_learning_phase\n-                    uses_learning_phase = True\n-                return [outputs] + new_states\n-\n-            # Theano likes to make shape==1 dimensions\n-            # in the initial states (outputs_info) broadcastable\n-            if len(initial_states) > 0:\n-                initial_states[0] = T.unbroadcast(initial_states[0], 0, 1)\n-\n-            results, _ = theano.scan(\n-                _step,\n-                sequences=inputs,\n-                outputs_info=[None] + initial_states,\n-                non_sequences=constants,\n-                go_backwards=go_backwards)\n-\n-            # deal with Theano API inconsistency\n-            if isinstance(results, list):\n-                outputs = results[0]\n-                states = results[1:]\n-            else:\n-                outputs = results\n-                states = []\n-\n-    outputs = T.squeeze(outputs)\n-    last_output = outputs[-1]\n-\n-    axes = [1, 0] + list(range(2, outputs.ndim))\n-    outputs = outputs.dimshuffle(axes)\n-    states = [T.squeeze(state[-1]) for state in states]\n-    last_output._uses_learning_phase = uses_learning_phase\n-    return last_output, outputs, states\n-\n-\n-def switch(condition, then_expression, else_expression):\n-    \"\"\"Switches between two operations depending on a scalar value.\n-\n-    Note that both `then_expression` and `else_expression`\n-    should be symbolic tensors of the *same shape*.\n-\n-    # Arguments\n-        condition: scalar tensor (`int` or `bool`).\n-        then_expression: either a tensor, or a callable that returns a tensor.\n-        else_expression: either a tensor, or a callable that returns a tensor.\n-\n-    # Returns\n-        The selected tensor.\n-    \"\"\"\n-    if callable(then_expression):\n-        then_expression = then_expression()\n-    if callable(else_expression):\n-        else_expression = else_expression()\n-    cond_ndim = ndim(condition)\n-    expr_ndim = ndim(then_expression)\n-    if cond_ndim < expr_ndim:\n-        ndim_diff = expr_ndim - cond_ndim\n-        for _ in range(ndim_diff):\n-            condition = expand_dims(condition)\n-    return T.switch(condition, then_expression, else_expression)\n-\n-\n-def in_train_phase(x, alt, training=None):\n-    \"\"\"Selects `x` in train phase, and `alt` otherwise.\n-\n-    Note that `alt` should have the *same shape* as `x`.\n-\n-    # Returns\n-        Either `x` or `alt` based on the `training` flag.\n-        the `training` flag defaults to `K.learning_phase()`.\n-    \"\"\"\n-    if training is None:\n-        training = learning_phase()\n-        uses_learning_phase = True\n-    else:\n-        uses_learning_phase = False\n-\n-    if training is 1 or training is True:\n-        if callable(x):\n-            return x()\n-        else:\n-            return x\n-\n-    elif training is 0 or training is False:\n-        if callable(alt):\n-            return alt()\n-        else:\n-            return alt\n-\n-    if callable(x):\n-        x = x()\n-    if callable(alt):\n-        alt = alt()\n-\n-    # else: assume learning phase is a placeholder tensor.\n-    x = ifelse(training, x, alt)\n-    if uses_learning_phase:\n-        x._uses_learning_phase = True\n-    return x\n-\n-\n-def in_test_phase(x, alt, training=None):\n-    \"\"\"Selects `x` in test phase, and `alt` otherwise.\n-    Note that `alt` should have the *same shape* as `x`.\n-\n-    # Returns\n-        Either `x` or `alt` based on `K.learning_phase`.\n-    \"\"\"\n-    return in_train_phase(alt, x, training=training)\n-\n-\n-# NN OPERATIONS\n-\n-def _assert_has_capability(module, func):\n-    if not hasattr(module, func):\n-        raise EnvironmentError(\n-            'It looks like like your version of '\n-            'Theano is out of date. '\n-            'Install the latest version with:\\n'\n-            'pip install git+git://github.com/Theano/Theano.git '\n-            '--upgrade --no-deps')\n-\n-\n-def elu(x, alpha=1.0):\n-    \"\"\" Exponential linear unit\n-\n-    # Arguments\n-        x: Tensor to compute the activation function for.\n-        alpha: scalar\n-    \"\"\"\n-    _assert_has_capability(T.nnet, 'elu')\n-    return T.nnet.elu(x, alpha)\n-\n-\n-def relu(x, alpha=0., max_value=None, threshold=0.):\n-    _assert_has_capability(T.nnet, 'relu')\n-\n-    if alpha != 0.:\n-        if threshold != 0.:\n-            negative_part = T.nnet.relu(-x + threshold)\n-        else:\n-            negative_part = T.nnet.relu(-x)\n-\n-    if threshold != 0.:\n-        x = x * T.cast(T.gt(x, threshold), floatx())\n-    else:\n-        x = T.nnet.relu(x)\n-\n-    if max_value is not None:\n-        x = T.clip(x, 0.0, max_value)\n-\n-    if alpha != 0.:\n-        x -= alpha * negative_part\n-\n-    return x\n-\n-\n-def softmax(x, axis=-1):\n-    if (axis == -1 or axis == x.ndim - 1) and x.ndim == 2:\n-        return T.nnet.softmax(x)\n-    xm = x.max(axis=axis, keepdims=True)\n-    return T.exp(x - xm) / T.exp(\n-        x - xm).sum(axis=axis, keepdims=True)\n-\n-\n-def softplus(x):\n-    return T.nnet.softplus(x)\n-\n-\n-def softsign(x):\n-    return T_softsign(x)\n-\n-\n-def categorical_crossentropy(target, output, from_logits=False, axis=-1):\n-    output_dimensions = list(range(len(int_shape(output))))\n-    if axis != -1 and axis not in output_dimensions:\n-        raise ValueError(\n-            '{}{}{}'.format(\n-                'Unexpected channels axis {}. '.format(axis),\n-                'Expected to be -1 or one of the axes of `output`, ',\n-                'which has {} dimensions.'.format(len(int_shape(output)))))\n-    # If the channels are not in the last axis, move them to be there:\n-    if axis != -1 and axis != output_dimensions[-1]:\n-        permutation = output_dimensions[:axis]\n-        permutation += output_dimensions[axis + 1:] + [axis]\n-        output = permute_dimensions(output, permutation)\n-        target = permute_dimensions(target, permutation)\n-    if from_logits:\n-        output = T.nnet.softmax(output)\n-    else:\n-        # scale preds so that the class probas of each sample sum to 1\n-        output /= output.sum(axis=-1, keepdims=True)\n-    # avoid numerical instability with _EPSILON clipping\n-    output = T.clip(output, epsilon(), 1.0 - epsilon())\n-    return T.nnet.categorical_crossentropy(output, target)\n-\n-\n-def sparse_categorical_crossentropy(target, output, from_logits=False, axis=-1):\n-    output_dimensions = list(range(len(int_shape(output))))\n-    if axis != -1 and axis not in output_dimensions:\n-        raise ValueError(\n-            '{}{}{}'.format(\n-                'Unexpected channels axis {}. '.format(axis),\n-                'Expected to be -1 or one of the axes of `output`, ',\n-                'which has {} dimensions.'.format(len(int_shape(output)))))\n-    # If the channels are not in the last axis, move them to be there:\n-    if axis != -1 and axis != output_dimensions[-1]:\n-        permutation = output_dimensions[:axis]\n-        permutation += output_dimensions[axis + 1:] + [axis]\n-        output = permute_dimensions(output, permutation)\n-        target = permute_dimensions(target, permutation)\n-    target = T.cast(T.flatten(target), 'int32')\n-    target = T.extra_ops.to_one_hot(target, nb_class=output.shape[-1])\n-    target = reshape(target, shape(output))\n-    return categorical_crossentropy(target, output, from_logits, axis=-1)\n-\n-\n-def binary_crossentropy(target, output, from_logits=False):\n-    if from_logits:\n-        output = T.nnet.sigmoid(output)\n-    # avoid numerical instability with _EPSILON clipping\n-    output = T.clip(output, epsilon(), 1.0 - epsilon())\n-    return T.nnet.binary_crossentropy(output, target)\n-\n-\n-def sigmoid(x):\n-    return T.nnet.sigmoid(x)\n-\n-\n-def hard_sigmoid(x):\n-    return T.nnet.hard_sigmoid(x)\n-\n-\n-def tanh(x):\n-    return T.tanh(x)\n-\n-\n-def dropout(x, level, noise_shape=None, seed=None):\n-    \"\"\"Sets entries in `x` to zero at random,\n-    while scaling the entire tensor.\n-\n-    # Arguments\n-        x: tensor\n-        level: fraction of the entries in the tensor\n-            that will be set to 0.\n-        noise_shape: shape for randomly generated keep/drop flags,\n-            must be broadcastable to the shape of `x`\n-        seed: random seed to ensure determinism.\n-    \"\"\"\n-    if level < 0. or level >= 1:\n-        raise ValueError('Dropout level must be in interval [0, 1[.')\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    if isinstance(noise_shape, list):\n-        noise_shape = tuple(noise_shape)\n-\n-    rng = RandomStreams(seed=seed)\n-    retain_prob = 1. - level\n-\n-    if noise_shape is None:\n-        random_tensor = rng.binomial(x.shape, p=retain_prob, dtype=x.dtype)\n-    else:\n-        random_tensor = rng.binomial(noise_shape, p=retain_prob, dtype=x.dtype)\n-        random_tensor = T.patternbroadcast(random_tensor,\n-                                           [dim == 1 for dim in noise_shape])\n-    x *= random_tensor\n-    x /= retain_prob\n-    return x\n-\n-\n-def l2_normalize(x, axis=None):\n-    square_sum = T.sum(T.square(x), axis=axis, keepdims=True)\n-    norm = T.sqrt(T.maximum(square_sum, epsilon()))\n-    return x / norm\n-\n-\n-def in_top_k(predictions, targets, k):\n-    \"\"\"Returns whether the `targets` are in the top `k` `predictions`.\n-\n-    # Arguments\n-        predictions: A tensor of shape `(batch_size, classes)` and type `float32`.\n-        targets: A 1D tensor of length `batch_size` and type `int32` or `int64`.\n-        k: An `int`, number of top elements to consider.\n-\n-    # Returns\n-        A 1D tensor of length `batch_size` and type `bool`.\n-        `output[i]` is `True` if `predictions[i, targets[i]]` is within top-`k`\n-        values of `predictions[i]`.\n-    \"\"\"\n-    # handle k < 1 and k >= predictions.shape[1] cases to match TF behavior\n-    if k < 1:\n-        # dtype='bool' is only available since Theano 0.9.0\n-        try:\n-            return T.zeros_like(targets, dtype='bool')\n-        except TypeError:\n-            return T.zeros_like(targets, dtype='int8')\n-\n-    if k >= int_shape(predictions)[1]:\n-        try:\n-            return T.ones_like(targets, dtype='bool')\n-        except TypeError:\n-            return T.ones_like(targets, dtype='int8')\n-\n-    predictions_k = T.sort(predictions)[:, -k]\n-    targets_values = predictions[T.arange(targets.shape[0]), targets]\n-    return T.ge(targets_values, predictions_k)\n-\n-\n-# CONVOLUTIONS\n-\n-def _preprocess_conv2d_input(x, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH input shape: (samples, input_depth, rows, cols)\n-        # TF input shape: (samples, rows, cols, input_depth)\n-        x = x.dimshuffle((0, 3, 1, 2))\n-    return x\n-\n-\n-def _preprocess_conv3d_input(x, data_format):\n-    if data_format == 'channels_last':\n-        # TF uses the last dimension as channel dimension,\n-        # instead of the 2nd one.\n-        # TH input shape: (samples, input_depth, rows, cols, slices)\n-        # TF input shape: (samples, rows, cols, slices, input_depth)\n-        x = x.dimshuffle((0, 4, 1, 2, 3))\n-    return x\n-\n-\n-def _preprocess_conv2d_kernel(kernel, data_format):\n-    # As of Keras 2.0.0, all kernels are normalized\n-    # on the format `(rows, cols, input_depth, depth)`,\n-    # independently of `data_format`.\n-    # Theano expects `(depth, input_depth, rows, cols)`.\n-    kernel = kernel.dimshuffle((3, 2, 0, 1))\n-    return kernel\n-\n-\n-def _preprocess_conv2d_depthwise_kernel(kernel, kernel_shape, data_format):\n-    # As of Keras 2.0.0, all kernels are normalized\n-    # on the format `(rows, cols, input_depth, depth)`,\n-    # independently of `data_format`.\n-    # Theano expects `(input_depth * depth, 1, rows, cols)`\n-    # for depthwise convolution.\n-    kernel = kernel[::-1, ::-1, :, :]\n-    kernel = kernel.dimshuffle((2, 3, 0, 1))\n-    kernel = reshape(kernel, kernel_shape)\n-    return kernel\n-\n-\n-def _preprocess_conv3d_kernel(kernel, data_format):\n-    # As of Keras 2.0.0, all kernels are normalized\n-    # on the format `(space, input_depth, depth)`,\n-    # independently of `data_format`.\n-    # Theano expects `(depth, input_depth, space)`.\n-    kernel = kernel.dimshuffle((4, 3, 0, 1, 2))\n-    return kernel\n-\n-\n-def _preprocess_padding(padding):\n-    if padding == 'same':\n-        th_padding = 'half'\n-    elif padding == 'valid':\n-        th_padding = 'valid'\n-    elif padding == 'full':\n-        th_padding = 'full'\n-    else:\n-        raise ValueError('Border mode not supported:', str(padding))\n-    return th_padding\n-\n-\n-def _preprocess_conv2d_image_shape(image_shape, data_format):\n-    # Theano might not accept long type\n-    def int_or_none(value):\n-        try:\n-            return int(value)\n-        except TypeError:\n-            return None\n-    if data_format == 'channels_last':\n-        if image_shape:\n-            image_shape = transpose_shape(image_shape, 'channels_first',\n-                                          spatial_axes=(1, 2))\n-    if image_shape is not None:\n-        image_shape = tuple(int_or_none(v) for v in image_shape)\n-    return image_shape\n-\n-\n-def _preprocess_conv3d_volume_shape(volume_shape, data_format):\n-    # Theano might not accept long type\n-    def int_or_none(value):\n-        try:\n-            return int(value)\n-        except TypeError:\n-            return None\n-    if data_format == 'channels_last':\n-        if volume_shape:\n-            volume_shape = (volume_shape[0], volume_shape[4],\n-                            volume_shape[1], volume_shape[2], volume_shape[3])\n-    if volume_shape is not None:\n-        volume_shape = tuple(int_or_none(v) for v in volume_shape)\n-    return volume_shape\n-\n-\n-def _preprocess_conv2d_filter_shape(filter_shape, data_format):\n-    # Theano might not accept long type\n-    def int_or_none(value):\n-        try:\n-            return int(value)\n-        except TypeError:\n-            return None\n-    if filter_shape:\n-        filter_shape = (filter_shape[3], filter_shape[2],\n-                        filter_shape[0], filter_shape[1])\n-    if filter_shape is not None:\n-        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n-    return filter_shape\n-\n-\n-def _preprocess_conv2d_depthwise_filter_shape(filter_shape, data_format):\n-    # Theano might not accept long type\n-    def int_or_none(value):\n-        try:\n-            return int(value)\n-        except TypeError:\n-            return None\n-    if filter_shape:\n-        filter_shape = (filter_shape[3] * filter_shape[2], 1,\n-                        filter_shape[0], filter_shape[1])\n-    if filter_shape is not None:\n-        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n-    return filter_shape\n-\n-\n-def _preprocess_conv3d_filter_shape(filter_shape, data_format):\n-    # Theano might not accept long type\n-    def int_or_none(value):\n-        try:\n-            return int(value)\n-        except TypeError:\n-            return None\n-    if filter_shape:\n-        filter_shape = (filter_shape[4], filter_shape[3],\n-                        filter_shape[0], filter_shape[1], filter_shape[2])\n-    if filter_shape is not None:\n-        filter_shape = tuple(int_or_none(v) for v in filter_shape)\n-    return filter_shape\n-\n-\n-def _postprocess_conv2d_output(conv_out, x,\n-                               padding, kernel_shape,\n-                               strides, data_format):\n-    if padding == 'same':\n-        if kernel_shape[2] % 2 == 0:\n-            i = (x.shape[2] + strides[0] - 1) // strides[0]\n-            conv_out = conv_out[:, :, :i, :]\n-        if kernel_shape[3] % 2 == 0:\n-            i = (x.shape[3] + strides[1] - 1) // strides[1]\n-            conv_out = conv_out[:, :, :, :i]\n-    if data_format == 'channels_last':\n-        conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n-    return conv_out\n-\n-\n-def _postprocess_conv3d_output(conv_out, x,\n-                               padding, kernel_shape,\n-                               strides, data_format):\n-    if padding == 'same':\n-        if kernel_shape[2] % 2 == 0:\n-            i = (x.shape[2] + strides[0] - 1) // strides[0]\n-            conv_out = conv_out[:, :, :i, :, :]\n-        if kernel_shape[3] % 2 == 0:\n-            i = (x.shape[3] + strides[1] - 1) // strides[1]\n-            conv_out = conv_out[:, :, :, :i, :]\n-        if kernel_shape[4] % 2 == 0:\n-            i = (x.shape[4] + strides[2] - 1) // strides[2]\n-            conv_out = conv_out[:, :, :, :, :i]\n-    if data_format == 'channels_last':\n-        conv_out = conv_out.dimshuffle((0, 2, 3, 4, 1))\n-    return conv_out\n-\n-\n-def conv1d(x, kernel, strides=1, padding='valid',\n-           data_format=None, dilation_rate=1):\n-    \"\"\"1D convolution.\n-\n-    # Arguments\n-        kernel: kernel tensor.\n-        strides: stride integer.\n-        padding: string, `\"same\"`, `\"causal\"` or `\"valid\"`.\n-        data_format: string, one of \"channels_last\", \"channels_first\"\n-        dilation_rate: integer.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    kernel_shape = int_shape(kernel)\n-    if padding == 'causal':\n-        # causal (dilated) convolution:\n-        if not kernel_shape:\n-            raise AttributeError('Causal padding requires kernel._keras_shape set.')\n-        left_pad = dilation_rate * (kernel_shape[0] - 1)\n-        x = temporal_padding(x, (left_pad, 0))\n-        padding = 'valid'\n-    shape = int_shape(x)\n-    if data_format == 'channels_last':\n-        # original shape: (batch, length, input_dim)\n-        # add dim to x to have (batch, length, 1, input_dim)\n-        x = expand_dims(x, 2)\n-        # update x._keras_shape\n-        if shape is not None:\n-            x._keras_shape = (shape[0], shape[1], 1, shape[2])\n-    else:\n-        # original shape: (batch, input_dim, length)\n-        # add dim to x to have (batch, input_dim, length, 1)\n-        x = expand_dims(x, 3)\n-        # update x._keras_shape\n-        if shape is not None:\n-            x._keras_shape = (shape[0], shape[1], shape[2], 1)\n-    # update dilation rate, strides\n-    dilation_rate = (dilation_rate, 1)\n-    strides = (strides, 1)\n-    # add dim to kernel (always same format independently of data_format)\n-    # i.e. (rows, 1, input_depth, depth)\n-    kernel = expand_dims(kernel, 1)\n-    output = conv2d(x, kernel,\n-                    strides=strides, padding=padding,\n-                    data_format=data_format, dilation_rate=dilation_rate)\n-    # remove added dim\n-    if data_format == 'channels_last':\n-        output = squeeze(output, 2)\n-    else:\n-        output = squeeze(output, 3)\n-    return output\n-\n-\n-def conv2d(x, kernel, strides=(1, 1), padding='valid',\n-           data_format=None, dilation_rate=(1, 1)):\n-    \"\"\"2D convolution.\n-\n-    # Arguments\n-        kernel: kernel tensor.\n-        strides: strides tuple.\n-        padding: string, \"same\" or \"valid\".\n-        data_format: \"channels_last\" or \"channels_first\".\n-            Whether to use Theano or TensorFlow data format\n-        in inputs/kernels/outputs.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    kernel_shape = int_shape(kernel)\n-    if kernel_shape is None:\n-        kernel_shape = kernel.eval().shape  # in case of a shared variable\n-    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n-    conv_out = T.nnet.conv2d(x, kernel,\n-                             border_mode=th_padding,\n-                             subsample=strides,\n-                             input_shape=image_shape,\n-                             filter_shape=kernel_shape,\n-                             filter_dilation=dilation_rate)\n-    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n-                                          kernel_shape, strides, data_format)\n-    return conv_out\n-\n-\n-def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n-                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n-    \"\"\"2D deconvolution (transposed convolution).\n-\n-    # Arguments\n-        kernel: kernel tensor.\n-        output_shape: desired dimensions of output.\n-        strides: strides tuple.\n-        padding: string, \"same\" or \"valid\".\n-        data_format: \"channels_last\" or \"channels_first\".\n-            Whether to use Theano or TensorFlow data format\n-            in inputs/kernels/outputs.\n-        dilation_rate: tuple of 2 integers.\n-\n-    # Raises\n-        ValueError: if using an even kernel size with padding 'same'.\n-    \"\"\"\n-    flip_filters = False\n-    data_format = normalize_data_format(data_format)\n-\n-    if data_format == 'channels_last':\n-        output_shape = (output_shape[0],\n-                        output_shape[3],\n-                        output_shape[1],\n-                        output_shape[2])\n-\n-    kernel_shape = int_shape(kernel)\n-    if kernel_shape is None:\n-        kernel_shape = kernel.eval().shape  # in case of a shared variable\n-\n-    if padding == 'same' and kernel_shape[0] % 2 == 0:\n-        raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n-                         'even kernel sizes are not supported with Theano. '\n-                         'You can set `kernel_size` to an odd number.')\n-\n-    kernel_shape = _preprocess_conv2d_filter_shape(kernel_shape, data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    kernel = _preprocess_conv2d_kernel(kernel, data_format)\n-\n-    th_padding = _preprocess_padding(padding)\n-    op = T.nnet.abstract_conv.AbstractConv2d_gradInputs(\n-        imshp=None,\n-        kshp=kernel_shape,\n-        subsample=strides,\n-        border_mode=th_padding,\n-        filter_flip=not flip_filters,\n-        filter_dilation=dilation_rate)\n-    conv_out = op(kernel, x, output_shape[2:])\n-    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n-                                          kernel_shape, strides, data_format)\n-    return conv_out\n-\n-\n-def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n-                     padding='valid', data_format=None, dilation_rate=1):\n-    \"\"\"1D convolution with separable filters.\n-\n-    # Arguments\n-        x: input tensor\n-        depthwise_kernel: convolution kernel for the depthwise convolution.\n-        pointwise_kernel: kernel for the 1x1 convolution.\n-        strides: strides integer.\n-        padding: string, `\"same\"` or `\"valid\"`.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-        dilation_rate: integer dilation rate.\n-\n-    # Returns\n-        Output tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is neither `\"channels_last\"` or\n-        `\"channels_first\"`.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-    if isinstance(strides, int):\n-        strides = (strides,)\n-    if isinstance(dilation_rate, int):\n-        dilation_rate = (dilation_rate,)\n-\n-    if data_format == 'channels_last':\n-        spatial_start_dim = 2\n-    else:\n-        spatial_start_dim = 3\n-    x = expand_dims(x, spatial_start_dim)\n-    depthwise_kernel = expand_dims(depthwise_kernel, 1)\n-    pointwise_kernel = expand_dims(pointwise_kernel, 1)\n-    strides = strides + (1,)\n-    dilation_rate = dilation_rate + (1,)\n-\n-    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    depthwise_kernel_shape = int_shape(depthwise_kernel)\n-    if depthwise_kernel_shape is None:\n-        # in case of a shared variable\n-        depthwise_kernel_shape = depthwise_kernel.eval().shape\n-    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n-        depthwise_kernel_shape, data_format)\n-    pointwise_kernel_shape = int_shape(pointwise_kernel)\n-    if pointwise_kernel_shape is None:\n-        # in case of a shared variable\n-        pointwise_kernel_shape = pointwise_kernel.eval().shape\n-    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(\n-        pointwise_kernel_shape, data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n-        depthwise_kernel, depthwise_kernel_shape, data_format)\n-    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n-    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n-                             border_mode=th_padding,\n-                             subsample=strides,\n-                             input_shape=image_shape,\n-                             filter_shape=depthwise_kernel_shape,\n-                             filter_dilation=dilation_rate,\n-                             num_groups=image_shape[1])\n-    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n-                             border_mode=th_padding,\n-                             subsample=(1, 1),\n-                             input_shape=None,\n-                             filter_shape=pointwise_kernel_shape,\n-                             filter_dilation=dilation_rate)\n-    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n-                                          pointwise_kernel_shape,\n-                                          strides, data_format)\n-    conv_out = squeeze(conv_out, spatial_start_dim)\n-    return conv_out\n-\n-\n-def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n-                     padding='valid', data_format=None, dilation_rate=(1, 1)):\n-    \"\"\"2D convolution with separable filters.\n-\n-    # Arguments\n-        x: input tensor\n-        depthwise_kernel: convolution kernel for the depthwise convolution.\n-        pointwise_kernel: kernel for the 1x1 convolution.\n-        strides: strides tuple (length 2).\n-        padding: string, `\"same\"` or `\"valid\"`.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-        dilation_rate: tuple of integers,\n-            dilation rates for the separable convolution.\n-\n-    # Returns\n-        Output tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is neither `\"channels_last\"` or\n-        `\"channels_first\"`.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    depthwise_kernel_shape = int_shape(depthwise_kernel)\n-    if depthwise_kernel_shape is None:\n-        # in case of a shared variable\n-        depthwise_kernel_shape = depthwise_kernel.eval().shape\n-    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n-        depthwise_kernel_shape, data_format)\n-    pointwise_kernel_shape = int_shape(pointwise_kernel)\n-    if pointwise_kernel_shape is None:\n-        # in case of a shared variable\n-        pointwise_kernel_shape = pointwise_kernel.eval().shape\n-    pointwise_kernel_shape = _preprocess_conv2d_filter_shape(\n-        pointwise_kernel_shape, data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n-        depthwise_kernel, depthwise_kernel_shape, data_format)\n-    pointwise_kernel = _preprocess_conv2d_kernel(pointwise_kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n-    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n-                             border_mode=th_padding,\n-                             subsample=strides,\n-                             input_shape=image_shape,\n-                             filter_shape=depthwise_kernel_shape,\n-                             filter_dilation=dilation_rate,\n-                             num_groups=image_shape[1])\n-    conv_out = T.nnet.conv2d(conv_out, pointwise_kernel,\n-                             border_mode=th_padding,\n-                             subsample=(1, 1),\n-                             input_shape=None,\n-                             filter_shape=pointwise_kernel_shape,\n-                             filter_dilation=dilation_rate)\n-    conv_out = _postprocess_conv2d_output(conv_out, x, padding,\n-                                          pointwise_kernel_shape,\n-                                          strides, data_format)\n-    return conv_out\n-\n-\n-def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n-                     data_format=None, dilation_rate=(1, 1)):\n-    \"\"\"2D convolution with separable filters.\n-\n-    # Arguments\n-        x: input tensor\n-        depthwise_kernel: convolution kernel for the depthwise convolution.\n-        strides: strides tuple (length 2).\n-        padding: string, `\"same\"` or `\"valid\"`.\n-        data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n-        dilation_rate: tuple of integers,\n-            dilation rates for the separable convolution.\n-\n-    # Returns\n-        Output tensor.\n-\n-    # Raises\n-        ValueError: if `data_format` is neither `\"channels_last\"` or\n-        `\"channels_first\"`.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    image_shape = _preprocess_conv2d_image_shape(int_shape(x), data_format)\n-    depthwise_kernel_shape = int_shape(depthwise_kernel)\n-    if depthwise_kernel_shape is None:\n-        # in case of a shared variable\n-        depthwise_kernel_shape = depthwise_kernel.eval().shape\n-    depthwise_kernel_shape = _preprocess_conv2d_depthwise_filter_shape(\n-        depthwise_kernel_shape, data_format)\n-\n-    x = _preprocess_conv2d_input(x, data_format)\n-    depthwise_kernel = _preprocess_conv2d_depthwise_kernel(\n-        depthwise_kernel, depthwise_kernel_shape, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n-    conv_out = T.nnet.conv2d(x, depthwise_kernel,\n-                             border_mode=th_padding,\n-                             subsample=strides,\n-                             input_shape=image_shape,\n-                             filter_shape=depthwise_kernel_shape,\n-                             filter_dilation=dilation_rate,\n-                             num_groups=image_shape[1])\n-    conv_out = _postprocess_conv2d_output(\n-        conv_out, x, padding, depthwise_kernel_shape, strides, data_format)\n-    return conv_out\n-\n-\n-def conv3d(x, kernel, strides=(1, 1, 1),\n-           padding='valid', data_format=None,\n-           dilation_rate=(1, 1, 1)):\n-    \"\"\"3D convolution.\n-\n-    # Arguments\n-        kernel: kernel tensor.\n-        strides: strides tuple.\n-        padding: string, \"same\" or \"valid\".\n-        data_format: \"channels_last\" or \"channels_first\".\n-            Whether to use Theano or TensorFlow data format\n-        in inputs/kernels/outputs.\n-    \"\"\"\n-    data_format = normalize_data_format(data_format)\n-\n-    volume_shape = _preprocess_conv3d_volume_shape(int_shape(x), data_format)\n-    kernel_shape = int_shape(kernel)\n-    if kernel_shape is None:\n-        kernel_shape = kernel.eval().shape  # in case of a shared variable\n-    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n-\n-    x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-    th_padding = _preprocess_padding(padding)\n-\n-    conv_out = T.nnet.conv3d(x, kernel,\n-                             border_mode=th_padding,\n-                             subsample=strides,\n-                             input_shape=volume_shape,\n-                             filter_shape=kernel_shape,\n-                             filter_dilation=dilation_rate)\n-    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n-                                          kernel_shape, strides, data_format)\n-    return conv_out\n-\n-\n-def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n-                     padding='valid', data_format=None):\n-    \"\"\"3D deconvolution (transposed convolution).\n-\n-    # Arguments\n-        kernel: kernel tensor.\n-        output_shape: desired dimensions of output.\n-        strides: strides tuple.\n-        padding: string, \"same\" or \"valid\".\n-        data_format: \"channels_last\" or \"channels_first\".\n-            Whether to use Theano or TensorFlow data format\n-        in inputs/kernels/outputs.\n-\n-    # Raises\n-        ValueError: if using an even kernel size with padding 'same'.\n-    \"\"\"\n-    flip_filters = False\n-    data_format = normalize_data_format(data_format)\n-\n-    if data_format == 'channels_last':\n-        output_shape = (output_shape[0],\n-                        output_shape[4],\n-                        output_shape[1],\n-                        output_shape[2],\n-                        output_shape[3])\n-\n-    kernel_shape = int_shape(kernel)\n-    if kernel_shape is None:\n-        kernel_shape = kernel.eval().shape  # in case of a shared variable\n-\n-    if padding == 'same' and kernel_shape[0] % 2 == 0:\n-        raise ValueError('In `Conv3DTranspose`, with padding mode `same`, '\n-                         'even kernel sizes are not supported with Theano. '\n-                         'You can set `kernel_size` to an odd number.')\n-\n-    kernel_shape = _preprocess_conv3d_filter_shape(kernel_shape, data_format)\n-\n-    x = _preprocess_conv3d_input(x, data_format)\n-    kernel = _preprocess_conv3d_kernel(kernel, data_format)\n-\n-    th_padding = _preprocess_padding(padding)\n-    op = T.nnet.abstract_conv.AbstractConv3d_gradInputs(imshp=None,\n-                                                        kshp=kernel_shape,\n-                                                        subsample=strides,\n-                                                        border_mode=th_padding,\n-                                                        filter_flip=not flip_filters)\n-    conv_out = op(kernel, x, output_shape[2:])\n-    conv_out = _postprocess_conv3d_output(conv_out, x, padding,\n-                                          kernel_shape, strides, data_format)\n-    return conv_out\n-\n-\n-def pool2d(x, pool_size, strides=(1, 1), padding='valid',\n-           data_format=None, pool_mode='max'):\n-    data_format = normalize_data_format(data_format)\n-\n-    assert pool_size[0] >= 1 and pool_size[1] >= 1\n-\n-    if padding == 'same':\n-        odd_pad_w = pool_size[0] > 2 and pool_size[0] % 2 == 1\n-        w_pad = pool_size[0] - 2 if odd_pad_w else pool_size[0] - 1\n-        odd_pad_h = pool_size[1] > 2 and pool_size[1] % 2 == 1\n-        h_pad = pool_size[1] - 2 if odd_pad_h else pool_size[1] - 1\n-        pad = (w_pad, h_pad)\n-    elif padding == 'valid':\n-        pad = (0, 0)\n-    else:\n-        raise ValueError('Invalid border mode:', padding)\n-\n-    if data_format == 'channels_last':\n-        x = x.dimshuffle((0, 3, 1, 2))\n-\n-    if pool_mode == 'max':\n-        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n-                                ignore_border=True,\n-                                pad=pad,\n-                                mode='max')\n-    elif pool_mode == 'avg':\n-        pool_out = pool.pool_2d(x, ws=pool_size, stride=strides,\n-                                ignore_border=True,\n-                                pad=pad,\n-                                mode='average_exc_pad')\n-    else:\n-        raise ValueError('Invalid pooling mode:', pool_mode)\n-    if padding == 'same':\n-        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n-        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n-        pool_out = pool_out[:, :,\n-                            : expected_width,\n-                            : expected_height]\n-\n-    if data_format == 'channels_last':\n-        pool_out = pool_out.dimshuffle((0, 2, 3, 1))\n-    return pool_out\n-\n-\n-def pool3d(x, pool_size, strides=(1, 1, 1), padding='valid',\n-           data_format=None, pool_mode='max'):\n-    data_format = normalize_data_format(data_format)\n-\n-    if padding == 'same':\n-        w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n-        h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n-        d_pad = pool_size[2] - 2 if pool_size[2] % 2 == 1 else pool_size[2] - 1\n-        pad = (w_pad, h_pad, d_pad)\n-    elif padding == 'valid':\n-        pad = (0, 0, 0)\n-    else:\n-        raise ValueError('Invalid padding:', padding)\n-\n-    if data_format == 'channels_last':\n-        x = x.dimshuffle((0, 4, 1, 2, 3))\n-\n-    if pool_mode == 'max':\n-        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n-                                ignore_border=True,\n-                                pad=pad,\n-                                mode='max')\n-    elif pool_mode == 'avg':\n-        pool_out = pool.pool_3d(x, ws=pool_size, stride=strides,\n-                                ignore_border=True,\n-                                pad=pad,\n-                                mode='average_exc_pad')\n-    else:\n-        raise ValueError('Invalid pooling mode:', pool_mode)\n-\n-    if padding == 'same':\n-        expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n-        expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n-        expected_depth = (x.shape[4] + strides[2] - 1) // strides[2]\n-\n-        pool_out = pool_out[:, :,\n-                            : expected_width,\n-                            : expected_height,\n-                            : expected_depth]\n-\n-    if data_format == 'channels_last':\n-        pool_out = pool_out.dimshuffle((0, 2, 3, 4, 1))\n-    return pool_out\n-\n-\n-def bias_add(x, bias, data_format=None):\n-    data_format = normalize_data_format(data_format)\n-    if ndim(bias) != 1 and ndim(bias) != ndim(x) - 1:\n-        raise ValueError('Unexpected bias dimensions %d, '\n-                         'expect to be 1 or %d dimensions'\n-                         % (ndim(bias), ndim(x) - 1))\n-    bias_shape = tuple(bias.shape)\n-    if ndim(x) == 5:\n-        if data_format == 'channels_first':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, bias_shape[0], 1, 1, 1))\n-            else:\n-                x += reshape(bias, (1, bias_shape[3]) + bias_shape[:3])\n-        elif data_format == 'channels_last':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, 1, 1, 1, bias_shape[0]))\n-            else:\n-                x += reshape(bias, (1,) + bias_shape)\n-    elif ndim(x) == 4:\n-        if data_format == 'channels_first':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, bias_shape[0], 1, 1))\n-            else:\n-                x += reshape(bias, (1, bias_shape[2]) + bias_shape[:2])\n-        elif data_format == 'channels_last':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, 1, 1, bias_shape[0]))\n-            else:\n-                x += reshape(bias, (1,) + bias_shape)\n-    elif ndim(x) == 3:\n-        if data_format == 'channels_first':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, bias_shape[0], 1))\n-            else:\n-                x += reshape(bias, (1, bias_shape[1], bias_shape[0]))\n-        elif data_format == 'channels_last':\n-            if ndim(bias) == 1:\n-                x += reshape(bias, (1, 1, bias_shape[0]))\n-            else:\n-                x += reshape(bias, (1,) + bias_shape)\n-    else:\n-        x += bias\n-    return x\n-\n-\n-# RANDOMNESS\n-\n-\n-def random_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    rng = RandomStreams(seed=seed)\n-    return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n-\n-\n-def random_uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    rng = RandomStreams(seed=seed)\n-    return rng.uniform(shape, low=minval, high=maxval, dtype=dtype)\n-\n-\n-def random_binomial(shape, p=0.0, dtype=None, seed=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    rng = RandomStreams(seed=seed)\n-    return rng.binomial(shape, p=p, dtype=dtype)\n-\n-\n-def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    if dtype is None:\n-        dtype = floatx()\n-    if seed is None:\n-        seed = np.random.randint(1, 10e6)\n-    rng = RandomStreams(seed=seed)\n-\n-    try:\n-        return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype,\n-                          truncate=True)\n-    except TypeError:\n-        normal_t = rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n-        # Poor man's truncated normal: we literally clip the tensor\n-        return T.clip(normal_t, mean - 2 * stddev, mean + 2 * stddev)\n-\n-\n-# Theano implementation of CTC\n-# Used with permission from Shawn Tan\n-# https://github.com/shawntan/\n-# Note that TensorFlow's native CTC code is significantly\n-# faster than this\n-\n-\n-def ctc_interleave_blanks(Y):\n-    Y_ = T.alloc(-1, Y.shape[0] * 2 + 1)\n-    Y_ = T.set_subtensor(Y_[T.arange(Y.shape[0]) * 2 + 1], Y)\n-    return Y_\n-\n-\n-def ctc_create_skip_idxs(Y):\n-    skip_idxs = T.arange((Y.shape[0] - 3) // 2) * 2 + 1\n-    non_repeats = T.neq(Y[skip_idxs], Y[skip_idxs + 2])\n-    return skip_idxs[non_repeats.nonzero()]\n-\n-\n-def ctc_update_log_p(skip_idxs, zeros, active, log_p_curr, log_p_prev):\n-    active_skip_idxs = skip_idxs[(skip_idxs < active).nonzero()]\n-    active_next = T.cast(T.minimum(\n-        T.maximum(\n-            active + 1,\n-            T.max(T.concatenate([active_skip_idxs, [-1]])) + 2 + 1\n-        ), log_p_curr.shape[0]), 'int32')\n-\n-    common_factor = T.max(log_p_prev[:active])\n-    p_prev = T.exp(log_p_prev[:active] - common_factor)\n-    _p_prev = zeros[:active_next]\n-    # copy over\n-    _p_prev = T.set_subtensor(_p_prev[:active], p_prev)\n-    # previous transitions\n-    _p_prev = T.inc_subtensor(_p_prev[1:], _p_prev[:-1])\n-    # skip transitions\n-    _p_prev = T.inc_subtensor(\n-        _p_prev[active_skip_idxs + 2], p_prev[active_skip_idxs])\n-    updated_log_p_prev = T.log(_p_prev) + common_factor\n-\n-    log_p_next = T.set_subtensor(\n-        zeros[:active_next],\n-        log_p_curr[:active_next] + updated_log_p_prev\n-    )\n-    return active_next, log_p_next\n-\n-\n-def ctc_path_probs(predict, Y, alpha=1e-4):\n-    smoothed = (1 - alpha) * predict[:, Y] + alpha * np.float32(1.) / Y.shape[0]\n-    L = T.log(smoothed)\n-    zeros = T.zeros_like(L[0])\n-    log_first = zeros\n-\n-    f_skip_idxs = ctc_create_skip_idxs(Y)\n-    # there should be a shortcut to calculating this\n-    b_skip_idxs = ctc_create_skip_idxs(Y[::-1])\n-\n-    def step(log_f_curr, log_b_curr, f_active, log_f_prev, b_active, log_b_prev):\n-        f_active_next, log_f_next = ctc_update_log_p(\n-            f_skip_idxs, zeros, f_active, log_f_curr, log_f_prev)\n-        b_active_next, log_b_next = ctc_update_log_p(\n-            b_skip_idxs, zeros, b_active, log_b_curr, log_b_prev)\n-        return f_active_next, log_f_next, b_active_next, log_b_next\n-\n-    [f_active, log_f_probs, b_active, log_b_probs], _ = theano.scan(\n-        step,\n-        sequences=[L, L[::-1, ::-1]],\n-        outputs_info=[np.int32(1), log_first, np.int32(1), log_first])\n-\n-    idxs = T.arange(L.shape[1]).dimshuffle('x', 0)\n-    mask = ((idxs < f_active.dimshuffle(0, 'x')) &\n-            (idxs < b_active.dimshuffle(0, 'x'))[::-1, ::-1])\n-    log_probs = log_f_probs + log_b_probs[::-1, ::-1] - L\n-    return log_probs, mask\n-\n-\n-def ctc_cost(predict, Y):\n-    log_probs, mask = ctc_path_probs(predict, ctc_interleave_blanks(Y))\n-    common_factor = T.max(log_probs)\n-    total_log_prob = T.log(T.sum(T.exp(log_probs - common_factor)[mask.nonzero()]))\n-    total_log_prob = total_log_prob + common_factor\n-    return -total_log_prob\n-\n-\n-# batchifies original CTC code\n-def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n-    \"\"\"Runs CTC loss algorithm on each batch element.\n-\n-    # Arguments\n-        y_true: tensor (samples, max_string_length) containing the truth labels\n-        y_pred: tensor (samples, time_steps, num_categories) containing the\n-                prediction, or output of the softmax\n-        input_length: tensor (samples,1) containing the sequence length for\n-                each batch item in y_pred\n-        label_length: tensor (samples,1) containing the sequence length for\n-                each batch item in y_true\n-\n-    # Returns\n-        Tensor with shape (samples,1) containing the\n-            CTC loss of each element\n-    \"\"\"\n-\n-    def ctc_step(y_true_step, y_pred_step, input_length_step, label_length_step):\n-        y_pred_step = y_pred_step[0: input_length_step[0]]\n-        y_true_step = y_true_step[0:label_length_step[0]]\n-        return ctc_cost(y_pred_step, y_true_step)\n-\n-    ret, _ = theano.scan(\n-        fn=ctc_step,\n-        outputs_info=None,\n-        sequences=[y_true, y_pred, input_length, label_length]\n-    )\n-\n-    ret = ret.dimshuffle('x', 0)\n-    return ret\n-\n-\n-# HIGH ORDER FUNCTIONS\n-\n-def map_fn(fn, elems, name=None, dtype=None):\n-    \"\"\"Map the function fn over the elements elems and return the outputs.\n-\n-    # Arguments\n-        fn: Callable that will be called upon each element in elems\n-        elems: tensor, at least 2 dimensional\n-        name: A string name for the map node in the graph\n-\n-    # Returns\n-        Tensor with first dimension equal to the elems and second depending on\n-        fn\n-    \"\"\"\n-    return theano.map(fn, elems, name=name)[0]\n-\n-\n-def foldl(fn, elems, initializer=None, name=None):\n-    \"\"\"Reduce elems using fn to combine them from left to right.\n-\n-    # Arguments\n-        fn: Callable that will be called upon each element in elems and an\n-            accumulator, for instance lambda acc, x: acc + x\n-        elems: tensor\n-        initializer: The first value used (elems[0] in case of None)\n-        name: A string name for the foldl node in the graph\n-\n-    # Returns\n-        Same type and shape as initializer\n-    \"\"\"\n-    if initializer is None:\n-        initializer = elems[0]\n-        elems = elems[1:]\n-\n-    # We need to change the order of the arguments because theano accepts x as\n-    # first parameter and accumulator as second\n-    return theano.foldl(lambda x, acc: fn(acc, x),\n-                        elems, initializer, name=name)[0]\n-\n-\n-def foldr(fn, elems, initializer=None, name=None):\n-    \"\"\"Reduce elems using fn to combine them from right to left.\n-\n-    # Arguments\n-        fn: Callable that will be called upon each element in elems and an\n-            accumulator, for instance lambda acc, x: acc + x\n-        elems: tensor\n-        initializer: The first value used (elems[-1] in case of None)\n-        name: A string name for the foldr node in the graph\n-\n-    # Returns\n-        Same type and shape as initializer\n-    \"\"\"\n-    if initializer is None:\n-        initializer = elems[-1]\n-        elems = elems[:-1]\n-\n-    # We need to change the order of the arguments because theano accepts x as\n-    # first parameter and accumulator as second\n-    return theano.foldr(lambda x, acc: fn(acc, x),\n-                        elems, initializer, name=name)[0]\n-\n-\n-def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    stride = strides[0]\n-    kernel_shape = int_shape(kernel)\n-    output_length, feature_dim, filters = kernel_shape\n-\n-    xs = []\n-    for i in range(output_length):\n-        slice_length = py_slice(i * stride,\n-                                i * stride + kernel_size[0])\n-        xs.append(reshape(inputs[:, slice_length, :],\n-                          (1, -1, feature_dim)))\n-    x_aggregate = concatenate(xs, axis=0)\n-    # Shape: `(output_length, batch_size, filters)`.\n-    output = batch_dot(x_aggregate, kernel)\n-    return permute_dimensions(output, (1, 0, 2))\n-\n-\n-def local_conv2d(inputs,\n-                 kernel,\n-                 kernel_size,\n-                 strides,\n-                 output_shape,\n-                 data_format=None):\n-    data_format = normalize_data_format(data_format)\n-\n-    stride_row, stride_col = strides\n-    output_row, output_col = output_shape\n-    kernel_shape = int_shape(kernel)\n-    _, feature_dim, filters = kernel_shape\n-\n-    if data_format == 'channels_first':\n-        output = []\n-        for i in range(output_row):\n-            for j in range(output_col):\n-                slice_row = py_slice(i * stride_row,\n-                                     i * stride_row + kernel_size[0])\n-                slice_col = py_slice(j * stride_col,\n-                                     j * stride_col + kernel_size[1])\n-                x_flatten = reshape(inputs[:, :, slice_row, slice_col],\n-                                    (1, -1, feature_dim))\n-                output.append(dot(x_flatten,\n-                                  kernel[i * output_col + j, :, :]))\n-        output = concatenate(output, axis=0)\n-        output = reshape(output,\n-                         (output_row, output_col, -1, filters))\n-        output = permute_dimensions(output, (2, 3, 0, 1))\n-    else:\n-        xs = []\n-        for i in range(output_row):\n-            for j in range(output_col):\n-                slice_row = py_slice(i * stride_row,\n-                                     i * stride_row + kernel_size[0])\n-                slice_col = py_slice(j * stride_col,\n-                                     j * stride_col + kernel_size[1])\n-                xs.append(reshape(inputs[:, slice_row, slice_col, :],\n-                                  (1, -1, feature_dim)))\n-\n-        x_aggregate = concatenate(xs, axis=0)\n-        output = batch_dot(x_aggregate, kernel)\n-        output = reshape(output,\n-                         (output_row, output_col, -1, filters))\n-        output = permute_dimensions(output, (2, 0, 1, 3))\n-    return output\n-\n-\n-def ctc_label_dense_to_sparse(labels, label_lengths):\n-    raise NotImplementedError\n-\n-\n-def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1,\n-               merge_repeated=False):\n-    raise NotImplementedError\n-\n-\n-def control_dependencies(control_inputs):\n-    @contextmanager\n-    def nullcontextmanager():\n-        yield\n-\n-    return nullcontextmanager()\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.callbacks import *\n\n@@ -1,22 +0,0 @@\n-from __future__ import absolute_import\n-\n-from .callbacks import Callback\n-from .callbacks import CallbackList\n-from .callbacks import BaseLogger\n-from .callbacks import TerminateOnNaN\n-from .callbacks import ProgbarLogger\n-from .callbacks import History\n-from .callbacks import ModelCheckpoint\n-from .callbacks import EarlyStopping\n-from .callbacks import RemoteMonitor\n-from .callbacks import LearningRateScheduler\n-from .callbacks import ReduceLROnPlateau\n-from .callbacks import CSVLogger\n-from .callbacks import LambdaCallback\n-\n-from .. import backend as K\n-\n-if K.backend() == 'tensorflow' and not K.tensorflow_backend._is_tf_1():\n-    from .tensorboard_v2 import TensorBoard\n-else:\n-    from .tensorboard_v1 import TensorBoard\n\n@@ -1,1248 +0,0 @@\n-\"\"\"Callbacks: utilities called at certain points during model training.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import os\n-import csv\n-import six\n-\n-import numpy as np\n-import time\n-import json\n-import warnings\n-import io\n-\n-from collections import deque\n-from collections import OrderedDict\n-from collections import Iterable\n-from collections import defaultdict\n-from ..utils.generic_utils import Progbar\n-from .. import backend as K\n-from ..engine.training_utils import standardize_input_data\n-\n-try:\n-    import requests\n-except ImportError:\n-    requests = None\n-\n-\n-_TRAIN = 'train'\n-_TEST = 'test'\n-_PREDICT = 'predict'\n-\n-\n-class CallbackList(object):\n-    \"\"\"Container abstracting a list of callbacks.\n-\n-    # Arguments\n-        callbacks: List of `Callback` instances.\n-        queue_length: Queue length for keeping\n-            running statistics over callback execution time.\n-    \"\"\"\n-\n-    def __init__(self, callbacks=None, queue_length=10):\n-        callbacks = callbacks or []\n-        self.callbacks = [c for c in callbacks]\n-        self.queue_length = queue_length\n-        self.params = {}\n-        self.model = None\n-        self._reset_batch_timing()\n-\n-    def _reset_batch_timing(self):\n-        self._delta_t_batch = 0.\n-        self._delta_ts = defaultdict(lambda: deque([], maxlen=self.queue_length))\n-\n-    def append(self, callback):\n-        self.callbacks.append(callback)\n-\n-    def set_params(self, params):\n-        self.params = params\n-        for callback in self.callbacks:\n-            callback.set_params(params)\n-\n-    def set_model(self, model):\n-        self.model = model\n-        for callback in self.callbacks:\n-            callback.set_model(model)\n-\n-    def _call_batch_hook(self, mode, hook, batch, logs=None):\n-        \"\"\"Helper function for all batch_{begin | end} methods.\"\"\"\n-        if not self.callbacks:\n-            return\n-        hook_name = 'on_{mode}_batch_{hook}'.format(mode=mode, hook=hook)\n-        if hook == 'end':\n-            if not hasattr(self, '_t_enter_batch'):\n-                self._t_enter_batch = time.time()\n-            # Batch is ending, calculate batch time\n-            self._delta_t_batch = time.time() - self._t_enter_batch\n-\n-        logs = logs or {}\n-        t_before_callbacks = time.time()\n-        for callback in self.callbacks:\n-            batch_hook = getattr(callback, hook_name)\n-            batch_hook(batch, logs)\n-        self._delta_ts[hook_name].append(time.time() - t_before_callbacks)\n-\n-        delta_t_median = np.median(self._delta_ts[hook_name])\n-        if (self._delta_t_batch > 0. and\n-           delta_t_median > 0.95 * self._delta_t_batch and\n-           delta_t_median > 0.1):\n-            warnings.warn(\n-                'Method (%s) is slow compared '\n-                'to the batch update (%f). Check your callbacks.'\n-                % (hook_name, delta_t_median), RuntimeWarning)\n-\n-        if hook == 'begin':\n-            self._t_enter_batch = time.time()\n-\n-    def _call_begin_hook(self, mode):\n-        \"\"\"Helper function for on_{train|test|predict}_begin methods.\"\"\"\n-        if mode == _TRAIN:\n-            self.on_train_begin()\n-        elif mode == _TEST:\n-            self.on_test_begin()\n-        else:\n-            self.on_predict_begin()\n-\n-    def _call_end_hook(self, mode):\n-        \"\"\"Helper function for on_{train|test|predict}_end methods.\"\"\"\n-        if mode == _TRAIN:\n-            self.on_train_end()\n-        elif mode == _TEST:\n-            self.on_test_end()\n-        else:\n-            self.on_predict_end()\n-\n-    def on_batch_begin(self, batch, logs=None):\n-        self._call_batch_hook(_TRAIN, 'begin', batch, logs=logs)\n-\n-    def on_batch_end(self, batch, logs=None):\n-        self._call_batch_hook(_TRAIN, 'end', batch, logs=logs)\n-\n-    def on_epoch_begin(self, epoch, logs=None):\n-        \"\"\"Calls the `on_epoch_begin` methods of its callbacks.\n-\n-        This function should only be called during train mode.\n-\n-        # Arguments\n-            epoch: integer, index of epoch.\n-            logs: dict, Currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        logs = logs or {}\n-        for callback in self.callbacks:\n-            callback.on_epoch_begin(epoch, logs)\n-        self._reset_batch_timing()\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        \"\"\"Calls the `on_epoch_end` methods of its callbacks.\n-\n-        This function should only be called during train mode.\n-\n-        # Arguments\n-            epoch: integer, index of epoch.\n-            logs: dict, metric results for this training epoch, and for the\n-                validation epoch if validation is performed. Validation result keys\n-                are prefixed with `val_`.\n-        \"\"\"\n-        logs = logs or {}\n-        for callback in self.callbacks:\n-            callback.on_epoch_end(epoch, logs)\n-\n-    def on_train_batch_begin(self, batch, logs=None):\n-        \"\"\"Calls the `on_train_batch_begin` methods of its callbacks.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-        self._call_batch_hook(_TRAIN, 'begin', batch, logs=logs)\n-\n-    def on_train_batch_end(self, batch, logs=None):\n-        \"\"\"Calls the `on_train_batch_end` methods of its callbacks.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-        self._call_batch_hook(_TRAIN, 'end', batch, logs=logs)\n-\n-    def on_test_batch_begin(self, batch, logs=None):\n-        \"\"\"Calls the `on_test_batch_begin` methods of its callbacks.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-        self._call_batch_hook(_TEST, 'begin', batch, logs=logs)\n-\n-    def on_test_batch_end(self, batch, logs=None):\n-        \"\"\"Calls the `on_test_batch_end` methods of its callbacks.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-        self._call_batch_hook(_TEST, 'end', batch, logs=logs)\n-\n-    def on_predict_batch_begin(self, batch, logs=None):\n-        \"\"\"Calls the `on_predict_batch_begin` methods of its callbacks.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-        self._call_batch_hook(_PREDICT, 'begin', batch, logs=logs)\n-\n-    def on_predict_batch_end(self, batch, logs=None):\n-        \"\"\"Calls the `on_predict_batch_end` methods of its callbacks.\n-\n-        # Argument\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-        self._call_batch_hook(_PREDICT, 'end', batch, logs=logs)\n-\n-    def on_train_begin(self, logs=None):\n-        \"\"\"Calls the `on_train_begin` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_train_begin(logs)\n-\n-    def on_train_end(self, logs=None):\n-        \"\"\"Calls the `on_train_end` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_train_end(logs)\n-\n-    def on_test_begin(self, logs=None):\n-        \"\"\"Calls the `on_test_begin` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_test_begin(logs)\n-\n-    def on_test_end(self, logs=None):\n-        \"\"\"Calls the `on_test_end` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_test_end(logs)\n-\n-    def on_predict_begin(self, logs=None):\n-        \"\"\"Calls the `on_predict_begin` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_predict_begin(logs)\n-\n-    def on_predict_end(self, logs=None):\n-        \"\"\"Calls the `on_predict_end` methods of its callbacks.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-        for callback in self.callbacks:\n-            callback.on_predict_end(logs)\n-\n-    def __iter__(self):\n-        return iter(self.callbacks)\n-\n-\n-class Callback(object):\n-    \"\"\"Abstract base class used to build new callbacks.\n-\n-    # Properties\n-        params: dict. Training parameters\n-            (eg. verbosity, batch size, number of epochs...).\n-        model: instance of `keras.models.Model`.\n-            Reference of the model being trained.\n-\n-    The `logs` dictionary that callback methods\n-    take as argument will contain keys for quantities relevant to\n-    the current batch or epoch.\n-\n-    Currently, the `.fit()` method of the `Sequential` model class\n-    will include the following quantities in the `logs` that\n-    it passes to its callbacks:\n-\n-        on_epoch_end: logs include `acc` and `loss`, and\n-            optionally include `val_loss`\n-            (if validation is enabled in `fit`), and `val_acc`\n-            (if validation and accuracy monitoring are enabled).\n-        on_batch_begin: logs include `size`,\n-            the number of samples in the current batch.\n-        on_batch_end: logs include `loss`, and optionally `acc`\n-            (if accuracy monitoring is enabled).\n-    \"\"\"\n-\n-    def __init__(self):\n-        self.validation_data = None\n-        self.model = None\n-\n-    def set_params(self, params):\n-        self.params = params\n-\n-    def set_model(self, model):\n-        self.model = model\n-\n-    def on_batch_begin(self, batch, logs=None):\n-        \"\"\"A backwards compatibility alias for `on_train_batch_begin`.\"\"\"\n-\n-    def on_batch_end(self, batch, logs=None):\n-        \"\"\"A backwards compatibility alias for `on_train_batch_end`.\"\"\"\n-\n-    def on_epoch_begin(self, epoch, logs=None):\n-        \"\"\"Called at the start of an epoch.\n-\n-        Subclasses should override for any actions to run. This function should only\n-        be called during train mode.\n-\n-        # Arguments\n-            epoch: integer, index of epoch.\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        \"\"\"Called at the end of an epoch.\n-\n-        Subclasses should override for any actions to run. This function should only\n-        be called during train mode.\n-\n-        # Arguments\n-            epoch: integer, index of epoch.\n-            logs: dict, metric results for this training epoch, and for the\n-                validation epoch if validation is performed. Validation result keys\n-                are prefixed with `val_`.\n-        \"\"\"\n-\n-    def on_train_batch_begin(self, batch, logs=None):\n-        \"\"\"Called at the beginning of a training batch in `fit` methods.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-        # For backwards compatibility\n-        self.on_batch_begin(batch, logs=logs)\n-\n-    def on_train_batch_end(self, batch, logs=None):\n-        \"\"\"Called at the end of a training batch in `fit` methods.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-        # For backwards compatibility\n-        self.on_batch_end(batch, logs=logs)\n-\n-    def on_test_batch_begin(self, batch, logs=None):\n-        \"\"\"Called at the beginning of a batch in `evaluate` methods.\n-\n-        Also called at the beginning of a validation batch in the `fit` methods,\n-        if validation data is provided.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-\n-    def on_test_batch_end(self, batch, logs=None):\n-        \"\"\"Called at the end of a batch in `evaluate` methods.\n-\n-        Also called at the end of a validation batch in the `fit` methods,\n-        if validation data is provided.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-\n-    def on_predict_batch_begin(self, batch, logs=None):\n-        \"\"\"Called at the beginning of a batch in `predict` methods.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, has keys `batch` and `size` representing the current\n-                batch number and the size of the batch.\n-        \"\"\"\n-\n-    def on_predict_batch_end(self, batch, logs=None):\n-        \"\"\"Called at the end of a batch in `predict` methods.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            batch: integer, index of batch within the current epoch.\n-            logs: dict, metric results for this batch.\n-        \"\"\"\n-\n-    def on_train_begin(self, logs=None):\n-        \"\"\"Called at the beginning of training.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_train_end(self, logs=None):\n-        \"\"\"Called at the end of training.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_test_begin(self, logs=None):\n-        \"\"\"Called at the beginning of evaluation or validation.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_test_end(self, logs=None):\n-        \"\"\"Called at the end of evaluation or validation.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_predict_begin(self, logs=None):\n-        \"\"\"Called at the beginning of prediction.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-    def on_predict_end(self, logs=None):\n-        \"\"\"Called at the end of prediction.\n-\n-        Subclasses should override for any actions to run.\n-\n-        # Arguments\n-            logs: dict, currently no data is passed to this argument for this method\n-                but that may change in the future.\n-        \"\"\"\n-\n-\n-class BaseLogger(Callback):\n-    \"\"\"Callback that accumulates epoch averages of metrics.\n-\n-    This callback is automatically applied to every Keras model.\n-\n-    # Arguments\n-        stateful_metrics: Iterable of string names of metrics that\n-            should *not* be averaged over an epoch.\n-            Metrics in this list will be logged as-is in `on_epoch_end`.\n-            All others will be averaged in `on_epoch_end`.\n-    \"\"\"\n-\n-    def __init__(self, stateful_metrics=None):\n-        if stateful_metrics:\n-            self.stateful_metrics = set(stateful_metrics)\n-        else:\n-            self.stateful_metrics = set()\n-\n-    def on_epoch_begin(self, epoch, logs=None):\n-        self.seen = 0\n-        self.totals = {}\n-\n-    def on_batch_end(self, batch, logs=None):\n-        logs = logs or {}\n-        batch_size = logs.get('size', 0)\n-        self.seen += batch_size\n-\n-        for k, v in logs.items():\n-            if k in self.stateful_metrics:\n-                self.totals[k] = v\n-            else:\n-                if k in self.totals:\n-                    self.totals[k] += v * batch_size\n-                else:\n-                    self.totals[k] = v * batch_size\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        if logs is not None:\n-            for k in self.params['metrics']:\n-                if k in self.totals:\n-                    # Make value available to next callbacks.\n-                    if k in self.stateful_metrics:\n-                        logs[k] = self.totals[k]\n-                    else:\n-                        logs[k] = self.totals[k] / self.seen\n-\n-\n-class TerminateOnNaN(Callback):\n-    \"\"\"Callback that terminates training when a NaN loss is encountered.\n-    \"\"\"\n-\n-    def on_batch_end(self, batch, logs=None):\n-        logs = logs or {}\n-        loss = logs.get('loss')\n-        if loss is not None:\n-            if np.isnan(loss) or np.isinf(loss):\n-                print('Batch %d: Invalid loss, terminating training' % (batch))\n-                self.model.stop_training = True\n-\n-\n-class ProgbarLogger(Callback):\n-    \"\"\"Callback that prints metrics to stdout.\n-\n-    # Arguments\n-        count_mode: One of \"steps\" or \"samples\".\n-            Whether the progress bar should\n-            count samples seen or steps (batches) seen.\n-        stateful_metrics: Iterable of string names of metrics that\n-            should *not* be averaged over an epoch.\n-            Metrics in this list will be logged as-is.\n-            All others will be averaged over time (e.g. loss, etc).\n-\n-    # Raises\n-        ValueError: In case of invalid `count_mode`.\n-    \"\"\"\n-\n-    def __init__(self, count_mode='samples',\n-                 stateful_metrics=None):\n-        super(ProgbarLogger, self).__init__()\n-        if count_mode == 'samples':\n-            self.use_steps = False\n-        elif count_mode == 'steps':\n-            self.use_steps = True\n-        else:\n-            raise ValueError('Unknown `count_mode`: ' + str(count_mode))\n-        if stateful_metrics:\n-            self.stateful_metrics = set(stateful_metrics)\n-        else:\n-            self.stateful_metrics = set()\n-\n-    def on_train_begin(self, logs=None):\n-        self.verbose = self.params['verbose']\n-        self.epochs = self.params['epochs']\n-\n-    def on_epoch_begin(self, epoch, logs=None):\n-        if self.verbose:\n-            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n-            if self.use_steps:\n-                target = self.params['steps']\n-            else:\n-                target = self.params['samples']\n-            self.target = target\n-            self.progbar = Progbar(target=self.target,\n-                                   verbose=self.verbose,\n-                                   stateful_metrics=self.stateful_metrics)\n-        self.seen = 0\n-\n-    def on_batch_begin(self, batch, logs=None):\n-        if self.seen < self.target:\n-            self.log_values = []\n-\n-    def on_batch_end(self, batch, logs=None):\n-        logs = logs or {}\n-        batch_size = logs.get('size', 0)\n-        if self.use_steps:\n-            self.seen += 1\n-        else:\n-            self.seen += batch_size\n-\n-        for k in self.params['metrics']:\n-            if k in logs:\n-                self.log_values.append((k, logs[k]))\n-\n-        # Skip progbar update for the last batch;\n-        # will be handled by on_epoch_end.\n-        if self.verbose and self.seen < self.target:\n-            self.progbar.update(self.seen, self.log_values)\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-        for k in self.params['metrics']:\n-            if k in logs:\n-                self.log_values.append((k, logs[k]))\n-        if self.verbose:\n-            self.progbar.update(self.seen, self.log_values)\n-\n-\n-class History(Callback):\n-    \"\"\"Callback that records events into a `History` object.\n-\n-    This callback is automatically applied to\n-    every Keras model. The `History` object\n-    gets returned by the `fit` method of models.\n-    \"\"\"\n-\n-    def on_train_begin(self, logs=None):\n-        self.epoch = []\n-        self.history = {}\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-        self.epoch.append(epoch)\n-        for k, v in logs.items():\n-            self.history.setdefault(k, []).append(v)\n-\n-\n-class ModelCheckpoint(Callback):\n-    \"\"\"Save the model after every epoch.\n-\n-    `filepath` can contain named formatting options,\n-    which will be filled with the values of `epoch` and\n-    keys in `logs` (passed in `on_epoch_end`).\n-\n-    For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`,\n-    then the model checkpoints will be saved with the epoch number and\n-    the validation loss in the filename.\n-\n-    # Arguments\n-        filepath: string, path to save the model file.\n-        monitor: quantity to monitor.\n-        verbose: verbosity mode, 0 or 1.\n-        save_best_only: if `save_best_only=True`,\n-            the latest best model according to\n-            the quantity monitored will not be overwritten.\n-        save_weights_only: if True, then only the model's weights will be\n-            saved (`model.save_weights(filepath)`), else the full model\n-            is saved (`model.save(filepath)`).\n-        mode: one of {auto, min, max}.\n-            If `save_best_only=True`, the decision\n-            to overwrite the current save file is made\n-            based on either the maximization or the\n-            minimization of the monitored quantity. For `val_acc`,\n-            this should be `max`, for `val_loss` this should\n-            be `min`, etc. In `auto` mode, the direction is\n-            automatically inferred from the name of the monitored quantity.\n-        period: Interval (number of epochs) between checkpoints.\n-    \"\"\"\n-\n-    def __init__(self, filepath, monitor='val_loss', verbose=0,\n-                 save_best_only=False, save_weights_only=False,\n-                 mode='auto', period=1):\n-        super(ModelCheckpoint, self).__init__()\n-        self.monitor = monitor\n-        self.verbose = verbose\n-        self.filepath = filepath\n-        self.save_best_only = save_best_only\n-        self.save_weights_only = save_weights_only\n-        self.period = period\n-        self.epochs_since_last_save = 0\n-\n-        if mode not in ['auto', 'min', 'max']:\n-            warnings.warn('ModelCheckpoint mode %s is unknown, '\n-                          'fallback to auto mode.' % (mode),\n-                          RuntimeWarning)\n-            mode = 'auto'\n-\n-        if mode == 'min':\n-            self.monitor_op = np.less\n-            self.best = np.Inf\n-        elif mode == 'max':\n-            self.monitor_op = np.greater\n-            self.best = -np.Inf\n-        else:\n-            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n-                self.monitor_op = np.greater\n-                self.best = -np.Inf\n-            else:\n-                self.monitor_op = np.less\n-                self.best = np.Inf\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-        self.epochs_since_last_save += 1\n-        if self.epochs_since_last_save >= self.period:\n-            self.epochs_since_last_save = 0\n-            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n-            if self.save_best_only:\n-                current = logs.get(self.monitor)\n-                if current is None:\n-                    warnings.warn('Can save best model only with %s available, '\n-                                  'skipping.' % (self.monitor), RuntimeWarning)\n-                else:\n-                    if self.monitor_op(current, self.best):\n-                        if self.verbose > 0:\n-                            print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n-                                  ' saving model to %s'\n-                                  % (epoch + 1, self.monitor, self.best,\n-                                     current, filepath))\n-                        self.best = current\n-                        if self.save_weights_only:\n-                            self.model.save_weights(filepath, overwrite=True)\n-                        else:\n-                            self.model.save(filepath, overwrite=True)\n-                    else:\n-                        if self.verbose > 0:\n-                            print('\\nEpoch %05d: %s did not improve from %0.5f' %\n-                                  (epoch + 1, self.monitor, self.best))\n-            else:\n-                if self.verbose > 0:\n-                    print('\\nEpoch %05d: saving model to %s' % (epoch + 1, filepath))\n-                if self.save_weights_only:\n-                    self.model.save_weights(filepath, overwrite=True)\n-                else:\n-                    self.model.save(filepath, overwrite=True)\n-\n-\n-class EarlyStopping(Callback):\n-    \"\"\"Stop training when a monitored quantity has stopped improving.\n-\n-    # Arguments\n-        monitor: quantity to be monitored.\n-        min_delta: minimum change in the monitored quantity\n-            to qualify as an improvement, i.e. an absolute\n-            change of less than min_delta, will count as no\n-            improvement.\n-        patience: number of epochs that produced the monitored\n-            quantity with no improvement after which training will\n-            be stopped.\n-            Validation quantities may not be produced for every\n-            epoch, if the validation frequency\n-            (`model.fit(validation_freq=5)`) is greater than one.\n-        verbose: verbosity mode.\n-        mode: one of {auto, min, max}. In `min` mode,\n-            training will stop when the quantity\n-            monitored has stopped decreasing; in `max`\n-            mode it will stop when the quantity\n-            monitored has stopped increasing; in `auto`\n-            mode, the direction is automatically inferred\n-            from the name of the monitored quantity.\n-        baseline: Baseline value for the monitored quantity to reach.\n-            Training will stop if the model doesn't show improvement\n-            over the baseline.\n-        restore_best_weights: whether to restore model weights from\n-            the epoch with the best value of the monitored quantity.\n-            If False, the model weights obtained at the last step of\n-            training are used.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 monitor='val_loss',\n-                 min_delta=0,\n-                 patience=0,\n-                 verbose=0,\n-                 mode='auto',\n-                 baseline=None,\n-                 restore_best_weights=False):\n-        super(EarlyStopping, self).__init__()\n-\n-        self.monitor = monitor\n-        self.baseline = baseline\n-        self.patience = patience\n-        self.verbose = verbose\n-        self.min_delta = min_delta\n-        self.wait = 0\n-        self.stopped_epoch = 0\n-        self.restore_best_weights = restore_best_weights\n-        self.best_weights = None\n-\n-        if mode not in ['auto', 'min', 'max']:\n-            warnings.warn('EarlyStopping mode %s is unknown, '\n-                          'fallback to auto mode.' % mode,\n-                          RuntimeWarning)\n-            mode = 'auto'\n-\n-        if mode == 'min':\n-            self.monitor_op = np.less\n-        elif mode == 'max':\n-            self.monitor_op = np.greater\n-        else:\n-            if 'acc' in self.monitor:\n-                self.monitor_op = np.greater\n-            else:\n-                self.monitor_op = np.less\n-\n-        if self.monitor_op == np.greater:\n-            self.min_delta *= 1\n-        else:\n-            self.min_delta *= -1\n-\n-    def on_train_begin(self, logs=None):\n-        # Allow instances to be re-used\n-        self.wait = 0\n-        self.stopped_epoch = 0\n-        if self.baseline is not None:\n-            self.best = self.baseline\n-        else:\n-            self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        current = self.get_monitor_value(logs)\n-        if current is None:\n-            return\n-\n-        if self.monitor_op(current - self.min_delta, self.best):\n-            self.best = current\n-            self.wait = 0\n-            if self.restore_best_weights:\n-                self.best_weights = self.model.get_weights()\n-        else:\n-            self.wait += 1\n-            if self.wait >= self.patience:\n-                self.stopped_epoch = epoch\n-                self.model.stop_training = True\n-                if self.restore_best_weights:\n-                    if self.verbose > 0:\n-                        print('Restoring model weights from the end of '\n-                              'the best epoch')\n-                    self.model.set_weights(self.best_weights)\n-\n-    def on_train_end(self, logs=None):\n-        if self.stopped_epoch > 0 and self.verbose > 0:\n-            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n-\n-    def get_monitor_value(self, logs):\n-        monitor_value = logs.get(self.monitor)\n-        if monitor_value is None:\n-            warnings.warn(\n-                'Early stopping conditioned on metric `%s` '\n-                'which is not available. Available metrics are: %s' %\n-                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n-            )\n-        return monitor_value\n-\n-\n-class RemoteMonitor(Callback):\n-    \"\"\"Callback used to stream events to a server.\n-\n-    Requires the `requests` library.\n-    Events are sent to `root + '/publish/epoch/end/'` by default. Calls are\n-    HTTP POST, with a `data` argument which is a\n-    JSON-encoded dictionary of event data.\n-    If send_as_json is set to True, the content type of the request will be\n-    application/json. Otherwise the serialized JSON will be send within a form\n-\n-    # Arguments\n-        root: String; root url of the target server.\n-        path: String; path relative to `root` to which the events will be sent.\n-        field: String; JSON field under which the data will be stored.\n-            The field is used only if the payload is sent within a form\n-            (i.e. send_as_json is set to False).\n-        headers: Dictionary; optional custom HTTP headers.\n-        send_as_json: Boolean; whether the request should be send as\n-            application/json.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 root='http://localhost:9000',\n-                 path='/publish/epoch/end/',\n-                 field='data',\n-                 headers=None,\n-                 send_as_json=False):\n-        super(RemoteMonitor, self).__init__()\n-\n-        self.root = root\n-        self.path = path\n-        self.field = field\n-        self.headers = headers\n-        self.send_as_json = send_as_json\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        if requests is None:\n-            raise ImportError('RemoteMonitor requires '\n-                              'the `requests` library.')\n-        logs = logs or {}\n-        send = {}\n-        send['epoch'] = epoch\n-        for k, v in logs.items():\n-            if isinstance(v, (np.ndarray, np.generic)):\n-                send[k] = v.item()\n-            else:\n-                send[k] = v\n-        try:\n-            if self.send_as_json:\n-                requests.post(self.root + self.path, json=send, headers=self.headers)\n-            else:\n-                requests.post(self.root + self.path,\n-                              {self.field: json.dumps(send)},\n-                              headers=self.headers)\n-        except requests.exceptions.RequestException:\n-            warnings.warn('Warning: could not reach RemoteMonitor '\n-                          'root server at ' + str(self.root))\n-\n-\n-class LearningRateScheduler(Callback):\n-    \"\"\"Learning rate scheduler.\n-\n-    # Arguments\n-        schedule: a function that takes an epoch index as input\n-            (integer, indexed from 0) and current learning rate\n-            and returns a new learning rate as output (float).\n-        verbose: int. 0: quiet, 1: update messages.\n-    \"\"\"\n-\n-    def __init__(self, schedule, verbose=0):\n-        super(LearningRateScheduler, self).__init__()\n-        self.schedule = schedule\n-        self.verbose = verbose\n-\n-    def on_epoch_begin(self, epoch, logs=None):\n-        if not hasattr(self.model.optimizer, 'lr'):\n-            raise ValueError('Optimizer must have a \"lr\" attribute.')\n-        lr = float(K.get_value(self.model.optimizer.lr))\n-        try:  # new API\n-            lr = self.schedule(epoch, lr)\n-        except TypeError:  # old API for backward compatibility\n-            lr = self.schedule(epoch)\n-        if not isinstance(lr, (float, np.float32, np.float64)):\n-            raise ValueError('The output of the \"schedule\" function '\n-                             'should be float.')\n-        K.set_value(self.model.optimizer.lr, lr)\n-        if self.verbose > 0:\n-            print('\\nEpoch %05d: LearningRateScheduler setting learning '\n-                  'rate to %s.' % (epoch + 1, lr))\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-        logs['lr'] = K.get_value(self.model.optimizer.lr)\n-\n-\n-class ReduceLROnPlateau(Callback):\n-    \"\"\"Reduce learning rate when a metric has stopped improving.\n-\n-    Models often benefit from reducing the learning rate by a factor\n-    of 2-10 once learning stagnates. This callback monitors a\n-    quantity and if no improvement is seen for a 'patience' number\n-    of epochs, the learning rate is reduced.\n-\n-    # Example\n-\n-    ```python\n-    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n-                                  patience=5, min_lr=0.001)\n-    model.fit(X_train, Y_train, callbacks=[reduce_lr])\n-    ```\n-\n-    # Arguments\n-        monitor: quantity to be monitored.\n-        factor: factor by which the learning rate will\n-            be reduced. new_lr = lr * factor\n-        patience: number of epochs that produced the monitored\n-            quantity with no improvement after which training will\n-            be stopped.\n-            Validation quantities may not be produced for every\n-            epoch, if the validation frequency\n-            (`model.fit(validation_freq=5)`) is greater than one.\n-        verbose: int. 0: quiet, 1: update messages.\n-        mode: one of {auto, min, max}. In `min` mode,\n-            lr will be reduced when the quantity\n-            monitored has stopped decreasing; in `max`\n-            mode it will be reduced when the quantity\n-            monitored has stopped increasing; in `auto`\n-            mode, the direction is automatically inferred\n-            from the name of the monitored quantity.\n-        min_delta: threshold for measuring the new optimum,\n-            to only focus on significant changes.\n-        cooldown: number of epochs to wait before resuming\n-            normal operation after lr has been reduced.\n-        min_lr: lower bound on the learning rate.\n-    \"\"\"\n-\n-    def __init__(self, monitor='val_loss', factor=0.1, patience=10,\n-                 verbose=0, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0,\n-                 **kwargs):\n-        super(ReduceLROnPlateau, self).__init__()\n-\n-        self.monitor = monitor\n-        if factor >= 1.0:\n-            raise ValueError('ReduceLROnPlateau '\n-                             'does not support a factor >= 1.0.')\n-        if 'epsilon' in kwargs:\n-            min_delta = kwargs.pop('epsilon')\n-            warnings.warn('`epsilon` argument is deprecated and '\n-                          'will be removed, use `min_delta` instead.')\n-        self.factor = factor\n-        self.min_lr = min_lr\n-        self.min_delta = min_delta\n-        self.patience = patience\n-        self.verbose = verbose\n-        self.cooldown = cooldown\n-        self.cooldown_counter = 0  # Cooldown counter.\n-        self.wait = 0\n-        self.best = 0\n-        self.mode = mode\n-        self.monitor_op = None\n-        self._reset()\n-\n-    def _reset(self):\n-        \"\"\"Resets wait counter and cooldown counter.\n-        \"\"\"\n-        if self.mode not in ['auto', 'min', 'max']:\n-            warnings.warn('Learning Rate Plateau Reducing mode %s is unknown, '\n-                          'fallback to auto mode.' % (self.mode),\n-                          RuntimeWarning)\n-            self.mode = 'auto'\n-        if (self.mode == 'min' or\n-           (self.mode == 'auto' and 'acc' not in self.monitor)):\n-            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n-            self.best = np.Inf\n-        else:\n-            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n-            self.best = -np.Inf\n-        self.cooldown_counter = 0\n-        self.wait = 0\n-\n-    def on_train_begin(self, logs=None):\n-        self._reset()\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-        logs['lr'] = K.get_value(self.model.optimizer.lr)\n-        current = logs.get(self.monitor)\n-        if current is None:\n-            warnings.warn(\n-                'Reduce LR on plateau conditioned on metric `%s` '\n-                'which is not available. Available metrics are: %s' %\n-                (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n-            )\n-\n-        else:\n-            if self.in_cooldown():\n-                self.cooldown_counter -= 1\n-                self.wait = 0\n-\n-            if self.monitor_op(current, self.best):\n-                self.best = current\n-                self.wait = 0\n-            elif not self.in_cooldown():\n-                self.wait += 1\n-                if self.wait >= self.patience:\n-                    old_lr = float(K.get_value(self.model.optimizer.lr))\n-                    if old_lr > self.min_lr:\n-                        new_lr = old_lr * self.factor\n-                        new_lr = max(new_lr, self.min_lr)\n-                        K.set_value(self.model.optimizer.lr, new_lr)\n-                        if self.verbose > 0:\n-                            print('\\nEpoch %05d: ReduceLROnPlateau reducing '\n-                                  'learning rate to %s.' % (epoch + 1, new_lr))\n-                        self.cooldown_counter = self.cooldown\n-                        self.wait = 0\n-\n-    def in_cooldown(self):\n-        return self.cooldown_counter > 0\n-\n-\n-class CSVLogger(Callback):\n-    \"\"\"Callback that streams epoch results to a csv file.\n-\n-    Supports all values that can be represented as a string,\n-    including 1D iterables such as np.ndarray.\n-\n-    # Example\n-\n-    ```python\n-    csv_logger = CSVLogger('training.log')\n-    model.fit(X_train, Y_train, callbacks=[csv_logger])\n-    ```\n-\n-    # Arguments\n-        filename: filename of the csv file, e.g. 'run/log.csv'.\n-        separator: string used to separate elements in the csv file.\n-        append: True: append if file exists (useful for continuing\n-            training). False: overwrite existing file,\n-    \"\"\"\n-\n-    def __init__(self, filename, separator=',', append=False):\n-        self.sep = separator\n-        self.filename = filename\n-        self.append = append\n-        self.writer = None\n-        self.keys = None\n-        self.append_header = True\n-        if six.PY2:\n-            self.file_flags = 'b'\n-            self._open_args = {}\n-        else:\n-            self.file_flags = ''\n-            self._open_args = {'newline': '\\n'}\n-        super(CSVLogger, self).__init__()\n-\n-    def on_train_begin(self, logs=None):\n-        if self.append:\n-            if os.path.exists(self.filename):\n-                with open(self.filename, 'r' + self.file_flags) as f:\n-                    self.append_header = not bool(len(f.readline()))\n-            mode = 'a'\n-        else:\n-            mode = 'w'\n-        self.csv_file = io.open(self.filename,\n-                                mode + self.file_flags,\n-                                **self._open_args)\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-\n-        def handle_value(k):\n-            is_zero_dim_ndarray = isinstance(k, np.ndarray) and k.ndim == 0\n-            if isinstance(k, six.string_types):\n-                return k\n-            elif isinstance(k, Iterable) and not is_zero_dim_ndarray:\n-                return '\"[%s]\"' % (', '.join(map(str, k)))\n-            else:\n-                return k\n-\n-        if self.keys is None:\n-            self.keys = sorted(logs.keys())\n-\n-        if self.model.stop_training:\n-            # We set NA so that csv parsers do not fail for this last epoch.\n-            logs = dict([(k, logs[k] if k in logs else 'NA') for k in self.keys])\n-\n-        if not self.writer:\n-            class CustomDialect(csv.excel):\n-                delimiter = self.sep\n-            fieldnames = ['epoch'] + self.keys\n-            if six.PY2:\n-                fieldnames = [unicode(x) for x in fieldnames]\n-            self.writer = csv.DictWriter(self.csv_file,\n-                                         fieldnames=fieldnames,\n-                                         dialect=CustomDialect)\n-            if self.append_header:\n-                self.writer.writeheader()\n-\n-        row_dict = OrderedDict({'epoch': epoch})\n-        row_dict.update((key, handle_value(logs[key])) for key in self.keys)\n-        self.writer.writerow(row_dict)\n-        self.csv_file.flush()\n-\n-    def on_train_end(self, logs=None):\n-        self.csv_file.close()\n-        self.writer = None\n-\n-    def __del__(self):\n-        if hasattr(self, 'csv_file') and not self.csv_file.closed:\n-            self.csv_file.close()\n-\n-\n-class LambdaCallback(Callback):\n-    r\"\"\"Callback for creating simple, custom callbacks on-the-fly.\n-\n-    This callback is constructed with anonymous functions that will be called\n-    at the appropriate time. Note that the callbacks expects positional\n-    arguments, as:\n-\n-     - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:\n-        `epoch`, `logs`\n-     - `on_batch_begin` and `on_batch_end` expect two positional arguments:\n-        `batch`, `logs`\n-     - `on_train_begin` and `on_train_end` expect one positional argument:\n-        `logs`\n-\n-    # Arguments\n-        on_epoch_begin: called at the beginning of every epoch.\n-        on_epoch_end: called at the end of every epoch.\n-        on_batch_begin: called at the beginning of every batch.\n-        on_batch_end: called at the end of every batch.\n-        on_train_begin: called at the beginning of model training.\n-        on_train_end: called at the end of model training.\n-\n-    # Example\n-\n-    ```python\n-    # Print the batch number at the beginning of every batch.\n-    batch_print_callback = LambdaCallback(\n-        on_batch_begin=lambda batch,logs: print(batch))\n-\n-    # Stream the epoch loss to a file in JSON format. The file content\n-    # is not well-formed JSON but rather has a JSON object per line.\n-    import json\n-    json_log = open('loss_log.json', mode='wt', buffering=1)\n-    json_logging_callback = LambdaCallback(\n-        on_epoch_end=lambda epoch, logs: json_log.write(\n-            json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\\n'),\n-        on_train_end=lambda logs: json_log.close()\n-    )\n-\n-    # Terminate some processes after having finished model training.\n-    processes = ...\n-    cleanup_callback = LambdaCallback(\n-        on_train_end=lambda logs: [\n-            p.terminate() for p in processes if p.is_alive()])\n-\n-    model.fit(...,\n-              callbacks=[batch_print_callback,\n-                         json_logging_callback,\n-                         cleanup_callback])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self,\n-                 on_epoch_begin=None,\n-                 on_epoch_end=None,\n-                 on_batch_begin=None,\n-                 on_batch_end=None,\n-                 on_train_begin=None,\n-                 on_train_end=None,\n-                 **kwargs):\n-        super(LambdaCallback, self).__init__()\n-        self.__dict__.update(kwargs)\n-        if on_epoch_begin is not None:\n-            self.on_epoch_begin = on_epoch_begin\n-        else:\n-            self.on_epoch_begin = lambda epoch, logs: None\n-        if on_epoch_end is not None:\n-            self.on_epoch_end = on_epoch_end\n-        else:\n-            self.on_epoch_end = lambda epoch, logs: None\n-        if on_batch_begin is not None:\n-            self.on_batch_begin = on_batch_begin\n-        else:\n-            self.on_batch_begin = lambda batch, logs: None\n-        if on_batch_end is not None:\n-            self.on_batch_end = on_batch_end\n-        else:\n-            self.on_batch_end = lambda batch, logs: None\n-        if on_train_begin is not None:\n-            self.on_train_begin = on_train_begin\n-        else:\n-            self.on_train_begin = lambda logs: None\n-        if on_train_end is not None:\n-            self.on_train_end = on_train_end\n-        else:\n-            self.on_train_end = lambda logs: None\n\n@@ -1,362 +0,0 @@\n-\"\"\"TensorBoard callback for training visualization.\n-\n-This is the TF v1 version. A subset of the functionality\n-also works with other backends.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import os\n-\n-import numpy as np\n-import warnings\n-\n-from .. import backend as K\n-from ..engine.training_utils import standardize_input_data\n-from . import Callback\n-\n-\n-class TensorBoard(Callback):\n-    \"\"\"TensorBoard basic visualizations.\n-\n-    [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n-    is a visualization tool provided with TensorFlow.\n-\n-    This callback writes a log for TensorBoard, which allows\n-    you to visualize dynamic graphs of your training and test\n-    metrics, as well as activation histograms for the different\n-    layers in your model.\n-\n-    If you have installed TensorFlow with pip, you should be able\n-    to launch TensorBoard from the command line:\n-    ```sh\n-    tensorboard --logdir=/full_path_to_your_logs\n-    ```\n-\n-    When using a backend other than TensorFlow, TensorBoard will still work\n-    (if you have TensorFlow installed), but the only feature available will\n-    be the display of the losses and metrics plots.\n-\n-    # Arguments\n-        log_dir: the path of the directory where to save the log\n-            files to be parsed by TensorBoard.\n-        histogram_freq: frequency (in epochs) at which to compute activation\n-            and weight histograms for the layers of the model. If set to 0,\n-            histograms won't be computed. Validation data (or split) must be\n-            specified for histogram visualizations.\n-        batch_size: size of batch of inputs to feed to the network\n-            for histograms computation.\n-        write_graph: whether to visualize the graph in TensorBoard.\n-            The log file can become quite large when\n-            write_graph is set to True.\n-        write_grads: whether to visualize gradient histograms in TensorBoard.\n-            `histogram_freq` must be greater than 0.\n-        write_images: whether to write model weights to visualize as\n-            image in TensorBoard.\n-        embeddings_freq: frequency (in epochs) at which selected embedding\n-            layers will be saved. If set to 0, embeddings won't be computed.\n-            Data to be visualized in TensorBoard's Embedding tab must be passed\n-            as `embeddings_data`.\n-        embeddings_layer_names: a list of names of layers to keep eye on. If\n-            None or empty list all the embedding layer will be watched.\n-        embeddings_metadata: a dictionary which maps layer name to a file name\n-            in which metadata for this embedding layer is saved. See the\n-            [details](https://www.tensorflow.org/guide/embedding#metadata)\n-            about metadata files format. In case if the same metadata file is\n-            used for all embedding layers, string can be passed.\n-        embeddings_data: data to be embedded at layers specified in\n-            `embeddings_layer_names`. Numpy array (if the model has a single\n-            input) or list of Numpy arrays (if the model has multiple inputs).\n-            Learn [more about embeddings](\n-            https://www.tensorflow.org/guide/embedding).\n-        update_freq: `'batch'` or `'epoch'` or integer. When using `'batch'`, writes\n-            the losses and metrics to TensorBoard after each batch. The same\n-            applies for `'epoch'`. If using an integer, let's say `10000`,\n-            the callback will write the metrics and losses to TensorBoard every\n-            10000 samples. Note that writing too frequently to TensorBoard\n-            can slow down your training.\n-    \"\"\"\n-\n-    def __init__(self, log_dir='./logs',\n-                 histogram_freq=0,\n-                 batch_size=32,\n-                 write_graph=True,\n-                 write_grads=False,\n-                 write_images=False,\n-                 embeddings_freq=0,\n-                 embeddings_layer_names=None,\n-                 embeddings_metadata=None,\n-                 embeddings_data=None,\n-                 update_freq='epoch'):\n-        super(TensorBoard, self).__init__()\n-        global tf, projector\n-        try:\n-            import tensorflow as tf\n-            from tensorflow.contrib.tensorboard.plugins import projector\n-        except ImportError:\n-            raise ImportError('You need the TensorFlow (v1) module installed to '\n-                              'use TensorBoard.')\n-\n-        if K.backend() != 'tensorflow':\n-            if histogram_freq != 0:\n-                warnings.warn('You are not using the TensorFlow backend. '\n-                              'histogram_freq was set to 0')\n-                histogram_freq = 0\n-            if write_graph:\n-                warnings.warn('You are not using the TensorFlow backend. '\n-                              'write_graph was set to False')\n-                write_graph = False\n-            if write_images:\n-                warnings.warn('You are not using the TensorFlow backend. '\n-                              'write_images was set to False')\n-                write_images = False\n-            if embeddings_freq != 0:\n-                warnings.warn('You are not using the TensorFlow backend. '\n-                              'embeddings_freq was set to 0')\n-                embeddings_freq = 0\n-\n-        self.log_dir = log_dir\n-        self.histogram_freq = histogram_freq\n-        self.merged = None\n-        self.write_graph = write_graph\n-        self.write_grads = write_grads\n-        self.write_images = write_images\n-        self.embeddings_freq = embeddings_freq\n-        self.embeddings_layer_names = embeddings_layer_names\n-        self.embeddings_metadata = embeddings_metadata or {}\n-        self.batch_size = batch_size\n-        self.embeddings_data = embeddings_data\n-        if update_freq == 'batch':\n-            # It is the same as writing as frequently as possible.\n-            self.update_freq = 1\n-        else:\n-            self.update_freq = update_freq\n-        self.samples_seen = 0\n-        self.samples_seen_at_last_write = 0\n-\n-    def set_model(self, model):\n-        self.model = model\n-        if K.backend() == 'tensorflow':\n-            self.sess = K.get_session()\n-        if self.histogram_freq and self.merged is None:\n-            for layer in self.model.layers:\n-                for weight in layer.weights:\n-                    mapped_weight_name = weight.name.replace(':', '_')\n-                    tf.summary.histogram(mapped_weight_name, weight)\n-                    if self.write_grads and weight in layer.trainable_weights:\n-                        grads = model.optimizer.get_gradients(model.total_loss,\n-                                                              weight)\n-\n-                        def is_indexed_slices(grad):\n-                            return type(grad).__name__ == 'IndexedSlices'\n-                        grads = [\n-                            grad.values if is_indexed_slices(grad) else grad\n-                            for grad in grads]\n-                        tf.summary.histogram('{}_grad'.format(mapped_weight_name),\n-                                             grads)\n-                    if self.write_images:\n-                        w_img = tf.squeeze(weight)\n-                        shape = K.int_shape(w_img)\n-                        if len(shape) == 2:  # dense layer kernel case\n-                            if shape[0] > shape[1]:\n-                                w_img = tf.transpose(w_img)\n-                                shape = K.int_shape(w_img)\n-                            w_img = tf.reshape(w_img, [1,\n-                                                       shape[0],\n-                                                       shape[1],\n-                                                       1])\n-                        elif len(shape) == 3:  # convnet case\n-                            if K.image_data_format() == 'channels_last':\n-                                # switch to channels_first to display\n-                                # every kernel as a separate image\n-                                w_img = tf.transpose(w_img, perm=[2, 0, 1])\n-                                shape = K.int_shape(w_img)\n-                            w_img = tf.reshape(w_img, [shape[0],\n-                                                       shape[1],\n-                                                       shape[2],\n-                                                       1])\n-                        elif len(shape) == 1:  # bias case\n-                            w_img = tf.reshape(w_img, [1,\n-                                                       shape[0],\n-                                                       1,\n-                                                       1])\n-                        else:\n-                            # not possible to handle 3D convnets etc.\n-                            continue\n-\n-                        shape = K.int_shape(w_img)\n-                        assert len(shape) == 4 and shape[-1] in [1, 3, 4]\n-                        tf.summary.image(mapped_weight_name, w_img)\n-\n-                if hasattr(layer, 'output'):\n-                    if isinstance(layer.output, list):\n-                        for i, output in enumerate(layer.output):\n-                            tf.summary.histogram('{}_out_{}'.format(layer.name, i),\n-                                                 output)\n-                    else:\n-                        tf.summary.histogram('{}_out'.format(layer.name),\n-                                             layer.output)\n-        self.merged = tf.summary.merge_all()\n-\n-        if self.write_graph:\n-            self.writer = tf.summary.FileWriter(self.log_dir,\n-                                                self.sess.graph)\n-        else:\n-            self.writer = tf.summary.FileWriter(self.log_dir)\n-\n-        if self.embeddings_freq and self.embeddings_data is not None:\n-            self.embeddings_data = standardize_input_data(self.embeddings_data,\n-                                                          model.input_names)\n-\n-            embeddings_layer_names = self.embeddings_layer_names\n-\n-            if not embeddings_layer_names:\n-                embeddings_layer_names = [layer.name for layer in self.model.layers\n-                                          if type(layer).__name__ == 'Embedding']\n-            self.assign_embeddings = []\n-            embeddings_vars = {}\n-\n-            self.batch_id = batch_id = tf.placeholder(tf.int32)\n-            self.step = step = tf.placeholder(tf.int32)\n-\n-            for layer in self.model.layers:\n-                if layer.name in embeddings_layer_names:\n-                    embedding_input = self.model.get_layer(layer.name).output\n-                    embedding_size = np.prod(embedding_input.shape[1:])\n-                    embedding_input = tf.reshape(embedding_input,\n-                                                 (step, int(embedding_size)))\n-                    shape = (self.embeddings_data[0].shape[0], int(embedding_size))\n-                    embedding = K.variable(K.zeros(shape),\n-                                           name=layer.name + '_embedding')\n-                    embeddings_vars[layer.name] = embedding\n-                    batch = tf.assign(embedding[batch_id:batch_id + step],\n-                                      embedding_input)\n-                    self.assign_embeddings.append(batch)\n-\n-            self.saver = tf.train.Saver(list(embeddings_vars.values()))\n-\n-            if not isinstance(self.embeddings_metadata, str):\n-                embeddings_metadata = self.embeddings_metadata\n-            else:\n-                embeddings_metadata = {layer_name: self.embeddings_metadata\n-                                       for layer_name in embeddings_vars.keys()}\n-\n-            config = projector.ProjectorConfig()\n-\n-            for layer_name, tensor in embeddings_vars.items():\n-                embedding = config.embeddings.add()\n-                embedding.tensor_name = tensor.name\n-\n-                if layer_name in embeddings_metadata:\n-                    embedding.metadata_path = embeddings_metadata[layer_name]\n-\n-            projector.visualize_embeddings(self.writer, config)\n-\n-    def on_epoch_end(self, epoch, logs=None):\n-        logs = logs or {}\n-\n-        if not self.validation_data and self.histogram_freq:\n-            raise ValueError(\"If printing histograms, validation_data must be \"\n-                             \"provided, and cannot be a generator.\")\n-        if self.embeddings_data is None and self.embeddings_freq:\n-            raise ValueError(\"To visualize embeddings, embeddings_data must \"\n-                             \"be provided.\")\n-        if self.validation_data and self.histogram_freq:\n-            if epoch % self.histogram_freq == 0:\n-\n-                val_data = self.validation_data\n-                tensors = (self.model.inputs +\n-                           self.model.targets +\n-                           self.model.sample_weights)\n-\n-                if self.model.uses_learning_phase:\n-                    tensors += [K.learning_phase()]\n-\n-                assert len(val_data) == len(tensors)\n-                val_size = val_data[0].shape[0]\n-                i = 0\n-                while i < val_size:\n-                    step = min(self.batch_size, val_size - i)\n-                    if self.model.uses_learning_phase:\n-                        # do not slice the learning phase\n-                        batch_val = [x[i:i + step] for x in val_data[:-1]]\n-                        batch_val.append(val_data[-1])\n-                    else:\n-                        batch_val = [x[i:i + step] for x in val_data]\n-                    assert len(batch_val) == len(tensors)\n-                    feed_dict = dict(zip(tensors, batch_val))\n-                    result = self.sess.run([self.merged], feed_dict=feed_dict)\n-                    summary_str = result[0]\n-                    self.writer.add_summary(summary_str, epoch)\n-                    i += self.batch_size\n-\n-        if self.embeddings_freq and self.embeddings_data is not None:\n-            if epoch % self.embeddings_freq == 0:\n-                # We need a second forward-pass here because we're passing\n-                # the `embeddings_data` explicitly. This design allows to pass\n-                # arbitrary data as `embeddings_data` and results from the fact\n-                # that we need to know the size of the `tf.Variable`s which\n-                # hold the embeddings in `set_model`. At this point, however,\n-                # the `validation_data` is not yet set.\n-\n-                # More details in this discussion:\n-                # https://github.com/keras-team/keras/pull/7766#issuecomment-329195622\n-\n-                embeddings_data = self.embeddings_data\n-                n_samples = embeddings_data[0].shape[0]\n-\n-                i = 0\n-                while i < n_samples:\n-                    step = min(self.batch_size, n_samples - i)\n-                    batch = slice(i, i + step)\n-\n-                    if type(self.model.input) == list:\n-                        feed_dict = {_input: embeddings_data[idx][batch]\n-                                     for idx, _input in enumerate(self.model.input)}\n-                    else:\n-                        feed_dict = {self.model.input: embeddings_data[0][batch]}\n-\n-                    feed_dict.update({self.batch_id: i, self.step: step})\n-\n-                    if self.model.uses_learning_phase:\n-                        feed_dict[K.learning_phase()] = False\n-\n-                    self.sess.run(self.assign_embeddings, feed_dict=feed_dict)\n-                    self.saver.save(self.sess,\n-                                    os.path.join(self.log_dir,\n-                                                 'keras_embedding.ckpt'),\n-                                    epoch)\n-\n-                    i += self.batch_size\n-\n-        if self.update_freq == 'epoch':\n-            index = epoch\n-        else:\n-            index = self.samples_seen\n-        self._write_logs(logs, index)\n-\n-    def _write_logs(self, logs, index):\n-        for name, value in logs.items():\n-            if name in ['batch', 'size']:\n-                continue\n-            summary = tf.Summary()\n-            summary_value = summary.value.add()\n-            if isinstance(value, np.ndarray):\n-                summary_value.simple_value = value.item()\n-            else:\n-                summary_value.simple_value = value\n-            summary_value.tag = name\n-            self.writer.add_summary(summary, index)\n-        self.writer.flush()\n-\n-    def on_train_end(self, _):\n-        self.writer.close()\n-\n-    def on_batch_end(self, batch, logs=None):\n-        if self.update_freq != 'epoch':\n-            self.samples_seen += logs['size']\n-            samples_seen_since = self.samples_seen - self.samples_seen_at_last_write\n-            if samples_seen_since >= self.update_freq:\n-                self._write_logs(logs, self.samples_seen)\n-                self.samples_seen_at_last_write = self.samples_seen\n\n@@ -1,116 +0,0 @@\n-\"\"\"TensorBoard callback for training visualization.\n-\n-This is the TF v2 version. A lot of the functionality\n-from the v1 version isn't currently supported (but will\n-likely be added back later).\n-\n-The docstring is left unchanged\n-to avoid creating confusion on the docs website.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import tensorflow as tf\n-import warnings\n-\n-\n-class TensorBoard(tf.keras.callbacks.TensorBoard):\n-    \"\"\"TensorBoard basic visualizations.\n-\n-    [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard)\n-    is a visualization tool provided with TensorFlow.\n-\n-    This callback writes a log for TensorBoard, which allows\n-    you to visualize dynamic graphs of your training and test\n-    metrics, as well as activation histograms for the different\n-    layers in your model.\n-\n-    If you have installed TensorFlow with pip, you should be able\n-    to launch TensorBoard from the command line:\n-    ```sh\n-    tensorboard --logdir=/full_path_to_your_logs\n-    ```\n-\n-    When using a backend other than TensorFlow, TensorBoard will still work\n-    (if you have TensorFlow installed), but the only feature available will\n-    be the display of the losses and metrics plots.\n-\n-    # Arguments\n-        log_dir: the path of the directory where to save the log\n-            files to be parsed by TensorBoard.\n-        histogram_freq: frequency (in epochs) at which to compute activation\n-            and weight histograms for the layers of the model. If set to 0,\n-            histograms won't be computed. Validation data (or split) must be\n-            specified for histogram visualizations.\n-        batch_size: size of batch of inputs to feed to the network\n-            for histograms computation.\n-        write_graph: whether to visualize the graph in TensorBoard.\n-            The log file can become quite large when\n-            write_graph is set to True.\n-        write_grads: whether to visualize gradient histograms in TensorBoard.\n-            `histogram_freq` must be greater than 0.\n-        write_images: whether to write model weights to visualize as\n-            image in TensorBoard.\n-        embeddings_freq: frequency (in epochs) at which selected embedding\n-            layers will be saved. If set to 0, embeddings won't be computed.\n-            Data to be visualized in TensorBoard's Embedding tab must be passed\n-            as `embeddings_data`.\n-        embeddings_layer_names: a list of names of layers to keep eye on. If\n-            None or empty list all the embedding layer will be watched.\n-        embeddings_metadata: a dictionary which maps layer name to a file name\n-            in which metadata for this embedding layer is saved. See the\n-            [details](https://www.tensorflow.org/guide/embedding#metadata)\n-            about metadata files format. In case if the same metadata file is\n-            used for all embedding layers, string can be passed.\n-        embeddings_data: data to be embedded at layers specified in\n-            `embeddings_layer_names`. Numpy array (if the model has a single\n-            input) or list of Numpy arrays (if the model has multiple inputs).\n-            Learn [more about embeddings](\n-            https://www.tensorflow.org/guide/embedding).\n-        update_freq: `'batch'` or `'epoch'` or integer. When using `'batch'`, writes\n-            the losses and metrics to TensorBoard after each batch. The same\n-            applies for `'epoch'`. If using an integer, let's say `10000`,\n-            the callback will write the metrics and losses to TensorBoard every\n-            10000 samples. Note that writing too frequently to TensorBoard\n-            can slow down your training.\n-    \"\"\"\n-\n-    def __init__(self, log_dir='./logs',\n-                 histogram_freq=0,\n-                 batch_size=None,\n-                 write_graph=True,\n-                 write_grads=False,\n-                 write_images=False,\n-                 embeddings_freq=0,\n-                 embeddings_layer_names=None,\n-                 embeddings_metadata=None,\n-                 embeddings_data=None,\n-                 update_freq='epoch',\n-                 **kwargs):\n-        if batch_size is not None:\n-            warnings.warn('The TensorBoard callback `batch_size` argument '\n-                          '(for histogram computation) '\n-                          'is deprecated with TensorFlow 2.0. '\n-                          'It will be ignored.')\n-        if write_grads:\n-            warnings.warn('The TensorBoard callback does not support '\n-                          'gradients display when using TensorFlow 2.0. '\n-                          'The `write_grads` argument is ignored.')\n-        if (embeddings_freq or embeddings_layer_names or\n-                embeddings_metadata or embeddings_data):\n-            warnings.warn('The TensorBoard callback does not support '\n-                          'embeddings display when using TensorFlow 2.0. '\n-                          'Embeddings-related arguments are ignored.')\n-        super(TensorBoard, self).__init__(\n-            log_dir=log_dir,\n-            histogram_freq=histogram_freq,\n-            write_graph=write_graph,\n-            write_images=write_images,\n-            update_freq=update_freq,\n-            **kwargs)\n-\n-    def set_model(self, model):\n-        \"\"\"Sets Keras model and writes graph if specified.\"\"\"\n-        model.run_eagerly = False\n-        super(TensorBoard, self).set_model(model)\n\n@@ -4,144 +4,16 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import six\n-from . import backend as K\n-from .utils.generic_utils import serialize_keras_object\n-from .utils.generic_utils import deserialize_keras_object\n+from tensorflow.keras.constraints import Constraint\n \n+from tensorflow.keras.constraints import MaxNorm\n+from tensorflow.keras.constraints import NonNeg\n+from tensorflow.keras.constraints import UnitNorm\n+from tensorflow.keras.constraints import MinMaxNorm\n \n-class Constraint(object):\n-\n-    def __call__(self, w):\n-        return w\n-\n-    def get_config(self):\n-        return {}\n-\n-\n-class MaxNorm(Constraint):\n-    \"\"\"MaxNorm weight constraint.\n-\n-    Constrains the weights incident to each hidden unit\n-    to have a norm less than or equal to a desired value.\n-\n-    # Arguments\n-        max_value: the maximum norm for the incoming weights.\n-        axis: integer, axis along which to calculate weight norms.\n-            For instance, in a `Dense` layer the weight matrix\n-            has shape `(input_dim, output_dim)`,\n-            set `axis` to `0` to constrain each weight vector\n-            of length `(input_dim,)`.\n-            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n-            the weight tensor has shape\n-            `(rows, cols, input_depth, output_depth)`,\n-            set `axis` to `[0, 1, 2]`\n-            to constrain the weights of each filter tensor of size\n-            `(rows, cols, input_depth)`.\n-\n-    # References\n-        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n-           http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n-    \"\"\"\n-\n-    def __init__(self, max_value=2, axis=0):\n-        self.max_value = max_value\n-        self.axis = axis\n-\n-    def __call__(self, w):\n-        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n-        desired = K.clip(norms, 0, self.max_value)\n-        return w * (desired / (K.epsilon() + norms))\n-\n-    def get_config(self):\n-        return {'max_value': self.max_value,\n-                'axis': self.axis}\n-\n-\n-class NonNeg(Constraint):\n-    \"\"\"Constrains the weights to be non-negative.\n-    \"\"\"\n-\n-    def __call__(self, w):\n-        return w * K.cast(K.greater_equal(w, 0.), K.floatx())\n-\n-\n-class UnitNorm(Constraint):\n-    \"\"\"Constrains the weights incident to each hidden unit to have unit norm.\n-\n-    # Arguments\n-        axis: integer, axis along which to calculate weight norms.\n-            For instance, in a `Dense` layer the weight matrix\n-            has shape `(input_dim, output_dim)`,\n-            set `axis` to `0` to constrain each weight vector\n-            of length `(input_dim,)`.\n-            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n-            the weight tensor has shape\n-            `(rows, cols, input_depth, output_depth)`,\n-            set `axis` to `[0, 1, 2]`\n-            to constrain the weights of each filter tensor of size\n-            `(rows, cols, input_depth)`.\n-    \"\"\"\n-\n-    def __init__(self, axis=0):\n-        self.axis = axis\n-\n-    def __call__(self, w):\n-        return w / (K.epsilon() + K.sqrt(K.sum(K.square(w),\n-                                               axis=self.axis,\n-                                               keepdims=True)))\n-\n-    def get_config(self):\n-        return {'axis': self.axis}\n-\n-\n-class MinMaxNorm(Constraint):\n-    \"\"\"MinMaxNorm weight constraint.\n-\n-    Constrains the weights incident to each hidden unit\n-    to have the norm between a lower bound and an upper bound.\n-\n-    # Arguments\n-        min_value: the minimum norm for the incoming weights.\n-        max_value: the maximum norm for the incoming weights.\n-        rate: rate for enforcing the constraint: weights will be\n-            rescaled to yield\n-            `(1 - rate) * norm + rate * norm.clip(min_value, max_value)`.\n-            Effectively, this means that rate=1.0 stands for strict\n-            enforcement of the constraint, while rate<1.0 means that\n-            weights will be rescaled at each step to slowly move\n-            towards a value inside the desired interval.\n-        axis: integer, axis along which to calculate weight norms.\n-            For instance, in a `Dense` layer the weight matrix\n-            has shape `(input_dim, output_dim)`,\n-            set `axis` to `0` to constrain each weight vector\n-            of length `(input_dim,)`.\n-            In a `Conv2D` layer with `data_format=\"channels_last\"`,\n-            the weight tensor has shape\n-            `(rows, cols, input_depth, output_depth)`,\n-            set `axis` to `[0, 1, 2]`\n-            to constrain the weights of each filter tensor of size\n-            `(rows, cols, input_depth)`.\n-    \"\"\"\n-\n-    def __init__(self, min_value=0.0, max_value=1.0, rate=1.0, axis=0):\n-        self.min_value = min_value\n-        self.max_value = max_value\n-        self.rate = rate\n-        self.axis = axis\n-\n-    def __call__(self, w):\n-        norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))\n-        desired = (self.rate * K.clip(norms, self.min_value, self.max_value) +\n-                   (1 - self.rate) * norms)\n-        return w * (desired / (K.epsilon() + norms))\n-\n-    def get_config(self):\n-        return {'min_value': self.min_value,\n-                'max_value': self.max_value,\n-                'rate': self.rate,\n-                'axis': self.axis}\n-\n+from tensorflow.keras.constraints import get\n+from tensorflow.keras.constraints import serialize\n+from tensorflow.keras.constraints import deserialize\n \n # Aliases.\n \n@@ -156,28 +28,3 @@ maxnorm = max_norm\n nonneg = non_neg\n unitnorm = unit_norm\n \n-\n-def serialize(constraint):\n-    return serialize_keras_object(constraint)\n-\n-\n-def deserialize(config, custom_objects=None):\n-    return deserialize_keras_object(config,\n-                                    module_objects=globals(),\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='constraint')\n-\n-\n-def get(identifier):\n-    if identifier is None:\n-        return None\n-    if isinstance(identifier, dict):\n-        return deserialize(identifier)\n-    elif isinstance(identifier, six.string_types):\n-        config = {'class_name': str(identifier), 'config': {}}\n-        return deserialize(config)\n-    elif callable(identifier):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret constraint identifier: ' +\n-                         str(identifier))\n\n@@ -1,5 +1,3 @@\n-from __future__ import absolute_import\n-\n from . import mnist\n from . import imdb\n from . import reuters\n\n@@ -1,43 +1,3 @@\n-\"\"\"Boston housing price regression dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Boston housing price regression dataset.\"\"\"\n \n-from ..utils.data_utils import get_file\n-import numpy as np\n-\n-\n-def load_data(path='boston_housing.npz', test_split=0.2, seed=113):\n-    \"\"\"Loads the Boston Housing dataset.\n-\n-    # Arguments\n-        path: path where to cache the dataset locally\n-            (relative to ~/.keras/datasets).\n-        test_split: fraction of the data to reserve as test set.\n-        seed: Random seed for shuffling the data\n-            before computing the test split.\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-    \"\"\"\n-    assert 0 <= test_split < 1\n-    path = get_file(\n-        path,\n-        origin='https://s3.amazonaws.com/keras-datasets/boston_housing.npz',\n-        file_hash='f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5')\n-    with np.load(path, allow_pickle=True) as f:\n-        x = f['x']\n-        y = f['y']\n-\n-    rng = np.random.RandomState(seed)\n-    indices = np.arange(len(x))\n-    rng.shuffle(indices)\n-    x = x[indices]\n-    y = y[indices]\n-\n-    x_train = np.array(x[:int(len(x) * (1 - test_split))])\n-    y_train = np.array(y[:int(len(x) * (1 - test_split))])\n-    x_test = np.array(x[int(len(x) * (1 - test_split)):])\n-    y_test = np.array(y[int(len(x) * (1 - test_split)):])\n-    return (x_train, y_train), (x_test, y_test)\n+from tensorflow.keras.datasets.boston_housing import load_data\n\n@@ -1,37 +0,0 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Utilities common to CIFAR10 and CIFAR100 datasets.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import sys\n-from six.moves import cPickle\n-\n-\n-def load_batch(fpath, label_key='labels'):\n-    \"\"\"Internal utility for parsing CIFAR data.\n-\n-    # Arguments\n-        fpath: path the file to parse.\n-        label_key: key for label data in the retrieve\n-            dictionary.\n-\n-    # Returns\n-        A tuple `(data, labels)`.\n-    \"\"\"\n-    with open(fpath, 'rb') as f:\n-        if sys.version_info < (3,):\n-            d = cPickle.load(f)\n-        else:\n-            d = cPickle.load(f, encoding='bytes')\n-            # decode utf8\n-            d_decoded = {}\n-            for k, v in d.items():\n-                d_decoded[k.decode('utf8')] = v\n-            d = d_decoded\n-    data = d['data']\n-    labels = d[label_key]\n-\n-    data = data.reshape(data.shape[0], 3, 32, 32)\n-    return data, labels\n\n@@ -1,44 +1,3 @@\n-\"\"\"CIFAR10 small images classification dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"CIFAR10 small images classification dataset.\"\"\"\n \n-from .cifar import load_batch\n-from ..utils.data_utils import get_file\n-from .. import backend as K\n-import numpy as np\n-import os\n-\n-\n-def load_data():\n-    \"\"\"Loads CIFAR10 dataset.\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-    \"\"\"\n-    dirname = 'cifar-10-batches-py'\n-    origin = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n-    path = get_file(dirname, origin=origin, untar=True)\n-\n-    num_train_samples = 50000\n-\n-    x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n-    y_train = np.empty((num_train_samples,), dtype='uint8')\n-\n-    for i in range(1, 6):\n-        fpath = os.path.join(path, 'data_batch_' + str(i))\n-        (x_train[(i - 1) * 10000: i * 10000, :, :, :],\n-         y_train[(i - 1) * 10000: i * 10000]) = load_batch(fpath)\n-\n-    fpath = os.path.join(path, 'test_batch')\n-    x_test, y_test = load_batch(fpath)\n-\n-    y_train = np.reshape(y_train, (len(y_train), 1))\n-    y_test = np.reshape(y_test, (len(y_test), 1))\n-\n-    if K.image_data_format() == 'channels_last':\n-        x_train = x_train.transpose(0, 2, 3, 1)\n-        x_test = x_test.transpose(0, 2, 3, 1)\n-\n-    return (x_train, y_train), (x_test, y_test)\n+from tensorflow.keras.datasets.cifar10 import load_data\n\n@@ -1,46 +1,3 @@\n-\"\"\"CIFAR100 small images classification dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"CIFAR100 small images classification dataset.\"\"\"\n \n-from .cifar import load_batch\n-from ..utils.data_utils import get_file\n-from .. import backend as K\n-import numpy as np\n-import os\n-\n-\n-def load_data(label_mode='fine'):\n-    \"\"\"Loads CIFAR100 dataset.\n-\n-    # Arguments\n-        label_mode: one of \"fine\", \"coarse\".\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-\n-    # Raises\n-        ValueError: in case of invalid `label_mode`.\n-    \"\"\"\n-    if label_mode not in ['fine', 'coarse']:\n-        raise ValueError('`label_mode` must be one of `\"fine\"`, `\"coarse\"`.')\n-\n-    dirname = 'cifar-100-python'\n-    origin = 'https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'\n-    path = get_file(dirname, origin=origin, untar=True)\n-\n-    fpath = os.path.join(path, 'train')\n-    x_train, y_train = load_batch(fpath, label_key=label_mode + '_labels')\n-\n-    fpath = os.path.join(path, 'test')\n-    x_test, y_test = load_batch(fpath, label_key=label_mode + '_labels')\n-\n-    y_train = np.reshape(y_train, (len(y_train), 1))\n-    y_test = np.reshape(y_test, (len(y_test), 1))\n-\n-    if K.image_data_format() == 'channels_last':\n-        x_train = x_train.transpose(0, 2, 3, 1)\n-        x_test = x_test.transpose(0, 2, 3, 1)\n-\n-    return (x_train, y_train), (x_test, y_test)\n+from tensorflow.keras.datasets.cifar100 import load_data\n\n@@ -1,45 +1,3 @@\n-\"\"\"Fashion-MNIST dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Fashion-MNIST dataset.\"\"\"\n \n-import gzip\n-import os\n-\n-from ..utils.data_utils import get_file\n-import numpy as np\n-\n-\n-def load_data():\n-    \"\"\"Loads the Fashion-MNIST dataset.\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-    \"\"\"\n-    dirname = os.path.join('datasets', 'fashion-mnist')\n-    base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n-    files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n-             't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n-\n-    paths = []\n-    for fname in files:\n-        paths.append(get_file(fname,\n-                              origin=base + fname,\n-                              cache_subdir=dirname))\n-\n-    with gzip.open(paths[0], 'rb') as lbpath:\n-        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n-\n-    with gzip.open(paths[1], 'rb') as imgpath:\n-        x_train = np.frombuffer(imgpath.read(), np.uint8,\n-                                offset=16).reshape(len(y_train), 28, 28)\n-\n-    with gzip.open(paths[2], 'rb') as lbpath:\n-        y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n-\n-    with gzip.open(paths[3], 'rb') as imgpath:\n-        x_test = np.frombuffer(imgpath.read(), np.uint8,\n-                               offset=16).reshape(len(y_test), 28, 28)\n-\n-    return (x_train, y_train), (x_test, y_test)\n+from tensorflow.keras.datasets.fashion_mnist import load_data\n\n@@ -1,121 +1,4 @@\n-\"\"\"IMDB sentiment classification dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"IMDB sentiment classification dataset.\"\"\"\n \n-from ..utils.data_utils import get_file\n-from ..preprocessing.sequence import _remove_long_seq\n-import numpy as np\n-import json\n-import warnings\n-\n-\n-def load_data(path='imdb.npz', num_words=None, skip_top=0,\n-              maxlen=None, seed=113,\n-              start_char=1, oov_char=2, index_from=3, **kwargs):\n-    \"\"\"Loads the IMDB dataset.\n-\n-    # Arguments\n-        path: where to cache the data (relative to `~/.keras/dataset`).\n-        num_words: max number of words to include. Words are ranked\n-            by how often they occur (in the training set) and only\n-            the most frequent words are kept\n-        skip_top: skip the top N most frequently occurring words\n-            (which may not be informative).\n-        maxlen: sequences longer than this will be filtered out.\n-        seed: random seed for sample shuffling.\n-        start_char: The start of a sequence will be marked with this character.\n-            Set to 1 because 0 is usually the padding character.\n-        oov_char: words that were cut out because of the `num_words`\n-            or `skip_top` limit will be replaced with this character.\n-        index_from: index actual words with this index and higher.\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-\n-    # Raises\n-        ValueError: in case `maxlen` is so low\n-            that no input sequence could be kept.\n-\n-    Note that the 'out of vocabulary' character is only used for\n-    words that were present in the training set but are not included\n-    because they're not making the `num_words` cut here.\n-    Words that were not seen in the training set but are in the test set\n-    have simply been skipped.\n-    \"\"\"\n-    # Legacy support\n-    if 'nb_words' in kwargs:\n-        warnings.warn('The `nb_words` argument in `load_data` '\n-                      'has been renamed `num_words`.')\n-        num_words = kwargs.pop('nb_words')\n-    if kwargs:\n-        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n-\n-    path = get_file(path,\n-                    origin='https://s3.amazonaws.com/text-datasets/imdb.npz',\n-                    file_hash='599dadb1135973df5b59232a0e9a887c')\n-    with np.load(path, allow_pickle=True) as f:\n-        x_train, labels_train = f['x_train'], f['y_train']\n-        x_test, labels_test = f['x_test'], f['y_test']\n-\n-    rng = np.random.RandomState(seed)\n-    indices = np.arange(len(x_train))\n-    rng.shuffle(indices)\n-    x_train = x_train[indices]\n-    labels_train = labels_train[indices]\n-\n-    indices = np.arange(len(x_test))\n-    rng.shuffle(indices)\n-    x_test = x_test[indices]\n-    labels_test = labels_test[indices]\n-\n-    xs = np.concatenate([x_train, x_test])\n-    labels = np.concatenate([labels_train, labels_test])\n-\n-    if start_char is not None:\n-        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n-    elif index_from:\n-        xs = [[w + index_from for w in x] for x in xs]\n-\n-    if maxlen:\n-        xs, labels = _remove_long_seq(maxlen, xs, labels)\n-        if not xs:\n-            raise ValueError('After filtering for sequences shorter than maxlen=' +\n-                             str(maxlen) + ', no sequence was kept. '\n-                             'Increase maxlen.')\n-    if not num_words:\n-        num_words = max([max(x) for x in xs])\n-\n-    # by convention, use 2 as OOV word\n-    # reserve 'index_from' (=3 by default) characters:\n-    # 0 (padding), 1 (start), 2 (OOV)\n-    if oov_char is not None:\n-        xs = [[w if (skip_top <= w < num_words) else oov_char for w in x]\n-              for x in xs]\n-    else:\n-        xs = [[w for w in x if skip_top <= w < num_words]\n-              for x in xs]\n-\n-    idx = len(x_train)\n-    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n-    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n-\n-    return (x_train, y_train), (x_test, y_test)\n-\n-\n-def get_word_index(path='imdb_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping words to word indices.\n-\n-    # Arguments\n-        path: where to cache the data (relative to `~/.keras/dataset`).\n-\n-    # Returns\n-        The word index dictionary.\n-    \"\"\"\n-    path = get_file(\n-        path,\n-        origin='https://s3.amazonaws.com/text-datasets/imdb_word_index.json',\n-        file_hash='bfafd718b763782e994055a2d397834f')\n-    with open(path) as f:\n-        return json.load(f)\n+from tensorflow.keras.datasets.imdb import load_data\n+from tensorflow.keras.datasets.imdb import get_word_index\n\n@@ -1,27 +1,3 @@\n-\"\"\"MNIST handwritten digits dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"MNIST handwritten digits dataset.\"\"\"\n \n-from ..utils.data_utils import get_file\n-import numpy as np\n-\n-\n-def load_data(path='mnist.npz'):\n-    \"\"\"Loads the MNIST dataset.\n-\n-    # Arguments\n-        path: path where to cache the dataset locally\n-            (relative to ~/.keras/datasets).\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-    \"\"\"\n-    path = get_file(path,\n-                    origin='https://s3.amazonaws.com/img-datasets/mnist.npz',\n-                    file_hash='8a61469f7ea1b51cbae51d4f78837e45')\n-    with np.load(path, allow_pickle=True) as f:\n-        x_train, y_train = f['x_train'], f['y_train']\n-        x_test, y_test = f['x_test'], f['y_test']\n-    return (x_train, y_train), (x_test, y_test)\n+from tensorflow.keras.datasets.mnist import load_data\n\n@@ -1,105 +1,4 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Reuters topic classification dataset.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Reuters topic classification dataset.\"\"\"\n \n-from ..utils.data_utils import get_file\n-from ..preprocessing.sequence import _remove_long_seq\n-import numpy as np\n-import json\n-import warnings\n-\n-\n-def load_data(path='reuters.npz', num_words=None, skip_top=0,\n-              maxlen=None, test_split=0.2, seed=113,\n-              start_char=1, oov_char=2, index_from=3, **kwargs):\n-    \"\"\"Loads the Reuters newswire classification dataset.\n-\n-    # Arguments\n-        path: where to cache the data (relative to `~/.keras/dataset`).\n-        num_words: max number of words to include. Words are ranked\n-            by how often they occur (in the training set) and only\n-            the most frequent words are kept\n-        skip_top: skip the top N most frequently occurring words\n-            (which may not be informative).\n-        maxlen: truncate sequences after this length.\n-        test_split: Fraction of the dataset to be used as test data.\n-        seed: random seed for sample shuffling.\n-        start_char: The start of a sequence will be marked with this character.\n-            Set to 1 because 0 is usually the padding character.\n-        oov_char: words that were cut out because of the `num_words`\n-            or `skip_top` limit will be replaced with this character.\n-        index_from: index actual words with this index and higher.\n-\n-    # Returns\n-        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n-\n-    Note that the 'out of vocabulary' character is only used for\n-    words that were present in the training set but are not included\n-    because they're not making the `num_words` cut here.\n-    Words that were not seen in the training set but are in the test set\n-    have simply been skipped.\n-    \"\"\"\n-    # Legacy support\n-    if 'nb_words' in kwargs:\n-        warnings.warn('The `nb_words` argument in `load_data` '\n-                      'has been renamed `num_words`.')\n-        num_words = kwargs.pop('nb_words')\n-    if kwargs:\n-        raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n-\n-    path = get_file(path,\n-                    origin='https://s3.amazonaws.com/text-datasets/reuters.npz',\n-                    file_hash='87aedbeb0cb229e378797a632c1997b6')\n-    with np.load(path, allow_pickle=True) as f:\n-        xs, labels = f['x'], f['y']\n-\n-    rng = np.random.RandomState(seed)\n-    indices = np.arange(len(xs))\n-    rng.shuffle(indices)\n-    xs = xs[indices]\n-    labels = labels[indices]\n-\n-    if start_char is not None:\n-        xs = [[start_char] + [w + index_from for w in x] for x in xs]\n-    elif index_from:\n-        xs = [[w + index_from for w in x] for x in xs]\n-\n-    if maxlen:\n-        xs, labels = _remove_long_seq(maxlen, xs, labels)\n-\n-    if not num_words:\n-        num_words = max([max(x) for x in xs])\n-\n-    # by convention, use 2 as OOV word\n-    # reserve 'index_from' (=3 by default) characters:\n-    # 0 (padding), 1 (start), 2 (OOV)\n-    if oov_char is not None:\n-        xs = [[w if skip_top <= w < num_words else oov_char for w in x] for x in xs]\n-    else:\n-        xs = [[w for w in x if skip_top <= w < num_words] for x in xs]\n-\n-    idx = int(len(xs) * (1 - test_split))\n-    x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n-    x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n-\n-    return (x_train, y_train), (x_test, y_test)\n-\n-\n-def get_word_index(path='reuters_word_index.json'):\n-    \"\"\"Retrieves the dictionary mapping words to word indices.\n-\n-    # Arguments\n-        path: where to cache the data (relative to `~/.keras/dataset`).\n-\n-    # Returns\n-        The word index dictionary.\n-    \"\"\"\n-    path = get_file(\n-        path,\n-        origin='https://s3.amazonaws.com/text-datasets/reuters_word_index.json',\n-        file_hash='4d44cc38712099c9e383dc6e5f11a921')\n-    with open(path) as f:\n-        return json.load(f)\n+from tensorflow.keras.datasets.reuters import load_data\n+from tensorflow.keras.datasets.reuters import get_word_index\n\n@@ -1,1474 +1,3 @@\n-\"\"\"Contains the base Layer class, from which all layers inherit.\n-\"\"\"\n-from __future__ import print_function\n-from __future__ import absolute_import\n-from __future__ import division\n-\n-import re\n-from six.moves import zip\n-import threading\n-\n-from .. import backend as K\n-from .. import initializers\n-from ..utils.layer_utils import count_params\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import object_list_uid\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import unpack_singleton\n-from ..utils.generic_utils import is_all_none\n-from ..legacy import interfaces\n-\n-_DISABLE_TRACKING = threading.local()\n-_DISABLE_TRACKING.value = False\n-\n-\n-def disable_tracking(func):\n-    def wrapped_fn(*args, **kwargs):\n-        global _DISABLE_TRACKING\n-        prev_value = _DISABLE_TRACKING.value\n-        _DISABLE_TRACKING.value = True\n-        out = func(*args, **kwargs)\n-        _DISABLE_TRACKING.value = prev_value\n-        return out\n-    return wrapped_fn\n-\n-\n-class Layer(object):\n-    \"\"\"Abstract base layer class.\n-\n-    # Properties\n-        input, output: Input/output tensor(s). Note that if the layer\n-            is used more than once (shared layer), this is ill-defined\n-            and will raise an exception. In such cases, use\n-            `layer.get_input_at(node_index)`.\n-        input_mask, output_mask: Mask tensors. Same caveats apply as\n-            input, output.\n-        input_shape: Shape tuple. Provided for convenience, but note\n-            that there may be cases in which this attribute is\n-            ill-defined (e.g. a shared layer with multiple input\n-            shapes), in which case requesting `input_shape` will raise\n-            an Exception. Prefer using\n-            `layer.get_input_shape_at(node_index)`.\n-        input_spec: List of InputSpec class instances\n-            each entry describes one required input:\n-                - ndim\n-                - dtype\n-            A layer with `n` input tensors must have\n-            an `input_spec` of length `n`.\n-        name: String, must be unique within a model.\n-        non_trainable_weights: List of variables.\n-        output_shape: Shape tuple. See `input_shape`.\n-        stateful: Boolean indicating whether the layer carries\n-            additional non-weight state. Used in, for instance, RNN\n-            cells to carry information between batches.\n-        supports_masking: Boolean indicator of whether the layer\n-            supports masking, typically for unused timesteps in a\n-            sequence.\n-        trainable: Boolean, whether the layer weights\n-            will be updated during training.\n-        trainable_weights: List of variables.\n-        uses_learning_phase: Whether any operation\n-            of the layer uses `K.in_training_phase()`\n-            or `K.in_test_phase()`.\n-        weights: The concatenation of the lists trainable_weights and\n-            non_trainable_weights (in this order).\n-        dtype:  Default dtype of the layers's weights.\n-\n-\n-    # Methods\n-        call(x, mask=None): Where the layer's logic lives.\n-        __call__(x, mask=None): Wrapper around the layer logic (`call`).\n-            If x is a Keras tensor:\n-                - Connect current layer with last layer from tensor:\n-                    `self._add_inbound_node(last_layer)`\n-                - Add layer to tensor history\n-            If layer is not built:\n-                - Build from x._keras_shape\n-        compute_mask(x, mask)\n-        compute_output_shape(input_shape)\n-        count_params()\n-        get_config()\n-        get_input_at(node_index)\n-        get_input_mask_at(node_index)\n-        get_input_shape_at(node_index)\n-        get_output_at(node_index)\n-        get_output_mask_at(node_index)\n-        get_output_shape_at(node_index)\n-        get_weights()\n-        set_weights(weights)\n-\n-    # Class Methods\n-        from_config(config)\n-\n-    # Internal methods:\n-        _add_inbound_node(layer, index=0)\n-        assert_input_compatibility()\n-        build(input_shape)\n-    \"\"\"\n-\n-    def __init__(self, **kwargs):\n-        self.input_spec = None\n-        self.supports_masking = False\n-        self.stateful = False\n-\n-        # These properties will be set upon call of self.build()\n-        self._trainable_weights = []\n-        self._non_trainable_weights = []\n-        self._losses = []\n-        self._updates = []\n-        self._per_input_losses = {}\n-        self._per_input_updates = {}\n-        self._built = False\n-\n-        # A list of metric instances corresponding to the metric tensors added using\n-        # the `add_metric` API.\n-        self._metrics = []\n-\n-        # These lists will be filled via successive calls\n-        # to self._add_inbound_node().\n-        self._inbound_nodes = []\n-        self._outbound_nodes = []\n-\n-        # These properties should be set by the user via keyword arguments.\n-        # note that 'dtype', 'input_shape' and 'batch_input_shape'\n-        # are only applicable to input layers: do not pass these keywords\n-        # to non-input layers.\n-        allowed_kwargs = {'input_shape',\n-                          'batch_input_shape',\n-                          'batch_size',\n-                          'dtype',\n-                          'name',\n-                          'trainable',\n-                          'weights',\n-                          'input_dtype',  # legacy\n-                          }\n-        for kwarg in kwargs:\n-            if kwarg not in allowed_kwargs:\n-                raise TypeError('Keyword argument not understood:', kwarg)\n-        name = kwargs.get('name')\n-        if not name:\n-            prefix = self.__class__.__name__\n-            name = _to_snake_case(prefix) + '_' + str(K.get_uid(prefix))\n-        self.name = name\n-\n-        self.trainable = kwargs.get('trainable', True)\n-        if 'input_shape' in kwargs or 'batch_input_shape' in kwargs:\n-            # In this case we will later create an input layer\n-            # to insert before the current layer\n-            if 'batch_input_shape' in kwargs:\n-                batch_input_shape = tuple(kwargs['batch_input_shape'])\n-            elif 'input_shape' in kwargs:\n-                batch_size = kwargs.get('batch_size')\n-                batch_input_shape = (\n-                    batch_size,) + tuple(kwargs['input_shape'])\n-            self.batch_input_shape = batch_input_shape\n-\n-        # Set dtype.\n-        dtype = kwargs.get('dtype')\n-        if dtype is None:\n-            dtype = kwargs.get('input_dtype')\n-        if dtype is None:\n-            dtype = K.floatx()\n-        self.dtype = dtype\n-\n-        self._initial_weights = kwargs.get('weights')\n-\n-    @staticmethod\n-    def _node_key(layer, node_index):\n-        \"\"\"Converts a layer and its index to a unique (immutable type) name.\n-\n-        This function is used internally with `self._network_nodes`.\n-\n-        # Arguments\n-            layer: The layer.\n-            node_index: The layer's position (e.g. via enumerate) in a list of\n-                nodes.\n-\n-        # Returns\n-            The unique name.\n-        \"\"\"\n-        return layer.name + '_ib-' + str(node_index)\n-\n-    @property\n-    def losses(self):\n-        losses = self._losses[:]\n-        for l in getattr(self, '_layers', []):\n-            losses += l.losses\n-        return losses\n-\n-    @property\n-    def updates(self):\n-        if not self.trainable and not self.stateful:\n-            return []\n-        updates = self._updates[:]\n-        for l in getattr(self, '_layers', []):\n-            updates += l.updates\n-        return updates\n-\n-    @property\n-    def built(self):\n-        return self._built\n-\n-    @built.setter\n-    def built(self, value):\n-        self._built = value\n-\n-    @property\n-    def trainable_weights(self):\n-        trainable = getattr(self, 'trainable', True)\n-        if trainable:\n-            trainable_weights = self._trainable_weights[:]\n-            for l in getattr(self, '_layers', []):\n-                trainable_weights += l.trainable_weights\n-            return trainable_weights\n-        else:\n-            return []\n-\n-    @trainable_weights.setter\n-    def trainable_weights(self, weights):\n-        self._trainable_weights = weights\n-\n-    @property\n-    def non_trainable_weights(self):\n-        trainable = getattr(self, 'trainable', True)\n-        if trainable:\n-            weights = self._non_trainable_weights[:]\n-            for l in getattr(self, '_layers', []):\n-                weights += l.non_trainable_weights\n-            return weights\n-\n-        else:\n-            weights = self._trainable_weights[:] + self._non_trainable_weights[:]\n-            for l in getattr(self, '_layers', []):\n-                weights += l.weights\n-            return weights\n-\n-    @non_trainable_weights.setter\n-    def non_trainable_weights(self, weights):\n-        self._non_trainable_weights = weights\n-\n-    def add_weight(self,\n-                   name=None,\n-                   shape=None,\n-                   dtype=None,\n-                   initializer=None,\n-                   regularizer=None,\n-                   trainable=True,\n-                   constraint=None):\n-        \"\"\"Adds a weight variable to the layer.\n-\n-        # Arguments\n-            name: String, the name for the weight variable.\n-            shape: The shape tuple of the weight.\n-            dtype: The dtype of the weight.\n-            initializer: An Initializer instance (callable).\n-            regularizer: An optional Regularizer instance.\n-            trainable: A boolean, whether the weight should\n-                be trained via backprop or not (assuming\n-                that the layer itself is also trainable).\n-            constraint: An optional Constraint instance.\n-\n-        # Returns\n-            The created weight variable.\n-        \"\"\"\n-        if shape is None:\n-            shape = ()\n-        initializer = initializers.get(initializer)\n-        if dtype is None:\n-            dtype = self.dtype\n-        weight = K.variable(initializer(shape, dtype=dtype),\n-                            dtype=dtype,\n-                            name=name,\n-                            constraint=constraint)\n-        if regularizer is not None:\n-            with K.name_scope('weight_regularizer'):\n-                self.add_loss(regularizer(weight))\n-        if trainable:\n-            self._trainable_weights.append(weight)\n-        else:\n-            self._non_trainable_weights.append(weight)\n-        weight._tracked = True\n-        return weight\n-\n-    def assert_input_compatibility(self, inputs):\n-        \"\"\"Checks compatibility between the layer and provided inputs.\n-\n-        This checks that the tensor(s) `input`\n-        verify the input assumptions of the layer\n-        (if any). If not, exceptions are raised.\n-\n-        # Arguments\n-            inputs: input tensor or list of input tensors.\n-\n-        # Raises\n-            ValueError: in case of mismatch between\n-                the provided inputs and the expectations of the layer.\n-        \"\"\"\n-        inputs = to_list(inputs)\n-        for x in inputs:\n-            try:\n-                K.is_keras_tensor(x)\n-            except ValueError:\n-                raise ValueError('Layer ' + self.name + ' was called with '\n-                                 'an input that isn\\'t a symbolic tensor. '\n-                                 'Received type: ' +\n-                                 str(type(x)) + '. Full input: ' +\n-                                 str(inputs) + '. All inputs to the layer '\n-                                 'should be tensors.')\n-\n-        if not self.input_spec:\n-            return\n-        if not isinstance(self.input_spec, (list, tuple)):\n-            input_spec = to_list(self.input_spec)\n-        else:\n-            input_spec = self.input_spec\n-        if len(inputs) != len(input_spec):\n-            raise ValueError('Layer ' + self.name + ' expects ' +\n-                             str(len(input_spec)) + ' inputs, '\n-                             'but it received ' + str(len(inputs)) +\n-                             ' input tensors. Input received: ' +\n-                             str(inputs))\n-        for input_index, (x, spec) in enumerate(zip(inputs, input_spec)):\n-            if spec is None:\n-                continue\n-\n-            # Check ndim.\n-            if spec.ndim is not None:\n-                if K.ndim(x) != spec.ndim:\n-                    raise ValueError('Input ' + str(input_index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected ndim=' +\n-                                     str(spec.ndim) + ', found ndim=' +\n-                                     str(K.ndim(x)))\n-            if spec.max_ndim is not None:\n-                ndim = K.ndim(x)\n-                if ndim is not None and ndim > spec.max_ndim:\n-                    raise ValueError('Input ' + str(input_index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected max_ndim=' +\n-                                     str(spec.max_ndim) + ', found ndim=' +\n-                                     str(K.ndim(x)))\n-            if spec.min_ndim is not None:\n-                ndim = K.ndim(x)\n-                if ndim is not None and ndim < spec.min_ndim:\n-                    raise ValueError('Input ' + str(input_index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected min_ndim=' +\n-                                     str(spec.min_ndim) + ', found ndim=' +\n-                                     str(K.ndim(x)))\n-            # Check dtype.\n-            if spec.dtype is not None:\n-                if K.dtype(x) != spec.dtype:\n-                    raise ValueError('Input ' + str(input_index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected dtype=' +\n-                                     str(spec.dtype) + ', found dtype=' +\n-                                     str(K.dtype(x)))\n-            # Check specific shape axes.\n-            if spec.axes:\n-                try:\n-                    x_shape = K.int_shape(x)\n-                except TypeError:\n-                    x_shape = None\n-                if x_shape is not None:\n-                    for axis, value in spec.axes.items():\n-                        if (value is not None and\n-                                x_shape[int(axis)] not in {value, None}):\n-                            raise ValueError(\n-                                'Input ' + str(input_index) +\n-                                ' is incompatible with layer ' +\n-                                self.name + ': expected axis ' +\n-                                str(axis) + ' of input shape to have '\n-                                'value ' + str(value) +\n-                                ' but got shape ' + str(x_shape))\n-            # Check shape.\n-            if spec.shape is not None:\n-                try:\n-                    x_shape = K.int_shape(x)\n-                except TypeError:\n-                    x_shape = None\n-                if x_shape is not None:\n-                    for spec_dim, dim in zip(spec.shape, x_shape):\n-                        if spec_dim is not None and dim is not None:\n-                            if spec_dim != dim:\n-                                raise ValueError(\n-                                    'Input ' + str(input_index) +\n-                                    ' is incompatible with layer ' +\n-                                    self.name + ': expected shape=' +\n-                                    str(spec.shape) + ', found shape=' +\n-                                    str(x_shape))\n-\n-    def call(self, inputs, **kwargs):\n-        \"\"\"This is where the layer's logic lives.\n-\n-        # Arguments\n-            inputs: Input tensor, or list/tuple of input tensors.\n-            **kwargs: Additional keyword arguments.\n-\n-        # Returns\n-            A tensor or list/tuple of tensors.\n-        \"\"\"\n-        return inputs\n-\n-    @K.symbolic\n-    def __call__(self, inputs, **kwargs):\n-        \"\"\"Wrapper around self.call(), for handling internal references.\n-\n-        If a Keras tensor is passed:\n-            - We call self._add_inbound_node().\n-            - If necessary, we `build` the layer to match\n-                the _keras_shape of the input(s).\n-            - We update the _keras_shape of every input tensor with\n-                its new shape (obtained via self.compute_output_shape).\n-                This is done as part of _add_inbound_node().\n-            - We update the _keras_history of the output tensor(s)\n-                with the current layer.\n-                This is done as part of _add_inbound_node().\n-\n-        # Arguments\n-            inputs: Can be a tensor or list/tuple of tensors.\n-            **kwargs: Additional keyword arguments to be passed to `call()`.\n-\n-        # Returns\n-            Output of the layer's `call` method.\n-\n-        # Raises\n-            ValueError: in case the layer is missing shape information\n-                for its `build` call.\n-        \"\"\"\n-        if isinstance(inputs, list):\n-            inputs = inputs[:]\n-        with K.name_scope(self.name):\n-            # Handle laying building (weight creating, input spec locking).\n-            if not self.built:\n-                # Raise exceptions in case the input is not compatible\n-                # with the input_spec specified in the layer constructor.\n-                self.assert_input_compatibility(inputs)\n-\n-                # Collect input shapes to build layer.\n-                input_shapes = []\n-                for x_elem in to_list(inputs):\n-                    if hasattr(x_elem, '_keras_shape'):\n-                        input_shapes.append(x_elem._keras_shape)\n-                    elif hasattr(K, 'int_shape'):\n-                        input_shapes.append(K.int_shape(x_elem))\n-                    else:\n-                        raise ValueError('You tried to call layer \"' +\n-                                         self.name +\n-                                         '\". This layer has no information'\n-                                         ' about its expected input shape, '\n-                                         'and thus cannot be built. '\n-                                         'You can build it manually via: '\n-                                         '`layer.build(batch_input_shape)`')\n-                self.build(unpack_singleton(input_shapes))\n-                self.built = True\n-\n-                # Load weights that were specified at layer instantiation.\n-                if self._initial_weights is not None:\n-                    self.set_weights(self._initial_weights)\n-\n-            # Raise exceptions in case the input is not compatible\n-            # with the input_spec set at build time.\n-            self.assert_input_compatibility(inputs)\n-\n-            # Handle mask propagation.\n-            previous_mask = _collect_previous_mask(inputs)\n-            user_kwargs = kwargs.copy()\n-            if not is_all_none(previous_mask):\n-                # The previous layer generated a mask.\n-                if has_arg(self.call, 'mask'):\n-                    if 'mask' not in kwargs:\n-                        # If mask is explicitly passed to __call__,\n-                        # we should override the default mask.\n-                        kwargs['mask'] = previous_mask\n-            # Handle automatic shape inference (only useful for Theano).\n-            input_shape = _collect_input_shape(inputs)\n-\n-            # Actually call the layer,\n-            # collecting output(s), mask(s), and shape(s).\n-            output = self.call(inputs, **kwargs)\n-            output_mask = self.compute_mask(inputs, previous_mask)\n-\n-            # If the layer returns tensors from its inputs, unmodified,\n-            # we copy them to avoid loss of tensor metadata.\n-            output_ls = to_list(output)\n-            inputs_ls = to_list(inputs)\n-            output_ls_copy = []\n-            for x in output_ls:\n-                if id(x) in [id(i) for i in inputs_ls]:\n-                    x = K.identity(x)\n-                output_ls_copy.append(x)\n-            output = unpack_singleton(output_ls_copy)\n-\n-            # Inferring the output shape is only relevant for Theano.\n-            if all([s is not None\n-                    for s in to_list(input_shape)]):\n-                output_shape = self.compute_output_shape(input_shape)\n-            else:\n-                if isinstance(input_shape, list):\n-                    output_shape = [None for _ in input_shape]\n-                else:\n-                    output_shape = None\n-\n-            if (not isinstance(output_mask, (list, tuple)) and\n-                    len(output_ls) > 1):\n-                # Augment the mask to match the length of the output.\n-                output_mask = [output_mask] * len(output_ls)\n-\n-            # Add an inbound node to the layer, so that it keeps track\n-            # of the call and of all new variables created during the call.\n-            # This also updates the layer history of the output tensor(s).\n-            # If the input tensor(s) had not previous Keras history,\n-            # this does nothing.\n-            self._add_inbound_node(input_tensors=inputs,\n-                                   output_tensors=output,\n-                                   input_masks=previous_mask,\n-                                   output_masks=output_mask,\n-                                   input_shapes=input_shape,\n-                                   output_shapes=output_shape,\n-                                   arguments=user_kwargs)\n-\n-            # Apply activity regularizer if any:\n-            if (hasattr(self, 'activity_regularizer') and\n-                    self.activity_regularizer is not None):\n-                with K.name_scope('activity_regularizer'):\n-                    regularization_losses = [\n-                        self.activity_regularizer(x)\n-                        for x in to_list(output)]\n-                self.add_loss(regularization_losses,\n-                              inputs=to_list(inputs))\n-        return output\n-\n-    def _add_inbound_node(self, input_tensors, output_tensors,\n-                          input_masks, output_masks,\n-                          input_shapes, output_shapes, arguments=None):\n-        \"\"\"Internal method to create an inbound node for the layer.\n-\n-        # Arguments\n-            input_tensors: list of input tensors.\n-            output_tensors: list of output tensors.\n-            input_masks: list of input masks (a mask can be a tensor, or None).\n-            output_masks: list of output masks\n-                (a mask can be a tensor, or None).\n-            input_shapes: list of input shape tuples.\n-            output_shapes: list of output shape tuples.\n-            arguments: dictionary of keyword arguments that were passed to the\n-                `call` method of the layer at the call that created the node.\n-        \"\"\"\n-        input_tensors = to_list(input_tensors)\n-        output_tensors = to_list(output_tensors)\n-        input_masks = to_list(input_masks)\n-        output_masks = to_list(output_masks)\n-        input_shapes = to_list(input_shapes)\n-        output_shapes = to_list(output_shapes)\n-\n-        # Collect input tensor(s) coordinates.\n-        inbound_layers = []\n-        node_indices = []\n-        tensor_indices = []\n-        for x in input_tensors:\n-            if hasattr(x, '_keras_history'):\n-                inbound_layer, node_index, tensor_index = x._keras_history\n-                inbound_layers.append(inbound_layer)\n-                node_indices.append(node_index)\n-                tensor_indices.append(tensor_index)\n-            else:\n-                inbound_layers.append(None)\n-                node_indices.append(None)\n-                tensor_indices.append(None)\n-\n-        # Create node, add it to inbound nodes.\n-        Node(\n-            self,\n-            inbound_layers=inbound_layers,\n-            node_indices=node_indices,\n-            tensor_indices=tensor_indices,\n-            input_tensors=input_tensors,\n-            output_tensors=output_tensors,\n-            input_masks=input_masks,\n-            output_masks=output_masks,\n-            input_shapes=input_shapes,\n-            output_shapes=output_shapes,\n-            arguments=arguments\n-        )\n-\n-        # Update tensor history, _keras_shape and _uses_learning_phase.\n-        for i in range(len(output_tensors)):\n-            output_tensors[i]._keras_shape = output_shapes[i]\n-            uses_lp = any(\n-                [getattr(x, '_uses_learning_phase', False)\n-                 for x in input_tensors])\n-            uses_lp = getattr(self, 'uses_learning_phase', False) or uses_lp\n-            output_tensors[i]._uses_learning_phase = getattr(\n-                output_tensors[i], '_uses_learning_phase', False) or uses_lp\n-            output_tensors[i]._keras_history = (self,\n-                                                len(self._inbound_nodes) - 1,\n-                                                i)\n-\n-    def compute_output_shape(self, input_shape):\n-        \"\"\"Computes the output shape of the layer.\n-\n-        Assumes that the layer will be built\n-        to match that input shape provided.\n-\n-        # Arguments\n-            input_shape: Shape tuple (tuple of integers)\n-                or list of shape tuples (one per output tensor of the layer).\n-                Shape tuples can include None for free dimensions,\n-                instead of an integer.\n-\n-        # Returns\n-            An output shape tuple.\n-        \"\"\"\n-        return input_shape\n-\n-    def compute_mask(self, inputs, mask=None):\n-        \"\"\"Computes an output mask tensor.\n-\n-        # Arguments\n-            inputs: Tensor or list of tensors.\n-            mask: Tensor or list of tensors.\n-\n-        # Returns\n-            None or a tensor (or list of tensors,\n-                one per output tensor of the layer).\n-        \"\"\"\n-        if not self.supports_masking:\n-            if mask is not None:\n-                if isinstance(mask, list):\n-                    if any(m is not None for m in mask):\n-                        raise TypeError('Layer ' + self.name +\n-                                        ' does not support masking, '\n-                                        'but was passed an input_mask: ' +\n-                                        str(mask))\n-                else:\n-                    raise TypeError('Layer ' + self.name +\n-                                    ' does not support masking, '\n-                                    'but was passed an input_mask: ' +\n-                                    str(mask))\n-            # masking not explicitly supported: return None as mask\n-            return None\n-        # if masking is explicitly supported, by default\n-        # carry over the input mask\n-        return mask\n-\n-    def build(self, input_shape):\n-        \"\"\"Creates the layer weights.\n-\n-        Must be implemented on all layers that have weights.\n-\n-        # Arguments\n-            input_shape: Keras tensor (future input to layer)\n-                or list/tuple of Keras tensors to reference\n-                for weight shape computations.\n-        \"\"\"\n-        self.built = True\n-\n-    def _get_node_attribute_at_index(self, node_index, attr, attr_name):\n-        \"\"\"Retrieves an attribute (e.g. input_tensors) from a node.\n-\n-        This is used to implement the methods:\n-            - get_input_shape_at\n-            - get_output_shape_at\n-            - get_input_at\n-            etc...\n-\n-        # Arguments\n-            node_index: Integer index of the node from which\n-                to retrieve the attribute.\n-            attr: Exact node attribute name.\n-            attr_name: Human-readable attribute name, for error messages.\n-\n-        # Returns\n-            The layer's attribute `attr` at the node of index `node_index`.\n-\n-        # Raises\n-            RuntimeError: If the layer has no inbound nodes.\n-            ValueError: If the index is does not match any node.\n-        \"\"\"\n-        if not self._inbound_nodes:\n-            raise RuntimeError('The layer has never been called '\n-                               'and thus has no defined ' + attr_name + '.')\n-        if not len(self._inbound_nodes) > node_index:\n-            raise ValueError('Asked to get ' + attr_name +\n-                             ' at node ' + str(node_index) +\n-                             ', but the layer has only ' +\n-                             str(len(self._inbound_nodes)) + ' inbound nodes.')\n-        values = getattr(self._inbound_nodes[node_index], attr)\n-        return unpack_singleton(values)\n-\n-    def get_input_shape_at(self, node_index):\n-        \"\"\"Retrieves the input shape(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A shape tuple\n-            (or list of shape tuples if the layer has multiple inputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'input_shapes',\n-                                                 'input shape')\n-\n-    def get_output_shape_at(self, node_index):\n-        \"\"\"Retrieves the output shape(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A shape tuple\n-            (or list of shape tuples if the layer has multiple outputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'output_shapes',\n-                                                 'output shape')\n-\n-    def get_input_at(self, node_index):\n-        \"\"\"Retrieves the input tensor(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A tensor (or list of tensors if the layer has multiple inputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'input_tensors',\n-                                                 'input')\n-\n-    def get_output_at(self, node_index):\n-        \"\"\"Retrieves the output tensor(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A tensor (or list of tensors if the layer has multiple outputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'output_tensors',\n-                                                 'output')\n-\n-    def get_input_mask_at(self, node_index):\n-        \"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A mask tensor\n-            (or list of tensors if the layer has multiple inputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'input_masks',\n-                                                 'input mask')\n-\n-    def get_output_mask_at(self, node_index):\n-        \"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n-\n-        # Arguments\n-            node_index: Integer, index of the node\n-                from which to retrieve the attribute.\n-                E.g. `node_index=0` will correspond to the\n-                first time the layer was called.\n-\n-        # Returns\n-            A mask tensor\n-            (or list of tensors if the layer has multiple outputs).\n-        \"\"\"\n-        return self._get_node_attribute_at_index(node_index,\n-                                                 'output_masks',\n-                                                 'output mask')\n-\n-    @property\n-    def input(self):\n-        \"\"\"Retrieves the input tensor(s) of a layer.\n-\n-        Only applicable if the layer has exactly one inbound node,\n-        i.e. if it is connected to one incoming layer.\n-\n-        # Returns\n-            Input tensor or list of input tensors.\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if len(self._inbound_nodes) > 1:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' has multiple inbound nodes, '\n-                                 'hence the notion of \"layer input\" '\n-                                 'is ill-defined. '\n-                                 'Use `get_input_at(node_index)` instead.')\n-        elif not self._inbound_nodes:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' is not connected, no input to return.')\n-        return self._get_node_attribute_at_index(0, 'input_tensors',\n-                                                 'input')\n-\n-    @property\n-    def output(self):\n-        \"\"\"Retrieves the output tensor(s) of a layer.\n-\n-        Only applicable if the layer has exactly one inbound node,\n-        i.e. if it is connected to one incoming layer.\n-\n-        # Returns\n-            Output tensor or list of output tensors.\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if not self._inbound_nodes:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' has no inbound nodes.')\n-        if len(self._inbound_nodes) > 1:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' has multiple inbound nodes, '\n-                                 'hence the notion of \"layer output\" '\n-                                 'is ill-defined. '\n-                                 'Use `get_output_at(node_index)` instead.')\n-        return self._get_node_attribute_at_index(0, 'output_tensors',\n-                                                 'output')\n-\n-    @property\n-    def input_mask(self):\n-        \"\"\"Retrieves the input mask tensor(s) of a layer.\n-\n-        Only applicable if the layer has exactly one inbound node,\n-        i.e. if it is connected to one incoming layer.\n-\n-        # Returns\n-            Input mask tensor (potentially None) or list of input\n-            mask tensors.\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if len(self._inbound_nodes) != 1:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' has multiple inbound nodes, ' +\n-                                 'hence the notion of \"layer input mask\" '\n-                                 'is ill-defined. '\n-                                 'Use `get_input_mask_at(node_index)` '\n-                                 'instead.')\n-        return self._get_node_attribute_at_index(0, 'input_masks',\n-                                                 'input mask')\n-\n-    @property\n-    def output_mask(self):\n-        \"\"\"Retrieves the output mask tensor(s) of a layer.\n-\n-        Only applicable if the layer has exactly one inbound node,\n-        i.e. if it is connected to one incoming layer.\n-\n-        # Returns\n-            Output mask tensor (potentially None) or list of output\n-            mask tensors.\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if len(self._inbound_nodes) != 1:\n-            raise AttributeError('Layer ' + self.name +\n-                                 ' has multiple inbound nodes, '\n-                                 'hence the notion of \"layer output mask\" '\n-                                 'is ill-defined. '\n-                                 'Use `get_output_mask_at(node_index)` '\n-                                 'instead.')\n-        return self._get_node_attribute_at_index(0, 'output_masks',\n-                                                 'output mask')\n-\n-    @property\n-    def input_shape(self):\n-        \"\"\"Retrieves the input shape tuple(s) of a layer.\n-\n-        Only applicable if the layer has exactly one inbound node,\n-        i.e. if it is connected to one incoming layer.\n-\n-        # Returns\n-            Input shape tuple\n-            (or list of input shape tuples, one tuple per input tensor).\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if not self._inbound_nodes:\n-            raise AttributeError('The layer has never been called '\n-                                 'and thus has no defined input shape.')\n-        all_input_shapes = set(\n-            [str(node.input_shapes) for node in self._inbound_nodes])\n-        if len(all_input_shapes) == 1:\n-            input_shapes = self._inbound_nodes[0].input_shapes\n-            return unpack_singleton(input_shapes)\n-        else:\n-            raise AttributeError('The layer \"' + str(self.name) +\n-                                 ' has multiple inbound nodes, '\n-                                 'with different input shapes. Hence '\n-                                 'the notion of \"input shape\" is '\n-                                 'ill-defined for the layer. '\n-                                 'Use `get_input_shape_at(node_index)` '\n-                                 'instead.')\n-\n-    @property\n-    def output_shape(self):\n-        \"\"\"Retrieves the output shape tuple(s) of a layer.\n-\n-        Only applicable if the layer has one inbound node,\n-        or if all inbound nodes have the same output shape.\n-\n-        # Returns\n-            Output shape tuple\n-            (or list of input shape tuples, one tuple per output tensor).\n-\n-        # Raises\n-            AttributeError: if the layer is connected to\n-            more than one incoming layers.\n-        \"\"\"\n-        if not self._inbound_nodes:\n-            raise AttributeError('The layer has never been called '\n-                                 'and thus has no defined output shape.')\n-        all_output_shapes = set(\n-            [str(node.output_shapes) for node in self._inbound_nodes])\n-        if len(all_output_shapes) == 1:\n-            output_shapes = self._inbound_nodes[0].output_shapes\n-            return unpack_singleton(output_shapes)\n-        else:\n-            raise AttributeError('The layer \"' + str(self.name) +\n-                                 ' has multiple inbound nodes, '\n-                                 'with different output shapes. Hence '\n-                                 'the notion of \"output shape\" is '\n-                                 'ill-defined for the layer. '\n-                                 'Use `get_output_shape_at(node_index)` '\n-                                 'instead.')\n-\n-    @property\n-    def metrics(self):\n-        metrics = self._metrics[:]\n-        for l in getattr(self, '_layers', []):\n-            metrics += l.metrics\n-        return metrics\n-\n-    def add_metric(self, value, name=None):\n-        \"\"\"Adds metric tensor to the layer.\n-\n-        # Arguments\n-            value: Metric tensor.\n-            name: String metric name.\n-        \"\"\"\n-        match = self._get_existing_metric(name)\n-        if match:\n-            return\n-        if hasattr(value, '_metric_obj'):\n-            # We track the instance using the metadata on the result tensor.\n-            # Use case: model.add_metric(metrics.Mean(name='metric_2')(y))\n-            self._metrics.append(value._metric_obj)\n-        else:\n-            # Use cases: model.add_metric(K.sum(y), name='metric_1')\n-            metric_obj = _create_mean_metric(value, name)\n-            self._metrics.append(metric_obj)\n-\n-    def add_loss(self, losses, inputs=None):\n-        \"\"\"Adds losses to the layer.\n-\n-        The loss may potentially be conditional on some inputs tensors,\n-        for instance activity losses are conditional on the layer's inputs.\n-\n-        # Arguments\n-            losses: loss tensor or list of loss tensors\n-                to add to the layer.\n-            inputs: input tensor or list of inputs tensors to mark\n-                the losses as conditional on these inputs.\n-                If None is passed, the loss is assumed unconditional\n-                (e.g. L2 weight regularization, which only depends\n-                on the layer's weights variables, not on any inputs tensors).\n-        \"\"\"\n-        if losses is None:\n-            return\n-        # Update self.losses\n-        losses = to_list(losses)\n-        if losses == []:\n-            return\n-        if hasattr(self, '_losses'):\n-            self._losses += losses\n-        # Update self._per_input_updates\n-        if isinstance(inputs, list) and inputs == []:\n-            inputs = None\n-        if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n-        else:\n-            # Updates indexed by None are unconditional\n-            # rather than input-dependent\n-            inputs_hash = None\n-        if inputs_hash not in self._per_input_losses:\n-            self._per_input_losses[inputs_hash] = []\n-        self._per_input_losses[inputs_hash] += losses\n-\n-    def add_update(self, updates, inputs=None):\n-        \"\"\"Adds updates to the layer.\n-\n-        The updates may potentially be conditional on some inputs tensors,\n-        for instance batch norm updates are conditional on the layer's inputs.\n-\n-        # Arguments\n-            updates: update op or list of update ops\n-                to add to the layer.\n-            inputs: input tensor or list of inputs tensors to mark\n-                the updates as conditional on these inputs.\n-                If None is passed, the updates are assumed unconditional.\n-        \"\"\"\n-        if updates is None:\n-            return\n-        # Update self.updates\n-        updates = to_list(updates)\n-        if updates == []:\n-            return\n-        if hasattr(self, '_updates'):\n-            self._updates += updates\n-        # Update self._per_input_updates\n-        if isinstance(inputs, list) and inputs == []:\n-            inputs = None\n-        if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n-        else:\n-            # Updates indexed by None are unconditional\n-            # rather than input-dependent\n-            inputs_hash = None\n-        if inputs_hash not in self._per_input_updates:\n-            self._per_input_updates[inputs_hash] = []\n-        self._per_input_updates[inputs_hash] += updates\n-\n-    def get_updates_for(self, inputs):\n-        if not self.trainable and not self.stateful:\n-            return []\n-        if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n-        else:\n-            inputs_hash = None\n-        updates = []\n-        if inputs_hash in self._per_input_updates:\n-            updates += self._per_input_updates[inputs_hash]\n-        for l in getattr(self, '_layers', []):\n-            updates += l.get_updates_for(inputs)\n-        return updates\n-\n-    def get_losses_for(self, inputs):\n-        if inputs is not None:\n-            inputs_hash = object_list_uid(inputs)\n-        else:\n-            inputs_hash = None\n-        losses = []\n-        if inputs_hash in self._per_input_losses:\n-            losses += self._per_input_losses[inputs_hash]\n-        for l in getattr(self, '_layers', []):\n-            losses += l.get_losses_for(inputs)\n-        return losses\n-\n-    @property\n-    def weights(self):\n-        return self.trainable_weights + self.non_trainable_weights\n-\n-    @K.eager\n-    def set_weights(self, weights):\n-        \"\"\"Sets the weights of the layer, from Numpy arrays.\n-\n-        # Arguments\n-            weights: a list of Numpy arrays. The number\n-                of arrays and their shape must match\n-                number of the dimensions of the weights\n-                of the layer (i.e. it should match the\n-                output of `get_weights`).\n-\n-        # Raises\n-            ValueError: If the provided weights list does not match the\n-                layer's specifications.\n-        \"\"\"\n-        params = self.weights\n-        if len(params) != len(weights):\n-            raise ValueError('You called `set_weights(weights)` on layer \"' +\n-                             self.name +\n-                             '\" with a weight list of length ' +\n-                             str(len(weights)) +\n-                             ', but the layer was expecting ' +\n-                             str(len(params)) +\n-                             ' weights. Provided weights: ' +\n-                             str(weights)[:50] + '...')\n-        if not params:\n-            return\n-        weight_value_tuples = []\n-        param_values = K.batch_get_value(params)\n-        for pv, p, w in zip(param_values, params, weights):\n-            if pv.shape != w.shape:\n-                raise ValueError('Layer weight shape ' +\n-                                 str(pv.shape) +\n-                                 ' not compatible with '\n-                                 'provided weight shape ' + str(w.shape))\n-            weight_value_tuples.append((p, w))\n-        K.batch_set_value(weight_value_tuples)\n-\n-    @K.eager\n-    def get_weights(self):\n-        \"\"\"Returns the current weights of the layer.\n-\n-        # Returns\n-            Weights values as a list of numpy arrays.\n-        \"\"\"\n-        params = self.weights\n-        return K.batch_get_value(params)\n-\n-    def get_config(self):\n-        \"\"\"Returns the config of the layer.\n-\n-        A layer config is a Python dictionary (serializable)\n-        containing the configuration of a layer.\n-        The same layer can be reinstantiated later\n-        (without its trained weights) from this configuration.\n-\n-        The config of a layer does not include connectivity\n-        information, nor the layer class name. These are handled\n-        by `Network` (one layer of abstraction above).\n-\n-        # Returns\n-            Python dictionary.\n-        \"\"\"\n-        config = {'name': self.name,\n-                  'trainable': self.trainable}\n-        if hasattr(self, 'batch_input_shape'):\n-            config['batch_input_shape'] = self.batch_input_shape\n-        if hasattr(self, 'dtype'):\n-            config['dtype'] = self.dtype\n-        return config\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        \"\"\"Creates a layer from its config.\n-\n-        This method is the reverse of `get_config`,\n-        capable of instantiating the same layer from the config\n-        dictionary. It does not handle layer connectivity\n-        (handled by Network), nor weights (handled by `set_weights`).\n-\n-        # Arguments\n-            config: A Python dictionary, typically the\n-                output of get_config.\n-\n-        # Returns\n-            A layer instance.\n-        \"\"\"\n-        return cls(**config)\n-\n-    def count_params(self):\n-        \"\"\"Counts the total number of scalars composing the weights.\n-\n-        # Returns\n-            An integer count.\n-\n-        # Raises\n-            RuntimeError: if the layer isn't yet built\n-                (in which case its weights aren't yet defined).\n-        \"\"\"\n-        if not self.built:\n-            if self.__class__.__name__ == 'Sequential':\n-                self.build()\n-            else:\n-                raise RuntimeError('You tried to call `count_params` on ' +\n-                                   self.name + ', but the layer isn\\'t built. '\n-                                   'You can build it manually via: `' +\n-                                   self.name + '.build(batch_input_shape)`.')\n-        return count_params(self.weights)\n-\n-    def _get_existing_metric(self, name=None):\n-        match = [m for m in self._metrics if m.name == name]\n-        if not match:\n-            return\n-        if len(match) > 1:\n-            raise ValueError(\n-                'Please provide different names for the metrics you have added. '\n-                'We found {} metrics with the name: \"{}\"'.format(len(match), name))\n-        return match[0]\n-\n-    def __setattr__(self, name, value):\n-        # Keep track of metric instance created in subclassed model/layer.\n-        # We do this so that we can maintain the correct order of metrics by adding\n-        # the instance to the `metrics` list as soon as it is created.\n-        if not hasattr(_DISABLE_TRACKING, 'value'):\n-            _DISABLE_TRACKING.value = False\n-        if not _DISABLE_TRACKING.value:\n-            from .. import metrics as metrics_module\n-            if isinstance(value, metrics_module.Metric):\n-                if not hasattr(self, '_metrics'):\n-                    self._metrics = []\n-                self._metrics.append(value)\n-            else:\n-                # Automatically track layers set as attributes.\n-                if isinstance(value, Layer):\n-                    if not hasattr(self, '_layers'):\n-                        self._layers = []\n-                    if value not in self._layers:\n-                        self._layers.append(value)\n-                if K.is_variable(value) and not getattr(value, '_tracked', False):\n-                    # Automatically track variables set as attributes.\n-                    trainable = getattr(value, 'trainable', False)\n-                    if trainable:\n-                        if not hasattr(self, '_trainable_weights'):\n-                            self._trainable_weights = []\n-                        if not any(v is value for v in self._trainable_weights):\n-                            print('tracking', value, name)\n-                            self._trainable_weights.append(value)\n-                    else:\n-                        if not hasattr(self, '_non_trainable_weights'):\n-                            self._non_trainable_weights = []\n-                        if not any(v is value for v in self._non_trainable_weights):\n-                            self._non_trainable_weights.append(value)\n-\n-        super(Layer, self).__setattr__(name, value)\n-\n-\n-def _create_mean_metric(value, name=None):\n-    from .. import metrics\n-    metric_obj = metrics.Mean(name=name)\n-    _call_metric(metric_obj, value)\n-    return metric_obj\n-\n-\n-@K.symbolic\n-def _call_metric(metric_obj, *args, **kwargs):\n-    update_op = metric_obj.update_state(*args, **kwargs)\n-    with K.control_dependencies(update_op):  # For TF\n-        result_t = metric_obj.result()\n-\n-\n-class InputSpec(object):\n-    \"\"\"Specifies the ndim, dtype and shape of every input to a layer.\n-\n-    Every layer should expose (if appropriate) an `input_spec` attribute:\n-    a list of instances of InputSpec (one per input tensor).\n-\n-    A None entry in a shape is compatible with any dimension,\n-    a None shape is compatible with any shape.\n-\n-    # Arguments\n-        dtype: Expected datatype of the input.\n-        shape: Shape tuple, expected shape of the input\n-            (may include None for unchecked axes).\n-        ndim: Integer, expected rank of the input.\n-        max_ndim: Integer, maximum rank of the input.\n-        min_ndim: Integer, minimum rank of the input.\n-        axes: Dictionary mapping integer axes to\n-            a specific dimension value.\n-    \"\"\"\n-\n-    def __init__(self, dtype=None,\n-                 shape=None,\n-                 ndim=None,\n-                 max_ndim=None,\n-                 min_ndim=None,\n-                 axes=None):\n-        self.dtype = dtype\n-        self.shape = shape\n-        if shape is not None:\n-            self.ndim = len(shape)\n-        else:\n-            self.ndim = ndim\n-        self.max_ndim = max_ndim\n-        self.min_ndim = min_ndim\n-        self.axes = axes or {}\n-\n-    def __repr__(self):\n-        spec = [('dtype=' + str(self.dtype)) if self.dtype else '',\n-                ('shape=' + str(self.shape)) if self.shape else '',\n-                ('ndim=' + str(self.ndim)) if self.ndim else '',\n-                ('max_ndim=' + str(self.max_ndim)) if self.max_ndim else '',\n-                ('min_ndim=' + str(self.min_ndim)) if self.min_ndim else '',\n-                ('axes=' + str(self.axes)) if self.axes else '']\n-        return 'InputSpec(%s)' % ', '.join(x for x in spec if x)\n-\n-\n-class Node(object):\n-    \"\"\"A `Node` describes the connectivity between two layers.\n-\n-    Each time a layer is connected to some new input,\n-    a node is added to `layer._inbound_nodes`.\n-    Each time the output of a layer is used by another layer,\n-    a node is added to `layer._outbound_nodes`.\n-\n-    # Arguments\n-        outbound_layer: the layer that takes\n-            `input_tensors` and turns them into `output_tensors`\n-            (the node gets created when the `call`\n-            method of the layer was called).\n-        inbound_layers: a list of layers, the same length as `input_tensors`,\n-            the layers from where `input_tensors` originate.\n-        node_indices: a list of integers, the same length as `inbound_layers`.\n-            `node_indices[i]` is the origin node of `input_tensors[i]`\n-            (necessary since each inbound layer might have several nodes,\n-            e.g. if the layer is being shared with a different data stream).\n-        tensor_indices: a list of integers,\n-            the same length as `inbound_layers`.\n-            `tensor_indices[i]` is the index of `input_tensors[i]` within the\n-            output of the inbound layer\n-            (necessary since each inbound layer might\n-            have multiple tensor outputs, with each one being\n-            independently manipulable).\n-        input_tensors: list of input tensors.\n-        output_tensors: list of output tensors.\n-        input_masks: list of input masks (a mask can be a tensor, or None).\n-        output_masks: list of output masks (a mask can be a tensor, or None).\n-        input_shapes: list of input shape tuples.\n-        output_shapes: list of output shape tuples.\n-        arguments: dictionary of keyword arguments that were passed to the\n-            `call` method of the layer at the call that created the node.\n-\n-    `node_indices` and `tensor_indices` are basically fine-grained coordinates\n-    describing the origin of the `input_tensors`, verifying the following:\n-\n-    origin_node = inbound_layers[i]._inbound_nodes[node_indices[i]]\n-    input_tensors[i] == origin_node.output_tensors[tensor_indices[i]]\n-\n-    A node from layer A to layer B is added to:\n-        A._outbound_nodes\n-        B._inbound_nodes\n-    \"\"\"\n-\n-    def __init__(self, outbound_layer,\n-                 inbound_layers, node_indices, tensor_indices,\n-                 input_tensors, output_tensors,\n-                 input_masks, output_masks,\n-                 input_shapes, output_shapes,\n-                 arguments=None):\n-        # Layer instance (NOT a list).\n-        # this is the layer that takes a list of input tensors\n-        # and turns them into a list of output tensors.\n-        # the current node will be added to\n-        # the inbound_nodes of outbound_layer.\n-        self.outbound_layer = outbound_layer\n-\n-        # The following 3 properties describe where\n-        # the input tensors come from: which layers,\n-        # and for each layer, which node and which\n-        # tensor output of each node.\n-\n-        # List of layer instances.\n-        self.inbound_layers = inbound_layers\n-        # List of integers, 1:1 mapping with inbound_layers.\n-        self.node_indices = node_indices\n-        # List of integers, 1:1 mapping with inbound_layers.\n-        self.tensor_indices = tensor_indices\n-\n-        # Following 2 properties:\n-        # tensor inputs and outputs of outbound_layer.\n-\n-        # List of tensors. 1:1 mapping with inbound_layers.\n-        self.input_tensors = input_tensors\n-        # List of tensors, created by outbound_layer.call().\n-        self.output_tensors = output_tensors\n-\n-        # Following 2 properties: input and output masks.\n-        # List of tensors, 1:1 mapping with input_tensor.\n-        self.input_masks = input_masks\n-        # List of tensors, created by outbound_layer.compute_mask().\n-        self.output_masks = output_masks\n-\n-        # Following 2 properties: input and output shapes.\n-\n-        # List of shape tuples, shapes of input_tensors.\n-        self.input_shapes = input_shapes\n-        # List of shape tuples, shapes of output_tensors.\n-        self.output_shapes = output_shapes\n-\n-        # Optional keyword arguments to layer's `call`.\n-        self.arguments = arguments\n-\n-        # Add nodes to all layers involved.\n-        for layer in inbound_layers:\n-            if layer is not None:\n-                layer._outbound_nodes.append(self)\n-        outbound_layer._inbound_nodes.append(self)\n-\n-    def get_config(self):\n-        inbound_names = []\n-        for layer in self.inbound_layers:\n-            if layer:\n-                inbound_names.append(layer.name)\n-            else:\n-                inbound_names.append(None)\n-        if self.outbound_layer:\n-            outbound_layer = self.outbound_layer.name\n-        else:\n-            outbound_layer = None\n-        return {'outbound_layer': outbound_layer,\n-                'inbound_layers': inbound_names,\n-                'node_indices': self.node_indices,\n-                'tensor_indices': self.tensor_indices}\n-\n-\n-def _collect_previous_mask(input_tensors):\n-    \"\"\"Retrieves the output mask(s) of the previous node.\n-\n-    # Arguments\n-        input_tensors: A tensor or list of tensors.\n-\n-    # Returns\n-        A mask tensor or list of mask tensors.\n-    \"\"\"\n-    input_tensors = to_list(input_tensors)\n-    masks = []\n-    for x in input_tensors:\n-        if hasattr(x, '_keras_history'):\n-            inbound_layer, node_index, tensor_index = x._keras_history\n-            node = inbound_layer._inbound_nodes[node_index]\n-            mask = node.output_masks[tensor_index]\n-            masks.append(mask)\n-        else:\n-            masks.append(None)\n-    return unpack_singleton(masks)\n-\n-\n-def _to_snake_case(name):\n-    intermediate = re.sub('(.)([A-Z][a-z0-9]+)', r'\\1_\\2', name)\n-    insecure = re.sub('([a-z])([A-Z])', r'\\1_\\2', intermediate).lower()\n-    # If the class is private the name starts with \"_\" which is not secure\n-    # for creating scopes. We prefix the name with \"private\" in this case.\n-    if insecure[0] != '_':\n-        return insecure\n-    return 'private' + insecure\n-\n-\n-def _collect_input_shape(input_tensors):\n-    \"\"\"Collects the output shape(s) of a list of Keras tensors.\n-\n-    # Arguments\n-        input_tensors: list of input tensors (or single input tensor).\n-\n-    # Returns\n-        List of shape tuples (or single tuple), one tuple per input.\n-    \"\"\"\n-    input_tensors = to_list(input_tensors)\n-    shapes = []\n-    for x in input_tensors:\n-        try:\n-            shapes.append(K.int_shape(x))\n-        except TypeError:\n-            shapes.append(None)\n-    return unpack_singleton(shapes)\n+\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\n+from tensorflow.keras.layers import Layer\n+from tensorflow.keras.layers import InputSpec\n\n@@ -1,182 +1,4 @@\n-\"\"\"Input layer code (`Input` and `InputLayer`).\n-\"\"\"\n-from __future__ import print_function\n-from __future__ import absolute_import\n-from __future__ import division\n+\"\"\"Input layer code (`Input` and `InputLayer`).\"\"\"\n+from tensorflow.keras.layers import InputLayer\n+from tensorflow.keras import Input\n \n-from .base_layer import Layer\n-from .base_layer import Node\n-from .. import backend as K\n-from ..legacy import interfaces\n-from ..utils.generic_utils import unpack_singleton\n-\n-\n-class InputLayer(Layer):\n-    \"\"\"Layer to be used as an entry point into a model.\n-\n-    It can either wrap an existing tensor (pass an `input_tensor` argument)\n-    or create its a placeholder tensor (pass arguments `input_shape`\n-    or `batch_input_shape` as well as `dtype`).\n-\n-    # Arguments\n-        input_shape: Shape tuple, not including the batch axis.\n-        batch_size: Optional input batch size (integer or None).\n-        batch_input_shape: Shape tuple, including the batch axis.\n-        dtype: Datatype of the input.\n-        input_tensor: Optional tensor to use as layer input\n-            instead of creating a placeholder.\n-        sparse: Boolean, whether the placeholder created\n-            is meant to be sparse.\n-        name: Name of the layer (string).\n-    \"\"\"\n-\n-    @interfaces.legacy_input_support\n-    def __init__(self, input_shape=None, batch_size=None,\n-                 batch_input_shape=None,\n-                 dtype=None, input_tensor=None, sparse=False, name=None):\n-        if not name:\n-            prefix = 'input'\n-            name = prefix + '_' + str(K.get_uid(prefix))\n-        super(InputLayer, self).__init__(dtype=dtype, name=name)\n-\n-        self.trainable = False\n-        self.built = True\n-        self.sparse = sparse\n-        self.supports_masking = True\n-\n-        if input_shape and batch_input_shape:\n-            raise ValueError('Only provide the input_shape OR '\n-                             'batch_input_shape argument to '\n-                             'InputLayer, not both at the same time.')\n-        if input_tensor is not None and batch_input_shape is None:\n-            # If input_tensor is set, and batch_input_shape is not set:\n-            # Attempt automatic input shape inference.\n-            try:\n-                batch_input_shape = K.int_shape(input_tensor)\n-            except TypeError:\n-                if not input_shape and not batch_input_shape:\n-                    raise ValueError('InputLayer was provided '\n-                                     'an input_tensor argument, '\n-                                     'but its input shape cannot be '\n-                                     'automatically inferred. '\n-                                     'You should pass an input_shape or '\n-                                     'batch_input_shape argument.')\n-        if not batch_input_shape:\n-            if not input_shape:\n-                raise ValueError('An Input layer should be passed either '\n-                                 'a `batch_input_shape` or an `input_shape`.')\n-            else:\n-                batch_input_shape = (batch_size,) + tuple(input_shape)\n-        else:\n-            batch_input_shape = tuple(batch_input_shape)\n-\n-        if not dtype:\n-            if input_tensor is None:\n-                dtype = K.floatx()\n-            else:\n-                dtype = K.dtype(input_tensor)\n-\n-        self.batch_input_shape = batch_input_shape\n-        self.dtype = dtype\n-\n-        if input_tensor is None:\n-            self.is_placeholder = True\n-            input_tensor = K.placeholder(shape=batch_input_shape,\n-                                         dtype=dtype,\n-                                         sparse=self.sparse,\n-                                         name=self.name)\n-        else:\n-            self.is_placeholder = False\n-            input_tensor._keras_shape = batch_input_shape\n-        # Create an input node to add to self.outbound_node\n-        # and set output_tensors' _keras_history.\n-        input_tensor._uses_learning_phase = False\n-        input_tensor._keras_history = (self, 0, 0)\n-        Node(self,\n-             inbound_layers=[],\n-             node_indices=[],\n-             tensor_indices=[],\n-             input_tensors=[input_tensor],\n-             output_tensors=[input_tensor],\n-             input_masks=[None],\n-             output_masks=[None],\n-             input_shapes=[batch_input_shape],\n-             output_shapes=[batch_input_shape])\n-\n-    def get_config(self):\n-        config = {'batch_input_shape': self.batch_input_shape,\n-                  'dtype': self.dtype,\n-                  'sparse': self.sparse,\n-                  'name': self.name}\n-        return config\n-\n-\n-def Input(shape=None, batch_shape=None,\n-          name=None, dtype=None, sparse=False,\n-          tensor=None):\n-    \"\"\"`Input()` is used to instantiate a Keras tensor.\n-\n-    A Keras tensor is a tensor object from the underlying backend\n-    (Theano, TensorFlow or CNTK), which we augment with certain\n-    attributes that allow us to build a Keras model\n-    just by knowing the inputs and outputs of the model.\n-\n-    For instance, if a, b and c are Keras tensors,\n-    it becomes possible to do:\n-    `model = Model(input=[a, b], output=c)`\n-\n-    The added Keras attributes are:\n-        `_keras_shape`: Integer shape tuple propagated\n-            via Keras-side shape inference.\n-        `_keras_history`: Last layer applied to the tensor.\n-            the entire layer graph is retrievable from that layer,\n-            recursively.\n-\n-    # Arguments\n-        shape: A shape tuple (integer), not including the batch size.\n-            For instance, `shape=(32,)` indicates that the expected input\n-            will be batches of 32-dimensional vectors.\n-        batch_shape: A shape tuple (integer), including the batch size.\n-            For instance, `batch_shape=(10, 32)` indicates that\n-            the expected input will be batches of 10 32-dimensional vectors.\n-            `batch_shape=(None, 32)` indicates batches of an arbitrary number\n-            of 32-dimensional vectors.\n-        name: An optional name string for the layer.\n-            Should be unique in a model (do not reuse the same name twice).\n-            It will be autogenerated if it isn't provided.\n-        dtype: The data type expected by the input, as a string\n-            (`float32`, `float64`, `int32`...)\n-        sparse: A boolean specifying whether the placeholder\n-            to be created is sparse.\n-        tensor: Optional existing tensor to wrap into the `Input` layer.\n-            If set, the layer will not create a placeholder tensor.\n-\n-    # Returns\n-        A tensor.\n-\n-    # Example\n-\n-    ```python\n-    # this is a logistic regression in Keras\n-    x = Input(shape=(32,))\n-    y = Dense(16, activation='softmax')(x)\n-    model = Model(x, y)\n-    ```\n-    \"\"\"\n-    if not batch_shape and tensor is None:\n-        assert shape is not None, ('Please provide to Input either a `shape`'\n-                                   ' or a `batch_shape` argument. Note that '\n-                                   '`shape` does not include the batch '\n-                                   'dimension.')\n-    if shape is not None and not batch_shape:\n-        batch_shape = (None,) + tuple(shape)\n-    if not dtype:\n-        dtype = K.floatx()\n-    input_layer = InputLayer(batch_input_shape=batch_shape,\n-                             name=name, dtype=dtype,\n-                             sparse=sparse,\n-                             input_tensor=tensor)\n-    # Return tensor including _keras_shape and _keras_history.\n-    # Note that in this case train_output and test_output are the same pointer.\n-    outputs = input_layer._inbound_nodes[0].output_tensors\n-    return unpack_singleton(outputs)\n\n@@ -1,1525 +1,4 @@\n-\"\"\"A `Network` is way to compose layers: the topological form of a `Model`.\n-\"\"\"\n-from __future__ import print_function\n-from __future__ import absolute_import\n-from __future__ import division\n+\"\"\"A `Network` is way to compose layers: the topological form of a `Model`.\"\"\"\n \n-import numpy as np\n-import json\n-import yaml\n-import warnings\n-import copy\n-import os\n-from six.moves import zip\n-\n-from . import saving\n-from .base_layer import Layer\n-from .base_layer import Node\n-from .input_layer import InputLayer\n-from .. import backend as K\n-from ..utils.io_utils import ask_to_proceed_with_overwrite\n-from ..utils.layer_utils import print_summary as print_layer_summary\n-from ..utils.layer_utils import get_source_inputs\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import object_list_uid\n-from ..utils.generic_utils import unpack_singleton\n-from ..legacy import interfaces\n-\n-try:\n-    import h5py\n-except ImportError:\n-    h5py = None\n-\n-\n-class Network(Layer):\n-    \"\"\"A Network is a directed acyclic graph of layers.\n-\n-    It is the topological form of a \"model\". A Model\n-    is simply a Network with added training routines.\n-\n-    # Properties\n-        name\n-        inputs\n-        outputs\n-        layers\n-        input_spec (list of class instances)\n-            each entry describes one required input:\n-                - ndim\n-                - dtype\n-        trainable (boolean)\n-        dtype\n-        input_shape\n-        output_shape\n-        weights (list of variables)\n-        trainable_weights (list of variables)\n-        non_trainable_weights (list of variables)\n-        losses\n-        updates\n-        state_updates\n-        stateful\n-\n-    # Methods\n-        __call__\n-        summary\n-        get_layer\n-        get_weights\n-        set_weights\n-        get_config\n-        compute_output_shape\n-        save\n-        add_loss\n-        add_update\n-        get_losses_for\n-        get_updates_for\n-        to_json\n-        to_yaml\n-        reset_states\n-\n-    # Class Methods\n-        from_config\n-\n-    # Raises\n-        TypeError: if input tensors are not Keras tensors\n-            (tensors returned by `Input`).\n-    \"\"\"\n-\n-    @interfaces.legacy_model_constructor_support\n-    def __init__(self, *args, **kwargs):\n-        # Signature detection\n-        if (len(args) == 2 or\n-            len(args) == 1 and 'outputs' in kwargs or\n-                'inputs' in kwargs and 'outputs' in kwargs):\n-            # Graph network\n-            self._init_graph_network(*args, **kwargs)\n-        else:\n-            # Subclassed network\n-            self._init_subclassed_network(**kwargs)\n-\n-    def _base_init(self, name=None, trainable=True, dtype=None):\n-        # The following are implemented as property functions:\n-        # self.trainable_weights\n-        # self.non_trainable_weights\n-        # self.input_spec\n-        # self.losses\n-        # self.updates\n-\n-        # Handle `name` argument.\n-        if not name:\n-            prefix = self.__class__.__name__.lower()\n-            name = prefix + '_' + str(K.get_uid(prefix))\n-        self.name = name\n-\n-        # This acts just like the `trainable` attribute of any layer instance.\n-        # It does not affect users of the underlying layers, only users of the\n-        # Network instance.\n-        self.trainable = trainable\n-        if dtype is None:\n-            dtype = K.floatx()\n-        self.dtype = dtype\n-        self._is_compiled = False\n-        self._expects_training_arg = False\n-        self._initial_weights = None\n-\n-        self.supports_masking = False\n-        if not hasattr(self, 'optimizer'):\n-            # Don't reset optimizer if already set.\n-            self.optimizer = None\n-\n-        # Private attributes to implement compatibility with Layer.\n-        self._trainable_weights = []\n-        self._non_trainable_weights = []\n-        self._updates = []\n-        self._losses = []\n-        self._per_input_losses = {}\n-        self._per_input_updates = {}\n-\n-        # A list of metric instances corresponding to the metric tensors added using\n-        # the `add_metric` API.\n-        self._metrics = []\n-\n-        # All layers in order of horizontal graph traversal.\n-        # Entries are unique. Includes input and output layers.\n-        self._layers = []\n-\n-        # Used only in conjunction with graph-networks\n-        self._outbound_nodes = []\n-        self._inbound_nodes = []\n-\n-    def _init_graph_network(self, inputs, outputs, name=None, **kwargs):\n-        self._uses_inputs_arg = True\n-        # Normalize and set self.inputs, self.outputs.\n-        self.inputs = to_list(inputs, allow_tuple=True)\n-        self.outputs = to_list(outputs, allow_tuple=True)\n-\n-        # User-provided argument validation.\n-        # Check for redundancy in inputs.\n-        if len(set(id(x) for x in self.inputs)) != len(self.inputs):\n-            raise ValueError('The list of inputs passed to the model '\n-                             'is redundant. '\n-                             'All inputs should only appear once.'\n-                             ' Found: ' + str(self.inputs))\n-        for x in self.inputs:\n-            # Check that x has appropriate `_keras_history` metadata.\n-            if not hasattr(x, '_keras_history'):\n-                cls_name = self.__class__.__name__\n-                raise ValueError('Input tensors to a ' + cls_name + ' ' +\n-                                 'must come from `keras.layers.Input`. '\n-                                 'Received: ' + str(x) +\n-                                 ' (missing previous layer metadata).')\n-            # Check that x is an input tensor.\n-            layer, node_index, tensor_index = x._keras_history\n-            if (len(layer._inbound_nodes) > 1 or\n-                    (layer._inbound_nodes and\n-                     layer._inbound_nodes[0].inbound_layers)):\n-                cls_name = self.__class__.__name__\n-                warnings.warn(cls_name + ' inputs must come from '\n-                              '`keras.layers.Input` '\n-                              '(thus holding past layer metadata), '\n-                              'they cannot be the output of '\n-                              'a previous non-Input layer. '\n-                              'Here, a tensor specified as '\n-                              'input to your model '\n-                              'was not an Input tensor, '\n-                              'it was generated by layer ' +\n-                              layer.name + '.\\n'\n-                              'Note that input tensors are '\n-                              'instantiated via '\n-                              '`tensor = keras.layers.Input(shape)`.\\n'\n-                              'The tensor that caused the issue was: ' +\n-                              str(x.name))\n-        for x in self.outputs:\n-            if not hasattr(x, '_keras_history'):\n-                cls_name = self.__class__.__name__\n-                raise ValueError('Output tensors to a ' + cls_name +\n-                                 ' must be '\n-                                 'the output of a Keras `Layer` '\n-                                 '(thus holding past layer metadata). '\n-                                 'Found: ' + str(x))\n-        self._base_init(name=name, **kwargs)\n-        self._compute_previous_mask = (\n-            has_arg(self.call, 'mask') or\n-            hasattr(self, 'compute_mask'))\n-        # A Network does not create weights of its own,\n-        # thus it is already built.\n-        self.built = True\n-        self._is_graph_network = True\n-\n-        self._input_layers = []\n-        self._output_layers = []\n-        self._input_coordinates = []\n-        self._output_coordinates = []\n-\n-        # This is for performance optimization when calling the Network on new\n-        # inputs. Every time the Network is called on a set on input tensors,\n-        # we compute the output tensors,\n-        # output masks and output shapes in one pass,\n-        # then cache them here. When any of these outputs is queried later, we\n-        # retrieve it from there instead of recomputing it.\n-        self._output_mask_cache = {}\n-        self._output_tensor_cache = {}\n-        self._output_shape_cache = {}\n-\n-        # Build self._output_layers:\n-        for x in self.outputs:\n-            layer, node_index, tensor_index = x._keras_history\n-            self._output_layers.append(layer)\n-            self._output_coordinates.append((layer, node_index, tensor_index))\n-\n-        # Build self._input_layers:\n-        for x in self.inputs:\n-            layer, node_index, tensor_index = x._keras_history\n-            # It's supposed to be an input layer, so only one node\n-            # and one tensor output.\n-            assert node_index == 0\n-            assert tensor_index == 0\n-            self._input_layers.append(layer)\n-            self._input_coordinates.append((layer, node_index, tensor_index))\n-\n-        # Keep track of the network's nodes and layers.\n-        nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n-            self.inputs, self.outputs)\n-        self._network_nodes = nodes\n-        self._nodes_by_depth = nodes_by_depth\n-        self._layers = layers\n-        self._layers_by_depth = layers_by_depth\n-\n-        # Create the node linking internal inputs to internal outputs.\n-        Node(outbound_layer=self,\n-             inbound_layers=[],\n-             node_indices=[],\n-             tensor_indices=[],\n-             input_tensors=self.inputs,\n-             output_tensors=self.outputs,\n-             # No network-level masking for now.\n-             input_masks=[None for _ in self.inputs],\n-             output_masks=[None for _ in self.outputs],\n-             input_shapes=[x._keras_shape for x in self.inputs],\n-             output_shapes=[x._keras_shape for x in self.outputs])\n-\n-        # Fill in the output mask cache.\n-        masks = []\n-        for x in self.inputs:\n-            layer, node_index, tensor_index = x._keras_history\n-            node = layer._inbound_nodes[node_index]\n-            mask = node.output_masks[tensor_index]\n-            masks.append(mask)\n-        mask_cache_key = object_list_uid(inputs)\n-        mask_cache_key += '_' + object_list_uid(masks)\n-        masks = []\n-        for x in self.outputs:\n-            layer, node_index, tensor_index = x._keras_history\n-            node = layer._inbound_nodes[node_index]\n-            mask = node.output_masks[tensor_index]\n-            masks.append(mask)\n-        mask = unpack_singleton(masks)\n-        self._output_mask_cache[mask_cache_key] = mask\n-\n-        # Build self.input_names and self.output_names.\n-        self.input_names = []\n-        self.output_names = []\n-        self._feed_input_names = []\n-        self._feed_inputs = []\n-        self._feed_input_shapes = []\n-        for i, layer in enumerate(self._input_layers):\n-            # Check that layer is an InputLayer.\n-            if not isinstance(layer, InputLayer):\n-                raise TypeError(\n-                    'Input layers to a `Model` must be `InputLayer` objects. '\n-                    'Received inputs: {}. '\n-                    'Input {} (0-based) originates '\n-                    'from layer type `{}`.'.format(inputs,\n-                                                   i,\n-                                                   layer.__class__.__name__))\n-            self.input_names.append(layer.name)\n-            if layer.is_placeholder:\n-                self._feed_inputs.append(layer.input)\n-                self._feed_input_names.append(layer.name)\n-                self._feed_input_shapes.append(self.inputs[i]._keras_shape)\n-\n-        for layer in self._output_layers:\n-            self.output_names.append(layer.name)\n-\n-    def _init_subclassed_network(self, name=None, **kwargs):\n-        self._base_init(name=name, **kwargs)\n-        self._is_graph_network = False\n-        self._expects_training_arg = has_arg(self.call, 'training')\n-        self._uses_inputs_arg = has_arg(self.call, 'inputs')\n-        self.outputs = None\n-        self.inputs = None\n-        self.built = False\n-\n-    def __setattr__(self, name, value):\n-        # Automatically track layers set as Model\n-        # attributes for subclassed Models.\n-        if isinstance(value, Layer):\n-            try:\n-                is_graph_network = self._is_graph_network\n-            except AttributeError:\n-                raise RuntimeError(\n-                    'It looks like you are subclassing `Model` and you '\n-                    'forgot to call `super(YourClass, self).__init__()`.'\n-                    ' Always start with this line.')\n-        super(Network, self).__setattr__(name, value)\n-\n-    @property\n-    def layers(self):\n-        return self._layers\n-\n-    def get_layer(self, name=None, index=None):\n-        \"\"\"Retrieves a layer based on either its name (unique) or index.\n-\n-        If `name` and `index` are both provided, `index` will take precedence.\n-\n-        Indices are based on order of horizontal graph traversal (bottom-up).\n-\n-        # Arguments\n-            name: String, name of layer.\n-            index: Integer, index of layer.\n-\n-        # Returns\n-            A layer instance.\n-\n-        # Raises\n-            ValueError: In case of invalid layer name or index.\n-        \"\"\"\n-        # It would be unreliable to build a dictionary\n-        # based on layer names, because names can potentially\n-        # be changed at any point by the user\n-        # without the network being notified of it.\n-        if index is not None:\n-            if len(self.layers) <= index:\n-                raise ValueError('Was asked to retrieve layer at index ' +\n-                                 str(index) + ' but model only has ' +\n-                                 str(len(self.layers)) + ' layers.')\n-            else:\n-                return self.layers[index]\n-        else:\n-            if not name:\n-                raise ValueError('Provide either a layer name or layer index.')\n-\n-        for layer in self.layers:\n-            if layer.name == name:\n-                return layer\n-\n-        raise ValueError('No such layer: ' + name)\n-\n-    @property\n-    def updates(self):\n-        \"\"\"Retrieves the model's updates.\n-\n-        Will only include updates that are either\n-        unconditional, or conditional on inputs to this model\n-        (e.g. will not include updates that depend on tensors\n-        that aren't inputs to this model).\n-\n-        # Returns\n-            A list of update ops.\n-        \"\"\"\n-        if not self.trainable and not self.stateful:\n-            return []\n-        updates = []\n-        for layer in self.layers:\n-            if hasattr(layer, 'updates'):\n-                if self._is_graph_network:\n-                    # Collect updates that are dependent on inputs\n-                    # that are part of the model.\n-                    for node_index, node in enumerate(layer._inbound_nodes):\n-                        node_key = self._node_key(layer, node_index)\n-                        if node_key in self._network_nodes:\n-                            # The model owns this layer node.\n-                            inputs = node.input_tensors\n-                            updates += layer.get_updates_for(inputs)\n-                    # Collect unconditional updates.\n-                    updates += layer.get_updates_for(None)\n-                else:\n-                    updates += layer.updates\n-        return updates\n-\n-    @property\n-    def losses(self):\n-        \"\"\"Retrieves the model's losses.\n-\n-        Will only include losses that are either\n-        unconditional, or conditional on inputs to this model\n-        (e.g. will not include losses that depend on tensors\n-        that aren't inputs to this model).\n-\n-        # Returns\n-            A list of loss tensors.\n-        \"\"\"\n-        losses = []\n-        for layer in self.layers:\n-            if hasattr(layer, 'losses'):\n-                if self._is_graph_network:\n-                    # Collect losses that are dependent on inputs\n-                    # that are part of the model.\n-                    for node_index, node in enumerate(layer._inbound_nodes):\n-                        node_key = self._node_key(layer, node_index)\n-                        if node_key in self._network_nodes:\n-                            # The model owns this layer node.\n-                            inputs = node.input_tensors\n-                            losses += layer.get_losses_for(inputs)\n-                    # Collect unconditional losses.\n-                    losses += layer.get_losses_for(None)\n-                else:\n-                    losses += layer.losses\n-\n-        # Add any potential unconditional model-level loss.\n-        losses += self.get_losses_for(None)\n-\n-        unique_tensors = []\n-        unique_tensors_ids = set()\n-        for x in losses:\n-            if not isinstance(x, (float, int)):\n-                if id(x) not in unique_tensors_ids:\n-                    unique_tensors.append(x)\n-                    unique_tensors_ids.add(id(x))\n-        non_tensors = [x for x in losses if isinstance(x, (float, int))]\n-        return unique_tensors + non_tensors\n-\n-    @property\n-    def uses_learning_phase(self):\n-        if not self.outputs:\n-            return False\n-        return any([x._uses_learning_phase for x in self.outputs])\n-\n-    @property\n-    def stateful(self):\n-        return any([(hasattr(layer, 'stateful') and\n-                    layer.stateful) for layer in self.layers])\n-\n-    def reset_states(self):\n-        for layer in self.layers:\n-            if hasattr(layer, 'reset_states') and getattr(layer, 'stateful', False):\n-                layer.reset_states()\n-\n-    @property\n-    def state_updates(self):\n-        \"\"\"Returns the `updates` from all layers that are stateful.\n-\n-        This is useful for separating training updates and\n-        state updates, e.g. when we need to update a layer's internal state\n-        during prediction.\n-\n-        # Returns\n-            A list of update ops.\n-        \"\"\"\n-        state_updates = []\n-        for layer in self.layers:\n-            if layer.stateful:\n-                state_updates += layer.updates\n-        return state_updates\n-\n-    @property\n-    def trainable_weights(self):\n-        if not self.trainable:\n-            return []\n-        weights = self._trainable_weights[:]\n-        for layer in self.layers:\n-            weights += layer.trainable_weights\n-        return weights\n-\n-    @property\n-    def non_trainable_weights(self):\n-        weights = self._non_trainable_weights[:]\n-        for layer in self.layers:\n-            weights += layer.non_trainable_weights\n-        if not self.trainable:\n-            trainable_weights = self._trainable_weights[:]\n-            for layer in self.layers:\n-                trainable_weights += layer.trainable_weights\n-            return trainable_weights + weights\n-        return weights\n-\n-    def get_weights(self):\n-        \"\"\"Retrieves the weights of the model.\n-\n-        # Returns\n-            A flat list of Numpy arrays.\n-        \"\"\"\n-        weights = self._trainable_weights + self._non_trainable_weights\n-        for layer in self.layers:\n-            weights += layer.weights\n-        return K.batch_get_value(weights)\n-\n-    def set_weights(self, weights):\n-        \"\"\"Sets the weights of the model.\n-\n-        # Arguments\n-            weights: A list of Numpy arrays with shapes and types matching\n-                the output of `model.get_weights()`.\n-        \"\"\"\n-        tuples = []\n-        own_weight_vars = self._trainable_weights + self._non_trainable_weights\n-        num_param = len(own_weight_vars)\n-        own_weights = weights[:num_param]\n-        for sw, w in zip(own_weight_vars, own_weights):\n-            tuples.append((sw, w))\n-        weights = weights[num_param:]\n-\n-        for layer in self.layers:\n-            num_param = len(layer.weights)\n-            layer_weights = weights[:num_param]\n-            for sw, w in zip(layer.weights, layer_weights):\n-                tuples.append((sw, w))\n-            weights = weights[num_param:]\n-        K.batch_set_value(tuples)\n-\n-    @property\n-    def input_spec(self):\n-        \"\"\"Gets the model's input specs.\n-\n-        # Returns\n-            A list of `InputSpec` instances (one per input to the model)\n-                or a single instance if the model has only one input.\n-        \"\"\"\n-        if not self._is_graph_network:\n-            # TODO: support it in subclassed networks after inputs are set.\n-            return None\n-\n-        specs = []\n-        for layer in getattr(self, '_input_layers', []):\n-            if layer.input_spec is None:\n-                specs.append(None)\n-            else:\n-                if not isinstance(layer.input_spec, list):\n-                    raise TypeError('Layer ' + layer.name +\n-                                    ' has an input_spec attribute that '\n-                                    'is not a list. We expect a list. '\n-                                    'Found input_spec = ' +\n-                                    str(layer.input_spec))\n-                specs += layer.input_spec\n-        return unpack_singleton(specs)\n-\n-    def call(self, inputs, mask=None):\n-        \"\"\"Calls the model on new inputs.\n-\n-        In this case `call` just reapplies\n-        all ops in the graph to the new inputs\n-        (e.g. build a new computational graph from the provided inputs).\n-\n-        A model is callable on non-Keras tensors.\n-\n-        # Arguments\n-            inputs: A tensor or list of tensors.\n-            mask: A mask or list of masks. A mask can be\n-                either a tensor or None (no mask).\n-\n-        # Returns\n-            A tensor if there is a single output, or\n-            a list of tensors if there are more than one outputs.\n-        \"\"\"\n-        inputs = to_list(inputs)\n-        if mask is None:\n-            masks = [None for _ in range(len(inputs))]\n-        else:\n-            masks = to_list(mask)\n-        cache_key = object_list_uid(inputs)\n-        cache_key += '_' + object_list_uid(masks)\n-        if cache_key in self._output_tensor_cache:\n-            return self._output_tensor_cache[cache_key]\n-        else:\n-            output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n-            return output_tensors\n-\n-    def compute_mask(self, inputs, mask):\n-        if not self._is_graph_network:\n-            return None\n-\n-        inputs = to_list(inputs)\n-        if mask is None:\n-            masks = [None for _ in range(len(inputs))]\n-        else:\n-            masks = to_list(mask)\n-        cache_key = object_list_uid(inputs)\n-        cache_key += '_' + object_list_uid(masks)\n-        if cache_key in self._output_mask_cache:\n-            return self._output_mask_cache[cache_key]\n-        else:\n-            _, output_masks, _ = self.run_internal_graph(inputs, masks)\n-            return output_masks\n-\n-    def compute_output_shape(self, input_shape):\n-        if not self._is_graph_network:\n-            # Must be implemented by subclasses.\n-            raise NotImplementedError\n-\n-        input_shapes = to_list(input_shape)\n-        if len(input_shapes) != len(self._input_layers):\n-            raise ValueError('Invalid input_shape argument ' +\n-                             str(input_shape) + ': model has ' +\n-                             str(len(self._input_layers)) + ' tensor inputs.')\n-\n-        cache_key = ', '.join([str(x) for x in input_shapes])\n-        if cache_key in self._output_shape_cache:\n-            output_shapes = self._output_shape_cache[cache_key]\n-            if isinstance(output_shapes, list):\n-                return unpack_singleton(output_shapes)\n-            return output_shapes\n-        else:\n-            # Bad luck, we have to run the graph manually.\n-            layers_to_output_shapes = {}\n-            for i in range(len(input_shapes)):\n-                layer = self._input_layers[i]\n-                input_shape = input_shapes[i]\n-                # It's an input layer: compute_output_shape is identity,\n-                # and there is only one node and one tensor output.\n-                shape_key = layer.name + '_0_0'\n-                layers_to_output_shapes[shape_key] = input_shape\n-\n-            depth_keys = list(self._nodes_by_depth.keys())\n-            depth_keys.sort(reverse=True)\n-            # Iterate over nodes, by depth level.\n-            if len(depth_keys) > 1:\n-                for depth in depth_keys:\n-                    nodes = self._nodes_by_depth[depth]\n-                    for node in nodes:\n-                        # This is always a single layer, never a list.\n-                        layer = node.outbound_layer\n-                        if layer in self._input_layers:\n-                            # We've already covered the input layers\n-                            # a few lines above.\n-                            continue\n-                        # Potentially redundant list,\n-                        # same size of node.input_tensors.\n-                        input_shapes = []\n-                        for j in range(len(node.inbound_layers)):\n-                            inbound_layer = node.inbound_layers[j]\n-                            node_index = node.node_indices[j]\n-                            tensor_index = node.tensor_indices[j]\n-                            shape_key = inbound_layer.name\n-                            shape_key += '_%s_%s' % (node_index, tensor_index)\n-                            input_shape = layers_to_output_shapes[shape_key]\n-                            input_shapes.append(input_shape)\n-\n-                        output_shape = layer.compute_output_shape(\n-                            unpack_singleton(input_shapes))\n-\n-                        output_shapes = to_list(output_shape)\n-                        node_index = layer._inbound_nodes.index(node)\n-                        for j in range(len(output_shapes)):\n-                            shape_key = layer.name + '_%s_%s' % (node_index, j)\n-                            layers_to_output_shapes[shape_key] = output_shapes[j]\n-\n-            # Read final output shapes from layers_to_output_shapes.\n-            output_shapes = []\n-            output_shape_keys = []\n-            for i in range(len(self._output_layers)):\n-                layer = self._output_layers[i]\n-                node_index = self._output_coordinates[i][1]\n-                tensor_index = self._output_coordinates[i][2]\n-                shape_key = layer.name + '_%s_%s' % (node_index, tensor_index)\n-                output_shape_keys.append(shape_key)\n-\n-            for i, key in enumerate(output_shape_keys):\n-                assert key in layers_to_output_shapes\n-                output_shapes.append(layers_to_output_shapes[key])\n-            # Store in cache.\n-            self._output_shape_cache[cache_key] = output_shapes\n-            if isinstance(output_shapes, list):\n-                return unpack_singleton(output_shapes)\n-            return output_shapes\n-\n-    def run_internal_graph(self, inputs, masks=None):\n-        \"\"\"Computes output tensors for new inputs.\n-\n-        # Note:\n-            - Expects `inputs` to be a list (potentially with 1 element).\n-            - Can be run on non-Keras tensors.\n-\n-        # Arguments\n-            inputs: List of tensors\n-            masks: List of masks (tensors or None).\n-\n-        # Returns\n-            Three lists: output_tensors, output_masks, output_shapes\n-        \"\"\"\n-        if masks is None:\n-            masks = [None for _ in range(len(inputs))]\n-\n-        # Dictionary mapping reference tensors to tuples\n-        # (computed tensor, compute mask)\n-        # we assume a 1:1 mapping from tensor to mask\n-        # TODO: raise exception when a `.compute_mask()` call\n-        # does not return a list the same size as `call`\n-        tensor_map = {}\n-        for x, y, mask in zip(self.inputs, inputs, masks):\n-            tensor_map[str(id(x))] = (y, mask)\n-\n-        depth_keys = list(self._nodes_by_depth.keys())\n-        depth_keys.sort(reverse=True)\n-        for depth in depth_keys:\n-            nodes = self._nodes_by_depth[depth]\n-            for node in nodes:\n-                # This is always a single layer, never a list.\n-                layer = node.outbound_layer\n-                reference_input_tensors = node.input_tensors\n-                reference_output_tensors = node.output_tensors\n-\n-                # If all previous input tensors are available in tensor_map,\n-                # then call node.inbound_layer on them.\n-                computed_data = []  # List of tuples (input, mask).\n-                for x in reference_input_tensors:\n-                    if str(id(x)) in tensor_map:\n-                        computed_data.append(tensor_map[str(id(x))])\n-\n-                if len(computed_data) == len(reference_input_tensors):\n-                    # call layer\n-                    with K.name_scope(layer.name):\n-                        if node.arguments:\n-                            kwargs = node.arguments\n-                        else:\n-                            kwargs = {}\n-                        if len(computed_data) == 1:\n-                            computed_tensor, computed_mask = computed_data[0]\n-                            if has_arg(layer.call, 'mask'):\n-                                if 'mask' not in kwargs:\n-                                    kwargs['mask'] = computed_mask\n-                            output_tensors = to_list(\n-                                layer.call(computed_tensor, **kwargs))\n-                            output_masks = layer.compute_mask(computed_tensor,\n-                                                              computed_mask)\n-                            if output_masks is None:\n-                                output_masks = [None for _ in output_tensors]\n-                            else:\n-                                output_masks = to_list(output_masks)\n-                            computed_tensors = [computed_tensor]\n-\n-                            # computed_masks might be used in the future.\n-                            computed_masks = [computed_mask]\n-                        else:\n-                            computed_tensors = [x[0] for x in computed_data]\n-                            computed_masks = [x[1] for x in computed_data]\n-                            if has_arg(layer.call, 'mask'):\n-                                if 'mask' not in kwargs:\n-                                    kwargs['mask'] = computed_masks\n-                            output_tensors = to_list(\n-                                layer.call(computed_tensors, **kwargs))\n-                            output_masks = layer.compute_mask(computed_tensors,\n-                                                              computed_masks)\n-                            if output_masks is None:\n-                                output_masks = [None for _ in output_tensors]\n-                            else:\n-                                output_masks = to_list(output_masks)\n-                        # Apply activity regularizer if any:\n-                        if (hasattr(layer, 'activity_regularizer') and\n-                                layer.activity_regularizer is not None):\n-                            with K.name_scope('activity_regularizer'):\n-                                regularization_losses = [\n-                                    layer.activity_regularizer(x)\n-                                    for x in output_tensors]\n-                            layer.add_loss(regularization_losses,\n-                                           inputs=computed_tensors)\n-\n-                        if len(output_masks) != len(output_tensors):\n-                            raise Exception(\n-                                'Layers should have equal number of output tensors '\n-                                'and output masks. Layer ' + str(layer.name) + ' has'\n-                                ' ' + str(len(output_tensors)) + ' output tensors '\n-                                'and ' + str(len(output_masks)) + ' output masks.')\n-                    # Update model updates and losses:\n-                    # Keep track of updates that depend on the inputs\n-                    # (e.g. BN updates).\n-                    self.add_update(layer.get_updates_for(computed_tensors), inputs)\n-                    # Keep track of unconditional updates (e.g. a counter).\n-                    self.add_update(layer.get_updates_for(None), None)\n-                    # Keep track of losses that depend on the inputs\n-                    # (e.g. activity regularizers).\n-                    self.add_loss(layer.get_losses_for(computed_tensors), inputs)\n-                    # Keep track of unconditional losses\n-                    # (e.g. weight regularizers).\n-                    self.add_loss(layer.get_losses_for(None), None)\n-\n-                    # Update _keras_shape.\n-                    if all([hasattr(x, '_keras_shape') for x in computed_tensors]):\n-                        input_shapes = unpack_singleton(\n-                            [x._keras_shape for x in computed_tensors])\n-                        shapes = to_list(layer.compute_output_shape(input_shapes))\n-                        uses_learning_phase = any(\n-                            [x._uses_learning_phase for x in computed_tensors])\n-\n-                        for x, s in zip(output_tensors, shapes):\n-                            x._keras_shape = s\n-                            _u = getattr(x, '_uses_learning_phase', False)\n-                            x._uses_learning_phase = _u or uses_learning_phase\n-\n-                    # Update tensor_map.\n-                    for x, y, mask in zip(reference_output_tensors,\n-                                          output_tensors,\n-                                          output_masks):\n-                        tensor_map[str(id(x))] = (y, mask)\n-\n-        output_tensors = []\n-        output_masks = []\n-        output_shapes = []\n-        for x in self.outputs:\n-            assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)\n-            tensor, mask = tensor_map[str(id(x))]\n-            if hasattr(tensor, '_keras_shape') and output_shapes is not None:\n-                shape = tensor._keras_shape\n-                output_shapes.append(shape)\n-            else:\n-                output_shapes = None\n-            output_tensors.append(tensor)\n-            output_masks.append(mask)\n-\n-        # Update cache;\n-        # keys are based on ids on input tensors and inputs masks.\n-        cache_key = object_list_uid(inputs)\n-        cache_key += '_' + object_list_uid(masks)\n-\n-        output_tensors = unpack_singleton(output_tensors)\n-        self._output_tensor_cache[cache_key] = output_tensors\n-\n-        output_masks = unpack_singleton(output_masks)\n-        self._output_mask_cache[cache_key] = output_masks\n-\n-        if output_shapes is not None:\n-            input_shapes = [x._keras_shape for x in inputs]\n-            cache_key = ', '.join([str(x) for x in input_shapes])\n-\n-            output_shapes = unpack_singleton(output_shapes)\n-            self._output_shape_cache[cache_key] = output_shapes\n-        return output_tensors, output_masks, output_shapes\n-\n-    def get_config(self):\n-        if not self._is_graph_network:\n-            # Subclassed networks are not serializable\n-            # (unless serialization is implemented by\n-            # the author of the subclassed network).\n-            raise NotImplementedError\n-\n-        config = {\n-            'name': self.name,\n-        }\n-\n-        # Build a map from a layer unique name (self._node_key)\n-        # to the index of the nodes that are saved in the config.\n-        # Only nodes in network_nodes are saved.\n-        node_conversion_map = {}\n-        for layer in self.layers:\n-            if issubclass(layer.__class__, Network):\n-                # Networks start with a pre-existing node\n-                # linking their input to output.\n-                kept_nodes = 1\n-            else:\n-                kept_nodes = 0\n-            for original_node_index, node in enumerate(layer._inbound_nodes):\n-                node_key = self._node_key(layer, original_node_index)\n-                if node_key in self._network_nodes:\n-                    # i.e. we mark it to be saved\n-                    node_conversion_map[node_key] = kept_nodes\n-                    kept_nodes += 1\n-\n-        # serialize and save the layers in layer_configs\n-        layer_configs = []\n-        for layer in self.layers:  # From the earliest layers on.\n-            layer_class_name = layer.__class__.__name__\n-            layer_config = layer.get_config()\n-            filtered_inbound_nodes = []\n-            for original_node_index, node in enumerate(layer._inbound_nodes):\n-                node_key = self._node_key(layer, original_node_index)\n-                if node_key in self._network_nodes:\n-                    # The node is relevant to the model:\n-                    # add to filtered_inbound_nodes.\n-                    if node.arguments:\n-                        try:\n-                            json.dumps(node.arguments)\n-                            kwargs = node.arguments\n-                        except TypeError:\n-                            warnings.warn(\n-                                'Layer ' + layer.name +\n-                                ' was passed non-serializable '\n-                                'keyword arguments: ' +\n-                                str(node.arguments) +\n-                                '. They will not be included '\n-                                'in the serialized model '\n-                                '(and thus will be missing '\n-                                'at deserialization time).')\n-                            kwargs = {}\n-                    else:\n-                        kwargs = {}\n-                    if node.inbound_layers:\n-                        node_data = []\n-                        for i in range(len(node.inbound_layers)):\n-                            inbound_layer = node.inbound_layers[i]\n-                            node_index = node.node_indices[i]\n-                            tensor_index = node.tensor_indices[i]\n-\n-                            new_node_index = node_conversion_map.get(\n-                                self._node_key(inbound_layer, node_index), 0)\n-                            node_data.append([inbound_layer.name,\n-                                              new_node_index,\n-                                              tensor_index,\n-                                              kwargs])\n-                        filtered_inbound_nodes.append(node_data)\n-            layer_configs.append({\n-                'name': layer.name,\n-                'class_name': layer_class_name,\n-                'config': layer_config,\n-                'inbound_nodes': filtered_inbound_nodes,\n-            })\n-        config['layers'] = layer_configs\n-\n-        # Gather info about inputs and outputs.\n-        model_inputs = []\n-        for i in range(len(self._input_layers)):\n-            layer = self._input_layers[i]\n-            node_index = self._input_coordinates[i][1]\n-\n-            node_key = self._node_key(layer, node_index)\n-            if node_key not in self._network_nodes:\n-                continue\n-            new_node_index = node_conversion_map[node_key]\n-            tensor_index = self._input_coordinates[i][2]\n-            model_inputs.append([layer.name, new_node_index, tensor_index])\n-        config['input_layers'] = model_inputs\n-        model_outputs = []\n-        for i in range(len(self._output_layers)):\n-            layer = self._output_layers[i]\n-            node_index = self._output_coordinates[i][1]\n-\n-            node_key = self._node_key(layer, node_index)\n-            if node_key not in self._network_nodes:\n-                continue\n-            new_node_index = node_conversion_map[node_key]\n-            tensor_index = self._output_coordinates[i][2]\n-            model_outputs.append([layer.name, new_node_index, tensor_index])\n-        config['output_layers'] = model_outputs\n-        return copy.deepcopy(config)\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        \"\"\"Instantiates a Model from its config (output of `get_config()`).\n-\n-        # Arguments\n-            config: Model config dictionary.\n-            custom_objects: Optional dictionary mapping names\n-                (strings) to custom classes or functions to be\n-                considered during deserialization.\n-\n-        # Returns\n-            A model instance.\n-\n-        # Raises\n-            ValueError: In case of improperly formatted config dict.\n-        \"\"\"\n-        # Layer instances created during\n-        # the graph reconstruction process\n-        created_layers = {}\n-\n-        # Dictionary mapping layer instances to\n-        # node data that specifies a layer call.\n-        # It acts as a queue that maintains any unprocessed\n-        # layer call until it becomes possible to process it\n-        # (i.e. until the input tensors to the call all exist).\n-        unprocessed_nodes = {}\n-\n-        def add_unprocessed_node(layer, node_data):\n-            \"\"\"Add node to layer list\n-\n-            # Arguments\n-                layer: layer object\n-                node_data: Node data specifying layer call\n-            \"\"\"\n-            if layer not in unprocessed_nodes:\n-                unprocessed_nodes[layer] = [node_data]\n-            else:\n-                unprocessed_nodes[layer].append(node_data)\n-\n-        def process_node(layer, node_data):\n-            \"\"\"Reconstruct node by linking to inbound layers\n-\n-            # Arguments\n-                layer: Layer to process\n-                node_data: List of layer configs\n-\n-            # Raises\n-                ValueError: For incorrect layer config\n-                LookupError: If layer required is not found\n-            \"\"\"\n-            input_tensors = []\n-            for input_data in node_data:\n-                inbound_layer_name = input_data[0]\n-                inbound_node_index = input_data[1]\n-                inbound_tensor_index = input_data[2]\n-                if len(input_data) == 3:\n-                    kwargs = {}\n-                elif len(input_data) == 4:\n-                    kwargs = input_data[3]\n-                else:\n-                    raise ValueError('Improperly formatted model config.')\n-                inbound_layer = created_layers[inbound_layer_name]\n-                # Raise an error if the corresponding layer node\n-                # has not yet been created\n-                if len(inbound_layer._inbound_nodes) <= inbound_node_index:\n-                    raise LookupError\n-                inbound_node = inbound_layer._inbound_nodes[inbound_node_index]\n-                input_tensors.append(\n-                    inbound_node.output_tensors[inbound_tensor_index])\n-\n-            # Call layer on its inputs, thus creating the node\n-            # and building the layer if needed.\n-            if input_tensors:\n-                layer(unpack_singleton(input_tensors), **kwargs)\n-\n-        def process_layer(layer_data):\n-            \"\"\"Deserializes a layer, then call it on appropriate inputs.\n-\n-            # Arguments\n-                layer_data: layer config dict.\n-\n-            # Raises\n-                ValueError: In case of improperly formatted `layer_data` dict.\n-            \"\"\"\n-            layer_name = layer_data['name']\n-\n-            # Instantiate layer.\n-            from ..layers import deserialize as deserialize_layer\n-\n-            layer = deserialize_layer(layer_data,\n-                                      custom_objects=custom_objects)\n-            created_layers[layer_name] = layer\n-\n-            # Gather layer inputs.\n-            inbound_nodes_data = layer_data['inbound_nodes']\n-            for node_data in inbound_nodes_data:\n-                # We don't process nodes (i.e. make layer calls)\n-                # on the fly because the inbound node may not yet exist,\n-                # in case of layer shared at different topological depths\n-                # (e.g. a model such as A(B(A(B(x)))))\n-                add_unprocessed_node(layer, node_data)\n-\n-        # First, we create all layers and enqueue nodes to be processed\n-        for layer_data in config['layers']:\n-            process_layer(layer_data)\n-\n-        # Then we process nodes in order of layer depth.\n-        # Nodes that cannot yet be processed (if the inbound node\n-        # does not yet exist) are re-enqueued, and the process\n-        # is repeated until all nodes are processed.\n-        while unprocessed_nodes:\n-            for layer_data in config['layers']:\n-                layer = created_layers[layer_data['name']]\n-\n-                # Process all nodes in layer, if not yet processed\n-                if layer in unprocessed_nodes:\n-                    node_data_list = unprocessed_nodes[layer]\n-\n-                    # Process nodes in order\n-                    node_index = 0\n-                    while node_index < len(node_data_list):\n-                        node_data = node_data_list[node_index]\n-                        try:\n-                            process_node(layer, node_data)\n-\n-                        # If the node does not have all inbound layers\n-                        # available, stop processing and continue later\n-                        except LookupError:\n-                            break\n-\n-                        node_index += 1\n-\n-                    # If not all nodes processed then store unprocessed nodes\n-                    if node_index < len(node_data_list):\n-                        unprocessed_nodes[layer] = node_data_list[node_index:]\n-                    # If all nodes processed remove the layer\n-                    else:\n-                        del unprocessed_nodes[layer]\n-\n-        # Create lits of input and output tensors and return new class\n-        name = config.get('name')\n-        input_tensors = []\n-        output_tensors = []\n-        for layer_data in config['input_layers']:\n-            layer_name, node_index, tensor_index = layer_data\n-            assert layer_name in created_layers\n-            layer = created_layers[layer_name]\n-            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n-            input_tensors.append(layer_output_tensors[tensor_index])\n-        for layer_data in config['output_layers']:\n-            layer_name, node_index, tensor_index = layer_data\n-            assert layer_name in created_layers\n-            layer = created_layers[layer_name]\n-            layer_output_tensors = layer._inbound_nodes[node_index].output_tensors\n-            output_tensors.append(layer_output_tensors[tensor_index])\n-        return cls(inputs=input_tensors, outputs=output_tensors, name=name)\n-\n-    def save(self, filepath, overwrite=True, include_optimizer=True):\n-        \"\"\"Saves the model to a single HDF5 file.\n-\n-        The savefile includes:\n-            - The model architecture, allowing to re-instantiate the model.\n-            - The model weights.\n-            - The state of the optimizer, allowing to resume training\n-                exactly where you left off.\n-\n-        This allows you to save the entirety of the state of a model\n-        in a single file.\n-\n-        Saved models can be reinstantiated via `keras.models.load_model`.\n-        The model returned by `load_model`\n-        is a compiled model ready to be used (unless the saved model\n-        was never compiled in the first place).\n-\n-        # Arguments\n-            filepath: one of the following:\n-                - string, path to the file to save the model to\n-                - h5py.File or h5py.Group object where to save the model\n-                - any file-like object implementing the method `write` that accepts\n-                    `bytes` data (e.g. `io.BytesIO`).\n-            overwrite: Whether to silently overwrite any existing file at the\n-                target location, or provide the user with a manual prompt.\n-            include_optimizer: If True, save optimizer's state together.\n-\n-        # Example\n-\n-        ```python\n-        from keras.models import load_model\n-\n-        model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n-        del model  # deletes the existing model\n-\n-        # returns a compiled model\n-        # identical to the previous one\n-        model = load_model('my_model.h5')\n-        ```\n-        \"\"\"\n-        if not self._is_graph_network:\n-            raise NotImplementedError\n-        from ..models import save_model\n-        save_model(self, filepath, overwrite, include_optimizer)\n-\n-    @saving.allow_write_to_gcs\n-    def save_weights(self, filepath, overwrite=True):\n-        \"\"\"Dumps all layer weights to a HDF5 file.\n-\n-        The weight file has:\n-            - `layer_names` (attribute), a list of strings\n-                (ordered names of model layers).\n-            - For every layer, a `group` named `layer.name`\n-                - For every such layer group, a group attribute `weight_names`,\n-                    a list of strings\n-                    (ordered names of weights tensor of the layer).\n-                - For every weight in the layer, a dataset\n-                    storing the weight value, named after the weight tensor.\n-\n-        # Arguments\n-            filepath: String, path to the file to save the weights to.\n-            overwrite: Whether to silently overwrite any existing file at the\n-                target location, or provide the user with a manual prompt.\n-\n-        # Raises\n-            ImportError: If h5py is not available.\n-        \"\"\"\n-        if h5py is None:\n-            raise ImportError('`save_weights` requires h5py.')\n-        # If file exists and should not be overwritten:\n-        if not overwrite and os.path.isfile(filepath):\n-            proceed = ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        with h5py.File(filepath, 'w') as f:\n-            saving.save_weights_to_hdf5_group(f, self.layers)\n-            f.flush()\n-\n-    @saving.allow_read_from_gcs\n-    def load_weights(self, filepath, by_name=False,\n-                     skip_mismatch=False, reshape=False):\n-        \"\"\"Loads all layer weights from a HDF5 save file.\n-\n-        If `by_name` is False (default) weights are loaded\n-        based on the network's topology, meaning the architecture\n-        should be the same as when the weights were saved.\n-        Note that layers that don't have weights are not taken\n-        into account in the topological ordering, so adding or\n-        removing layers is fine as long as they don't have weights.\n-\n-        If `by_name` is True, weights are loaded into layers\n-        only if they share the same name. This is useful\n-        for fine-tuning or transfer-learning models where\n-        some of the layers have changed.\n-\n-        # Arguments\n-            filepath: String, path to the weights file to load.\n-            by_name: Boolean, whether to load weights by name\n-                or by topological order.\n-            skip_mismatch: Boolean, whether to skip loading of layers\n-                where there is a mismatch in the number of weights,\n-                or a mismatch in the shape of the weight\n-                (only valid when `by_name`=True).\n-            reshape: Reshape weights to fit the layer when the correct number\n-                of weight arrays is present but their shape does not match.\n-\n-\n-        # Raises\n-            ImportError: If h5py is not available.\n-        \"\"\"\n-        if h5py is None:\n-            raise ImportError('`load_weights` requires h5py.')\n-        with h5py.File(filepath, mode='r') as f:\n-            if 'layer_names' not in f.attrs and 'model_weights' in f:\n-                f = f['model_weights']\n-            if by_name:\n-                saving.load_weights_from_hdf5_group_by_name(\n-                    f, self.layers, skip_mismatch=skip_mismatch,\n-                    reshape=reshape)\n-            else:\n-                saving.load_weights_from_hdf5_group(\n-                    f, self.layers, reshape=reshape)\n-            if hasattr(f, 'close'):\n-                f.close()\n-            elif hasattr(f.file, 'close'):\n-                f.file.close()\n-\n-    def _updated_config(self):\n-        \"\"\"Util hared between different serialization methods.\n-\n-        # Returns\n-            Model config with Keras version information added.\n-        \"\"\"\n-        from .. import __version__ as keras_version\n-\n-        config = self.get_config()\n-        model_config = {\n-            'class_name': self.__class__.__name__,\n-            'config': config,\n-            'keras_version': keras_version,\n-            'backend': K.backend()\n-        }\n-        return model_config\n-\n-    def to_json(self, **kwargs):\n-        \"\"\"Returns a JSON string containing the network configuration.\n-\n-        To load a network from a JSON save file, use\n-        `keras.models.model_from_json(json_string, custom_objects={})`.\n-\n-        # Arguments\n-            **kwargs: Additional keyword arguments\n-                to be passed to `json.dumps()`.\n-\n-        # Returns\n-            A JSON string.\n-        \"\"\"\n-        def get_json_type(obj):\n-            # If obj is any numpy type\n-            if type(obj).__module__ == np.__name__:\n-                if isinstance(obj, np.ndarray):\n-                    return obj.tolist()\n-                else:\n-                    return obj.item()\n-\n-            # If obj is a python 'type'\n-            if type(obj).__name__ == type.__name__:\n-                return obj.__name__\n-\n-            raise TypeError('Not JSON Serializable:', obj)\n-\n-        model_config = self._updated_config()\n-        return json.dumps(model_config, default=get_json_type, **kwargs)\n-\n-    def to_yaml(self, **kwargs):\n-        \"\"\"Returns a yaml string containing the network configuration.\n-\n-        To load a network from a yaml save file, use\n-        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n-\n-        `custom_objects` should be a dictionary mapping\n-        the names of custom losses / layers / etc to the corresponding\n-        functions / classes.\n-\n-        # Arguments\n-            **kwargs: Additional keyword arguments\n-                to be passed to `yaml.dump()`.\n-\n-        # Returns\n-            A YAML string.\n-        \"\"\"\n-        return yaml.dump(self._updated_config(), **kwargs)\n-\n-    def summary(self, line_length=None, positions=None, print_fn=None):\n-        \"\"\"Prints a string summary of the network.\n-\n-        # Arguments\n-            line_length: Total length of printed lines\n-                (e.g. set this to adapt the display to different\n-                terminal window sizes).\n-            positions: Relative or absolute positions of log elements\n-                in each line. If not provided,\n-                defaults to `[.33, .55, .67, 1.]`.\n-            print_fn: Print function to use.\n-                It will be called on each line of the summary.\n-                You can set it to a custom function\n-                in order to capture the string summary.\n-                It defaults to `print` (prints to stdout).\n-        \"\"\"\n-        if not self.built:\n-            raise ValueError(\n-                'This model has not yet been built. '\n-                'Build the model first by calling build() '\n-                'or calling fit() with some data. '\n-                'Or specify input_shape or batch_input_shape '\n-                'in the first layer for automatic build. ')\n-        return print_layer_summary(self,\n-                                   line_length=line_length,\n-                                   positions=positions,\n-                                   print_fn=print_fn)\n-\n-    def __getstate__(self):\n-        return saving.pickle_model(self)\n-\n-    def __setstate__(self, state):\n-        model = saving.unpickle_model(state)\n-        self.__dict__.update(model.__dict__)\n-\n-\n-def _make_node_key(layer_name, node_index):\n-    return layer_name + '_ib-' + str(node_index)\n-\n-\n-def _map_graph_network(inputs, outputs):\n-    \"\"\"Validates a network's topology and gather its layers and nodes.\n-\n-    # Arguments\n-        inputs: List of input tensors.\n-        outputs: List of outputs tensors.\n-\n-    # Returns\n-        A tuple `(nodes, nodes_by_depth, layers, layers_by_depth)`.\n-        - nodes: list of Node instances.\n-        - nodes_by_depth: dict mapping ints (depth) to lists of node instances.\n-        - layers: list of Layer instances.\n-        - layers_by_depth: dict mapping ints (depth)\n-            to lists of layer instances.\n-\n-    # Raises\n-        ValueError: In case the network is not valid (e.g. disconnected graph).\n-    \"\"\"\n-    # Network_nodes: set of nodes included in the graph of layers\n-    # (not all nodes included in the layers are relevant to the current graph).\n-    network_nodes = set()  # ids of all nodes relevant to the Network\n-    nodes_depths = {}  # dict {node: depth value}\n-    layers_depths = {}  # dict {layer: depth value}\n-    layer_indices = {}  # dict {layer: index in traversal}\n-    nodes_in_decreasing_depth = []\n-\n-    def build_map(tensor,\n-                  finished_nodes,\n-                  nodes_in_progress,\n-                  layer,\n-                  node_index,\n-                  tensor_index):\n-        \"\"\"Builds a map of the graph of layers.\n-\n-        This recursively updates the map `layer_indices`,\n-        the list `nodes_in_decreasing_depth` and the set `network_nodes`.\n-\n-        # Arguments\n-            tensor: Some tensor in a graph.\n-            finished_nodes: Set of nodes whose subgraphs have been traversed\n-                completely. Useful to prevent duplicated work.\n-            nodes_in_progress: Set of nodes that are currently active on the\n-                recursion stack. Useful to detect cycles.\n-            layer: Layer from which `tensor` comes from. If not provided,\n-                will be obtained from `tensor._keras_history`.\n-            node_index: Node index from which `tensor` comes from.\n-            tensor_index: Tensor_index from which `tensor` comes from.\n-\n-        # Raises\n-            ValueError: if a cycle is detected.\n-        \"\"\"\n-        node = layer._inbound_nodes[node_index]\n-\n-        # Prevent cycles.\n-        if node in nodes_in_progress:\n-            raise ValueError('The tensor ' + str(tensor) + ' at layer \"' +\n-                             layer.name + '\" is part of a cycle.')\n-\n-        # Don't repeat work for shared subgraphs\n-        if node in finished_nodes:\n-            return\n-\n-        node_key = _make_node_key(layer.name, node_index)\n-        # Update network_nodes.\n-        network_nodes.add(node_key)\n-\n-        # Store the traversal order for layer sorting.\n-        if layer not in layer_indices:\n-            layer_indices[layer] = len(layer_indices)\n-\n-        nodes_in_progress.add(node)\n-\n-        # Propagate to all previous tensors connected to this node.\n-        for i in range(len(node.inbound_layers)):\n-            x = node.input_tensors[i]\n-            layer = node.inbound_layers[i]\n-            node_index = node.node_indices[i]\n-            tensor_index = node.tensor_indices[i]\n-            build_map(x, finished_nodes, nodes_in_progress, layer,\n-                      node_index, tensor_index)\n-\n-        finished_nodes.add(node)\n-        nodes_in_progress.remove(node)\n-        nodes_in_decreasing_depth.append(node)\n-\n-    finished_nodes = set()\n-    nodes_in_progress = set()\n-    for x in outputs:\n-        layer, node_index, tensor_index = x._keras_history\n-        build_map(x, finished_nodes, nodes_in_progress,\n-                  layer=layer,\n-                  node_index=node_index,\n-                  tensor_index=tensor_index)\n-\n-    for node in reversed(nodes_in_decreasing_depth):\n-        # If the depth is not set, the node has no outbound nodes (depth 0).\n-        depth = nodes_depths.setdefault(node, 0)\n-\n-        # Update the depth of the corresponding layer\n-        previous_depth = layers_depths.get(node.outbound_layer, 0)\n-        # If we've seen this layer before at a higher depth,\n-        # we should use that depth instead of the node depth.\n-        # This is necessary for shared layers that have inputs at different\n-        # depth levels in the graph.\n-        depth = max(depth, previous_depth)\n-        layers_depths[node.outbound_layer] = depth\n-        nodes_depths[node] = depth\n-\n-        # Update the depth of inbound nodes.\n-        # The \"depth\" of a node is the max of the depths\n-        # of all layers it is connected to.\n-        for i in range(len(node.inbound_layers)):\n-            inbound_layer = node.inbound_layers[i]\n-            node_index = node.node_indices[i]\n-            inbound_node = inbound_layer._inbound_nodes[node_index]\n-            previous_depth = nodes_depths.get(inbound_node, 0)\n-            nodes_depths[inbound_node] = max(depth + 1, previous_depth)\n-\n-    # Build a dict {depth: list of nodes with this depth}\n-    nodes_by_depth = {}\n-    for node, depth in nodes_depths.items():\n-        if depth not in nodes_by_depth:\n-            nodes_by_depth[depth] = []\n-        nodes_by_depth[depth].append(node)\n-\n-    # Build a dict {depth: list of layers with this depth}\n-    layers_by_depth = {}\n-    for layer, depth in layers_depths.items():\n-        if depth not in layers_by_depth:\n-            layers_by_depth[depth] = []\n-        layers_by_depth[depth].append(layer)\n-\n-    # Get sorted list of layer depths.\n-    depth_keys = list(layers_by_depth.keys())\n-    depth_keys.sort(reverse=True)\n-\n-    # Set self.layers and self._layers_by_depth.\n-    layers = []\n-    for depth in depth_keys:\n-        layers_for_depth = layers_by_depth[depth]\n-        # Network.layers needs to have a deterministic order:\n-        # here we order them by traversal order.\n-        layers_for_depth.sort(key=lambda x: layer_indices[x])\n-        layers.extend(layers_for_depth)\n-\n-    # Get sorted list of node depths.\n-    depth_keys = list(nodes_by_depth.keys())\n-    depth_keys.sort(reverse=True)\n-\n-    # Check that all tensors required are computable.\n-    # computable_tensors: all tensors in the graph\n-    # that can be computed from the inputs provided.\n-    computable_tensors = []\n-    for x in inputs:\n-        computable_tensors.append(x)\n-\n-    layers_with_complete_input = []  # To provide a better error msg.\n-    for depth in depth_keys:\n-        for node in nodes_by_depth[depth]:\n-            layer = node.outbound_layer\n-            if layer:\n-                for x in node.input_tensors:\n-                    if id(x) not in [id(ct) for ct in computable_tensors]:\n-                        raise ValueError('Graph disconnected: '\n-                                         'cannot obtain value for tensor ' +\n-                                         str(x) + ' at layer \"' +\n-                                         layer.name + '\". '\n-                                         'The following previous layers '\n-                                         'were accessed without issue: ' +\n-                                         str(layers_with_complete_input))\n-                for x in node.output_tensors:\n-                    computable_tensors.append(x)\n-                layers_with_complete_input.append(layer.name)\n-\n-    # Ensure name unicity, which will be crucial for serialization\n-    # (since serialized nodes refer to layers by their name).\n-    all_names = [layer.name for layer in layers]\n-    for name in all_names:\n-        if all_names.count(name) != 1:\n-            raise ValueError('The name \"' + name + '\" is used ' +\n-                             str(all_names.count(name)) +\n-                             ' times in the model. '\n-                             'All layer names should be unique.')\n-    return network_nodes, nodes_by_depth, layers, layers_by_depth\n+from tensorflow.keras import Model as Network\n+from tensorflow.keras.utils import get_source_inputs\n\n@@ -1,1335 +1,6 @@\n-\"\"\"Model saving utilities.\n-\"\"\"\n-from __future__ import print_function\n-from __future__ import absolute_import\n-from __future__ import division\n-\n-import os\n-import json\n-import yaml\n-import inspect\n-import warnings\n-import tempfile\n-from six.moves import zip\n-from six import string_types\n-from functools import wraps\n-\n-import numpy as np\n-\n-from .. import backend as K\n-from .. import losses\n-from .. import optimizers\n-from ..utils.io_utils import H5Dict\n-from ..utils.io_utils import ask_to_proceed_with_overwrite\n-from ..utils.io_utils import save_to_binary_h5py\n-from ..utils.io_utils import load_from_binary_h5py\n-from ..utils import conv_utils\n-\n-try:\n-    import h5py\n-    HDF5_OBJECT_HEADER_LIMIT = 64512\n-except ImportError:\n-    h5py = None\n-\n-try:\n-    from tensorflow.python.lib.io import file_io as tf_file_io\n-except ImportError:\n-    tf_file_io = None\n-\n-try:\n-    getargspec = inspect.getfullargspec\n-except AttributeError:  # getargspec() is deprecated since Python 3.0\n-    getargspec = inspect.getargspec\n-\n-\n-def _uniquify(names):\n-    \"\"\"Uniquify list of strings.\n-\n-    Custom layers and optimizers written by users\n-    for TF 1.x might produce weights with same variable\n-    names in TF 2. This method \"uniquifies\" a given list\n-    of names.\n-\n-    e.g: `['a', 'b', 'b', 'c'] -> ['a', 'b', 'b_2', 'c']`\n-\n-    # Arguments\n-        names: List of strings.\n-\n-    # Returns\n-        List of unique strings.\n-    \"\"\"\n-    counts = {}\n-    unique_names = []\n-    for name in names:\n-        if name in counts:\n-            counts[name] += 1\n-            name = str(name) + '_' + str(counts[name])\n-        else:\n-            counts[name] = 1\n-        unique_names.append(name)\n-    return unique_names\n-\n-\n-def _serialize_model(model, h5dict, include_optimizer=True):\n-    \"\"\"Model serialization logic.\n-\n-    This method is used for both writing to HDF5 file/group,\n-    as well as pickling. This is achieved via a\n-    `keras.utils.hdf5_utls.H5Dict` object, which can wrap HDF5\n-    files, groups and dicts with a common API.\n-\n-    # Arguments\n-        model: Keras model instance to be serialized.\n-        h5dict: keras.utils.io_utils.HD5Dict instance.\n-        include_optimizer: If True, serialize optimizer's state together.\n-\n-    \"\"\"\n-    def get_json_type(obj):\n-        \"\"\"Serialize any object to a JSON-serializable structure.\n-\n-        # Arguments\n-            obj: the object to serialize\n-\n-        # Returns\n-            JSON-serializable structure representing `obj`.\n-\n-        # Raises\n-            TypeError: if `obj` cannot be serialized.\n-        \"\"\"\n-        # if obj is a serializable Keras class instance\n-        # e.g. optimizer, layer\n-        if hasattr(obj, 'get_config'):\n-            return {'class_name': obj.__class__.__name__,\n-                    'config': obj.get_config()}\n-\n-        # if obj is any numpy type\n-        if type(obj).__module__ == np.__name__:\n-            if isinstance(obj, np.ndarray):\n-                return obj.tolist()\n-            else:\n-                return obj.item()\n-\n-        # misc functions (e.g. loss function)\n-        if callable(obj):\n-            return obj.__name__\n-\n-        # if obj is a python 'type'\n-        if type(obj).__name__ == type.__name__:\n-            return obj.__name__\n-\n-        raise TypeError('Not JSON Serializable: %s' % (obj,))\n-\n-    from .. import __version__ as keras_version\n-\n-    h5dict['keras_version'] = str(keras_version).encode('utf8')\n-    h5dict['backend'] = K.backend().encode('utf8')\n-\n-    model_config = {}\n-    model_config['class_name'] = model.__class__.__name__\n-    model_config['config'] = model.get_config()\n-    model_config = json.dumps(model_config, default=get_json_type)\n-    model_config = model_config.encode('utf-8')\n-    h5dict['model_config'] = model_config\n-\n-    model_weights_group = h5dict['model_weights']\n-    model_layers = model.layers\n-    model_weights_group['layer_names'] = [layer.name.encode('utf8')\n-                                          for layer in model_layers]\n-    model_weights_group['backend'] = K.backend().encode('utf8')\n-    model_weights_group['keras_version'] = str(keras_version).encode('utf8')\n-    for layer in model_layers:\n-        layer_group = model_weights_group[layer.name]\n-        symbolic_weights = layer.weights\n-        weight_values = K.batch_get_value(symbolic_weights)\n-        weight_names = []\n-        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n-            if hasattr(w, 'name') and w.name:\n-                name = str(w.name)\n-            else:\n-                name = 'param_' + str(i)\n-            if name in weight_names:\n-                idx = 2\n-                unique_name = name + '_1'\n-                while unique_name in weight_names:\n-                    unique_name = name + '_' + str(idx)\n-                    idx += 1\n-                name = unique_name\n-            weight_names.append(name.encode('utf8'))\n-        weight_names = _uniquify(weight_names)\n-        layer_group['weight_names'] = weight_names\n-        for name, val in zip(weight_names, weight_values):\n-            layer_group[name] = val\n-    if include_optimizer and model.optimizer:\n-        if isinstance(model.optimizer, optimizers.TFOptimizer):\n-            warnings.warn(\n-                'TensorFlow optimizers do not '\n-                'make it possible to access '\n-                'optimizer attributes or optimizer state '\n-                'after instantiation. '\n-                'As a result, we cannot save the optimizer '\n-                'as part of the model save file.'\n-                'You will have to compile your model again '\n-                'after loading it. '\n-                'Prefer using a Keras optimizer instead '\n-                '(see keras.io/optimizers).')\n-        else:\n-            h5dict['training_config'] = json.dumps({\n-                'optimizer_config': {\n-                    'class_name': model.optimizer.__class__.__name__,\n-                    'config': model.optimizer.get_config()\n-                },\n-                'loss': model.loss,\n-                'metrics': model._compile_metrics,\n-                'weighted_metrics': model._compile_weighted_metrics,\n-                'sample_weight_mode': model.sample_weight_mode,\n-                'loss_weights': model.loss_weights,\n-            }, default=get_json_type).encode('utf8')\n-            symbolic_weights = getattr(model.optimizer, 'weights')\n-            if symbolic_weights:\n-                optimizer_weights_group = h5dict['optimizer_weights']\n-                weight_values = K.batch_get_value(symbolic_weights)\n-                weight_names = []\n-                for i, (w, val) in enumerate(zip(symbolic_weights,\n-                                                 weight_values)):\n-                    # Default values of symbolic_weights is /variable\n-                    # for Theano and CNTK\n-                    if K.backend() == 'theano' or K.backend() == 'cntk':\n-                        if hasattr(w, 'name'):\n-                            if w.name.split('/')[-1] == 'variable':\n-                                name = str(w.name) + '_' + str(i)\n-                            else:\n-                                name = str(w.name)\n-                        else:\n-                            name = 'param_' + str(i)\n-                    else:\n-                        if hasattr(w, 'name') and w.name:\n-                            name = str(w.name)\n-                        else:\n-                            name = 'param_' + str(i)\n-                    if name in weight_names:\n-                        idx = 2\n-                        unique_name = name + '_1'\n-                        while unique_name in weight_names:\n-                            unique_name = name + '_' + str(idx)\n-                            idx += 1\n-                        name = unique_name\n-                    weight_names.append(name.encode('utf8'))\n-                weight_names = _uniquify(weight_names)\n-                optimizer_weights_group['weight_names'] = weight_names\n-                for name, val in zip(weight_names, weight_values):\n-                    optimizer_weights_group[name] = val\n-\n-\n-def _deserialize_model(h5dict, custom_objects=None, compile=True):\n-    \"\"\"De-serializes a model serialized via _serialize_model\n-\n-    # Arguments\n-        h5dict: `keras.utils.hdf5_utils.HFDict` instance.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-        compile: Boolean, whether to compile the model\n-            after loading.\n-\n-    # Returns\n-        A Keras model instance. If an optimizer was found\n-        as part of the saved model, the model is already\n-        compiled. Otherwise, the model is uncompiled and\n-        a warning will be displayed. When `compile` is set\n-        to False, the compilation is omitted without any\n-        warning.\n-    \"\"\"\n-    if not custom_objects:\n-        custom_objects = {}\n-\n-    def convert_custom_objects(obj):\n-        \"\"\"Handles custom object lookup.\n-\n-        # Arguments\n-            obj: object, dict, or list.\n-\n-        # Returns\n-            The same structure, where occurrences\n-                of a custom object name have been replaced\n-                with the custom object.\n-        \"\"\"\n-        if isinstance(obj, list):\n-            deserialized = []\n-            for value in obj:\n-                deserialized.append(convert_custom_objects(value))\n-            return deserialized\n-        if isinstance(obj, dict):\n-            deserialized = {}\n-            for key, value in obj.items():\n-                deserialized[key] = convert_custom_objects(value)\n-            return deserialized\n-        if obj in custom_objects:\n-            return custom_objects[obj]\n-        return obj\n-\n-    model_config = h5dict['model_config']\n-    if model_config is None:\n-        raise ValueError('No model found in config.')\n-    model_config = json.loads(model_config.decode('utf-8'))\n-    model = model_from_config(model_config, custom_objects=custom_objects)\n-    model_weights_group = h5dict['model_weights']\n-\n-    if 'keras_version' in model_weights_group:\n-        original_keras_version = model_weights_group['keras_version'].decode('utf8')\n-    else:\n-        original_keras_version = '1'\n-    if 'backend' in model_weights_group:\n-        original_backend = model_weights_group['backend'].decode('utf8')\n-    else:\n-        original_backend = None\n-\n-    layer_names = model_weights_group['layer_names']\n-\n-    layers = model.layers\n-\n-    filtered_layers = []\n-    for layer in layers:\n-        weights = layer.weights\n-        if weights:\n-            filtered_layers.append(layer)\n-\n-    filtered_layer_names = []\n-    for name in layer_names:\n-        layer_weights = model_weights_group[name]\n-        weight_names = layer_weights['weight_names']\n-        if len(weight_names) > 0:\n-            filtered_layer_names.append(name)\n-\n-    layer_names = filtered_layer_names\n-    if len(layer_names) != len(filtered_layers):\n-        raise ValueError('You are trying to load a weight file'\n-                         ' containing {} layers into a model with {} layers'\n-                         .format(len(layer_names), len(filtered_layers))\n-                         )\n-\n-    # We batch weight value assignments in a single backend call\n-    # which provides a speedup in TensorFlow.\n-    weight_value_tuples = []\n-    for k, name in enumerate(layer_names):\n-        layer_weights = model_weights_group[name]\n-        weight_names = layer_weights['weight_names']\n-        weight_values = [layer_weights[weight_name] for weight_name in weight_names]\n-        layer = filtered_layers[k]\n-        symbolic_weights = layer.weights\n-        weight_values = preprocess_weights_for_loading(layer,\n-                                                       weight_values,\n-                                                       original_keras_version,\n-                                                       original_backend,\n-                                                       reshape=False)\n-        if len(weight_values) != len(symbolic_weights):\n-            raise ValueError('Layer #' + str(k) +\n-                             ' (named \"' + layer.name +\n-                             '\" in the current model) was found to '\n-                             'correspond to layer ' + name +\n-                             ' in the save file. '\n-                             'However the new layer ' + layer.name +\n-                             ' expects ' + str(len(symbolic_weights)) +\n-                             ' weights, but the saved weights have ' +\n-                             str(len(weight_values)) +\n-                             ' elements.')\n-        weight_value_tuples += zip(symbolic_weights, weight_values)\n-    K.batch_set_value(weight_value_tuples)\n-\n-    if compile:\n-        training_config = h5dict.get('training_config')\n-        if training_config is None:\n-            warnings.warn('No training configuration found in save file: '\n-                          'the model was *not* compiled. '\n-                          'Compile it manually.')\n-            return model\n-        training_config = json.loads(training_config.decode('utf-8'))\n-        optimizer_config = training_config['optimizer_config']\n-        optimizer = optimizers.deserialize(optimizer_config,\n-                                           custom_objects=custom_objects)\n-\n-        # Recover loss functions and metrics.\n-        loss_config = training_config['loss']  # Deserialize loss class.\n-        if isinstance(loss_config, dict) and 'class_name' in loss_config:\n-            loss_config = losses.get(loss_config)\n-        loss = convert_custom_objects(loss_config)\n-        metrics = convert_custom_objects(training_config['metrics'])\n-        # Earlier versions of keras didn't dump weighted_metrics properly. Use\n-        # a get to avoid failing if the key is missing\n-        weighted_metrics = convert_custom_objects(\n-            training_config.get('weighted_metrics'))\n-        sample_weight_mode = training_config['sample_weight_mode']\n-        loss_weights = training_config['loss_weights']\n-\n-        # Compile model.\n-        model.compile(optimizer=optimizer,\n-                      loss=loss,\n-                      metrics=metrics,\n-                      weighted_metrics=weighted_metrics,\n-                      loss_weights=loss_weights,\n-                      sample_weight_mode=sample_weight_mode)\n-\n-        # Set optimizer weights.\n-        if 'optimizer_weights' in h5dict:\n-            # Build train function (to get weight updates).\n-            model._make_train_function()\n-            optimizer_weights_group = h5dict['optimizer_weights']\n-            optimizer_weight_names = [\n-                n.decode('utf8') for n in\n-                optimizer_weights_group['weight_names']]\n-            optimizer_weight_values = [optimizer_weights_group[n] for n in\n-                                       optimizer_weight_names]\n-            try:\n-                model.optimizer.set_weights(optimizer_weight_values)\n-            except ValueError:\n-                warnings.warn('Error in loading the saved optimizer '\n-                              'state. As a result, your model is '\n-                              'starting with a freshly initialized '\n-                              'optimizer.')\n-\n-    return model\n-\n-\n-def _gcs_copy(source_filepath, target_filepath, overwrite=True):\n-    \"\"\"Copies a file to/from/within Google Cloud Storage (GCS).\n-\n-    # Arguments\n-        source_filepath: String, path to the file on filesystem or object on GCS to\n-            copy from.\n-        target_filepath: String, path to the file on filesystem or object on GCS to\n-            copy to.\n-        overwrite: Whether we should overwrite an existing file/object at the target\n-            location, or instead ask the user with a manual prompt.\n-    \"\"\"\n-    if tf_file_io is None:\n-        raise ImportError('Google Cloud Storage file transfer requires TensorFlow.')\n-    if not overwrite and tf_file_io.file_exists(target_filepath):\n-        proceed = ask_to_proceed_with_overwrite(target_filepath)\n-        if not proceed:\n-            return\n-    with tf_file_io.FileIO(source_filepath, mode='rb') as source_f:\n-        with tf_file_io.FileIO(target_filepath, mode='wb') as target_f:\n-            target_f.write(source_f.read())\n-\n-\n-def _is_gcs_location(filepath):\n-    \"\"\"Checks if `filepath` is referencing a google storage bucket.\n-\n-    # Arguments\n-        filepath: The location to check.\n-    \"\"\"\n-    return isinstance(filepath, string_types) and filepath.startswith('gs://')\n-\n-\n-def allow_write_to_gcs(save_function):\n-    \"\"\"Function decorator to support saving to Google Cloud Storage (GCS).\n-\n-    This decorator parses the `filepath` argument of the `save_function` and\n-    transfers the file to GCS if `filepath` starts with \"gs://\".\n-\n-    Note: the file is temporarily writen to local filesystem before copied to GSC.\n-\n-    # Arguments\n-        save_function: The function to wrap, with requirements:\n-            - second positional argument should indicate the location to save to.\n-            - third positional argument should be the `overwrite` option indicating\n-            whether we should overwrite an existing file/object at the target\n-            location, or instead ask the user with a manual prompt.\n-    \"\"\"\n-    @wraps(save_function)\n-    def save_wrapper(obj, filepath, overwrite=True, *args, **kwargs):\n-        if _is_gcs_location(filepath):\n-            tmp_filepath = os.path.join(tempfile.gettempdir(),\n-                                        os.path.basename(filepath))\n-            save_function(obj, tmp_filepath, True, *args, **kwargs)\n-            try:\n-                _gcs_copy(tmp_filepath, filepath, overwrite)\n-            finally:\n-                os.remove(tmp_filepath)\n-        else:\n-            save_function(obj, filepath, overwrite, *args, **kwargs)\n-\n-    return save_wrapper\n-\n-\n-def allow_read_from_gcs(load_function):\n-    \"\"\"Function decorator to support loading from Google Cloud Storage (GCS).\n-\n-    This decorator parses the `filepath` argument of the `load_function` and\n-    fetches the required object from GCS if `filepath` starts with \"gs://\".\n-\n-    Note: the file is temporarily copied to local filesystem from GCS before loaded.\n-\n-    # Arguments\n-        load_function: The function to wrap, with requirements:\n-            - should have one _named_ argument `filepath` indicating the location to\n-            load from.\n-    \"\"\"\n-    def extract_named_arg(f, name, args, kwargs):\n-        if name in kwargs:\n-            arg = kwargs.pop(name)\n-            return arg, args, kwargs\n-        argnames = getargspec(f)[0]\n-        for i, (argname, arg) in enumerate(zip(argnames, args)):\n-            if argname == name:\n-                return arg, args[:i] + args[i + 1:], kwargs\n-        else:\n-            raise ValueError('function {} has no argument {}'.format(f, name))\n-\n-    @wraps(load_function)\n-    def load_wrapper(*args, **kwargs):\n-        filepath, _args, _kwargs = extract_named_arg(\n-            load_function, 'filepath', args, kwargs)\n-        if _is_gcs_location(filepath):\n-            tmp_filepath = os.path.join(tempfile.gettempdir(),\n-                                        os.path.basename(filepath))\n-            _gcs_copy(filepath, tmp_filepath)\n-            _kwargs['filepath'] = tmp_filepath\n-            try:\n-                res = load_function(*_args, **_kwargs)\n-            finally:\n-                os.remove(tmp_filepath)\n-            return res\n-        return load_function(*args, **kwargs)\n-\n-    return load_wrapper\n-\n-\n-@allow_write_to_gcs\n-def save_model(model, filepath, overwrite=True, include_optimizer=True):\n-    \"\"\"Save a model to a HDF5 file.\n-\n-    Note: Please also see\n-    [How can I install HDF5 or h5py to save my models in Keras?](\n-        /getting-started/faq/\n-        #how-can-i-install-HDF5-or-h5py-to-save-my-models-in-Keras)\n-    in the FAQ for instructions on how to install `h5py`.\n-\n-    The saved model contains:\n-        - the model's configuration (topology)\n-        - the model's weights\n-        - the model's optimizer's state (if any)\n-\n-    Thus the saved model can be reinstantiated in\n-    the exact same state, without any of the code\n-    used for model definition or training.\n-\n-    # Arguments\n-        model: Keras model instance to be saved.\n-        filepath: one of the following:\n-            - string, path to the file to save the model to\n-            - h5py.File or h5py.Group object where to save the model\n-            - any file-like object implementing the method `write` that accepts\n-                `bytes` data (e.g. `io.BytesIO`).\n-        overwrite: Whether we should overwrite any existing\n-            model at the target location, or instead\n-            ask the user with a manual prompt.\n-        include_optimizer: If True, save optimizer's state together.\n-\n-    # Raises\n-        ImportError: if h5py is not available.\n-    \"\"\"\n-    if h5py is None:\n-        raise ImportError('`save_model` requires h5py.')\n-\n-    if H5Dict.is_supported_type(filepath):\n-        opens_file = not isinstance(filepath, (dict, h5py.Group))\n-        if opens_file and os.path.isfile(filepath) and not overwrite:\n-            proceed = ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        with H5Dict(filepath, mode='w') as h5dict:\n-            _serialize_model(model, h5dict, include_optimizer)\n-    elif hasattr(filepath, 'write') and callable(filepath.write):\n-        # write as binary stream\n-        def save_function(h5file):\n-            _serialize_model(model, H5Dict(h5file), include_optimizer)\n-        save_to_binary_h5py(save_function, filepath)\n-    else:\n-        raise ValueError('unexpected type {} for `filepath`'.format(type(filepath)))\n-\n-\n-@allow_read_from_gcs\n-def load_model(filepath, custom_objects=None, compile=True):\n-    \"\"\"Loads a model saved via `save_model`.\n-\n-    # Arguments\n-        filepath: one of the following:\n-            - string, path to the saved model\n-            - h5py.File or h5py.Group object from which to load the model\n-            - any file-like object implementing the method `read` that returns\n-            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-        compile: Boolean, whether to compile the model\n-            after loading.\n-\n-    # Returns\n-        A Keras model instance. If an optimizer was found\n-        as part of the saved model, the model is already\n-        compiled. Otherwise, the model is uncompiled and\n-        a warning will be displayed. When `compile` is set\n-        to False, the compilation is omitted without any\n-        warning.\n-\n-    # Raises\n-        ImportError: if h5py is not available.\n-        ValueError: In case of an invalid savefile.\n-    \"\"\"\n-    if h5py is None:\n-        raise ImportError('`load_model` requires h5py.')\n-\n-    if H5Dict.is_supported_type(filepath):\n-        with H5Dict(filepath, mode='r') as h5dict:\n-            model = _deserialize_model(h5dict, custom_objects, compile)\n-    elif hasattr(filepath, 'write') and callable(filepath.write):\n-        def load_function(h5file):\n-            return _deserialize_model(H5Dict(h5file), custom_objects, compile)\n-        model = load_from_binary_h5py(load_function, filepath)\n-    else:\n-        raise ValueError('unexpected type {} for `filepath`'.format(type(filepath)))\n-\n-    return model\n-\n-\n-def pickle_model(model):\n-    d = {}\n-    h5dict = H5Dict(d)\n-    _serialize_model(model, h5dict)\n-    return d\n-\n-\n-def unpickle_model(state):\n-    h5dict = H5Dict(state, mode='r')\n-    return _deserialize_model(h5dict)\n-\n-\n-def model_from_config(config, custom_objects=None):\n-    \"\"\"Instantiates a Keras model from its config.\n-\n-    # Arguments\n-        config: Configuration dictionary.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-\n-    # Returns\n-        A Keras model instance (uncompiled).\n-\n-    # Raises\n-        TypeError: if `config` is not a dictionary.\n-    \"\"\"\n-    if isinstance(config, list):\n-        raise TypeError('`model_from_config` expects a dictionary, '\n-                        'not a list. Maybe you meant to use '\n-                        '`Sequential.from_config(config)`?')\n-    from ..layers import deserialize\n-    return deserialize(config, custom_objects=custom_objects)\n-\n-\n-def model_from_yaml(yaml_string, custom_objects=None):\n-    \"\"\"Parses a yaml model configuration file and returns a model instance.\n-\n-    # Arguments\n-        yaml_string: YAML string encoding a model configuration.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-\n-    # Returns\n-        A Keras model instance (uncompiled).\n-    \"\"\"\n-    if hasattr(yaml, 'FullLoader'):\n-        config = yaml.load(yaml_string, Loader=yaml.FullLoader)\n-    else:\n-        config = yaml.load(yaml_string)\n-    from ..layers import deserialize\n-    return deserialize(config, custom_objects=custom_objects)\n-\n-\n-def model_from_json(json_string, custom_objects=None):\n-    \"\"\"Parses a JSON model configuration file and returns a model instance.\n-\n-    # Arguments\n-        json_string: JSON string encoding a model configuration.\n-        custom_objects: Optional dictionary mapping names\n-            (strings) to custom classes or functions to be\n-            considered during deserialization.\n-\n-    # Returns\n-        A Keras model instance (uncompiled).\n-    \"\"\"\n-    config = json.loads(json_string)\n-    from ..layers import deserialize\n-    return deserialize(config, custom_objects=custom_objects)\n-\n-\n-def save_attributes_to_hdf5_group(group, name, data):\n-    \"\"\"Saves attributes (data) of the specified name into the HDF5 group.\n-\n-    This method deals with an inherent problem of HDF5 file which is not\n-    able to store data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n-\n-    # Arguments\n-        group: A pointer to a HDF5 group.\n-        name: A name of the attributes to save.\n-        data: Attributes data to store.\n-    \"\"\"\n-    # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n-    # because in that case even chunking the array would not make the saving\n-    # possible.\n-    bad_attributes = [x for x in data if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n-\n-    # Expecting this to never be true.\n-    if len(bad_attributes) > 0:\n-        raise RuntimeError('The following attributes cannot be saved to HDF5 '\n-                           'file because they are larger than %d bytes: %s'\n-                           % (HDF5_OBJECT_HEADER_LIMIT,\n-                              ', '.join([x for x in bad_attributes])))\n-\n-    data_npy = np.asarray(data)\n-\n-    num_chunks = 1\n-    chunked_data = np.array_split(data_npy, num_chunks)\n-\n-    # This will never loop forever thanks to the test above.\n-    while any(map(lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT, chunked_data)):\n-        num_chunks += 1\n-        chunked_data = np.array_split(data_npy, num_chunks)\n-\n-    if num_chunks > 1:\n-        for chunk_id, chunk_data in enumerate(chunked_data):\n-            group.attrs['%s%d' % (name, chunk_id)] = chunk_data\n-    else:\n-        group.attrs[name] = data\n-\n-\n-def load_attributes_from_hdf5_group(group, name):\n-    \"\"\"Loads attributes of the specified name from the HDF5 group.\n-\n-    This method deals with an inherent problem\n-    of HDF5 file which is not able to store\n-    data larger than HDF5_OBJECT_HEADER_LIMIT bytes.\n-\n-    # Arguments\n-        group: A pointer to a HDF5 group.\n-        name: A name of the attributes to load.\n-\n-    # Returns\n-        data: Attributes data.\n-    \"\"\"\n-    if name in group.attrs:\n-        data = [n.decode('utf8') for n in group.attrs[name]]\n-    else:\n-        data = []\n-        chunk_id = 0\n-        while ('%s%d' % (name, chunk_id)) in group.attrs:\n-            data.extend([n.decode('utf8')\n-                         for n in group.attrs['%s%d' % (name, chunk_id)]])\n-            chunk_id += 1\n-    return data\n-\n-\n-def save_weights_to_hdf5_group(group, layers):\n-    \"\"\"Saves weights into the HDF5 group.\n-\n-    # Arguments\n-        group: A pointer to a HDF5 group.\n-        layers: Layers to load.\n-    \"\"\"\n-    from .. import __version__ as keras_version\n-\n-    save_attributes_to_hdf5_group(\n-        group, 'layer_names', [layer.name.encode('utf8') for layer in layers])\n-    group.attrs['backend'] = K.backend().encode('utf8')\n-    group.attrs['keras_version'] = str(keras_version).encode('utf8')\n-\n-    # Sort model layers by layer name to ensure that group names are strictly\n-    # growing to avoid prefix issues.\n-    for layer in sorted(layers, key=lambda x: x.name):\n-        g = group.create_group(layer.name)\n-        symbolic_weights = layer.weights\n-        weight_values = K.batch_get_value(symbolic_weights)\n-        weight_names = []\n-        for i, (w, val) in enumerate(zip(symbolic_weights, weight_values)):\n-            if hasattr(w, 'name') and w.name:\n-                name = str(w.name)\n-            else:\n-                name = 'param_' + str(i)\n-            weight_names.append(name.encode('utf8'))\n-        save_attributes_to_hdf5_group(g, 'weight_names', weight_names)\n-        for name, val in zip(weight_names, weight_values):\n-            param_dset = g.create_dataset(name, val.shape,\n-                                          dtype=val.dtype)\n-            if not val.shape:\n-                # scalar\n-                param_dset[()] = val\n-            else:\n-                param_dset[:] = val\n-\n-\n-def preprocess_weights_for_loading(layer, weights,\n-                                   original_keras_version=None,\n-                                   original_backend=None,\n-                                   reshape=False):\n-    \"\"\"Converts layers weights from Keras 1 format to Keras 2.\n-\n-    # Arguments\n-        layer: Layer instance.\n-        weights: List of weights values (Numpy arrays).\n-        original_keras_version: Keras version for the weights, as a string.\n-        original_backend: Keras backend the weights were trained with,\n-            as a string.\n-        reshape: Reshape weights to fit the layer when the correct number\n-            of values are present but the shape does not match.\n-\n-    # Returns\n-        A list of weights values (Numpy arrays).\n-    \"\"\"\n-    def convert_nested_bidirectional(weights):\n-        \"\"\"Converts layers nested in `Bidirectional` wrapper.\n-\n-        # Arguments\n-            weights: List of weights values (Numpy arrays).\n-        # Returns\n-            A list of weights values (Numpy arrays).\n-        \"\"\"\n-        num_weights_per_layer = len(weights) // 2\n-        forward_weights = preprocess_weights_for_loading(\n-            layer.forward_layer,\n-            weights[:num_weights_per_layer],\n-            original_keras_version,\n-            original_backend)\n-        backward_weights = preprocess_weights_for_loading(\n-            layer.backward_layer,\n-            weights[num_weights_per_layer:],\n-            original_keras_version,\n-            original_backend)\n-        return forward_weights + backward_weights\n-\n-    def convert_nested_time_distributed(weights):\n-        \"\"\"Converts layers nested in `TimeDistributed` wrapper.\n-\n-        # Arguments\n-            weights: List of weights values (Numpy arrays).\n-        # Returns\n-            A list of weights values (Numpy arrays).\n-        \"\"\"\n-        return preprocess_weights_for_loading(\n-            layer.layer, weights, original_keras_version, original_backend)\n-\n-    def convert_nested_model(weights):\n-        \"\"\"Converts layers nested in `Model` or `Sequential`.\n-\n-        # Arguments\n-            weights: List of weights values (Numpy arrays).\n-        # Returns\n-            A list of weights values (Numpy arrays).\n-        \"\"\"\n-        new_weights = []\n-        # trainable weights\n-        for sublayer in layer.layers:\n-            num_weights = len(sublayer.trainable_weights)\n-            if num_weights > 0:\n-                new_weights.extend(preprocess_weights_for_loading(\n-                    layer=sublayer,\n-                    weights=weights[:num_weights],\n-                    original_keras_version=original_keras_version,\n-                    original_backend=original_backend))\n-                weights = weights[num_weights:]\n-\n-        # non-trainable weights\n-        for sublayer in layer.layers:\n-            ref_ids = [id(w) for w in sublayer.trainable_weights]\n-            num_weights = len([l for l in sublayer.weights\n-                               if id(l) not in ref_ids])\n-            if num_weights > 0:\n-                new_weights.extend(preprocess_weights_for_loading(\n-                    layer=sublayer,\n-                    weights=weights[:num_weights],\n-                    original_keras_version=original_keras_version,\n-                    original_backend=original_backend))\n-                weights = weights[num_weights:]\n-        return new_weights\n-\n-    # Convert layers nested in Bidirectional/TimeDistributed/Model/Sequential.\n-    # Both transformation should be ran for both Keras 1->2 conversion\n-    # and for conversion of CuDNN layers.\n-    if layer.__class__.__name__ == 'Bidirectional':\n-        weights = convert_nested_bidirectional(weights)\n-    if layer.__class__.__name__ == 'TimeDistributed':\n-        weights = convert_nested_time_distributed(weights)\n-    elif layer.__class__.__name__ in ['Model', 'Sequential']:\n-        weights = convert_nested_model(weights)\n-\n-    if original_keras_version == '1':\n-        if layer.__class__.__name__ == 'TimeDistributed':\n-            weights = preprocess_weights_for_loading(layer.layer,\n-                                                     weights,\n-                                                     original_keras_version,\n-                                                     original_backend)\n-\n-        if layer.__class__.__name__ == 'Conv1D':\n-            shape = weights[0].shape\n-            # Handle Keras 1.1 format\n-            if shape[:2] != (layer.kernel_size[0], 1) or shape[3] != layer.filters:\n-                # Legacy shape:\n-                # (filters, input_dim, filter_length, 1)\n-                assert (shape[0] == layer.filters and\n-                        shape[2:] == (layer.kernel_size[0], 1))\n-                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n-            weights[0] = weights[0][:, 0, :, :]\n-\n-        if layer.__class__.__name__ == 'Conv2D':\n-            if layer.data_format == 'channels_first':\n-                # old: (filters, stack_size, kernel_rows, kernel_cols)\n-                # new: (kernel_rows, kernel_cols, stack_size, filters)\n-                weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n-\n-        if layer.__class__.__name__ == 'Conv2DTranspose':\n-            if layer.data_format == 'channels_last':\n-                # old: (kernel_rows, kernel_cols, stack_size, filters)\n-                # new: (kernel_rows, kernel_cols, filters, stack_size)\n-                weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n-            if layer.data_format == 'channels_first':\n-                # old: (filters, stack_size, kernel_rows, kernel_cols)\n-                # new: (kernel_rows, kernel_cols, filters, stack_size)\n-                weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n-\n-        if layer.__class__.__name__ == 'Conv3D':\n-            if layer.data_format == 'channels_first':\n-                # old: (filters, stack_size, ...)\n-                # new: (..., stack_size, filters)\n-                weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n-\n-        if layer.__class__.__name__ == 'GRU':\n-            if len(weights) == 9:\n-                kernel = np.concatenate([weights[0],\n-                                         weights[3],\n-                                         weights[6]], axis=-1)\n-                recurrent_kernel = np.concatenate([weights[1],\n-                                                   weights[4],\n-                                                   weights[7]], axis=-1)\n-                bias = np.concatenate([weights[2],\n-                                       weights[5],\n-                                       weights[8]], axis=-1)\n-                weights = [kernel, recurrent_kernel, bias]\n-\n-        if layer.__class__.__name__ == 'LSTM':\n-            if len(weights) == 12:\n-                # old: i, c, f, o\n-                # new: i, f, c, o\n-                kernel = np.concatenate([weights[0],\n-                                         weights[6],\n-                                         weights[3],\n-                                         weights[9]], axis=-1)\n-                recurrent_kernel = np.concatenate([weights[1],\n-                                                   weights[7],\n-                                                   weights[4],\n-                                                   weights[10]], axis=-1)\n-                bias = np.concatenate([weights[2],\n-                                       weights[8],\n-                                       weights[5],\n-                                       weights[11]], axis=-1)\n-                weights = [kernel, recurrent_kernel, bias]\n-\n-        if layer.__class__.__name__ == 'ConvLSTM2D':\n-            if len(weights) == 12:\n-                kernel = np.concatenate([weights[0],\n-                                         weights[6],\n-                                         weights[3],\n-                                         weights[9]], axis=-1)\n-                recurrent_kernel = np.concatenate([weights[1],\n-                                                   weights[7],\n-                                                   weights[4],\n-                                                   weights[10]], axis=-1)\n-                bias = np.concatenate([weights[2],\n-                                       weights[8],\n-                                       weights[5],\n-                                       weights[11]], axis=-1)\n-                if layer.data_format == 'channels_first':\n-                    # old: (filters, stack_size, kernel_rows, kernel_cols)\n-                    # new: (kernel_rows, kernel_cols, stack_size, filters)\n-                    kernel = np.transpose(kernel, (2, 3, 1, 0))\n-                    recurrent_kernel = np.transpose(recurrent_kernel,\n-                                                    (2, 3, 1, 0))\n-                weights = [kernel, recurrent_kernel, bias]\n-\n-    conv_layers = ['Conv1D',\n-                   'Conv2D',\n-                   'Conv3D',\n-                   'Conv2DTranspose',\n-                   'ConvLSTM2D']\n-    if layer.__class__.__name__ in conv_layers:\n-        layer_weights_shape = K.int_shape(layer.weights[0])\n-        if _need_convert_kernel(original_backend):\n-            weights[0] = conv_utils.convert_kernel(weights[0])\n-            if layer.__class__.__name__ == 'ConvLSTM2D':\n-                weights[1] = conv_utils.convert_kernel(weights[1])\n-        if reshape and layer_weights_shape != weights[0].shape:\n-            if weights[0].size != np.prod(layer_weights_shape):\n-                raise ValueError('Weights must be of equal size to ' +\n-                                 'apply a reshape operation. ' +\n-                                 'Layer ' + layer.name +\n-                                 '\\'s weights have shape ' +\n-                                 str(layer_weights_shape) + ' and size ' +\n-                                 str(np.prod(layer_weights_shape)) + '. ' +\n-                                 'The weights for loading have shape ' +\n-                                 str(weights[0].shape) + ' and size ' +\n-                                 str(weights[0].size) + '. ')\n-            weights[0] = np.reshape(weights[0], layer_weights_shape)\n-        elif layer_weights_shape != weights[0].shape:\n-            weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n-            if layer.__class__.__name__ == 'ConvLSTM2D':\n-                weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\n-\n-    # convert CuDNN layers\n-    weights = _convert_rnn_weights(layer, weights)\n-\n-    return weights\n-\n-\n-def _convert_rnn_weights(layer, weights):\n-    \"\"\"Converts weights for RNN layers between native and CuDNN format.\n-\n-    Input kernels for each gate are transposed and converted between Fortran\n-    and C layout, recurrent kernels are transposed. For LSTM biases are summed/\n-    split in half, for GRU biases are reshaped.\n-\n-    Weights can be converted in both directions between `LSTM` and`CuDNNSLTM`\n-    and between `CuDNNGRU` and `GRU(reset_after=True)`. Default `GRU` is not\n-    compatible with `CuDNNGRU`.\n-\n-    For missing biases in `LSTM`/`GRU` (`use_bias=False`),\n-    no conversion is made.\n-\n-    # Arguments\n-        layer: Target layer instance.\n-        weights: List of source weights values (input kernels, recurrent\n-            kernels, [biases]) (Numpy arrays).\n-\n-    # Returns\n-        A list of converted weights values (Numpy arrays).\n-\n-    # Raises\n-        ValueError: for incompatible GRU layer/weights or incompatible biases\n-    \"\"\"\n-\n-    def transform_kernels(kernels, func, n_gates):\n-        \"\"\"Transforms kernel for each gate separately using given function.\n-\n-        # Arguments\n-            kernels: Stacked array of kernels for individual gates.\n-            func: Function applied to kernel of each gate.\n-            n_gates: Number of gates (4 for LSTM, 3 for GRU).\n-        # Returns\n-            Stacked array of transformed kernels.\n-        \"\"\"\n-        return np.hstack([func(k) for k in np.hsplit(kernels, n_gates)])\n-\n-    def transpose_input(from_cudnn):\n-        \"\"\"Makes a function that transforms input kernels from/to CuDNN format.\n-\n-        It keeps the shape, but changes between the layout (Fortran/C). Eg.:\n-\n-        ```\n-        Keras                 CuDNN\n-        [[0, 1, 2],  <--->  [[0, 2, 4],\n-         [3, 4, 5]]          [1, 3, 5]]\n-        ```\n-\n-        It can be passed to `transform_kernels()`.\n-\n-        # Arguments\n-            from_cudnn: `True` if source weights are in CuDNN format, `False`\n-                if they're in plain Keras format.\n-        # Returns\n-            Function that converts input kernel to the other format.\n-        \"\"\"\n-        order = 'F' if from_cudnn else 'C'\n-\n-        def transform(kernel):\n-            return kernel.T.reshape(kernel.shape, order=order)\n-\n-        return transform\n-\n-    target_class = layer.__class__.__name__\n-\n-    # convert the weights between CuDNNLSTM and LSTM\n-    if target_class in ['LSTM', 'CuDNNLSTM'] and len(weights) == 3:\n-        # determine if we're loading a CuDNNLSTM layer\n-        # from the number of bias weights:\n-        # CuDNNLSTM has (units * 8) weights; while LSTM has (units * 4)\n-        # if there's no bias weight in the file, skip this conversion\n-        units = weights[1].shape[0]\n-        bias_shape = weights[2].shape\n-        n_gates = 4\n-\n-        if bias_shape == (2 * units * n_gates,):\n-            source = 'CuDNNLSTM'\n-        elif bias_shape == (units * n_gates,):\n-            source = 'LSTM'\n-        else:\n-            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n-\n-        def convert_weights(weights, from_cudnn=True):\n-            # transpose (and reshape) input and recurrent kernels\n-            kernels = transform_kernels(weights[0],\n-                                        transpose_input(from_cudnn),\n-                                        n_gates)\n-            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n-            if from_cudnn:\n-                # merge input and recurrent biases into a single set\n-                biases = np.sum(np.split(weights[2], 2, axis=0), axis=0)\n-            else:\n-                # Split single set of biases evenly to two sets. The way of\n-                # splitting doesn't matter as long as the two sets sum is kept.\n-                biases = np.tile(0.5 * weights[2], 2)\n-            return [kernels, recurrent_kernels, biases]\n-\n-        if source != target_class:\n-            weights = convert_weights(weights, from_cudnn=source == 'CuDNNLSTM')\n-\n-    # convert the weights between CuDNNGRU and GRU(reset_after=True)\n-    if target_class in ['GRU', 'CuDNNGRU'] and len(weights) == 3:\n-        # We can determine the source of the weights from the shape of the bias.\n-        # If there is no bias we skip the conversion\n-        # since CuDNNGRU always has biases.\n-\n-        units = weights[1].shape[0]\n-        bias_shape = weights[2].shape\n-        n_gates = 3\n-\n-        def convert_weights(weights, from_cudnn=True):\n-            kernels = transform_kernels(weights[0],\n-                                        transpose_input(from_cudnn),\n-                                        n_gates)\n-            recurrent_kernels = transform_kernels(weights[1], lambda k: k.T, n_gates)\n-            biases = np.array(weights[2]).reshape((2, -1) if from_cudnn else -1)\n-            return [kernels, recurrent_kernels, biases]\n-\n-        if bias_shape == (2 * units * n_gates,):\n-            source = 'CuDNNGRU'\n-        elif bias_shape == (2, units * n_gates):\n-            source = 'GRU(reset_after=True)'\n-        elif bias_shape == (units * n_gates,):\n-            source = 'GRU(reset_after=False)'\n-        else:\n-            raise ValueError('Invalid bias shape: ' + str(bias_shape))\n-\n-        if target_class == 'CuDNNGRU':\n-            target = 'CuDNNGRU'\n-        elif layer.reset_after:\n-            target = 'GRU(reset_after=True)'\n-        else:\n-            target = 'GRU(reset_after=False)'\n-\n-        # only convert between different types\n-        if source != target:\n-            types = (source, target)\n-            if 'GRU(reset_after=False)' in types:\n-                raise ValueError('%s is not compatible with %s' % types)\n-            if source == 'CuDNNGRU':\n-                weights = convert_weights(weights, from_cudnn=True)\n-            elif source == 'GRU(reset_after=True)':\n-                weights = convert_weights(weights, from_cudnn=False)\n-\n-    return weights\n-\n-\n-def _need_convert_kernel(original_backend):\n-    \"\"\"Checks if conversion on kernel matrices is required during weight loading.\n-\n-    The convolution operation is implemented differently in different backends.\n-    While TH implements convolution, TF and CNTK implement the correlation operation.\n-    So the channel axis needs to be flipped when TF weights are loaded on a TH model,\n-    or vice versa. However, there's no conversion required between TF and CNTK.\n-\n-    # Arguments\n-        original_backend: Keras backend the weights were trained with, as a string.\n-\n-    # Returns\n-        `True` if conversion on kernel matrices is required, otherwise `False`.\n-    \"\"\"\n-    if original_backend is None:\n-        # backend information not available\n-        return False\n-    uses_correlation = {'tensorflow': True,\n-                        'theano': False,\n-                        'cntk': True}\n-    if original_backend not in uses_correlation:\n-        # By default, do not convert the kernels if the original backend is unknown\n-        return False\n-    if K.backend() in uses_correlation:\n-        current_uses_correlation = uses_correlation[K.backend()]\n-    else:\n-        # Assume unknown backends use correlation\n-        current_uses_correlation = True\n-    return uses_correlation[original_backend] != current_uses_correlation\n-\n-\n-def load_weights_from_hdf5_group(f, layers, reshape=False):\n-    \"\"\"Implements topological (order-based) weight loading.\n-\n-    # Arguments\n-        f: A pointer to a HDF5 group.\n-        layers: a list of target layers.\n-        reshape: Reshape weights to fit the layer when the correct number\n-            of values are present but the shape does not match.\n-\n-    # Raises\n-        ValueError: in case of mismatch between provided layers\n-            and weights file.\n-    \"\"\"\n-    if 'keras_version' in f.attrs:\n-        original_keras_version = f.attrs['keras_version'].decode('utf8')\n-    else:\n-        original_keras_version = '1'\n-    if 'backend' in f.attrs:\n-        original_backend = f.attrs['backend'].decode('utf8')\n-    else:\n-        original_backend = None\n-\n-    filtered_layers = []\n-    for layer in layers:\n-        weights = layer.weights\n-        if weights:\n-            filtered_layers.append(layer)\n-\n-    layer_names = load_attributes_from_hdf5_group(f, 'layer_names')\n-    filtered_layer_names = []\n-    for name in layer_names:\n-        g = f[name]\n-        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n-        if weight_names:\n-            filtered_layer_names.append(name)\n-    layer_names = filtered_layer_names\n-    if len(layer_names) != len(filtered_layers):\n-        raise ValueError('You are trying to load a weight file '\n-                         'containing ' + str(len(layer_names)) +\n-                         ' layers into a model with ' +\n-                         str(len(filtered_layers)) + ' layers.')\n-\n-    # We batch weight value assignments in a single backend call\n-    # which provides a speedup in TensorFlow.\n-    weight_value_tuples = []\n-    for k, name in enumerate(layer_names):\n-        g = f[name]\n-        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n-        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n-        layer = filtered_layers[k]\n-        symbolic_weights = layer.weights\n-        weight_values = preprocess_weights_for_loading(layer,\n-                                                       weight_values,\n-                                                       original_keras_version,\n-                                                       original_backend,\n-                                                       reshape=reshape)\n-        if len(weight_values) != len(symbolic_weights):\n-            raise ValueError('Layer #' + str(k) +\n-                             ' (named \"' + layer.name +\n-                             '\" in the current model) was found to '\n-                             'correspond to layer ' + name +\n-                             ' in the save file. '\n-                             'However the new layer ' + layer.name +\n-                             ' expects ' + str(len(symbolic_weights)) +\n-                             ' weights, but the saved weights have ' +\n-                             str(len(weight_values)) +\n-                             ' elements.')\n-        weight_value_tuples += zip(symbolic_weights, weight_values)\n-    K.batch_set_value(weight_value_tuples)\n-\n-\n-def load_weights_from_hdf5_group_by_name(f, layers, skip_mismatch=False,\n-                                         reshape=False):\n-    \"\"\"Implements name-based weight loading.\n-\n-    (instead of topological weight loading).\n-\n-    Layers that have no matching name are skipped.\n-\n-    # Arguments\n-        f: A pointer to a HDF5 group.\n-        layers: A list of target layers.\n-        skip_mismatch: Boolean, whether to skip loading of layers\n-            where there is a mismatch in the number of weights,\n-            or a mismatch in the shape of the weights.\n-        reshape: Reshape weights to fit the layer when the correct number\n-            of values are present but the shape does not match.\n-\n-    # Raises\n-        ValueError: in case of mismatch between provided layers\n-            and weights file and skip_mismatch=False.\n-    \"\"\"\n-    if 'keras_version' in f.attrs:\n-        original_keras_version = f.attrs['keras_version'].decode('utf8')\n-    else:\n-        original_keras_version = '1'\n-    if 'backend' in f.attrs:\n-        original_backend = f.attrs['backend'].decode('utf8')\n-    else:\n-        original_backend = None\n-\n-    # New file format.\n-    layer_names = load_attributes_from_hdf5_group(f, 'layer_names')\n-\n-    # Reverse index of layer name to list of layers with name.\n-    index = {}\n-    for layer in layers:\n-        if layer.name:\n-            index.setdefault(layer.name, []).append(layer)\n-\n-    # We batch weight value assignments in a single backend call\n-    # which provides a speedup in TensorFlow.\n-    weight_value_tuples = []\n-    for k, name in enumerate(layer_names):\n-        g = f[name]\n-        weight_names = load_attributes_from_hdf5_group(g, 'weight_names')\n-        weight_values = [np.asarray(g[weight_name]) for weight_name in weight_names]\n-\n-        for layer in index.get(name, []):\n-            symbolic_weights = layer.weights\n-            weight_values = preprocess_weights_for_loading(\n-                layer,\n-                weight_values,\n-                original_keras_version,\n-                original_backend,\n-                reshape=reshape)\n-            if len(weight_values) != len(symbolic_weights):\n-                if skip_mismatch:\n-                    warnings.warn('Skipping loading of weights for '\n-                                  'layer {}'.format(layer.name) + ' due to mismatch '\n-                                  'in number of weights ({} vs {}).'.format(\n-                                      len(symbolic_weights), len(weight_values)))\n-                    continue\n-                else:\n-                    raise ValueError('Layer #' + str(k) +\n-                                     ' (named \"' + layer.name +\n-                                     '\") expects ' +\n-                                     str(len(symbolic_weights)) +\n-                                     ' weight(s), but the saved weights' +\n-                                     ' have ' + str(len(weight_values)) +\n-                                     ' element(s).')\n-            # Set values.\n-            for i in range(len(weight_values)):\n-                symbolic_shape = K.int_shape(symbolic_weights[i])\n-                if symbolic_shape != weight_values[i].shape:\n-                    if skip_mismatch:\n-                        warnings.warn('Skipping loading of weights for '\n-                                      'layer {}'.format(layer.name) + ' due to '\n-                                      'mismatch in shape ({} vs {}).'.format(\n-                                          symbolic_weights[i].shape,\n-                                          weight_values[i].shape))\n-                        continue\n-                    else:\n-                        raise ValueError('Layer #' + str(k) +\n-                                         ' (named \"' + layer.name +\n-                                         '\"), weight ' +\n-                                         str(symbolic_weights[i]) +\n-                                         ' has shape {}'.format(symbolic_shape) +\n-                                         ', but the saved weight has shape ' +\n-                                         str(weight_values[i].shape) + '.')\n-                else:\n-                    weight_value_tuples.append((symbolic_weights[i],\n-                                                weight_values[i]))\n-\n-    K.batch_set_value(weight_value_tuples)\n+\"\"\"Model saving utilities.\"\"\"\n+from tensorflow.keras.models import save_model\n+from tensorflow.keras.models import load_model\n+from tensorflow.keras.models import model_from_config\n+from tensorflow.keras.models import model_from_yaml\n+from tensorflow.keras.models import model_from_json\n\n@@ -1,305 +1,2 @@\n-\"\"\"Sequential model class.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import warnings\n-import copy\n-\n-from . import network\n-from .training import Model\n-from .base_layer import Layer\n-from .input_layer import Input\n-from .input_layer import InputLayer\n-from .. import backend as K\n-from .. import layers as layer_module\n-\n-try:\n-    import h5py\n-except ImportError:\n-    h5py = None\n-\n-\n-class Sequential(Model):\n-    \"\"\"Linear stack of layers.\n-\n-    # Arguments\n-        layers: list of layers to add to the model.\n-        name: Name given to the model\n-\n-    # Example\n-\n-    ```python\n-    # Optionally, the first layer can receive an `input_shape` argument:\n-    model = Sequential()\n-    model.add(Dense(32, input_shape=(500,)))\n-\n-    # Afterwards, we do automatic shape inference:\n-    model.add(Dense(32))\n-\n-    # This is identical to the following:\n-    model = Sequential()\n-    model.add(Dense(32, input_dim=500))\n-\n-    # And to the following:\n-    model = Sequential()\n-    model.add(Dense(32, batch_input_shape=(None, 500)))\n-\n-    # Note that you can also omit the `input_shape` argument:\n-    # In that case the model gets built the first time you call `fit` (or other\n-    # training and evaluation methods).\n-    model = Sequential()\n-    model.add(Dense(32))\n-    model.add(Dense(32))\n-    model.compile(optimizer=optimizer, loss=loss)\n-\n-    # This builds the model for the first time:\n-    model.fit(x, y, batch_size=32, epochs=10)\n-\n-    # Note that when using this delayed-build pattern\n-    # (no input shape specified),\n-    # the model doesn't have any weights until the first call\n-    # to a training/evaluation method (since it isn't yet built):\n-    model = Sequential()\n-    model.add(Dense(32))\n-    model.add(Dense(32))\n-    model.weights  # returns []\n-\n-    # Whereas if you specify the input shape, the model gets built continuously\n-    # as you are adding layers:\n-    model = Sequential()\n-    model.add(Dense(32, input_shape=(500,)))\n-    model.add(Dense(32))\n-    model.weights  # returns list of length 4\n-\n-    # When using the delayed-build pattern (no input shape specified), you can\n-    # choose to manually build your model by calling\n-    # `build(batch_input_shape)`:\n-    model = Sequential()\n-    model.add(Dense(32))\n-    model.add(Dense(32))\n-    model.build((None, 500))\n-    model.weights  # returns list of length 4\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, layers=None, name=None):\n-        super(Sequential, self).__init__(name=name)\n-        self._build_input_shape = None\n-\n-        # Add to the model any layers passed to the constructor.\n-        if layers:\n-            for layer in layers:\n-                self.add(layer)\n-\n-    @property\n-    def layers(self):\n-        # Historically, `sequential.layers` only returns layers that were added\n-        # via `add`, and omits the auto-generated `InputLayer`\n-        # that comes at the bottom of the stack.\n-        if self._layers and isinstance(self._layers[0], InputLayer):\n-            return self._layers[1:]\n-        return self._layers\n-\n-    @property\n-    def model(self):\n-        # Historically, `Sequential` was once\n-        # implemented as a wrapper for `Model` which maintained\n-        # its underlying `Model` as the `model` property.\n-        # We keep it for compatibility reasons.\n-        warnings.warn('`Sequential.model` is deprecated. '\n-                      '`Sequential` is a subclass of `Model`, you can '\n-                      'just use your `Sequential` instance directly.')\n-        return self\n-\n-    def add(self, layer):\n-        \"\"\"Adds a layer instance on top of the layer stack.\n-\n-        # Arguments\n-            layer: layer instance.\n-\n-        # Raises\n-            TypeError: If `layer` is not a layer instance.\n-            ValueError: In case the `layer` argument does not\n-                know its input shape.\n-            ValueError: In case the `layer` argument has\n-                multiple output tensors, or is already connected\n-                somewhere else (forbidden in `Sequential` models).\n-        \"\"\"\n-        if not isinstance(layer, Layer):\n-            raise TypeError('The added layer must be '\n-                            'an instance of class Layer. '\n-                            'Found: ' + str(layer))\n-        self.built = False\n-        if not self._layers:\n-            set_inputs = False\n-            # First layer in model: check that it is an input layer.\n-            if not isinstance(layer, InputLayer):\n-                # Create an input tensor and call `layer` on the input tensor.\n-                # First, we need to infer the expected input shape and dtype.\n-                first_layer = layer\n-                if isinstance(layer, (Model, Sequential)):\n-                    # We were passed a model as first layer.\n-                    # This requires a specific way to figure out the\n-                    # input shape and dtype.\n-                    if not layer.layers:\n-                        raise ValueError('Cannot add an empty model '\n-                                         'to a `Sequential` model.')\n-                    # In case of nested models: recover the first layer\n-                    # of the deepest model to infer input shape and dtype.\n-                    first_layer = layer.layers[0]\n-                    while isinstance(first_layer, (Model, Sequential)):\n-                        first_layer = first_layer.layers[0]\n-\n-                if hasattr(first_layer, 'batch_input_shape'):\n-                    batch_shape = first_layer.batch_input_shape\n-                    dtype = first_layer.dtype\n-                    # Instantiate the input layer.\n-                    x = Input(\n-                        batch_shape=batch_shape,\n-                        dtype=dtype,\n-                        name=layer.name + '_input')\n-                    # This will build the current layer\n-                    # and create the node connecting the current layer\n-                    # to the input layer we just created.\n-                    layer(x)\n-                    set_inputs = True\n-            else:\n-                # Corner case where the user passes an InputLayer via `add`.\n-                assert len(layer._inbound_nodes[-1].output_tensors) == 1\n-                set_inputs = True\n-\n-            if set_inputs:\n-                if len(layer._inbound_nodes[-1].output_tensors) != 1:\n-                    raise ValueError('All layers in a Sequential model '\n-                                     'should have a single output tensor. '\n-                                     'For multi-output layers, '\n-                                     'use the functional API.')\n-                self.outputs = [layer._inbound_nodes[-1].output_tensors[0]]\n-                self.inputs = network.get_source_inputs(self.outputs[0])\n-        elif self.outputs:\n-            output_tensor = layer(self.outputs[0])\n-            if isinstance(output_tensor, list):\n-                raise TypeError('All layers in a Sequential model '\n-                                'should have a single output tensor. '\n-                                'For multi-output layers, '\n-                                'use the functional API.')\n-            self.outputs = [output_tensor]\n-        if self.inputs:\n-            self.build()\n-        else:\n-            self._layers.append(layer)\n-\n-    def pop(self):\n-        \"\"\"Removes the last layer in the model.\n-\n-        # Raises\n-            TypeError: if there are no layers in the model.\n-        \"\"\"\n-        if not self.layers:\n-            raise TypeError('There are no layers in the model.')\n-\n-        self._layers.pop()\n-        self.built = False\n-        if not self.layers:\n-            self.outputs = None\n-            self.inputs = None\n-        elif self.outputs:\n-            self.layers[-1]._outbound_nodes = []\n-            self.outputs = [self.layers[-1].output]\n-            self.build()\n-\n-    def build(self, input_shape=None):\n-        if input_shape and not self.inputs:\n-            batch_shape = tuple(input_shape)\n-            dtype = K.floatx()\n-            x = Input(batch_shape=batch_shape,\n-                      dtype=dtype,\n-                      name=self.name + '_input')\n-            self.inputs = [x]\n-            for layer in self._layers:\n-                x = layer(x)\n-            self.outputs = [x]\n-            self._build_input_shape = input_shape\n-\n-        if self.inputs:\n-            self._init_graph_network(self.inputs,\n-                                     self.outputs,\n-                                     name=self.name)\n-            self.built = True\n-\n-    def predict_proba(self, x, batch_size=32, verbose=0):\n-        \"\"\"Generates class probability predictions for the input samples.\n-\n-        The input samples are processed batch by batch.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-            batch_size: integer.\n-            verbose: verbosity mode, 0 or 1.\n-\n-        # Returns\n-            A Numpy array of probability predictions.\n-        \"\"\"\n-        preds = self.predict(x, batch_size, verbose)\n-        if preds.min() < 0. or preds.max() > 1.:\n-            warnings.warn('Network returning invalid probability values. '\n-                          'The last layer might not normalize predictions '\n-                          'into probabilities '\n-                          '(like softmax or sigmoid would).')\n-        return preds\n-\n-    def predict_classes(self, x, batch_size=32, verbose=0):\n-        \"\"\"Generate class predictions for the input samples.\n-\n-        The input samples are processed batch by batch.\n-\n-        # Arguments\n-            x: input data, as a Numpy array or list of Numpy arrays\n-                (if the model has multiple inputs).\n-            batch_size: integer.\n-            verbose: verbosity mode, 0 or 1.\n-\n-        # Returns\n-            A numpy array of class predictions.\n-        \"\"\"\n-        proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n-        if proba.shape[-1] > 1:\n-            return proba.argmax(axis=-1)\n-        else:\n-            return (proba > 0.5).astype('int32')\n-\n-    def get_config(self):\n-        layer_configs = []\n-        for layer in self.layers:\n-            layer_configs.append({\n-                'class_name': layer.__class__.__name__,\n-                'config': layer.get_config()\n-            })\n-        config = {\n-            'name': self.name,\n-            'layers': copy.deepcopy(layer_configs)\n-        }\n-        if self._build_input_shape:\n-            config['build_input_shape'] = self._build_input_shape\n-        return config\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        if 'name' in config:\n-            name = config['name']\n-            build_input_shape = config.get('build_input_shape')\n-            layer_configs = config['layers']\n-        else:  # legacy config file\n-            name = build_input_shape = None\n-            layer_configs = config\n-        model = cls(name=name)\n-        for conf in layer_configs:\n-            layer = layer_module.deserialize(conf,\n-                                             custom_objects=custom_objects)\n-            model.add(layer)\n-        if not model.inputs and build_input_shape:\n-            model.build(build_input_shape)\n-        return model\n+\"\"\"Sequential model class.\"\"\"\n+from tensorflow.keras import Sequential\n\n@@ -1,5 +1,5 @@\n \"\"\"This module is deprecated, but kept around for backwards compatibility.\n \"\"\"\n-from .base_layer import Layer, Node, InputSpec\n+from .base_layer import Layer, InputSpec\n from .input_layer import Input, InputLayer\n from .network import Network, get_source_inputs\n\n@@ -1,1868 +1,2 @@\n-\"\"\"Training-related part of the Keras engine.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import collections\n-import warnings\n-import copy\n-import numpy as np\n-\n-from .network import Network\n-from .base_layer import Layer\n-from . import training_utils\n-from . import training_arrays\n-from . import training_generator\n-from .. import backend as K\n-from .. import optimizers\n-from .. import losses\n-from .. import metrics as metrics_module\n-from ..utils.generic_utils import slice_arrays\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import unpack_singleton\n-from ..utils import losses_utils\n-from ..legacy import interfaces\n-\n-\n-class Model(Network):\n-    \"\"\"The `Model` class adds training & evaluation routines to a `Network`.\n-    \"\"\"\n-\n-    @K.symbolic\n-    def compile(self, optimizer,\n-                loss=None,\n-                metrics=None,\n-                loss_weights=None,\n-                sample_weight_mode=None,\n-                weighted_metrics=None,\n-                target_tensors=None,\n-                **kwargs):\n-        \"\"\"Configures the model for training.\n-\n-        # Arguments\n-            optimizer: String (name of optimizer) or optimizer instance.\n-                See [optimizers](/optimizers).\n-            loss: String (name of objective function) or objective function or\n-                `Loss` instance. See [losses](/losses).\n-                If the model has multiple outputs, you can use a different loss\n-                on each output by passing a dictionary or a list of losses.\n-                The loss value that will be minimized by the model\n-                will then be the sum of all individual losses.\n-            metrics: List of metrics to be evaluated by the model\n-                during training and testing. Typically you will use\n-                `metrics=['accuracy']`. To specify different metrics for different\n-                outputs of a multi-output model, you could also pass a dictionary,\n-                such as\n-                `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n-                You can also pass a list (len = len(outputs)) of lists of metrics\n-                such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n-                `metrics=['accuracy', ['accuracy', 'mse']]`.\n-            loss_weights: Optional list or dictionary specifying scalar\n-                coefficients (Python floats) to weight the loss contributions\n-                of different model outputs.\n-                The loss value that will be minimized by the model\n-                will then be the *weighted sum* of all individual losses,\n-                weighted by the `loss_weights` coefficients.\n-                If a list, it is expected to have a 1:1 mapping\n-                to the model's outputs. If a dict, it is expected to map\n-                output names (strings) to scalar coefficients.\n-            sample_weight_mode: If you need to do timestep-wise\n-                sample weighting (2D weights), set this to `\"temporal\"`.\n-                `None` defaults to sample-wise weights (1D).\n-                If the model has multiple outputs, you can use a different\n-                `sample_weight_mode` on each output by passing a\n-                dictionary or a list of modes.\n-            weighted_metrics: List of metrics to be evaluated and weighted\n-                by sample_weight or class_weight during training and testing.\n-            target_tensors: By default, Keras will create placeholders for the\n-                model's target, which will be fed with the target data during\n-                training. If instead you would like to use your own\n-                target tensors (in turn, Keras will not expect external\n-                Numpy data for these targets at training time), you\n-                can specify them via the `target_tensors` argument. It can be\n-                a single tensor (for a single-output model), a list of tensors,\n-                or a dict mapping output names to target tensors.\n-            **kwargs: When using the Theano/CNTK backends, these arguments\n-                are passed into `K.function`.\n-                When using the TensorFlow backend,\n-                these arguments are passed into `tf.Session.run`.\n-\n-        # Raises\n-            ValueError: In case of invalid arguments for\n-                `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n-        \"\"\"\n-        self.optimizer = optimizers.get(optimizer)\n-        self.loss = loss or {}\n-        self._compile_metrics = metrics or []\n-        self.loss_weights = loss_weights\n-        self.sample_weight_mode = sample_weight_mode\n-        self._compile_weighted_metrics = weighted_metrics\n-\n-        # List of stateful metric functions. Used for resetting metric state during\n-        # training/eval.\n-        self._compile_metric_functions = []\n-        # List of metric wrappers on output losses.\n-        self._output_loss_metrics = None\n-\n-        if not self.built:\n-            # Model is not compilable because\n-            # it does not know its number of inputs\n-            # and outputs, nor their shapes and names.\n-            # We will compile after the first\n-            # time the model gets called on training data.\n-            return\n-        self._is_compiled = True\n-\n-        # Prepare list of loss functions, same size as model outputs.\n-        self.loss_functions = training_utils.prepare_loss_functions(\n-            self.loss, self.output_names)\n-\n-        self._feed_outputs = []\n-        self._feed_output_names = []\n-        self._feed_output_shapes = []\n-        self._feed_loss_fns = []\n-\n-        # if loss function is None, then this output will be skipped during total\n-        # loss calculation and feed targets preparation.\n-        self.skip_target_indices = []\n-        skip_target_weighing_indices = []\n-        for i, loss_function in enumerate(self.loss_functions):\n-            if loss_function is None:\n-                self.skip_target_indices.append(i)\n-                skip_target_weighing_indices.append(i)\n-\n-        # Prepare output masks.\n-        masks = self.compute_mask(self.inputs, mask=None)\n-        if masks is None:\n-            masks = [None for _ in self.outputs]\n-        masks = to_list(masks)\n-\n-        # Prepare list loss weights, same size of model outputs.\n-        self.loss_weights_list = training_utils.prepare_loss_weights(\n-            self.output_names, loss_weights)\n-\n-        # Prepare targets of model.\n-        self.targets = []\n-        self._feed_targets = []\n-        if target_tensors is not None:\n-            if isinstance(target_tensors, list):\n-                if len(target_tensors) != len(self.outputs):\n-                    raise ValueError(\n-                        'When passing a list as `target_tensors`, '\n-                        'it should have one entry per model output. '\n-                        'The model has ' + str(len(self.outputs)) +\n-                        ' outputs, but you passed target_tensors=' +\n-                        str(target_tensors))\n-            elif isinstance(target_tensors, dict):\n-                for name in target_tensors:\n-                    if name not in self.output_names:\n-                        raise ValueError('Unknown entry in `target_tensors` '\n-                                         'dictionary: \"' + name + '\". '\n-                                         'Only expected the following keys: ' +\n-                                         str(self.output_names))\n-                tmp_target_tensors = []\n-                for name in self.output_names:\n-                    tmp_target_tensors.append(target_tensors.get(name, None))\n-                target_tensors = tmp_target_tensors\n-            elif K.is_tensor(target_tensors):\n-                if len(self.outputs) != 1:\n-                    raise ValueError('The model has ' + str(len(self.outputs)) +\n-                                     ' outputs, but you passed a single tensor as '\n-                                     '`target_tensors`. Expected a list or a dict '\n-                                     'of tensors.')\n-                target_tensors = [target_tensors]\n-            else:\n-                raise TypeError('Expected `target_tensors` to be a tensor, '\n-                                'a list of tensors, or dict of tensors, but got:',\n-                                target_tensors)\n-\n-        for i in range(len(self.outputs)):\n-            if i in self.skip_target_indices:\n-                self.targets.append(None)\n-            else:\n-                shape = K.int_shape(self.outputs[i])\n-                name = self.output_names[i]\n-                if target_tensors is not None:\n-                    target = target_tensors[i]\n-                else:\n-                    target = None\n-                if target is None or K.is_placeholder(target):\n-                    if target is None:\n-                        target = K.placeholder(\n-                            ndim=len(shape),\n-                            name=name + '_target',\n-                            sparse=K.is_sparse(self.outputs[i]),\n-                            dtype=K.dtype(self.outputs[i]))\n-                    self._feed_targets.append(target)\n-                    self._feed_outputs.append(self.outputs[i])\n-                    self._feed_output_names.append(name)\n-                    self._feed_output_shapes.append(shape)\n-                    self._feed_loss_fns.append(self.loss_functions[i])\n-                else:\n-                    skip_target_weighing_indices.append(i)\n-                self.targets.append(target)\n-\n-        # Prepare sample weights.\n-        self._set_sample_weight_attributes(\n-            sample_weight_mode, skip_target_weighing_indices)\n-\n-        # Save all metric attributes per output of the model.\n-        self._cache_output_metric_attributes(metrics, weighted_metrics)\n-\n-        # Set metric attributes on model.\n-        self._set_metric_attributes()\n-\n-        # Invoke metric functions (unweighted) for all the outputs.\n-        self._handle_metrics(\n-            self.outputs,\n-            targets=self.targets,\n-            skip_target_masks=[l is None for l in self.loss_functions],\n-            sample_weights=self.sample_weights,\n-            masks=masks)\n-\n-        # Compute total loss.\n-        # Used to keep track of the total loss value (stateless).\n-        # eg., total_loss = loss_weight_1 * output_1_loss_fn(...) +\n-        #                   loss_weight_2 * output_2_loss_fn(...) +\n-        #                   layer losses.\n-        self.total_loss = self._prepare_total_loss(masks)\n-\n-        # Functions for train, test and predict will\n-        # be compiled lazily when required.\n-        # This saves time when the user is not using all functions.\n-        self._function_kwargs = kwargs\n-\n-        self.train_function = None\n-        self.test_function = None\n-        self.predict_function = None\n-\n-        # Collected trainable weights, sorted in topological order.\n-        trainable_weights = self.trainable_weights\n-        self._collected_trainable_weights = trainable_weights\n-\n-    @property\n-    def metrics(self):\n-        \"\"\"Returns the model's metrics added using `compile`, `add_metric` APIs.\"\"\"\n-        metrics = []\n-        if self._is_compiled:\n-            metrics += self._compile_metric_functions\n-        metrics.extend(self._metrics)\n-        metrics.extend(_get_metrics_from_layers(self._layers))\n-        return metrics\n-\n-    @property\n-    def metrics_names(self):\n-        \"\"\"Returns the model's display labels for all outputs.\"\"\"\n-        metrics_names = ['loss']\n-        if self._is_compiled:\n-            # Add output loss metric names to the metric names list.\n-            if len(self.outputs) > 1:\n-                metrics_names.extend([\n-                    self.output_names[i] + '_loss'\n-                    for i in range(len(self.outputs))\n-                    if i not in self.skip_target_indices\n-                ])\n-\n-            # Add compile metrics/weighted metrics' names to the metric names list.\n-            metrics_names.extend([m.name for m in self._compile_metric_functions])\n-\n-        # Add metric names from layers.\n-        for layer in self.layers:\n-            metrics_names += [m.name for m in layer._metrics]\n-        metrics_names += [m.name for m in self._metrics]\n-        return metrics_names\n-\n-    def reset_metrics(self):\n-        \"\"\"Resets the state of metrics.\"\"\"\n-        metrics = self._get_training_eval_metrics()\n-        for m in metrics:\n-            m.reset_states()\n-\n-    def _check_trainable_weights_consistency(self):\n-        \"\"\"Check trainable weights count consistency.\n-\n-        This will raise a warning if `trainable_weights` and\n-        `_collected_trainable_weights` are inconsistent (i.e. have different\n-        number of parameters).\n-        Inconsistency will typically arise when one modifies `model.trainable`\n-        without calling `model.compile` again.\n-        \"\"\"\n-        if not hasattr(self, '_collected_trainable_weights'):\n-            return\n-\n-        if (len(self.trainable_weights) !=\n-                len(self._collected_trainable_weights)):\n-            warnings.warn(UserWarning(\n-                'Discrepancy between trainable weights and collected trainable'\n-                ' weights, did you set `model.trainable` without calling'\n-                ' `model.compile` after ?'))\n-\n-    def _make_train_function(self):\n-        if not hasattr(self, 'train_function'):\n-            raise RuntimeError('You must compile your model before using it.')\n-        self._check_trainable_weights_consistency()\n-        if self.train_function is None:\n-            inputs = (self._feed_inputs +\n-                      self._feed_targets +\n-                      self._feed_sample_weights)\n-            if self._uses_dynamic_learning_phase():\n-                inputs += [K.learning_phase()]\n-\n-            with K.name_scope('training'):\n-                with K.name_scope(self.optimizer.__class__.__name__):\n-                    training_updates = self.optimizer.get_updates(\n-                        params=self._collected_trainable_weights,\n-                        loss=self.total_loss)\n-                updates = self.updates + training_updates\n-\n-                metrics = self._get_training_eval_metrics()\n-                metrics_tensors = [\n-                    m._call_result for m in metrics if hasattr(m, '_call_result')\n-                ]\n-                metrics_updates = []\n-                for m in metrics:\n-                    metrics_updates.extend(m.updates)\n-\n-                # Gets loss and metrics. Updates weights at each call.\n-                self.train_function = K.function(\n-                    inputs,\n-                    [self.total_loss] + metrics_tensors,\n-                    updates=updates + metrics_updates,\n-                    name='train_function',\n-                    **self._function_kwargs)\n-\n-    def _make_test_function(self):\n-        if not hasattr(self, 'test_function'):\n-            raise RuntimeError('You must compile your model before using it.')\n-        if self.test_function is None:\n-            inputs = (self._feed_inputs +\n-                      self._feed_targets +\n-                      self._feed_sample_weights)\n-            if self._uses_dynamic_learning_phase():\n-                inputs += [K.learning_phase()]\n-\n-            metrics = self._get_training_eval_metrics()\n-            metrics_tensors = [\n-                m._call_result for m in metrics if hasattr(m, '_call_result')\n-            ]\n-\n-            metrics_updates = []\n-            for m in metrics:\n-                metrics_updates.extend(m.updates)\n-\n-            # Return loss and metrics, no gradient updates.\n-            # Does update the network states.\n-            self.test_function = K.function(\n-                inputs,\n-                [self.total_loss] + metrics_tensors,\n-                updates=self.state_updates + metrics_updates,\n-                name='test_function',\n-                **self._function_kwargs)\n-\n-    def _make_predict_function(self):\n-        if not hasattr(self, 'predict_function'):\n-            self.predict_function = None\n-        if self.predict_function is None:\n-            if self._uses_dynamic_learning_phase():\n-                inputs = self._feed_inputs + [K.learning_phase()]\n-            else:\n-                inputs = self._feed_inputs\n-            # Gets network outputs. Does not update weights.\n-            # Does update the network states.\n-            kwargs = getattr(self, '_function_kwargs', {})\n-            self.predict_function = K.function(inputs,\n-                                               self.outputs,\n-                                               updates=self.state_updates,\n-                                               name='predict_function',\n-                                               **kwargs)\n-\n-    def _uses_dynamic_learning_phase(self):\n-        return (self.uses_learning_phase and\n-                not isinstance(K.learning_phase(), int))\n-\n-    def _set_inputs(self, inputs, outputs=None, training=None):\n-        \"\"\"Set model's input and output specs based on the input data received.\n-\n-        This is to be used for Model subclasses, which do not know at instantiation\n-        time what their inputs look like.\n-\n-        # Arguments\n-            inputs: Single array, or list of arrays. The arrays could be\n-                placeholders, Numpy arrays, or data tensors.\n-                - if placeholders: the model is built on top of these\n-                  placeholders, and we expect Numpy data to be fed for them\n-                  when calling `fit`/etc.\n-                - if Numpy data: we create placeholders matching the shape of\n-                  the Numpy arrays. We expect Numpy data to be fed for these\n-                  placeholders when calling `fit`/etc.\n-                - if data tensors: the model is built on top of these tensors.\n-                  We do not expect any Numpy data to be provided when calling\n-                  `fit`/etc.\n-            outputs: Optional output tensors (if already computed by running\n-                the model).\n-            training: Boolean or None. Only relevant in symbolic mode.\n-                Specifies whether to build the model's graph in inference\n-                mode (False), training mode (True), or using the Keras\n-                learning phase (None).\n-        \"\"\"\n-        if self.__class__.__name__ == 'Sequential':\n-            # Note: we can't test whether the model\n-            # is `Sequential` via `isinstance`\n-            # since `Sequential` depends on `Model`.\n-            if isinstance(inputs, list):\n-                assert len(inputs) == 1\n-                inputs = inputs[0]\n-            self.build(input_shape=(None,) + inputs.shape[1:])\n-            return\n-\n-        if self.inputs:\n-            raise ValueError('Model inputs are already set.')\n-\n-        # On-the-fly setting of symbolic model inputs\n-        # (either by using the tensor provided,\n-        # or by creating a placeholder if Numpy data was provided).\n-        self.inputs = []\n-        self.input_names = []\n-        self._feed_inputs = []\n-        self._feed_input_names = []\n-        self._feed_input_shapes = []\n-        inputs = to_list(inputs, allow_tuple=True)\n-\n-        for i, v in enumerate(inputs):\n-            name = 'input_%d' % (i + 1)\n-            self.input_names.append(name)\n-            if isinstance(v, list):\n-                v = np.asarray(v)\n-                if v.ndim == 1:\n-                    v = np.expand_dims(v, 1)\n-            if isinstance(v, (np.ndarray)):\n-                # We fix the placeholder shape except the batch size.\n-                # This is suboptimal, but it is the best we can do with the info\n-                # we have. The user should call `model._set_inputs(placeholders)`\n-                # to specify custom placeholders if the need arises.\n-                shape = (None,) + v.shape[1:]\n-                placeholder = K.placeholder(shape=shape, name=name)\n-                self.inputs.append(placeholder)\n-                self._feed_inputs.append(placeholder)\n-                self._feed_input_names.append(name)\n-                self._feed_input_shapes.append(shape)\n-            else:\n-                # Assumed tensor - TODO(fchollet) additional type check?\n-                self.inputs.append(v)\n-                if K.is_placeholder(v):\n-                    self._feed_inputs.append(v)\n-                    self._feed_input_names.append(name)\n-                    self._feed_input_shapes.append(K.int_shape(v))\n-\n-        if outputs is None:\n-            # Obtain symbolic outputs by calling the model.\n-            if self._expects_training_arg:\n-                outputs = self.call(unpack_singleton(self.inputs), training=training)\n-            else:\n-                outputs = self.call(unpack_singleton(self.inputs))\n-        outputs = to_list(outputs, allow_tuple=True)\n-        self.outputs = outputs\n-        self.output_names = [\n-            'output_%d' % (i + 1) for i in range(len(self.outputs))]\n-        self.built = True\n-\n-    def _standardize_user_data(self, x,\n-                               y=None,\n-                               sample_weight=None,\n-                               class_weight=None,\n-                               check_array_lengths=True,\n-                               batch_size=None):\n-        all_inputs = []\n-        if not self.built:\n-            # We need to use `x` to set the model inputs.\n-            # We type-check that `x` and `y` are either single arrays\n-            # or lists of arrays.\n-            if isinstance(x, (list, tuple)):\n-                if not all(isinstance(v, np.ndarray) or\n-                           K.is_tensor(v) for v in x):\n-                    raise ValueError('Please provide as model inputs '\n-                                     'either a single '\n-                                     'array or a list of arrays. '\n-                                     'You passed: x=' + str(x))\n-                all_inputs += list(x)\n-            elif isinstance(x, dict):\n-                raise ValueError('Please do not pass a dictionary '\n-                                 'as model inputs.')\n-            else:\n-                if not isinstance(x, np.ndarray) and not K.is_tensor(x):\n-                    raise ValueError('Please provide as model inputs '\n-                                     'either a single '\n-                                     'array or a list of arrays. '\n-                                     'You passed: x=' + str(x))\n-                all_inputs.append(x)\n-\n-            # Build the model using the retrieved inputs (value or symbolic).\n-            # If values, then in symbolic-mode placeholders will be created\n-            # to match the value shapes.\n-            if not self.inputs:\n-                self._set_inputs(x)\n-\n-        if y is not None:\n-            if not self.optimizer:\n-                raise RuntimeError('You must compile a model before '\n-                                   'training/testing. '\n-                                   'Use `model.compile(optimizer, loss)`.')\n-            if not self._is_compiled:\n-                # On-the-fly compilation of the model.\n-                # We need to use `y` to set the model targets.\n-                if isinstance(y, (list, tuple)):\n-                    if not all(isinstance(v, np.ndarray) or\n-                               K.is_tensor(v) for v in y):\n-                        raise ValueError('Please provide as model targets '\n-                                         'either a single '\n-                                         'array or a list of arrays. '\n-                                         'You passed: y=' + str(y))\n-                elif isinstance(y, dict):\n-                    raise ValueError('Please do not pass a dictionary '\n-                                     'as model targets.')\n-                else:\n-                    if not isinstance(y, np.ndarray) and not K.is_tensor(y):\n-                        raise ValueError('Please provide as model targets '\n-                                         'either a single '\n-                                         'array or a list of arrays. '\n-                                         'You passed: y=' + str(y))\n-                # Typecheck that all inputs are *either* value *or* symbolic.\n-                if y is not None:\n-                    all_inputs += to_list(y, allow_tuple=True)\n-                if any(K.is_tensor(v) for v in all_inputs):\n-                    if not all(K.is_tensor(v) for v in all_inputs):\n-                        raise ValueError('Do not pass inputs that mix Numpy '\n-                                         'arrays and symbolic tensors. '\n-                                         'You passed: x=' + str(x) +\n-                                         '; y=' + str(y))\n-\n-                # Handle target tensors if any passed.\n-                y = to_list(y, allow_tuple=True)\n-                target_tensors = [v for v in y if K.is_tensor(v)]\n-                if not target_tensors:\n-                    target_tensors = None\n-                self.compile(optimizer=self.optimizer,\n-                             loss=self.loss,\n-                             metrics=self._compile_metrics,\n-                             weighted_metrics=self._compile_weighted_metrics,\n-                             loss_weights=self.loss_weights,\n-                             target_tensors=target_tensors)\n-\n-        # If `x` and `y` were all symbolic,\n-        # then the model should not be fed any inputs and targets.\n-        # Note: in this case, `any` and `all` are equivalent since we disallow\n-        # mixed symbolic/value inputs.\n-        if any(K.is_tensor(v) for v in all_inputs):\n-            return [], [], []\n-\n-        # What follows is input validation and standardization to list format,\n-        # in the case where all inputs are value arrays.\n-\n-        if not self._is_graph_network:\n-            # Case: symbolic-mode subclassed network.\n-            # Do not do shape validation.\n-            feed_input_names = self._feed_input_names\n-            feed_input_shapes = None\n-        else:\n-            # Case: symbolic-mode graph network.\n-            # In this case, we run extensive shape validation checks.\n-            feed_input_names = self._feed_input_names\n-            feed_input_shapes = self._feed_input_shapes\n-\n-        # Standardize the inputs.\n-        x = training_utils.standardize_input_data(\n-            x,\n-            feed_input_names,\n-            feed_input_shapes,\n-            check_batch_axis=False,  # Don't enforce the batch size.\n-            exception_prefix='input')\n-\n-        if y is not None:\n-            if not self._is_graph_network:\n-                feed_output_names = self._feed_output_names\n-                feed_output_shapes = None\n-                # Sample weighting not supported in this case.\n-                # TODO: consider supporting it.\n-                feed_sample_weight_modes = [None for _ in self.outputs]\n-            else:\n-                feed_output_names = self._feed_output_names\n-                feed_sample_weight_modes = self._feed_sample_weight_modes\n-                feed_output_shapes = []\n-                for output_shape, loss_fn in zip(self._feed_output_shapes,\n-                                                 self._feed_loss_fns):\n-                    if ((isinstance(loss_fn, losses.LossFunctionWrapper) and\n-                         loss_fn.fn == losses.sparse_categorical_crossentropy)) or (\n-                            isinstance(\n-                                loss_fn, losses.SparseCategoricalCrossentropy)):\n-                        if K.image_data_format() == 'channels_first' and len(\n-                                output_shape) in [4, 5]:\n-                            feed_output_shapes.append(\n-                                (output_shape[0], 1) + output_shape[2:])\n-                        else:\n-                            feed_output_shapes.append(output_shape[:-1] + (1,))\n-                    elif (not isinstance(loss_fn, losses.Loss) or\n-                            (isinstance(loss_fn, losses.LossFunctionWrapper) and\n-                             (getattr(losses, loss_fn.fn.__name__, None) is None))):\n-                        # If the given loss is not an instance of the `Loss` class\n-                        # (custom class) or if the loss function that is wrapped is\n-                        # not in the `losses` module, then it is a user-defined loss\n-                        # and we make no assumptions about it.\n-                        feed_output_shapes.append(None)\n-                    else:\n-                        feed_output_shapes.append(output_shape)\n-\n-            # Standardize the outputs.\n-            y = training_utils.standardize_input_data(\n-                y,\n-                feed_output_names,\n-                feed_output_shapes,\n-                check_batch_axis=False,  # Don't enforce the batch size.\n-                exception_prefix='target')\n-\n-            # Generate sample-wise weight values given the `sample_weight` and\n-            # `class_weight` arguments.\n-            sample_weights = training_utils.standardize_sample_weights(\n-                sample_weight, feed_output_names)\n-            class_weights = training_utils.standardize_class_weights(\n-                class_weight, feed_output_names)\n-            sample_weights = [\n-                training_utils.standardize_weights(ref, sw, cw, mode)\n-                for (ref, sw, cw, mode) in\n-                zip(y, sample_weights, class_weights,\n-                    feed_sample_weight_modes)\n-            ]\n-            # Check that all arrays have the same length.\n-            if check_array_lengths:\n-                training_utils.check_array_length_consistency(x, y, sample_weights)\n-            if self._is_graph_network:\n-                # Additional checks to avoid users mistakenly\n-                # using improper loss fns.\n-                training_utils.check_loss_and_target_compatibility(\n-                    y, self._feed_loss_fns, feed_output_shapes)\n-        else:\n-            y = []\n-            sample_weights = []\n-\n-        if self.stateful and batch_size:\n-            # Check that for stateful networks, number of samples is a multiple\n-            # of the static batch size.\n-            if x[0].shape[0] % batch_size != 0:\n-                raise ValueError('In a stateful network, '\n-                                 'you should only pass inputs with '\n-                                 'a number of samples that can be '\n-                                 'divided by the batch size. Found: ' +\n-                                 str(x[0].shape[0]) + ' samples')\n-        return x, y, sample_weights\n-\n-    def _prepare_total_loss(self, masks=None):\n-        \"\"\"Computes total loss from loss functions.\n-\n-        # Arguments\n-            skip_target_indices: A list of indices of model outputs where loss\n-                function is None.\n-            masks: List of mask values corresponding to each model output.\n-\n-        # Returns\n-            A list of loss weights of python floats.\n-        \"\"\"\n-        total_loss = None\n-        with K.name_scope('loss'):\n-            zipped_inputs = zip(self.targets, self.outputs, self.loss_functions,\n-                                self.sample_weights, masks, self.loss_weights_list)\n-            for i, (y_true, y_pred, loss_fn, sample_weight, mask,\n-                    loss_weight) in enumerate(zipped_inputs):\n-                if i in self.skip_target_indices:\n-                    continue\n-                loss_name = self.output_names[i] + '_loss'\n-                with K.name_scope(loss_name):\n-                    if mask is not None:\n-                        mask = K.cast(mask, y_pred.dtype)\n-                        # Update weights with mask.\n-                        if sample_weight is None:\n-                            sample_weight = mask\n-                        else:\n-                            # Update dimensions of weights to match with mask.\n-                            mask, _, sample_weight = (\n-                                losses_utils.squeeze_or_expand_dimensions(\n-                                    mask, None, sample_weight))\n-                            sample_weight *= mask\n-\n-                    output_loss = loss_fn(\n-                        y_true, y_pred, sample_weight=sample_weight)\n-\n-                if len(self.outputs) > 1:\n-                    update_ops = self._output_loss_metrics[i].update_state(\n-                        output_loss)\n-                    with K.control_dependencies(update_ops):  # For TF\n-                        self._output_loss_metrics[i].result()\n-                if total_loss is None:\n-                    total_loss = loss_weight * output_loss\n-                else:\n-                    total_loss += loss_weight * output_loss\n-\n-            if total_loss is None:\n-                if not self.losses:\n-                    raise ValueError('The model cannot be compiled '\n-                                     'because it has no loss to optimize.')\n-                else:\n-                    total_loss = 0.\n-\n-            # Add regularization penalties and other layer-specific losses.\n-            for loss_tensor in self.losses:\n-                total_loss += loss_tensor\n-\n-        return K.mean(total_loss)\n-\n-    def _get_training_eval_metrics(self):\n-        \"\"\"Returns all the metrics that are to be reported.\n-\n-        This includes the output loss metrics, compile metrics/weighted metrics.\n-        \"\"\"\n-        metrics = []\n-        if getattr(self, '_output_loss_metrics', None) is not None:\n-            metrics.extend(self._output_loss_metrics)\n-        if hasattr(self, 'metrics'):\n-            metrics.extend(self.metrics)\n-        return metrics\n-\n-    def _cache_output_metric_attributes(self, metrics, weighted_metrics):\n-        \"\"\"Caches metric name and function attributes for every model output.\"\"\"\n-        output_shapes = []\n-        for output in self.outputs:\n-            if output is None:\n-                output_shapes.append(None)\n-            else:\n-                output_shapes.append(list(output.shape))\n-        self._per_output_metrics = training_utils.collect_per_output_metric_info(\n-            metrics, self.output_names, output_shapes, self.loss_functions)\n-        self._per_output_weighted_metrics = (\n-            training_utils.collect_per_output_metric_info(\n-                weighted_metrics,\n-                self.output_names,\n-                output_shapes,\n-                self.loss_functions,\n-                is_weighted=True))\n-\n-    def _add_unique_metric_name(self, metric_name, output_index):\n-        \"\"\"Makes the metric name unique and adds it to the model's metric name list.\n-\n-        If there are multiple outputs for which the metrics are calculated, the\n-        metric names have to be made unique by appending an integer.\n-\n-        # Arguments\n-            metric_name: Metric name that corresponds to the metric specified by the\n-                user. For example: 'acc'.\n-            output_index: The index of the model output for which the metric name is\n-                being added.\n-\n-        # Returns\n-            string, name of the model's unique metric name\n-        \"\"\"\n-        if len(self.output_names) > 1:\n-            metric_name = '%s_%s' % (self.output_names[output_index], metric_name)\n-\n-        j = 1\n-        base_metric_name = metric_name\n-        while metric_name in self.metrics_names:\n-            metric_name = '%s_%d' % (base_metric_name, j)\n-            j += 1\n-        return metric_name\n-\n-    def _set_per_output_metric_attributes(self, metrics_dict, output_index):\n-        \"\"\"Sets the metric attributes on the model for the given output.\n-\n-        # Arguments\n-            metrics_dict: A dict with metric names as keys and metric fns as values.\n-            output_index: The index of the model output for which the metric\n-                attributes are added.\n-\n-        # Returns\n-            Metrics dict updated with unique metric names as keys.\n-        \"\"\"\n-        updated_metrics_dict = collections.OrderedDict()\n-        for metric_name, metric_fn in metrics_dict.items():\n-            metric_name = self._add_unique_metric_name(metric_name, output_index)\n-\n-            # Update the name on the metric class to be the unique generated name.\n-            metric_fn.name = metric_name\n-            updated_metrics_dict[metric_name] = metric_fn\n-            # Keep track of metric function.\n-            self._compile_metric_functions.append(metric_fn)\n-        return updated_metrics_dict\n-\n-    def _set_metric_attributes(self):\n-        \"\"\"Sets the metric attributes on the model for all the model outputs.\"\"\"\n-        updated_per_output_metrics = []\n-        updated_per_output_weighted_metrics = []\n-        for i in range(len(self.outputs)):\n-            if i in self.skip_target_indices:\n-                updated_per_output_metrics.append(self._per_output_metrics[i])\n-                updated_per_output_weighted_metrics.append(\n-                    self._per_output_weighted_metrics[i])\n-                continue\n-            updated_per_output_metrics.append(\n-                self._set_per_output_metric_attributes(\n-                    self._per_output_metrics[i], i))\n-            updated_per_output_weighted_metrics.append(\n-                self._set_per_output_metric_attributes(\n-                    self._per_output_weighted_metrics[i], i))\n-\n-        # Create a metric wrapper for each output loss. This computes mean of an\n-        # output loss across mini-batches (irrespective of how we reduce within a\n-        # batch).\n-        if len(self.outputs) > 1:\n-            self._output_loss_metrics = [\n-                metrics_module.Mean(name=self.output_names[i] + '_loss')\n-                for i in range(len(self.loss_functions))\n-            ]\n-\n-        self._per_output_metrics = updated_per_output_metrics\n-        self._per_output_weighted_metrics = updated_per_output_weighted_metrics\n-\n-    def _handle_per_output_metrics(self,\n-                                   metrics_dict,\n-                                   y_true,\n-                                   y_pred,\n-                                   mask,\n-                                   weights=None):\n-        \"\"\"Calls metric functions for a single output.\n-\n-        # Arguments\n-            metrics_dict: A dict with metric names as keys and metric fns as values.\n-            y_true: Target output.\n-            y_pred: Predicted output.\n-            mask: Computed mask value for the current output.\n-            weights: Weights to be applied on the current output.\n-        \"\"\"\n-\n-        for metric_name, metric_fn in metrics_dict.items():\n-            with K.name_scope(metric_name):\n-                training_utils.call_metric_function(\n-                    metric_fn, y_true, y_pred, weights=weights, mask=mask)\n-\n-    def _handle_metrics(self,\n-                        outputs,\n-                        targets=None,\n-                        skip_target_masks=None,\n-                        sample_weights=None,\n-                        masks=None):\n-        \"\"\"Handles calling metric functions.\n-\n-        # Arguments\n-            outputs: List of outputs (predictions).\n-            targets: List of targets.\n-            skip_target_masks: Optional. List of boolean for whether the\n-                corresponding target should be ignored or not.\n-            sample_weights: Optional list of sample weight arrays.\n-            masks: List of computed output mask values.\n-        \"\"\"\n-        skip_target_masks = skip_target_masks or [False] * len(outputs)\n-        with K.name_scope('metrics'):\n-            # Invoke all metrics added using `compile`.\n-            for i in range(len(outputs)):\n-                if skip_target_masks[i]:\n-                    continue\n-                output = outputs[i] if outputs else None\n-                target = targets[i] if targets else None\n-                output_mask = masks[i] if masks else None\n-\n-                self._handle_per_output_metrics(\n-                    self._per_output_metrics[i], target, output, output_mask)\n-                self._handle_per_output_metrics(\n-                    self._per_output_weighted_metrics[i],\n-                    target,\n-                    output,\n-                    output_mask,\n-                    weights=sample_weights[i] if sample_weights else None)\n-\n-    def _get_callback_model(self):\n-        \"\"\"Returns the Callback Model for this Model.\"\"\"\n-        if hasattr(self, 'callback_model') and self.callback_model:\n-            return self.callback_model\n-        return self\n-\n-    def _validate_or_infer_batch_size(self, batch_size, steps, x):\n-        \"\"\"Validates that the `batch_size` provided is consistent with InputLayer.\n-\n-        It's possible that the user specified a static batch size in their\n-        InputLayer. If so, this method checks the provided `batch_size` and `x`\n-        arguments are consistent with this static batch size. Also, if\n-        `batch_size` is `None`, this method will attempt to infer the batch size\n-        from the static batch size of the InputLayer. Lastly, ValueError will be\n-        raised if `x` is a generator or `Sequence` instance and `batch_size` is\n-        specified as we expect users to provide batched datasets.\n-\n-        # Arguments\n-            batch_size: The batch_size provided as an argument to\n-                fit/evaluate/predict.\n-            steps: The steps provided as an argument to fit/evaluate/predict.\n-            x: The data passed as `x` to fit/evaluate/predict.\n-\n-        # Returns\n-            The validated batch_size, auto-inferred from the first layer if\n-            not provided.\n-\n-        # Raises\n-            ValueError: if a batch size is specified and a generator/Sequence\n-                is passed, or if the specified batch size does not match the\n-                exepected size defined in the Input Layer.\n-        \"\"\"\n-        if batch_size is not None and training_utils.is_generator_or_sequence(x):\n-            raise ValueError('The `batch_size` argument must not be specified when'\n-                             ' using a generator or Sequence as an input.')\n-\n-        layers = super(Model, self).layers  # Avoids the override in Sequential.\n-        if layers:\n-            first_layer = layers[0]\n-            static_batch_size = training_utils.get_static_batch_size(first_layer)\n-            if static_batch_size is not None:\n-\n-                # Check `batch_size` argument is consistent with InputLayer.\n-                if batch_size is not None and batch_size != static_batch_size:\n-                    raise ValueError('The `batch_size` argument value {} is '\n-                                     'incompatible with the specified batch '\n-                                     'size of your Input Layer: {}'\n-                                     .format(batch_size, static_batch_size))\n-\n-                # Set inferred batch size from the InputLayer.\n-                if steps is None:\n-                    batch_size = static_batch_size\n-\n-        if batch_size is None and steps is None:\n-            # Backwards compatibility\n-            batch_size = 32\n-        return batch_size\n-\n-    def _set_sample_weight_attributes(self, sample_weight_mode,\n-                                      skip_target_weighing_indices):\n-        \"\"\"Sets sample weight related attributes on the model.\"\"\"\n-        sample_weights, sample_weight_modes = training_utils.prepare_sample_weights(\n-            self.output_names, sample_weight_mode, skip_target_weighing_indices)\n-        self.sample_weights = sample_weights\n-        self.sample_weight_modes = sample_weight_modes\n-        self._feed_sample_weight_modes = [\n-            sample_weight_modes[i]\n-            for i in range(len(self.outputs))\n-            if i not in skip_target_weighing_indices\n-        ]\n-        self._feed_sample_weights = [\n-            sample_weights[i]\n-            for i in range(len(sample_weights))\n-            if i not in skip_target_weighing_indices\n-        ]\n-\n-    def fit(self,\n-            x=None,\n-            y=None,\n-            batch_size=None,\n-            epochs=1,\n-            verbose=1,\n-            callbacks=None,\n-            validation_split=0.,\n-            validation_data=None,\n-            shuffle=True,\n-            class_weight=None,\n-            sample_weight=None,\n-            initial_epoch=0,\n-            steps_per_epoch=None,\n-            validation_steps=None,\n-            validation_freq=1,\n-            max_queue_size=10,\n-            workers=1,\n-            use_multiprocessing=False,\n-            **kwargs):\n-        \"\"\"Trains the model for a fixed number of epochs (iterations on a dataset).\n-\n-        # Arguments\n-            x: Input data. It could be:\n-                - A Numpy array (or array-like), or a list of arrays\n-                  (in case the model has multiple inputs).\n-                - A dict mapping input names to the corresponding\n-                  array/tensors, if the model has named inputs.\n-                - A generator or `keras.utils.Sequence` returning\n-                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n-                - None (default) if feeding from framework-native\n-                  tensors (e.g. TensorFlow data tensors).\n-            y: Target data. Like the input data `x`,\n-                it could be either Numpy array(s), framework-native tensor(s),\n-                list of Numpy arrays (if the model has multiple outputs) or\n-                None (default) if feeding from framework-native tensors\n-                (e.g. TensorFlow data tensors).\n-                If output layers in the model are named, you can also pass a\n-                dictionary mapping output names to Numpy arrays.\n-                If `x` is a generator, or `keras.utils.Sequence` instance,\n-                `y` should not be specified (since targets will be obtained\n-                from `x`).\n-            batch_size: Integer or `None`.\n-                Number of samples per gradient update.\n-                If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of symbolic tensors, generators, or `Sequence` instances\n-                (since they generate batches).\n-            epochs: Integer. Number of epochs to train the model.\n-                An epoch is an iteration over the entire `x` and `y`\n-                data provided.\n-                Note that in conjunction with `initial_epoch`,\n-                `epochs` is to be understood as \"final epoch\".\n-                The model is not trained for a number of iterations\n-                given by `epochs`, but merely until the epoch\n-                of index `epochs` is reached.\n-            verbose: Integer. 0, 1, or 2. Verbosity mode.\n-                0 = silent, 1 = progress bar, 2 = one line per epoch.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during training and validation\n-                (if ).\n-                See [callbacks](/callbacks).\n-            validation_split: Float between 0 and 1.\n-                Fraction of the training data to be used as validation data.\n-                The model will set apart this fraction of the training data,\n-                will not train on it, and will evaluate\n-                the loss and any model metrics\n-                on this data at the end of each epoch.\n-                The validation data is selected from the last samples\n-                in the `x` and `y` data provided, before shuffling.\n-                This argument is not supported when `x` is a generator or\n-                `Sequence` instance.\n-            validation_data: Data on which to evaluate\n-                the loss and any model metrics at the end of each epoch.\n-                The model will not be trained on this data.\n-                `validation_data` will override `validation_split`.\n-                `validation_data` could be:\n-                    - tuple `(x_val, y_val)` of Numpy arrays or tensors\n-                    - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n-                    - dataset or a dataset iterator\n-                For the first two cases, `batch_size` must be provided.\n-                For the last case, `validation_steps` must be provided.\n-            shuffle: Boolean (whether to shuffle the training data\n-                before each epoch) or str (for 'batch').\n-                'batch' is a special option for dealing with the\n-                limitations of HDF5 data; it shuffles in batch-sized chunks.\n-                Has no effect when `steps_per_epoch` is not `None`.\n-            class_weight: Optional dictionary mapping class indices (integers)\n-                to a weight (float) value, used for weighting the loss function\n-                (during training only).\n-                This can be useful to tell the model to\n-                \"pay more attention\" to samples from\n-                an under-represented class.\n-            sample_weight: Optional Numpy array of weights for\n-                the training samples, used for weighting the loss function\n-                (during training only). You can either pass a flat (1D)\n-                Numpy array with the same length as the input samples\n-                (1:1 mapping between weights and samples),\n-                or in the case of temporal data,\n-                you can pass a 2D array with shape\n-                `(samples, sequence_length)`,\n-                to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify\n-                `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n-                is not supported when `x` generator, or `Sequence` instance,\n-                instead provide the sample_weights as the third element of `x`.\n-            initial_epoch: Integer.\n-                Epoch at which to start training\n-                (useful for resuming a previous training run).\n-            steps_per_epoch: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                before declaring one epoch finished and starting the\n-                next epoch. When training with input tensors such as\n-                TensorFlow data tensors, the default `None` is equal to\n-                the number of samples in your dataset divided by\n-                the batch size, or 1 if that cannot be determined.\n-            validation_steps: Only relevant if `steps_per_epoch`\n-                is specified. Total number of steps (batches of samples)\n-                to validate before stopping.\n-            validation_steps: Only relevant if `validation_data` is provided\n-                and is a generator. Total number of steps (batches of samples)\n-                to draw before stopping when performing validation at the end\n-                of every epoch.\n-            validation_freq: Only relevant if validation data is provided. Integer\n-                or list/tuple/set. If an integer, specifies how many training\n-                epochs to run before a new validation run is performed, e.g.\n-                `validation_freq=2` runs validation every 2 epochs. If a list,\n-                tuple, or set, specifies the epochs on which to run validation,\n-                e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n-                of the 1st, 2nd, and 10th epochs.\n-            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n-                input only. Maximum size for the generator queue.\n-                If unspecified, `max_queue_size` will default to 10.\n-            workers: Integer. Used for generator or `keras.utils.Sequence` input\n-                only. Maximum number of processes to spin up\n-                when using process-based threading. If unspecified, `workers`\n-                will default to 1. If 0, will execute the generator on the main\n-                thread.\n-            use_multiprocessing: Boolean. Used for generator or\n-                `keras.utils.Sequence` input only. If `True`, use process-based\n-                threading. If unspecified, `use_multiprocessing` will default to\n-                `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n-                the generator as they can't be passed easily to children processes.\n-            **kwargs: Used for backwards compatibility.\n-\n-        # Returns\n-            A `History` object. Its `History.history` attribute is\n-            a record of training loss values and metrics values\n-            at successive epochs, as well as validation loss values\n-            and validation metrics values (if applicable).\n-\n-        # Raises\n-            RuntimeError: If the model was never compiled.\n-            ValueError: In case of mismatch between the provided input data\n-                and what the model expects.\n-        \"\"\"\n-        # Legacy support\n-        if 'nb_epoch' in kwargs:\n-            warnings.warn('The `nb_epoch` argument in `fit` '\n-                          'has been renamed `epochs`.', stacklevel=2)\n-            epochs = kwargs.pop('nb_epoch')\n-        if kwargs:\n-            raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n-\n-        if x is None and y is None and steps_per_epoch is None:\n-            raise ValueError('If fitting from data tensors, '\n-                             'you should specify the `steps_per_epoch` '\n-                             'argument.')\n-\n-        batch_size = self._validate_or_infer_batch_size(\n-            batch_size, steps_per_epoch, x)\n-\n-        # Case 1: generator-like. Input is Python generator,\n-        # or Sequence object, or iterator.\n-        if training_utils.is_generator_or_sequence(x):\n-            training_utils.check_generator_arguments(\n-                y, sample_weight, validation_split=validation_split)\n-            return self.fit_generator(\n-                x,\n-                steps_per_epoch=steps_per_epoch,\n-                epochs=epochs,\n-                verbose=verbose,\n-                callbacks=callbacks,\n-                validation_data=validation_data,\n-                validation_steps=validation_steps,\n-                validation_freq=validation_freq,\n-                class_weight=class_weight,\n-                max_queue_size=max_queue_size,\n-                workers=workers,\n-                use_multiprocessing=use_multiprocessing,\n-                shuffle=shuffle,\n-                initial_epoch=initial_epoch)\n-\n-        # Case 2: Symbolic tensors or Numpy array-like.\n-        x, y, sample_weights = self._standardize_user_data(\n-            x, y,\n-            sample_weight=sample_weight,\n-            class_weight=class_weight,\n-            batch_size=batch_size)\n-\n-        # Prepare validation data.\n-        do_validation = False\n-        if validation_data:\n-            do_validation = True\n-            if len(validation_data) == 2:\n-                val_x, val_y = validation_data\n-                val_sample_weight = None\n-            elif len(validation_data) == 3:\n-                val_x, val_y, val_sample_weight = validation_data\n-            else:\n-                raise ValueError('When passing validation_data, '\n-                                 'it must contain 2 (x_val, y_val) '\n-                                 'or 3 (x_val, y_val, val_sample_weights) '\n-                                 'items, however it contains %d items' %\n-                                 len(validation_data))\n-\n-            val_x, val_y, val_sample_weights = self._standardize_user_data(\n-                val_x, val_y,\n-                sample_weight=val_sample_weight,\n-                batch_size=batch_size)\n-            if self._uses_dynamic_learning_phase():\n-                val_inputs = val_x + val_y + val_sample_weights + [0]\n-            else:\n-                val_inputs = val_x + val_y + val_sample_weights\n-\n-        elif validation_split and 0. < validation_split < 1.:\n-            if any(K.is_tensor(t) for t in x):\n-                raise ValueError(\n-                    'If your data is in the form of symbolic tensors, '\n-                    'you cannot use `validation_split`.')\n-            do_validation = True\n-            if hasattr(x[0], 'shape'):\n-                split_at = int(int(x[0].shape[0]) * (1. - validation_split))\n-            else:\n-                split_at = int(len(x[0]) * (1. - validation_split))\n-            x, val_x = (slice_arrays(x, 0, split_at),\n-                        slice_arrays(x, split_at))\n-            y, val_y = (slice_arrays(y, 0, split_at),\n-                        slice_arrays(y, split_at))\n-            sample_weights, val_sample_weights = (\n-                slice_arrays(sample_weights, 0, split_at),\n-                slice_arrays(sample_weights, split_at))\n-            if self._uses_dynamic_learning_phase():\n-                val_inputs = val_x + val_y + val_sample_weights + [0]\n-            else:\n-                val_inputs = val_x + val_y + val_sample_weights\n-\n-        elif validation_steps:\n-            do_validation = True\n-            if self._uses_dynamic_learning_phase():\n-                val_inputs = [0]\n-\n-        # Prepare input arrays and training function.\n-        if self._uses_dynamic_learning_phase():\n-            fit_inputs = x + y + sample_weights + [1]\n-        else:\n-            fit_inputs = x + y + sample_weights\n-        self._make_train_function()\n-        fit_function = self.train_function\n-\n-        # Prepare display labels.\n-        out_labels = self.metrics_names\n-\n-        if do_validation:\n-            self._make_test_function()\n-            val_function = self.test_function\n-        else:\n-            val_function = None\n-            val_inputs = []\n-\n-        # Delegate logic to `fit_loop`.\n-        return training_arrays.fit_loop(self, fit_function, fit_inputs,\n-                                        out_labels=out_labels,\n-                                        batch_size=batch_size,\n-                                        epochs=epochs,\n-                                        verbose=verbose,\n-                                        callbacks=callbacks,\n-                                        val_function=val_function,\n-                                        val_inputs=val_inputs,\n-                                        shuffle=shuffle,\n-                                        initial_epoch=initial_epoch,\n-                                        steps_per_epoch=steps_per_epoch,\n-                                        validation_steps=validation_steps,\n-                                        validation_freq=validation_freq)\n-\n-    def evaluate(self,\n-                 x=None,\n-                 y=None,\n-                 batch_size=None,\n-                 verbose=1,\n-                 sample_weight=None,\n-                 steps=None,\n-                 callbacks=None,\n-                 max_queue_size=10,\n-                 workers=1,\n-                 use_multiprocessing=False):\n-        \"\"\"Returns the loss value & metrics values for the model in test mode.\n-\n-        Computation is done in batches.\n-\n-        # Arguments\n-            x: Input data. It could be:\n-                - A Numpy array (or array-like), or a list of arrays\n-                  (in case the model has multiple inputs).\n-                - A dict mapping input names to the corresponding\n-                  array/tensors, if the model has named inputs.\n-                - A generator or `keras.utils.Sequence` returning\n-                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n-                - None (default) if feeding from framework-native\n-                  tensors (e.g. TensorFlow data tensors).\n-            y: Target data. Like the input data `x`,\n-                it could be either Numpy array(s), framework-native tensor(s),\n-                list of Numpy arrays (if the model has multiple outputs) or\n-                None (default) if feeding from framework-native tensors\n-                (e.g. TensorFlow data tensors).\n-                If output layers in the model are named, you can also pass a\n-                dictionary mapping output names to Numpy arrays.\n-                If `x` is a generator, or `keras.utils.Sequence` instance,\n-                `y` should not be specified (since targets will be obtained\n-                from `x`).\n-            batch_size: Integer or `None`.\n-                Number of samples per evaluation step.\n-                If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of symbolic tensors, generators, or\n-                `keras.utils.Sequence` instances (since they generate batches).\n-            verbose: 0 or 1. Verbosity mode.\n-                0 = silent, 1 = progress bar.\n-            sample_weight: Optional Numpy array of weights for\n-                the test samples, used for weighting the loss function.\n-                You can either pass a flat (1D)\n-                Numpy array with the same length as the input samples\n-                (1:1 mapping between weights and samples),\n-                or in the case of temporal data,\n-                you can pass a 2D array with shape\n-                `(samples, sequence_length)`,\n-                to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify\n-                `sample_weight_mode=\"temporal\"` in `compile()`.\n-            steps: Integer or `None`.\n-                Total number of steps (batches of samples)\n-                before declaring the evaluation round finished.\n-                Ignored with the default value of `None`.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during evaluation.\n-                See [callbacks](/callbacks).\n-            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n-                input only. Maximum size for the generator queue.\n-                If unspecified, `max_queue_size` will default to 10.\n-            workers: Integer. Used for generator or `keras.utils.Sequence` input\n-                only. Maximum number of processes to spin up when using\n-                process-based threading. If unspecified, `workers` will default\n-                to 1. If 0, will execute the generator on the main thread.\n-            use_multiprocessing: Boolean. Used for generator or\n-                `keras.utils.Sequence` input only. If `True`, use process-based\n-                threading. If unspecified, `use_multiprocessing` will default to\n-                `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n-                the generator as they can't be passed easily to children processes.\n-\n-        # Raises\n-            ValueError: in case of invalid arguments.\n-\n-        # Returns\n-            Scalar test loss (if the model has a single output and no metrics)\n-            or list of scalars (if the model has multiple outputs\n-            and/or metrics). The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-        \"\"\"\n-\n-        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n-\n-        # Case 1: generator-like. Input is Python generator, or Sequence object.\n-        if training_utils.is_generator_or_sequence(x):\n-            training_utils.check_generator_arguments(y, sample_weight)\n-            return self.evaluate_generator(\n-                x,\n-                steps=steps,\n-                verbose=verbose,\n-                callbacks=callbacks,\n-                max_queue_size=max_queue_size,\n-                workers=workers,\n-                use_multiprocessing=use_multiprocessing)\n-\n-        # Case 2: Symbolic tensors or Numpy array-like.\n-        if x is None and y is None and steps is None:\n-            raise ValueError('If evaluating from data tensors, '\n-                             'you should specify the `steps` '\n-                             'argument.')\n-        # Validate user data.\n-        x, y, sample_weights = self._standardize_user_data(\n-            x, y,\n-            sample_weight=sample_weight,\n-            batch_size=batch_size)\n-        # Prepare inputs, delegate logic to `test_loop`.\n-        if self._uses_dynamic_learning_phase():\n-            ins = x + y + sample_weights + [0]\n-        else:\n-            ins = x + y + sample_weights\n-        self._make_test_function()\n-        f = self.test_function\n-        return training_arrays.test_loop(self, f, ins,\n-                                         batch_size=batch_size,\n-                                         verbose=verbose,\n-                                         steps=steps,\n-                                         callbacks=callbacks)\n-\n-    def predict(self, x,\n-                batch_size=None,\n-                verbose=0,\n-                steps=None,\n-                callbacks=None,\n-                max_queue_size=10,\n-                workers=1,\n-                use_multiprocessing=False):\n-        \"\"\"Generates output predictions for the input samples.\n-\n-        Computation is done in batches.\n-\n-        # Arguments\n-            x: Input data. It could be:\n-                - A Numpy array (or array-like), or a list of arrays\n-                  (in case the model has multiple inputs).\n-                - A dict mapping input names to the corresponding\n-                  array/tensors, if the model has named inputs.\n-                - A generator or `keras.utils.Sequence` returning\n-                  `(inputs, targets)` or `(inputs, targets, sample weights)`.\n-                - None (default) if feeding from framework-native\n-                  tensors (e.g. TensorFlow data tensors).\n-            batch_size: Integer or `None`.\n-                Number of samples to be predicted at once.\n-                If unspecified, `batch_size` will default to 32.\n-                Do not specify the `batch_size` if your data is in the\n-                form of symbolic tensors, generators, or\n-                `keras.utils.Sequence` instances (since they generate batches).\n-            verbose: Verbosity mode, 0 or 1.\n-            steps: Total number of steps (batches of samples)\n-                before declaring the prediction round finished.\n-                Ignored with the default value of `None`.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during prediction.\n-                See [callbacks](/callbacks).\n-            max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n-                input only. Maximum size for the generator queue.\n-                If unspecified, `max_queue_size` will default to 10.\n-            workers: Integer. Used for generator or `keras.utils.Sequence` input\n-                only. Maximum number of processes to spin up when using\n-                process-based threading. If unspecified, `workers` will default\n-                to 1. If 0, will execute the generator on the main thread.\n-            use_multiprocessing: Boolean. Used for generator or\n-                `keras.utils.Sequence` input only. If `True`, use process-based\n-                threading. If unspecified, `use_multiprocessing` will default to\n-                `False`. Note that because this implementation relies on\n-                multiprocessing, you should not pass non-picklable arguments to\n-                the generator as they can't be passed easily to children processes.\n-\n-        # Returns\n-            Numpy array(s) of predictions.\n-\n-        # Raises\n-            ValueError: In case of mismatch between the provided\n-                input data and the model's expectations,\n-                or in case a stateful model receives a number of samples\n-                that is not a multiple of the batch size.\n-        \"\"\"\n-\n-        batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\n-\n-        # Case 1: generator-like. Input is Python generator, or Sequence object.\n-        if training_utils.is_generator_or_sequence(x):\n-            return self.predict_generator(\n-                x,\n-                steps=steps,\n-                verbose=verbose,\n-                callbacks=callbacks,\n-                max_queue_size=max_queue_size,\n-                workers=workers,\n-                use_multiprocessing=use_multiprocessing)\n-\n-        if x is None and steps is None:\n-            raise ValueError('If predicting from data tensors, '\n-                             'you should specify the `steps` '\n-                             'argument.')\n-\n-        # Case 2: Symbolic tensors or Numpy array-like.\n-        x, _, _ = self._standardize_user_data(x)\n-        if self.stateful:\n-            if x[0].shape[0] > batch_size and x[0].shape[0] % batch_size != 0:\n-                raise ValueError('In a stateful network, '\n-                                 'you should only pass inputs with '\n-                                 'a number of samples that can be '\n-                                 'divided by the batch size. Found: ' +\n-                                 str(x[0].shape[0]) + ' samples. '\n-                                 'Batch size: ' + str(batch_size) + '.')\n-\n-        # Prepare inputs, delegate logic to `predict_loop`.\n-        if self._uses_dynamic_learning_phase():\n-            ins = x + [0]\n-        else:\n-            ins = x\n-        self._make_predict_function()\n-        f = self.predict_function\n-        return training_arrays.predict_loop(self, f, ins,\n-                                            batch_size=batch_size,\n-                                            verbose=verbose,\n-                                            steps=steps,\n-                                            callbacks=callbacks)\n-\n-    def train_on_batch(self, x, y,\n-                       sample_weight=None,\n-                       class_weight=None,\n-                       reset_metrics=True):\n-        \"\"\"Runs a single gradient update on a single batch of data.\n-\n-        # Arguments\n-            x: Numpy array of training data,\n-                or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named,\n-                you can also pass a dictionary\n-                mapping input names to Numpy arrays.\n-            y: Numpy array of target data,\n-                or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named,\n-                you can also pass a dictionary\n-                mapping output names to Numpy arrays.\n-            sample_weight: Optional array of the same length as x, containing\n-                weights to apply to the model's loss for each sample.\n-                In the case of temporal data, you can pass a 2D array\n-                with shape (samples, sequence_length),\n-                to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify\n-                sample_weight_mode=\"temporal\" in compile().\n-            class_weight: Optional dictionary mapping\n-                class indices (integers) to\n-                a weight (float) to apply to the model's loss for the samples\n-                from this class during training.\n-                This can be useful to tell the model to \"pay more attention\" to\n-                samples from an under-represented class.\n-            reset_metrics: If `True`, the metrics returned will be only for this\n-                batch. If `False`, the metrics will be statefully accumulated across\n-                batches.\n-\n-        # Returns\n-            Scalar training loss\n-            (if the model has a single output and no metrics)\n-            or list of scalars (if the model has multiple outputs\n-            and/or metrics). The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-        \"\"\"\n-        x, y, sample_weights = self._standardize_user_data(\n-            x, y,\n-            sample_weight=sample_weight,\n-            class_weight=class_weight)\n-        if self._uses_dynamic_learning_phase():\n-            ins = x + y + sample_weights + [1]\n-        else:\n-            ins = x + y + sample_weights\n-        self._make_train_function()\n-        outputs = self.train_function(ins)\n-\n-        if reset_metrics:\n-            self.reset_metrics()\n-        return unpack_singleton(outputs)\n-\n-    def test_on_batch(self, x, y, sample_weight=None, reset_metrics=True):\n-        \"\"\"Test the model on a single batch of samples.\n-\n-        # Arguments\n-            x: Numpy array of test data,\n-                or list of Numpy arrays if the model has multiple inputs.\n-                If all inputs in the model are named,\n-                you can also pass a dictionary\n-                mapping input names to Numpy arrays.\n-            y: Numpy array of target data,\n-                or list of Numpy arrays if the model has multiple outputs.\n-                If all outputs in the model are named,\n-                you can also pass a dictionary\n-                mapping output names to Numpy arrays.\n-            sample_weight: Optional array of the same length as x, containing\n-                weights to apply to the model's loss for each sample.\n-                In the case of temporal data, you can pass a 2D array\n-                with shape (samples, sequence_length),\n-                to apply a different weight to every timestep of every sample.\n-                In this case you should make sure to specify\n-                sample_weight_mode=\"temporal\" in compile().\n-            reset_metrics: If `True`, the metrics returned will be only for this\n-                batch. If `False`, the metrics will be statefully accumulated across\n-                batches.\n-\n-        # Returns\n-            Scalar test loss (if the model has a single output and no metrics)\n-            or list of scalars (if the model has multiple outputs\n-            and/or metrics). The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-        \"\"\"\n-        x, y, sample_weights = self._standardize_user_data(\n-            x, y,\n-            sample_weight=sample_weight)\n-        if self._uses_dynamic_learning_phase():\n-            ins = x + y + sample_weights + [0]\n-        else:\n-            ins = x + y + sample_weights\n-        self._make_test_function()\n-        outputs = self.test_function(ins)\n-\n-        if reset_metrics:\n-            self.reset_metrics()\n-        return unpack_singleton(outputs)\n-\n-    def predict_on_batch(self, x):\n-        \"\"\"Returns predictions for a single batch of samples.\n-\n-        # Arguments\n-            x: Input samples, as a Numpy array.\n-\n-        # Returns\n-            Numpy array(s) of predictions.\n-        \"\"\"\n-        x, _, _ = self._standardize_user_data(x)\n-        if self._uses_dynamic_learning_phase():\n-            ins = x + [0]\n-        else:\n-            ins = x\n-        self._make_predict_function()\n-        outputs = self.predict_function(ins)\n-        return unpack_singleton(outputs)\n-\n-    @interfaces.legacy_generator_methods_support\n-    def fit_generator(self, generator,\n-                      steps_per_epoch=None,\n-                      epochs=1,\n-                      verbose=1,\n-                      callbacks=None,\n-                      validation_data=None,\n-                      validation_steps=None,\n-                      validation_freq=1,\n-                      class_weight=None,\n-                      max_queue_size=10,\n-                      workers=1,\n-                      use_multiprocessing=False,\n-                      shuffle=True,\n-                      initial_epoch=0):\n-        \"\"\"Trains the model on data generated batch-by-batch by a Python generator\n-        (or an instance of `Sequence`).\n-\n-        The generator is run in parallel to the model, for efficiency.\n-        For instance, this allows you to do real-time data augmentation\n-        on images on CPU in parallel to training your model on GPU.\n-\n-        The use of `keras.utils.Sequence` guarantees the ordering\n-        and guarantees the single use of every input per epoch when\n-        using `use_multiprocessing=True`.\n-\n-        # Arguments\n-            generator: A generator or an instance of `Sequence`\n-                (`keras.utils.Sequence`) object in order to avoid\n-                duplicate data when using multiprocessing.\n-                The output of the generator must be either\n-                - a tuple `(inputs, targets)`\n-                - a tuple `(inputs, targets, sample_weights)`.\n-                This tuple (a single output of the generator) makes a single\n-                batch. Therefore, all arrays in this tuple must have the same\n-                length (equal to the size of this batch). Different batches may\n-                have different sizes. For example, the last batch of the epoch\n-                is commonly smaller than the others, if the size of the dataset\n-                is not divisible by the batch size.\n-                The generator is expected to loop over its data\n-                indefinitely. An epoch finishes when `steps_per_epoch`\n-                batches have been seen by the model.\n-            steps_per_epoch: Integer.\n-                Total number of steps (batches of samples)\n-                to yield from `generator` before declaring one epoch\n-                finished and starting the next epoch. It should typically\n-                be equal to `ceil(num_samples / batch_size)`\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            epochs: Integer. Number of epochs to train the model.\n-                An epoch is an iteration over the entire data provided,\n-                as defined by `steps_per_epoch`.\n-                Note that in conjunction with `initial_epoch`,\n-                `epochs` is to be understood as \"final epoch\".\n-                The model is not trained for a number of iterations\n-                given by `epochs`, but merely until the epoch\n-                of index `epochs` is reached.\n-            verbose: Integer. 0, 1, or 2. Verbosity mode.\n-                0 = silent, 1 = progress bar, 2 = one line per epoch.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during training.\n-                See [callbacks](/callbacks).\n-            validation_data: This can be either\n-                - a generator or a `Sequence` object for the validation data\n-                - tuple `(x_val, y_val)`\n-                - tuple `(x_val, y_val, val_sample_weights)`\n-                on which to evaluate\n-                the loss and any model metrics at the end of each epoch.\n-                The model will not be trained on this data.\n-            validation_steps: Only relevant if `validation_data`\n-                is a generator. Total number of steps (batches of samples)\n-                to yield from `validation_data` generator before stopping\n-                at the end of every epoch. It should typically\n-                be equal to the number of samples of your\n-                validation dataset divided by the batch size.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(validation_data)` as a number of steps.\n-            validation_freq: Only relevant if validation data is provided. Integer\n-                or `collections.Container` instance (e.g. list, tuple, etc.). If an\n-                integer, specifies how many training epochs to run before a new\n-                validation run is performed, e.g. `validation_freq=2` runs\n-                validation every 2 epochs. If a Container, specifies the epochs on\n-                which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n-                validation at the end of the 1st, 2nd, and 10th epochs.\n-            class_weight: Optional dictionary mapping class indices (integers)\n-                to a weight (float) value, used for weighting the loss function\n-                (during training only). This can be useful to tell the model to\n-                \"pay more attention\" to samples\n-                from an under-represented class.\n-            max_queue_size: Integer. Maximum size for the generator queue.\n-                If unspecified, `max_queue_size` will default to 10.\n-            workers: Integer. Maximum number of processes to spin up\n-                when using process-based threading.\n-                If unspecified, `workers` will default to 1. If 0, will\n-                execute the generator on the main thread.\n-            use_multiprocessing: Boolean.\n-                If `True`, use process-based threading.\n-                If unspecified, `use_multiprocessing` will default to `False`.\n-                Note that because this implementation\n-                relies on multiprocessing,\n-                you should not pass non-picklable arguments to the generator\n-                as they can't be passed easily to children processes.\n-            shuffle: Boolean. Whether to shuffle the order of the batches at\n-                the beginning of each epoch. Only used with instances\n-                of `Sequence` (`keras.utils.Sequence`).\n-                Has no effect when `steps_per_epoch` is not `None`.\n-            initial_epoch: Integer.\n-                Epoch at which to start training\n-                (useful for resuming a previous training run).\n-\n-        # Returns\n-            A `History` object. Its `History.history` attribute is\n-            a record of training loss values and metrics values\n-            at successive epochs, as well as validation loss values\n-            and validation metrics values (if applicable).\n-\n-        # Raises\n-            ValueError: In case the generator yields data in an invalid format.\n-\n-        # Example\n-\n-        ```python\n-        def generate_arrays_from_file(path):\n-            while True:\n-                with open(path) as f:\n-                    for line in f:\n-                        # create numpy arrays of input data\n-                        # and labels, from each line in the file\n-                        x1, x2, y = process_line(line)\n-                        yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n-\n-        model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n-                            steps_per_epoch=10000, epochs=10)\n-        ```\n-        \"\"\"\n-        return training_generator.fit_generator(\n-            self, generator,\n-            steps_per_epoch=steps_per_epoch,\n-            epochs=epochs,\n-            verbose=verbose,\n-            callbacks=callbacks,\n-            validation_data=validation_data,\n-            validation_steps=validation_steps,\n-            validation_freq=validation_freq,\n-            class_weight=class_weight,\n-            max_queue_size=max_queue_size,\n-            workers=workers,\n-            use_multiprocessing=use_multiprocessing,\n-            shuffle=shuffle,\n-            initial_epoch=initial_epoch)\n-\n-    @interfaces.legacy_generator_methods_support\n-    def evaluate_generator(self, generator,\n-                           steps=None,\n-                           callbacks=None,\n-                           max_queue_size=10,\n-                           workers=1,\n-                           use_multiprocessing=False,\n-                           verbose=0):\n-        \"\"\"Evaluates the model on a data generator.\n-\n-        The generator should return the same kind of data\n-        as accepted by `test_on_batch`.\n-\n-        # Arguments\n-            generator: Generator yielding tuples (inputs, targets)\n-                or (inputs, targets, sample_weights)\n-                or an instance of Sequence (keras.utils.Sequence)\n-                object in order to avoid duplicate data\n-                when using multiprocessing.\n-            steps: Total number of steps (batches of samples)\n-                to yield from `generator` before stopping.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during evaluation.\n-                See [callbacks](/callbacks).\n-            max_queue_size: maximum size for the generator queue\n-            workers: Integer. Maximum number of processes to spin up\n-                when using process based threading.\n-                If unspecified, `workers` will default to 1. If 0, will\n-                execute the generator on the main thread.\n-            use_multiprocessing: if True, use process based threading.\n-                Note that because\n-                this implementation relies on multiprocessing,\n-                you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed\n-                easily to children processes.\n-            verbose: verbosity mode, 0 or 1.\n-\n-        # Returns\n-            Scalar test loss (if the model has a single output and no metrics)\n-            or list of scalars (if the model has multiple outputs\n-            and/or metrics). The attribute `model.metrics_names` will give you\n-            the display labels for the scalar outputs.\n-\n-        # Raises\n-            ValueError: In case the generator yields\n-                data in an invalid format.\n-        \"\"\"\n-        return training_generator.evaluate_generator(\n-            self, generator,\n-            steps=steps,\n-            callbacks=callbacks,\n-            max_queue_size=max_queue_size,\n-            workers=workers,\n-            use_multiprocessing=use_multiprocessing,\n-            verbose=verbose)\n-\n-    @interfaces.legacy_generator_methods_support\n-    def predict_generator(self, generator,\n-                          steps=None,\n-                          callbacks=None,\n-                          max_queue_size=10,\n-                          workers=1,\n-                          use_multiprocessing=False,\n-                          verbose=0):\n-        \"\"\"Generates predictions for the input samples from a data generator.\n-\n-        The generator should return the same kind of data as accepted by\n-        `predict_on_batch`.\n-\n-        # Arguments\n-            generator: Generator yielding batches of input samples\n-                or an instance of Sequence (keras.utils.Sequence)\n-                object in order to avoid duplicate data\n-                when using multiprocessing.\n-            steps: Total number of steps (batches of samples)\n-                to yield from `generator` before stopping.\n-                Optional for `Sequence`: if unspecified, will use\n-                the `len(generator)` as a number of steps.\n-            callbacks: List of `keras.callbacks.Callback` instances.\n-                List of callbacks to apply during prediction.\n-                See [callbacks](/callbacks).\n-            max_queue_size: Maximum size for the generator queue.\n-            workers: Integer. Maximum number of processes to spin up\n-                when using process based threading.\n-                If unspecified, `workers` will default to 1. If 0, will\n-                execute the generator on the main thread.\n-            use_multiprocessing: If `True`, use process based threading.\n-                Note that because\n-                this implementation relies on multiprocessing,\n-                you should not pass\n-                non picklable arguments to the generator\n-                as they can't be passed\n-                easily to children processes.\n-            verbose: verbosity mode, 0 or 1.\n-\n-        # Returns\n-            Numpy array(s) of predictions.\n-\n-        # Raises\n-            ValueError: In case the generator yields\n-                data in an invalid format.\n-        \"\"\"\n-        return training_generator.predict_generator(\n-            self, generator,\n-            steps=steps,\n-            callbacks=callbacks,\n-            max_queue_size=max_queue_size,\n-            workers=workers,\n-            use_multiprocessing=use_multiprocessing,\n-            verbose=verbose)\n-\n-\n-def _get_metrics_from_layers(layers):\n-    \"\"\"Returns list of metrics from the given layers.\n-    This will not include the `compile` metrics of a model layer.\n-\n-    # Arguments\n-        layers: List of layers.\n-\n-    # Returns\n-        List of metrics.\n-    \"\"\"\n-    metrics = []\n-    for layer in layers:\n-        if isinstance(layer, Model):\n-            # We cannot call 'metrics' on the model because we do not want to\n-            # include the metrics that were added in compile API of a nested model.\n-            metrics.extend(layer._metrics)\n-            metrics.extend(_get_metrics_from_layers(layer.layers))\n-        else:\n-            metrics.extend(layer.metrics)\n-    return metrics\n+\"\"\"Training-related part of the Keras engine.\"\"\"\n+from tensorflow.keras import Model\n\n@@ -1,471 +0,0 @@\n-\"\"\"Part of the training engine related to plain array data (e.g. Numpy).\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-from scipy.sparse import issparse\n-\n-from .training_utils import batch_shuffle\n-from .training_utils import check_num_samples\n-from .training_utils import make_batches\n-from .training_utils import should_run_validation\n-from .. import backend as K\n-from .. import callbacks as cbks\n-from ..utils.generic_utils import Progbar\n-from ..utils.generic_utils import slice_arrays\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import unpack_singleton\n-\n-\n-def fit_loop(model, fit_function, fit_inputs,\n-             out_labels=None,\n-             batch_size=None,\n-             epochs=100,\n-             verbose=1,\n-             callbacks=None,\n-             val_function=None,\n-             val_inputs=None,\n-             shuffle=True,\n-             initial_epoch=0,\n-             steps_per_epoch=None,\n-             validation_steps=None,\n-             validation_freq=1):\n-    \"\"\"Abstract fit function for `fit_function(fit_inputs)`.\n-\n-    Assumes that fit_function returns a list, labeled by out_labels.\n-\n-    # Arguments\n-        model: Keras model instance.\n-        fit_function: Keras function returning a list of tensors\n-        fit_inputs: List of tensors to be fed to `fit_function`\n-        out_labels: List of strings, display names of\n-            the outputs of `fit_function`\n-        batch_size: Integer batch size or None if unknown.\n-        epochs: Number of times to iterate over the data\n-        verbose: Verbosity mode, 0, 1 or 2\n-        callbacks: List of callbacks to be called during training and validation\n-            (if `val_function` and `val_inputs` are not `None`).\n-        val_function: Keras function to call for validation\n-        val_inputs: List of tensors to be fed to `val_function`\n-        shuffle: Whether to shuffle the data at the beginning of each epoch\n-        initial_epoch: Epoch at which to start training\n-            (useful for resuming a previous training run)\n-        steps_per_epoch: Total number of steps (batches of samples)\n-            before declaring one epoch finished and starting the\n-            next epoch. Ignored with the default value of `None`.\n-        validation_steps: Number of steps to run validation for\n-            (only if doing validation from data tensors).\n-            Ignored with the default value of `None`.\n-        validation_freq: Only relevant if validation data is provided. Integer\n-            or list/tuple/set. If an integer, specifies how many training\n-            epochs to run before a new validation run is performed, e.g.\n-            validation_freq=2` runs validation every 2 epochs. If a list,\n-            tuple, or set, specifies the epochs on which to run validation,\n-            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n-            of the 1st, 2nd, and 10th epochs.\n-\n-    # Returns\n-        `History` object.\n-    \"\"\"\n-    do_validation = False\n-    if val_function and val_inputs:\n-        do_validation = True\n-        if (verbose and fit_inputs and\n-           hasattr(fit_inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):\n-            print('Train on %d samples, validate on %d samples' %\n-                  (fit_inputs[0].shape[0], val_inputs[0].shape[0]))\n-    if validation_steps:\n-        do_validation = True\n-        if steps_per_epoch is None:\n-            raise ValueError('Can only use `validation_steps` '\n-                             'when doing step-wise '\n-                             'training, i.e. `steps_per_epoch` '\n-                             'must be set.')\n-    elif do_validation:\n-        if steps_per_epoch:\n-            raise ValueError('Must specify `validation_steps` '\n-                             'to perform validation '\n-                             'when doing step-wise training.')\n-\n-    num_train_samples = check_num_samples(fit_inputs,\n-                                          batch_size=batch_size,\n-                                          steps=steps_per_epoch,\n-                                          steps_name='steps_per_epoch')\n-    if num_train_samples is not None:\n-        index_array = np.arange(num_train_samples)\n-\n-    model.history = cbks.History()\n-    _callbacks = [cbks.BaseLogger(stateful_metrics=model.metrics_names[1:])]\n-    if verbose:\n-        if steps_per_epoch is not None:\n-            count_mode = 'steps'\n-        else:\n-            count_mode = 'samples'\n-        _callbacks.append(\n-            cbks.ProgbarLogger(count_mode, stateful_metrics=model.metrics_names[1:]))\n-    _callbacks += (callbacks or []) + [model.history]\n-    callbacks = cbks.CallbackList(_callbacks)\n-    out_labels = out_labels or []\n-\n-    # it's possible to callback a different model than itself\n-    # (used by Sequential models)\n-    callback_model = model._get_callback_model()\n-    callback_metrics = list(model.metrics_names)\n-    if do_validation:\n-        callback_metrics += ['val_' + n for n in model.metrics_names]\n-\n-    callbacks.set_model(callback_model)\n-    callbacks.set_params({\n-        'batch_size': batch_size,\n-        'epochs': epochs,\n-        'steps': steps_per_epoch,\n-        'samples': num_train_samples,\n-        'verbose': verbose,\n-        'do_validation': do_validation,\n-        'metrics': callback_metrics,\n-    })\n-    callbacks._call_begin_hook('train')\n-    callbacks.model.stop_training = False\n-    for cbk in callbacks:\n-        cbk.validation_data = val_inputs\n-\n-    # To prevent a slowdown,\n-    # we find beforehand the arrays that need conversion.\n-    feed = (model._feed_inputs +\n-            model._feed_targets +\n-            model._feed_sample_weights)\n-    indices_for_conversion_to_dense = []\n-    for i in range(len(feed)):\n-        if issparse(fit_inputs[i]) and not K.is_sparse(feed[i]):\n-            indices_for_conversion_to_dense.append(i)\n-\n-    for epoch in range(initial_epoch, epochs):\n-        model.reset_metrics()\n-        callbacks.on_epoch_begin(epoch)\n-        epoch_logs = {}\n-        if steps_per_epoch is not None:\n-            for step_index in range(steps_per_epoch):\n-                batch_logs = {'batch': step_index, 'size': 1}\n-                callbacks._call_batch_hook('train', 'begin', step_index, batch_logs)\n-                outs = fit_function(fit_inputs)\n-\n-                outs = to_list(outs)\n-                for l, o in zip(out_labels, outs):\n-                    batch_logs[l] = o\n-\n-                callbacks._call_batch_hook('train', 'end', step_index, batch_logs)\n-                if callback_model.stop_training:\n-                    break\n-\n-            if do_validation and should_run_validation(validation_freq, epoch):\n-                val_outs = test_loop(model, val_function, val_inputs,\n-                                     steps=validation_steps,\n-                                     callbacks=callbacks,\n-                                     verbose=0)\n-                val_outs = to_list(val_outs)\n-                # Same labels assumed.\n-                for l, o in zip(out_labels, val_outs):\n-                    epoch_logs['val_' + l] = o\n-        else:\n-            if shuffle == 'batch':\n-                index_array = batch_shuffle(index_array, batch_size)\n-            elif shuffle:\n-                np.random.shuffle(index_array)\n-\n-            batches = make_batches(num_train_samples, batch_size)\n-            for batch_index, (batch_start, batch_end) in enumerate(batches):\n-                batch_ids = index_array[batch_start:batch_end]\n-                try:\n-                    if isinstance(fit_inputs[-1], int):\n-                        # Do not slice the training phase flag.\n-                        ins_batch = slice_arrays(\n-                            fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n-                    else:\n-                        ins_batch = slice_arrays(fit_inputs, batch_ids)\n-                except TypeError:\n-                    raise TypeError('TypeError while preparing batch. '\n-                                    'If using HDF5 input data, '\n-                                    'pass shuffle=\"batch\".')\n-                batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n-                callbacks._call_batch_hook('train', 'begin', batch_index, batch_logs)\n-                for i in indices_for_conversion_to_dense:\n-                    ins_batch[i] = ins_batch[i].toarray()\n-\n-                outs = fit_function(ins_batch)\n-                outs = to_list(outs)\n-                for l, o in zip(out_labels, outs):\n-                    batch_logs[l] = o\n-\n-                callbacks._call_batch_hook('train', 'end', batch_index, batch_logs)\n-                if callbacks.model.stop_training:\n-                    break\n-\n-            if batch_index == len(batches) - 1:  # Last batch.\n-                if do_validation and should_run_validation(validation_freq, epoch):\n-                    val_outs = test_loop(model, val_function, val_inputs,\n-                                         batch_size=batch_size,\n-                                         callbacks=callbacks,\n-                                         verbose=0)\n-                    val_outs = to_list(val_outs)\n-                    # Same labels assumed.\n-                    for l, o in zip(out_labels, val_outs):\n-                        epoch_logs['val_' + l] = o\n-\n-        callbacks.on_epoch_end(epoch, epoch_logs)\n-        if callbacks.model.stop_training:\n-            break\n-    callbacks._call_end_hook('train')\n-    return model.history\n-\n-\n-def predict_loop(model, f, ins,\n-                 batch_size=32,\n-                 verbose=0,\n-                 steps=None,\n-                 callbacks=None):\n-    \"\"\"Abstract method to loop over some data in batches.\n-\n-    # Arguments\n-        model: Keras model instance.\n-        f: Keras function returning a list of tensors.\n-        ins: list of tensors to be fed to `f`.\n-        batch_size: integer batch size.\n-        verbose: verbosity mode.\n-        steps: Total number of steps (batches of samples)\n-            before declaring `predict_loop` finished.\n-            Ignored with the default value of `None`.\n-        callbacks: List of callbacks or an instance of\n-            `keras.callbacks.CallbackList` to be called during prediction.\n-\n-    # Returns\n-        Array of predictions (if the model has a single output)\n-        or list of arrays of predictions\n-        (if the model has multiple outputs).\n-    \"\"\"\n-    num_samples = check_num_samples(ins,\n-                                    batch_size=batch_size,\n-                                    steps=steps,\n-                                    steps_name='steps')\n-\n-    # Check if callbacks have not been already configured\n-    if not isinstance(callbacks, cbks.CallbackList):\n-        callbacks = cbks.CallbackList(callbacks)\n-        callback_model = model._get_callback_model()\n-        callbacks.set_model(callback_model)\n-        callback_params = {\n-            'batch_size': batch_size,\n-            'steps': steps,\n-            'samples': num_samples,\n-            'verbose': verbose,\n-        }\n-        callbacks.set_params(callback_params)\n-\n-    if verbose == 1:\n-        if steps is not None:\n-            progbar = Progbar(target=steps)\n-        else:\n-            progbar = Progbar(target=num_samples)\n-\n-    indices_for_conversion_to_dense = []\n-    for i in range(len(model._feed_inputs)):\n-        if issparse(ins[i]) and not K.is_sparse(model._feed_inputs[i]):\n-            indices_for_conversion_to_dense.append(i)\n-\n-    callbacks.model.stop_training = False\n-    callbacks._call_begin_hook('predict')\n-\n-    if steps is not None:\n-        # Step-based predictions.\n-        # Since we do not know how many samples\n-        # we will see, we cannot pre-allocate\n-        # the returned Numpy arrays.\n-        # Instead, we store one array per batch seen\n-        # and concatenate them upon returning.\n-        unconcatenated_outs = []\n-        for step in range(steps):\n-            batch_logs = {'batch': step, 'size': 1}\n-            callbacks._call_batch_hook('predict', 'begin', step, batch_logs)\n-            batch_outs = f(ins)\n-            batch_outs = to_list(batch_outs)\n-            if step == 0:\n-                for batch_out in batch_outs:\n-                    unconcatenated_outs.append([])\n-            for i, batch_out in enumerate(batch_outs):\n-                unconcatenated_outs[i].append(batch_out)\n-\n-            batch_logs['outputs'] = batch_outs\n-            callbacks._call_batch_hook('predict', 'end', step, batch_logs)\n-            if verbose == 1:\n-                progbar.update(step + 1)\n-        callbacks.on_predict_end()\n-        if len(unconcatenated_outs) == 1:\n-            return np.concatenate(unconcatenated_outs[0], axis=0)\n-        return [np.concatenate(unconcatenated_outs[i], axis=0)\n-                for i in range(len(unconcatenated_outs))]\n-    else:\n-        # Sample-based predictions.\n-        outs = []\n-        batches = make_batches(num_samples, batch_size)\n-        index_array = np.arange(num_samples)\n-        for batch_index, (batch_start, batch_end) in enumerate(batches):\n-            batch_ids = index_array[batch_start:batch_end]\n-            if ins and isinstance(ins[-1], int):\n-                # Do not slice the training phase flag.\n-                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n-            else:\n-                ins_batch = slice_arrays(ins, batch_ids)\n-            for i in indices_for_conversion_to_dense:\n-                ins_batch[i] = ins_batch[i].toarray()\n-\n-            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n-            callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)\n-            batch_outs = f(ins_batch)\n-            batch_outs = to_list(batch_outs)\n-            if batch_index == 0:\n-                # Pre-allocate the results arrays.\n-                for batch_out in batch_outs:\n-                    shape = (num_samples,) + batch_out.shape[1:]\n-                    outs.append(np.zeros(shape, dtype=batch_out.dtype))\n-            for i, batch_out in enumerate(batch_outs):\n-                outs[i][batch_start:batch_end] = batch_out\n-\n-            batch_logs['outputs'] = batch_outs\n-            callbacks._call_batch_hook('predict', 'end', batch_index, batch_logs)\n-            if verbose == 1:\n-                progbar.update(batch_end)\n-        callbacks._call_end_hook('predict')\n-        return unpack_singleton(outs)\n-\n-\n-def test_loop(model, f, ins,\n-              batch_size=None,\n-              verbose=0,\n-              steps=None,\n-              callbacks=None):\n-    \"\"\"Abstract method to loop over some data in batches.\n-\n-    # Arguments\n-        model: Keras model instance.\n-        f: Keras function returning a list of tensors.\n-        ins: list of tensors to be fed to `f`.\n-        batch_size: integer batch size or `None`.\n-        verbose: verbosity mode.\n-        steps: Total number of steps (batches of samples)\n-            before declaring predictions finished.\n-            Ignored with the default value of `None`.\n-        callbacks: List of callbacks or an instance of\n-            `keras.callbacks.CallbackList` to be called during evaluation.\n-\n-    # Returns\n-        Scalar loss (if the model has a single output and no metrics)\n-        or list of scalars (if the model has multiple outputs\n-        and/or metrics). The attribute `model.metrics_names` will give you\n-        the display labels for the scalar outputs.\n-    \"\"\"\n-\n-    model.reset_metrics()\n-    num_samples = check_num_samples(ins,\n-                                    batch_size=batch_size,\n-                                    steps=steps,\n-                                    steps_name='steps')\n-\n-    # Check if callbacks have not been already configured\n-    if not isinstance(callbacks, cbks.CallbackList):\n-        callbacks = cbks.CallbackList(callbacks)\n-        callback_model = model._get_callback_model()\n-        callbacks.set_model(callback_model)\n-        callback_metrics = list(model.metrics_names)\n-        callback_params = {\n-            'batch_size': batch_size,\n-            'steps': steps,\n-            'samples': num_samples,\n-            'verbose': verbose,\n-            'metrics': callback_metrics,\n-        }\n-        callbacks.set_params(callback_params)\n-\n-    outs = []\n-    if verbose == 1:\n-        if steps is not None:\n-            progbar = Progbar(target=steps)\n-        else:\n-            progbar = Progbar(target=num_samples)\n-\n-    # To prevent a slowdown,\n-    # we find beforehand the arrays that need conversion.\n-    feed = (model._feed_inputs +\n-            model._feed_targets +\n-            model._feed_sample_weights)\n-    indices_for_conversion_to_dense = []\n-    for i in range(len(feed)):\n-        if issparse(ins[i]) and not K.is_sparse(feed[i]):\n-            indices_for_conversion_to_dense.append(i)\n-\n-    callbacks.model.stop_training = False\n-    callbacks._call_begin_hook('test')\n-\n-    if steps is not None:\n-        for step in range(steps):\n-            batch_logs = {'batch': step, 'size': 1}\n-            callbacks._call_batch_hook('test', 'begin', step, batch_logs)\n-            batch_outs = f(ins)\n-            if isinstance(batch_outs, list):\n-                if step == 0:\n-                    outs.extend([0.] * len(batch_outs))\n-                for i, batch_out in enumerate(batch_outs):\n-                    if i == 0:  # Index 0 == `Loss`\n-                        outs[i] = float(batch_out)\n-                    else:\n-                        outs[i] += float(batch_out)\n-            else:\n-                if step == 0:\n-                    outs.append(0.)\n-                outs[0] += float(batch_outs)\n-\n-            for l, o in zip(model.metrics_names, batch_outs):\n-                batch_logs[l] = o\n-            callbacks._call_batch_hook('test', 'end', step, batch_logs)\n-\n-            if verbose == 1:\n-                progbar.update(step + 1)\n-        outs[0] /= steps  # Index 0 == `Loss`\n-    else:\n-        batches = make_batches(num_samples, batch_size)\n-        index_array = np.arange(num_samples)\n-        for batch_index, (batch_start, batch_end) in enumerate(batches):\n-            batch_ids = index_array[batch_start:batch_end]\n-            if isinstance(ins[-1], int):\n-                # Do not slice the training phase flag.\n-                ins_batch = slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n-            else:\n-                ins_batch = slice_arrays(ins, batch_ids)\n-            for i in indices_for_conversion_to_dense:\n-                ins_batch[i] = ins_batch[i].toarray()\n-\n-            batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n-            callbacks._call_batch_hook('test', 'begin', batch_index, batch_logs)\n-            batch_outs = f(ins_batch)\n-            if isinstance(batch_outs, list):\n-                if batch_index == 0:\n-                    outs.extend([0.] * len(batch_outs))\n-                for i, batch_out in enumerate(batch_outs):\n-                    if i == 0:  # Index 0 == `Loss`\n-                        outs[i] += float(batch_out) * len(batch_ids)\n-                    else:\n-                        outs[i] = float(batch_out)\n-            else:\n-                if batch_index == 0:\n-                    outs.append(0.)\n-                outs[0] += float(batch_outs) * len(batch_ids)\n-\n-            for l, o in zip(model.metrics_names, batch_outs):\n-                batch_logs[l] = float(o)\n-            callbacks._call_batch_hook('test', 'end', batch_index, batch_logs)\n-\n-            if verbose == 1:\n-                progbar.update(batch_end)\n-        outs[0] /= num_samples  # Index 0 == `Loss`\n-    callbacks._call_end_hook('test')\n-    return unpack_singleton(outs)\n\n@@ -1,556 +0,0 @@\n-\"\"\"Part of the training engine related to Python generators of array data.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import warnings\n-import numpy as np\n-\n-from .training_utils import is_sequence\n-from .training_utils import iter_sequence_infinite\n-from .training_utils import should_run_validation\n-from .. import backend as K\n-from ..utils.data_utils import Sequence\n-from ..utils.data_utils import GeneratorEnqueuer\n-from ..utils.data_utils import OrderedEnqueuer\n-from ..utils.generic_utils import Progbar\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import unpack_singleton\n-from .. import callbacks as cbks\n-\n-\n-def fit_generator(model,\n-                  generator,\n-                  steps_per_epoch=None,\n-                  epochs=1,\n-                  verbose=1,\n-                  callbacks=None,\n-                  validation_data=None,\n-                  validation_steps=None,\n-                  validation_freq=1,\n-                  class_weight=None,\n-                  max_queue_size=10,\n-                  workers=1,\n-                  use_multiprocessing=False,\n-                  shuffle=True,\n-                  initial_epoch=0):\n-    \"\"\"See docstring for `Model.fit_generator`.\"\"\"\n-    epoch = initial_epoch\n-\n-    do_validation = bool(validation_data)\n-    model._make_train_function()\n-    if do_validation:\n-        model._make_test_function()\n-\n-    use_sequence_api = is_sequence(generator)\n-    if not use_sequence_api and use_multiprocessing and workers > 1:\n-        warnings.warn(\n-            UserWarning('Using a generator with `use_multiprocessing=True`'\n-                        ' and multiple workers may duplicate your data.'\n-                        ' Please consider using the `keras.utils.Sequence'\n-                        ' class.'))\n-\n-    # if generator is instance of Sequence and steps_per_epoch are not provided -\n-    # recompute steps_per_epoch after each epoch\n-    recompute_steps_per_epoch = use_sequence_api and steps_per_epoch is None\n-\n-    if steps_per_epoch is None:\n-        if use_sequence_api:\n-            steps_per_epoch = len(generator)\n-        else:\n-            raise ValueError('`steps_per_epoch=None` is only valid for a'\n-                             ' generator based on the '\n-                             '`keras.utils.Sequence`'\n-                             ' class. Please specify `steps_per_epoch` '\n-                             'or use the `keras.utils.Sequence` class.')\n-\n-    # python 2 has 'next', 3 has '__next__'\n-    # avoid any explicit version checks\n-    val_use_sequence_api = is_sequence(validation_data)\n-    val_gen = (hasattr(validation_data, 'next') or\n-               hasattr(validation_data, '__next__') or\n-               val_use_sequence_api)\n-    if (val_gen and not val_use_sequence_api and\n-            not validation_steps):\n-        raise ValueError('`validation_steps=None` is only valid for a'\n-                         ' generator based on the `keras.utils.Sequence`'\n-                         ' class. Please specify `validation_steps` or use'\n-                         ' the `keras.utils.Sequence` class.')\n-\n-    # Prepare display labels.\n-    out_labels = model.metrics_names\n-    callback_metrics = out_labels + ['val_' + n for n in out_labels]\n-\n-    # prepare callbacks\n-    model.history = cbks.History()\n-    _callbacks = [cbks.BaseLogger(\n-        stateful_metrics=model.metrics_names[1:])]\n-    if verbose:\n-        _callbacks.append(\n-            cbks.ProgbarLogger(\n-                count_mode='steps',\n-                stateful_metrics=model.metrics_names[1:]))\n-    _callbacks += (callbacks or []) + [model.history]\n-    callbacks = cbks.CallbackList(_callbacks)\n-\n-    # it's possible to callback a different model than self:\n-    callback_model = model._get_callback_model()\n-\n-    callbacks.set_model(callback_model)\n-    callbacks.set_params({\n-        'epochs': epochs,\n-        'steps': steps_per_epoch,\n-        'verbose': verbose,\n-        'do_validation': do_validation,\n-        'metrics': callback_metrics,\n-    })\n-    callbacks._call_begin_hook('train')\n-\n-    enqueuer = None\n-    val_enqueuer = None\n-\n-    try:\n-        if do_validation:\n-            if val_gen and workers > 0:\n-                # Create an Enqueuer that can be reused\n-                val_data = validation_data\n-                if is_sequence(val_data):\n-                    val_enqueuer = OrderedEnqueuer(\n-                        val_data,\n-                        use_multiprocessing=use_multiprocessing)\n-                    validation_steps = validation_steps or len(val_data)\n-                else:\n-                    val_enqueuer = GeneratorEnqueuer(\n-                        val_data,\n-                        use_multiprocessing=use_multiprocessing)\n-                val_enqueuer.start(workers=workers,\n-                                   max_queue_size=max_queue_size)\n-                val_enqueuer_gen = val_enqueuer.get()\n-            elif val_gen:\n-                val_data = validation_data\n-                if is_sequence(val_data):\n-                    val_enqueuer_gen = iter_sequence_infinite(val_data)\n-                    validation_steps = validation_steps or len(val_data)\n-                else:\n-                    val_enqueuer_gen = val_data\n-            else:\n-                # Prepare data for validation\n-                if len(validation_data) == 2:\n-                    val_x, val_y = validation_data\n-                    val_sample_weight = None\n-                elif len(validation_data) == 3:\n-                    val_x, val_y, val_sample_weight = validation_data\n-                else:\n-                    raise ValueError('`validation_data` should be a tuple '\n-                                     '`(val_x, val_y, val_sample_weight)` '\n-                                     'or `(val_x, val_y)`. Found: ' +\n-                                     str(validation_data))\n-                val_x, val_y, val_sample_weights = model._standardize_user_data(\n-                    val_x, val_y, val_sample_weight)\n-                val_data = val_x + val_y + val_sample_weights\n-                if model.uses_learning_phase and not isinstance(K.learning_phase(),\n-                                                                int):\n-                    val_data += [0.]\n-                for cbk in callbacks:\n-                    cbk.validation_data = val_data\n-\n-        if workers > 0:\n-            if use_sequence_api:\n-                enqueuer = OrderedEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing,\n-                    shuffle=shuffle)\n-            else:\n-                enqueuer = GeneratorEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing)\n-            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n-            output_generator = enqueuer.get()\n-        else:\n-            if use_sequence_api:\n-                output_generator = iter_sequence_infinite(generator)\n-            else:\n-                output_generator = generator\n-\n-        callbacks.model.stop_training = False\n-        # Construct epoch logs.\n-        epoch_logs = {}\n-        while epoch < epochs:\n-            model.reset_metrics()\n-            callbacks.on_epoch_begin(epoch)\n-            steps_done = 0\n-            batch_index = 0\n-            while steps_done < steps_per_epoch:\n-                generator_output = next(output_generator)\n-\n-                if not hasattr(generator_output, '__len__'):\n-                    raise ValueError('Output of generator should be '\n-                                     'a tuple `(x, y, sample_weight)` '\n-                                     'or `(x, y)`. Found: ' +\n-                                     str(generator_output))\n-\n-                if len(generator_output) == 2:\n-                    x, y = generator_output\n-                    sample_weight = None\n-                elif len(generator_output) == 3:\n-                    x, y, sample_weight = generator_output\n-                else:\n-                    raise ValueError('Output of generator should be '\n-                                     'a tuple `(x, y, sample_weight)` '\n-                                     'or `(x, y)`. Found: ' +\n-                                     str(generator_output))\n-                if x is None or len(x) == 0:\n-                    # Handle data tensors support when no input given\n-                    # step-size = 1 for data tensors\n-                    batch_size = 1\n-                elif isinstance(x, list):\n-                    batch_size = x[0].shape[0]\n-                elif isinstance(x, dict):\n-                    batch_size = list(x.values())[0].shape[0]\n-                else:\n-                    batch_size = x.shape[0]\n-                # build batch logs\n-                batch_logs = {'batch': batch_index, 'size': batch_size}\n-                callbacks.on_batch_begin(batch_index, batch_logs)\n-\n-                outs = model.train_on_batch(x, y,\n-                                            sample_weight=sample_weight,\n-                                            class_weight=class_weight,\n-                                            reset_metrics=False)\n-\n-                outs = to_list(outs)\n-                for l, o in zip(out_labels, outs):\n-                    batch_logs[l] = o\n-\n-                callbacks._call_batch_hook('train', 'end', batch_index, batch_logs)\n-\n-                batch_index += 1\n-                steps_done += 1\n-\n-                # Epoch finished.\n-                if (steps_done >= steps_per_epoch and\n-                        do_validation and\n-                        should_run_validation(validation_freq, epoch)):\n-                    # Note that `callbacks` here is an instance of\n-                    # `keras.callbacks.CallbackList`\n-                    if val_gen:\n-                        val_outs = model.evaluate_generator(\n-                            val_enqueuer_gen,\n-                            validation_steps,\n-                            callbacks=callbacks,\n-                            workers=0)\n-                    else:\n-                        # No need for try/except because\n-                        # data has already been validated.\n-                        val_outs = model.evaluate(\n-                            val_x, val_y,\n-                            batch_size=batch_size,\n-                            sample_weight=val_sample_weights,\n-                            callbacks=callbacks,\n-                            verbose=0)\n-                    val_outs = to_list(val_outs)\n-                    # Same labels assumed.\n-                    for l, o in zip(out_labels, val_outs):\n-                        epoch_logs['val_' + l] = o\n-\n-                if callbacks.model.stop_training:\n-                    break\n-\n-            callbacks.on_epoch_end(epoch, epoch_logs)\n-            epoch += 1\n-            if callbacks.model.stop_training:\n-                break\n-\n-            if use_sequence_api and workers == 0:\n-                generator.on_epoch_end()\n-\n-            if recompute_steps_per_epoch:\n-                if workers > 0:\n-                    enqueuer.join_end_of_epoch()\n-\n-                # recomute steps per epochs in case if Sequence changes it's length\n-                steps_per_epoch = len(generator)\n-\n-                # update callbacks to make sure params are valid each epoch\n-                callbacks.set_params({\n-                    'epochs': epochs,\n-                    'steps': steps_per_epoch,\n-                    'verbose': verbose,\n-                    'do_validation': do_validation,\n-                    'metrics': callback_metrics,\n-                })\n-\n-    finally:\n-        try:\n-            if enqueuer is not None:\n-                enqueuer.stop()\n-        finally:\n-            if val_enqueuer is not None:\n-                val_enqueuer.stop()\n-\n-    callbacks._call_end_hook('train')\n-    return model.history\n-\n-\n-def evaluate_generator(model, generator,\n-                       steps=None,\n-                       callbacks=None,\n-                       max_queue_size=10,\n-                       workers=1,\n-                       use_multiprocessing=False,\n-                       verbose=0):\n-    \"\"\"See docstring for `Model.evaluate_generator`.\"\"\"\n-    model._make_test_function()\n-    model.reset_metrics()\n-\n-    steps_done = 0\n-    outs_per_batch = []\n-    batch_sizes = []\n-    use_sequence_api = is_sequence(generator)\n-    if not use_sequence_api and use_multiprocessing and workers > 1:\n-        warnings.warn(\n-            UserWarning('Using a generator with `use_multiprocessing=True`'\n-                        ' and multiple workers may duplicate your data.'\n-                        ' Please consider using the `keras.utils.Sequence'\n-                        ' class.'))\n-    if steps is None:\n-        if use_sequence_api:\n-            steps = len(generator)\n-        else:\n-            raise ValueError('`steps=None` is only valid for a generator'\n-                             ' based on the `keras.utils.Sequence` class.'\n-                             ' Please specify `steps` or use the'\n-                             ' `keras.utils.Sequence` class.')\n-    enqueuer = None\n-\n-    # Check if callbacks have not been already configured\n-    if not isinstance(callbacks, cbks.CallbackList):\n-        callbacks = cbks.CallbackList(callbacks)\n-        callback_model = model._get_callback_model()\n-        callbacks.set_model(callback_model)\n-        callback_metrics = list(model.metrics_names)\n-        callback_params = {\n-            'steps': steps,\n-            'verbose': verbose,\n-            'metrics': callback_metrics,\n-        }\n-        callbacks.set_params(callback_params)\n-\n-    callbacks.model.stop_training = False\n-    callbacks._call_begin_hook('test')\n-\n-    try:\n-        if workers > 0:\n-            if use_sequence_api:\n-                enqueuer = OrderedEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing)\n-            else:\n-                enqueuer = GeneratorEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing)\n-            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n-            output_generator = enqueuer.get()\n-        else:\n-            if use_sequence_api:\n-                output_generator = iter_sequence_infinite(generator)\n-            else:\n-                output_generator = generator\n-\n-        if verbose == 1:\n-            progbar = Progbar(target=steps)\n-\n-        while steps_done < steps:\n-            generator_output = next(output_generator)\n-            if not hasattr(generator_output, '__len__'):\n-                raise ValueError('Output of generator should be a tuple '\n-                                 '(x, y, sample_weight) '\n-                                 'or (x, y). Found: ' +\n-                                 str(generator_output))\n-            if len(generator_output) == 2:\n-                x, y = generator_output\n-                sample_weight = None\n-            elif len(generator_output) == 3:\n-                x, y, sample_weight = generator_output\n-            else:\n-                raise ValueError('Output of generator should be a tuple '\n-                                 '(x, y, sample_weight) '\n-                                 'or (x, y). Found: ' +\n-                                 str(generator_output))\n-\n-            if x is None or len(x) == 0:\n-                # Handle data tensors support when no input given\n-                # step-size = 1 for data tensors\n-                batch_size = 1\n-            elif isinstance(x, list):\n-                batch_size = x[0].shape[0]\n-            elif isinstance(x, dict):\n-                batch_size = list(x.values())[0].shape[0]\n-            else:\n-                batch_size = x.shape[0]\n-            if batch_size == 0:\n-                raise ValueError('Received an empty batch. '\n-                                 'Batches should contain '\n-                                 'at least one item.')\n-\n-            batch_logs = {'batch': steps_done, 'size': batch_size}\n-            callbacks._call_batch_hook('test', 'begin', steps_done, batch_logs)\n-            outs = model.test_on_batch(x, y,\n-                                       sample_weight=sample_weight,\n-                                       reset_metrics=False)\n-            outs = to_list(outs)\n-            outs_per_batch.append(outs)\n-\n-            for l, o in zip(model.metrics_names, outs):\n-                batch_logs[l] = o\n-            callbacks._call_batch_hook('test', 'end', steps_done, batch_logs)\n-\n-            steps_done += 1\n-            batch_sizes.append(batch_size)\n-\n-            if verbose == 1:\n-                progbar.update(steps_done)\n-        callbacks._call_end_hook('test')\n-\n-    finally:\n-        if enqueuer is not None:\n-            enqueuer.stop()\n-\n-    averages = [float(outs_per_batch[-1][0])]  # index 0 = 'loss'\n-    for i in range(1, len(outs)):\n-        averages.append(np.float64(outs_per_batch[-1][i]))\n-    return unpack_singleton(averages)\n-\n-\n-def predict_generator(model, generator,\n-                      steps=None,\n-                      callbacks=None,\n-                      max_queue_size=10,\n-                      workers=1,\n-                      use_multiprocessing=False,\n-                      verbose=0):\n-    \"\"\"See docstring for `Model.predict_generator`.\"\"\"\n-    model._make_predict_function()\n-\n-    steps_done = 0\n-    all_outs = []\n-    use_sequence_api = is_sequence(generator)\n-    if not use_sequence_api and use_multiprocessing and workers > 1:\n-        warnings.warn(\n-            UserWarning('Using a generator with `use_multiprocessing=True`'\n-                        ' and multiple workers may duplicate your data.'\n-                        ' Please consider using the `keras.utils.Sequence'\n-                        ' class.'))\n-    if steps is None:\n-        if use_sequence_api:\n-            steps = len(generator)\n-        else:\n-            raise ValueError('`steps=None` is only valid for a generator'\n-                             ' based on the `keras.utils.Sequence` class.'\n-                             ' Please specify `steps` or use the'\n-                             ' `keras.utils.Sequence` class.')\n-    enqueuer = None\n-\n-    # Check if callbacks have not been already configured\n-    if not isinstance(callbacks, cbks.CallbackList):\n-        callbacks = cbks.CallbackList(callbacks)\n-        callback_model = model._get_callback_model()\n-        callbacks.set_model(callback_model)\n-        callback_params = {\n-            'steps': steps,\n-            'verbose': verbose,\n-        }\n-        callbacks.set_params(callback_params)\n-\n-    callbacks.model.stop_training = False\n-    callbacks._call_begin_hook('predict')\n-\n-    try:\n-        if workers > 0:\n-            if use_sequence_api:\n-                enqueuer = OrderedEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing)\n-            else:\n-                enqueuer = GeneratorEnqueuer(\n-                    generator,\n-                    use_multiprocessing=use_multiprocessing)\n-            enqueuer.start(workers=workers, max_queue_size=max_queue_size)\n-            output_generator = enqueuer.get()\n-        else:\n-            if use_sequence_api:\n-                output_generator = iter_sequence_infinite(generator)\n-            else:\n-                output_generator = generator\n-\n-        if verbose == 1:\n-            progbar = Progbar(target=steps)\n-\n-        while steps_done < steps:\n-            generator_output = next(output_generator)\n-            if isinstance(generator_output, tuple):\n-                # Compatibility with the generators\n-                # used for training.\n-                if len(generator_output) == 2:\n-                    x, _ = generator_output\n-                elif len(generator_output) == 3:\n-                    x, _, _ = generator_output\n-                else:\n-                    raise ValueError('Output of generator should be '\n-                                     'a tuple `(x, y, sample_weight)` '\n-                                     'or `(x, y)`. Found: ' +\n-                                     str(generator_output))\n-            else:\n-                # Assumes a generator that only\n-                # yields inputs (not targets and sample weights).\n-                x = generator_output\n-\n-            if x is None or len(x) == 0:\n-                # Handle data tensors support when no input given\n-                # step-size = 1 for data tensors\n-                batch_size = 1\n-            elif isinstance(x, list):\n-                batch_size = x[0].shape[0]\n-            elif isinstance(x, dict):\n-                batch_size = list(x.values())[0].shape[0]\n-            else:\n-                batch_size = x.shape[0]\n-            if batch_size == 0:\n-                raise ValueError('Received an empty batch. '\n-                                 'Batches should contain '\n-                                 'at least one item.')\n-\n-            batch_logs = {'batch': steps_done, 'size': batch_size}\n-            callbacks._call_batch_hook('predict', 'begin', steps_done, batch_logs)\n-\n-            outs = model.predict_on_batch(x)\n-            outs = to_list(outs)\n-\n-            if not all_outs:\n-                for out in outs:\n-                    all_outs.append([])\n-\n-            for i, out in enumerate(outs):\n-                all_outs[i].append(out)\n-\n-            batch_logs['outputs'] = outs\n-            callbacks._call_batch_hook('predict', 'end', steps_done, batch_logs)\n-\n-            steps_done += 1\n-            if verbose == 1:\n-                progbar.update(steps_done)\n-        callbacks._call_end_hook('predict')\n-    finally:\n-        if enqueuer is not None:\n-            enqueuer.stop()\n-\n-    if len(all_outs) == 1:\n-        if steps_done == 1:\n-            return all_outs[0][0]\n-        else:\n-            return np.concatenate(all_outs[0])\n-    if steps_done == 1:\n-        return [out[0] for out in all_outs]\n-    else:\n-        return [np.concatenate(out) for out in all_outs]\n\n@@ -1,1040 +0,0 @@\n-\"\"\"Training-related utilities.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import inspect\n-import collections\n-import copy\n-import numpy as np\n-import six\n-import warnings\n-from collections import OrderedDict\n-\n-from .. import backend as K\n-from .. import losses\n-from .. import metrics as metrics_module\n-from ..utils import Sequence\n-from ..utils import generic_utils\n-from ..utils import losses_utils\n-\n-\n-def standardize_single_array(x):\n-    if x is None:\n-        return None\n-    elif K.is_tensor(x):\n-        shape = K.int_shape(x)\n-        if shape is None or shape[0] is None:\n-            raise ValueError(\n-                'When feeding symbolic tensors to a model, we expect the '\n-                'tensors to have a static batch size. '\n-                'Got tensor with shape: %s' % str(shape))\n-        return x\n-    elif x.ndim == 1:\n-        x = np.expand_dims(x, 1)\n-    return x\n-\n-\n-def standardize_input_data(data,\n-                           names,\n-                           shapes=None,\n-                           check_batch_axis=True,\n-                           exception_prefix=''):\n-    \"\"\"Normalizes inputs and targets provided by users.\n-\n-    Users may pass data as a list of arrays, dictionary of arrays,\n-    or as a single array. We normalize this to an ordered list of\n-    arrays (same order as `names`), while checking that the provided\n-    arrays have shapes that match the network's expectations.\n-\n-    # Arguments\n-        data: User-provided input data (polymorphic).\n-        names: List of expected array names.\n-        shapes: Optional list of expected array shapes.\n-        check_batch_axis: Boolean; whether to check that\n-            the batch axis of the arrays matches the expected\n-            value found in `shapes`.\n-        exception_prefix: String prefix used for exception formatting.\n-\n-    # Returns\n-        List of standardized input arrays (one array per model input).\n-\n-    # Raises\n-        ValueError: in case of improperly formatted user-provided data.\n-    \"\"\"\n-    if not names:\n-        if data is not None and hasattr(data, '__len__') and len(data):\n-            raise ValueError('Error when checking model ' +\n-                             exception_prefix + ': '\n-                             'expected no data, but got:', data)\n-        return []\n-    if data is None:\n-        return [None for _ in range(len(names))]\n-\n-    if isinstance(data, dict):\n-        try:\n-            data = [\n-                data[x].values\n-                if data[x].__class__.__name__ == 'DataFrame' else data[x]\n-                for x in names\n-            ]\n-        except KeyError as e:\n-            raise ValueError('No data provided for \"' + e.args[0] +\n-                             '\". Need data '\n-                             'for each key in: ' + str(names))\n-    elif isinstance(data, list):\n-        if isinstance(data[0], list):\n-            data = [np.asarray(d) for d in data]\n-        elif len(names) == 1 and isinstance(data[0], (float, int)):\n-            data = [np.asarray(data)]\n-        else:\n-            data = [\n-                x.values if x.__class__.__name__ == 'DataFrame'\n-                else x for x in data\n-            ]\n-    else:\n-        data = data.values if data.__class__.__name__ == 'DataFrame' else data\n-        data = [data]\n-    data = [standardize_single_array(x) for x in data]\n-\n-    if len(data) != len(names):\n-        if data and hasattr(data[0], 'shape'):\n-            raise ValueError(\n-                'Error when checking model ' + exception_prefix +\n-                ': the list of Numpy arrays that you are passing to '\n-                'your model is not the size the model expected. '\n-                'Expected to see ' + str(len(names)) + ' array(s), '\n-                'but instead got the following list of ' +\n-                str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n-        elif len(names) > 1:\n-            raise ValueError(\n-                'Error when checking model ' + exception_prefix +\n-                ': you are passing a list as input to your model, '\n-                'but the model expects a list of ' + str(len(names)) +\n-                ' Numpy arrays instead. '\n-                'The list you passed was: ' + str(data)[:200])\n-        elif len(data) == 1 and not hasattr(data[0], 'shape'):\n-            raise TypeError('Error when checking model ' + exception_prefix +\n-                            ': data should be a Numpy array, or list/dict of '\n-                            'Numpy arrays. Found: ' + str(data)[:200] + '...')\n-        elif len(names) == 1:\n-            data = [np.asarray(data)]\n-\n-    # Check shapes compatibility.\n-    if shapes:\n-        for i in range(len(names)):\n-            if shapes[i] is not None and not K.is_tensor(data[i]):\n-                data_shape = data[i].shape\n-                shape = shapes[i]\n-                if data[i].ndim != len(shape):\n-                    raise ValueError(\n-                        'Error when checking ' + exception_prefix +\n-                        ': expected ' + names[i] + ' to have ' +\n-                        str(len(shape)) + ' dimensions, but got array '\n-                        'with shape ' + str(data_shape))\n-                if not check_batch_axis:\n-                    data_shape = data_shape[1:]\n-                    shape = shape[1:]\n-                for dim, ref_dim in zip(data_shape, shape):\n-                    if ref_dim != dim and ref_dim:\n-                        raise ValueError(\n-                            'Error when checking ' + exception_prefix +\n-                            ': expected ' + names[i] + ' to have shape ' +\n-                            str(shape) + ' but got array with shape ' +\n-                            str(data_shape))\n-    return data\n-\n-\n-def standardize_sample_or_class_weights(x_weight,\n-                                        output_names,\n-                                        weight_type):\n-    \"\"\"Maps `sample_weight` or `class_weight` to model outputs.\n-\n-    # Arguments\n-        x_weight: User-provided `sample_weight` or `class_weight` argument.\n-        output_names: List of output names (strings) in the model.\n-        weight_type: A string used purely for exception printing.\n-\n-    # Returns\n-        A list of `sample_weight` or `class_weight` where there are exactly\n-            one element per model output.\n-\n-    # Raises\n-        ValueError: In case of invalid user-provided argument.\n-    \"\"\"\n-    if x_weight is None or len(x_weight) == 0:\n-        return [None for _ in output_names]\n-    if len(output_names) == 1:\n-        if isinstance(x_weight, list) and len(x_weight) == 1:\n-            return x_weight\n-        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n-            return [x_weight[output_names[0]]]\n-        else:\n-            return [x_weight]\n-    if isinstance(x_weight, list):\n-        if len(x_weight) != len(output_names):\n-            raise ValueError('Provided `' + weight_type + '` was a list of ' +\n-                             str(len(x_weight)) +\n-                             ' elements, but the model has ' +\n-                             str(len(output_names)) + ' outputs. '\n-                             'You should provide one `' + weight_type + '`'\n-                             'array per model output.')\n-        return x_weight\n-    if isinstance(x_weight, dict):\n-        x_weights = []\n-        for name in output_names:\n-            x_weights.append(x_weight.get(name))\n-        return x_weights\n-    else:\n-        raise TypeError('The model has multiple outputs, so `' +\n-                        weight_type + '` '\n-                        'should be either a list or a dict. '\n-                        'Provided `' + weight_type +\n-                        '` type not understood: ' +\n-                        str(x_weight))\n-\n-\n-def standardize_class_weights(class_weight, output_names):\n-    return standardize_sample_or_class_weights(class_weight,\n-                                               output_names,\n-                                               'class_weight')\n-\n-\n-def standardize_sample_weights(sample_weight, output_names):\n-    return standardize_sample_or_class_weights(sample_weight,\n-                                               output_names,\n-                                               'sample_weight')\n-\n-\n-def check_array_length_consistency(inputs, targets, weights=None):\n-    \"\"\"Checks if batch axes are the same for Numpy arrays.\n-\n-    # Arguments\n-        inputs: list of Numpy arrays of inputs.\n-        targets: list of Numpy arrays of targets.\n-        weights: list of Numpy arrays of sample weights.\n-\n-    # Raises\n-        ValueError: in case of incorrectly formatted data.\n-    \"\"\"\n-    def set_of_lengths(x):\n-        # return a set with the variation between\n-        # different shapes, with None => 0\n-        if x is None:\n-            return {0}\n-        else:\n-            return set([0 if y is None else int(y.shape[0]) for y in x])\n-\n-    set_x = set_of_lengths(inputs)\n-    set_y = set_of_lengths(targets)\n-    set_w = set_of_lengths(weights)\n-    if len(set_x) > 1:\n-        raise ValueError('All input arrays (x) should have '\n-                         'the same number of samples. Got array shapes: ' +\n-                         str([x.shape for x in inputs]))\n-    if len(set_y) > 1:\n-        raise ValueError('All target arrays (y) should have '\n-                         'the same number of samples. Got array shapes: ' +\n-                         str([y.shape for y in targets]))\n-    if set_x and set_y and list(set_x)[0] != list(set_y)[0]:\n-        raise ValueError('Input arrays should have '\n-                         'the same number of samples as target arrays. '\n-                         'Found ' + str(list(set_x)[0]) + ' input samples '\n-                         'and ' + str(list(set_y)[0]) + ' target samples.')\n-    if len(set_w) > 1:\n-        raise ValueError('All sample_weight arrays should have '\n-                         'the same number of samples. Got array shapes: ' +\n-                         str([w.shape for w in weights]))\n-    if set_y and set_w and list(set_y)[0] != list(set_w)[0]:\n-        raise ValueError('Sample_weight arrays should have '\n-                         'the same number of samples as target arrays. Got ' +\n-                         str(list(set_y)[0]) + ' input samples and ' +\n-                         str(list(set_w)[0]) + ' target samples.')\n-\n-\n-def check_loss_and_target_compatibility(targets, loss_fns, output_shapes):\n-    \"\"\"Does validation on the compatibility of targets and loss functions.\n-\n-    This helps prevent users from using loss functions incorrectly. This check\n-    is purely for UX purposes.\n-\n-    # Arguments\n-        targets: list of Numpy arrays of targets.\n-        loss_fns: list of loss functions.\n-        output_shapes: list of shapes of model outputs.\n-\n-    # Raises\n-        ValueError: if a loss function or target array\n-            is incompatible with an output.\n-    \"\"\"\n-    key_loss_fns = {\n-        losses.mean_squared_error, losses.binary_crossentropy,\n-        losses.categorical_crossentropy\n-    }\n-    key_loss_classes = (losses.MeanSquaredError, losses.BinaryCrossentropy,\n-                        losses.CategoricalCrossentropy)\n-    for y, loss, shape in zip(targets, loss_fns, output_shapes):\n-        if y is None or loss is None:\n-            continue\n-        if losses.is_categorical_crossentropy(loss):\n-            if y.shape[-1] == 1:\n-                raise ValueError(\n-                    'You are passing a target array of shape ' + str(y.shape) +\n-                    ' while using as loss `categorical_crossentropy`. '\n-                    '`categorical_crossentropy` expects '\n-                    'targets to be binary matrices (1s and 0s) '\n-                    'of shape (samples, classes). '\n-                    'If your targets are integer classes, '\n-                    'you can convert them to the expected format via:\\n'\n-                    '```\\n'\n-                    'from keras.utils import to_categorical\\n'\n-                    'y_binary = to_categorical(y_int)\\n'\n-                    '```\\n'\n-                    '\\n'\n-                    'Alternatively, you can use the loss function '\n-                    '`sparse_categorical_crossentropy` instead, '\n-                    'which does expect integer targets.')\n-        is_loss_wrapper = isinstance(loss, losses.LossFunctionWrapper)\n-        if (isinstance(loss, key_loss_classes) or (is_loss_wrapper and\n-                                                   (loss.fn in key_loss_fns))):\n-            for target_dim, out_dim in zip(y.shape[1:], shape[1:]):\n-                if out_dim is not None and target_dim != out_dim:\n-                    loss_name = loss.name\n-                    if loss_name is None:\n-                        loss_type = loss.fn if is_loss_wrapper else type(loss)\n-                        loss_name = loss_type.__name__\n-                    raise ValueError(\n-                        'A target array with shape ' + str(y.shape) +\n-                        ' was passed for an output of shape ' + str(shape) +\n-                        ' while using as loss `' + loss_name + '`. '\n-                        'This loss expects targets to have the same shape '\n-                        'as the output.')\n-\n-\n-def check_generator_arguments(y=None, sample_weight=None,\n-                              validation_split=None):\n-    \"\"\"Validates arguments passed when using a generator.\"\"\"\n-    if y is not None:\n-        raise ValueError('`y` argument is not supported when data is'\n-                         'a generator or Sequence instance. Instead pass targets'\n-                         ' as the second element of the generator.')\n-    if sample_weight is not None:\n-        raise ValueError('`sample_weight` argument is not supported when data is'\n-                         'a generator or Sequence instance. Instead pass sample'\n-                         ' weights as the third element of the generator.')\n-    if validation_split:\n-        raise ValueError('If your data is in the form of a Python generator, '\n-                         'you cannot use `validation_split`.')\n-\n-\n-def batch_shuffle(index_array, batch_size):\n-    \"\"\"Shuffles an array in a batch-wise fashion.\n-\n-    Useful for shuffling HDF5 arrays\n-    (where one cannot access arbitrary indices).\n-\n-    # Arguments\n-        index_array: array of indices to be shuffled.\n-        batch_size: integer.\n-\n-    # Returns\n-        The `index_array` array, shuffled in a batch-wise fashion.\n-    \"\"\"\n-    batch_count = int(len(index_array) / batch_size)\n-    # to reshape we need to be cleanly divisible by batch size\n-    # we stash extra items and reappend them after shuffling\n-    last_batch = index_array[batch_count * batch_size:]\n-    index_array = index_array[:batch_count * batch_size]\n-    index_array = index_array.reshape((batch_count, batch_size))\n-    np.random.shuffle(index_array)\n-    index_array = index_array.flatten()\n-    return np.append(index_array, last_batch)\n-\n-\n-def make_batches(size, batch_size):\n-    \"\"\"Returns a list of batch indices (tuples of indices).\n-\n-    # Arguments\n-        size: Integer, total size of the data to slice into batches.\n-        batch_size: Integer, batch size.\n-\n-    # Returns\n-        A list of tuples of array indices.\n-    \"\"\"\n-    num_batches = (size + batch_size - 1) // batch_size  # round up\n-    return [(i * batch_size, min(size, (i + 1) * batch_size))\n-            for i in range(num_batches)]\n-\n-\n-def weighted_masked_objective(fn):\n-    \"\"\"Adds support for masking and sample-weighting to an objective function.\n-\n-    It transforms an objective function `fn(y_true, y_pred)`\n-    into a sample-weighted, cost-masked objective function\n-    `fn(y_true, y_pred, weights, mask)`.\n-\n-    # Arguments\n-        fn: The objective function to wrap,\n-            with signature `fn(y_true, y_pred)`.\n-\n-    # Returns\n-        A function with signature `fn(y_true, y_pred, weights, mask)`.\n-    \"\"\"\n-    if fn is None:\n-        return None\n-\n-    def weighted(y_true, y_pred, weights, mask=None):\n-        \"\"\"Wrapper function.\n-\n-        # Arguments\n-            y_true: `y_true` argument of `fn`.\n-            y_pred: `y_pred` argument of `fn`.\n-            weights: Weights tensor.\n-            mask: Mask tensor.\n-\n-        # Returns\n-            Scalar tensor.\n-        \"\"\"\n-        # score_array has ndim >= 2\n-        score_array = fn(y_true, y_pred)\n-        if mask is not None:\n-            # Cast the mask to floatX to avoid float64 upcasting in Theano\n-            mask = K.cast(mask, K.floatx())\n-            # mask should have the same shape as score_array\n-            score_array *= mask\n-            #  the loss per batch should be proportional\n-            #  to the number of unmasked samples.\n-            score_array /= K.mean(mask) + K.epsilon()\n-\n-        # apply sample weighting\n-        if weights is not None:\n-            # reduce score_array to same ndim as weight array\n-            ndim = K.ndim(score_array)\n-            weight_ndim = K.ndim(weights)\n-            score_array = K.mean(score_array,\n-                                 axis=list(range(weight_ndim, ndim)))\n-            score_array *= weights\n-            score_array /= K.mean(K.cast(K.not_equal(weights, 0), K.floatx()))\n-        return K.mean(score_array)\n-    return weighted\n-\n-\n-def standardize_weights(y,\n-                        sample_weight=None,\n-                        class_weight=None,\n-                        sample_weight_mode=None):\n-    \"\"\"Performs sample weight validation and standardization.\n-\n-    Everything gets normalized to a single sample-wise (or timestep-wise)\n-    weight array. If both `sample_weights` and `class_weights` are provided,\n-    the weights are multiplied together.\n-\n-    # Arguments\n-        y: Numpy array of model targets to be weighted.\n-        sample_weight: User-provided `sample_weight` argument.\n-        class_weight: User-provided `class_weight` argument.\n-        sample_weight_mode: One of `None` or `\"temporal\"`.\n-            `\"temporal\"` indicated that we expect 2D weight data\n-            that will be applied to the last 2 dimensions of\n-            the targets (i.e. we are weighting timesteps, not samples).\n-\n-    # Returns\n-        A Numpy array of target weights, one entry per sample to weight.\n-\n-    # Raises\n-        ValueError: In case of invalid user-provided arguments.\n-    \"\"\"\n-    if sample_weight_mode is not None:\n-        if sample_weight_mode != 'temporal':\n-            raise ValueError('\"sample_weight_mode '\n-                             'should be None or \"temporal\". '\n-                             'Found: ' + str(sample_weight_mode))\n-        if len(y.shape) < 3:\n-            raise ValueError('Found a sample_weight array for '\n-                             'an input with shape ' +\n-                             str(y.shape) + '. '\n-                             'Timestep-wise sample weighting (use of '\n-                             'sample_weight_mode=\"temporal\") is restricted to '\n-                             'outputs that are at least 3D, i.e. that have '\n-                             'a time dimension.')\n-        if sample_weight is not None and len(sample_weight.shape) != 2:\n-            raise ValueError('Found a sample_weight array with shape ' +\n-                             str(sample_weight.shape) + '. '\n-                             'In order to use timestep-wise sample weighting, '\n-                             'you should pass a 2D sample_weight array.')\n-    else:\n-        if sample_weight is not None and len(sample_weight.shape) != 1:\n-            raise ValueError('Found a sample_weight array with shape ' +\n-                             str(sample_weight.shape) + '. '\n-                             'In order to use timestep-wise sample weights, '\n-                             'you should specify '\n-                             'sample_weight_mode=\"temporal\" '\n-                             'in compile(). If you just mean to use '\n-                             'sample-wise weights, make sure your '\n-                             'sample_weight array is 1D.')\n-\n-    if sample_weight is not None:\n-        if len(sample_weight.shape) > len(y.shape):\n-            raise ValueError('Found a sample_weight with shape' +\n-                             str(sample_weight.shape) + '.'\n-                             'Expected sample_weight with rank '\n-                             'less than or equal to ' + str(len(y.shape)))\n-\n-        if y.shape[:sample_weight.ndim] != sample_weight.shape:\n-            raise ValueError('Found a sample_weight array with shape ' +\n-                             str(sample_weight.shape) +\n-                             ' for an input with shape ' +\n-                             str(y.shape) + '. '\n-                             'sample_weight cannot be broadcast.')\n-\n-    class_sample_weight = None\n-    if isinstance(class_weight, dict):\n-        if len(y.shape) > 2:\n-            raise ValueError('`class_weight` not supported for '\n-                             '3+ dimensional targets.')\n-        if len(y.shape) == 2:\n-            if y.shape[1] > 1:\n-                y_classes = np.argmax(y, axis=1)\n-            elif y.shape[1] == 1:\n-                y_classes = np.reshape(y, y.shape[0])\n-        else:\n-            y_classes = y\n-\n-        class_sample_weight = np.asarray(\n-            [class_weight[cls] for cls in y_classes if cls in class_weight])\n-\n-        if len(class_sample_weight) != len(y_classes):\n-            # subtract the sets to pick all missing classes\n-            existing_classes = set(y_classes)\n-            existing_class_weight = set(class_weight.keys())\n-            raise ValueError('`class_weight` must contain '\n-                             'all classes in the data.'\n-                             ' The classes %s exist in the data but not in '\n-                             '`class_weight`.'\n-                             % (existing_classes - existing_class_weight))\n-\n-    if sample_weight is not None and class_sample_weight is not None:\n-        return sample_weight * class_sample_weight\n-    if sample_weight is not None:\n-        return sample_weight\n-    if class_sample_weight is not None:\n-        return class_sample_weight\n-\n-    # Everything has weight 1 by default.\n-    if sample_weight_mode is None:\n-        return np.ones((y.shape[0],), dtype=K.floatx())\n-    else:\n-        return np.ones((y.shape[0], y.shape[1]), dtype=K.floatx())\n-\n-\n-def check_num_samples(ins,\n-                      batch_size=None,\n-                      steps=None,\n-                      steps_name='steps'):\n-    \"\"\"Checks the number of samples provided for training and evaluation.\n-\n-    The number of samples is not defined when running with `steps`,\n-    in which case the number of samples is set to `None`.\n-\n-    # Arguments\n-        ins: List of tensors to be fed to the Keras function.\n-        batch_size: Integer batch size or `None` if not defined.\n-        steps: Total number of steps (batches of samples)\n-            before declaring `predict_loop` finished.\n-            Ignored with the default value of `None`.\n-        steps_name: The public API's parameter name for `steps`.\n-\n-    # Raises\n-        ValueError: when `steps` is `None` and the attribute `ins.shape`\n-        does not exist. Also raises ValueError when `steps` is not `None`\n-        and `batch_size` is not `None` because they are mutually\n-        exclusive.\n-\n-    # Returns\n-        When `steps` is `None`, returns the number of samples to be\n-        processed based on the size of the first dimension of the\n-        first input Numpy array. When `steps` is not `None` and\n-        `batch_size` is `None`, returns `None`.\n-\n-    # Raises\n-        ValueError: In case of invalid arguments.\n-    \"\"\"\n-    if steps is not None and batch_size is not None:\n-        raise ValueError(\n-            'If ' + steps_name + ' is set, the `batch_size` must be None.')\n-\n-    if not ins or any(K.is_tensor(x) for x in ins):\n-        if steps is None:\n-            raise ValueError(\n-                'If your data is in the form of symbolic tensors, '\n-                'you should specify the `' + steps_name + '` argument '\n-                '(instead of the `batch_size` argument, '\n-                'because symbolic tensors are expected to produce '\n-                'batches of input data).')\n-        return None\n-\n-    if hasattr(ins[0], 'shape'):\n-        return int(ins[0].shape[0])\n-    return None  # Edge case where ins == [static_learning_phase]\n-\n-\n-def iter_sequence_infinite(seq):\n-    \"\"\"Iterate indefinitely over a Sequence.\n-\n-    # Arguments\n-        seq: Sequence object\n-\n-    # Returns\n-        Generator yielding batches.\n-    \"\"\"\n-    while True:\n-        for item in seq:\n-            yield item\n-\n-\n-def is_sequence(seq):\n-    \"\"\"Determine if an object follows the Sequence API.\n-\n-    # Arguments\n-        seq: a possible Sequence object\n-\n-    # Returns\n-        boolean, whether the object follows the Sequence API.\n-    \"\"\"\n-    # TODO Dref360: Decide which pattern to follow. First needs a new TF Version.\n-    return (getattr(seq, 'use_sequence_api', False)\n-            or set(dir(Sequence())).issubset(set(dir(seq) + ['use_sequence_api'])))\n-\n-\n-def is_generator_or_sequence(x):\n-    \"\"\"Check if `x` is a Keras generator type.\"\"\"\n-    return inspect.isgenerator(x) or is_sequence(x)\n-\n-\n-def should_run_validation(validation_freq, epoch):\n-    \"\"\"Checks if validation should be run this epoch.\n-\n-    # Arguments\n-        validation_freq: Integer or list. If an integer, specifies how many training\n-          epochs to run before a new validation run is performed. If a list,\n-          specifies the epochs on which to run validation.\n-        epoch: Integer, the number of the training epoch just completed.\n-\n-    # Returns\n-        Bool, True if validation should be run.\n-\n-    # Raises\n-        ValueError: if `validation_freq` is an Integer and less than 1, or if\n-        it is neither an Integer nor a Sequence.\n-    \"\"\"\n-    # `epoch` is 0-indexed internally but 1-indexed in the public API.\n-    one_indexed_epoch = epoch + 1\n-\n-    if isinstance(validation_freq, int):\n-        if validation_freq < 1:\n-            raise ValueError('`validation_freq` can not be less than 1.')\n-        return one_indexed_epoch % validation_freq == 0\n-\n-    if not isinstance(validation_freq, collections.Container):\n-        raise ValueError('`validation_freq` must be an Integer or '\n-                         '`collections.Container` (e.g. list, tuple, etc.)')\n-    return one_indexed_epoch in validation_freq\n-\n-\n-def get_static_batch_size(layer):\n-    \"\"\"Gets the static batch size of a Layer.\n-\n-    # Arguments\n-        layer: a `Layer` instance.\n-\n-    # Returns\n-        The static batch size of a Layer.\n-    \"\"\"\n-    batch_input_shape, _ = get_input_shape_and_dtype(layer)\n-    if batch_input_shape is not None:\n-        return batch_input_shape[0]\n-    return None\n-\n-\n-def get_input_shape_and_dtype(layer):\n-    \"\"\"Retrieves input shape and input dtype of layer if applicable.\n-\n-    # Arguments\n-        layer: Layer (or model) instance.\n-\n-    # Returns\n-        Tuple (input_shape, input_dtype). Both could be None if the layer\n-        does not have a defined input shape.\n-\n-    # Raises\n-      ValueError: in case an empty Sequential or Functional model is passed.\n-    \"\"\"\n-    def _is_graph_model(layer):\n-        return ((hasattr(layer, '_is_graph_network') and layer._is_graph_network) or\n-                layer.__class__.__name__ == 'Sequential')\n-\n-    # In case of nested models: recover the first layer\n-    # of the deepest model to infer input shape and dtype.\n-    # Subclassed Models may not have been built so can't be checked.\n-    while _is_graph_model(layer):\n-        if not layer.layers:\n-            raise ValueError('An empty Model cannot be used as a Layer.')\n-        layer = layer.layers[0]\n-\n-    if hasattr(layer, '_batch_input_shape'):\n-        return layer._batch_input_shape, layer.dtype\n-    return None, None\n-\n-\n-def get_loss_function(loss):\n-    \"\"\"Returns the loss corresponding to the loss input in `compile` API.\"\"\"\n-    if loss is None or isinstance(loss, losses.Loss):\n-        return loss\n-\n-    # Deserialize loss configuration, if needed.\n-    if isinstance(loss, collections.Mapping):\n-        loss = losses.get(loss)\n-\n-    # Custom callable class.\n-    if callable(loss) and not hasattr(loss, '__name__'):\n-        return loss\n-\n-    # Wrap loss function with signature `(y_true, y_pred, **kwargs)`\n-    # in `LossFunctionWrapper` class.\n-    loss_fn = losses.get(loss)\n-\n-    # For losses which are given as strings/functions in the compile API,\n-    # we always set the loss reduction type to be `SUM_OVER_BATCH_SIZE`..\n-    return losses.LossFunctionWrapper(\n-        loss_fn,\n-        name=loss_fn.__name__,\n-        reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE)\n-\n-\n-def get_output_sample_weight_and_mode(skip_target_weighing_indices,\n-                                      sample_weight_mode, output_name,\n-                                      output_index):\n-    \"\"\"Returns the sample weight and weight mode for a single output.\"\"\"\n-    if output_index in skip_target_weighing_indices:\n-        return None, None\n-\n-    if sample_weight_mode == 'temporal':\n-        shape = [None, None]\n-        mode = 'temporal'\n-    else:\n-        shape = [None]\n-        mode = None\n-    weight = K.placeholder(\n-        shape=shape,\n-        name=output_name + '_sample_weights')\n-    return weight, mode\n-\n-\n-def prepare_sample_weights(output_names, sample_weight_mode,\n-                           skip_target_weighing_indices):\n-    \"\"\"Prepares sample weights for the model.\n-\n-    # Arguments\n-        output_names: List of model output names.\n-        sample_weight_mode: sample weight mode user input passed from compile API.\n-        skip_target_weighing_indices: Indices of output for which sample weights\n-            should be skipped.\n-\n-    # Returns\n-        A pair of list of sample weights and sample weight modes\n-            (one for each output).\n-\n-    # Raises\n-        ValueError: In case of invalid `sample_weight_mode` input.\n-    \"\"\"\n-    sample_weights = []\n-    sample_weight_modes = []\n-    if isinstance(sample_weight_mode, dict):\n-        unknown_output = set(sample_weight_mode.keys()) - set(output_names)\n-        if unknown_output:\n-            raise ValueError(\n-                'Unknown entry in '\n-                'sample_weight_mode dictionary: \"' + str(unknown_output) +\n-                '\". Only expected the following keys: ' + str(output_names))\n-        for i, name in enumerate(output_names):\n-            if (i not in skip_target_weighing_indices and\n-                    name not in sample_weight_mode):\n-                raise ValueError(\n-                    'Output missing from sample_weight_modes dictionary')\n-            weight, mode = get_output_sample_weight_and_mode(\n-                skip_target_weighing_indices,\n-                sample_weight_mode.get(name),\n-                name,\n-                i)\n-            sample_weights.append(weight)\n-            sample_weight_modes.append(mode)\n-    elif isinstance(sample_weight_mode, list):\n-        if len(sample_weight_mode) != len(output_names):\n-            raise ValueError('When passing a list as sample_weight_mode, '\n-                             'it should have one entry per model output. '\n-                             'The model has ' + str(len(output_names)) +\n-                             ' outputs, but you passed ' +\n-                             str(len(sample_weight_mode)) + 'sample_weight_modes')\n-        for i, name in enumerate(output_names):\n-            weight, mode = get_output_sample_weight_and_mode(\n-                skip_target_weighing_indices, sample_weight_mode[i], name, i)\n-            sample_weights.append(weight)\n-            sample_weight_modes.append(mode)\n-    else:\n-        for i, name in enumerate(output_names):\n-            weight, mode = get_output_sample_weight_and_mode(\n-                skip_target_weighing_indices, sample_weight_mode, name, i)\n-            sample_weights.append(weight)\n-            sample_weight_modes.append(mode)\n-    return sample_weights, sample_weight_modes\n-\n-\n-def prepare_loss_functions(loss, output_names):\n-    \"\"\"Converts loss to a list of loss functions.\n-\n-    # Arguments\n-        loss: String (name of objective function), objective function or\n-            `Loss` instance. If the model has multiple outputs, you can use\n-            a different loss on each output by passing a dictionary or a\n-            list of losses. The loss value that will be minimized by the model\n-            will then be the sum of all individual losses.\n-        output_names: List of model output names.\n-\n-    # Returns\n-        A list of loss objective functions.\n-\n-    # Raises:\n-        ValueError: If loss is a dict with keys not in model output names,\n-            or if loss is a list with len not equal to model outputs.\n-    \"\"\"\n-    if isinstance(loss, collections.Mapping):\n-        generic_utils.check_for_unexpected_keys('loss', loss, output_names)\n-        loss_functions = []\n-        for name in output_names:\n-            if name not in loss:\n-                warnings.warn(\n-                    'Output {0} missing from loss dictionary. We assume '\n-                    'this was done on purpose. The fit and evaluate APIs will not '\n-                    'be expecting any data to be passed to {0}.'.format(name))\n-            loss_functions.append(get_loss_function(loss.get(name, None)))\n-    elif isinstance(loss, six.string_types):\n-        loss_functions = [get_loss_function(loss) for _ in output_names]\n-    elif isinstance(loss, collections.Sequence):\n-        if len(loss) != len(output_names):\n-            raise ValueError('When passing a list as loss, it should have one entry '\n-                             'per model outputs. The model has {} outputs, but you '\n-                             'passed loss={}'.format(len(output_names), loss))\n-        loss_functions = [get_loss_function(l) for l in loss]\n-    else:\n-        loss_functions = [get_loss_function(loss) for _ in range(len(output_names))]\n-\n-    return loss_functions\n-\n-\n-def prepare_loss_weights(output_names, loss_weights=None):\n-    \"\"\"Converts loss weights to a list of loss weights.\n-\n-    # Arguments\n-        output_names: List of model output names.\n-        loss_weights: Optional list or dictionary specifying scalar coefficients\n-            (Python floats) to weight the loss contributions of different model\n-            outputs. The loss value that will be minimized by the model will then be\n-            the *weighted sum* of all individual losses, weighted by the\n-            `loss_weights` coefficients. If a list, it is expected to have a 1:1\n-            mapping to the model's outputs. If a dict, it is expected to map\n-            output names (strings) to scalar coefficients.\n-\n-    # Returns\n-        A list of loss weights of python floats.\n-\n-    # Raises\n-        ValueError: If loss weight is a dict with key not in model output names,\n-            or if loss is a list with len not equal to model outputs.\n-    \"\"\"\n-    if loss_weights is None:\n-        weights_list = [1.] * len(output_names)\n-    elif isinstance(loss_weights, collections.Mapping):\n-        generic_utils.check_for_unexpected_keys('loss_weights', loss_weights,\n-                                                output_names)\n-        weights_list = [loss_weights.get(name, 1.) for name in output_names]\n-    elif isinstance(loss_weights, list):\n-        if len(loss_weights) != len(output_names):\n-            raise ValueError('When passing a list as loss_weights, '\n-                             'it should have one entry per model output. '\n-                             'The model has ' + str(len(output_names)) +\n-                             ' outputs, but you passed loss_weights=' +\n-                             str(loss_weights))\n-        weights_list = loss_weights\n-    else:\n-        raise TypeError('Could not interpret loss_weights argument: ' +\n-                        str(loss_weights) + ' - expected a list of dicts.')\n-\n-    return weights_list\n-\n-\n-def collect_per_output_metric_info(metrics,\n-                                   output_names,\n-                                   output_shapes,\n-                                   loss_fns,\n-                                   is_weighted=False):\n-    \"\"\"Maps metric names and functions to model outputs.\n-\n-    # Arguments\n-        metrics: a list or a list of lists or a dict of metric functions.\n-        output_names: a list of the names (strings) of model outputs.\n-        output_shapes: a list of the shapes (strings) of model outputs.\n-        loss_fns: a list of the loss functions corresponding to the model outputs.\n-        is_weighted: Boolean indicating whether the given metrics are weighted.\n-\n-    # Returns\n-        A list (one entry per model output) of dicts.\n-        For instance, if the model has 2 outputs, and for the first output\n-        we want to compute \"binary_accuracy\" and \"binary_crossentropy\",\n-        and just \"binary_accuracy\" for the second output,\n-        the list would look like: `[{\n-            'acc': binary_accuracy(),\n-            'ce': binary_crossentropy(),\n-        }, {\n-            'acc': binary_accuracy(),\n-        }]`\n-\n-    # Raises\n-        TypeError: if an incorrect type is passed for the `metrics` argument.\n-    \"\"\"\n-    if not metrics:\n-        return [{} for _ in output_names]\n-\n-    if isinstance(metrics, list):\n-        any_sub_list = any(isinstance(m, list) for m in metrics)\n-        if any_sub_list:\n-            if len(metrics) != len(output_names):\n-                raise ValueError('When passing a list of lists as `metrics`, '\n-                                 'it should have one entry per model output. '\n-                                 'The model has ' + str(len(output_names)) +\n-                                 ' outputs, but you passed metrics=' + str(metrics))\n-            # User has provided a list of len = len(outputs).\n-            nested_metrics = [generic_utils.to_list(m) for m in metrics]\n-        else:\n-            # If it is a single list we then apply all metrics to all outputs.\n-            if len(output_names) > 1:\n-                nested_metrics = []\n-                for _ in output_names:\n-                    nested_metrics.append(\n-                        [metrics_module.clone_metric(m) for m in metrics])\n-            else:\n-                nested_metrics = [metrics]\n-    elif isinstance(metrics, collections.Mapping):\n-        generic_utils.check_for_unexpected_keys('metrics', metrics, output_names)\n-        nested_metrics = []\n-        for name in output_names:\n-            output_metrics = generic_utils.to_list(metrics.get(name, []))\n-            nested_metrics.append(output_metrics)\n-    else:\n-        raise TypeError('Type of `metrics` argument not understood. '\n-                        'Expected a list or dictionary, found: ' + str(metrics))\n-\n-    per_output_metrics = []\n-    for i, metrics in enumerate(nested_metrics):\n-        metrics_dict = OrderedDict()\n-        for metric in metrics:\n-            metric_name = get_metric_name(metric, is_weighted)\n-            metric_fn = get_metric_function(\n-                metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])\n-\n-            # If the metric function is not stateful, we create a stateful version.\n-            if not isinstance(metric_fn, metrics_module.Metric):\n-                metric_fn = metrics_module.MeanMetricWrapper(\n-                    metric_fn, name=metric_name)\n-            metrics_dict[metric_name] = metric_fn\n-        per_output_metrics.append(metrics_dict)\n-\n-    return per_output_metrics\n-\n-\n-def get_metric_name(metric, weighted=False):\n-    \"\"\"Returns the name corresponding to the given metric input.\n-\n-    # Arguments\n-        metric: Metric function name or reference.\n-        weighted: Boolean indicating if the given metric is weighted.\n-\n-    # Returns\n-        The metric name.\n-    \"\"\"\n-    # We keep the string that the user has set in compile as the metric name.\n-    if isinstance(metric, six.string_types):\n-        return metric\n-\n-    metric = metrics_module.get(metric)\n-    return metric.name if hasattr(metric, 'name') else metric.__name__\n-\n-\n-def get_metric_function(metric, output_shape=None, loss_fn=None):\n-    \"\"\"Returns the metric function corresponding to the given metric input.\n-\n-    # Arguments\n-        metric: Metric function name or reference.\n-        output_shape: The shape of the output that this metric will be calculated\n-            for.\n-        loss_fn: The loss function used.\n-\n-    # Returns\n-        The metric function.\n-    \"\"\"\n-    if metric not in ['accuracy', 'acc', 'crossentropy', 'ce']:\n-        return metrics_module.get(metric)\n-\n-    is_sparse_categorical_crossentropy = (\n-        isinstance(loss_fn, losses.SparseCategoricalCrossentropy) or\n-        (isinstance(loss_fn, losses.LossFunctionWrapper) and\n-         loss_fn.fn == losses.sparse_categorical_crossentropy))\n-\n-    is_binary_crossentropy = (\n-        isinstance(loss_fn, losses.BinaryCrossentropy) or\n-        (isinstance(loss_fn, losses.LossFunctionWrapper) and\n-         loss_fn.fn == losses.binary_crossentropy))\n-\n-    if metric in ['accuracy', 'acc']:\n-        if output_shape[-1] == 1 or is_binary_crossentropy:\n-            return metrics_module.binary_accuracy\n-        elif is_sparse_categorical_crossentropy:\n-            return metrics_module.sparse_categorical_accuracy\n-        # If the output_shape[-1] is not 1, then we know output is `categorical`.\n-        # We assume it is sparse categorical only if loss is explicitly given\n-        # as sparse categorical crossentropy loss.\n-        return metrics_module.categorical_accuracy\n-    else:\n-        if output_shape[-1] == 1 or is_binary_crossentropy:\n-            return metrics_module.binary_crossentropy\n-        elif is_sparse_categorical_crossentropy:\n-            return metrics_module.sparse_categorical_crossentropy\n-        return metrics_module.categorical_crossentropy\n-\n-\n-def call_metric_function(metric_fn,\n-                         y_true,\n-                         y_pred=None,\n-                         weights=None,\n-                         mask=None):\n-    \"\"\"Invokes metric function and returns the metric result tensor.\"\"\"\n-    if mask is not None:\n-        mask = K.cast(mask, y_pred.dtype)\n-        if weights is None:\n-            # Use mask as sample weight.\n-            weights = mask\n-        else:\n-            # Update dimensions of weights to match with mask.\n-            mask, _, weights = losses_utils.squeeze_or_expand_dimensions(\n-                mask, sample_weight=weights)\n-            weights *= mask\n-\n-    if y_pred is not None:\n-        update_ops = metric_fn.update_state(y_true, y_pred, sample_weight=weights)\n-        with K.control_dependencies(update_ops):  # For TF\n-            metric_fn.result()\n-    else:\n-        # `Mean` metric only takes a single value.\n-        update_ops = metric_fn.update_state(y_true, sample_weight=weights)\n-        with K.control_dependencies(update_ops):  # For TF\n-            metric_fn.result()\n\n@@ -1,523 +1,3 @@\n-\"\"\"Built-in weight initializers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Built-in weight initializers.\"\"\"\n \n-import numpy as np\n-import six\n-from . import backend as K\n-from .utils.generic_utils import serialize_keras_object\n-from .utils.generic_utils import deserialize_keras_object\n-\n-\n-class Initializer(object):\n-    \"\"\"Initializer base class: all initializers inherit from this class.\n-    \"\"\"\n-\n-    def __call__(self, shape, dtype=None):\n-        raise NotImplementedError\n-\n-    def get_config(self):\n-        return {}\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        if 'dtype' in config:\n-            # Initializers saved from `tf.keras`\n-            # may contain an unused `dtype` argument.\n-            config.pop('dtype')\n-        return cls(**config)\n-\n-\n-class Zeros(Initializer):\n-    \"\"\"Initializer that generates tensors initialized to 0.\n-    \"\"\"\n-\n-    def __call__(self, shape, dtype=None):\n-        return K.constant(0, shape=shape, dtype=dtype)\n-\n-\n-class Ones(Initializer):\n-    \"\"\"Initializer that generates tensors initialized to 1.\n-    \"\"\"\n-\n-    def __call__(self, shape, dtype=None):\n-        return K.constant(1, shape=shape, dtype=dtype)\n-\n-\n-class Constant(Initializer):\n-    \"\"\"Initializer that generates tensors initialized to a constant value.\n-\n-    # Arguments\n-        value: float; the value of the generator tensors.\n-    \"\"\"\n-\n-    def __init__(self, value=0):\n-        self.value = value\n-\n-    def __call__(self, shape, dtype=None):\n-        return K.constant(self.value, shape=shape, dtype=dtype)\n-\n-    def get_config(self):\n-        return {'value': self.value}\n-\n-\n-class RandomNormal(Initializer):\n-    \"\"\"Initializer that generates tensors with a normal distribution.\n-\n-    # Arguments\n-        mean: a python scalar or a scalar tensor. Mean of the random values\n-          to generate.\n-        stddev: a python scalar or a scalar tensor. Standard deviation of the\n-          random values to generate.\n-        seed: A Python integer. Used to seed the random generator.\n-    \"\"\"\n-\n-    def __init__(self, mean=0., stddev=0.05, seed=None):\n-        self.mean = mean\n-        self.stddev = stddev\n-        self.seed = seed\n-\n-    def __call__(self, shape, dtype=None):\n-        x = K.random_normal(shape, self.mean, self.stddev,\n-                            dtype=dtype, seed=self.seed)\n-        if self.seed is not None:\n-            self.seed += 1\n-        return x\n-\n-    def get_config(self):\n-        return {\n-            'mean': self.mean,\n-            'stddev': self.stddev,\n-            'seed': self.seed\n-        }\n-\n-\n-class RandomUniform(Initializer):\n-    \"\"\"Initializer that generates tensors with a uniform distribution.\n-\n-    # Arguments\n-        minval: A python scalar or a scalar tensor. Lower bound of the range\n-          of random values to generate.\n-        maxval: A python scalar or a scalar tensor. Upper bound of the range\n-          of random values to generate.  Defaults to 1 for float types.\n-        seed: A Python integer. Used to seed the random generator.\n-    \"\"\"\n-\n-    def __init__(self, minval=-0.05, maxval=0.05, seed=None):\n-        self.minval = minval\n-        self.maxval = maxval\n-        self.seed = seed\n-\n-    def __call__(self, shape, dtype=None):\n-        x = K.random_uniform(shape, self.minval, self.maxval,\n-                             dtype=dtype, seed=self.seed)\n-        if self.seed is not None:\n-            self.seed += 1\n-        return x\n-\n-    def get_config(self):\n-        return {\n-            'minval': self.minval,\n-            'maxval': self.maxval,\n-            'seed': self.seed,\n-        }\n-\n-\n-class TruncatedNormal(Initializer):\n-    \"\"\"Initializer that generates a truncated normal distribution.\n-\n-    These values are similar to values from a `RandomNormal`\n-    except that values more than two standard deviations from the mean\n-    are discarded and redrawn. This is the recommended initializer for\n-    neural network weights and filters.\n-\n-    # Arguments\n-        mean: a python scalar or a scalar tensor. Mean of the random values\n-          to generate.\n-        stddev: a python scalar or a scalar tensor. Standard deviation of the\n-          random values to generate.\n-        seed: A Python integer. Used to seed the random generator.\n-    \"\"\"\n-\n-    def __init__(self, mean=0., stddev=0.05, seed=None):\n-        self.mean = mean\n-        self.stddev = stddev\n-        self.seed = seed\n-\n-    def __call__(self, shape, dtype=None):\n-        x = K.truncated_normal(shape, self.mean, self.stddev,\n-                               dtype=dtype, seed=self.seed)\n-        if self.seed is not None:\n-            self.seed += 1\n-        return x\n-\n-    def get_config(self):\n-        return {\n-            'mean': self.mean,\n-            'stddev': self.stddev,\n-            'seed': self.seed\n-        }\n-\n-\n-class VarianceScaling(Initializer):\n-    \"\"\"Initializer capable of adapting its scale to the shape of weights.\n-\n-    With `distribution=\"normal\"`, samples are drawn from a truncated normal\n-    distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n-\n-        - number of input units in the weight tensor, if mode = \"fan_in\"\n-        - number of output units, if mode = \"fan_out\"\n-        - average of the numbers of input and output units, if mode = \"fan_avg\"\n-\n-    With `distribution=\"uniform\"`,\n-    samples are drawn from a uniform distribution\n-    within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n-\n-    # Arguments\n-        scale: Scaling factor (positive float).\n-        mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n-        distribution: Random distribution to use. One of \"normal\", \"uniform\".\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Raises\n-        ValueError: In case of an invalid value for the \"scale\", mode\" or\n-          \"distribution\" arguments.\n-    \"\"\"\n-\n-    def __init__(self, scale=1.0,\n-                 mode='fan_in',\n-                 distribution='normal',\n-                 seed=None):\n-        if scale <= 0.:\n-            raise ValueError('`scale` must be a positive float. Got:', scale)\n-        mode = mode.lower()\n-        if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n-            raise ValueError('Invalid `mode` argument: '\n-                             'expected on of {\"fan_in\", \"fan_out\", \"fan_avg\"} '\n-                             'but got', mode)\n-        distribution = distribution.lower()\n-        if distribution not in {'normal', 'uniform'}:\n-            raise ValueError('Invalid `distribution` argument: '\n-                             'expected one of {\"normal\", \"uniform\"} '\n-                             'but got', distribution)\n-        self.scale = scale\n-        self.mode = mode\n-        self.distribution = distribution\n-        self.seed = seed\n-\n-    def __call__(self, shape, dtype=None):\n-        fan_in, fan_out = _compute_fans(shape)\n-        scale = self.scale\n-        if self.mode == 'fan_in':\n-            scale /= max(1., fan_in)\n-        elif self.mode == 'fan_out':\n-            scale /= max(1., fan_out)\n-        else:\n-            scale /= max(1., float(fan_in + fan_out) / 2)\n-        if self.distribution == 'normal':\n-            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n-            stddev = np.sqrt(scale) / .87962566103423978\n-            x = K.truncated_normal(shape, 0., stddev,\n-                                   dtype=dtype, seed=self.seed)\n-        else:\n-            limit = np.sqrt(3. * scale)\n-            x = K.random_uniform(shape, -limit, limit,\n-                                 dtype=dtype, seed=self.seed)\n-        if self.seed is not None:\n-            self.seed += 1\n-        return x\n-\n-    def get_config(self):\n-        return {\n-            'scale': self.scale,\n-            'mode': self.mode,\n-            'distribution': self.distribution,\n-            'seed': self.seed\n-        }\n-\n-\n-class Orthogonal(Initializer):\n-    \"\"\"Initializer that generates a random orthogonal matrix.\n-\n-    # Arguments\n-        gain: Multiplicative factor to apply to the orthogonal matrix.\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # References\n-        - [Exact solutions to the nonlinear dynamics of learning in deep\n-           linear neural networks](http://arxiv.org/abs/1312.6120)\n-    \"\"\"\n-\n-    def __init__(self, gain=1., seed=None):\n-        self.gain = gain\n-        self.seed = seed\n-\n-    def __call__(self, shape, dtype=None):\n-        num_rows = 1\n-        for dim in shape[:-1]:\n-            num_rows *= dim\n-        num_cols = shape[-1]\n-        flat_shape = (num_rows, num_cols)\n-        rng = np.random\n-        if self.seed is not None:\n-            rng = np.random.RandomState(self.seed)\n-            self.seed += 1\n-        a = rng.normal(0.0, 1.0, flat_shape)\n-        u, _, v = np.linalg.svd(a, full_matrices=False)\n-        # Pick the one with the correct shape.\n-        q = u if u.shape == flat_shape else v\n-        q = q.reshape(shape)\n-        return self.gain * q[:shape[0], :shape[1]]\n-\n-    def get_config(self):\n-        return {\n-            'gain': self.gain,\n-            'seed': self.seed\n-        }\n-\n-\n-class Identity(Initializer):\n-    \"\"\"Initializer that generates the identity matrix.\n-\n-    Only use for 2D matrices.\n-    If the desired matrix is not square, it gets padded\n-    with zeros for the additional rows/columns.\n-\n-    # Arguments\n-        gain: Multiplicative factor to apply to the identity matrix.\n-    \"\"\"\n-\n-    def __init__(self, gain=1.):\n-        self.gain = gain\n-\n-    @K.eager\n-    def __call__(self, shape, dtype=None):\n-        if len(shape) != 2:\n-            raise ValueError(\n-                'Identity matrix initializer '\n-                'can only be used for 2D matrices.')\n-        return self.gain * K.eye((shape[0], shape[1]), dtype=dtype)\n-\n-    def get_config(self):\n-        return {\n-            'gain': self.gain\n-        }\n-\n-\n-def lecun_uniform(seed=None):\n-    \"\"\"LeCun uniform initializer.\n-\n-    It draws samples from a uniform distribution within [-limit, limit]\n-    where `limit` is `sqrt(3 / fan_in)`\n-    where `fan_in` is the number of input units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n-    \"\"\"\n-    return VarianceScaling(scale=1.,\n-                           mode='fan_in',\n-                           distribution='uniform',\n-                           seed=seed)\n-\n-\n-def glorot_normal(seed=None):\n-    \"\"\"Glorot normal initializer, also called Xavier normal initializer.\n-\n-    It draws samples from a truncated normal distribution centered on 0\n-    with `stddev = sqrt(2 / (fan_in + fan_out))`\n-    where `fan_in` is the number of input units in the weight tensor\n-    and `fan_out` is the number of output units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Understanding the difficulty of training deep feedforward neural\n-           networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n-    \"\"\"\n-    return VarianceScaling(scale=1.,\n-                           mode='fan_avg',\n-                           distribution='normal',\n-                           seed=seed)\n-\n-\n-def glorot_uniform(seed=None):\n-    \"\"\"Glorot uniform initializer, also called Xavier uniform initializer.\n-\n-    It draws samples from a uniform distribution within [-limit, limit]\n-    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n-    where `fan_in` is the number of input units in the weight tensor\n-    and `fan_out` is the number of output units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Understanding the difficulty of training deep feedforward neural\n-           networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf)\n-    \"\"\"\n-    return VarianceScaling(scale=1.,\n-                           mode='fan_avg',\n-                           distribution='uniform',\n-                           seed=seed)\n-\n-\n-def he_normal(seed=None):\n-    \"\"\"He normal initializer.\n-\n-    It draws samples from a truncated normal distribution centered on 0\n-    with `stddev = sqrt(2 / fan_in)`\n-    where `fan_in` is the number of input units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n-           ImageNet Classification](http://arxiv.org/abs/1502.01852)\n-    \"\"\"\n-    return VarianceScaling(scale=2.,\n-                           mode='fan_in',\n-                           distribution='normal',\n-                           seed=seed)\n-\n-\n-def lecun_normal(seed=None):\n-    \"\"\"LeCun normal initializer.\n-\n-    It draws samples from a truncated normal distribution centered on 0\n-    with `stddev = sqrt(1 / fan_in)`\n-    where `fan_in` is the number of input units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n-        - [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n-    \"\"\"\n-    return VarianceScaling(scale=1.,\n-                           mode='fan_in',\n-                           distribution='normal',\n-                           seed=seed)\n-\n-\n-def he_uniform(seed=None):\n-    \"\"\"He uniform variance scaling initializer.\n-\n-    It draws samples from a uniform distribution within [-limit, limit]\n-    where `limit` is `sqrt(6 / fan_in)`\n-    where `fan_in` is the number of input units in the weight tensor.\n-\n-    # Arguments\n-        seed: A Python integer. Used to seed the random generator.\n-\n-    # Returns\n-        An initializer.\n-\n-    # References\n-        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n-           ImageNet Classification](http://arxiv.org/abs/1502.01852)\n-    \"\"\"\n-    return VarianceScaling(scale=2.,\n-                           mode='fan_in',\n-                           distribution='uniform',\n-                           seed=seed)\n-\n-\n-# Compatibility aliases\n-\n-zero = zeros = Zeros\n-one = ones = Ones\n-constant = Constant\n-uniform = random_uniform = RandomUniform\n-normal = random_normal = RandomNormal\n-truncated_normal = TruncatedNormal\n-identity = Identity\n-orthogonal = Orthogonal\n-\n-# Utility functions\n-\n-\n-def _compute_fans(shape, data_format='channels_last'):\n-    \"\"\"Computes the number of input and output units for a weight shape.\n-\n-    # Arguments\n-        shape: Integer shape tuple.\n-        data_format: Image data format to use for convolution kernels.\n-            Note that all kernels in Keras are standardized on the\n-            `channels_last` ordering (even when inputs are set\n-            to `channels_first`).\n-\n-    # Returns\n-        A tuple of scalars, `(fan_in, fan_out)`.\n-\n-    # Raises\n-        ValueError: in case of invalid `data_format` argument.\n-    \"\"\"\n-    if len(shape) == 2:\n-        fan_in = shape[0]\n-        fan_out = shape[1]\n-    elif len(shape) in {3, 4, 5}:\n-        # Assuming convolution kernels (1D, 2D or 3D).\n-        # TH kernel shape: (depth, input_depth, ...)\n-        # TF kernel shape: (..., input_depth, depth)\n-        if data_format == 'channels_first':\n-            receptive_field_size = np.prod(shape[2:])\n-            fan_in = shape[1] * receptive_field_size\n-            fan_out = shape[0] * receptive_field_size\n-        elif data_format == 'channels_last':\n-            receptive_field_size = np.prod(shape[:-2])\n-            fan_in = shape[-2] * receptive_field_size\n-            fan_out = shape[-1] * receptive_field_size\n-        else:\n-            raise ValueError('Invalid data_format: ' + data_format)\n-    else:\n-        # No specific assumptions.\n-        fan_in = np.sqrt(np.prod(shape))\n-        fan_out = np.sqrt(np.prod(shape))\n-    return fan_in, fan_out\n-\n-\n-def serialize(initializer):\n-    return serialize_keras_object(initializer)\n-\n-\n-def deserialize(config, custom_objects=None):\n-    return deserialize_keras_object(config,\n-                                    module_objects=globals(),\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='initializer')\n-\n-\n-def get(identifier):\n-    if isinstance(identifier, dict):\n-        return deserialize(identifier)\n-    elif isinstance(identifier, six.string_types):\n-        config = {'class_name': str(identifier), 'config': {}}\n-        return deserialize(config)\n-    elif callable(identifier):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret initializer identifier: ' +\n-                         str(identifier))\n+from tensorflow.keras.initializers import *\n\\ No newline at end of file\n\n@@ -1,168 +1,15 @@\n-from __future__ import absolute_import\n+from tensorflow.keras.layers import *\n \n-from ..utils.generic_utils import deserialize_keras_object\n-from ..engine.base_layer import Layer\n-from ..engine import Input\n-from ..engine import InputLayer\n-from ..engine.base_layer import InputSpec\n-\n-from .merge import Add\n-from .merge import Subtract\n-from .merge import Multiply\n-from .merge import Average\n-from .merge import Maximum\n-from .merge import Minimum\n-from .merge import Concatenate\n-from .merge import Dot\n-from .merge import add\n-from .merge import subtract\n-from .merge import multiply\n-from .merge import average\n-from .merge import maximum\n-from .merge import minimum\n-from .merge import concatenate\n-from .merge import dot\n-\n-from .core import Dense\n-from .core import Activation\n-from .core import Dropout\n-from .core import Flatten\n-from .core import Reshape\n-from .core import Permute\n-from .core import RepeatVector\n-from .core import Lambda\n-from .core import ActivityRegularization\n-from .core import Masking\n-from .core import SpatialDropout1D\n-from .core import SpatialDropout2D\n-from .core import SpatialDropout3D\n-\n-from .convolutional import Conv1D\n-from .convolutional import Conv2D\n-from .convolutional import SeparableConv1D\n-from .convolutional import SeparableConv2D\n-from .convolutional import DepthwiseConv2D\n-from .convolutional import Conv2DTranspose\n-from .convolutional import Conv3D\n-from .convolutional import Conv3DTranspose\n-from .convolutional import Cropping1D\n-from .convolutional import Cropping2D\n-from .convolutional import Cropping3D\n-from .convolutional import UpSampling1D\n-from .convolutional import UpSampling2D\n-from .convolutional import UpSampling3D\n-from .convolutional import ZeroPadding1D\n-from .convolutional import ZeroPadding2D\n-from .convolutional import ZeroPadding3D\n-\n-# Aliases (not in the docs)\n-from .convolutional import Convolution1D\n-from .convolutional import Convolution2D\n-from .convolutional import Convolution3D\n-from .convolutional import Deconvolution2D\n-from .convolutional import Deconvolution3D\n-\n-from .pooling import MaxPooling1D\n-from .pooling import MaxPooling2D\n-from .pooling import MaxPooling3D\n-from .pooling import AveragePooling1D\n-from .pooling import AveragePooling2D\n-from .pooling import AveragePooling3D\n-from .pooling import GlobalMaxPooling1D\n-from .pooling import GlobalMaxPooling2D\n-from .pooling import GlobalMaxPooling3D\n-from .pooling import GlobalAveragePooling2D\n-from .pooling import GlobalAveragePooling1D\n-from .pooling import GlobalAveragePooling3D\n-\n-# Aliases (not in the docs)\n-from .pooling import MaxPool1D\n-from .pooling import MaxPool2D\n-from .pooling import MaxPool3D\n-from .pooling import AvgPool1D\n-from .pooling import AvgPool2D\n-from .pooling import AvgPool3D\n-from .pooling import GlobalMaxPool1D\n-from .pooling import GlobalMaxPool2D\n-from .pooling import GlobalMaxPool3D\n-from .pooling import GlobalAvgPool1D\n-from .pooling import GlobalAvgPool2D\n-from .pooling import GlobalAvgPool3D\n-\n-from .local import LocallyConnected1D\n-from .local import LocallyConnected2D\n-\n-from .recurrent import RNN\n-from .recurrent import SimpleRNN\n-from .recurrent import GRU\n-from .recurrent import LSTM\n-from .recurrent import SimpleRNNCell\n-from .recurrent import GRUCell\n-from .recurrent import LSTMCell\n-from .recurrent import StackedRNNCells\n-\n-from .cudnn_recurrent import CuDNNGRU\n-from .cudnn_recurrent import CuDNNLSTM\n-\n-from .normalization import BatchNormalization\n-\n-from .embeddings import Embedding\n-\n-from .noise import GaussianNoise\n-from .noise import GaussianDropout\n-from .noise import AlphaDropout\n-\n-from .advanced_activations import LeakyReLU\n-from .advanced_activations import PReLU\n-from .advanced_activations import ELU\n-from .advanced_activations import ThresholdedReLU\n-from .advanced_activations import Softmax\n-from .advanced_activations import ReLU\n-\n-from .wrappers import Bidirectional\n-from .wrappers import TimeDistributed\n-\n-from .convolutional_recurrent import ConvLSTM2D\n-from .convolutional_recurrent import ConvLSTM2DCell\n-\n-# Legacy imports\n-from ..legacy.layers import MaxoutDense\n-from ..legacy.layers import Highway\n-from ..legacy.layers import AtrousConvolution1D\n-from ..legacy.layers import AtrousConvolution2D\n-from ..legacy.layers import Recurrent\n-from ..legacy.layers import ConvRecurrent2D\n-\n-\n-def serialize(layer):\n-    \"\"\"Serialize a layer.\n-\n-    # Arguments\n-        layer: a Layer object.\n-\n-    # Returns\n-        dictionary with config.\n-    \"\"\"\n-    return {'class_name': layer.__class__.__name__,\n-            'config': layer.get_config()}\n-\n-\n-def deserialize(config, custom_objects=None):\n-    \"\"\"Instantiate a layer from a config dictionary.\n-\n-    # Arguments\n-        config: dict of the form {'class_name': str, 'config': dict}\n-        custom_objects: dict mapping class names (or function names)\n-            of custom (non-Keras) objects to class/functions\n-\n-    # Returns\n-        Layer instance (may be Model, Sequential, Layer...)\n-    \"\"\"\n-    from .. import models\n-    globs = globals()  # All layers.\n-    globs['Model'] = models.Model\n-    globs['Sequential'] = models.Sequential\n-    return deserialize_keras_object(config,\n-                                    module_objects=globs,\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='layer')\n+from . import advanced_activations\n+from . import convolutional\n+from . import convolutional_recurrent\n+from . import core\n+from . import embeddings\n+from . import experimental\n+from . import local\n+from . import merge\n+from . import noise\n+from . import normalization\n+from . import pooling\n+from . import recurrent\n+from . import wrappers\n\n@@ -1,321 +1,8 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Layers that act as activation functions.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import InputSpec\n-from .. import backend as K\n-from ..legacy import interfaces\n-from ..utils.generic_utils import to_list\n-\n-\n-class LeakyReLU(Layer):\n-    \"\"\"Leaky version of a Rectified Linear Unit.\n-\n-    It allows a small gradient when the unit is not active:\n-    `f(x) = alpha * x for x < 0`,\n-    `f(x) = x for x >= 0`.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        alpha: float >= 0. Negative slope coefficient.\n-\n-    # References\n-        - [Rectifier Nonlinearities Improve Neural Network Acoustic Models](\n-           https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)\n-    \"\"\"\n-\n-    def __init__(self, alpha=0.3, **kwargs):\n-        super(LeakyReLU, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.alpha = K.cast_to_floatx(alpha)\n-\n-    def call(self, inputs):\n-        return K.relu(inputs, alpha=self.alpha)\n-\n-    def get_config(self):\n-        config = {'alpha': float(self.alpha)}\n-        base_config = super(LeakyReLU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class PReLU(Layer):\n-    \"\"\"Parametric Rectified Linear Unit.\n-\n-    It follows:\n-    `f(x) = alpha * x for x < 0`,\n-    `f(x) = x for x >= 0`,\n-    where `alpha` is a learned array with the same shape as x.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        alpha_initializer: initializer function for the weights.\n-        alpha_regularizer: regularizer for the weights.\n-        alpha_constraint: constraint for the weights.\n-        shared_axes: the axes along which to share learnable\n-            parameters for the activation function.\n-            For example, if the incoming feature maps\n-            are from a 2D convolution\n-            with output shape `(batch, height, width, channels)`,\n-            and you wish to share parameters across space\n-            so that each filter only has one set of parameters,\n-            set `shared_axes=[1, 2]`.\n-\n-    # References\n-        - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on\n-           ImageNet Classification](https://arxiv.org/abs/1502.01852)\n-    \"\"\"\n-\n-    @interfaces.legacy_prelu_support\n-    def __init__(self, alpha_initializer='zeros',\n-                 alpha_regularizer=None,\n-                 alpha_constraint=None,\n-                 shared_axes=None,\n-                 **kwargs):\n-        super(PReLU, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.alpha_initializer = initializers.get(alpha_initializer)\n-        self.alpha_regularizer = regularizers.get(alpha_regularizer)\n-        self.alpha_constraint = constraints.get(alpha_constraint)\n-        if shared_axes is None:\n-            self.shared_axes = None\n-        else:\n-            self.shared_axes = to_list(shared_axes, allow_tuple=True)\n-\n-    def build(self, input_shape):\n-        param_shape = list(input_shape[1:])\n-        self.param_broadcast = [False] * len(param_shape)\n-        if self.shared_axes is not None:\n-            for i in self.shared_axes:\n-                param_shape[i - 1] = 1\n-                self.param_broadcast[i - 1] = True\n-        self.alpha = self.add_weight(shape=param_shape,\n-                                     name='alpha',\n-                                     initializer=self.alpha_initializer,\n-                                     regularizer=self.alpha_regularizer,\n-                                     constraint=self.alpha_constraint)\n-        # Set input spec\n-        axes = {}\n-        if self.shared_axes:\n-            for i in range(1, len(input_shape)):\n-                if i not in self.shared_axes:\n-                    axes[i] = input_shape[i]\n-        self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n-        self.built = True\n-\n-    def call(self, inputs, mask=None):\n-        pos = K.relu(inputs)\n-        if K.backend() == 'theano':\n-            neg = (K.pattern_broadcast(self.alpha, self.param_broadcast) *\n-                   (inputs - K.abs(inputs)) * 0.5)\n-        else:\n-            neg = -self.alpha * K.relu(-inputs)\n-        return pos + neg\n-\n-    def get_config(self):\n-        config = {\n-            'alpha_initializer': initializers.serialize(self.alpha_initializer),\n-            'alpha_regularizer': regularizers.serialize(self.alpha_regularizer),\n-            'alpha_constraint': constraints.serialize(self.alpha_constraint),\n-            'shared_axes': self.shared_axes\n-        }\n-        base_config = super(PReLU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class ELU(Layer):\n-    \"\"\"Exponential Linear Unit.\n-\n-    It follows:\n-    `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\n-    `f(x) = x for x >= 0`.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        alpha: scale for the negative factor.\n-\n-    # References\n-        - [Fast and Accurate Deep Network Learning by Exponential Linear Units\n-           (ELUs)](https://arxiv.org/abs/1511.07289v1)\n-    \"\"\"\n-\n-    def __init__(self, alpha=1.0, **kwargs):\n-        super(ELU, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.alpha = K.cast_to_floatx(alpha)\n-\n-    def call(self, inputs):\n-        return K.elu(inputs, self.alpha)\n-\n-    def get_config(self):\n-        config = {'alpha': float(self.alpha)}\n-        base_config = super(ELU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class ThresholdedReLU(Layer):\n-    \"\"\"Thresholded Rectified Linear Unit.\n-\n-    It follows:\n-    `f(x) = x for x > theta`,\n-    `f(x) = 0 otherwise`.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        theta: float >= 0. Threshold location of activation.\n-\n-    # References\n-        - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](\n-           https://arxiv.org/abs/1402.3337)\n-    \"\"\"\n-\n-    def __init__(self, theta=1.0, **kwargs):\n-        super(ThresholdedReLU, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.theta = K.cast_to_floatx(theta)\n-\n-    def call(self, inputs, mask=None):\n-        return inputs * K.cast(K.greater(inputs, self.theta), K.floatx())\n-\n-    def get_config(self):\n-        config = {'theta': float(self.theta)}\n-        base_config = super(ThresholdedReLU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class Softmax(Layer):\n-    \"\"\"Softmax activation function.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        axis: Integer, axis along which the softmax normalization is applied.\n-    \"\"\"\n-\n-    def __init__(self, axis=-1, **kwargs):\n-        super(Softmax, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.axis = axis\n-\n-    def call(self, inputs):\n-        return activations.softmax(inputs, axis=self.axis)\n-\n-    def get_config(self):\n-        config = {'axis': self.axis}\n-        base_config = super(Softmax, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class ReLU(Layer):\n-    \"\"\"Rectified Linear Unit activation function.\n-\n-    With default values, it returns element-wise `max(x, 0)`.\n-\n-    Otherwise, it follows:\n-    `f(x) = max_value` for `x >= max_value`,\n-    `f(x) = x` for `threshold <= x < max_value`,\n-    `f(x) = negative_slope * (x - threshold)` otherwise.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as the input.\n-\n-    # Arguments\n-        max_value: float >= 0. Maximum activation value.\n-        negative_slope: float >= 0. Negative slope coefficient.\n-        threshold: float. Threshold value for thresholded activation.\n-    \"\"\"\n-\n-    def __init__(self, max_value=None, negative_slope=0.,\n-                 threshold=0., **kwargs):\n-        super(ReLU, self).__init__(**kwargs)\n-        if max_value is not None and max_value < 0.:\n-            raise ValueError('max_value of ReLU layer '\n-                             'cannot be negative value: %s' % str(max_value))\n-        if negative_slope < 0.:\n-            raise ValueError('negative_slope of ReLU layer cannot be '\n-                             'negative value: %s' % str(negative_slope))\n-        self.supports_masking = True\n-        if max_value is not None:\n-            max_value = K.cast_to_floatx(max_value)\n-        self.max_value = max_value\n-        self.negative_slope = K.cast_to_floatx(negative_slope)\n-        self.threshold = K.cast_to_floatx(threshold)\n-\n-    def call(self, inputs):\n-        return K.relu(inputs,\n-                      alpha=self.negative_slope,\n-                      max_value=self.max_value,\n-                      threshold=self.threshold)\n-\n-    def get_config(self):\n-        config = {\n-            'max_value': self.max_value,\n-            'negative_slope': self.negative_slope,\n-            'threshold': self.threshold\n-        }\n-        base_config = super(ReLU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+\"\"\"Layers that act as activation functions.\"\"\"\n+\n+from tensorflow.keras.layers import LeakyReLU\n+from tensorflow.keras.layers import PReLU\n+from tensorflow.keras.layers import ELU\n+from tensorflow.keras.layers import ThresholdedReLU\n+from tensorflow.keras.layers import Softmax\n+from tensorflow.keras.layers import ReLU\n\n@@ -1,2572 +1,21 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Convolutional layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from .. import backend as K\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import InputSpec\n-from ..utils import conv_utils\n-from ..utils.generic_utils import transpose_shape\n-from ..legacy import interfaces\n-\n-# imports for backwards namespace compatibility\n-from .pooling import AveragePooling1D\n-from .pooling import AveragePooling2D\n-from .pooling import AveragePooling3D\n-from .pooling import MaxPooling1D\n-from .pooling import MaxPooling2D\n-from .pooling import MaxPooling3D\n-\n-from ..legacy.layers import AtrousConvolution1D\n-from ..legacy.layers import AtrousConvolution2D\n-\n-\n-class _Conv(Layer):\n-    \"\"\"Abstract nD convolution layer (private, used as implementation base).\n-\n-    This layer creates a convolution kernel that is convolved\n-    with the layer input to produce a tensor of outputs.\n-    If `use_bias` is True, a bias vector is created and added to the outputs.\n-    Finally, if `activation` is not `None`,\n-    it is applied to the outputs as well.\n-\n-    # Arguments\n-        rank: An integer, the rank of the convolution,\n-            e.g. \"2\" for 2D convolution.\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of n integers, specifying the\n-            dimensions of the convolution window.\n-        strides: An integer or tuple/list of n integers,\n-            specifying the strides of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n-            inputs with shape `(batch, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: An integer or tuple/list of n integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-    \"\"\"\n-\n-    def __init__(self, rank,\n-                 filters,\n-                 kernel_size,\n-                 strides=1,\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=1,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(_Conv, self).__init__(**kwargs)\n-        self.rank = rank\n-        self.filters = filters\n-        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank,\n-                                                      'kernel_size')\n-        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank,\n-                                                        'dilation_rate')\n-        self.activation = activations.get(activation)\n-        self.use_bias = use_bias\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-        self.input_spec = InputSpec(ndim=self.rank + 2)\n-\n-    def build(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = -1\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs '\n-                             'should be defined. Found `None`.')\n-        input_dim = input_shape[channel_axis]\n-        kernel_shape = self.kernel_size + (input_dim, self.filters)\n-\n-        self.kernel = self.add_weight(shape=kernel_shape,\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.filters,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=self.rank + 2,\n-                                    axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs):\n-        if self.rank == 1:\n-            outputs = K.conv1d(\n-                inputs,\n-                self.kernel,\n-                strides=self.strides[0],\n-                padding=self.padding,\n-                data_format=self.data_format,\n-                dilation_rate=self.dilation_rate[0])\n-        if self.rank == 2:\n-            outputs = K.conv2d(\n-                inputs,\n-                self.kernel,\n-                strides=self.strides,\n-                padding=self.padding,\n-                data_format=self.data_format,\n-                dilation_rate=self.dilation_rate)\n-        if self.rank == 3:\n-            outputs = K.conv3d(\n-                inputs,\n-                self.kernel,\n-                strides=self.strides,\n-                padding=self.padding,\n-                data_format=self.data_format,\n-                dilation_rate=self.dilation_rate)\n-\n-        if self.use_bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_last':\n-            space = input_shape[1:-1]\n-        elif self.data_format == 'channels_first':\n-            space = input_shape[2:]\n-        new_space = []\n-        for i in range(len(space)):\n-            new_dim = conv_utils.conv_output_length(\n-                space[i],\n-                self.kernel_size[i],\n-                padding=self.padding,\n-                stride=self.strides[i],\n-                dilation=self.dilation_rate[i])\n-            new_space.append(new_dim)\n-        if self.data_format == 'channels_last':\n-            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n-        elif self.data_format == 'channels_first':\n-            return (input_shape[0], self.filters) + tuple(new_space)\n-\n-    def get_config(self):\n-        config = {\n-            'rank': self.rank,\n-            'filters': self.filters,\n-            'kernel_size': self.kernel_size,\n-            'strides': self.strides,\n-            'padding': self.padding,\n-            'data_format': self.data_format,\n-            'dilation_rate': self.dilation_rate,\n-            'activation': activations.serialize(self.activation),\n-            'use_bias': self.use_bias,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)\n-        }\n-        base_config = super(_Conv, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Conv1D(_Conv):\n-    \"\"\"1D convolution layer (e.g. temporal convolution).\n-\n-    This layer creates a convolution kernel that is convolved\n-    with the layer input over a single spatial (or temporal) dimension\n-    to produce a tensor of outputs.\n-    If `use_bias` is True, a bias vector is created and added to the outputs.\n-    Finally, if `activation` is not `None`,\n-    it is applied to the outputs as well.\n-\n-    When using this layer as the first layer in a model,\n-    provide an `input_shape` argument (tuple of integers or `None`, does not\n-    include the batch axis), e.g. `input_shape=(10, 128)` for time series\n-    sequences of 10 time steps with 128 features per step in\n-    `data_format=\"channels_last\"`, or `(None, 128)` for variable-length\n-    sequences with 128 features per step.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of a single integer,\n-            specifying the length of the 1D convolution window.\n-        strides: An integer or tuple/list of a single integer,\n-            specifying the stride length of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: One of `\"valid\"`, `\"causal\"` or `\"same\"` (case-insensitive).\n-            `\"valid\"` means \"no padding\".\n-            `\"same\"` results in padding the input such that\n-            the output has the same length as the original input.\n-            `\"causal\"` results in causal (dilated) convolutions,\n-            e.g. `output[t]` does not depend on `input[t + 1:]`.\n-            A zero padding is used such that\n-            the output has the same length as the original input.\n-            Useful when modeling temporal data where the model\n-            should not violate the temporal order. See\n-            [WaveNet: A Generative Model for Raw Audio, section 2.1](\n-            https://arxiv.org/abs/1609.03499).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, channels)`\n-            (default format for temporal data in Keras)\n-            while `\"channels_first\"` corresponds to inputs\n-            with shape `(batch, channels, steps)`.\n-        dilation_rate: an integer or tuple/list of a single integer, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        3D tensor with shape: `(batch, steps, channels)`\n-\n-    # Output shape\n-        3D tensor with shape: `(batch, new_steps, filters)`\n-        `steps` value might have changed due to padding or strides.\n-    \"\"\"\n-\n-    @interfaces.legacy_conv1d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=1,\n-                 padding='valid',\n-                 data_format='channels_last',\n-                 dilation_rate=1,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        if padding == 'causal':\n-            if data_format != 'channels_last':\n-                raise ValueError('When using causal padding in `Conv1D`, '\n-                                 '`data_format` must be \"channels_last\" '\n-                                 '(temporal data).')\n-        super(Conv1D, self).__init__(\n-            rank=1,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            kernel_initializer=kernel_initializer,\n-            bias_initializer=bias_initializer,\n-            kernel_regularizer=kernel_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            kernel_constraint=kernel_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-    def get_config(self):\n-        config = super(Conv1D, self).get_config()\n-        config.pop('rank')\n-        return config\n-\n-\n-class Conv2D(_Conv):\n-    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n-\n-    This layer creates a convolution kernel that is convolved\n-    with the layer input to produce a tensor of\n-    outputs. If `use_bias` is True,\n-    a bias vector is created and added to the outputs. Finally, if\n-    `activation` is not `None`, it is applied to the outputs as well.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the batch axis),\n-    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n-    in `data_format=\"channels_last\"`.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            height and width of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution\n-            along the height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-            Note that `\"same\"` is slightly inconsistent across backends with\n-            `strides` != 1, as described\n-            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: an integer or tuple/list of 2 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(batch, channels, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    @interfaces.legacy_conv2d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(Conv2D, self).__init__(\n-            rank=2,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            kernel_initializer=kernel_initializer,\n-            bias_initializer=bias_initializer,\n-            kernel_regularizer=kernel_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            kernel_constraint=kernel_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-    def get_config(self):\n-        config = super(Conv2D, self).get_config()\n-        config.pop('rank')\n-        return config\n-\n-\n-class Conv3D(_Conv):\n-    \"\"\"3D convolution layer (e.g. spatial convolution over volumes).\n-\n-    This layer creates a convolution kernel that is convolved\n-    with the layer input to produce a tensor of\n-    outputs. If `use_bias` is True,\n-    a bias vector is created and added to the outputs. Finally, if\n-    `activation` is not `None`, it is applied to the outputs as well.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the batch axis),\n-    e.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\n-    with a single channel,\n-    in `data_format=\"channels_last\"`.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 3 integers, specifying the\n-            depth, height and width of the 3D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 3 integers,\n-            specifying the strides of the convolution along each spatial dimension.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: an integer or tuple/list of 3 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        5D tensor with shape:\n-        `(batch, channels, conv_dim1, conv_dim2, conv_dim3)`\n-        if `data_format` is `\"channels_first\"`\n-        or 5D tensor with shape:\n-        `(batch, conv_dim1, conv_dim2, conv_dim3, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        5D tensor with shape:\n-        `(batch, filters, new_conv_dim1, new_conv_dim2, new_conv_dim3)`\n-        if `data_format` is `\"channels_first\"`\n-        or 5D tensor with shape:\n-        `(batch, new_conv_dim1, new_conv_dim2, new_conv_dim3, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have\n-        changed due to padding.\n-    \"\"\"\n-\n-    @interfaces.legacy_conv3d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1, 1),\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(Conv3D, self).__init__(\n-            rank=3,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            kernel_initializer=kernel_initializer,\n-            bias_initializer=bias_initializer,\n-            kernel_regularizer=kernel_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            kernel_constraint=kernel_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-    def get_config(self):\n-        config = super(Conv3D, self).get_config()\n-        config.pop('rank')\n-        return config\n-\n-\n-class Conv2DTranspose(Conv2D):\n-    \"\"\"Transposed convolution layer (sometimes called Deconvolution).\n-\n-    The need for transposed convolutions generally arises\n-    from the desire to use a transformation going in the opposite direction\n-    of a normal convolution, i.e., from something that has the shape of the\n-    output of some convolution to something that has the shape of its input\n-    while maintaining a connectivity pattern that is compatible with\n-    said convolution.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the batch axis),\n-    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n-    in `data_format=\"channels_last\"`.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            height and width of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution\n-            along the height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        output_padding: An integer or tuple/list of 2 integers,\n-            specifying the amount of padding along the height and width\n-            of the output tensor.\n-            Can be a single integer to specify the same value for all\n-            spatial dimensions.\n-            The amount of output padding along a given dimension must be\n-            lower than the stride along that same dimension.\n-            If set to `None` (default), the output shape is inferred.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: an integer or tuple/list of 2 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(batch, channels, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `rows` and `cols` values might have changed due to padding.\n-        If `output_padding` is specified:\n-\n-        ```\n-        new_rows = ((rows - 1) * strides[0] + kernel_size[0]\n-                    - 2 * padding[0] + output_padding[0])\n-        new_cols = ((cols - 1) * strides[1] + kernel_size[1]\n-                    - 2 * padding[1] + output_padding[1])\n-        ```\n-\n-    # References\n-        - [A guide to convolution arithmetic for deep learning](\n-           https://arxiv.org/abs/1603.07285v1)\n-        - [Deconvolutional Networks](\n-           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n-    \"\"\"\n-\n-    @interfaces.legacy_deconv2d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 output_padding=None,\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(Conv2DTranspose, self).__init__(\n-            filters,\n-            kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            kernel_initializer=kernel_initializer,\n-            bias_initializer=bias_initializer,\n-            kernel_regularizer=kernel_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            kernel_constraint=kernel_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-        self.output_padding = output_padding\n-        if self.output_padding is not None:\n-            self.output_padding = conv_utils.normalize_tuple(\n-                self.output_padding, 2, 'output_padding')\n-            for stride, out_pad in zip(self.strides, self.output_padding):\n-                if out_pad >= stride:\n-                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n-                                     'greater than output padding ' +\n-                                     str(self.output_padding))\n-\n-    def build(self, input_shape):\n-        if len(input_shape) != 4:\n-            raise ValueError('Inputs should have rank ' +\n-                             str(4) +\n-                             '; Received input shape:', str(input_shape))\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = -1\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs '\n-                             'should be defined. Found `None`.')\n-        input_dim = input_shape[channel_axis]\n-        kernel_shape = self.kernel_size + (self.filters, input_dim)\n-\n-        self.kernel = self.add_weight(shape=kernel_shape,\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.filters,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs):\n-        input_shape = K.shape(inputs)\n-        batch_size = input_shape[0]\n-        if self.data_format == 'channels_first':\n-            h_axis, w_axis = 2, 3\n-        else:\n-            h_axis, w_axis = 1, 2\n-\n-        height, width = input_shape[h_axis], input_shape[w_axis]\n-        kernel_h, kernel_w = self.kernel_size\n-        stride_h, stride_w = self.strides\n-        if self.output_padding is None:\n-            out_pad_h = out_pad_w = None\n-        else:\n-            out_pad_h, out_pad_w = self.output_padding\n-\n-        # Infer the dynamic output shape:\n-        out_height = conv_utils.deconv_length(height,\n-                                              stride_h, kernel_h,\n-                                              self.padding,\n-                                              out_pad_h,\n-                                              self.dilation_rate[0])\n-        out_width = conv_utils.deconv_length(width,\n-                                             stride_w, kernel_w,\n-                                             self.padding,\n-                                             out_pad_w,\n-                                             self.dilation_rate[1])\n-        if self.data_format == 'channels_first':\n-            output_shape = (batch_size, self.filters, out_height, out_width)\n-        else:\n-            output_shape = (batch_size, out_height, out_width, self.filters)\n-\n-        outputs = K.conv2d_transpose(\n-            inputs,\n-            self.kernel,\n-            output_shape,\n-            self.strides,\n-            padding=self.padding,\n-            data_format=self.data_format,\n-            dilation_rate=self.dilation_rate)\n-\n-        if self.use_bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        output_shape = list(input_shape)\n-        if self.data_format == 'channels_first':\n-            c_axis, h_axis, w_axis = 1, 2, 3\n-        else:\n-            c_axis, h_axis, w_axis = 3, 1, 2\n-\n-        kernel_h, kernel_w = self.kernel_size\n-        stride_h, stride_w = self.strides\n-        if self.output_padding is None:\n-            out_pad_h = out_pad_w = None\n-        else:\n-            out_pad_h, out_pad_w = self.output_padding\n-\n-        output_shape[c_axis] = self.filters\n-        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n-                                                        stride_h,\n-                                                        kernel_h,\n-                                                        self.padding,\n-                                                        out_pad_h,\n-                                                        self.dilation_rate[0])\n-        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n-                                                        stride_w,\n-                                                        kernel_w,\n-                                                        self.padding,\n-                                                        out_pad_w,\n-                                                        self.dilation_rate[1])\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = super(Conv2DTranspose, self).get_config()\n-        config['output_padding'] = self.output_padding\n-        return config\n-\n-\n-class Conv3DTranspose(Conv3D):\n-    \"\"\"Transposed convolution layer (sometimes called Deconvolution).\n-\n-    The need for transposed convolutions generally arises\n-    from the desire to use a transformation going in the opposite direction\n-    of a normal convolution, i.e., from something that has the shape of the\n-    output of some convolution to something that has the shape of its input\n-    while maintaining a connectivity pattern that is compatible with\n-    said convolution.\n-\n-    When using this layer as the first layer in a model,\n-    provide the keyword argument `input_shape`\n-    (tuple of integers, does not include the batch axis),\n-    e.g. `input_shape=(128, 128, 128, 3)` for a 128x128x128 volume with 3 channels\n-    if `data_format=\"channels_last\"`.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 3 integers, specifying the\n-            depth, height and width of the 3D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 3 integers,\n-            specifying the strides of the convolution\n-            along the depth, height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        output_padding: An integer or tuple/list of 3 integers,\n-            specifying the amount of padding along the depth, height, and\n-            width.\n-            Can be a single integer to specify the same value for all\n-            spatial dimensions.\n-            The amount of output padding along a given dimension must be\n-            lower than the stride along that same dimension.\n-            If set to `None` (default), the output shape is inferred.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, depth, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, depth, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: an integer or tuple/list of 3 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        5D tensor with shape:\n-        `(batch, channels, depth, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 5D tensor with shape:\n-        `(batch, depth, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        5D tensor with shape:\n-        `(batch, filters, new_depth, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 5D tensor with shape:\n-        `(batch, new_depth, new_rows, new_cols, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `depth` and `rows` and `cols` values might have changed due to padding.\n-        If `output_padding` is specified::\n-\n-        ```\n-        new_depth = ((depth - 1) * strides[0] + kernel_size[0]\n-                     - 2 * padding[0] + output_padding[0])\n-        new_rows = ((rows - 1) * strides[1] + kernel_size[1]\n-                    - 2 * padding[1] + output_padding[1])\n-        new_cols = ((cols - 1) * strides[2] + kernel_size[2]\n-                    - 2 * padding[2] + output_padding[2])\n-        ```\n-\n-    # References\n-        - [A guide to convolution arithmetic for deep learning](\n-           https://arxiv.org/abs/1603.07285v1)\n-        - [Deconvolutional Networks](\n-           https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n-    \"\"\"\n-\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1, 1),\n-                 padding='valid',\n-                 output_padding=None,\n-                 data_format=None,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(Conv3DTranspose, self).__init__(\n-            filters,\n-            kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            activation=activation,\n-            use_bias=use_bias,\n-            kernel_initializer=kernel_initializer,\n-            bias_initializer=bias_initializer,\n-            kernel_regularizer=kernel_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            kernel_constraint=kernel_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-        self.output_padding = output_padding\n-        if self.output_padding is not None:\n-            self.output_padding = conv_utils.normalize_tuple(\n-                self.output_padding, 3, 'output_padding')\n-            for stride, out_pad in zip(self.strides, self.output_padding):\n-                if out_pad >= stride:\n-                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n-                                     'greater than output padding ' +\n-                                     str(self.output_padding))\n-\n-    def build(self, input_shape):\n-        if len(input_shape) != 5:\n-            raise ValueError('Inputs should have rank ' +\n-                             str(5) +\n-                             '; Received input shape:', str(input_shape))\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = -1\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs '\n-                             'should be defined. Found `None`.')\n-        input_dim = input_shape[channel_axis]\n-        kernel_shape = self.kernel_size + (self.filters, input_dim)\n-\n-        self.kernel = self.add_weight(shape=kernel_shape,\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.filters,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=5, axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs):\n-        input_shape = K.shape(inputs)\n-        batch_size = input_shape[0]\n-        if self.data_format == 'channels_first':\n-            d_axis, h_axis, w_axis = 2, 3, 4\n-        else:\n-            d_axis, h_axis, w_axis = 1, 2, 3\n-\n-        depth = input_shape[d_axis]\n-        height = input_shape[h_axis]\n-        width = input_shape[w_axis]\n-\n-        kernel_d, kernel_h, kernel_w = self.kernel_size\n-        stride_d, stride_h, stride_w = self.strides\n-        if self.output_padding is None:\n-            out_pad_d = out_pad_h = out_pad_w = None\n-        else:\n-            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n-\n-        # Infer the dynamic output shape:\n-        out_depth = conv_utils.deconv_length(depth,\n-                                             stride_d, kernel_d,\n-                                             self.padding,\n-                                             out_pad_d)\n-        out_height = conv_utils.deconv_length(height,\n-                                              stride_h, kernel_h,\n-                                              self.padding,\n-                                              out_pad_h)\n-        out_width = conv_utils.deconv_length(width,\n-                                             stride_w, kernel_w,\n-                                             self.padding,\n-                                             out_pad_w)\n-\n-        if self.data_format == 'channels_first':\n-            output_shape = (batch_size, self.filters,\n-                            out_depth, out_height, out_width)\n-        else:\n-            output_shape = (batch_size, out_depth,\n-                            out_height, out_width, self.filters)\n-\n-        outputs = K.conv3d_transpose(inputs,\n-                                     self.kernel,\n-                                     output_shape,\n-                                     self.strides,\n-                                     padding=self.padding,\n-                                     data_format=self.data_format)\n-\n-        if self.use_bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        output_shape = list(input_shape)\n-        if self.data_format == 'channels_first':\n-            c_axis, d_axis, h_axis, w_axis = 1, 2, 3, 4\n-        else:\n-            c_axis, d_axis, h_axis, w_axis = 4, 1, 2, 3\n-\n-        kernel_d, kernel_h, kernel_w = self.kernel_size\n-        stride_d, stride_h, stride_w = self.strides\n-        if self.output_padding is None:\n-            out_pad_d = out_pad_h = out_pad_w = None\n-        else:\n-            out_pad_d, out_pad_h, out_pad_w = self.output_padding\n-\n-        output_shape[c_axis] = self.filters\n-        output_shape[d_axis] = conv_utils.deconv_length(output_shape[d_axis],\n-                                                        stride_d,\n-                                                        kernel_d,\n-                                                        self.padding,\n-                                                        out_pad_d)\n-        output_shape[h_axis] = conv_utils.deconv_length(output_shape[h_axis],\n-                                                        stride_h,\n-                                                        kernel_h,\n-                                                        self.padding,\n-                                                        out_pad_h)\n-        output_shape[w_axis] = conv_utils.deconv_length(output_shape[w_axis],\n-                                                        stride_w,\n-                                                        kernel_w,\n-                                                        self.padding,\n-                                                        out_pad_w)\n-\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = super(Conv3DTranspose, self).get_config()\n-        config.pop('dilation_rate')\n-        config['output_padding'] = self.output_padding\n-        return config\n-\n-\n-class _SeparableConv(_Conv):\n-    \"\"\"Abstract nD depthwise separable convolution layer (private).\n-\n-    Separable convolutions consist in first performing\n-    a depthwise spatial convolution\n-    (which acts on each input channel separately)\n-    followed by a pointwise convolution which mixes together the resulting\n-    output channels. The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    Intuitively, separable convolutions can be understood as\n-    a way to factorize a convolution kernel into two smaller kernels,\n-    or as an extreme version of an Inception block.\n-\n-    # Arguments\n-        rank: An integer, the rank of the convolution,\n-            e.g. \"2\" for 2D convolution.\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            height and width of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution\n-            along the height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: an integer or tuple/list of n integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel.\n-            The total number of depthwise convolution output\n-            channels will be equal to `filters_in * depth_multiplier`.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        depthwise_initializer: Initializer for the depthwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        pointwise_initializer: Initializer for the pointwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        depthwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        pointwise_regularizer: Regularizer function applied to\n-            the pointwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        depthwise_constraint: Constraint function applied to\n-            the depthwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        pointwise_constraint: Constraint function applied to\n-            the pointwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(batch, channels, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self, rank,\n-                 filters,\n-                 kernel_size,\n-                 strides=1,\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=1,\n-                 depth_multiplier=1,\n-                 activation=None,\n-                 use_bias=True,\n-                 depthwise_initializer='glorot_uniform',\n-                 pointwise_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 depthwise_regularizer=None,\n-                 pointwise_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 depthwise_constraint=None,\n-                 pointwise_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(_SeparableConv, self).__init__(\n-            rank=rank,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            bias_initializer=bias_initializer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-        self.depth_multiplier = depth_multiplier\n-        self.depthwise_initializer = initializers.get(depthwise_initializer)\n-        self.pointwise_initializer = initializers.get(pointwise_initializer)\n-        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n-        self.pointwise_regularizer = regularizers.get(pointwise_regularizer)\n-        self.depthwise_constraint = constraints.get(depthwise_constraint)\n-        self.pointwise_constraint = constraints.get(pointwise_constraint)\n-\n-    def build(self, input_shape):\n-        if len(input_shape) < self.rank + 2:\n-            raise ValueError('Inputs to `SeparableConv' + str(self.rank) + 'D` '\n-                             'should have rank ' + str(self.rank + 2) + '. '\n-                             'Received input shape:', str(input_shape))\n-        channel_axis = 1 if self.data_format == 'channels_first' else -1\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs '\n-                             'should be defined. Found `None`.')\n-        input_dim = int(input_shape[channel_axis])\n-        depthwise_kernel_shape = (input_dim, self.depth_multiplier)\n-        depthwise_kernel_shape = self.kernel_size + depthwise_kernel_shape\n-        pointwise_kernel_shape = (self.depth_multiplier * input_dim, self.filters)\n-        pointwise_kernel_shape = (1,) * self.rank + pointwise_kernel_shape\n-\n-        self.depthwise_kernel = self.add_weight(\n-            shape=depthwise_kernel_shape,\n-            initializer=self.depthwise_initializer,\n-            name='depthwise_kernel',\n-            regularizer=self.depthwise_regularizer,\n-            constraint=self.depthwise_constraint)\n-        self.pointwise_kernel = self.add_weight(\n-            shape=pointwise_kernel_shape,\n-            initializer=self.pointwise_initializer,\n-            name='pointwise_kernel',\n-            regularizer=self.pointwise_regularizer,\n-            constraint=self.pointwise_constraint)\n-\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.filters,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=self.rank + 2,\n-                                    axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs):\n-        if self.rank == 1:\n-            outputs = K.separable_conv1d(\n-                inputs,\n-                self.depthwise_kernel,\n-                self.pointwise_kernel,\n-                data_format=self.data_format,\n-                strides=self.strides,\n-                padding=self.padding,\n-                dilation_rate=self.dilation_rate)\n-        if self.rank == 2:\n-            outputs = K.separable_conv2d(\n-                inputs,\n-                self.depthwise_kernel,\n-                self.pointwise_kernel,\n-                data_format=self.data_format,\n-                strides=self.strides,\n-                padding=self.padding,\n-                dilation_rate=self.dilation_rate)\n-\n-        if self.use_bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-        return outputs\n-\n-    def get_config(self):\n-        config = super(_SeparableConv, self).get_config()\n-        config.pop('rank')\n-        config.pop('kernel_initializer')\n-        config.pop('kernel_regularizer')\n-        config.pop('kernel_constraint')\n-        config['depth_multiplier'] = self.depth_multiplier\n-        config['depthwise_initializer'] = (\n-            initializers.serialize(self.depthwise_initializer))\n-        config['pointwise_initializer'] = (\n-            initializers.serialize(self.pointwise_initializer))\n-        config['depthwise_regularizer'] = (\n-            regularizers.serialize(self.depthwise_regularizer))\n-        config['pointwise_regularizer'] = (\n-            regularizers.serialize(self.pointwise_regularizer))\n-        config['depthwise_constraint'] = (\n-            constraints.serialize(self.depthwise_constraint))\n-        config['pointwise_constraint'] = (\n-            constraints.serialize(self.pointwise_constraint))\n-        return config\n-\n-\n-class SeparableConv1D(_SeparableConv):\n-    \"\"\"Depthwise separable 1D convolution.\n-\n-    Separable convolutions consist in first performing\n-    a depthwise spatial convolution\n-    (which acts on each input channel separately)\n-    followed by a pointwise convolution which mixes together the resulting\n-    output channels. The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    Intuitively, separable convolutions can be understood as\n-    a way to factorize a convolution kernel into two smaller kernels,\n-    or as an extreme version of an Inception block.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of single integer,\n-            specifying the length of the 1D convolution window.\n-        strides: An integer or tuple/list of single integer,\n-            specifying the stride length of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, steps)`.\n-        dilation_rate: An integer or tuple/list of a single integer, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel.\n-            The total number of depthwise convolution output\n-            channels will be equal to `filters_in * depth_multiplier`.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        depthwise_initializer: Initializer for the depthwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        pointwise_initializer: Initializer for the pointwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        depthwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        pointwise_regularizer: Regularizer function applied to\n-            the pointwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        depthwise_constraint: Constraint function applied to\n-            the depthwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        pointwise_constraint: Constraint function applied to\n-            the pointwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        3D tensor with shape:\n-        `(batch, channels, steps)`\n-        if `data_format` is `\"channels_first\"`\n-        or 3D tensor with shape:\n-        `(batch, steps, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        3D tensor with shape:\n-        `(batch, filters, new_steps)`\n-        if `data_format` is `\"channels_first\"`\n-        or 3D tensor with shape:\n-        `(batch, new_steps, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `new_steps` values might have changed due to padding or strides.\n-    \"\"\"\n-\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=1,\n-                 padding='valid',\n-                 data_format='channels_last',\n-                 dilation_rate=1,\n-                 depth_multiplier=1,\n-                 activation=None,\n-                 use_bias=True,\n-                 depthwise_initializer='glorot_uniform',\n-                 pointwise_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 depthwise_regularizer=None,\n-                 pointwise_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 depthwise_constraint=None,\n-                 pointwise_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(SeparableConv1D, self).__init__(\n-            rank=1,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            depth_multiplier=depth_multiplier,\n-            activation=activation,\n-            use_bias=use_bias,\n-            depthwise_initializer=depthwise_initializer,\n-            pointwise_initializer=pointwise_initializer,\n-            bias_initializer=bias_initializer,\n-            depthwise_regularizer=depthwise_regularizer,\n-            pointwise_regularizer=pointwise_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            depthwise_constraint=depthwise_constraint,\n-            pointwise_constraint=pointwise_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-\n-class SeparableConv2D(_SeparableConv):\n-    \"\"\"Depthwise separable 2D convolution.\n-\n-    Separable convolution performs first\n-    a depthwise spatial convolution\n-    (which acts on each input channel separately)\n-    followed by a pointwise convolution which mixes together the resulting\n-    output channels. The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    Intuitively, separable convolutions can be understood as\n-    a way to factorize a convolution kernel into two smaller kernels,\n-    or as an extreme version of an Inception block.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            height and width of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution\n-            along the height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: An integer or tuple/list of 2 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel.\n-            The total number of depthwise convolution output\n-            channels will be equal to `filters_in * depth_multiplier`.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        depthwise_initializer: Initializer for the depthwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        pointwise_initializer: Initializer for the pointwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        depthwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        pointwise_regularizer: Regularizer function applied to\n-            the pointwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        depthwise_constraint: Constraint function applied to\n-            the depthwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        pointwise_constraint: Constraint function applied to\n-            the pointwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(batch, channels, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)`\n-        if `data_format` is `\"channels_last\"`.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    @interfaces.legacy_separable_conv2d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 depth_multiplier=1,\n-                 activation=None,\n-                 use_bias=True,\n-                 depthwise_initializer='glorot_uniform',\n-                 pointwise_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 depthwise_regularizer=None,\n-                 pointwise_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 depthwise_constraint=None,\n-                 pointwise_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(SeparableConv2D, self).__init__(\n-            rank=2,\n-            filters=filters,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            depth_multiplier=depth_multiplier,\n-            activation=activation,\n-            use_bias=use_bias,\n-            depthwise_initializer=depthwise_initializer,\n-            pointwise_initializer=pointwise_initializer,\n-            bias_initializer=bias_initializer,\n-            depthwise_regularizer=depthwise_regularizer,\n-            pointwise_regularizer=pointwise_regularizer,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            depthwise_constraint=depthwise_constraint,\n-            pointwise_constraint=pointwise_constraint,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-\n-\n-class DepthwiseConv2D(Conv2D):\n-    \"\"\"Depthwise 2D convolution.\n-\n-    Depthwise convolution performs\n-    just the first step of a depthwise spatial convolution\n-    (which acts on each input channel separately).\n-    The `depth_multiplier` argument controls how many\n-    output channels are generated per input channel in the depthwise step.\n-\n-    # Arguments\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            height and width of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution\n-            along the height and width.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n-        depth_multiplier: The number of depthwise convolution output channels\n-            for each input channel.\n-            The total number of depthwise convolution output\n-            channels will be equal to `filters_in * depth_multiplier`.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be 'channels_last'.\n-        dilation_rate: an integer or tuple/list of 2 integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any stride value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. 'linear' activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        depthwise_initializer: Initializer for the depthwise kernel matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        depthwise_regularizer: Regularizer function applied to\n-            the depthwise kernel matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its 'activation').\n-            (see [regularizer](../regularizers.md)).\n-        depthwise_constraint: Constraint function applied to\n-            the depthwise kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(batch, channels, rows, cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, rows, cols, channels)`\n-        if `data_format` is `\"channels_last\"`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(batch, channels * depth_multiplier, new_rows, new_cols)`\n-        if `data_format` is `\"channels_first\"`\n-        or 4D tensor with shape:\n-        `(batch, new_rows, new_cols,  channels * depth_multiplier)`\n-        if `data_format` is `\"channels_last\"`.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 depth_multiplier=1,\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 activation=None,\n-                 use_bias=True,\n-                 depthwise_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 depthwise_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 depthwise_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(DepthwiseConv2D, self).__init__(\n-            filters=None,\n-            kernel_size=kernel_size,\n-            strides=strides,\n-            padding=padding,\n-            data_format=data_format,\n-            dilation_rate=dilation_rate,\n-            activation=activation,\n-            use_bias=use_bias,\n-            bias_regularizer=bias_regularizer,\n-            activity_regularizer=activity_regularizer,\n-            bias_constraint=bias_constraint,\n-            **kwargs)\n-        self.depth_multiplier = depth_multiplier\n-        self.depthwise_initializer = initializers.get(depthwise_initializer)\n-        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n-        self.depthwise_constraint = constraints.get(depthwise_constraint)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-\n-    def build(self, input_shape):\n-        if len(input_shape) < 4:\n-            raise ValueError('Inputs to `DepthwiseConv2D` should have rank 4. '\n-                             'Received input shape:', str(input_shape))\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = 3\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs to '\n-                             '`DepthwiseConv2D` '\n-                             'should be defined. Found `None`.')\n-        input_dim = int(input_shape[channel_axis])\n-        depthwise_kernel_shape = (self.kernel_size[0],\n-                                  self.kernel_size[1],\n-                                  input_dim,\n-                                  self.depth_multiplier)\n-\n-        self.depthwise_kernel = self.add_weight(\n-            shape=depthwise_kernel_shape,\n-            initializer=self.depthwise_initializer,\n-            name='depthwise_kernel',\n-            regularizer=self.depthwise_regularizer,\n-            constraint=self.depthwise_constraint)\n-\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        # Set input spec.\n-        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs, training=None):\n-        outputs = K.depthwise_conv2d(\n-            inputs,\n-            self.depthwise_kernel,\n-            strides=self.strides,\n-            padding=self.padding,\n-            dilation_rate=self.dilation_rate,\n-            data_format=self.data_format)\n-\n-        if self.use_bias:\n-            outputs = K.bias_add(\n-                outputs,\n-                self.bias,\n-                data_format=self.data_format)\n-\n-        if self.activation is not None:\n-            return self.activation(outputs)\n-\n-        return outputs\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_last':\n-            space = input_shape[1:-1]\n-            out_filters = input_shape[3] * self.depth_multiplier\n-        elif self.data_format == 'channels_first':\n-            space = input_shape[2:]\n-            out_filters = input_shape[1] * self.depth_multiplier\n-        new_space = []\n-        for i in range(len(space)):\n-            new_dim = conv_utils.conv_output_length(\n-                space[i],\n-                self.kernel_size[i],\n-                padding=self.padding,\n-                stride=self.strides[i],\n-                dilation=self.dilation_rate[i])\n-            new_space.append(new_dim)\n-        if self.data_format == 'channels_last':\n-            return (input_shape[0], new_space[0], new_space[1], out_filters)\n-        elif self.data_format == 'channels_first':\n-            return (input_shape[0], out_filters, new_space[0], new_space[1])\n-\n-    def get_config(self):\n-        config = super(DepthwiseConv2D, self).get_config()\n-        config.pop('filters')\n-        config.pop('kernel_initializer')\n-        config.pop('kernel_regularizer')\n-        config.pop('kernel_constraint')\n-        config['depth_multiplier'] = self.depth_multiplier\n-        config['depthwise_initializer'] = (\n-            initializers.serialize(self.depthwise_initializer))\n-        config['depthwise_regularizer'] = (\n-            regularizers.serialize(self.depthwise_regularizer))\n-        config['depthwise_constraint'] = (\n-            constraints.serialize(self.depthwise_constraint))\n-        return config\n-\n-\n-class _UpSampling(Layer):\n-    \"\"\"Abstract nD UpSampling layer (private, used as implementation base).\n-\n-    # Arguments\n-        size: Tuple of ints.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n-            inputs with shape `(batch, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-    \"\"\"\n-    def __init__(self, size, data_format=None, **kwargs):\n-        # self.rank is 1 for UpSampling1D, 2 for UpSampling2D.\n-        self.rank = len(size)\n-        self.size = size\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=self.rank + 2)\n-        super(_UpSampling, self).__init__(**kwargs)\n-\n-    def call(self, inputs):\n-        raise NotImplementedError\n-\n-    def compute_output_shape(self, input_shape):\n-        size_all_dims = (1,) + self.size + (1,)\n-        spatial_axes = list(range(1, 1 + self.rank))\n-        size_all_dims = transpose_shape(size_all_dims,\n-                                        self.data_format,\n-                                        spatial_axes)\n-        output_shape = list(input_shape)\n-        for dim in range(len(output_shape)):\n-            if output_shape[dim] is not None:\n-                output_shape[dim] *= size_all_dims[dim]\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = {'size': self.size,\n-                  'data_format': self.data_format}\n-        base_config = super(_UpSampling, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class UpSampling1D(_UpSampling):\n-    \"\"\"Upsampling layer for 1D inputs.\n-\n-    Repeats each temporal step `size` times along the time axis.\n-\n-    # Arguments\n-        size: integer. Upsampling factor.\n-\n-    # Input shape\n-        3D tensor with shape: `(batch, steps, features)`.\n-\n-    # Output shape\n-        3D tensor with shape: `(batch, upsampled_steps, features)`.\n-    \"\"\"\n-\n-    @interfaces.legacy_upsampling1d_support\n-    def __init__(self, size=2, **kwargs):\n-        super(UpSampling1D, self).__init__((int(size),), 'channels_last', **kwargs)\n-\n-    def call(self, inputs):\n-        output = K.repeat_elements(inputs, self.size[0], axis=1)\n-        return output\n-\n-    def get_config(self):\n-        config = super(UpSampling1D, self).get_config()\n-        config['size'] = self.size[0]\n-        config.pop('data_format')\n-        return config\n-\n-\n-class UpSampling2D(_UpSampling):\n-    \"\"\"Upsampling layer for 2D inputs.\n-\n-    Repeats the rows and columns of the data\n-    by size[0] and size[1] respectively.\n-\n-    # Arguments\n-        size: int, or tuple of 2 integers.\n-            The upsampling factors for rows and columns.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        interpolation: A string, one of `nearest` or `bilinear`.\n-            Note that CNTK does not support yet the `bilinear` upscaling\n-            and that with Theano, only `size=(2, 2)` is possible.\n-\n-    # Input shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, rows, cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, rows, cols)`\n-\n-    # Output shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, upsampled_rows, upsampled_cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, upsampled_rows, upsampled_cols)`\n-    \"\"\"\n-\n-    @interfaces.legacy_upsampling2d_support\n-    def __init__(self, size=(2, 2), data_format=None, interpolation='nearest',\n-                 **kwargs):\n-        normalized_size = conv_utils.normalize_tuple(size, 2, 'size')\n-        super(UpSampling2D, self).__init__(normalized_size, data_format, **kwargs)\n-        if interpolation not in ['nearest', 'bilinear']:\n-            raise ValueError('interpolation should be one '\n-                             'of \"nearest\" or \"bilinear\".')\n-        self.interpolation = interpolation\n-\n-    def call(self, inputs):\n-        return K.resize_images(inputs, self.size[0], self.size[1],\n-                               self.data_format, self.interpolation)\n-\n-    def get_config(self):\n-        config = super(UpSampling2D, self).get_config()\n-        config['interpolation'] = self.interpolation\n-        return config\n-\n-\n-class UpSampling3D(_UpSampling):\n-    \"\"\"Upsampling layer for 3D inputs.\n-\n-    Repeats the 1st, 2nd and 3rd dimensions\n-    of the data by size[0], size[1] and size[2] respectively.\n-\n-    # Arguments\n-        size: int, or tuple of 3 integers.\n-            The upsampling factors for dim1, dim2 and dim3.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-\n-    # Input shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, dim1, dim2, dim3, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, dim1, dim2, dim3)`\n-\n-    # Output shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, upsampled_dim1, upsampled_dim2, upsampled_dim3, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, upsampled_dim1, upsampled_dim2, upsampled_dim3)`\n-    \"\"\"\n-\n-    @interfaces.legacy_upsampling3d_support\n-    def __init__(self, size=(2, 2, 2), data_format=None, **kwargs):\n-        normalized_size = conv_utils.normalize_tuple(size, 3, 'size')\n-        super(UpSampling3D, self).__init__(normalized_size, data_format, **kwargs)\n-\n-    def call(self, inputs):\n-        return K.resize_volumes(inputs,\n-                                self.size[0], self.size[1], self.size[2],\n-                                self.data_format)\n-\n-\n-class _ZeroPadding(Layer):\n-    \"\"\"Abstract nD ZeroPadding layer (private, used as implementation base).\n-\n-    # Arguments\n-        padding: Tuple of tuples of two ints. Can be a tuple of ints when\n-            rank is 1.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n-            inputs with shape `(batch, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-    \"\"\"\n-    def __init__(self, padding, data_format=None, **kwargs):\n-        # self.rank is 1 for ZeroPadding1D, 2 for ZeroPadding2D.\n-        self.rank = len(padding)\n-        self.padding = padding\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=self.rank + 2)\n-        super(_ZeroPadding, self).__init__(**kwargs)\n-\n-    def call(self, inputs):\n-        raise NotImplementedError\n-\n-    def compute_output_shape(self, input_shape):\n-        padding_all_dims = ((0, 0),) + self.padding + ((0, 0),)\n-        spatial_axes = list(range(1, 1 + self.rank))\n-        padding_all_dims = transpose_shape(padding_all_dims,\n-                                           self.data_format,\n-                                           spatial_axes)\n-        output_shape = list(input_shape)\n-        for dim in range(len(output_shape)):\n-            if output_shape[dim] is not None:\n-                output_shape[dim] += sum(padding_all_dims[dim])\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = {'padding': self.padding,\n-                  'data_format': self.data_format}\n-        base_config = super(_ZeroPadding, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class ZeroPadding1D(_ZeroPadding):\n-    \"\"\"Zero-padding layer for 1D input (e.g. temporal sequence).\n-\n-    # Arguments\n-        padding: int, or tuple of int (length 2), or dictionary.\n-            - If int:\n-            How many zeros to add at the beginning and end of\n-            the padding dimension (axis 1).\n-            - If tuple of int (length 2):\n-            How many zeros to add at the beginning and at the end of\n-            the padding dimension (`(left_pad, right_pad)`).\n-\n-    # Input shape\n-        3D tensor with shape `(batch, axis_to_pad, features)`\n-\n-    # Output shape\n-        3D tensor with shape `(batch, padded_axis, features)`\n-    \"\"\"\n-\n-    def __init__(self, padding=1, **kwargs):\n-        normalized_padding = (conv_utils.normalize_tuple(padding, 2, 'padding'),)\n-        super(ZeroPadding1D, self).__init__(normalized_padding,\n-                                            'channels_last',\n-                                            **kwargs)\n-\n-    def call(self, inputs):\n-        return K.temporal_padding(inputs, padding=self.padding[0])\n-\n-    def get_config(self):\n-        config = super(ZeroPadding1D, self).get_config()\n-        config['padding'] = config['padding'][0]\n-        config.pop('data_format')\n-        return config\n-\n-\n-class ZeroPadding2D(_ZeroPadding):\n-    \"\"\"Zero-padding layer for 2D input (e.g. picture).\n-\n-    This layer can add rows and columns of zeros\n-    at the top, bottom, left and right side of an image tensor.\n-\n-    # Arguments\n-        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n-            - If int: the same symmetric padding\n-                is applied to height and width.\n-            - If tuple of 2 ints:\n-                interpreted as two different\n-                symmetric padding values for height and width:\n-                `(symmetric_height_pad, symmetric_width_pad)`.\n-            - If tuple of 2 tuples of 2 ints:\n-                interpreted as\n-                `((top_pad, bottom_pad), (left_pad, right_pad))`\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-\n-    # Input shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, rows, cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, rows, cols)`\n-\n-    # Output shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, padded_rows, padded_cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, padded_rows, padded_cols)`\n-    \"\"\"\n-\n-    @interfaces.legacy_zeropadding2d_support\n-    def __init__(self,\n-                 padding=(1, 1),\n-                 data_format=None,\n-                 **kwargs):\n-        if isinstance(padding, int):\n-            normalized_padding = ((padding, padding), (padding, padding))\n-        elif hasattr(padding, '__len__'):\n-            if len(padding) != 2:\n-                raise ValueError('`padding` should have two elements. '\n-                                 'Found: ' + str(padding))\n-            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                        '1st entry of padding')\n-            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                       '2nd entry of padding')\n-            normalized_padding = (height_padding, width_padding)\n-        else:\n-            raise ValueError('`padding` should be either an int, '\n-                             'a tuple of 2 ints '\n-                             '(symmetric_height_pad, symmetric_width_pad), '\n-                             'or a tuple of 2 tuples of 2 ints '\n-                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n-                             'Found: ' + str(padding))\n-        super(ZeroPadding2D, self).__init__(normalized_padding,\n-                                            data_format,\n-                                            **kwargs)\n-\n-    def call(self, inputs):\n-        return K.spatial_2d_padding(inputs,\n-                                    padding=self.padding,\n-                                    data_format=self.data_format)\n-\n-\n-class ZeroPadding3D(_ZeroPadding):\n-    \"\"\"Zero-padding layer for 3D data (spatial or spatio-temporal).\n-\n-    # Arguments\n-        padding: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n-            - If int: the same symmetric padding\n-                is applied to height and width.\n-            - If tuple of 3 ints:\n-                interpreted as three different\n-                symmetric padding values for depth, height, and width:\n-                `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n-            - If tuple of 3 tuples of 2 ints:\n-                interpreted as\n-                `((left_dim1_pad, right_dim1_pad),\n-                  (left_dim2_pad, right_dim2_pad),\n-                  (left_dim3_pad, right_dim3_pad))`\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-\n-    # Input shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, first_axis_to_pad, second_axis_to_pad, third_axis_to_pad,\n-              depth)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, depth,\n-              first_axis_to_pad, second_axis_to_pad, third_axis_to_pad)`\n-\n-    # Output shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, first_padded_axis, second_padded_axis, third_axis_to_pad,\n-              depth)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, depth,\n-              first_padded_axis, second_padded_axis, third_axis_to_pad)`\n-    \"\"\"\n-\n-    @interfaces.legacy_zeropadding3d_support\n-    def __init__(self, padding=(1, 1, 1), data_format=None, **kwargs):\n-        if isinstance(padding, int):\n-            normalized_padding = 3 * ((padding, padding),)\n-        elif hasattr(padding, '__len__'):\n-            if len(padding) != 3:\n-                raise ValueError('`padding` should have 3 elements. '\n-                                 'Found: ' + str(padding))\n-            dim1_padding = conv_utils.normalize_tuple(padding[0], 2,\n-                                                      '1st entry of padding')\n-            dim2_padding = conv_utils.normalize_tuple(padding[1], 2,\n-                                                      '2nd entry of padding')\n-            dim3_padding = conv_utils.normalize_tuple(padding[2], 2,\n-                                                      '3rd entry of padding')\n-            normalized_padding = (dim1_padding, dim2_padding, dim3_padding)\n-        else:\n-            raise ValueError(\n-                '`padding` should be either an int, a tuple of 3 ints '\n-                '(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad), '\n-                'or a tuple of 3 tuples of 2 ints '\n-                '((left_dim1_pad, right_dim1_pad),'\n-                ' (left_dim2_pad, right_dim2_pad),'\n-                ' (left_dim3_pad, right_dim2_pad)). '\n-                'Found: ' + str(padding))\n-        super(ZeroPadding3D, self).__init__(normalized_padding,\n-                                            data_format,\n-                                            **kwargs)\n-\n-    def call(self, inputs):\n-        return K.spatial_3d_padding(inputs,\n-                                    padding=self.padding,\n-                                    data_format=self.data_format)\n-\n-\n-class _Cropping(Layer):\n-    \"\"\"Abstract nD copping layer (private, used as implementation base).\n-\n-    # Arguments\n-        cropping: A tuple of tuples of 2 ints.\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n-            inputs with shape `(batch, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-            For Cropping1D, the data format is always `\"channels_last\"`.\n-    \"\"\"\n-\n-    def __init__(self, cropping,\n-                 data_format=None,\n-                 **kwargs):\n-        super(_Cropping, self).__init__(**kwargs)\n-        # self.rank is 1 for Cropping1D, 2 for Cropping2D...\n-        self.rank = len(cropping)\n-        self.cropping = cropping\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=2 + self.rank)\n-\n-    def call(self, inputs):\n-        slices_dims = []\n-        for start, end in self.cropping:\n-            if end == 0:\n-                end = None\n-            else:\n-                end = -end\n-            slices_dims.append(slice(start, end))\n-\n-        slices = [slice(None)] + slices_dims + [slice(None)]\n-        slices = tuple(slices)\n-        spatial_axes = list(range(1, 1 + self.rank))\n-        slices = transpose_shape(slices, self.data_format, spatial_axes)\n-        return inputs[slices]\n-\n-    def compute_output_shape(self, input_shape):\n-        cropping_all_dims = ((0, 0),) + self.cropping + ((0, 0),)\n-        spatial_axes = list(range(1, 1 + self.rank))\n-        cropping_all_dims = transpose_shape(cropping_all_dims,\n-                                            self.data_format,\n-                                            spatial_axes)\n-        output_shape = list(input_shape)\n-        for dim in range(len(output_shape)):\n-            if output_shape[dim] is not None:\n-                output_shape[dim] -= sum(cropping_all_dims[dim])\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = {'cropping': self.cropping,\n-                  'data_format': self.data_format}\n-        base_config = super(_Cropping, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Cropping1D(_Cropping):\n-    \"\"\"Cropping layer for 1D input (e.g. temporal sequence).\n-\n-    It crops along the time dimension (axis 1).\n-\n-    # Arguments\n-        cropping: int or tuple of int (length 2)\n-            How many units should be trimmed off at the beginning and end of\n-            the cropping dimension (axis 1).\n-            If a single int is provided,\n-            the same value will be used for both.\n-\n-    # Input shape\n-        3D tensor with shape `(batch, axis_to_crop, features)`\n-\n-    # Output shape\n-        3D tensor with shape `(batch, cropped_axis, features)`\n-    \"\"\"\n-\n-    def __init__(self, cropping=(1, 1), **kwargs):\n-        normalized_cropping = (conv_utils.normalize_tuple(cropping, 2, 'cropping'),)\n-        super(Cropping1D, self).__init__(normalized_cropping,\n-                                         'channels_last',\n-                                         **kwargs)\n-\n-    def get_config(self):\n-        base_config = super(Cropping1D, self).get_config()\n-        base_config.pop('data_format')\n-        base_config['cropping'] = base_config['cropping'][0]\n-        return base_config\n-\n-\n-class Cropping2D(_Cropping):\n-    \"\"\"Cropping layer for 2D input (e.g. picture).\n-\n-    It crops along spatial dimensions, i.e. height and width.\n-\n-    # Arguments\n-        cropping: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n-            - If int: the same symmetric cropping\n-                is applied to height and width.\n-            - If tuple of 2 ints:\n-                interpreted as two different\n-                symmetric cropping values for height and width:\n-                `(symmetric_height_crop, symmetric_width_crop)`.\n-            - If tuple of 2 tuples of 2 ints:\n-                interpreted as\n-                `((top_crop, bottom_crop), (left_crop, right_crop))`\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-\n-    # Input shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, rows, cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, rows, cols)`\n-\n-    # Output shape\n-        4D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, cropped_rows, cropped_cols, channels)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, channels, cropped_rows, cropped_cols)`\n-\n-    # Examples\n-\n-    ```python\n-        # Crop the input 2D images or feature maps\n-        model = Sequential()\n-        model.add(Cropping2D(cropping=((2, 2), (4, 4)),\n-                             input_shape=(28, 28, 3)))\n-        # now model.output_shape == (None, 24, 20, 3)\n-        model.add(Conv2D(64, (3, 3), padding='same'))\n-        model.add(Cropping2D(cropping=((2, 2), (2, 2))))\n-        # now model.output_shape == (None, 20, 16, 64)\n-    ```\n-    \"\"\"\n-\n-    @interfaces.legacy_cropping2d_support\n-    def __init__(self, cropping=((0, 0), (0, 0)),\n-                 data_format=None, **kwargs):\n-        if isinstance(cropping, int):\n-            normalized_cropping = ((cropping, cropping), (cropping, cropping))\n-        elif hasattr(cropping, '__len__'):\n-            if len(cropping) != 2:\n-                raise ValueError('`cropping` should have two elements. '\n-                                 'Found: ' + str(cropping))\n-            height_cropping = conv_utils.normalize_tuple(\n-                cropping[0], 2,\n-                '1st entry of cropping')\n-            width_cropping = conv_utils.normalize_tuple(\n-                cropping[1], 2,\n-                '2nd entry of cropping')\n-            normalized_cropping = (height_cropping, width_cropping)\n-        else:\n-            raise ValueError('`cropping` should be either an int, '\n-                             'a tuple of 2 ints '\n-                             '(symmetric_height_crop, symmetric_width_crop), '\n-                             'or a tuple of 2 tuples of 2 ints '\n-                             '((top_crop, bottom_crop), (left_crop, right_crop)). '\n-                             'Found: ' + str(cropping))\n-        super(Cropping2D, self).__init__(normalized_cropping,\n-                                         data_format,\n-                                         **kwargs)\n-\n-\n-class Cropping3D(_Cropping):\n-    \"\"\"Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n-\n-    # Arguments\n-        cropping: int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n-            - If int: the same symmetric cropping\n-                is applied to depth, height, and width.\n-            - If tuple of 3 ints:\n-                interpreted as three different\n-                symmetric cropping values for depth, height, and width:\n-                `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n-            - If tuple of 3 tuples of 2 ints:\n-                interpreted as\n-                `((left_dim1_crop, right_dim1_crop),\n-                  (left_dim2_crop, right_dim2_crop),\n-                  (left_dim3_crop, right_dim3_crop))`\n-        data_format: A string,\n-            one of `\"channels_last\"` or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-\n-    # Input shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, first_axis_to_crop, second_axis_to_crop, third_axis_to_crop,\n-              depth)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, depth,\n-              first_axis_to_crop, second_axis_to_crop, third_axis_to_crop)`\n-\n-    # Output shape\n-        5D tensor with shape:\n-        - If `data_format` is `\"channels_last\"`:\n-            `(batch, first_cropped_axis, second_cropped_axis, third_cropped_axis,\n-              depth)`\n-        - If `data_format` is `\"channels_first\"`:\n-            `(batch, depth,\n-              first_cropped_axis, second_cropped_axis, third_cropped_axis)`\n-    \"\"\"\n-\n-    @interfaces.legacy_cropping3d_support\n-    def __init__(self, cropping=((1, 1), (1, 1), (1, 1)),\n-                 data_format=None, **kwargs):\n-        self.data_format = K.normalize_data_format(data_format)\n-        if isinstance(cropping, int):\n-            normalized_cropping = ((cropping, cropping),\n-                                   (cropping, cropping),\n-                                   (cropping, cropping))\n-        elif hasattr(cropping, '__len__'):\n-            if len(cropping) != 3:\n-                raise ValueError('`cropping` should have 3 elements. '\n-                                 'Found: ' + str(cropping))\n-            dim1_cropping = conv_utils.normalize_tuple(cropping[0], 2,\n-                                                       '1st entry of cropping')\n-            dim2_cropping = conv_utils.normalize_tuple(cropping[1], 2,\n-                                                       '2nd entry of cropping')\n-            dim3_cropping = conv_utils.normalize_tuple(cropping[2], 2,\n-                                                       '3rd entry of cropping')\n-            normalized_cropping = (dim1_cropping, dim2_cropping, dim3_cropping)\n-        else:\n-            raise ValueError(\n-                '`cropping` should be either an int, a tuple of 3 ints '\n-                '(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop), '\n-                'or a tuple of 3 tuples of 2 ints '\n-                '((left_dim1_crop, right_dim1_crop),'\n-                ' (left_dim2_crop, right_dim2_crop),'\n-                ' (left_dim3_crop, right_dim2_crop)). '\n-                'Found: ' + str(cropping))\n-        super(Cropping3D, self).__init__(normalized_cropping,\n-                                         data_format,\n-                                         **kwargs)\n-\n+\"\"\"Convolutional layers.\"\"\"\n+from tensorflow.keras.layers import Conv1D\n+from tensorflow.keras.layers import Conv2D\n+from tensorflow.keras.layers import Conv3D\n+from tensorflow.keras.layers import Conv2DTranspose\n+from tensorflow.keras.layers import Conv3DTranspose\n+from tensorflow.keras.layers import SeparableConv1D\n+from tensorflow.keras.layers import SeparableConv2D\n+from tensorflow.keras.layers import DepthwiseConv2D\n+from tensorflow.keras.layers import UpSampling1D\n+from tensorflow.keras.layers import UpSampling2D\n+from tensorflow.keras.layers import UpSampling3D\n+from tensorflow.keras.layers import ZeroPadding1D\n+from tensorflow.keras.layers import ZeroPadding2D\n+from tensorflow.keras.layers import ZeroPadding3D\n+from tensorflow.keras.layers import Cropping1D\n+from tensorflow.keras.layers import Cropping2D\n+from tensorflow.keras.layers import Cropping3D\n \n # Aliases\n \n@@ -2579,6 +28,11 @@ Convolution2DTranspose = Conv2DTranspose\n Deconvolution2D = Deconv2D = Conv2DTranspose\n Deconvolution3D = Deconv3D = Conv3DTranspose\n \n-# Legacy aliases\n-AtrousConv1D = AtrousConvolution1D\n-AtrousConv2D = AtrousConvolution2D\n+# imports for backwards namespace compatibility\n+\n+from .pooling import AveragePooling1D\n+from .pooling import AveragePooling2D\n+from .pooling import AveragePooling3D\n+from .pooling import MaxPooling1D\n+from .pooling import MaxPooling2D\n+from .pooling import MaxPooling3D\n\n@@ -1,1097 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Convolutional-recurrent layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Convolutional-recurrent layers.\"\"\"\n \n-from .. import backend as K\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from .recurrent import _generate_dropout_mask\n-from .recurrent import _standardize_args\n-\n-import numpy as np\n-import warnings\n-from ..engine.base_layer import InputSpec, Layer\n-from ..utils import conv_utils\n-from ..legacy import interfaces\n-from ..legacy.layers import Recurrent, ConvRecurrent2D\n-from .recurrent import RNN\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import to_list\n-from ..utils.generic_utils import transpose_shape\n-\n-\n-class ConvRNN2D(RNN):\n-    \"\"\"Base class for convolutional-recurrent layers.\n-\n-    # Arguments\n-        cell: A RNN cell instance. A RNN cell is a class that has:\n-            - a `call(input_at_t, states_at_t)` method, returning\n-              `(output_at_t, states_at_t_plus_1)`. The call method of the\n-              cell can also take the optional argument `constants`, see\n-              section \"Note on passing external constants\" below.\n-            - a `state_size` attribute. This can be a single integer (single state)\n-              in which case it is the number of channels of the recurrent state\n-              (which should be the same as the number of channels of the cell\n-              output). This can also be a list/tuple of integers\n-              (one size per state). In this case, the first entry (`state_size[0]`)\n-              should be the same as the size of the cell output.\n-        return_sequences: Boolean. Whether to return the last output.\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        input_shape: Use this argument to specify the shape of the\n-            input when this layer is the first one in a model.\n-\n-    # Input shape\n-        5D tensor with shape:\n-        `(samples, timesteps, channels, rows, cols)` if data_format='channels_first'\n-        or 5D tensor with shape:\n-        `(samples, timesteps, rows, cols, channels)` if data_format='channels_last'.\n-\n-    # Output shape\n-        - if `return_state`: a list of tensors. The first tensor is\n-            the output. The remaining tensors are the last states,\n-            each 5D tensor with shape:\n-            `(samples, timesteps,\n-              filters, new_rows, new_cols)` if data_format='channels_first'\n-            or 5D tensor with shape:\n-            `(samples, timesteps,\n-              new_rows, new_cols, filters)` if data_format='channels_last'.\n-            `rows` and `cols` values might have changed due to padding.\n-        - if `return_sequences`: 5D tensor with shape:\n-            `(samples, timesteps,\n-              filters, new_rows, new_cols)` if data_format='channels_first'\n-            or 5D tensor with shape:\n-            `(samples, timesteps,\n-              new_rows, new_cols, filters)` if data_format='channels_last'.\n-        - else, 4D tensor with shape:\n-            `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n-            or 4D tensor with shape:\n-            `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n-\n-    # Masking\n-        This layer supports masking for input data with a variable number\n-        of timesteps. To introduce masks to your data,\n-        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-        set to `True`.\n-\n-    # Note on using statefulness in RNNs\n-        You can set RNN layers to be 'stateful', which means that the states\n-        computed for the samples in one batch will be reused as initial states\n-        for the samples in the next batch. This assumes a one-to-one mapping\n-        between samples in different successive batches.\n-\n-        To enable statefulness:\n-            - specify `stateful=True` in the layer constructor.\n-            - specify a fixed batch size for your model, by passing\n-                 - if sequential model:\n-                    `batch_input_shape=(...)` to the first layer in your model.\n-                 - if functional model with 1 or more Input layers:\n-                    `batch_shape=(...)` to all the first layers in your model.\n-                    This is the expected shape of your inputs\n-                    *including the batch size*.\n-                    It should be a tuple of integers, e.g. `(32, 10, 100, 100, 32)`.\n-                    Note that the number of rows and columns should be specified too.\n-            - specify `shuffle=False` when calling fit().\n-\n-        To reset the states of your model, call `.reset_states()` on either\n-        a specific layer, or on your entire model.\n-\n-    # Note on specifying the initial state of RNNs\n-        You can specify the initial state of RNN layers symbolically by\n-        calling them with the keyword argument `initial_state`. The value of\n-        `initial_state` should be a tensor or list of tensors representing\n-        the initial state of the RNN layer.\n-\n-        You can specify the initial state of RNN layers numerically by\n-        calling `reset_states` with the keyword argument `states`. The value of\n-        `states` should be a numpy array or list of numpy arrays representing\n-        the initial state of the RNN layer.\n-\n-    # Note on passing external constants to RNNs\n-        You can pass \"external\" constants to the cell using the `constants`\n-        keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n-        requires that the `cell.call` method accepts the same keyword argument\n-        `constants`. Such constants can be used to condition the cell\n-        transformation on additional static inputs (not changing over time),\n-        a.k.a. an attention mechanism.\n-    \"\"\"\n-\n-    def __init__(self, cell,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 **kwargs):\n-        if unroll:\n-            raise TypeError('Unrolling isn\\'t possible with '\n-                            'convolutional RNNs.')\n-        if isinstance(cell, (list, tuple)):\n-            # The StackedConvRNN2DCells isn't implemented yet.\n-            raise TypeError('It is not possible at the moment to'\n-                            'stack convolutional cells.')\n-        super(ConvRNN2D, self).__init__(cell,\n-                                        return_sequences,\n-                                        return_state,\n-                                        go_backwards,\n-                                        stateful,\n-                                        unroll,\n-                                        **kwargs)\n-        self.input_spec = [InputSpec(ndim=5)]\n-\n-    def compute_output_shape(self, input_shape):\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-\n-        cell = self.cell\n-        if cell.data_format == 'channels_first':\n-            rows = input_shape[3]\n-            cols = input_shape[4]\n-        elif cell.data_format == 'channels_last':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        rows = conv_utils.conv_output_length(rows,\n-                                             cell.kernel_size[0],\n-                                             padding=cell.padding,\n-                                             stride=cell.strides[0],\n-                                             dilation=cell.dilation_rate[0])\n-        cols = conv_utils.conv_output_length(cols,\n-                                             cell.kernel_size[1],\n-                                             padding=cell.padding,\n-                                             stride=cell.strides[1],\n-                                             dilation=cell.dilation_rate[1])\n-\n-        output_shape = input_shape[:2] + (rows, cols, cell.filters)\n-        output_shape = transpose_shape(output_shape, cell.data_format,\n-                                       spatial_axes=(2, 3))\n-\n-        if not self.return_sequences:\n-            output_shape = output_shape[:1] + output_shape[2:]\n-\n-        if self.return_state:\n-            output_shape = [output_shape]\n-            base = (input_shape[0], rows, cols, cell.filters)\n-            base = transpose_shape(base, cell.data_format, spatial_axes=(1, 2))\n-            output_shape += [base[:] for _ in range(2)]\n-        return output_shape\n-\n-    def build(self, input_shape):\n-        # Note input_shape will be list of shapes of initial states and\n-        # constants if these are passed in __call__.\n-        if self._num_constants is not None:\n-            constants_shape = input_shape[-self._num_constants:]\n-        else:\n-            constants_shape = None\n-\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-\n-        batch_size = input_shape[0] if self.stateful else None\n-        self.input_spec[0] = InputSpec(shape=(batch_size, None) + input_shape[2:5])\n-\n-        # allow cell (if layer) to build before we set or validate state_spec\n-        if isinstance(self.cell, Layer):\n-            step_input_shape = (input_shape[0],) + input_shape[2:]\n-            if constants_shape is not None:\n-                self.cell.build([step_input_shape] + constants_shape)\n-            else:\n-                self.cell.build(step_input_shape)\n-\n-        # set or validate state_spec\n-        if hasattr(self.cell.state_size, '__len__'):\n-            state_size = list(self.cell.state_size)\n-        else:\n-            state_size = [self.cell.state_size]\n-\n-        if self.state_spec is not None:\n-            # initial_state was passed in call, check compatibility\n-            if self.cell.data_format == 'channels_first':\n-                ch_dim = 1\n-            elif self.cell.data_format == 'channels_last':\n-                ch_dim = 3\n-            if not [spec.shape[ch_dim] for spec in self.state_spec] == state_size:\n-                raise ValueError(\n-                    'An initial_state was passed that is not compatible with '\n-                    '`cell.state_size`. Received `state_spec`={}; '\n-                    'However `cell.state_size` is '\n-                    '{}'.format([spec.shape for spec in self.state_spec],\n-                                self.cell.state_size))\n-        else:\n-            if self.cell.data_format == 'channels_first':\n-                self.state_spec = [InputSpec(shape=(None, dim, None, None))\n-                                   for dim in state_size]\n-            elif self.cell.data_format == 'channels_last':\n-                self.state_spec = [InputSpec(shape=(None, None, None, dim))\n-                                   for dim in state_size]\n-        if self.stateful:\n-            self.reset_states()\n-        self.built = True\n-\n-    def get_initial_state(self, inputs):\n-        # (samples, timesteps, rows, cols, filters)\n-        initial_state = K.zeros_like(inputs)\n-        # (samples, rows, cols, filters)\n-        initial_state = K.sum(initial_state, axis=1)\n-        shape = list(self.cell.kernel_shape)\n-        shape[-1] = self.cell.filters\n-\n-        if K.backend() == 'tensorflow':\n-            # We need to force this to be a tensor\n-            # and not a variable, to avoid variable initialization\n-            # issues.\n-            import tensorflow as tf\n-            kernel = tf.zeros(tuple(shape))\n-        else:\n-            kernel = K.zeros(tuple(shape))\n-        initial_state = self.cell.input_conv(initial_state,\n-                                             kernel,\n-                                             padding=self.cell.padding)\n-        # Fix for Theano because it needs\n-        # K.int_shape to work in call() with initial_state.\n-        keras_shape = list(K.int_shape(inputs))\n-        keras_shape.pop(1)\n-        if K.image_data_format() == 'channels_first':\n-            indices = 2, 3\n-        else:\n-            indices = 1, 2\n-        for i, j in enumerate(indices):\n-            keras_shape[j] = conv_utils.conv_output_length(\n-                keras_shape[j],\n-                shape[i],\n-                padding=self.cell.padding,\n-                stride=self.cell.strides[i],\n-                dilation=self.cell.dilation_rate[i])\n-        initial_state._keras_shape = keras_shape\n-\n-        if hasattr(self.cell.state_size, '__len__'):\n-            return [initial_state for _ in self.cell.state_size]\n-        else:\n-            return [initial_state]\n-\n-    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n-        inputs, initial_state, constants = _standardize_args(\n-            inputs, initial_state, constants, self._num_constants)\n-\n-        if initial_state is None and constants is None:\n-            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n-\n-        # If any of `initial_state` or `constants` are specified and are Keras\n-        # tensors, then add them to the inputs and temporarily modify the\n-        # input_spec to include them.\n-\n-        additional_inputs = []\n-        additional_specs = []\n-        if initial_state is not None:\n-            kwargs['initial_state'] = initial_state\n-            additional_inputs += initial_state\n-            self.state_spec = []\n-            for state in initial_state:\n-                try:\n-                    shape = K.int_shape(state)\n-                # Fix for Theano\n-                except TypeError:\n-                    shape = tuple(None for _ in range(K.ndim(state)))\n-                self.state_spec.append(InputSpec(shape=shape))\n-\n-            additional_specs += self.state_spec\n-        if constants is not None:\n-            kwargs['constants'] = constants\n-            additional_inputs += constants\n-            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n-                                   for constant in constants]\n-            self._num_constants = len(constants)\n-            additional_specs += self.constants_spec\n-        # at this point additional_inputs cannot be empty\n-        for tensor in additional_inputs:\n-            if K.is_keras_tensor(tensor) != K.is_keras_tensor(additional_inputs[0]):\n-                raise ValueError('The initial state or constants of an RNN'\n-                                 ' layer cannot be specified with a mix of'\n-                                 ' Keras tensors and non-Keras tensors')\n-\n-        if K.is_keras_tensor(additional_inputs[0]):\n-            # Compute the full input spec, including state and constants\n-            full_input = [inputs] + additional_inputs\n-            full_input_spec = self.input_spec + additional_specs\n-            # Perform the call with temporarily replaced input_spec\n-            original_input_spec = self.input_spec\n-            self.input_spec = full_input_spec\n-            output = super(ConvRNN2D, self).__call__(full_input, **kwargs)\n-            self.input_spec = original_input_spec\n-            return output\n-        else:\n-            return super(ConvRNN2D, self).__call__(inputs, **kwargs)\n-\n-    def call(self,\n-             inputs,\n-             mask=None,\n-             training=None,\n-             initial_state=None,\n-             constants=None):\n-        # note that the .build() method of subclasses MUST define\n-        # self.input_spec and self.state_spec with complete input shapes.\n-        if isinstance(inputs, list):\n-            inputs = inputs[0]\n-        if initial_state is not None:\n-            pass\n-        elif self.stateful:\n-            initial_state = self.states\n-        else:\n-            initial_state = self.get_initial_state(inputs)\n-\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-\n-        if len(initial_state) != len(self.states):\n-            raise ValueError('Layer has ' + str(len(self.states)) +\n-                             ' states but was passed ' +\n-                             str(len(initial_state)) +\n-                             ' initial states.')\n-        timesteps = K.int_shape(inputs)[1]\n-\n-        kwargs = {}\n-        if has_arg(self.cell.call, 'training'):\n-            kwargs['training'] = training\n-\n-        if constants:\n-            if not has_arg(self.cell.call, 'constants'):\n-                raise ValueError('RNN cell does not support constants')\n-\n-            def step(inputs, states):\n-                constants = states[-self._num_constants:]\n-                states = states[:-self._num_constants]\n-                return self.cell.call(inputs, states, constants=constants,\n-                                      **kwargs)\n-        else:\n-            def step(inputs, states):\n-                return self.cell.call(inputs, states, **kwargs)\n-\n-        last_output, outputs, states = K.rnn(step,\n-                                             inputs,\n-                                             initial_state,\n-                                             constants=constants,\n-                                             go_backwards=self.go_backwards,\n-                                             mask=mask,\n-                                             input_length=timesteps)\n-        if self.stateful:\n-            updates = []\n-            for i in range(len(states)):\n-                updates.append((self.states[i], states[i]))\n-            self.add_update(updates, inputs)\n-\n-        if self.return_sequences:\n-            output = outputs\n-        else:\n-            output = last_output\n-\n-        # Properly set learning phase\n-        if getattr(last_output, '_uses_learning_phase', False):\n-            output._uses_learning_phase = True\n-\n-        if self.return_state:\n-            states = to_list(states, allow_tuple=True)\n-            return [output] + states\n-        else:\n-            return output\n-\n-    def reset_states(self, states=None):\n-        if not self.stateful:\n-            raise AttributeError('Layer must be stateful.')\n-        input_shape = self.input_spec[0].shape\n-        state_shape = self.compute_output_shape(input_shape)\n-        if self.return_state:\n-            state_shape = state_shape[0]\n-        if self.return_sequences:\n-            state_shape = state_shape[:1] + state_shape[2:]\n-        if None in state_shape:\n-            raise ValueError('If a RNN is stateful, it needs to know '\n-                             'its batch size. Specify the batch size '\n-                             'of your input tensors: \\n'\n-                             '- If using a Sequential model, '\n-                             'specify the batch size by passing '\n-                             'a `batch_input_shape` '\n-                             'argument to your first layer.\\n'\n-                             '- If using the functional API, specify '\n-                             'the time dimension by passing a '\n-                             '`batch_shape` argument to your Input layer.\\n'\n-                             'The same thing goes for the number of rows '\n-                             'and columns.')\n-\n-        # helper function\n-        def get_tuple_shape(nb_channels):\n-            result = list(state_shape)\n-            if self.cell.data_format == 'channels_first':\n-                result[1] = nb_channels\n-            elif self.cell.data_format == 'channels_last':\n-                result[3] = nb_channels\n-            else:\n-                raise KeyError\n-            return tuple(result)\n-\n-        # initialize state if None\n-        if self.states[0] is None:\n-            if hasattr(self.cell.state_size, '__len__'):\n-                self.states = [K.zeros(get_tuple_shape(dim))\n-                               for dim in self.cell.state_size]\n-            else:\n-                self.states = [K.zeros(get_tuple_shape(self.cell.state_size))]\n-        elif states is None:\n-            if hasattr(self.cell.state_size, '__len__'):\n-                for state, dim in zip(self.states, self.cell.state_size):\n-                    K.set_value(state, np.zeros(get_tuple_shape(dim)))\n-            else:\n-                K.set_value(self.states[0],\n-                            np.zeros(get_tuple_shape(self.cell.state_size)))\n-        else:\n-            states = to_list(states, allow_tuple=True)\n-            if len(states) != len(self.states):\n-                raise ValueError('Layer ' + self.name + ' expects ' +\n-                                 str(len(self.states)) + ' states, '\n-                                 'but it received ' + str(len(states)) +\n-                                 ' state values. Input received: ' +\n-                                 str(states))\n-            for index, (value, state) in enumerate(zip(states, self.states)):\n-                if hasattr(self.cell.state_size, '__len__'):\n-                    dim = self.cell.state_size[index]\n-                else:\n-                    dim = self.cell.state_size\n-                if value.shape != get_tuple_shape(dim):\n-                    raise ValueError('State ' + str(index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected shape=' +\n-                                     str(get_tuple_shape(dim)) +\n-                                     ', found shape=' + str(value.shape))\n-                # TODO: consider batch calls to `set_value`.\n-                K.set_value(state, value)\n-\n-\n-class ConvLSTM2DCell(Layer):\n-    \"\"\"Cell class for the ConvLSTM2D layer.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of n integers, specifying the\n-            dimensions of the convolution window.\n-        strides: An integer or tuple/list of n integers,\n-            specifying the strides of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: An integer or tuple/list of n integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state.\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        unit_forget_bias: Boolean.\n-            If True, add 1 to the bias of the forget gate at initialization.\n-            Use in combination with `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al. (2015)](\n-            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-    \"\"\"\n-\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 activation='tanh',\n-                 recurrent_activation='hard_sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 unit_forget_bias=True,\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 **kwargs):\n-        super(ConvLSTM2DCell, self).__init__(**kwargs)\n-        self.filters = filters\n-        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n-                                                        'dilation_rate')\n-        self.activation = activations.get(activation)\n-        self.recurrent_activation = activations.get(recurrent_activation)\n-        self.use_bias = use_bias\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.unit_forget_bias = unit_forget_bias\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n-            warnings.warn(\n-                'RNN dropout is no longer supported with the Theano backend '\n-                'due to technical limitations. '\n-                'You can either set `dropout` and `recurrent_dropout` to 0, '\n-                'or use the TensorFlow backend.')\n-            dropout = 0.\n-            recurrent_dropout = 0.\n-        self.dropout = min(1., max(0., dropout))\n-        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n-        self.state_size = (self.filters, self.filters)\n-        self._dropout_mask = None\n-        self._recurrent_dropout_mask = None\n-\n-    def build(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            channel_axis = 1\n-        else:\n-            channel_axis = -1\n-        if input_shape[channel_axis] is None:\n-            raise ValueError('The channel dimension of the inputs '\n-                             'should be defined. Found `None`.')\n-        input_dim = input_shape[channel_axis]\n-        kernel_shape = self.kernel_size + (input_dim, self.filters * 4)\n-        self.kernel_shape = kernel_shape\n-        recurrent_kernel_shape = self.kernel_size + (self.filters, self.filters * 4)\n-\n-        self.kernel = self.add_weight(shape=kernel_shape,\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=recurrent_kernel_shape,\n-            initializer=self.recurrent_initializer,\n-            name='recurrent_kernel',\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-        if self.use_bias:\n-            if self.unit_forget_bias:\n-                @K.eager\n-                def bias_initializer(_, *args, **kwargs):\n-                    return K.concatenate([\n-                        self.bias_initializer((self.filters,), *args, **kwargs),\n-                        initializers.Ones()((self.filters,), *args, **kwargs),\n-                        self.bias_initializer((self.filters * 2,), *args, **kwargs),\n-                    ])\n-            else:\n-                bias_initializer = self.bias_initializer\n-            self.bias = self.add_weight(shape=(self.filters * 4,),\n-                                        name='bias',\n-                                        initializer=bias_initializer,\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-\n-        self.kernel_i = self.kernel[:, :, :, :self.filters]\n-        self.recurrent_kernel_i = self.recurrent_kernel[:, :, :, :self.filters]\n-        self.kernel_f = self.kernel[:, :, :, self.filters: self.filters * 2]\n-        self.recurrent_kernel_f = (\n-            self.recurrent_kernel[:, :, :, self.filters: self.filters * 2])\n-        self.kernel_c = self.kernel[:, :, :, self.filters * 2: self.filters * 3]\n-        self.recurrent_kernel_c = (\n-            self.recurrent_kernel[:, :, :, self.filters * 2: self.filters * 3])\n-        self.kernel_o = self.kernel[:, :, :, self.filters * 3:]\n-        self.recurrent_kernel_o = self.recurrent_kernel[:, :, :, self.filters * 3:]\n-\n-        if self.use_bias:\n-            self.bias_i = self.bias[:self.filters]\n-            self.bias_f = self.bias[self.filters: self.filters * 2]\n-            self.bias_c = self.bias[self.filters * 2: self.filters * 3]\n-            self.bias_o = self.bias[self.filters * 3:]\n-        else:\n-            self.bias_i = None\n-            self.bias_f = None\n-            self.bias_c = None\n-            self.bias_o = None\n-        self.built = True\n-\n-    def call(self, inputs, states, training=None):\n-        if 0 < self.dropout < 1 and self._dropout_mask is None:\n-            self._dropout_mask = _generate_dropout_mask(\n-                K.ones_like(inputs),\n-                self.dropout,\n-                training=training,\n-                count=4)\n-        if (0 < self.recurrent_dropout < 1 and\n-                self._recurrent_dropout_mask is None):\n-            self._recurrent_dropout_mask = _generate_dropout_mask(\n-                K.ones_like(states[1]),\n-                self.recurrent_dropout,\n-                training=training,\n-                count=4)\n-\n-        # dropout matrices for input units\n-        dp_mask = self._dropout_mask\n-        # dropout matrices for recurrent units\n-        rec_dp_mask = self._recurrent_dropout_mask\n-\n-        h_tm1 = states[0]  # previous memory state\n-        c_tm1 = states[1]  # previous carry state\n-\n-        if 0 < self.dropout < 1.:\n-            inputs_i = inputs * dp_mask[0]\n-            inputs_f = inputs * dp_mask[1]\n-            inputs_c = inputs * dp_mask[2]\n-            inputs_o = inputs * dp_mask[3]\n-        else:\n-            inputs_i = inputs\n-            inputs_f = inputs\n-            inputs_c = inputs\n-            inputs_o = inputs\n-\n-        if 0 < self.recurrent_dropout < 1.:\n-            h_tm1_i = h_tm1 * rec_dp_mask[0]\n-            h_tm1_f = h_tm1 * rec_dp_mask[1]\n-            h_tm1_c = h_tm1 * rec_dp_mask[2]\n-            h_tm1_o = h_tm1 * rec_dp_mask[3]\n-        else:\n-            h_tm1_i = h_tm1\n-            h_tm1_f = h_tm1\n-            h_tm1_c = h_tm1\n-            h_tm1_o = h_tm1\n-\n-        x_i = self.input_conv(inputs_i, self.kernel_i, self.bias_i,\n-                              padding=self.padding)\n-        x_f = self.input_conv(inputs_f, self.kernel_f, self.bias_f,\n-                              padding=self.padding)\n-        x_c = self.input_conv(inputs_c, self.kernel_c, self.bias_c,\n-                              padding=self.padding)\n-        x_o = self.input_conv(inputs_o, self.kernel_o, self.bias_o,\n-                              padding=self.padding)\n-        h_i = self.recurrent_conv(h_tm1_i,\n-                                  self.recurrent_kernel_i)\n-        h_f = self.recurrent_conv(h_tm1_f,\n-                                  self.recurrent_kernel_f)\n-        h_c = self.recurrent_conv(h_tm1_c,\n-                                  self.recurrent_kernel_c)\n-        h_o = self.recurrent_conv(h_tm1_o,\n-                                  self.recurrent_kernel_o)\n-\n-        i = self.recurrent_activation(x_i + h_i)\n-        f = self.recurrent_activation(x_f + h_f)\n-        c = f * c_tm1 + i * self.activation(x_c + h_c)\n-        o = self.recurrent_activation(x_o + h_o)\n-        h = o * self.activation(c)\n-\n-        if 0 < self.dropout + self.recurrent_dropout:\n-            if training is None:\n-                h._uses_learning_phase = True\n-\n-        return h, [h, c]\n-\n-    def input_conv(self, x, w, b=None, padding='valid'):\n-        conv_out = K.conv2d(x, w, strides=self.strides,\n-                            padding=padding,\n-                            data_format=self.data_format,\n-                            dilation_rate=self.dilation_rate)\n-        if b is not None:\n-            conv_out = K.bias_add(conv_out, b,\n-                                  data_format=self.data_format)\n-        return conv_out\n-\n-    def recurrent_conv(self, x, w):\n-        conv_out = K.conv2d(x, w, strides=(1, 1),\n-                            padding='same',\n-                            data_format=self.data_format)\n-        return conv_out\n-\n-    def get_config(self):\n-        config = {'filters': self.filters,\n-                  'kernel_size': self.kernel_size,\n-                  'strides': self.strides,\n-                  'padding': self.padding,\n-                  'data_format': self.data_format,\n-                  'dilation_rate': self.dilation_rate,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'unit_forget_bias': self.unit_forget_bias,\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'kernel_constraint':\n-                      constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout}\n-        base_config = super(ConvLSTM2DCell, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class ConvLSTM2D(ConvRNN2D):\n-    \"\"\"Convolutional LSTM.\n-\n-    It is similar to an LSTM layer, but the input transformations\n-    and recurrent transformations are both convolutional.\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number output of filters in the convolution).\n-        kernel_size: An integer or tuple/list of n integers, specifying the\n-            dimensions of the convolution window.\n-        strides: An integer or tuple/list of n integers,\n-            specifying the strides of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, time, ..., channels)`\n-            while `\"channels_first\"` corresponds to\n-            inputs with shape `(batch, time, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-        dilation_rate: An integer or tuple/list of n integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            tanh is applied by default.\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state.\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        unit_forget_bias: Boolean.\n-            If True, add 1 to the bias of the forget gate at initialization.\n-            Use in combination with `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al. (2015)](\n-            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-\n-    # Input shape\n-        - if data_format='channels_first'\n-            5D tensor with shape:\n-            `(samples, time, channels, rows, cols)`\n-        - if data_format='channels_last'\n-            5D tensor with shape:\n-            `(samples, time, rows, cols, channels)`\n-\n-    # Output shape\n-        - if `return_sequences`\n-             - if data_format='channels_first'\n-                5D tensor with shape:\n-                `(samples, time, filters, output_row, output_col)`\n-             - if data_format='channels_last'\n-                5D tensor with shape:\n-                `(samples, time, output_row, output_col, filters)`\n-        - else\n-            - if data_format='channels_first'\n-                4D tensor with shape:\n-                `(samples, filters, output_row, output_col)`\n-            - if data_format='channels_last'\n-                4D tensor with shape:\n-                `(samples, output_row, output_col, filters)`\n-            where o_row and o_col depend on the shape of the filter and\n-            the padding\n-\n-    # Raises\n-        ValueError: in case of invalid constructor arguments.\n-\n-    # References\n-        - [Convolutional LSTM Network: A Machine Learning Approach for\n-          Precipitation Nowcasting](http://arxiv.org/abs/1506.04214v1)\n-          The current implementation does not include the feedback loop on the\n-          cells output\n-    \"\"\"\n-\n-    @interfaces.legacy_convlstm2d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 activation='tanh',\n-                 recurrent_activation='hard_sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 unit_forget_bias=True,\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 return_sequences=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 **kwargs):\n-        cell = ConvLSTM2DCell(filters=filters,\n-                              kernel_size=kernel_size,\n-                              strides=strides,\n-                              padding=padding,\n-                              data_format=data_format,\n-                              dilation_rate=dilation_rate,\n-                              activation=activation,\n-                              recurrent_activation=recurrent_activation,\n-                              use_bias=use_bias,\n-                              kernel_initializer=kernel_initializer,\n-                              recurrent_initializer=recurrent_initializer,\n-                              bias_initializer=bias_initializer,\n-                              unit_forget_bias=unit_forget_bias,\n-                              kernel_regularizer=kernel_regularizer,\n-                              recurrent_regularizer=recurrent_regularizer,\n-                              bias_regularizer=bias_regularizer,\n-                              kernel_constraint=kernel_constraint,\n-                              recurrent_constraint=recurrent_constraint,\n-                              bias_constraint=bias_constraint,\n-                              dropout=dropout,\n-                              recurrent_dropout=recurrent_dropout)\n-        super(ConvLSTM2D, self).__init__(cell,\n-                                         return_sequences=return_sequences,\n-                                         go_backwards=go_backwards,\n-                                         stateful=stateful,\n-                                         **kwargs)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        return super(ConvLSTM2D, self).call(inputs,\n-                                            mask=mask,\n-                                            training=training,\n-                                            initial_state=initial_state)\n-\n-    @property\n-    def filters(self):\n-        return self.cell.filters\n-\n-    @property\n-    def kernel_size(self):\n-        return self.cell.kernel_size\n-\n-    @property\n-    def strides(self):\n-        return self.cell.strides\n-\n-    @property\n-    def padding(self):\n-        return self.cell.padding\n-\n-    @property\n-    def data_format(self):\n-        return self.cell.data_format\n-\n-    @property\n-    def dilation_rate(self):\n-        return self.cell.dilation_rate\n-\n-    @property\n-    def activation(self):\n-        return self.cell.activation\n-\n-    @property\n-    def recurrent_activation(self):\n-        return self.cell.recurrent_activation\n-\n-    @property\n-    def use_bias(self):\n-        return self.cell.use_bias\n-\n-    @property\n-    def kernel_initializer(self):\n-        return self.cell.kernel_initializer\n-\n-    @property\n-    def recurrent_initializer(self):\n-        return self.cell.recurrent_initializer\n-\n-    @property\n-    def bias_initializer(self):\n-        return self.cell.bias_initializer\n-\n-    @property\n-    def unit_forget_bias(self):\n-        return self.cell.unit_forget_bias\n-\n-    @property\n-    def kernel_regularizer(self):\n-        return self.cell.kernel_regularizer\n-\n-    @property\n-    def recurrent_regularizer(self):\n-        return self.cell.recurrent_regularizer\n-\n-    @property\n-    def bias_regularizer(self):\n-        return self.cell.bias_regularizer\n-\n-    @property\n-    def kernel_constraint(self):\n-        return self.cell.kernel_constraint\n-\n-    @property\n-    def recurrent_constraint(self):\n-        return self.cell.recurrent_constraint\n-\n-    @property\n-    def bias_constraint(self):\n-        return self.cell.bias_constraint\n-\n-    @property\n-    def dropout(self):\n-        return self.cell.dropout\n-\n-    @property\n-    def recurrent_dropout(self):\n-        return self.cell.recurrent_dropout\n-\n-    def get_config(self):\n-        config = {'filters': self.filters,\n-                  'kernel_size': self.kernel_size,\n-                  'strides': self.strides,\n-                  'padding': self.padding,\n-                  'data_format': self.data_format,\n-                  'dilation_rate': self.dilation_rate,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'unit_forget_bias': self.unit_forget_bias,\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'kernel_constraint':\n-                      constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout}\n-        base_config = super(ConvLSTM2D, self).get_config()\n-        del base_config['cell']\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        return cls(**config)\n+from tensorflow.keras.layers import ConvLSTM2D\n\n@@ -1,970 +1,17 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Core Keras layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-\n-import copy\n-import types as python_types\n-import warnings\n-\n-from .. import backend as K\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import InputSpec\n-from ..engine.base_layer import Layer\n-from ..utils.generic_utils import func_dump\n-from ..utils.generic_utils import func_load\n-from ..utils.generic_utils import deserialize_keras_object\n-from ..utils.generic_utils import has_arg\n-from ..legacy import interfaces\n-\n-\n-class Masking(Layer):\n-    \"\"\"Masks a sequence by using a mask value to skip timesteps.\n-\n-    If all features for a given sample timestep are equal to `mask_value`,\n-    then the sample timestep will be masked (skipped) in all downstream layers\n-    (as long as they support masking).\n-\n-    If any downstream layer does not support masking yet receives such\n-    an input mask, an exception will be raised.\n-\n-    # Example\n-\n-    Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\n-    to be fed to an LSTM layer.\n-    You want to mask sample #0 at timestep #3, and sample #2 at timestep #5,\n-    because you lack features for these sample timesteps. You can do:\n-\n-        - set `x[0, 3, :] = 0.` and `x[2, 5, :] = 0.`\n-        - insert a `Masking` layer with `mask_value=0.` before the LSTM layer:\n-\n-    ```python\n-        model = Sequential()\n-        model.add(Masking(mask_value=0., input_shape=(timesteps, features)))\n-        model.add(LSTM(32))\n-    ```\n-\n-    # Arguments\n-        mask_value: Either None or mask value to skip\n-    \"\"\"\n-\n-    def __init__(self, mask_value=0., **kwargs):\n-        super(Masking, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.mask_value = mask_value\n-\n-    def compute_mask(self, inputs, mask=None):\n-        output_mask = K.any(K.not_equal(inputs, self.mask_value), axis=-1)\n-        return output_mask\n-\n-    def call(self, inputs):\n-        boolean_mask = K.any(K.not_equal(inputs, self.mask_value),\n-                             axis=-1, keepdims=True)\n-        return inputs * K.cast(boolean_mask, K.dtype(inputs))\n-\n-    def get_config(self):\n-        config = {'mask_value': self.mask_value}\n-        base_config = super(Masking, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class Dropout(Layer):\n-    \"\"\"Applies Dropout to the input.\n-\n-    Dropout consists in randomly setting\n-    a fraction `rate` of input units to 0 at each update during training time,\n-    which helps prevent overfitting.\n-\n-    # Arguments\n-        rate: float between 0 and 1. Fraction of the input units to drop.\n-        noise_shape: 1D integer tensor representing the shape of the\n-            binary dropout mask that will be multiplied with the input.\n-            For instance, if your inputs have shape\n-            `(batch_size, timesteps, features)` and\n-            you want the dropout mask to be the same for all timesteps,\n-            you can use `noise_shape=(batch_size, 1, features)`.\n-        seed: A Python integer to use as random seed.\n-\n-    # References\n-        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n-           http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n-    \"\"\"\n-    @interfaces.legacy_dropout_support\n-    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n-        super(Dropout, self).__init__(**kwargs)\n-        self.rate = min(1., max(0., rate))\n-        self.noise_shape = noise_shape\n-        self.seed = seed\n-        self.supports_masking = True\n-\n-    def _get_noise_shape(self, inputs):\n-        if self.noise_shape is None:\n-            return self.noise_shape\n-\n-        symbolic_shape = K.shape(inputs)\n-        noise_shape = [symbolic_shape[axis] if shape is None else shape\n-                       for axis, shape in enumerate(self.noise_shape)]\n-        return tuple(noise_shape)\n-\n-    def call(self, inputs, training=None):\n-        if 0. < self.rate < 1.:\n-            noise_shape = self._get_noise_shape(inputs)\n-\n-            def dropped_inputs():\n-                return K.dropout(inputs, self.rate, noise_shape,\n-                                 seed=self.seed)\n-            return K.in_train_phase(dropped_inputs, inputs,\n-                                    training=training)\n-        return inputs\n-\n-    def get_config(self):\n-        config = {'rate': self.rate,\n-                  'noise_shape': self.noise_shape,\n-                  'seed': self.seed}\n-        base_config = super(Dropout, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class SpatialDropout1D(Dropout):\n-    \"\"\"Spatial 1D version of Dropout.\n-\n-    This version performs the same function as Dropout, however it drops\n-    entire 1D feature maps instead of individual elements. If adjacent frames\n-    within feature maps are strongly correlated (as is normally the case in\n-    early convolution layers) then regular dropout will not regularize the\n-    activations and will otherwise just result in an effective learning rate\n-    decrease. In this case, SpatialDropout1D will help promote independence\n-    between feature maps and should be used instead.\n-\n-    # Arguments\n-        rate: float between 0 and 1. Fraction of the input units to drop.\n-\n-    # Input shape\n-        3D tensor with shape:\n-        `(samples, timesteps, channels)`\n-\n-    # Output shape\n-        Same as input\n-\n-    # References\n-        - [Efficient Object Localization Using Convolutional Networks](\n-           https://arxiv.org/abs/1411.4280)\n-    \"\"\"\n-\n-    @interfaces.legacy_spatialdropout1d_support\n-    def __init__(self, rate, **kwargs):\n-        super(SpatialDropout1D, self).__init__(rate, **kwargs)\n-        self.input_spec = InputSpec(ndim=3)\n-\n-    def _get_noise_shape(self, inputs):\n-        input_shape = K.shape(inputs)\n-        noise_shape = (input_shape[0], 1, input_shape[2])\n-        return noise_shape\n-\n-\n-class SpatialDropout2D(Dropout):\n-    \"\"\"Spatial 2D version of Dropout.\n-\n-    This version performs the same function as Dropout, however it drops\n-    entire 2D feature maps instead of individual elements. If adjacent pixels\n-    within feature maps are strongly correlated (as is normally the case in\n-    early convolution layers) then regular dropout will not regularize the\n-    activations and will otherwise just result in an effective learning rate\n-    decrease. In this case, SpatialDropout2D will help promote independence\n-    between feature maps and should be used instead.\n-\n-    # Arguments\n-        rate: float between 0 and 1. Fraction of the input units to drop.\n-        data_format: `'channels_first'` or `'channels_last'`.\n-            In `'channels_first'` mode, the channels dimension\n-            (the depth) is at index 1,\n-            in `'channels_last'` mode is it at index 3.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `'channels_last'`.\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if `data_format='channels_first'`\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if `data_format='channels_last'`.\n-\n-    # Output shape\n-        Same as input\n-\n-    # References\n-        - [Efficient Object Localization Using Convolutional Networks](\n-           https://arxiv.org/abs/1411.4280)\n-    \"\"\"\n-\n-    @interfaces.legacy_spatialdropoutNd_support\n-    def __init__(self, rate, data_format=None, **kwargs):\n-        super(SpatialDropout2D, self).__init__(rate, **kwargs)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=4)\n-\n-    def _get_noise_shape(self, inputs):\n-        input_shape = K.shape(inputs)\n-        if self.data_format == 'channels_first':\n-            noise_shape = (input_shape[0], input_shape[1], 1, 1)\n-        else:\n-            noise_shape = (input_shape[0], 1, 1, input_shape[3])\n-        return noise_shape\n-\n-\n-class SpatialDropout3D(Dropout):\n-    \"\"\"Spatial 3D version of Dropout.\n-\n-    This version performs the same function as Dropout, however it drops\n-    entire 3D feature maps instead of individual elements. If adjacent voxels\n-    within feature maps are strongly correlated (as is normally the case in\n-    early convolution layers) then regular dropout will not regularize the\n-    activations and will otherwise just result in an effective learning rate\n-    decrease. In this case, SpatialDropout3D will help promote independence\n-    between feature maps and should be used instead.\n-\n-    # Arguments\n-        rate: float between 0 and 1. Fraction of the input units to drop.\n-        data_format: `'channels_first'` or `'channels_last'`.\n-            In `'channels_first'` mode, the channels dimension (the depth)\n-            is at index 1, in `'channels_last'` mode is it at index 4.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `'channels_last'`.\n-\n-    # Input shape\n-        5D tensor with shape:\n-        `(samples, channels, dim1, dim2, dim3)` if `data_format='channels_first'`\n-        or 5D tensor with shape:\n-        `(samples, dim1, dim2, dim3, channels)` if `data_format='channels_last'`.\n-\n-    # Output shape\n-        Same as input\n-\n-    # References\n-        - [Efficient Object Localization Using Convolutional Networks](\n-           https://arxiv.org/abs/1411.4280)\n-    \"\"\"\n-\n-    @interfaces.legacy_spatialdropoutNd_support\n-    def __init__(self, rate, data_format=None, **kwargs):\n-        super(SpatialDropout3D, self).__init__(rate, **kwargs)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=5)\n-\n-    def _get_noise_shape(self, inputs):\n-        input_shape = K.shape(inputs)\n-        if self.data_format == 'channels_first':\n-            noise_shape = (input_shape[0], input_shape[1], 1, 1, 1)\n-        else:\n-            noise_shape = (input_shape[0], 1, 1, 1, input_shape[4])\n-        return noise_shape\n-\n-\n-class Activation(Layer):\n-    \"\"\"Applies an activation function to an output.\n-\n-    # Arguments\n-        activation: name of activation function to use\n-            (see: [activations](../activations.md)),\n-            or alternatively, a Theano or TensorFlow operation.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-    \"\"\"\n-\n-    def __init__(self, activation, **kwargs):\n-        super(Activation, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.activation = activations.get(activation)\n-\n-    def call(self, inputs):\n-        return self.activation(inputs)\n-\n-    def get_config(self):\n-        config = {'activation': activations.serialize(self.activation)}\n-        base_config = super(Activation, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class Reshape(Layer):\n-    \"\"\"Reshapes an output to a certain shape.\n-\n-    # Arguments\n-        target_shape: target shape. Tuple of integers.\n-            Does not include the batch axis.\n-\n-    # Input shape\n-        Arbitrary, although all dimensions in the input shaped must be fixed.\n-        Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the batch axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        `(batch_size,) + target_shape`\n-\n-    # Example\n-\n-    ```python\n-        # as first layer in a Sequential model\n-        model = Sequential()\n-        model.add(Reshape((3, 4), input_shape=(12,)))\n-        # now: model.output_shape == (None, 3, 4)\n-        # note: `None` is the batch dimension\n-\n-        # as intermediate layer in a Sequential model\n-        model.add(Reshape((6, 2)))\n-        # now: model.output_shape == (None, 6, 2)\n-\n-        # also supports shape inference using `-1` as dimension\n-        model.add(Reshape((-1, 2, 2)))\n-        # now: model.output_shape == (None, 3, 2, 2)\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, target_shape, **kwargs):\n-        super(Reshape, self).__init__(**kwargs)\n-        self.target_shape = tuple(target_shape)\n-\n-    def _fix_unknown_dimension(self, input_shape, output_shape):\n-        \"\"\"Finds and replaces a missing dimension in an output shape.\n-\n-        This is a near direct port of the internal Numpy function\n-        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`\n-\n-        # Arguments\n-            input_shape: original shape of array being reshaped\n-            output_shape: target shape of the array, with at most\n-                a single -1 which indicates a dimension that should be\n-                derived from the input shape.\n-\n-        # Returns\n-            The new output shape with a `-1` replaced with its computed value.\n-\n-        # Raises\n-            ValueError: if `input_shape` and `output_shape` do not match.\n-        \"\"\"\n-        output_shape = list(output_shape)\n-        msg = 'total size of new array must be unchanged'\n-\n-        known, unknown = 1, None\n-        for index, dim in enumerate(output_shape):\n-            if dim < 0:\n-                if unknown is None:\n-                    unknown = index\n-                else:\n-                    raise ValueError('Can only specify one unknown dimension.')\n-            else:\n-                known *= dim\n-\n-        original = np.prod(input_shape, dtype=int)\n-        if unknown is not None:\n-            if known == 0 or original % known != 0:\n-                raise ValueError(msg)\n-            output_shape[unknown] = original // known\n-        elif original != known:\n-            raise ValueError(msg)\n-\n-        return tuple(output_shape)\n-\n-    def compute_output_shape(self, input_shape):\n-        if None in input_shape[1:]:\n-            # input shape (partially) unknown? replace -1's with None's\n-            return ((input_shape[0],) +\n-                    tuple(s if s != -1 else None for s in self.target_shape))\n-        else:\n-            # input shape known? then we can compute the output shape\n-            return (input_shape[0],) + self._fix_unknown_dimension(\n-                input_shape[1:], self.target_shape)\n-\n-    def call(self, inputs):\n-        return K.reshape(inputs, (K.shape(inputs)[0],) + self.target_shape)\n-\n-    def get_config(self):\n-        config = {'target_shape': self.target_shape}\n-        base_config = super(Reshape, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Permute(Layer):\n-    \"\"\"Permutes the dimensions of the input according to a given pattern.\n-\n-    Useful for e.g. connecting RNNs and convnets together.\n-\n-    # Example\n-\n-    ```python\n-        model = Sequential()\n-        model.add(Permute((2, 1), input_shape=(10, 64)))\n-        # now: model.output_shape == (None, 64, 10)\n-        # note: `None` is the batch dimension\n-    ```\n-\n-    # Arguments\n-        dims: Tuple of integers. Permutation pattern, does not include the\n-            samples dimension. Indexing starts at 1.\n-            For instance, `(2, 1)` permutes the first and second dimension\n-            of the input.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same as the input shape, but with the dimensions re-ordered according\n-        to the specified pattern.\n-    \"\"\"\n-\n-    def __init__(self, dims, **kwargs):\n-        super(Permute, self).__init__(**kwargs)\n-        self.dims = tuple(dims)\n-        self.input_spec = InputSpec(ndim=len(self.dims) + 1)\n-\n-    def compute_output_shape(self, input_shape):\n-        input_shape = list(input_shape)\n-        output_shape = copy.copy(input_shape)\n-        for i, dim in enumerate(self.dims):\n-            target_dim = input_shape[dim]\n-            output_shape[i + 1] = target_dim\n-        return tuple(output_shape)\n-\n-    def call(self, inputs):\n-        return K.permute_dimensions(inputs, (0,) + self.dims)\n-\n-    def get_config(self):\n-        config = {'dims': self.dims}\n-        base_config = super(Permute, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Flatten(Layer):\n-    \"\"\"Flattens the input. Does not affect the batch size.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `'channels_last'` (default) or `'channels_first'`.\n-            The ordering of the dimensions in the inputs.\n-            The purpose of this argument is to preserve weight\n-            ordering when switching a model from one data format\n-            to another.\n-            `'channels_last'` corresponds to inputs with shape\n-            `(batch, ..., channels)` while `'channels_first'` corresponds to\n-            inputs with shape `(batch, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `'channels_last'`.\n-\n-    # Example\n-\n-    ```python\n-        model = Sequential()\n-        model.add(Conv2D(64, (3, 3),\n-                         input_shape=(3, 32, 32), padding='same',))\n-        # now: model.output_shape == (None, 64, 32, 32)\n-\n-        model.add(Flatten())\n-        # now: model.output_shape == (None, 65536)\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, data_format=None, **kwargs):\n-        super(Flatten, self).__init__(**kwargs)\n-        self.input_spec = InputSpec(min_ndim=3)\n-        self.data_format = K.normalize_data_format(data_format)\n-\n-    def compute_output_shape(self, input_shape):\n-        if not all(input_shape[1:]):\n-            raise ValueError('The shape of the input to \"Flatten\" '\n-                             'is not fully defined '\n-                             '(got ' + str(input_shape[1:]) + '). '\n-                             'Make sure to pass a complete \"input_shape\" '\n-                             'or \"batch_input_shape\" argument to the first '\n-                             'layer in your model.')\n-        return (input_shape[0], np.prod(input_shape[1:]))\n-\n-    def call(self, inputs):\n-        if self.data_format == 'channels_first':\n-            # Ensure works for any dim\n-            permutation = [0]\n-            permutation.extend([i for i in\n-                                range(2, K.ndim(inputs))])\n-            permutation.append(1)\n-            inputs = K.permute_dimensions(inputs, permutation)\n-\n-        return K.batch_flatten(inputs)\n-\n-    def get_config(self):\n-        config = {'data_format': self.data_format}\n-        base_config = super(Flatten, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class RepeatVector(Layer):\n-    \"\"\"Repeats the input n times.\n-\n-    # Example\n-\n-    ```python\n-        model = Sequential()\n-        model.add(Dense(32, input_dim=32))\n-        # now: model.output_shape == (None, 32)\n-        # note: `None` is the batch dimension\n-\n-        model.add(RepeatVector(3))\n-        # now: model.output_shape == (None, 3, 32)\n-    ```\n-\n-    # Arguments\n-        n: integer, repetition factor.\n-\n-    # Input shape\n-        2D tensor of shape `(num_samples, features)`.\n-\n-    # Output shape\n-        3D tensor of shape `(num_samples, n, features)`.\n-    \"\"\"\n-\n-    def __init__(self, n, **kwargs):\n-        super(RepeatVector, self).__init__(**kwargs)\n-        self.n = n\n-        self.input_spec = InputSpec(ndim=2)\n-\n-    def compute_output_shape(self, input_shape):\n-        return (input_shape[0], self.n, input_shape[1])\n-\n-    def call(self, inputs):\n-        return K.repeat(inputs, self.n)\n-\n-    def get_config(self):\n-        config = {'n': self.n}\n-        base_config = super(RepeatVector, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Lambda(Layer):\n-    \"\"\"Wraps arbitrary expression as a `Layer` object.\n-\n-    # Examples\n-\n-    ```python\n-        # add a x -> x^2 layer\n-        model.add(Lambda(lambda x: x ** 2))\n-    ```\n-    ```python\n-        # add a layer that returns the concatenation\n-        # of the positive part of the input and\n-        # the opposite of the negative part\n-\n-        def antirectifier(x):\n-            x -= K.mean(x, axis=1, keepdims=True)\n-            x = K.l2_normalize(x, axis=1)\n-            pos = K.relu(x)\n-            neg = K.relu(-x)\n-            return K.concatenate([pos, neg], axis=1)\n-\n-        def antirectifier_output_shape(input_shape):\n-            shape = list(input_shape)\n-            assert len(shape) == 2  # only valid for 2D tensors\n-            shape[-1] *= 2\n-            return tuple(shape)\n-\n-        model.add(Lambda(antirectifier,\n-                         output_shape=antirectifier_output_shape))\n-    ```\n-    ```python\n-        # add a layer that returns the hadamard product\n-        # and sum of it from two input tensors\n-\n-        def hadamard_product_sum(tensors):\n-            out1 = tensors[0] * tensors[1]\n-            out2 = K.sum(out1, axis=-1)\n-            return [out1, out2]\n-\n-        def hadamard_product_sum_output_shape(input_shapes):\n-            shape1 = list(input_shapes[0])\n-            shape2 = list(input_shapes[1])\n-            assert shape1 == shape2  # else hadamard product isn't possible\n-            return [tuple(shape1), tuple(shape2[:-1])]\n-\n-        x1 = Dense(32)(input_1)\n-        x2 = Dense(32)(input_2)\n-        layer = Lambda(hadamard_product_sum, hadamard_product_sum_output_shape)\n-        x_hadamard, x_sum = layer([x1, x2])\n-    ```\n-\n-    # Arguments\n-        function: The function to be evaluated.\n-            Takes input tensor or list of tensors as first argument.\n-        output_shape: Expected output shape from function.\n-            Only relevant when using Theano.\n-            Can be a tuple or function.\n-            If a tuple, it only specifies the first dimension onward;\n-                 sample dimension is assumed either the same as the input:\n-                 `output_shape = (input_shape[0], ) + output_shape`\n-                 or, the input is `None` and\n-                 the sample dimension is also `None`:\n-                 `output_shape = (None, ) + output_shape`\n-            If a function, it specifies the entire shape as a function of the\n-            input shape: `output_shape = f(input_shape)`\n-        mask: Either None (indicating no masking) or a Tensor indicating the\n-          input mask for Embedding.\n-        arguments: optional dictionary of keyword arguments to be passed\n-            to the function.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument input_shape\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Specified by `output_shape` argument\n-        (or auto-inferred when using TensorFlow or CNTK).\n-    \"\"\"\n-\n-    @interfaces.legacy_lambda_support\n-    def __init__(self, function, output_shape=None,\n-                 mask=None, arguments=None, **kwargs):\n-        super(Lambda, self).__init__(**kwargs)\n-        self.function = function\n-        self._input_dtypes = None\n-        self.arguments = arguments if arguments else {}\n-        if mask is not None:\n-            self.supports_masking = True\n-        self.mask = mask\n-\n-        if output_shape is None:\n-            self._output_shape = None\n-        elif isinstance(output_shape, (tuple, list)):\n-            self._output_shape = tuple(output_shape)\n-        else:\n-            if not callable(output_shape):\n-                raise TypeError('In Lambda, `output_shape` '\n-                                'must be a list, a tuple, or a function.')\n-            self._output_shape = output_shape\n-\n-    def compute_output_shape(self, input_shape):\n-        if self._output_shape is None:\n-            # With TensorFlow or CNTK, we can infer the output shape directly:\n-            if K.backend() in ('tensorflow', 'cntk'):\n-                if isinstance(input_shape, list):\n-                    xs = [K.placeholder(shape=shape, dtype=dtype)\n-                          for shape, dtype in zip(input_shape, self._input_dtypes)]\n-                    x = self.call(xs)\n-                else:\n-                    x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)\n-                    x = self.call(x)\n-                if isinstance(x, list):\n-                    return [K.int_shape(x_elem) for x_elem in x]\n-                else:\n-                    return K.int_shape(x)\n-            # Otherwise, we default to the input shape.\n-            warnings.warn('`output_shape` argument not specified for layer {} '\n-                          'and cannot be automatically inferred '\n-                          'with the Theano backend. '\n-                          'Defaulting to output shape `{}` '\n-                          '(same as input shape). '\n-                          'If the expected output shape is different, '\n-                          'specify it via the `output_shape` argument.'\n-                          .format(self.name, input_shape))\n-            return input_shape\n-        elif isinstance(self._output_shape, (tuple, list)):\n-            if isinstance(input_shape, list):\n-                num_samples = input_shape[0][0]\n-            else:\n-                num_samples = input_shape[0] if input_shape else None\n-            return (num_samples,) + tuple(self._output_shape)\n-        else:\n-            shape = self._output_shape(input_shape)\n-            if not isinstance(shape, (list, tuple)):\n-                raise ValueError('`output_shape` function must return a tuple or '\n-                                 'a list of tuples.')\n-            if isinstance(shape, list):\n-                if isinstance(shape[0], int) or shape[0] is None:\n-                    shape = tuple(shape)\n-            return shape\n-\n-    def call(self, inputs, mask=None):\n-        arguments = self.arguments\n-        if has_arg(self.function, 'mask'):\n-            arguments['mask'] = mask\n-        if isinstance(inputs, list):\n-            self._input_dtypes = [K.dtype(x) for x in inputs]\n-        else:\n-            self._input_dtypes = K.dtype(inputs)\n-        return self.function(inputs, **arguments)\n-\n-    def compute_mask(self, inputs, mask=None):\n-        if callable(self.mask):\n-            return self.mask(inputs, mask)\n-        return self.mask\n-\n-    def get_config(self):\n-        if isinstance(self.function, python_types.LambdaType):\n-            function = func_dump(self.function)\n-            function_type = 'lambda'\n-        else:\n-            function = self.function.__name__\n-            function_type = 'function'\n-\n-        if isinstance(self._output_shape, python_types.LambdaType):\n-            output_shape = func_dump(self._output_shape)\n-            output_shape_type = 'lambda'\n-        elif callable(self._output_shape):\n-            output_shape = self._output_shape.__name__\n-            output_shape_type = 'function'\n-        else:\n-            output_shape = self._output_shape\n-            output_shape_type = 'raw'\n-\n-        config = {'function': function,\n-                  'function_type': function_type,\n-                  'output_shape': output_shape,\n-                  'output_shape_type': output_shape_type,\n-                  'arguments': self.arguments}\n-        base_config = super(Lambda, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        config = config.copy()\n-        globs = globals()\n-        if custom_objects:\n-            globs = dict(list(globs.items()) + list(custom_objects.items()))\n-        function_type = config.pop('function_type')\n-        if function_type == 'function':\n-            # Simple lookup in custom objects\n-            function = deserialize_keras_object(\n-                config['function'],\n-                custom_objects=custom_objects,\n-                printable_module_name='function in Lambda layer')\n-        elif function_type == 'lambda':\n-            # Unsafe deserialization from bytecode\n-            function = func_load(config['function'], globs=globs)\n-        else:\n-            raise TypeError('Unknown function type:', function_type)\n-\n-        output_shape_type = config.pop('output_shape_type')\n-        if output_shape_type == 'function':\n-            # Simple lookup in custom objects\n-            output_shape = deserialize_keras_object(\n-                config['output_shape'],\n-                custom_objects=custom_objects,\n-                printable_module_name='output_shape function in Lambda layer')\n-        elif output_shape_type == 'lambda':\n-            # Unsafe deserialization from bytecode\n-            output_shape = func_load(config['output_shape'], globs=globs)\n-        else:\n-            output_shape = config['output_shape']\n-\n-        # If arguments were numpy array, they have been saved as\n-        # list. We need to recover the ndarray\n-        if 'arguments' in config:\n-            for key in config['arguments']:\n-                if isinstance(config['arguments'][key], dict):\n-                    arg_dict = config['arguments'][key]\n-                    if 'type' in arg_dict and arg_dict['type'] == 'ndarray':\n-                        # Overwrite the argument with its numpy translation\n-                        config['arguments'][key] = np.array(arg_dict['value'])\n-\n-        config['function'] = function\n-        config['output_shape'] = output_shape\n-        return cls(**config)\n-\n-\n-class Dense(Layer):\n-    \"\"\"Just your regular densely-connected NN layer.\n-\n-    `Dense` implements the operation:\n-    `output = activation(dot(input, kernel) + bias)`\n-    where `activation` is the element-wise activation function\n-    passed as the `activation` argument, `kernel` is a weights matrix\n-    created by the layer, and `bias` is a bias vector created by the layer\n-    (only applicable if `use_bias` is `True`).\n-\n-    Note: if the input to the layer has a rank greater than 2, then\n-    it is flattened prior to the initial dot product with `kernel`.\n-\n-    # Example\n-\n-    ```python\n-        # as first layer in a sequential model:\n-        model = Sequential()\n-        model.add(Dense(32, input_shape=(16,)))\n-        # now the model will take as input arrays of shape (*, 16)\n-        # and output arrays of shape (*, 32)\n-\n-        # after the first layer, you don't need to specify\n-        # the size of the input anymore:\n-        model.add(Dense(32))\n-    ```\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        nD tensor with shape: `(batch_size, ..., input_dim)`.\n-        The most common situation would be\n-        a 2D input with shape `(batch_size, input_dim)`.\n-\n-    # Output shape\n-        nD tensor with shape: `(batch_size, ..., units)`.\n-        For instance, for a 2D input with shape `(batch_size, input_dim)`,\n-        the output would have shape `(batch_size, units)`.\n-    \"\"\"\n-\n-    @interfaces.legacy_dense_support\n-    def __init__(self, units,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n-            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n-        super(Dense, self).__init__(**kwargs)\n-        self.units = units\n-        self.activation = activations.get(activation)\n-        self.use_bias = use_bias\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-        self.input_spec = InputSpec(min_ndim=2)\n-        self.supports_masking = True\n-\n-    def build(self, input_shape):\n-        assert len(input_shape) >= 2\n-        input_dim = input_shape[-1]\n-\n-        self.kernel = self.add_weight(shape=(input_dim, self.units),\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.units,),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n-        self.built = True\n-\n-    def call(self, inputs):\n-        output = K.dot(inputs, self.kernel)\n-        if self.use_bias:\n-            output = K.bias_add(output, self.bias, data_format='channels_last')\n-        if self.activation is not None:\n-            output = self.activation(output)\n-        return output\n-\n-    def compute_output_shape(self, input_shape):\n-        assert input_shape and len(input_shape) >= 2\n-        assert input_shape[-1]\n-        output_shape = list(input_shape)\n-        output_shape[-1] = self.units\n-        return tuple(output_shape)\n-\n-    def get_config(self):\n-        config = {\n-            'units': self.units,\n-            'activation': activations.serialize(self.activation),\n-            'use_bias': self.use_bias,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)\n-        }\n-        base_config = super(Dense, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class ActivityRegularization(Layer):\n-    \"\"\"Layer that applies an update to the cost function based input activity.\n-\n-    # Arguments\n-        l1: L1 regularization factor (positive float).\n-        l2: L2 regularization factor (positive float).\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-    \"\"\"\n-\n-    def __init__(self, l1=0., l2=0., **kwargs):\n-        super(ActivityRegularization, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.l1 = l1\n-        self.l2 = l2\n-        self.activity_regularizer = regularizers.L1L2(l1=l1, l2=l2)\n-\n-    def get_config(self):\n-        config = {'l1': self.l1,\n-                  'l2': self.l2}\n-        base_config = super(ActivityRegularization, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+\"\"\"Core Keras layers.\"\"\"\n+\n+from tensorflow.keras.layers import Dense\n+from tensorflow.keras.layers import Activation\n+from tensorflow.keras.layers import ActivityRegularization\n+from tensorflow.keras.layers import Lambda\n+from tensorflow.keras.layers import Masking\n+\n+from tensorflow.keras.layers import Dropout\n+from tensorflow.keras.layers import SpatialDropout1D\n+from tensorflow.keras.layers import SpatialDropout2D\n+from tensorflow.keras.layers import SpatialDropout3D\n+\n+from tensorflow.keras.layers import Flatten\n+from tensorflow.keras.layers import Permute\n+from tensorflow.keras.layers import RepeatVector\n+from tensorflow.keras.layers import Reshape\n\n@@ -1,546 +1,4 @@\n-\"\"\"Recurrent layers backed by cuDNN.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Recurrent layers backed by cuDNN.\"\"\"\n \n-from .. import backend as K\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from .recurrent import RNN\n-from ..layers import InputSpec\n-\n-from collections import namedtuple\n-\n-\n-class _CuDNNRNN(RNN):\n-    \"\"\"Private base class for CuDNNGRU and CuDNNLSTM.\n-\n-    # Arguments\n-        return_sequences: Boolean. Whether to return the last output.\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 **kwargs):\n-        if K.backend() != 'tensorflow':\n-            raise RuntimeError('CuDNN RNNs are only available '\n-                               'with the TensorFlow backend.')\n-        super(RNN, self).__init__(**kwargs)\n-        self.return_sequences = return_sequences\n-        self.return_state = return_state\n-        self.go_backwards = go_backwards\n-        self.stateful = stateful\n-        self.supports_masking = False\n-        self.input_spec = [InputSpec(ndim=3)]\n-        if hasattr(self.cell.state_size, '__len__'):\n-            state_size = self.cell.state_size\n-        else:\n-            state_size = [self.cell.state_size]\n-        self.state_spec = [InputSpec(shape=(None, dim))\n-                           for dim in state_size]\n-        self.constants_spec = None\n-        self._states = None\n-        self._num_constants = None\n-\n-    def _canonical_to_params(self, weights, biases):\n-        import tensorflow as tf\n-        weights = [tf.reshape(x, (-1,)) for x in weights]\n-        biases = [tf.reshape(x, (-1,)) for x in biases]\n-        return tf.concat(weights + biases, 0)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-        if mask is not None:\n-            raise ValueError('Masking is not supported for CuDNN RNNs.')\n-\n-        # input shape: `(samples, time (padded with zeros), input_dim)`\n-        # note that the .build() method of subclasses MUST define\n-        # self.input_spec and self.state_spec with complete input shapes.\n-        if isinstance(inputs, list):\n-            initial_state = inputs[1:]\n-            inputs = inputs[0]\n-        elif initial_state is not None:\n-            pass\n-        elif self.stateful:\n-            initial_state = self.states\n-        else:\n-            initial_state = self.get_initial_state(inputs)\n-\n-        if len(initial_state) != len(self.states):\n-            raise ValueError('Layer has ' + str(len(self.states)) +\n-                             ' states but was passed ' +\n-                             str(len(initial_state)) +\n-                             ' initial states.')\n-\n-        if self.go_backwards:\n-            # Reverse time axis.\n-            inputs = K.reverse(inputs, 1)\n-        output, states = self._process_batch(inputs, initial_state)\n-\n-        if self.stateful:\n-            updates = []\n-            for i in range(len(states)):\n-                updates.append((self.states[i], states[i]))\n-            self.add_update(updates, inputs)\n-\n-        if self.return_state:\n-            return [output] + states\n-        else:\n-            return output\n-\n-    def get_config(self):\n-        config = {'return_sequences': self.return_sequences,\n-                  'return_state': self.return_state,\n-                  'go_backwards': self.go_backwards,\n-                  'stateful': self.stateful}\n-        base_config = super(RNN, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        return cls(**config)\n-\n-    @property\n-    def trainable_weights(self):\n-        if self.trainable and self.built:\n-            return [self.kernel, self.recurrent_kernel, self.bias]\n-        return []\n-\n-    @property\n-    def non_trainable_weights(self):\n-        if not self.trainable and self.built:\n-            return [self.kernel, self.recurrent_kernel, self.bias]\n-        return []\n-\n-    @property\n-    def losses(self):\n-        return super(RNN, self).losses\n-\n-    def get_losses_for(self, inputs=None):\n-        return super(RNN, self).get_losses_for(inputs=inputs)\n-\n-\n-class CuDNNGRU(_CuDNNRNN):\n-    \"\"\"Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).\n-\n-    Can only be run on GPU, with the TensorFlow backend.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state.\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        return_sequences: Boolean. Whether to return the last output.\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-    \"\"\"\n-\n-    def __init__(self, units,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 stateful=False,\n-                 **kwargs):\n-        self.units = units\n-        super(CuDNNGRU, self).__init__(\n-            return_sequences=return_sequences,\n-            return_state=return_state,\n-            stateful=stateful,\n-            **kwargs)\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-    @property\n-    def cell(self):\n-        Cell = namedtuple('cell', 'state_size')\n-        cell = Cell(state_size=self.units)\n-        return cell\n-\n-    def build(self, input_shape):\n-        super(CuDNNGRU, self).build(input_shape)\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-        input_dim = input_shape[-1]\n-\n-        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n-        self._cudnn_gru = cudnn_rnn_ops.CudnnGRU(\n-            num_layers=1,\n-            num_units=self.units,\n-            input_size=input_dim,\n-            input_mode='linear_input')\n-\n-        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n-                                      name='kernel',\n-                                      initializer=self.kernel_initializer,\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units * 3),\n-            name='recurrent_kernel',\n-            initializer=self.recurrent_initializer,\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-\n-        self.bias = self.add_weight(shape=(self.units * 6,),\n-                                    name='bias',\n-                                    initializer=self.bias_initializer,\n-                                    regularizer=self.bias_regularizer,\n-                                    constraint=self.bias_constraint)\n-\n-        self.kernel_z = self.kernel[:, :self.units]\n-        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n-        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n-        self.recurrent_kernel_r = self.recurrent_kernel[:,\n-                                                        self.units:\n-                                                        self.units * 2]\n-        self.kernel_h = self.kernel[:, self.units * 2:]\n-        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n-\n-        self.bias_z_i = self.bias[:self.units]\n-        self.bias_r_i = self.bias[self.units: self.units * 2]\n-        self.bias_h_i = self.bias[self.units * 2: self.units * 3]\n-        self.bias_z = self.bias[self.units * 3: self.units * 4]\n-        self.bias_r = self.bias[self.units * 4: self.units * 5]\n-        self.bias_h = self.bias[self.units * 5:]\n-\n-        self.built = True\n-\n-    def _process_batch(self, inputs, initial_state):\n-        import tensorflow as tf\n-        inputs = tf.transpose(inputs, (1, 0, 2))\n-        input_h = initial_state[0]\n-        input_h = tf.expand_dims(input_h, axis=0)\n-\n-        params = self._canonical_to_params(\n-            weights=[\n-                self.kernel_r,\n-                self.kernel_z,\n-                self.kernel_h,\n-                self.recurrent_kernel_r,\n-                self.recurrent_kernel_z,\n-                self.recurrent_kernel_h,\n-            ],\n-            biases=[\n-                self.bias_r_i,\n-                self.bias_z_i,\n-                self.bias_h_i,\n-                self.bias_r,\n-                self.bias_z,\n-                self.bias_h,\n-            ],\n-        )\n-        outputs, h = self._cudnn_gru(\n-            inputs,\n-            input_h=input_h,\n-            params=params,\n-            is_training=True)\n-\n-        if self.stateful or self.return_state:\n-            h = h[0]\n-        if self.return_sequences:\n-            output = tf.transpose(outputs, (1, 0, 2))\n-        else:\n-            output = outputs[-1]\n-        return output, [h]\n-\n-    def get_config(self):\n-        config = {\n-            'units': self.units,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'recurrent_initializer':\n-                initializers.serialize(self.recurrent_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'recurrent_regularizer':\n-                regularizers.serialize(self.recurrent_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'recurrent_constraint':\n-                constraints.serialize(self.recurrent_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)}\n-        base_config = super(CuDNNGRU, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class CuDNNLSTM(_CuDNNRNN):\n-    \"\"\"Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n-\n-    Can only be run on GPU, with the TensorFlow backend.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state.\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        unit_forget_bias: Boolean.\n-            If True, add 1 to the bias of the forget gate at initialization.\n-            Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al. (2015)](\n-            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        return_sequences: Boolean. Whether to return the last output.\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-    \"\"\"\n-    def __init__(self, units,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 unit_forget_bias=True,\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 stateful=False,\n-                 **kwargs):\n-        self.units = units\n-        super(CuDNNLSTM, self).__init__(\n-            return_sequences=return_sequences,\n-            return_state=return_state,\n-            stateful=stateful,\n-            **kwargs)\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.unit_forget_bias = unit_forget_bias\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-    @property\n-    def cell(self):\n-        Cell = namedtuple('cell', 'state_size')\n-        cell = Cell(state_size=(self.units, self.units))\n-        return cell\n-\n-    def build(self, input_shape):\n-        super(CuDNNLSTM, self).build(input_shape)\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-        input_dim = input_shape[-1]\n-\n-        from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n-        self._cudnn_lstm = cudnn_rnn_ops.CudnnLSTM(\n-            num_layers=1,\n-            num_units=self.units,\n-            input_size=input_dim,\n-            input_mode='linear_input')\n-\n-        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n-                                      name='kernel',\n-                                      initializer=self.kernel_initializer,\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units * 4),\n-            name='recurrent_kernel',\n-            initializer=self.recurrent_initializer,\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-\n-        if self.unit_forget_bias:\n-            def bias_initializer(shape, *args, **kwargs):\n-                return K.concatenate([\n-                    self.bias_initializer((self.units * 5,), *args, **kwargs),\n-                    initializers.Ones()((self.units,), *args, **kwargs),\n-                    self.bias_initializer((self.units * 2,), *args, **kwargs),\n-                ])\n-        else:\n-            bias_initializer = self.bias_initializer\n-        self.bias = self.add_weight(shape=(self.units * 8,),\n-                                    name='bias',\n-                                    initializer=bias_initializer,\n-                                    regularizer=self.bias_regularizer,\n-                                    constraint=self.bias_constraint)\n-\n-        self.kernel_i = self.kernel[:, :self.units]\n-        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n-        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n-        self.kernel_o = self.kernel[:, self.units * 3:]\n-\n-        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n-        self.recurrent_kernel_f = (\n-            self.recurrent_kernel[:, self.units: self.units * 2])\n-        self.recurrent_kernel_c = (\n-            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n-        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n-\n-        self.bias_i_i = self.bias[:self.units]\n-        self.bias_f_i = self.bias[self.units: self.units * 2]\n-        self.bias_c_i = self.bias[self.units * 2: self.units * 3]\n-        self.bias_o_i = self.bias[self.units * 3: self.units * 4]\n-        self.bias_i = self.bias[self.units * 4: self.units * 5]\n-        self.bias_f = self.bias[self.units * 5: self.units * 6]\n-        self.bias_c = self.bias[self.units * 6: self.units * 7]\n-        self.bias_o = self.bias[self.units * 7:]\n-\n-        self.built = True\n-\n-    def _process_batch(self, inputs, initial_state):\n-        import tensorflow as tf\n-        inputs = tf.transpose(inputs, (1, 0, 2))\n-        input_h = initial_state[0]\n-        input_c = initial_state[1]\n-        input_h = tf.expand_dims(input_h, axis=0)\n-        input_c = tf.expand_dims(input_c, axis=0)\n-\n-        params = self._canonical_to_params(\n-            weights=[\n-                self.kernel_i,\n-                self.kernel_f,\n-                self.kernel_c,\n-                self.kernel_o,\n-                self.recurrent_kernel_i,\n-                self.recurrent_kernel_f,\n-                self.recurrent_kernel_c,\n-                self.recurrent_kernel_o,\n-            ],\n-            biases=[\n-                self.bias_i_i,\n-                self.bias_f_i,\n-                self.bias_c_i,\n-                self.bias_o_i,\n-                self.bias_i,\n-                self.bias_f,\n-                self.bias_c,\n-                self.bias_o,\n-            ],\n-        )\n-        outputs, h, c = self._cudnn_lstm(\n-            inputs,\n-            input_h=input_h,\n-            input_c=input_c,\n-            params=params,\n-            is_training=True)\n-\n-        if self.stateful or self.return_state:\n-            h = h[0]\n-            c = c[0]\n-        if self.return_sequences:\n-            output = tf.transpose(outputs, (1, 0, 2))\n-        else:\n-            output = outputs[-1]\n-        return output, [h, c]\n-\n-    def get_config(self):\n-        config = {\n-            'units': self.units,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'recurrent_initializer':\n-                initializers.serialize(self.recurrent_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'unit_forget_bias': self.unit_forget_bias,\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'recurrent_regularizer':\n-                regularizers.serialize(self.recurrent_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)}\n-        base_config = super(CuDNNLSTM, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+from tensorflow.keras.layers import GRU as CuDNNGRU\n+from tensorflow.keras.layers import LSTM as CuDNNLSTM\n\n@@ -1,161 +1,3 @@\n-\"\"\"Embedding layer.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Embedding layer.\"\"\"\n \n-from .. import backend as K\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import Layer\n-from ..legacy import interfaces\n-from ..utils.generic_utils import to_list\n-\n-\n-class Embedding(Layer):\n-    \"\"\"Turns positive integers (indexes) into dense vectors of fixed size.\n-    eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n-\n-    This layer can only be used as the first layer in a model.\n-\n-    # Example\n-\n-    ```python\n-      model = Sequential()\n-      model.add(Embedding(1000, 64, input_length=10))\n-      # the model will take as input an integer matrix of size (batch, input_length).\n-      # the largest integer (i.e. word index) in the input should be\n-      # no larger than 999 (vocabulary size).\n-      # now model.output_shape == (None, 10, 64), where None is the batch dimension.\n-\n-      input_array = np.random.randint(1000, size=(32, 10))\n-\n-      model.compile('rmsprop', 'mse')\n-      output_array = model.predict(input_array)\n-      assert output_array.shape == (32, 10, 64)\n-    ```\n-\n-    # Arguments\n-        input_dim: int > 0. Size of the vocabulary,\n-            i.e. maximum integer index + 1.\n-        output_dim: int >= 0. Dimension of the dense embedding.\n-        embeddings_initializer: Initializer for the `embeddings` matrix\n-            (see [initializers](../initializers.md)).\n-        embeddings_regularizer: Regularizer function applied to\n-            the `embeddings` matrix\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        embeddings_constraint: Constraint function applied to\n-            the `embeddings` matrix\n-            (see [constraints](../constraints.md)).\n-        mask_zero: Whether or not the input value 0 is a special \"padding\"\n-            value that should be masked out.\n-            This is useful when using [recurrent layers](recurrent.md)\n-            which may take variable length input.\n-            If this is `True` then all subsequent layers\n-            in the model need to support masking or an exception will be raised.\n-            If mask_zero is set to True, as a consequence, index 0 cannot be\n-            used in the vocabulary (input_dim should equal size of\n-            vocabulary + 1).\n-        input_length: Length of input sequences, when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-\n-    # Input shape\n-        2D tensor with shape: `(batch_size, sequence_length)`.\n-\n-    # Output shape\n-        3D tensor with shape: `(batch_size, sequence_length, output_dim)`.\n-\n-    # References\n-        - [A Theoretically Grounded Application of Dropout in\n-           Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n-    \"\"\"\n-\n-    @interfaces.legacy_embedding_support\n-    def __init__(self, input_dim, output_dim,\n-                 embeddings_initializer='uniform',\n-                 embeddings_regularizer=None,\n-                 activity_regularizer=None,\n-                 embeddings_constraint=None,\n-                 mask_zero=False,\n-                 input_length=None,\n-                 **kwargs):\n-        if 'input_shape' not in kwargs:\n-            if input_length:\n-                kwargs['input_shape'] = (input_length,)\n-            else:\n-                kwargs['input_shape'] = (None,)\n-        super(Embedding, self).__init__(**kwargs)\n-\n-        self.input_dim = input_dim\n-        self.output_dim = output_dim\n-        self.embeddings_initializer = initializers.get(embeddings_initializer)\n-        self.embeddings_regularizer = regularizers.get(embeddings_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-        self.embeddings_constraint = constraints.get(embeddings_constraint)\n-        self.mask_zero = mask_zero\n-        self.supports_masking = mask_zero\n-        self.input_length = input_length\n-\n-    def build(self, input_shape):\n-        self.embeddings = self.add_weight(\n-            shape=(self.input_dim, self.output_dim),\n-            initializer=self.embeddings_initializer,\n-            name='embeddings',\n-            regularizer=self.embeddings_regularizer,\n-            constraint=self.embeddings_constraint,\n-            dtype=self.dtype)\n-        self.built = True\n-\n-    def compute_mask(self, inputs, mask=None):\n-        if not self.mask_zero:\n-            return None\n-        output_mask = K.not_equal(inputs, 0)\n-        return output_mask\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.input_length is None:\n-            return input_shape + (self.output_dim,)\n-        else:\n-            # input_length can be tuple if input is 3D or higher\n-            in_lens = to_list(self.input_length, allow_tuple=True)\n-            if len(in_lens) != len(input_shape) - 1:\n-                raise ValueError(\n-                    '\"input_length\" is %s, but received input has shape %s' %\n-                    (str(self.input_length), str(input_shape)))\n-            else:\n-                for i, (s1, s2) in enumerate(zip(in_lens, input_shape[1:])):\n-                    if s1 is not None and s2 is not None and s1 != s2:\n-                        raise ValueError(\n-                            '\"input_length\" is %s, but received input has shape %s' %\n-                            (str(self.input_length), str(input_shape)))\n-                    elif s1 is None:\n-                        in_lens[i] = s2\n-            return (input_shape[0],) + tuple(in_lens) + (self.output_dim,)\n-\n-    def call(self, inputs):\n-        if K.dtype(inputs) != 'int32':\n-            inputs = K.cast(inputs, 'int32')\n-        out = K.gather(self.embeddings, inputs)\n-        return out\n-\n-    def get_config(self):\n-        config = {'input_dim': self.input_dim,\n-                  'output_dim': self.output_dim,\n-                  'embeddings_initializer':\n-                      initializers.serialize(self.embeddings_initializer),\n-                  'embeddings_regularizer':\n-                      regularizers.serialize(self.embeddings_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'embeddings_constraint':\n-                      constraints.serialize(self.embeddings_constraint),\n-                  'mask_zero': self.mask_zero,\n-                  'input_length': self.input_length}\n-        base_config = super(Embedding, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+from tensorflow.keras.layers import Embedding\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.layers.experimental import *\n\\ No newline at end of file\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.layers.experimental.preprocessing import *\n\n@@ -1,393 +1,4 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Locally-connected layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Locally-connected layers.\"\"\"\n \n-from .. import backend as K\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import InputSpec\n-from ..utils import conv_utils\n-from ..legacy import interfaces\n-\n-\n-class LocallyConnected1D(Layer):\n-    \"\"\"Locally-connected layer for 1D inputs.\n-\n-    The `LocallyConnected1D` layer works similarly to\n-    the `Conv1D` layer, except that weights are unshared,\n-    that is, a different set of filters is applied at each different patch\n-    of the input.\n-\n-    # Example\n-    ```python\n-        # apply a unshared weight convolution 1d of length 3 to a sequence with\n-        # 10 timesteps, with 64 output filters\n-        model = Sequential()\n-        model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n-        # now model.output_shape == (None, 8, 64)\n-        # add a new conv1d on top\n-        model.add(LocallyConnected1D(32, 3))\n-        # now model.output_shape == (None, 6, 32)\n-    ```\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of a single integer,\n-            specifying the length of the 1D convolution window.\n-        strides: An integer or tuple/list of a single integer,\n-            specifying the stride length of the convolution.\n-            Specifying any `strides!=1` is incompatible with specifying\n-            any `dilation_rate!=1`.\n-        padding: Currently only supports `\"valid\"` (case-insensitive).\n-            `\"same\"` may be supported in the future.\n-        data_format: String, one of `channels_first`, `channels_last`.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        3D tensor with shape: `(batch_size, steps, input_dim)`\n-\n-    # Output shape\n-        3D tensor with shape: `(batch_size, new_steps, filters)`\n-        `steps` value might have changed due to padding or strides.\n-    \"\"\"\n-\n-    @interfaces.legacy_conv1d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=1,\n-                 padding='valid',\n-                 data_format=None,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(LocallyConnected1D, self).__init__(**kwargs)\n-        self.filters = filters\n-        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        if self.padding != 'valid':\n-            raise ValueError('Invalid border mode for LocallyConnected1D '\n-                             '(only \"valid\" is supported): ' + padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.activation = activations.get(activation)\n-        self.use_bias = use_bias\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-        self.input_spec = InputSpec(ndim=3)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[2]\n-        if input_dim is None:\n-            raise ValueError('Axis 2 of input should be fully-defined. '\n-                             'Found shape:', input_shape)\n-        output_length = conv_utils.conv_output_length(input_shape[1],\n-                                                      self.kernel_size[0],\n-                                                      self.padding,\n-                                                      self.strides[0])\n-        self.kernel_shape = (output_length,\n-                             self.kernel_size[0] * input_dim,\n-                             self.filters)\n-        self.kernel = self.add_weight(\n-            shape=self.kernel_shape,\n-            initializer=self.kernel_initializer,\n-            name='kernel',\n-            regularizer=self.kernel_regularizer,\n-            constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(\n-                shape=(output_length, self.filters),\n-                initializer=self.bias_initializer,\n-                name='bias',\n-                regularizer=self.bias_regularizer,\n-                constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        self.input_spec = InputSpec(ndim=3, axes={2: input_dim})\n-        self.built = True\n-\n-    def compute_output_shape(self, input_shape):\n-        length = conv_utils.conv_output_length(input_shape[1],\n-                                               self.kernel_size[0],\n-                                               self.padding,\n-                                               self.strides[0])\n-        return (input_shape[0], length, self.filters)\n-\n-    def call(self, inputs):\n-        output = K.local_conv1d(inputs, self.kernel, self.kernel_size, self.strides)\n-        if self.use_bias:\n-            output = K.bias_add(output, self.bias)\n-        if self.activation is not None:\n-            output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {\n-            'filters': self.filters,\n-            'kernel_size': self.kernel_size,\n-            'strides': self.strides,\n-            'padding': self.padding,\n-            'activation': activations.serialize(self.activation),\n-            'use_bias': self.use_bias,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)\n-        }\n-        base_config = super(LocallyConnected1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class LocallyConnected2D(Layer):\n-    \"\"\"Locally-connected layer for 2D inputs.\n-\n-    The `LocallyConnected2D` layer works similarly\n-    to the `Conv2D` layer, except that weights are unshared,\n-    that is, a different set of filters is applied at each\n-    different patch of the input.\n-\n-    # Examples\n-    ```python\n-        # apply a 3x3 unshared weights convolution with 64 output filters\n-        # on a 32x32 image with `data_format=\"channels_last\"`:\n-        model = Sequential()\n-        model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n-        # now model.output_shape == (None, 30, 30, 64)\n-        # notice that this layer will consume (30*30)*(3*3*3*64)\n-        # + (30*30)*64 parameters\n-\n-        # add a 3x3 unshared weights convolution on top, with 32 output filters:\n-        model.add(LocallyConnected2D(32, (3, 3)))\n-        # now model.output_shape == (None, 28, 28, 32)\n-    ```\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number of output filters in the convolution).\n-        kernel_size: An integer or tuple/list of 2 integers, specifying the\n-            width and height of the 2D convolution window.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        strides: An integer or tuple/list of 2 integers,\n-            specifying the strides of the convolution along the width and height.\n-            Can be a single integer to specify the same value for\n-            all spatial dimensions.\n-        padding: Currently only support `\"valid\"` (case-insensitive).\n-            `\"same\"` will be supported in future.\n-        data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n-            The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `channels_first`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to the kernel matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-\n-    # Input shape\n-        4D tensor with shape:\n-        `(samples, channels, rows, cols)` if `data_format='channels_first'`\n-        or 4D tensor with shape:\n-        `(samples, rows, cols, channels)` if `data_format='channels_last'`.\n-\n-    # Output shape\n-        4D tensor with shape:\n-        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n-        or 4D tensor with shape:\n-        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n-        `rows` and `cols` values might have changed due to padding.\n-    \"\"\"\n-\n-    @interfaces.legacy_conv2d_support\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 activation=None,\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 bias_constraint=None,\n-                 **kwargs):\n-        super(LocallyConnected2D, self).__init__(**kwargs)\n-        self.filters = filters\n-        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        if self.padding != 'valid':\n-            raise ValueError('Invalid border mode for LocallyConnected2D '\n-                             '(only \"valid\" is supported): ' + padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.activation = activations.get(activation)\n-        self.use_bias = use_bias\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-        self.input_spec = InputSpec(ndim=4)\n-\n-    def build(self, input_shape):\n-        if self.data_format == 'channels_last':\n-            input_row, input_col = input_shape[1:-1]\n-            input_filter = input_shape[3]\n-        else:\n-            input_row, input_col = input_shape[2:]\n-            input_filter = input_shape[1]\n-        if input_row is None or input_col is None:\n-            raise ValueError('The spatial dimensions of the inputs to '\n-                             ' a LocallyConnected2D layer '\n-                             'should be fully-defined, but layer received '\n-                             'the inputs shape ' + str(input_shape))\n-        output_row = conv_utils.conv_output_length(input_row, self.kernel_size[0],\n-                                                   self.padding, self.strides[0])\n-        output_col = conv_utils.conv_output_length(input_col, self.kernel_size[1],\n-                                                   self.padding, self.strides[1])\n-        self.output_row = output_row\n-        self.output_col = output_col\n-        self.kernel_shape = (\n-            output_row * output_col,\n-            self.kernel_size[0] * self.kernel_size[1] * input_filter,\n-            self.filters)\n-        self.kernel = self.add_weight(shape=self.kernel_shape,\n-                                      initializer=self.kernel_initializer,\n-                                      name='kernel',\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(output_row, output_col, self.filters),\n-                                        initializer=self.bias_initializer,\n-                                        name='bias',\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        if self.data_format == 'channels_first':\n-            self.input_spec = InputSpec(ndim=4, axes={1: input_filter})\n-        else:\n-            self.input_spec = InputSpec(ndim=4, axes={-1: input_filter})\n-        self.built = True\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-\n-        rows = conv_utils.conv_output_length(rows, self.kernel_size[0],\n-                                             self.padding, self.strides[0])\n-        cols = conv_utils.conv_output_length(cols, self.kernel_size[1],\n-                                             self.padding, self.strides[1])\n-\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], self.filters, rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, self.filters)\n-\n-    def call(self, inputs):\n-        output = K.local_conv2d(inputs,\n-                                self.kernel,\n-                                self.kernel_size,\n-                                self.strides,\n-                                (self.output_row, self.output_col),\n-                                self.data_format)\n-\n-        if self.use_bias:\n-            output = K.bias_add(output, self.bias, data_format=self.data_format)\n-\n-        output = self.activation(output)\n-        return output\n-\n-    def get_config(self):\n-        config = {\n-            'filters': self.filters,\n-            'kernel_size': self.kernel_size,\n-            'strides': self.strides,\n-            'padding': self.padding,\n-            'data_format': self.data_format,\n-            'activation': activations.serialize(self.activation),\n-            'use_bias': self.use_bias,\n-            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n-            'bias_initializer': initializers.serialize(self.bias_initializer),\n-            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n-            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-            'activity_regularizer':\n-                regularizers.serialize(self.activity_regularizer),\n-            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-            'bias_constraint': constraints.serialize(self.bias_constraint)\n-        }\n-        base_config = super(LocallyConnected2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n+from tensorflow.keras.layers import LocallyConnected1D\n+from tensorflow.keras.layers import LocallyConnected2D\n\n@@ -1,668 +1,18 @@\n-\"\"\"Layers that can merge several inputs into one.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from ..engine.base_layer import Layer\n-from .. import backend as K\n-\n-\n-class _Merge(Layer):\n-    \"\"\"Generic merge layer for elementwise merge functions.\n-\n-    Used to implement `Sum`, `Average`, etc.\n-\n-    # Arguments\n-        **kwargs: standard layer keyword arguments.\n-    \"\"\"\n-\n-    def __init__(self, **kwargs):\n-        super(_Merge, self).__init__(**kwargs)\n-        self.supports_masking = True\n-\n-    def _merge_function(self, inputs):\n-        raise NotImplementedError\n-\n-    def _compute_elemwise_op_output_shape(self, shape1, shape2):\n-        \"\"\"Computes the shape of the resultant of an elementwise operation.\n-\n-        # Arguments\n-            shape1: tuple or None. Shape of the first tensor\n-            shape2: tuple or None. Shape of the second tensor\n-\n-        # Returns\n-            expected output shape when an element-wise operation is\n-            carried out on 2 tensors with shapes shape1 and shape2.\n-            tuple or None.\n-\n-        # Raises\n-            ValueError: if shape1 and shape2 are not compatible for\n-                element-wise operations.\n-        \"\"\"\n-        if None in [shape1, shape2]:\n-            return None\n-        elif len(shape1) < len(shape2):\n-            return self._compute_elemwise_op_output_shape(shape2, shape1)\n-        elif not shape2:\n-            return shape1\n-        output_shape = list(shape1[:-len(shape2)])\n-        for i, j in zip(shape1[-len(shape2):], shape2):\n-            if i is None or j is None:\n-                output_shape.append(None)\n-            elif i == 1:\n-                output_shape.append(j)\n-            elif j == 1:\n-                output_shape.append(i)\n-            else:\n-                if i != j:\n-                    raise ValueError('Operands could not be broadcast '\n-                                     'together with shapes ' +\n-                                     str(shape1) + ' ' + str(shape2))\n-                output_shape.append(i)\n-        return tuple(output_shape)\n-\n-    def build(self, input_shape):\n-        # Used purely for shape validation.\n-        if not isinstance(input_shape, list):\n-            raise ValueError('A merge layer should be called '\n-                             'on a list of inputs.')\n-        if len(input_shape) < 2:\n-            raise ValueError('A merge layer should be called '\n-                             'on a list of at least 2 inputs. '\n-                             'Got ' + str(len(input_shape)) + ' inputs.')\n-        batch_sizes = [s[0] for s in input_shape if s is not None]\n-        batch_sizes = set(batch_sizes)\n-        batch_sizes -= set([None])\n-        if len(batch_sizes) > 1:\n-            raise ValueError('Can not merge tensors with different '\n-                             'batch sizes. Got tensors with shapes : ' +\n-                             str(input_shape))\n-        if input_shape[0] is None:\n-            output_shape = None\n-        else:\n-            output_shape = input_shape[0][1:]\n-        for i in range(1, len(input_shape)):\n-            if input_shape[i] is None:\n-                shape = None\n-            else:\n-                shape = input_shape[i][1:]\n-            output_shape = self._compute_elemwise_op_output_shape(output_shape,\n-                                                                  shape)\n-        # If the inputs have different ranks, we have to reshape them\n-        # to make them broadcastable.\n-        if None not in input_shape and len(set(map(len, input_shape))) == 1:\n-            self._reshape_required = False\n-        else:\n-            self._reshape_required = True\n-\n-    def call(self, inputs):\n-        if not isinstance(inputs, list):\n-            raise ValueError('A merge layer should be called '\n-                             'on a list of inputs.')\n-        if self._reshape_required:\n-            reshaped_inputs = []\n-            input_ndims = list(map(K.ndim, inputs))\n-            if None not in input_ndims:\n-                # If ranks of all inputs are available,\n-                # we simply expand each of them at axis=1\n-                # until all of them have the same rank.\n-                max_ndim = max(input_ndims)\n-                for x in inputs:\n-                    x_ndim = K.ndim(x)\n-                    for _ in range(max_ndim - x_ndim):\n-                        x = K.expand_dims(x, 1)\n-                    reshaped_inputs.append(x)\n-                return self._merge_function(reshaped_inputs)\n-            else:\n-                # Transpose all inputs so that batch size is the last dimension.\n-                # (batch_size, dim1, dim2, ... ) -> (dim1, dim2, ... , batch_size)\n-                transposed = False\n-                for x in inputs:\n-                    x_ndim = K.ndim(x)\n-                    if x_ndim is None:\n-                        x_shape = K.shape(x)\n-                        batch_size = x_shape[0]\n-                        new_shape = K.concatenate([x_shape[1:],\n-                                                   K.expand_dims(batch_size)])\n-                        x_transposed = K.reshape(x, K.stack([batch_size,\n-                                                             K.prod(x_shape[1:])]))\n-                        x_transposed = K.permute_dimensions(x_transposed, (1, 0))\n-                        x_transposed = K.reshape(x_transposed, new_shape)\n-                        reshaped_inputs.append(x_transposed)\n-                        transposed = True\n-                    elif x_ndim > 1:\n-                        dims = list(range(1, x_ndim)) + [0]\n-                        reshaped_inputs.append(K.permute_dimensions(x, dims))\n-                        transposed = True\n-                    else:\n-                        # We don't transpose inputs if they are\n-                        # 1D vectors or scalars.\n-                        reshaped_inputs.append(x)\n-                y = self._merge_function(reshaped_inputs)\n-                y_ndim = K.ndim(y)\n-                if transposed:\n-                    # If inputs have been transposed,\n-                    # we have to transpose the output too.\n-                    if y_ndim is None:\n-                        y_shape = K.shape(y)\n-                        y_ndim = K.shape(y_shape)[0]\n-                        batch_size = y_shape[y_ndim - 1]\n-                        new_shape = K.concatenate([K.expand_dims(batch_size),\n-                                                   y_shape[:y_ndim - 1]])\n-                        y = K.reshape(y, (-1, batch_size))\n-                        y = K.permute_dimensions(y, (1, 0))\n-                        y = K.reshape(y, new_shape)\n-                    elif y_ndim > 1:\n-                        dims = [y_ndim - 1] + list(range(y_ndim - 1))\n-                        y = K.permute_dimensions(y, dims)\n-                return y\n-        else:\n-            return self._merge_function(inputs)\n-\n-    def compute_output_shape(self, input_shape):\n-        if input_shape[0] is None:\n-            output_shape = None\n-        else:\n-            output_shape = input_shape[0][1:]\n-        for i in range(1, len(input_shape)):\n-            if input_shape[i] is None:\n-                shape = None\n-            else:\n-                shape = input_shape[i][1:]\n-            output_shape = self._compute_elemwise_op_output_shape(output_shape,\n-                                                                  shape)\n-        batch_sizes = [s[0] for s in input_shape if s is not None]\n-        batch_sizes = set(batch_sizes)\n-        batch_sizes -= set([None])\n-        if len(batch_sizes) == 1:\n-            output_shape = (list(batch_sizes)[0],) + output_shape\n-        else:\n-            output_shape = (None,) + output_shape\n-        return output_shape\n-\n-    def compute_mask(self, inputs, mask=None):\n-        if mask is None:\n-            return None\n-        if not isinstance(mask, list):\n-            raise ValueError('`mask` should be a list.')\n-        if not isinstance(inputs, list):\n-            raise ValueError('`inputs` should be a list.')\n-        if len(mask) != len(inputs):\n-            raise ValueError('The lists `inputs` and `mask` '\n-                             'should have the same length.')\n-        if all([m is None for m in mask]):\n-            return None\n-        masks = [K.expand_dims(m, 0) for m in mask if m is not None]\n-        return K.all(K.concatenate(masks, axis=0), axis=0, keepdims=False)\n-\n-\n-class Add(_Merge):\n-    \"\"\"Layer that adds a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape, and returns\n-    a single tensor (also of the same shape).\n-\n-    # Examples\n-\n-    ```python\n-        import keras\n-\n-        input1 = keras.layers.Input(shape=(16,))\n-        x1 = keras.layers.Dense(8, activation='relu')(input1)\n-        input2 = keras.layers.Input(shape=(32,))\n-        x2 = keras.layers.Dense(8, activation='relu')(input2)\n-        # equivalent to added = keras.layers.add([x1, x2])\n-        added = keras.layers.Add()([x1, x2])\n-\n-        out = keras.layers.Dense(4)(added)\n-        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n-    ```\n-    \"\"\"\n-\n-    def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output += inputs[i]\n-        return output\n-\n-\n-class Subtract(_Merge):\n-    \"\"\"Layer that subtracts two inputs.\n-\n-    It takes as input a list of tensors of size 2,\n-    both of the same shape, and returns a single tensor, (inputs[0] - inputs[1]),\n-    also of the same shape.\n-\n-    # Examples\n-\n-    ```python\n-        import keras\n-\n-        input1 = keras.layers.Input(shape=(16,))\n-        x1 = keras.layers.Dense(8, activation='relu')(input1)\n-        input2 = keras.layers.Input(shape=(32,))\n-        x2 = keras.layers.Dense(8, activation='relu')(input2)\n-        # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n-        subtracted = keras.layers.Subtract()([x1, x2])\n-\n-        out = keras.layers.Dense(4)(subtracted)\n-        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n-    ```\n-    \"\"\"\n-\n-    def build(self, input_shape):\n-        super(Subtract, self).build(input_shape)\n-        if len(input_shape) != 2:\n-            raise ValueError('A `Subtract` layer should be called '\n-                             'on exactly 2 inputs')\n-\n-    def _merge_function(self, inputs):\n-        if len(inputs) != 2:\n-            raise ValueError('A `Subtract` layer should be called '\n-                             'on exactly 2 inputs')\n-        return inputs[0] - inputs[1]\n-\n-\n-class Multiply(_Merge):\n-    \"\"\"Layer that multiplies (element-wise) a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape, and returns\n-    a single tensor (also of the same shape).\n-    \"\"\"\n-\n-    def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output *= inputs[i]\n-        return output\n-\n-\n-class Average(_Merge):\n-    \"\"\"Layer that averages a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape, and returns\n-    a single tensor (also of the same shape).\n-    \"\"\"\n-\n-    def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output += inputs[i]\n-        return output / len(inputs)\n-\n-\n-class Maximum(_Merge):\n-    \"\"\"Layer that computes the maximum (element-wise) a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape, and returns\n-    a single tensor (also of the same shape).\n-    \"\"\"\n-\n-    def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output = K.maximum(output, inputs[i])\n-        return output\n-\n-\n-class Minimum(_Merge):\n-    \"\"\"Layer that computes the minimum (element-wise) a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape, and returns\n-    a single tensor (also of the same shape).\n-    \"\"\"\n-\n-    def _merge_function(self, inputs):\n-        output = inputs[0]\n-        for i in range(1, len(inputs)):\n-            output = K.minimum(output, inputs[i])\n-        return output\n-\n-\n-class Concatenate(_Merge):\n-    \"\"\"Layer that concatenates a list of inputs.\n-\n-    It takes as input a list of tensors,\n-    all of the same shape except for the concatenation axis,\n-    and returns a single tensor, the concatenation of all inputs.\n-\n-    # Arguments\n-        axis: Axis along which to concatenate.\n-        **kwargs: standard layer keyword arguments.\n-    \"\"\"\n-\n-    def __init__(self, axis=-1, **kwargs):\n-        super(Concatenate, self).__init__(**kwargs)\n-        self.axis = axis\n-        self.supports_masking = True\n-        self._reshape_required = False\n-\n-    def build(self, input_shape):\n-        # Used purely for shape validation.\n-        if not isinstance(input_shape, list) or len(input_shape) < 2:\n-            raise ValueError('A `Concatenate` layer should be called '\n-                             'on a list of at least 2 inputs')\n-        if all([shape is None for shape in input_shape]):\n-            return\n-        reduced_inputs_shapes = [list(shape) for shape in input_shape]\n-        shape_set = set()\n-        for i in range(len(reduced_inputs_shapes)):\n-            del reduced_inputs_shapes[i][self.axis]\n-            shape_set.add(tuple(reduced_inputs_shapes[i]))\n-        if len(shape_set) > 1:\n-            raise ValueError('A `Concatenate` layer requires '\n-                             'inputs with matching shapes '\n-                             'except for the concat axis. '\n-                             'Got inputs shapes: %s' % (input_shape))\n-\n-    def _merge_function(self, inputs):\n-        return K.concatenate(inputs, axis=self.axis)\n-\n-    def compute_output_shape(self, input_shape):\n-        if not isinstance(input_shape, list):\n-            raise ValueError('A `Concatenate` layer should be called '\n-                             'on a list of inputs.')\n-        input_shapes = input_shape\n-        output_shape = list(input_shapes[0])\n-        for shape in input_shapes[1:]:\n-            if output_shape[self.axis] is None or shape[self.axis] is None:\n-                output_shape[self.axis] = None\n-                break\n-            output_shape[self.axis] += shape[self.axis]\n-        return tuple(output_shape)\n-\n-    def compute_mask(self, inputs, mask=None):\n-        if mask is None:\n-            return None\n-        if not isinstance(mask, list):\n-            raise ValueError('`mask` should be a list.')\n-        if not isinstance(inputs, list):\n-            raise ValueError('`inputs` should be a list.')\n-        if len(mask) != len(inputs):\n-            raise ValueError('The lists `inputs` and `mask` '\n-                             'should have the same length.')\n-        if all([m is None for m in mask]):\n-            return None\n-        # Make a list of masks while making sure\n-        # the dimensionality of each mask\n-        # is the same as the corresponding input.\n-        masks = []\n-        for input_i, mask_i in zip(inputs, mask):\n-            if mask_i is None:\n-                # Input is unmasked. Append all 1s to masks,\n-                masks.append(K.ones_like(input_i, dtype='bool'))\n-            elif K.ndim(mask_i) < K.ndim(input_i):\n-                # Mask is smaller than the input, expand it\n-                masks.append(K.expand_dims(mask_i))\n-            else:\n-                masks.append(mask_i)\n-        concatenated = K.concatenate(masks, axis=self.axis)\n-        return K.all(concatenated, axis=-1, keepdims=False)\n-\n-    def get_config(self):\n-        config = {\n-            'axis': self.axis,\n-        }\n-        base_config = super(Concatenate, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Dot(_Merge):\n-    \"\"\"Layer that computes a dot product between samples in two tensors.\n-\n-    E.g. if applied to a list of two tensors `a` and `b` of shape `(batch_size, n)`,\n-    the output will be a tensor of shape `(batch_size, 1)`\n-    where each entry `i` will be the dot product between\n-    `a[i]` and `b[i]`.\n-\n-    # Arguments\n-        axes: Integer or tuple of integers,\n-            axis or axes along which to take the dot product.\n-        normalize: Whether to L2-normalize samples along the\n-            dot product axis before taking the dot product.\n-            If set to True, then the output of the dot product\n-            is the cosine proximity between the two samples.\n-        **kwargs: Standard layer keyword arguments.\n-    \"\"\"\n-\n-    def __init__(self, axes, normalize=False, **kwargs):\n-        super(Dot, self).__init__(**kwargs)\n-        if not isinstance(axes, int):\n-            if not isinstance(axes, (list, tuple)):\n-                raise TypeError('Invalid type for `axes` - '\n-                                'should be a list or an int.')\n-            if len(axes) != 2:\n-                raise ValueError('Invalid format for `axes` - '\n-                                 'should contain two elements.')\n-            if not isinstance(axes[0], int) or not isinstance(axes[1], int):\n-                raise ValueError('Invalid format for `axes` - '\n-                                 'list elements should be \"int\".')\n-        self.axes = axes\n-        self.normalize = normalize\n-        self.supports_masking = True\n-        self._reshape_required = False\n-\n-    def build(self, input_shape):\n-        # Used purely for shape validation.\n-        if not isinstance(input_shape, list) or len(input_shape) != 2:\n-            raise ValueError('A `Dot` layer should be called '\n-                             'on a list of 2 inputs.')\n-        shape1 = input_shape[0]\n-        shape2 = input_shape[1]\n-        if shape1 is None or shape2 is None:\n-            return\n-        if isinstance(self.axes, int):\n-            if self.axes < 0:\n-                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n-            else:\n-                axes = [self.axes] * 2\n-        else:\n-            axes = self.axes\n-        if shape1[axes[0]] != shape2[axes[1]]:\n-            raise ValueError(\n-                'Dimension incompatibility '\n-                '%s != %s. ' % (shape1[axes[0]], shape2[axes[1]]) +\n-                'Layer shapes: %s, %s' % (shape1, shape2))\n-\n-    def _merge_function(self, inputs):\n-        if len(inputs) != 2:\n-            raise ValueError('A `Dot` layer should be called '\n-                             'on exactly 2 inputs')\n-        x1 = inputs[0]\n-        x2 = inputs[1]\n-        if isinstance(self.axes, int):\n-            if self.axes < 0:\n-                axes = [self.axes % K.ndim(x1), self.axes % K.ndim(x2)]\n-            else:\n-                axes = [self.axes] * 2\n-        else:\n-            axes = []\n-            for i in range(len(self.axes)):\n-                if self.axes[i] < 0:\n-                    axes.append(self.axes[i] % K.ndim(inputs[i]))\n-                else:\n-                    axes.append(self.axes[i])\n-        if self.normalize:\n-            x1 = K.l2_normalize(x1, axis=axes[0])\n-            x2 = K.l2_normalize(x2, axis=axes[1])\n-        output = K.batch_dot(x1, x2, axes)\n-        return output\n-\n-    def compute_output_shape(self, input_shape):\n-        if not isinstance(input_shape, list) or len(input_shape) != 2:\n-            raise ValueError('A `Dot` layer should be called '\n-                             'on a list of 2 inputs.')\n-        shape1 = list(input_shape[0])\n-        shape2 = list(input_shape[1])\n-        if isinstance(self.axes, int):\n-            if self.axes < 0:\n-                axes = [self.axes % len(shape1), self.axes % len(shape2)]\n-            else:\n-                axes = [self.axes] * 2\n-        else:\n-            axes = self.axes\n-        shape1.pop(axes[0])\n-        shape2.pop(axes[1])\n-        shape2.pop(0)\n-        output_shape = shape1 + shape2\n-        if len(output_shape) == 1:\n-            output_shape += [1]\n-        return tuple(output_shape)\n-\n-    def compute_mask(self, inputs, mask=None):\n-        return None\n-\n-    def get_config(self):\n-        config = {\n-            'axes': self.axes,\n-            'normalize': self.normalize,\n-        }\n-        base_config = super(Dot, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-def add(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Add` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the sum of the inputs.\n-\n-    # Examples\n-\n-    ```python\n-        import keras\n-\n-        input1 = keras.layers.Input(shape=(16,))\n-        x1 = keras.layers.Dense(8, activation='relu')(input1)\n-        input2 = keras.layers.Input(shape=(32,))\n-        x2 = keras.layers.Dense(8, activation='relu')(input2)\n-        added = keras.layers.add([x1, x2])\n-\n-        out = keras.layers.Dense(4)(added)\n-        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n-    ```\n-    \"\"\"\n-    return Add(**kwargs)(inputs)\n-\n-\n-def subtract(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Subtract` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (exactly 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the difference of the inputs.\n-\n-    # Examples\n-\n-    ```python\n-        import keras\n-\n-        input1 = keras.layers.Input(shape=(16,))\n-        x1 = keras.layers.Dense(8, activation='relu')(input1)\n-        input2 = keras.layers.Input(shape=(32,))\n-        x2 = keras.layers.Dense(8, activation='relu')(input2)\n-        subtracted = keras.layers.subtract([x1, x2])\n-\n-        out = keras.layers.Dense(4)(subtracted)\n-        model = keras.models.Model(inputs=[input1, input2], outputs=out)\n-    ```\n-    \"\"\"\n-    return Subtract(**kwargs)(inputs)\n-\n-\n-def multiply(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Multiply` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the element-wise product of the inputs.\n-    \"\"\"\n-    return Multiply(**kwargs)(inputs)\n-\n-\n-def average(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Average` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the average of the inputs.\n-    \"\"\"\n-    return Average(**kwargs)(inputs)\n-\n-\n-def maximum(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Maximum` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the element-wise maximum of the inputs.\n-    \"\"\"\n-    return Maximum(**kwargs)(inputs)\n-\n-\n-def minimum(inputs, **kwargs):\n-    \"\"\"Functional interface to the `Minimum` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the element-wise minimum of the inputs.\n-    \"\"\"\n-    return Minimum(**kwargs)(inputs)\n-\n-\n-def concatenate(inputs, axis=-1, **kwargs):\n-    \"\"\"Functional interface to the `Concatenate` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        axis: Concatenation axis.\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the concatenation of the inputs alongside axis `axis`.\n-    \"\"\"\n-    return Concatenate(axis=axis, **kwargs)(inputs)\n-\n-\n-def dot(inputs, axes, normalize=False, **kwargs):\n-    \"\"\"Functional interface to the `Dot` layer.\n-\n-    # Arguments\n-        inputs: A list of input tensors (at least 2).\n-        axes: Integer or tuple of integers,\n-            axis or axes along which to take the dot product.\n-        normalize: Whether to L2-normalize samples along the\n-            dot product axis before taking the dot product.\n-            If set to True, then the output of the dot product\n-            is the cosine proximity between the two samples.\n-        **kwargs: Standard layer keyword arguments.\n-\n-    # Returns\n-        A tensor, the dot product of the samples from the inputs.\n-    \"\"\"\n-    return Dot(axes=axes, normalize=normalize, **kwargs)(inputs)\n+\"\"\"Layers that can merge several inputs into one.\"\"\"\n+\n+from tensorflow.keras.layers import Add\n+from tensorflow.keras.layers import Subtract\n+from tensorflow.keras.layers import Multiply\n+from tensorflow.keras.layers import Average\n+from tensorflow.keras.layers import Maximum\n+from tensorflow.keras.layers import Minimum\n+from tensorflow.keras.layers import Concatenate\n+from tensorflow.keras.layers import Dot\n+from tensorflow.keras.layers import add\n+from tensorflow.keras.layers import subtract\n+from tensorflow.keras.layers import multiply\n+from tensorflow.keras.layers import average\n+from tensorflow.keras.layers import maximum\n+from tensorflow.keras.layers import minimum\n+from tensorflow.keras.layers import concatenate\n+from tensorflow.keras.layers import dot\n\n@@ -1,176 +1,5 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Layers that operate regularization via the addition of noise.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Layers that operate regularization via the addition of noise.\"\"\"\n \n-from ..engine.base_layer import Layer\n-from .. import backend as K\n-import numpy as np\n-from ..legacy import interfaces\n-\n-\n-class GaussianNoise(Layer):\n-    \"\"\"Apply additive zero-centered Gaussian noise.\n-\n-    This is useful to mitigate overfitting\n-    (you could see it as a form of random data augmentation).\n-    Gaussian Noise (GS) is a natural choice as corruption process\n-    for real valued inputs.\n-\n-    As it is a regularization layer, it is only active at training time.\n-\n-    # Arguments\n-        stddev: float, standard deviation of the noise distribution.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-    \"\"\"\n-\n-    @interfaces.legacy_gaussiannoise_support\n-    def __init__(self, stddev, **kwargs):\n-        super(GaussianNoise, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.stddev = stddev\n-\n-    def call(self, inputs, training=None):\n-        def noised():\n-            return inputs + K.random_normal(shape=K.shape(inputs),\n-                                            mean=0.,\n-                                            stddev=self.stddev)\n-        return K.in_train_phase(noised, inputs, training=training)\n-\n-    def get_config(self):\n-        config = {'stddev': self.stddev}\n-        base_config = super(GaussianNoise, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class GaussianDropout(Layer):\n-    \"\"\"Apply multiplicative 1-centered Gaussian noise.\n-\n-    As it is a regularization layer, it is only active at training time.\n-\n-    # Arguments\n-        rate: float, drop probability (as with `Dropout`).\n-            The multiplicative noise will have\n-            standard deviation `sqrt(rate / (1 - rate))`.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-\n-    # References\n-        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n-           http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n-    \"\"\"\n-\n-    @interfaces.legacy_gaussiandropout_support\n-    def __init__(self, rate, **kwargs):\n-        super(GaussianDropout, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.rate = rate\n-\n-    def call(self, inputs, training=None):\n-        if 0 < self.rate < 1:\n-            def noised():\n-                stddev = np.sqrt(self.rate / (1.0 - self.rate))\n-                return inputs * K.random_normal(shape=K.shape(inputs),\n-                                                mean=1.0,\n-                                                stddev=stddev)\n-            return K.in_train_phase(noised, inputs, training=training)\n-        return inputs\n-\n-    def get_config(self):\n-        config = {'rate': self.rate}\n-        base_config = super(GaussianDropout, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n-\n-\n-class AlphaDropout(Layer):\n-    \"\"\"Applies Alpha Dropout to the input.\n-\n-    Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n-    to their original values, in order to ensure the self-normalizing property\n-    even after this dropout.\n-    Alpha Dropout fits well to Scaled Exponential Linear Units\n-    by randomly setting activations to the negative saturation value.\n-\n-    # Arguments\n-        rate: float, drop probability (as with `Dropout`).\n-            The multiplicative noise will have\n-            standard deviation `sqrt(rate / (1 - rate))`.\n-        noise_shape: A 1-D `Tensor` of type `int32`, representing the\n-            shape for randomly generated keep/drop flags.\n-        seed: A Python integer to use as random seed.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-\n-    # References\n-        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n-    \"\"\"\n-    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n-        super(AlphaDropout, self).__init__(**kwargs)\n-        self.rate = rate\n-        self.noise_shape = noise_shape\n-        self.seed = seed\n-        self.supports_masking = True\n-\n-    def _get_noise_shape(self, inputs):\n-        return self.noise_shape if self.noise_shape else K.shape(inputs)\n-\n-    def call(self, inputs, training=None):\n-        if 0. < self.rate < 1.:\n-            noise_shape = self._get_noise_shape(inputs)\n-\n-            def dropped_inputs(inputs=inputs, rate=self.rate, seed=self.seed):\n-                alpha = 1.6732632423543772848170429916717\n-                scale = 1.0507009873554804934193349852946\n-                alpha_p = -alpha * scale\n-\n-                kept_idx = K.greater_equal(K.random_uniform(noise_shape,\n-                                                            seed=seed), rate)\n-                kept_idx = K.cast(kept_idx, K.floatx())\n-\n-                # Get affine transformation params\n-                a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5\n-                b = -a * alpha_p * rate\n-\n-                # Apply mask\n-                x = inputs * kept_idx + alpha_p * (1 - kept_idx)\n-\n-                # Do affine transformation\n-                return a * x + b\n-\n-            return K.in_train_phase(dropped_inputs, inputs, training=training)\n-        return inputs\n-\n-    def get_config(self):\n-        config = {'rate': self.rate}\n-        base_config = super(AlphaDropout, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+from tensorflow.keras.layers import GaussianNoise\n+from tensorflow.keras.layers import GaussianDropout\n+from tensorflow.keras.layers import AlphaDropout\n\n@@ -1,232 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Normalization layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Normalization layers.\"\"\"\n \n-from ..engine.base_layer import Layer, InputSpec\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from .. import backend as K\n-from ..legacy import interfaces\n-\n-\n-class BatchNormalization(Layer):\n-    \"\"\"Batch normalization layer (Ioffe and Szegedy, 2014).\n-\n-    Normalize the activations of the previous layer at each batch,\n-    i.e. applies a transformation that maintains the mean activation\n-    close to 0 and the activation standard deviation close to 1.\n-\n-    # Arguments\n-        axis: Integer, the axis that should be normalized\n-            (typically the features axis).\n-            For instance, after a `Conv2D` layer with\n-            `data_format=\"channels_first\"`,\n-            set `axis=1` in `BatchNormalization`.\n-        momentum: Momentum for the moving mean and the moving variance.\n-        epsilon: Small float added to variance to avoid dividing by zero.\n-        center: If True, add offset of `beta` to normalized tensor.\n-            If False, `beta` is ignored.\n-        scale: If True, multiply by `gamma`.\n-            If False, `gamma` is not used.\n-            When the next layer is linear (also e.g. `nn.relu`),\n-            this can be disabled since the scaling\n-            will be done by the next layer.\n-        beta_initializer: Initializer for the beta weight.\n-        gamma_initializer: Initializer for the gamma weight.\n-        moving_mean_initializer: Initializer for the moving mean.\n-        moving_variance_initializer: Initializer for the moving variance.\n-        beta_regularizer: Optional regularizer for the beta weight.\n-        gamma_regularizer: Optional regularizer for the gamma weight.\n-        beta_constraint: Optional constraint for the beta weight.\n-        gamma_constraint: Optional constraint for the gamma weight.\n-\n-    # Input shape\n-        Arbitrary. Use the keyword argument `input_shape`\n-        (tuple of integers, does not include the samples axis)\n-        when using this layer as the first layer in a model.\n-\n-    # Output shape\n-        Same shape as input.\n-\n-    # References\n-        - [Batch Normalization: Accelerating Deep Network Training by\n-           Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n-    \"\"\"\n-\n-    @interfaces.legacy_batchnorm_support\n-    def __init__(self,\n-                 axis=-1,\n-                 momentum=0.99,\n-                 epsilon=1e-3,\n-                 center=True,\n-                 scale=True,\n-                 beta_initializer='zeros',\n-                 gamma_initializer='ones',\n-                 moving_mean_initializer='zeros',\n-                 moving_variance_initializer='ones',\n-                 beta_regularizer=None,\n-                 gamma_regularizer=None,\n-                 beta_constraint=None,\n-                 gamma_constraint=None,\n-                 **kwargs):\n-        super(BatchNormalization, self).__init__(**kwargs)\n-        self.supports_masking = True\n-        self.axis = axis\n-        self.momentum = momentum\n-        self.epsilon = epsilon\n-        self.center = center\n-        self.scale = scale\n-        self.beta_initializer = initializers.get(beta_initializer)\n-        self.gamma_initializer = initializers.get(gamma_initializer)\n-        self.moving_mean_initializer = initializers.get(moving_mean_initializer)\n-        self.moving_variance_initializer = (\n-            initializers.get(moving_variance_initializer))\n-        self.beta_regularizer = regularizers.get(beta_regularizer)\n-        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n-        self.beta_constraint = constraints.get(beta_constraint)\n-        self.gamma_constraint = constraints.get(gamma_constraint)\n-\n-    def build(self, input_shape):\n-        dim = input_shape[self.axis]\n-        if dim is None:\n-            raise ValueError('Axis ' + str(self.axis) + ' of '\n-                             'input tensor should have a defined dimension '\n-                             'but the layer received an input with shape ' +\n-                             str(input_shape) + '.')\n-        self.input_spec = InputSpec(ndim=len(input_shape),\n-                                    axes={self.axis: dim})\n-        shape = (dim,)\n-\n-        if self.scale:\n-            self.gamma = self.add_weight(shape=shape,\n-                                         name='gamma',\n-                                         initializer=self.gamma_initializer,\n-                                         regularizer=self.gamma_regularizer,\n-                                         constraint=self.gamma_constraint)\n-        else:\n-            self.gamma = None\n-        if self.center:\n-            self.beta = self.add_weight(shape=shape,\n-                                        name='beta',\n-                                        initializer=self.beta_initializer,\n-                                        regularizer=self.beta_regularizer,\n-                                        constraint=self.beta_constraint)\n-        else:\n-            self.beta = None\n-        self.moving_mean = self.add_weight(\n-            shape=shape,\n-            name='moving_mean',\n-            initializer=self.moving_mean_initializer,\n-            trainable=False)\n-        self.moving_variance = self.add_weight(\n-            shape=shape,\n-            name='moving_variance',\n-            initializer=self.moving_variance_initializer,\n-            trainable=False)\n-        self.built = True\n-\n-    def call(self, inputs, training=None):\n-        input_shape = K.int_shape(inputs)\n-        # Prepare broadcasting shape.\n-        ndim = len(input_shape)\n-        reduction_axes = list(range(len(input_shape)))\n-        del reduction_axes[self.axis]\n-        broadcast_shape = [1] * len(input_shape)\n-        broadcast_shape[self.axis] = input_shape[self.axis]\n-\n-        # Determines whether broadcasting is needed.\n-        needs_broadcasting = (sorted(reduction_axes) != list(range(ndim))[:-1])\n-\n-        def normalize_inference():\n-            if needs_broadcasting:\n-                # In this case we must explicitly broadcast all parameters.\n-                broadcast_moving_mean = K.reshape(self.moving_mean,\n-                                                  broadcast_shape)\n-                broadcast_moving_variance = K.reshape(self.moving_variance,\n-                                                      broadcast_shape)\n-                if self.center:\n-                    broadcast_beta = K.reshape(self.beta, broadcast_shape)\n-                else:\n-                    broadcast_beta = None\n-                if self.scale:\n-                    broadcast_gamma = K.reshape(self.gamma,\n-                                                broadcast_shape)\n-                else:\n-                    broadcast_gamma = None\n-                return K.batch_normalization(\n-                    inputs,\n-                    broadcast_moving_mean,\n-                    broadcast_moving_variance,\n-                    broadcast_beta,\n-                    broadcast_gamma,\n-                    axis=self.axis,\n-                    epsilon=self.epsilon)\n-            else:\n-                return K.batch_normalization(\n-                    inputs,\n-                    self.moving_mean,\n-                    self.moving_variance,\n-                    self.beta,\n-                    self.gamma,\n-                    axis=self.axis,\n-                    epsilon=self.epsilon)\n-\n-        # If the learning phase is *static* and set to inference:\n-        if training in {0, False}:\n-            return normalize_inference()\n-\n-        # If the learning is either dynamic, or set to training:\n-        normed_training, mean, variance = K.normalize_batch_in_training(\n-            inputs, self.gamma, self.beta, reduction_axes,\n-            epsilon=self.epsilon)\n-\n-        if K.backend() != 'cntk':\n-            sample_size = K.prod([K.shape(inputs)[axis]\n-                                  for axis in reduction_axes])\n-            sample_size = K.cast(sample_size, dtype=K.dtype(inputs))\n-            if K.backend() == 'tensorflow' and sample_size.dtype != 'float32':\n-                sample_size = K.cast(sample_size, dtype='float32')\n-\n-            # sample variance - unbiased estimator of population variance\n-            variance *= sample_size / (sample_size - (1.0 + self.epsilon))\n-\n-        self.add_update([K.moving_average_update(self.moving_mean,\n-                                                 mean,\n-                                                 self.momentum),\n-                         K.moving_average_update(self.moving_variance,\n-                                                 variance,\n-                                                 self.momentum)],\n-                        inputs)\n-\n-        # Pick the normalized form corresponding to the training phase.\n-        return K.in_train_phase(normed_training,\n-                                normalize_inference,\n-                                training=training)\n-\n-    def get_config(self):\n-        config = {\n-            'axis': self.axis,\n-            'momentum': self.momentum,\n-            'epsilon': self.epsilon,\n-            'center': self.center,\n-            'scale': self.scale,\n-            'beta_initializer': initializers.serialize(self.beta_initializer),\n-            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n-            'moving_mean_initializer':\n-                initializers.serialize(self.moving_mean_initializer),\n-            'moving_variance_initializer':\n-                initializers.serialize(self.moving_variance_initializer),\n-            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n-            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n-            'beta_constraint': constraints.serialize(self.beta_constraint),\n-            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n-        }\n-        base_config = super(BatchNormalization, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    def compute_output_shape(self, input_shape):\n-        return input_shape\n+from tensorflow.keras.layers import BatchNormalization\n\n@@ -1,779 +1,20 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Pooling layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Pooling layers.\"\"\"\n \n-from .. import backend as K\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import InputSpec\n-from ..utils import conv_utils\n-from ..legacy import interfaces\n+from tensorflow.keras.layers import MaxPooling1D\n+from tensorflow.keras.layers import MaxPooling2D\n+from tensorflow.keras.layers import MaxPooling3D\n \n+from tensorflow.keras.layers import AveragePooling1D\n+from tensorflow.keras.layers import AveragePooling2D\n+from tensorflow.keras.layers import AveragePooling3D\n \n-class _Pooling1D(Layer):\n-    \"\"\"Abstract class for different pooling 1D layers.\n-    \"\"\"\n+from tensorflow.keras.layers import GlobalAveragePooling1D\n+from tensorflow.keras.layers import GlobalAveragePooling2D\n+from tensorflow.keras.layers import GlobalAveragePooling3D\n \n-    def __init__(self, pool_size=2, strides=None,\n-                 padding='valid', data_format='channels_last', **kwargs):\n-        super(_Pooling1D, self).__init__(**kwargs)\n-        if strides is None:\n-            strides = pool_size\n-        self.pool_size = conv_utils.normalize_tuple(pool_size, 1, 'pool_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 1, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=3)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            steps = input_shape[2]\n-            features = input_shape[1]\n-        else:\n-            steps = input_shape[1]\n-            features = input_shape[2]\n-        length = conv_utils.conv_output_length(steps,\n-                                               self.pool_size[0],\n-                                               self.padding,\n-                                               self.strides[0])\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], features, length)\n-        else:\n-            return (input_shape[0], length, features)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        raise NotImplementedError\n-\n-    def call(self, inputs):\n-        dummy_axis = 2 if self.data_format == 'channels_last' else 3\n-        inputs = K.expand_dims(inputs, dummy_axis)   # add dummy last dimension\n-        output = self._pooling_function(inputs=inputs,\n-                                        pool_size=self.pool_size + (1,),\n-                                        strides=self.strides + (1,),\n-                                        padding=self.padding,\n-                                        data_format=self.data_format)\n-        return K.squeeze(output, dummy_axis)  # remove dummy last dimension\n-\n-    def get_config(self):\n-        config = {'strides': self.strides,\n-                  'pool_size': self.pool_size,\n-                  'padding': self.padding,\n-                  'data_format': self.data_format}\n-        base_config = super(_Pooling1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MaxPooling1D(_Pooling1D):\n-    \"\"\"Max pooling operation for temporal data.\n-\n-    # Arguments\n-        pool_size: Integer, size of the max pooling windows.\n-        strides: Integer, or None. Factor by which to downscale.\n-            E.g. 2 will halve the input.\n-            If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, features)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, features, steps)`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, steps)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, downsampled_steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, downsampled_steps)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling1d_support\n-    def __init__(self, pool_size=2, strides=None,\n-                 padding='valid', data_format='channels_last', **kwargs):\n-        super(MaxPooling1D, self).__init__(pool_size, strides,\n-                                           padding, data_format,\n-                                           **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool2d(inputs, pool_size, strides,\n-                          padding, data_format, pool_mode='max')\n-        return output\n-\n-\n-class AveragePooling1D(_Pooling1D):\n-    \"\"\"Average pooling for temporal data.\n-\n-    # Arguments\n-        pool_size: Integer, size of the average pooling windows.\n-        strides: Integer, or None. Factor by which to downscale.\n-            E.g. 2 will halve the input.\n-            If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, features)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, features, steps)`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, steps)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, downsampled_steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, downsampled_steps)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling1d_support\n-    def __init__(self, pool_size=2, strides=None,\n-                 padding='valid', data_format='channels_last', **kwargs):\n-        super(AveragePooling1D, self).__init__(pool_size, strides,\n-                                               padding, data_format,\n-                                               **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool2d(inputs, pool_size, strides,\n-                          padding, data_format, pool_mode='avg')\n-        return output\n-\n-\n-class _Pooling2D(Layer):\n-    \"\"\"Abstract class for different pooling 2D layers.\n-    \"\"\"\n-\n-    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(_Pooling2D, self).__init__(**kwargs)\n-        if strides is None:\n-            strides = pool_size\n-        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=4)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[1]\n-            cols = input_shape[2]\n-        rows = conv_utils.conv_output_length(rows, self.pool_size[0],\n-                                             self.padding, self.strides[0])\n-        cols = conv_utils.conv_output_length(cols, self.pool_size[1],\n-                                             self.padding, self.strides[1])\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], input_shape[1], rows, cols)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0], rows, cols, input_shape[3])\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        raise NotImplementedError\n-\n-    def call(self, inputs):\n-        output = self._pooling_function(inputs=inputs,\n-                                        pool_size=self.pool_size,\n-                                        strides=self.strides,\n-                                        padding=self.padding,\n-                                        data_format=self.data_format)\n-        return output\n-\n-    def get_config(self):\n-        config = {'pool_size': self.pool_size,\n-                  'padding': self.padding,\n-                  'strides': self.strides,\n-                  'data_format': self.data_format}\n-        base_config = super(_Pooling2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MaxPooling2D(_Pooling2D):\n-    \"\"\"Max pooling operation for spatial data.\n-\n-    # Arguments\n-        pool_size: integer or tuple of 2 integers,\n-            factors by which to downscale (vertical, horizontal).\n-            (2, 2) will halve the input in both spatial dimension.\n-            If only one integer is specified, the same window length\n-            will be used for both dimensions.\n-        strides: Integer, tuple of 2 integers, or None.\n-            Strides values.\n-            If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, rows, cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, rows, cols)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, pooled_rows, pooled_cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, pooled_rows, pooled_cols)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling2d_support\n-    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(MaxPooling2D, self).__init__(pool_size, strides, padding,\n-                                           data_format, **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool2d(inputs, pool_size, strides,\n-                          padding, data_format,\n-                          pool_mode='max')\n-        return output\n-\n-\n-class AveragePooling2D(_Pooling2D):\n-    \"\"\"Average pooling operation for spatial data.\n-\n-    # Arguments\n-        pool_size: Integer or tuple of 2 integers,\n-            factors by which to downscale (vertical, horizontal).\n-            (2, 2) will halve the input in both spatial dimension.\n-            If only one integer is specified, the same window length\n-            will be used for both dimensions.\n-        strides: Integer, tuple of 2 integers, or None.\n-            Strides values.\n-            If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, rows, cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, rows, cols)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, pooled_rows, pooled_cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, pooled_rows, pooled_cols)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling2d_support\n-    def __init__(self, pool_size=(2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(AveragePooling2D, self).__init__(pool_size, strides, padding,\n-                                               data_format, **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool2d(inputs, pool_size, strides,\n-                          padding, data_format, pool_mode='avg')\n-        return output\n-\n-\n-class _Pooling3D(Layer):\n-    \"\"\"Abstract class for different pooling 3D layers.\n-    \"\"\"\n-\n-    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(_Pooling3D, self).__init__(**kwargs)\n-        if strides is None:\n-            strides = pool_size\n-        self.pool_size = conv_utils.normalize_tuple(pool_size, 3, 'pool_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 3, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=5)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            len_dim1 = input_shape[2]\n-            len_dim2 = input_shape[3]\n-            len_dim3 = input_shape[4]\n-        elif self.data_format == 'channels_last':\n-            len_dim1 = input_shape[1]\n-            len_dim2 = input_shape[2]\n-            len_dim3 = input_shape[3]\n-        len_dim1 = conv_utils.conv_output_length(len_dim1, self.pool_size[0],\n-                                                 self.padding, self.strides[0])\n-        len_dim2 = conv_utils.conv_output_length(len_dim2, self.pool_size[1],\n-                                                 self.padding, self.strides[1])\n-        len_dim3 = conv_utils.conv_output_length(len_dim3, self.pool_size[2],\n-                                                 self.padding, self.strides[2])\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0],\n-                    input_shape[1],\n-                    len_dim1, len_dim2, len_dim3)\n-        elif self.data_format == 'channels_last':\n-            return (input_shape[0],\n-                    len_dim1, len_dim2, len_dim3,\n-                    input_shape[4])\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        raise NotImplementedError\n-\n-    def call(self, inputs):\n-        output = self._pooling_function(inputs=inputs,\n-                                        pool_size=self.pool_size,\n-                                        strides=self.strides,\n-                                        padding=self.padding,\n-                                        data_format=self.data_format)\n-        return output\n-\n-    def get_config(self):\n-        config = {'pool_size': self.pool_size,\n-                  'padding': self.padding,\n-                  'strides': self.strides,\n-                  'data_format': self.data_format}\n-        base_config = super(_Pooling3D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MaxPooling3D(_Pooling3D):\n-    \"\"\"Max pooling operation for 3D data (spatial or spatio-temporal).\n-\n-    # Arguments\n-        pool_size: Integer or tuple of 3 integers,\n-            factors by which to downscale (dim1, dim2, dim3).\n-            (2, 2, 2) will halve the size of the 3D input in each dimension.\n-        strides: Integer, tuple of 3 integers, or None. Strides values.\n-                If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling3d_support\n-    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(MaxPooling3D, self).__init__(pool_size, strides, padding,\n-                                           data_format, **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool3d(inputs, pool_size, strides,\n-                          padding, data_format, pool_mode='max')\n-        return output\n-\n-\n-class AveragePooling3D(_Pooling3D):\n-    \"\"\"Average pooling operation for 3D data (spatial or spatio-temporal).\n-\n-    # Arguments\n-        pool_size: Integer or tuple of 3 integers,\n-            factors by which to downscale (dim1, dim2, dim3).\n-            (2, 2, 2) will halve the size of the 3D input in each dimension.\n-        strides: Integer, tuple of 3 integers, or None. Strides values.\n-            If None, it will default to `pool_size`.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n-\n-    # Output shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`\n-    \"\"\"\n-\n-    @interfaces.legacy_pooling3d_support\n-    def __init__(self, pool_size=(2, 2, 2), strides=None, padding='valid',\n-                 data_format=None, **kwargs):\n-        super(AveragePooling3D, self).__init__(pool_size, strides, padding,\n-                                               data_format, **kwargs)\n-\n-    def _pooling_function(self, inputs, pool_size, strides,\n-                          padding, data_format):\n-        output = K.pool3d(inputs, pool_size, strides,\n-                          padding, data_format,\n-                          pool_mode='avg')\n-        return output\n-\n-\n-class _GlobalPooling1D(Layer):\n-    \"\"\"Abstract class for different global pooling 1D layers.\n-    \"\"\"\n-\n-    def __init__(self, data_format='channels_last', **kwargs):\n-        super(_GlobalPooling1D, self).__init__(**kwargs)\n-        self.input_spec = InputSpec(ndim=3)\n-        self.data_format = K.normalize_data_format(data_format)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_first':\n-            return (input_shape[0], input_shape[1])\n-        else:\n-            return (input_shape[0], input_shape[2])\n-\n-    def call(self, inputs):\n-        raise NotImplementedError\n-\n-    def get_config(self):\n-        config = {'data_format': self.data_format}\n-        base_config = super(_GlobalPooling1D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class GlobalAveragePooling1D(_GlobalPooling1D):\n-    \"\"\"Global average pooling operation for temporal data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, features)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, features, steps)`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, steps)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, features)`\n-    \"\"\"\n-\n-    def __init__(self, data_format='channels_last', **kwargs):\n-        super(GlobalAveragePooling1D, self).__init__(data_format,\n-                                                     **kwargs)\n-        self.supports_masking = True\n-\n-    def call(self, inputs, mask=None):\n-        steps_axis = 1 if self.data_format == 'channels_last' else 2\n-        if mask is not None:\n-            mask = K.cast(mask, K.floatx())\n-            input_shape = K.int_shape(inputs)\n-            broadcast_shape = [-1, input_shape[steps_axis], 1]\n-            mask = K.reshape(mask, broadcast_shape)\n-            inputs *= mask\n-            return K.sum(inputs, axis=steps_axis) / K.sum(mask, axis=steps_axis)\n-        else:\n-            return K.mean(inputs, axis=steps_axis)\n-\n-    def compute_mask(self, inputs, mask=None):\n-        return None\n-\n-\n-class GlobalMaxPooling1D(_GlobalPooling1D):\n-    \"\"\"Global max pooling operation for temporal data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, steps, features)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, features, steps)`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            3D tensor with shape:\n-            `(batch_size, steps, features)`\n-        - If `data_format='channels_first'`:\n-            3D tensor with shape:\n-            `(batch_size, features, steps)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, features)`\n-    \"\"\"\n-\n-    def call(self, inputs):\n-        steps_axis = 1 if self.data_format == 'channels_last' else 2\n-        return K.max(inputs, axis=steps_axis)\n-\n-\n-class _GlobalPooling2D(Layer):\n-    \"\"\"Abstract class for different global pooling 2D layers.\n-    \"\"\"\n-\n-    @interfaces.legacy_global_pooling_support\n-    def __init__(self, data_format=None, **kwargs):\n-        super(_GlobalPooling2D, self).__init__(**kwargs)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=4)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_last':\n-            return (input_shape[0], input_shape[3])\n-        else:\n-            return (input_shape[0], input_shape[1])\n-\n-    def call(self, inputs):\n-        raise NotImplementedError\n-\n-    def get_config(self):\n-        config = {'data_format': self.data_format}\n-        base_config = super(_GlobalPooling2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class GlobalAveragePooling2D(_GlobalPooling2D):\n-    \"\"\"Global average pooling operation for spatial data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, rows, cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, rows, cols)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, channels)`\n-    \"\"\"\n-\n-    def call(self, inputs):\n-        if self.data_format == 'channels_last':\n-            return K.mean(inputs, axis=[1, 2])\n-        else:\n-            return K.mean(inputs, axis=[2, 3])\n-\n-\n-class GlobalMaxPooling2D(_GlobalPooling2D):\n-    \"\"\"Global max pooling operation for spatial data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, height, width, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape\n-            `(batch, channels, height, width)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            4D tensor with shape:\n-            `(batch_size, rows, cols, channels)`\n-        - If `data_format='channels_first'`:\n-            4D tensor with shape:\n-            `(batch_size, channels, rows, cols)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, channels)`\n-    \"\"\"\n-\n-    def call(self, inputs):\n-        if self.data_format == 'channels_last':\n-            return K.max(inputs, axis=[1, 2])\n-        else:\n-            return K.max(inputs, axis=[2, 3])\n-\n-\n-class _GlobalPooling3D(Layer):\n-    \"\"\"Abstract class for different global pooling 3D layers.\n-    \"\"\"\n-\n-    @interfaces.legacy_global_pooling_support\n-    def __init__(self, data_format=None, **kwargs):\n-        super(_GlobalPooling3D, self).__init__(**kwargs)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.input_spec = InputSpec(ndim=5)\n-\n-    def compute_output_shape(self, input_shape):\n-        if self.data_format == 'channels_last':\n-            return (input_shape[0], input_shape[4])\n-        else:\n-            return (input_shape[0], input_shape[1])\n-\n-    def call(self, inputs):\n-        raise NotImplementedError\n-\n-    def get_config(self):\n-        config = {'data_format': self.data_format}\n-        base_config = super(_GlobalPooling3D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class GlobalAveragePooling3D(_GlobalPooling3D):\n-    \"\"\"Global Average pooling operation for 3D data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, channels)`\n-    \"\"\"\n-\n-    def call(self, inputs):\n-        if self.data_format == 'channels_last':\n-            return K.mean(inputs, axis=[1, 2, 3])\n-        else:\n-            return K.mean(inputs, axis=[2, 3, 4])\n-\n-\n-class GlobalMaxPooling3D(_GlobalPooling3D):\n-    \"\"\"Global Max pooling operation for 3D data.\n-\n-    # Arguments\n-        data_format: A string,\n-            one of `\"channels_last\"` (default) or `\"channels_first\"`.\n-            The ordering of the dimensions in the inputs.\n-            `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-            while `\"channels_first\"` corresponds to inputs with shape\n-            `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be `\"channels_last\"`.\n-\n-    # Input shape\n-        - If `data_format='channels_last'`:\n-            5D tensor with shape:\n-            `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n-        - If `data_format='channels_first'`:\n-            5D tensor with shape:\n-            `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`\n-\n-    # Output shape\n-        2D tensor with shape:\n-        `(batch_size, channels)`\n-    \"\"\"\n-\n-    def call(self, inputs):\n-        if self.data_format == 'channels_last':\n-            return K.max(inputs, axis=[1, 2, 3])\n-        else:\n-            return K.max(inputs, axis=[2, 3, 4])\n+from tensorflow.keras.layers import GlobalMaxPooling1D\n+from tensorflow.keras.layers import GlobalMaxPooling2D\n+from tensorflow.keras.layers import GlobalMaxPooling3D\n \n \n # Aliases\n\n@@ -1,2407 +1,12 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Recurrent layers and their base classes.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Recurrent layers and their base classes.\"\"\"\n \n-import numpy as np\n-import warnings\n+from tensorflow.keras.layers import RNN\n+from tensorflow.keras.layers import StackedRNNCells\n \n-from .. import backend as K\n-from .. import activations\n-from .. import initializers\n-from .. import regularizers\n-from .. import constraints\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import disable_tracking\n-from ..engine.base_layer import InputSpec\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import to_list\n+from tensorflow.keras.layers import SimpleRNN\n+from tensorflow.keras.layers import GRU\n+from tensorflow.keras.layers import LSTM\n \n-# Legacy support.\n-from ..legacy.layers import Recurrent\n-from ..legacy import interfaces\n-\n-\n-class StackedRNNCells(Layer):\n-    \"\"\"Wrapper allowing a stack of RNN cells to behave as a single cell.\n-\n-    Used to implement efficient stacked RNNs.\n-\n-    # Arguments\n-        cells: List of RNN cell instances.\n-\n-    # Examples\n-\n-    ```python\n-        cells = [\n-            keras.layers.LSTMCell(output_dim),\n-            keras.layers.LSTMCell(output_dim),\n-            keras.layers.LSTMCell(output_dim),\n-        ]\n-\n-        inputs = keras.Input((timesteps, input_dim))\n-        x = keras.layers.RNN(cells)(inputs)\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, cells, **kwargs):\n-        for cell in cells:\n-            if not hasattr(cell, 'call'):\n-                raise ValueError('All cells must have a `call` method. '\n-                                 'received cells:', cells)\n-            if not hasattr(cell, 'state_size'):\n-                raise ValueError('All cells must have a '\n-                                 '`state_size` attribute. '\n-                                 'received cells:', cells)\n-        self.cells = cells\n-        # reverse_state_order determines whether the state size will be in a\n-        # reverse order of the cells' state. User might want to set this to True\n-        # to keep the existing behavior. This is only useful when use\n-        # `RNN(return_state=True)` since the state will be returned as the same\n-        # order of state_size.\n-        self.reverse_state_order = kwargs.pop('reverse_state_order', False)\n-        if self.reverse_state_order:\n-            warnings.warn('`reverse_state_order=True` in `StackedRNNCells` '\n-                          'will soon be deprecated. Please update the code to '\n-                          'work with the natural order of states if you '\n-                          'reply on the RNN states, '\n-                          'eg `RNN(return_state=True)`.')\n-        super(StackedRNNCells, self).__init__(**kwargs)\n-\n-    @property\n-    def state_size(self):\n-        # States are a flat list of the individual cell state size.\n-        # e.g. states of a 2-layer LSTM would be `[h1, c1, h2, c2]`.\n-        # (assuming one LSTM has states [h, c])\n-        # In the case of reverse_state_order=True, the state_size will be\n-        # `[h2, c2, h1, c1]`.\n-        state_size = []\n-        for cell in self.cells[::-1] if self.reverse_state_order else self.cells:\n-            if hasattr(cell.state_size, '__len__'):\n-                state_size += list(cell.state_size)\n-            else:\n-                state_size.append(cell.state_size)\n-        return tuple(state_size)\n-\n-    @property\n-    def output_size(self):\n-        if getattr(self.cells[-1], 'output_size', None) is not None:\n-            return self.cells[-1].output_size\n-        if hasattr(self.cells[-1].state_size, '__len__'):\n-            return self.cells[-1].state_size[0]\n-        else:\n-            return self.cells[-1].state_size\n-\n-    def call(self, inputs, states, constants=None, **kwargs):\n-        # Recover per-cell states.\n-        nested_states = []\n-        for cell in self.cells[::-1] if self.reverse_state_order else self.cells:\n-            if hasattr(cell.state_size, '__len__'):\n-                nested_states.append(states[:len(cell.state_size)])\n-                states = states[len(cell.state_size):]\n-            else:\n-                nested_states.append([states[0]])\n-                states = states[1:]\n-        if self.reverse_state_order:\n-            nested_states = nested_states[::-1]\n-\n-        # Call the cells in order and store the returned states.\n-        new_nested_states = []\n-        for cell, states in zip(self.cells, nested_states):\n-            if has_arg(cell.call, 'constants'):\n-                inputs, states = cell.call(inputs, states,\n-                                           constants=constants,\n-                                           **kwargs)\n-            else:\n-                inputs, states = cell.call(inputs, states, **kwargs)\n-            new_nested_states.append(states)\n-\n-        # Format the new states as a flat list\n-        # in reverse cell order.\n-        new_states = []\n-        if self.reverse_state_order:\n-            new_nested_states = new_nested_states[::-1]\n-        for cell_states in new_nested_states:\n-            new_states += cell_states\n-        return inputs, new_states\n-\n-    def build(self, input_shape):\n-        if isinstance(input_shape, list):\n-            constants_shape = input_shape[1:]\n-            input_shape = input_shape[0]\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                if has_arg(cell.call, 'constants'):\n-                    cell.build([input_shape] + constants_shape)\n-                else:\n-                    cell.build(input_shape)\n-            if getattr(cell, 'output_size', None) is not None:\n-                output_dim = cell.output_size\n-            elif hasattr(cell.state_size, '__len__'):\n-                output_dim = cell.state_size[0]\n-            else:\n-                output_dim = cell.state_size\n-            input_shape = (input_shape[0], output_dim)\n-        self.built = True\n-\n-    def get_config(self):\n-        cells = []\n-        for cell in self.cells:\n-            cells.append({'class_name': cell.__class__.__name__,\n-                          'config': cell.get_config()})\n-        config = {'cells': cells}\n-        base_config = super(StackedRNNCells, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        from . import deserialize as deserialize_layer\n-        cells = []\n-        for cell_config in config.pop('cells'):\n-            cells.append(deserialize_layer(cell_config,\n-                                           custom_objects=custom_objects))\n-        return cls(cells, **config)\n-\n-    @property\n-    def trainable_weights(self):\n-        if not self.trainable:\n-            return []\n-        weights = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                weights += cell.trainable_weights\n-        return weights\n-\n-    @property\n-    def non_trainable_weights(self):\n-        weights = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                weights += cell.non_trainable_weights\n-        if not self.trainable:\n-            trainable_weights = []\n-            for cell in self.cells:\n-                if isinstance(cell, Layer):\n-                    trainable_weights += cell.trainable_weights\n-            return trainable_weights + weights\n-        return weights\n-\n-    def get_weights(self):\n-        \"\"\"Retrieves the weights of the model.\n-\n-        # Returns\n-            A flat list of Numpy arrays.\n-        \"\"\"\n-        weights = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                weights += cell.weights\n-        return K.batch_get_value(weights)\n-\n-    def set_weights(self, weights):\n-        \"\"\"Sets the weights of the model.\n-\n-        # Arguments\n-            weights: A list of Numpy arrays with shapes and types matching\n-                the output of `model.get_weights()`.\n-        \"\"\"\n-        tuples = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                num_param = len(cell.weights)\n-                weights = weights[:num_param]\n-                for sw, w in zip(cell.weights, weights):\n-                    tuples.append((sw, w))\n-                weights = weights[num_param:]\n-        K.batch_set_value(tuples)\n-\n-    @property\n-    def losses(self):\n-        losses = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                cell_losses = cell.losses\n-                losses += cell_losses\n-        return losses\n-\n-    def get_losses_for(self, inputs=None):\n-        losses = []\n-        for cell in self.cells:\n-            if isinstance(cell, Layer):\n-                cell_losses = cell.get_losses_for(inputs)\n-                losses += cell_losses\n-        return losses\n-\n-\n-class RNN(Layer):\n-    \"\"\"Base class for recurrent layers.\n-\n-    # Arguments\n-        cell: A RNN cell instance. A RNN cell is a class that has:\n-            - a `call(input_at_t, states_at_t)` method, returning\n-                `(output_at_t, states_at_t_plus_1)`. The call method of the\n-                cell can also take the optional argument `constants`, see\n-                section \"Note on passing external constants\" below.\n-            - a `state_size` attribute. This can be a single integer\n-                (single state) in which case it is\n-                the size of the recurrent state\n-                (which should be the same as the size of the cell output).\n-                This can also be a list/tuple of integers\n-                (one size per state).\n-            - a `output_size` attribute. This can be a single integer or a\n-                TensorShape, which represent the shape of the output. For\n-                backward compatible reason, if this attribute is not available\n-                for the cell, the value will be inferred by the first element\n-                of the `state_size`.\n-            It is also possible for `cell` to be a list of RNN cell instances,\n-            in which cases the cells get stacked one after the other in the RNN,\n-            implementing an efficient stacked RNN.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-        input_dim: dimensionality of the input (integer).\n-            This argument (or alternatively,\n-            the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, to be specified\n-            when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-            Note that if the recurrent layer is not the first layer\n-            in your model, you would need to specify the input length\n-            at the level of the first layer\n-            (e.g. via the `input_shape` argument)\n-\n-    # Input shape\n-        3D tensor with shape `(batch_size, timesteps, input_dim)`.\n-\n-    # Output shape\n-        - if `return_state`: a list of tensors. The first tensor is\n-            the output. The remaining tensors are the last states,\n-            each with shape `(batch_size, units)`. For example, the number of\n-            state tensors is 1 (for RNN and GRU) or 2 (for LSTM).\n-        - if `return_sequences`: 3D tensor with shape\n-            `(batch_size, timesteps, units)`.\n-        - else, 2D tensor with shape `(batch_size, units)`.\n-\n-    # Masking\n-        This layer supports masking for input data with a variable number\n-        of timesteps. To introduce masks to your data,\n-        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-        set to `True`.\n-\n-    # Note on using statefulness in RNNs\n-        You can set RNN layers to be 'stateful', which means that the states\n-        computed for the samples in one batch will be reused as initial states\n-        for the samples in the next batch. This assumes a one-to-one mapping\n-        between samples in different successive batches.\n-\n-        To enable statefulness:\n-            - specify `stateful=True` in the layer constructor.\n-            - specify a fixed batch size for your model, by passing\n-                if sequential model:\n-                  `batch_input_shape=(...)` to the first layer in your model.\n-                else for functional model with 1 or more Input layers:\n-                  `batch_shape=(...)` to all the first layers in your model.\n-                This is the expected shape of your inputs\n-                *including the batch size*.\n-                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n-            - specify `shuffle=False` when calling fit().\n-\n-        To reset the states of your model, call `.reset_states()` on either\n-        a specific layer, or on your entire model.\n-\n-    # Note on specifying the initial state of RNNs\n-        You can specify the initial state of RNN layers symbolically by\n-        calling them with the keyword argument `initial_state`. The value of\n-        `initial_state` should be a tensor or list of tensors representing\n-        the initial state of the RNN layer.\n-\n-        You can specify the initial state of RNN layers numerically by\n-        calling `reset_states` with the keyword argument `states`. The value of\n-        `states` should be a numpy array or list of numpy arrays representing\n-        the initial state of the RNN layer.\n-\n-    # Note on passing external constants to RNNs\n-        You can pass \"external\" constants to the cell using the `constants`\n-        keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n-        requires that the `cell.call` method accepts the same keyword argument\n-        `constants`. Such constants can be used to condition the cell\n-        transformation on additional static inputs (not changing over time),\n-        a.k.a. an attention mechanism.\n-\n-    # Examples\n-\n-    ```python\n-        # First, let's define a RNN Cell, as a layer subclass.\n-\n-        class MinimalRNNCell(keras.layers.Layer):\n-\n-            def __init__(self, units, **kwargs):\n-                self.units = units\n-                self.state_size = units\n-                super(MinimalRNNCell, self).__init__(**kwargs)\n-\n-            def build(self, input_shape):\n-                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n-                                              initializer='uniform',\n-                                              name='kernel')\n-                self.recurrent_kernel = self.add_weight(\n-                    shape=(self.units, self.units),\n-                    initializer='uniform',\n-                    name='recurrent_kernel')\n-                self.built = True\n-\n-            def call(self, inputs, states):\n-                prev_output = states[0]\n-                h = K.dot(inputs, self.kernel)\n-                output = h + K.dot(prev_output, self.recurrent_kernel)\n-                return output, [output]\n-\n-        # Let's use this cell in a RNN layer:\n-\n-        cell = MinimalRNNCell(32)\n-        x = keras.Input((None, 5))\n-        layer = RNN(cell)\n-        y = layer(x)\n-\n-        # Here's how to use the cell to build a stacked RNN:\n-\n-        cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n-        x = keras.Input((None, 5))\n-        layer = RNN(cells)\n-        y = layer(x)\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, cell,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 **kwargs):\n-        if isinstance(cell, (list, tuple)):\n-            cell = StackedRNNCells(cell)\n-        if not hasattr(cell, 'call'):\n-            raise ValueError('`cell` should have a `call` method. '\n-                             'The RNN was passed:', cell)\n-        if not hasattr(cell, 'state_size'):\n-            raise ValueError('The RNN cell should have '\n-                             'an attribute `state_size` '\n-                             '(tuple of integers, '\n-                             'one integer per RNN state).')\n-        super(RNN, self).__init__(**kwargs)\n-        self._set_cell(cell)\n-        self.return_sequences = return_sequences\n-        self.return_state = return_state\n-        self.go_backwards = go_backwards\n-        self.stateful = stateful\n-        self.unroll = unroll\n-\n-        self.supports_masking = True\n-        self.input_spec = [InputSpec(ndim=3)]\n-        self.state_spec = None\n-        self._states = None\n-        self.constants_spec = None\n-        self._num_constants = None\n-\n-    @disable_tracking\n-    def _set_cell(self, cell):\n-        # This is isolated in its own method in order to use\n-        # the disable_tracking decorator without altering the\n-        # visible signature of __init__.\n-        self.cell = cell\n-\n-    @property\n-    def states(self):\n-        if self._states is None:\n-            if isinstance(self.cell.state_size, int):\n-                num_states = 1\n-            else:\n-                num_states = len(self.cell.state_size)\n-            return [None for _ in range(num_states)]\n-        return self._states\n-\n-    @states.setter\n-    def states(self, states):\n-        self._states = states\n-\n-    def compute_output_shape(self, input_shape):\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-\n-        if hasattr(self.cell.state_size, '__len__'):\n-            state_size = self.cell.state_size\n-        else:\n-            state_size = [self.cell.state_size]\n-\n-        if getattr(self.cell, 'output_size', None) is not None:\n-            output_dim = self.cell.output_size\n-        else:\n-            output_dim = state_size[0]\n-\n-        if self.return_sequences:\n-            output_shape = (input_shape[0], input_shape[1], output_dim)\n-        else:\n-            output_shape = (input_shape[0], output_dim)\n-\n-        if self.return_state:\n-            state_shape = [(input_shape[0], dim) for dim in state_size]\n-            return [output_shape] + state_shape\n-        else:\n-            return output_shape\n-\n-    def compute_mask(self, inputs, mask):\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-        output_mask = mask if self.return_sequences else None\n-        if self.return_state:\n-            state_mask = [None for _ in self.states]\n-            return [output_mask] + state_mask\n-        else:\n-            return output_mask\n-\n-    def build(self, input_shape):\n-        # Note input_shape will be list of shapes of initial states and\n-        # constants if these are passed in __call__.\n-        if self._num_constants is not None:\n-            constants_shape = input_shape[-self._num_constants:]\n-        else:\n-            constants_shape = None\n-\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-\n-        batch_size = input_shape[0] if self.stateful else None\n-        input_dim = input_shape[-1]\n-        self.input_spec[0] = InputSpec(shape=(batch_size, None, input_dim))\n-\n-        # allow cell (if layer) to build before we set or validate state_spec\n-        if isinstance(self.cell, Layer):\n-            step_input_shape = (input_shape[0],) + input_shape[2:]\n-            if constants_shape is not None:\n-                self.cell.build([step_input_shape] + constants_shape)\n-            else:\n-                self.cell.build(step_input_shape)\n-\n-        # set or validate state_spec\n-        if hasattr(self.cell.state_size, '__len__'):\n-            state_size = list(self.cell.state_size)\n-        else:\n-            state_size = [self.cell.state_size]\n-\n-        if self.state_spec is not None:\n-            # initial_state was passed in call, check compatibility\n-            if [spec.shape[-1] for spec in self.state_spec] != state_size:\n-                raise ValueError(\n-                    'An `initial_state` was passed that is not compatible with '\n-                    '`cell.state_size`. Received `state_spec`={}; '\n-                    'however `cell.state_size` is '\n-                    '{}'.format(self.state_spec, self.cell.state_size))\n-        else:\n-            self.state_spec = [InputSpec(shape=(None, dim))\n-                               for dim in state_size]\n-        if self.stateful:\n-            self.reset_states()\n-        self.built = True\n-\n-    def get_initial_state(self, inputs):\n-        # build an all-zero tensor of shape (samples, output_dim)\n-        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n-        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n-        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n-        if hasattr(self.cell.state_size, '__len__'):\n-            return [K.tile(initial_state, [1, dim])\n-                    for dim in self.cell.state_size]\n-        else:\n-            return [K.tile(initial_state, [1, self.cell.state_size])]\n-\n-    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n-        inputs, initial_state, constants = _standardize_args(\n-            inputs, initial_state, constants, self._num_constants)\n-\n-        if initial_state is None and constants is None:\n-            return super(RNN, self).__call__(inputs, **kwargs)\n-\n-        # If any of `initial_state` or `constants` are specified and are Keras\n-        # tensors, then add them to the inputs and temporarily modify the\n-        # input_spec to include them.\n-\n-        additional_inputs = []\n-        additional_specs = []\n-\n-        if initial_state is not None:\n-            kwargs['initial_state'] = initial_state\n-            additional_inputs += initial_state\n-            self.state_spec = [InputSpec(shape=K.int_shape(state))\n-                               for state in initial_state]\n-            additional_specs += self.state_spec\n-        if constants is not None:\n-            kwargs['constants'] = constants\n-            additional_inputs += constants\n-            self.constants_spec = [InputSpec(shape=K.int_shape(constant))\n-                                   for constant in constants]\n-            self._num_constants = len(constants)\n-            additional_specs += self.constants_spec\n-        # at this point additional_inputs cannot be empty\n-        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n-        for tensor in additional_inputs:\n-            if K.is_keras_tensor(tensor) != is_keras_tensor:\n-                raise ValueError('The initial state or constants of an RNN'\n-                                 ' layer cannot be specified with a mix of'\n-                                 ' Keras tensors and non-Keras tensors'\n-                                 ' (a \"Keras tensor\" is a tensor that was'\n-                                 ' returned by a Keras layer, or by `Input`)')\n-\n-        if is_keras_tensor:\n-            # Compute the full input spec, including state and constants\n-            full_input = [inputs] + additional_inputs\n-            full_input_spec = self.input_spec + additional_specs\n-            # Perform the call with temporarily replaced input_spec\n-            original_input_spec = self.input_spec\n-            self.input_spec = full_input_spec\n-            if 'initial_state' in kwargs:\n-                kwargs.pop('initial_state')\n-            if 'constants' in kwargs:\n-                kwargs.pop('constants')\n-            output = super(RNN, self).__call__(full_input, **kwargs)\n-            self.input_spec = original_input_spec\n-            return output\n-        else:\n-            return super(RNN, self).__call__(inputs, **kwargs)\n-\n-    def call(self,\n-             inputs,\n-             mask=None,\n-             training=None,\n-             initial_state=None,\n-             constants=None):\n-        if not isinstance(initial_state, (list, tuple, type(None))):\n-            initial_state = [initial_state]\n-        if not isinstance(constants, (list, tuple, type(None))):\n-            constants = [constants]\n-        # input shape: `(samples, time (padded with zeros), input_dim)`\n-        # note that the .build() method of subclasses MUST define\n-        # self.input_spec and self.state_spec with complete input shapes.\n-        if isinstance(inputs, list):\n-            if len(inputs) == 1:\n-                inputs = inputs[0]\n-            else:\n-                # get initial_state from full input spec\n-                # as they could be copied to multiple GPU.\n-                if self._num_constants is None:\n-                    if initial_state is not None:\n-                        raise ValueError('Layer was passed initial state ' +\n-                                         'via both kwarg and inputs list)')\n-                    initial_state = inputs[1:]\n-                else:\n-                    if initial_state is not None and inputs[1:-self._num_constants]:\n-                        raise ValueError('Layer was passed initial state ' +\n-                                         'via both kwarg and inputs list')\n-                    initial_state = inputs[1:-self._num_constants]\n-                    if constants is None:\n-                        constants = inputs[-self._num_constants:]\n-                    elif len(inputs) > 1 + len(initial_state):\n-                        raise ValueError('Layer was passed constants ' +\n-                                         'via both kwarg and inputs list)')\n-                if len(initial_state) == 0:\n-                    initial_state = None\n-                inputs = inputs[0]\n-        if initial_state is not None:\n-            pass\n-        elif self.stateful:\n-            initial_state = self.states\n-        else:\n-            initial_state = self.get_initial_state(inputs)\n-\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-\n-        if len(initial_state) != len(self.states):\n-            raise ValueError('Layer has ' + str(len(self.states)) +\n-                             ' states but was passed ' +\n-                             str(len(initial_state)) +\n-                             ' initial states.')\n-\n-        input_shape = K.int_shape(inputs)\n-        timesteps = input_shape[1]\n-        if self.unroll and timesteps is None:\n-            raise ValueError('Cannot unroll a RNN if the '\n-                             'time dimension is undefined. \\n'\n-                             '- If using a Sequential model, '\n-                             'specify the time dimension by passing '\n-                             'an `input_shape` or `batch_input_shape` '\n-                             'argument to your first layer. If your '\n-                             'first layer is an Embedding, you can '\n-                             'also use the `input_length` argument.\\n'\n-                             '- If using the functional API, specify '\n-                             'the time dimension by passing a `shape` '\n-                             'or `batch_shape` argument to your Input layer.')\n-\n-        kwargs = {}\n-        if has_arg(self.cell.call, 'training'):\n-            kwargs['training'] = training\n-\n-        if constants:\n-            if not has_arg(self.cell.call, 'constants'):\n-                raise ValueError('RNN cell does not support constants')\n-\n-            def step(inputs, states):\n-                constants = states[-self._num_constants:]\n-                states = states[:-self._num_constants]\n-                return self.cell.call(inputs, states, constants=constants,\n-                                      **kwargs)\n-        else:\n-            def step(inputs, states):\n-                return self.cell.call(inputs, states, **kwargs)\n-\n-        last_output, outputs, states = K.rnn(step,\n-                                             inputs,\n-                                             initial_state,\n-                                             constants=constants,\n-                                             go_backwards=self.go_backwards,\n-                                             mask=mask,\n-                                             unroll=self.unroll,\n-                                             input_length=timesteps)\n-        if self.stateful:\n-            updates = []\n-            for i in range(len(states)):\n-                updates.append((self.states[i], states[i]))\n-            self.add_update(updates, inputs)\n-\n-        if self.return_sequences:\n-            output = outputs\n-        else:\n-            output = last_output\n-\n-        # Properly set learning phase\n-        if getattr(last_output, '_uses_learning_phase', False):\n-            output._uses_learning_phase = True\n-            for state in states:\n-                state._uses_learning_phase = True\n-\n-        if self.return_state:\n-            states = to_list(states, allow_tuple=True)\n-            return [output] + states\n-        else:\n-            return output\n-\n-    def reset_states(self, states=None):\n-        if not self.stateful:\n-            raise AttributeError('Layer must be stateful.')\n-        batch_size = self.input_spec[0].shape[0]\n-        if not batch_size:\n-            raise ValueError('If a RNN is stateful, it needs to know '\n-                             'its batch size. Specify the batch size '\n-                             'of your input tensors: \\n'\n-                             '- If using a Sequential model, '\n-                             'specify the batch size by passing '\n-                             'a `batch_input_shape` '\n-                             'argument to your first layer.\\n'\n-                             '- If using the functional API, specify '\n-                             'the batch size by passing a '\n-                             '`batch_shape` argument to your Input layer.')\n-        # initialize state if None\n-        if self.states[0] is None:\n-            if hasattr(self.cell.state_size, '__len__'):\n-                self.states = [K.zeros((batch_size, dim))\n-                               for dim in self.cell.state_size]\n-            else:\n-                self.states = [K.zeros((batch_size, self.cell.state_size))]\n-        elif states is None:\n-            if hasattr(self.cell.state_size, '__len__'):\n-                for state, dim in zip(self.states, self.cell.state_size):\n-                    K.set_value(state, np.zeros((batch_size, dim)))\n-            else:\n-                K.set_value(self.states[0],\n-                            np.zeros((batch_size, self.cell.state_size)))\n-        else:\n-            states = to_list(states, allow_tuple=True)\n-            if len(states) != len(self.states):\n-                raise ValueError('Layer ' + self.name + ' expects ' +\n-                                 str(len(self.states)) + ' states, '\n-                                 'but it received ' + str(len(states)) +\n-                                 ' state values. Input received: ' +\n-                                 str(states))\n-            for index, (value, state) in enumerate(zip(states, self.states)):\n-                if hasattr(self.cell.state_size, '__len__'):\n-                    dim = self.cell.state_size[index]\n-                else:\n-                    dim = self.cell.state_size\n-                if value.shape != (batch_size, dim):\n-                    raise ValueError('State ' + str(index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected shape=' +\n-                                     str((batch_size, dim)) +\n-                                     ', found shape=' + str(value.shape))\n-                # TODO: consider batch calls to `set_value`.\n-                K.set_value(state, value)\n-\n-    def get_config(self):\n-        config = {'return_sequences': self.return_sequences,\n-                  'return_state': self.return_state,\n-                  'go_backwards': self.go_backwards,\n-                  'stateful': self.stateful,\n-                  'unroll': self.unroll}\n-        if self._num_constants is not None:\n-            config['num_constants'] = self._num_constants\n-\n-        cell_config = self.cell.get_config()\n-        config['cell'] = {'class_name': self.cell.__class__.__name__,\n-                          'config': cell_config}\n-        base_config = super(RNN, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        from . import deserialize as deserialize_layer\n-        cell = deserialize_layer(config.pop('cell'),\n-                                 custom_objects=custom_objects)\n-        num_constants = config.pop('num_constants', None)\n-        layer = cls(cell, **config)\n-        layer._num_constants = num_constants\n-        return layer\n-\n-    @property\n-    def trainable_weights(self):\n-        if not self.trainable:\n-            return []\n-        if isinstance(self.cell, Layer):\n-            return self.cell.trainable_weights\n-        return []\n-\n-    @property\n-    def non_trainable_weights(self):\n-        if isinstance(self.cell, Layer):\n-            if not self.trainable:\n-                return self.cell.weights\n-            return self.cell.non_trainable_weights\n-        return []\n-\n-    @property\n-    def losses(self):\n-        layer_losses = super(RNN, self).losses\n-        if isinstance(self.cell, Layer):\n-            return self.cell.losses + layer_losses\n-        return layer_losses\n-\n-    def get_losses_for(self, inputs=None):\n-        if isinstance(self.cell, Layer):\n-            cell_losses = self.cell.get_losses_for(inputs)\n-            return cell_losses + super(RNN, self).get_losses_for(inputs)\n-        return super(RNN, self).get_losses_for(inputs)\n-\n-\n-class SimpleRNNCell(Layer):\n-    \"\"\"Cell class for SimpleRNN.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-    \"\"\"\n-\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 **kwargs):\n-        super(SimpleRNNCell, self).__init__(**kwargs)\n-        self.units = units\n-        self.activation = activations.get(activation)\n-        self.use_bias = use_bias\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-        self.dropout = min(1., max(0., dropout))\n-        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n-        self.state_size = self.units\n-        self.output_size = self.units\n-        self._dropout_mask = None\n-        self._recurrent_dropout_mask = None\n-\n-    def build(self, input_shape):\n-        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n-                                      name='kernel',\n-                                      initializer=self.kernel_initializer,\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units),\n-            name='recurrent_kernel',\n-            initializer=self.recurrent_initializer,\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-        if self.use_bias:\n-            self.bias = self.add_weight(shape=(self.units,),\n-                                        name='bias',\n-                                        initializer=self.bias_initializer,\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-        self.built = True\n-\n-    def call(self, inputs, states, training=None):\n-        prev_output = states[0]\n-        if 0 < self.dropout < 1 and self._dropout_mask is None:\n-            self._dropout_mask = _generate_dropout_mask(\n-                K.ones_like(inputs),\n-                self.dropout,\n-                training=training)\n-        if (0 < self.recurrent_dropout < 1 and\n-                self._recurrent_dropout_mask is None):\n-            self._recurrent_dropout_mask = _generate_dropout_mask(\n-                K.ones_like(prev_output),\n-                self.recurrent_dropout,\n-                training=training)\n-\n-        dp_mask = self._dropout_mask\n-        rec_dp_mask = self._recurrent_dropout_mask\n-\n-        if dp_mask is not None:\n-            h = K.dot(inputs * dp_mask, self.kernel)\n-        else:\n-            h = K.dot(inputs, self.kernel)\n-        if self.bias is not None:\n-            h = K.bias_add(h, self.bias)\n-\n-        if rec_dp_mask is not None:\n-            prev_output *= rec_dp_mask\n-        output = h + K.dot(prev_output, self.recurrent_kernel)\n-        if self.activation is not None:\n-            output = self.activation(output)\n-\n-        # Properly set learning phase on output tensor.\n-        if 0 < self.dropout + self.recurrent_dropout:\n-            if training is None:\n-                output._uses_learning_phase = True\n-        return output, [output]\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout}\n-        base_config = super(SimpleRNNCell, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class SimpleRNN(RNN):\n-    \"\"\"Fully-connected RNN where the output is to be fed back to input.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-    \"\"\"\n-\n-    @interfaces.legacy_recurrent_support\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 **kwargs):\n-        if 'implementation' in kwargs:\n-            kwargs.pop('implementation')\n-            warnings.warn('The `implementation` argument '\n-                          'in `SimpleRNN` has been deprecated. '\n-                          'Please remove it from your layer call.')\n-        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n-            warnings.warn(\n-                'RNN dropout is no longer supported with the Theano backend '\n-                'due to technical limitations. '\n-                'You can either set `dropout` and `recurrent_dropout` to 0, '\n-                'or use the TensorFlow backend.')\n-            dropout = 0.\n-            recurrent_dropout = 0.\n-\n-        cell = SimpleRNNCell(units,\n-                             activation=activation,\n-                             use_bias=use_bias,\n-                             kernel_initializer=kernel_initializer,\n-                             recurrent_initializer=recurrent_initializer,\n-                             bias_initializer=bias_initializer,\n-                             kernel_regularizer=kernel_regularizer,\n-                             recurrent_regularizer=recurrent_regularizer,\n-                             bias_regularizer=bias_regularizer,\n-                             kernel_constraint=kernel_constraint,\n-                             recurrent_constraint=recurrent_constraint,\n-                             bias_constraint=bias_constraint,\n-                             dropout=dropout,\n-                             recurrent_dropout=recurrent_dropout)\n-        super(SimpleRNN, self).__init__(cell,\n-                                        return_sequences=return_sequences,\n-                                        return_state=return_state,\n-                                        go_backwards=go_backwards,\n-                                        stateful=stateful,\n-                                        unroll=unroll,\n-                                        **kwargs)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._dropout_mask = None\n-        self.cell._recurrent_dropout_mask = None\n-        return super(SimpleRNN, self).call(inputs,\n-                                           mask=mask,\n-                                           training=training,\n-                                           initial_state=initial_state)\n-\n-    @property\n-    def units(self):\n-        return self.cell.units\n-\n-    @property\n-    def activation(self):\n-        return self.cell.activation\n-\n-    @property\n-    def use_bias(self):\n-        return self.cell.use_bias\n-\n-    @property\n-    def kernel_initializer(self):\n-        return self.cell.kernel_initializer\n-\n-    @property\n-    def recurrent_initializer(self):\n-        return self.cell.recurrent_initializer\n-\n-    @property\n-    def bias_initializer(self):\n-        return self.cell.bias_initializer\n-\n-    @property\n-    def kernel_regularizer(self):\n-        return self.cell.kernel_regularizer\n-\n-    @property\n-    def recurrent_regularizer(self):\n-        return self.cell.recurrent_regularizer\n-\n-    @property\n-    def bias_regularizer(self):\n-        return self.cell.bias_regularizer\n-\n-    @property\n-    def kernel_constraint(self):\n-        return self.cell.kernel_constraint\n-\n-    @property\n-    def recurrent_constraint(self):\n-        return self.cell.recurrent_constraint\n-\n-    @property\n-    def bias_constraint(self):\n-        return self.cell.bias_constraint\n-\n-    @property\n-    def dropout(self):\n-        return self.cell.dropout\n-\n-    @property\n-    def recurrent_dropout(self):\n-        return self.cell.recurrent_dropout\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout}\n-        base_config = super(SimpleRNN, self).get_config()\n-        del base_config['cell']\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        if 'implementation' in config:\n-            config.pop('implementation')\n-        return cls(**config)\n-\n-\n-class GRUCell(Layer):\n-    \"\"\"Cell class for the GRU layer.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-            Default: sigmoid (`sigmoid`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-        implementation: Implementation mode, either 1 or 2.\n-            Mode 1 will structure its operations as a larger number of\n-            smaller dot products and additions, whereas mode 2 will\n-            batch them into fewer, larger operations. These modes will\n-            have different performance profiles on different hardware and\n-            for different applications.\n-        reset_after: GRU convention (whether to apply reset gate after or\n-            before matrix multiplication). False = \"before\" (default),\n-            True = \"after\" (CuDNN compatible).\n-    \"\"\"\n-\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 recurrent_activation='sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 implementation=2,\n-                 reset_after=False,\n-                 **kwargs):\n-        super(GRUCell, self).__init__(**kwargs)\n-        self.units = units\n-        self.activation = activations.get(activation)\n-        self.recurrent_activation = activations.get(recurrent_activation)\n-        self.use_bias = use_bias\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-        self.dropout = min(1., max(0., dropout))\n-        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n-        self.implementation = implementation\n-        self.reset_after = reset_after\n-        self.state_size = self.units\n-        self.output_size = self.units\n-        self._dropout_mask = None\n-        self._recurrent_dropout_mask = None\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[-1]\n-\n-        if isinstance(self.recurrent_initializer, initializers.Identity):\n-            def recurrent_identity(shape, gain=1., dtype=None):\n-                del dtype\n-                return gain * np.concatenate(\n-                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n-\n-            self.recurrent_initializer = recurrent_identity\n-\n-        self.kernel = self.add_weight(shape=(input_dim, self.units * 3),\n-                                      name='kernel',\n-                                      initializer=self.kernel_initializer,\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units * 3),\n-            name='recurrent_kernel',\n-            initializer=self.recurrent_initializer,\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-\n-        if self.use_bias:\n-            if not self.reset_after:\n-                bias_shape = (3 * self.units,)\n-            else:\n-                # separate biases for input and recurrent kernels\n-                # Note: the shape is intentionally different from CuDNNGRU biases\n-                # `(2 * 3 * self.units,)`, so that we can distinguish the classes\n-                # when loading and converting saved weights.\n-                bias_shape = (2, 3 * self.units)\n-            self.bias = self.add_weight(shape=bias_shape,\n-                                        name='bias',\n-                                        initializer=self.bias_initializer,\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-            if not self.reset_after:\n-                self.input_bias, self.recurrent_bias = self.bias, None\n-            else:\n-                # NOTE: need to flatten, since slicing in CNTK gives 2D array\n-                self.input_bias = K.flatten(self.bias[0])\n-                self.recurrent_bias = K.flatten(self.bias[1])\n-        else:\n-            self.bias = None\n-\n-        # update gate\n-        self.kernel_z = self.kernel[:, :self.units]\n-        self.recurrent_kernel_z = self.recurrent_kernel[:, :self.units]\n-        # reset gate\n-        self.kernel_r = self.kernel[:, self.units: self.units * 2]\n-        self.recurrent_kernel_r = self.recurrent_kernel[:,\n-                                                        self.units:\n-                                                        self.units * 2]\n-        # new gate\n-        self.kernel_h = self.kernel[:, self.units * 2:]\n-        self.recurrent_kernel_h = self.recurrent_kernel[:, self.units * 2:]\n-\n-        if self.use_bias:\n-            # bias for inputs\n-            self.input_bias_z = self.input_bias[:self.units]\n-            self.input_bias_r = self.input_bias[self.units: self.units * 2]\n-            self.input_bias_h = self.input_bias[self.units * 2:]\n-            # bias for hidden state - just for compatibility with CuDNN\n-            if self.reset_after:\n-                self.recurrent_bias_z = self.recurrent_bias[:self.units]\n-                self.recurrent_bias_r = (\n-                    self.recurrent_bias[self.units: self.units * 2])\n-                self.recurrent_bias_h = self.recurrent_bias[self.units * 2:]\n-        else:\n-            self.input_bias_z = None\n-            self.input_bias_r = None\n-            self.input_bias_h = None\n-            if self.reset_after:\n-                self.recurrent_bias_z = None\n-                self.recurrent_bias_r = None\n-                self.recurrent_bias_h = None\n-        self.built = True\n-\n-    def call(self, inputs, states, training=None):\n-        h_tm1 = states[0]  # previous memory\n-\n-        if 0 < self.dropout < 1 and self._dropout_mask is None:\n-            self._dropout_mask = _generate_dropout_mask(\n-                K.ones_like(inputs),\n-                self.dropout,\n-                training=training,\n-                count=3)\n-        if (0 < self.recurrent_dropout < 1 and\n-                self._recurrent_dropout_mask is None):\n-            self._recurrent_dropout_mask = _generate_dropout_mask(\n-                K.ones_like(h_tm1),\n-                self.recurrent_dropout,\n-                training=training,\n-                count=3)\n-\n-        # dropout matrices for input units\n-        dp_mask = self._dropout_mask\n-        # dropout matrices for recurrent units\n-        rec_dp_mask = self._recurrent_dropout_mask\n-\n-        if self.implementation == 1:\n-            if 0. < self.dropout < 1.:\n-                inputs_z = inputs * dp_mask[0]\n-                inputs_r = inputs * dp_mask[1]\n-                inputs_h = inputs * dp_mask[2]\n-            else:\n-                inputs_z = inputs\n-                inputs_r = inputs\n-                inputs_h = inputs\n-\n-            x_z = K.dot(inputs_z, self.kernel_z)\n-            x_r = K.dot(inputs_r, self.kernel_r)\n-            x_h = K.dot(inputs_h, self.kernel_h)\n-            if self.use_bias:\n-                x_z = K.bias_add(x_z, self.input_bias_z)\n-                x_r = K.bias_add(x_r, self.input_bias_r)\n-                x_h = K.bias_add(x_h, self.input_bias_h)\n-\n-            if 0. < self.recurrent_dropout < 1.:\n-                h_tm1_z = h_tm1 * rec_dp_mask[0]\n-                h_tm1_r = h_tm1 * rec_dp_mask[1]\n-                h_tm1_h = h_tm1 * rec_dp_mask[2]\n-            else:\n-                h_tm1_z = h_tm1\n-                h_tm1_r = h_tm1\n-                h_tm1_h = h_tm1\n-\n-            recurrent_z = K.dot(h_tm1_z, self.recurrent_kernel_z)\n-            recurrent_r = K.dot(h_tm1_r, self.recurrent_kernel_r)\n-            if self.reset_after and self.use_bias:\n-                recurrent_z = K.bias_add(recurrent_z, self.recurrent_bias_z)\n-                recurrent_r = K.bias_add(recurrent_r, self.recurrent_bias_r)\n-\n-            z = self.recurrent_activation(x_z + recurrent_z)\n-            r = self.recurrent_activation(x_r + recurrent_r)\n-\n-            # reset gate applied after/before matrix multiplication\n-            if self.reset_after:\n-                recurrent_h = K.dot(h_tm1_h, self.recurrent_kernel_h)\n-                if self.use_bias:\n-                    recurrent_h = K.bias_add(recurrent_h, self.recurrent_bias_h)\n-                recurrent_h = r * recurrent_h\n-            else:\n-                recurrent_h = K.dot(r * h_tm1_h, self.recurrent_kernel_h)\n-\n-            hh = self.activation(x_h + recurrent_h)\n-        else:\n-            if 0. < self.dropout < 1.:\n-                inputs *= dp_mask[0]\n-\n-            # inputs projected by all gate matrices at once\n-            matrix_x = K.dot(inputs, self.kernel)\n-            if self.use_bias:\n-                # biases: bias_z_i, bias_r_i, bias_h_i\n-                matrix_x = K.bias_add(matrix_x, self.input_bias)\n-            x_z = matrix_x[:, :self.units]\n-            x_r = matrix_x[:, self.units: 2 * self.units]\n-            x_h = matrix_x[:, 2 * self.units:]\n-\n-            if 0. < self.recurrent_dropout < 1.:\n-                h_tm1 *= rec_dp_mask[0]\n-\n-            if self.reset_after:\n-                # hidden state projected by all gate matrices at once\n-                matrix_inner = K.dot(h_tm1, self.recurrent_kernel)\n-                if self.use_bias:\n-                    matrix_inner = K.bias_add(matrix_inner, self.recurrent_bias)\n-            else:\n-                # hidden state projected separately for update/reset and new\n-                matrix_inner = K.dot(h_tm1,\n-                                     self.recurrent_kernel[:, :2 * self.units])\n-\n-            recurrent_z = matrix_inner[:, :self.units]\n-            recurrent_r = matrix_inner[:, self.units: 2 * self.units]\n-\n-            z = self.recurrent_activation(x_z + recurrent_z)\n-            r = self.recurrent_activation(x_r + recurrent_r)\n-\n-            if self.reset_after:\n-                recurrent_h = r * matrix_inner[:, 2 * self.units:]\n-            else:\n-                recurrent_h = K.dot(r * h_tm1,\n-                                    self.recurrent_kernel[:, 2 * self.units:])\n-\n-            hh = self.activation(x_h + recurrent_h)\n-\n-        # previous and candidate state mixed by update gate\n-        h = z * h_tm1 + (1 - z) * hh\n-\n-        if 0 < self.dropout + self.recurrent_dropout:\n-            if training is None:\n-                h._uses_learning_phase = True\n-\n-        return h, [h]\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout,\n-                  'implementation': self.implementation,\n-                  'reset_after': self.reset_after}\n-        base_config = super(GRUCell, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class GRU(RNN):\n-    \"\"\"Gated Recurrent Unit - Cho et al. 2014.\n-\n-    There are two variants. The default one is based on 1406.1078v3 and\n-    has reset gate applied to hidden state before matrix multiplication. The\n-    other one is based on original 1406.1078v1 and has the order reversed.\n-\n-    The second variant is compatible with CuDNNGRU (GPU-only) and allows\n-    inference on CPU. Thus it has separate biases for `kernel` and\n-    `recurrent_kernel`. Use `'reset_after'=True` and\n-    `recurrent_activation='sigmoid'`.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-            Default: sigmoid (`sigmoid`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-        implementation: Implementation mode, either 1 or 2.\n-            Mode 1 will structure its operations as a larger number of\n-            smaller dot products and additions, whereas mode 2 will\n-            batch them into fewer, larger operations. These modes will\n-            have different performance profiles on different hardware and\n-            for different applications.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-        reset_after: GRU convention (whether to apply reset gate after or\n-            before matrix multiplication). False = \"before\" (default),\n-            True = \"after\" (CuDNN compatible).\n-\n-    # References\n-        - [Learning Phrase Representations using RNN Encoder-Decoder for\n-           Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n-        - [On the Properties of Neural Machine Translation:\n-           Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)\n-        - [Empirical Evaluation of Gated Recurrent Neural Networks on\n-           Sequence Modeling](https://arxiv.org/abs/1412.3555v1)\n-        - [A Theoretically Grounded Application of Dropout in\n-           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n-    \"\"\"\n-\n-    @interfaces.legacy_recurrent_support\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 recurrent_activation='sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 implementation=2,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 reset_after=False,\n-                 **kwargs):\n-        if implementation == 0:\n-            warnings.warn('`implementation=0` has been deprecated, '\n-                          'and now defaults to `implementation=1`.'\n-                          'Please update your layer call.')\n-        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n-            warnings.warn(\n-                'RNN dropout is no longer supported with the Theano backend '\n-                'due to technical limitations. '\n-                'You can either set `dropout` and `recurrent_dropout` to 0, '\n-                'or use the TensorFlow backend.')\n-            dropout = 0.\n-            recurrent_dropout = 0.\n-\n-        cell = GRUCell(units,\n-                       activation=activation,\n-                       recurrent_activation=recurrent_activation,\n-                       use_bias=use_bias,\n-                       kernel_initializer=kernel_initializer,\n-                       recurrent_initializer=recurrent_initializer,\n-                       bias_initializer=bias_initializer,\n-                       kernel_regularizer=kernel_regularizer,\n-                       recurrent_regularizer=recurrent_regularizer,\n-                       bias_regularizer=bias_regularizer,\n-                       kernel_constraint=kernel_constraint,\n-                       recurrent_constraint=recurrent_constraint,\n-                       bias_constraint=bias_constraint,\n-                       dropout=dropout,\n-                       recurrent_dropout=recurrent_dropout,\n-                       implementation=implementation,\n-                       reset_after=reset_after)\n-        super(GRU, self).__init__(cell,\n-                                  return_sequences=return_sequences,\n-                                  return_state=return_state,\n-                                  go_backwards=go_backwards,\n-                                  stateful=stateful,\n-                                  unroll=unroll,\n-                                  **kwargs)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._dropout_mask = None\n-        self.cell._recurrent_dropout_mask = None\n-        return super(GRU, self).call(inputs,\n-                                     mask=mask,\n-                                     training=training,\n-                                     initial_state=initial_state)\n-\n-    @property\n-    def units(self):\n-        return self.cell.units\n-\n-    @property\n-    def activation(self):\n-        return self.cell.activation\n-\n-    @property\n-    def recurrent_activation(self):\n-        return self.cell.recurrent_activation\n-\n-    @property\n-    def use_bias(self):\n-        return self.cell.use_bias\n-\n-    @property\n-    def kernel_initializer(self):\n-        return self.cell.kernel_initializer\n-\n-    @property\n-    def recurrent_initializer(self):\n-        return self.cell.recurrent_initializer\n-\n-    @property\n-    def bias_initializer(self):\n-        return self.cell.bias_initializer\n-\n-    @property\n-    def kernel_regularizer(self):\n-        return self.cell.kernel_regularizer\n-\n-    @property\n-    def recurrent_regularizer(self):\n-        return self.cell.recurrent_regularizer\n-\n-    @property\n-    def bias_regularizer(self):\n-        return self.cell.bias_regularizer\n-\n-    @property\n-    def kernel_constraint(self):\n-        return self.cell.kernel_constraint\n-\n-    @property\n-    def recurrent_constraint(self):\n-        return self.cell.recurrent_constraint\n-\n-    @property\n-    def bias_constraint(self):\n-        return self.cell.bias_constraint\n-\n-    @property\n-    def dropout(self):\n-        return self.cell.dropout\n-\n-    @property\n-    def recurrent_dropout(self):\n-        return self.cell.recurrent_dropout\n-\n-    @property\n-    def implementation(self):\n-        return self.cell.implementation\n-\n-    @property\n-    def reset_after(self):\n-        return self.cell.reset_after\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout,\n-                  'implementation': self.implementation,\n-                  'reset_after': self.reset_after}\n-        base_config = super(GRU, self).get_config()\n-        del base_config['cell']\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        if 'implementation' in config and config['implementation'] == 0:\n-            config['implementation'] = 1\n-        return cls(**config)\n-\n-\n-class LSTMCell(Layer):\n-    \"\"\"Cell class for the LSTM layer.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-            Default: sigmoid (`sigmoid`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).x\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        unit_forget_bias: Boolean.\n-            If True, add 1 to the bias of the forget gate at initialization.\n-            Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al. (2015)](\n-            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-        implementation: Implementation mode, either 1 or 2.\n-            Mode 1 will structure its operations as a larger number of\n-            smaller dot products and additions, whereas mode 2 will\n-            batch them into fewer, larger operations. These modes will\n-            have different performance profiles on different hardware and\n-            for different applications.\n-    \"\"\"\n-\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 recurrent_activation='sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 unit_forget_bias=True,\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 implementation=2,\n-                 **kwargs):\n-        super(LSTMCell, self).__init__(**kwargs)\n-        self.units = units\n-        self.activation = activations.get(activation)\n-        self.recurrent_activation = activations.get(recurrent_activation)\n-        self.use_bias = use_bias\n-\n-        self.kernel_initializer = initializers.get(kernel_initializer)\n-        self.recurrent_initializer = initializers.get(recurrent_initializer)\n-        self.bias_initializer = initializers.get(bias_initializer)\n-        self.unit_forget_bias = unit_forget_bias\n-\n-        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n-        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n-        self.bias_regularizer = regularizers.get(bias_regularizer)\n-\n-        self.kernel_constraint = constraints.get(kernel_constraint)\n-        self.recurrent_constraint = constraints.get(recurrent_constraint)\n-        self.bias_constraint = constraints.get(bias_constraint)\n-\n-        self.dropout = min(1., max(0., dropout))\n-        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n-        self.implementation = implementation\n-        self.state_size = (self.units, self.units)\n-        self.output_size = self.units\n-        self._dropout_mask = None\n-        self._recurrent_dropout_mask = None\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[-1]\n-\n-        if type(self.recurrent_initializer).__name__ == 'Identity':\n-            def recurrent_identity(shape, gain=1., dtype=None):\n-                del dtype\n-                return gain * np.concatenate(\n-                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n-\n-            self.recurrent_initializer = recurrent_identity\n-\n-        self.kernel = self.add_weight(shape=(input_dim, self.units * 4),\n-                                      name='kernel',\n-                                      initializer=self.kernel_initializer,\n-                                      regularizer=self.kernel_regularizer,\n-                                      constraint=self.kernel_constraint)\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units * 4),\n-            name='recurrent_kernel',\n-            initializer=self.recurrent_initializer,\n-            regularizer=self.recurrent_regularizer,\n-            constraint=self.recurrent_constraint)\n-\n-        if self.use_bias:\n-            if self.unit_forget_bias:\n-                @K.eager\n-                def bias_initializer(_, *args, **kwargs):\n-                    return K.concatenate([\n-                        self.bias_initializer((self.units,), *args, **kwargs),\n-                        initializers.Ones()((self.units,), *args, **kwargs),\n-                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n-                    ])\n-            else:\n-                bias_initializer = self.bias_initializer\n-            self.bias = self.add_weight(shape=(self.units * 4,),\n-                                        name='bias',\n-                                        initializer=bias_initializer,\n-                                        regularizer=self.bias_regularizer,\n-                                        constraint=self.bias_constraint)\n-        else:\n-            self.bias = None\n-\n-        self.kernel_i = self.kernel[:, :self.units]\n-        self.kernel_f = self.kernel[:, self.units: self.units * 2]\n-        self.kernel_c = self.kernel[:, self.units * 2: self.units * 3]\n-        self.kernel_o = self.kernel[:, self.units * 3:]\n-\n-        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n-        self.recurrent_kernel_f = (\n-            self.recurrent_kernel[:, self.units: self.units * 2])\n-        self.recurrent_kernel_c = (\n-            self.recurrent_kernel[:, self.units * 2: self.units * 3])\n-        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n-\n-        if self.use_bias:\n-            self.bias_i = self.bias[:self.units]\n-            self.bias_f = self.bias[self.units: self.units * 2]\n-            self.bias_c = self.bias[self.units * 2: self.units * 3]\n-            self.bias_o = self.bias[self.units * 3:]\n-        else:\n-            self.bias_i = None\n-            self.bias_f = None\n-            self.bias_c = None\n-            self.bias_o = None\n-        self.built = True\n-\n-    def call(self, inputs, states, training=None):\n-        if 0 < self.dropout < 1 and self._dropout_mask is None:\n-            self._dropout_mask = _generate_dropout_mask(\n-                K.ones_like(inputs),\n-                self.dropout,\n-                training=training,\n-                count=4)\n-        if (0 < self.recurrent_dropout < 1 and\n-                self._recurrent_dropout_mask is None):\n-            self._recurrent_dropout_mask = _generate_dropout_mask(\n-                K.ones_like(states[0]),\n-                self.recurrent_dropout,\n-                training=training,\n-                count=4)\n-\n-        # dropout matrices for input units\n-        dp_mask = self._dropout_mask\n-        # dropout matrices for recurrent units\n-        rec_dp_mask = self._recurrent_dropout_mask\n-\n-        h_tm1 = states[0]  # previous memory state\n-        c_tm1 = states[1]  # previous carry state\n-\n-        if self.implementation == 1:\n-            if 0 < self.dropout < 1.:\n-                inputs_i = inputs * dp_mask[0]\n-                inputs_f = inputs * dp_mask[1]\n-                inputs_c = inputs * dp_mask[2]\n-                inputs_o = inputs * dp_mask[3]\n-            else:\n-                inputs_i = inputs\n-                inputs_f = inputs\n-                inputs_c = inputs\n-                inputs_o = inputs\n-            x_i = K.dot(inputs_i, self.kernel_i)\n-            x_f = K.dot(inputs_f, self.kernel_f)\n-            x_c = K.dot(inputs_c, self.kernel_c)\n-            x_o = K.dot(inputs_o, self.kernel_o)\n-            if self.use_bias:\n-                x_i = K.bias_add(x_i, self.bias_i)\n-                x_f = K.bias_add(x_f, self.bias_f)\n-                x_c = K.bias_add(x_c, self.bias_c)\n-                x_o = K.bias_add(x_o, self.bias_o)\n-\n-            if 0 < self.recurrent_dropout < 1.:\n-                h_tm1_i = h_tm1 * rec_dp_mask[0]\n-                h_tm1_f = h_tm1 * rec_dp_mask[1]\n-                h_tm1_c = h_tm1 * rec_dp_mask[2]\n-                h_tm1_o = h_tm1 * rec_dp_mask[3]\n-            else:\n-                h_tm1_i = h_tm1\n-                h_tm1_f = h_tm1\n-                h_tm1_c = h_tm1\n-                h_tm1_o = h_tm1\n-            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n-                                                      self.recurrent_kernel_i))\n-            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n-                                                      self.recurrent_kernel_f))\n-            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n-                                                            self.recurrent_kernel_c))\n-            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n-                                                      self.recurrent_kernel_o))\n-        else:\n-            if 0. < self.dropout < 1.:\n-                inputs *= dp_mask[0]\n-            z = K.dot(inputs, self.kernel)\n-            if 0. < self.recurrent_dropout < 1.:\n-                h_tm1 *= rec_dp_mask[0]\n-            z += K.dot(h_tm1, self.recurrent_kernel)\n-            if self.use_bias:\n-                z = K.bias_add(z, self.bias)\n-\n-            z0 = z[:, :self.units]\n-            z1 = z[:, self.units: 2 * self.units]\n-            z2 = z[:, 2 * self.units: 3 * self.units]\n-            z3 = z[:, 3 * self.units:]\n-\n-            i = self.recurrent_activation(z0)\n-            f = self.recurrent_activation(z1)\n-            c = f * c_tm1 + i * self.activation(z2)\n-            o = self.recurrent_activation(z3)\n-\n-        h = o * self.activation(c)\n-        if 0 < self.dropout + self.recurrent_dropout:\n-            if training is None:\n-                h._uses_learning_phase = True\n-        return h, [h, c]\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'unit_forget_bias': self.unit_forget_bias,\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout,\n-                  'implementation': self.implementation}\n-        base_config = super(LSTMCell, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class LSTM(RNN):\n-    \"\"\"Long Short-Term Memory layer - Hochreiter 1997.\n-\n-    # Arguments\n-        units: Positive integer, dimensionality of the output space.\n-        activation: Activation function to use\n-            (see [activations](../activations.md)).\n-            Default: hyperbolic tangent (`tanh`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        recurrent_activation: Activation function to use\n-            for the recurrent step\n-            (see [activations](../activations.md)).\n-            Default: sigmoid (`sigmoid`).\n-            If you pass `None`, no activation is applied\n-            (ie. \"linear\" activation: `a(x) = x`).\n-        use_bias: Boolean, whether the layer uses a bias vector.\n-        kernel_initializer: Initializer for the `kernel` weights matrix,\n-            used for the linear transformation of the inputs.\n-            (see [initializers](../initializers.md)).\n-        recurrent_initializer: Initializer for the `recurrent_kernel`\n-            weights matrix,\n-            used for the linear transformation of the recurrent state.\n-            (see [initializers](../initializers.md)).\n-        bias_initializer: Initializer for the bias vector\n-            (see [initializers](../initializers.md)).\n-        unit_forget_bias: Boolean.\n-            If True, add 1 to the bias of the forget gate at initialization.\n-            Setting it to true will also force `bias_initializer=\"zeros\"`.\n-            This is recommended in [Jozefowicz et al. (2015)](\n-            http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).\n-        kernel_regularizer: Regularizer function applied to\n-            the `kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        recurrent_regularizer: Regularizer function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [regularizer](../regularizers.md)).\n-        bias_regularizer: Regularizer function applied to the bias vector\n-            (see [regularizer](../regularizers.md)).\n-        activity_regularizer: Regularizer function applied to\n-            the output of the layer (its \"activation\").\n-            (see [regularizer](../regularizers.md)).\n-        kernel_constraint: Constraint function applied to\n-            the `kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        recurrent_constraint: Constraint function applied to\n-            the `recurrent_kernel` weights matrix\n-            (see [constraints](../constraints.md)).\n-        bias_constraint: Constraint function applied to the bias vector\n-            (see [constraints](../constraints.md)).\n-        dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the inputs.\n-        recurrent_dropout: Float between 0 and 1.\n-            Fraction of the units to drop for\n-            the linear transformation of the recurrent state.\n-        implementation: Implementation mode, either 1 or 2.\n-            Mode 1 will structure its operations as a larger number of\n-            smaller dot products and additions, whereas mode 2 will\n-            batch them into fewer, larger operations. These modes will\n-            have different performance profiles on different hardware and\n-            for different applications.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output. The returned elements of the\n-            states list are the hidden state and the cell state, respectively.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-\n-    # References\n-        - [Long short-term memory](\n-          http://www.bioinf.jku.at/publications/older/2604.pdf)\n-        - [Learning to forget: Continual prediction with LSTM](\n-          http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n-        - [Supervised sequence labeling with recurrent neural networks](\n-          http://www.cs.toronto.edu/~graves/preprint.pdf)\n-        - [A Theoretically Grounded Application of Dropout in\n-           Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n-    \"\"\"\n-\n-    @interfaces.legacy_recurrent_support\n-    def __init__(self, units,\n-                 activation='tanh',\n-                 recurrent_activation='sigmoid',\n-                 use_bias=True,\n-                 kernel_initializer='glorot_uniform',\n-                 recurrent_initializer='orthogonal',\n-                 bias_initializer='zeros',\n-                 unit_forget_bias=True,\n-                 kernel_regularizer=None,\n-                 recurrent_regularizer=None,\n-                 bias_regularizer=None,\n-                 activity_regularizer=None,\n-                 kernel_constraint=None,\n-                 recurrent_constraint=None,\n-                 bias_constraint=None,\n-                 dropout=0.,\n-                 recurrent_dropout=0.,\n-                 implementation=2,\n-                 return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 **kwargs):\n-        if implementation == 0:\n-            warnings.warn('`implementation=0` has been deprecated, '\n-                          'and now defaults to `implementation=1`.'\n-                          'Please update your layer call.')\n-        if K.backend() == 'theano' and (dropout or recurrent_dropout):\n-            warnings.warn(\n-                'RNN dropout is no longer supported with the Theano backend '\n-                'due to technical limitations. '\n-                'You can either set `dropout` and `recurrent_dropout` to 0, '\n-                'or use the TensorFlow backend.')\n-            dropout = 0.\n-            recurrent_dropout = 0.\n-\n-        cell = LSTMCell(units,\n-                        activation=activation,\n-                        recurrent_activation=recurrent_activation,\n-                        use_bias=use_bias,\n-                        kernel_initializer=kernel_initializer,\n-                        recurrent_initializer=recurrent_initializer,\n-                        unit_forget_bias=unit_forget_bias,\n-                        bias_initializer=bias_initializer,\n-                        kernel_regularizer=kernel_regularizer,\n-                        recurrent_regularizer=recurrent_regularizer,\n-                        bias_regularizer=bias_regularizer,\n-                        kernel_constraint=kernel_constraint,\n-                        recurrent_constraint=recurrent_constraint,\n-                        bias_constraint=bias_constraint,\n-                        dropout=dropout,\n-                        recurrent_dropout=recurrent_dropout,\n-                        implementation=implementation)\n-        super(LSTM, self).__init__(cell,\n-                                   return_sequences=return_sequences,\n-                                   return_state=return_state,\n-                                   go_backwards=go_backwards,\n-                                   stateful=stateful,\n-                                   unroll=unroll,\n-                                   **kwargs)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        self.cell._dropout_mask = None\n-        self.cell._recurrent_dropout_mask = None\n-        return super(LSTM, self).call(inputs,\n-                                      mask=mask,\n-                                      training=training,\n-                                      initial_state=initial_state)\n-\n-    @property\n-    def units(self):\n-        return self.cell.units\n-\n-    @property\n-    def activation(self):\n-        return self.cell.activation\n-\n-    @property\n-    def recurrent_activation(self):\n-        return self.cell.recurrent_activation\n-\n-    @property\n-    def use_bias(self):\n-        return self.cell.use_bias\n-\n-    @property\n-    def kernel_initializer(self):\n-        return self.cell.kernel_initializer\n-\n-    @property\n-    def recurrent_initializer(self):\n-        return self.cell.recurrent_initializer\n-\n-    @property\n-    def bias_initializer(self):\n-        return self.cell.bias_initializer\n-\n-    @property\n-    def unit_forget_bias(self):\n-        return self.cell.unit_forget_bias\n-\n-    @property\n-    def kernel_regularizer(self):\n-        return self.cell.kernel_regularizer\n-\n-    @property\n-    def recurrent_regularizer(self):\n-        return self.cell.recurrent_regularizer\n-\n-    @property\n-    def bias_regularizer(self):\n-        return self.cell.bias_regularizer\n-\n-    @property\n-    def kernel_constraint(self):\n-        return self.cell.kernel_constraint\n-\n-    @property\n-    def recurrent_constraint(self):\n-        return self.cell.recurrent_constraint\n-\n-    @property\n-    def bias_constraint(self):\n-        return self.cell.bias_constraint\n-\n-    @property\n-    def dropout(self):\n-        return self.cell.dropout\n-\n-    @property\n-    def recurrent_dropout(self):\n-        return self.cell.recurrent_dropout\n-\n-    @property\n-    def implementation(self):\n-        return self.cell.implementation\n-\n-    def get_config(self):\n-        config = {'units': self.units,\n-                  'activation': activations.serialize(self.activation),\n-                  'recurrent_activation':\n-                      activations.serialize(self.recurrent_activation),\n-                  'use_bias': self.use_bias,\n-                  'kernel_initializer':\n-                      initializers.serialize(self.kernel_initializer),\n-                  'recurrent_initializer':\n-                      initializers.serialize(self.recurrent_initializer),\n-                  'bias_initializer': initializers.serialize(self.bias_initializer),\n-                  'unit_forget_bias': self.unit_forget_bias,\n-                  'kernel_regularizer':\n-                      regularizers.serialize(self.kernel_regularizer),\n-                  'recurrent_regularizer':\n-                      regularizers.serialize(self.recurrent_regularizer),\n-                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n-                  'recurrent_constraint':\n-                      constraints.serialize(self.recurrent_constraint),\n-                  'bias_constraint': constraints.serialize(self.bias_constraint),\n-                  'dropout': self.dropout,\n-                  'recurrent_dropout': self.recurrent_dropout,\n-                  'implementation': self.implementation}\n-        base_config = super(LSTM, self).get_config()\n-        del base_config['cell']\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        if 'implementation' in config and config['implementation'] == 0:\n-            config['implementation'] = 1\n-        return cls(**config)\n-\n-\n-def _generate_dropout_mask(ones, rate, training=None, count=1):\n-    def dropped_inputs():\n-        return K.dropout(ones, rate)\n-\n-    if count > 1:\n-        return [K.in_train_phase(\n-            dropped_inputs,\n-            ones,\n-            training=training) for _ in range(count)]\n-    return K.in_train_phase(\n-        dropped_inputs,\n-        ones,\n-        training=training)\n-\n-\n-def _standardize_args(inputs, initial_state, constants, num_constants):\n-    \"\"\"Standardize `__call__` to a single list of tensor inputs.\n-\n-    When running a model loaded from file, the input tensors\n-    `initial_state` and `constants` can be passed to `RNN.__call__` as part\n-    of `inputs` instead of by the dedicated keyword arguments. This method\n-    makes sure the arguments are separated and that `initial_state` and\n-    `constants` are lists of tensors (or None).\n-\n-    # Arguments\n-        inputs: tensor or list/tuple of tensors\n-        initial_state: tensor or list of tensors or None\n-        constants: tensor or list of tensors or None\n-\n-    # Returns\n-        inputs: tensor\n-        initial_state: list of tensors or None\n-        constants: list of tensors or None\n-    \"\"\"\n-    if isinstance(inputs, list):\n-        assert initial_state is None and constants is None\n-        if num_constants is not None:\n-            constants = inputs[-num_constants:]\n-            inputs = inputs[:-num_constants]\n-        if len(inputs) > 1:\n-            initial_state = inputs[1:]\n-        inputs = inputs[0]\n-\n-    def to_list_or_none(x):\n-        if x is None or isinstance(x, list):\n-            return x\n-        if isinstance(x, tuple):\n-            return list(x)\n-        return [x]\n-\n-    initial_state = to_list_or_none(initial_state)\n-    constants = to_list_or_none(constants)\n-\n-    return inputs, initial_state, constants\n+from tensorflow.keras.layers import SimpleRNNCell\n+from tensorflow.keras.layers import GRUCell\n+from tensorflow.keras.layers import LSTMCell\n\n@@ -1,668 +1,5 @@\n-# -*- coding: utf-8 -*-\n-\"\"\"Layers that augment the functionality of a base layer.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Layers that augment the functionality of a base layer.\"\"\"\n \n-import copy\n-from ..engine.base_layer import Layer\n-from ..engine.base_layer import disable_tracking\n-from ..engine.base_layer import InputSpec\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import object_list_uid\n-from .. import backend as K\n-\n-from . import recurrent\n-\n-\n-class Wrapper(Layer):\n-    \"\"\"Abstract wrapper base class.\n-\n-    Wrappers take another layer and augment it in various ways.\n-    Do not use this class as a layer, it is only an abstract base class.\n-    Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n-\n-    # Arguments\n-        layer: The layer to be wrapped.\n-    \"\"\"\n-\n-    @disable_tracking\n-    def __init__(self, layer, **kwargs):\n-        self.layer = layer\n-        # Tracks mapping of Wrapper inputs to inner layer inputs. Useful when\n-        # the inner layer has update ops that depend on its inputs (as opposed\n-        # to the inputs to the Wrapper layer).\n-        self._input_map = {}\n-        super(Wrapper, self).__init__(**kwargs)\n-\n-    def build(self, input_shape=None):\n-        self.built = True\n-\n-    @property\n-    def activity_regularizer(self):\n-        if hasattr(self.layer, 'activity_regularizer'):\n-            return self.layer.activity_regularizer\n-        else:\n-            return None\n-\n-    @property\n-    def trainable(self):\n-        return self.layer.trainable\n-\n-    @trainable.setter\n-    def trainable(self, value):\n-        self.layer.trainable = value\n-\n-    @property\n-    def trainable_weights(self):\n-        return self.layer.trainable_weights\n-\n-    @property\n-    def non_trainable_weights(self):\n-        return self.layer.non_trainable_weights\n-\n-    @property\n-    def updates(self):\n-        if hasattr(self.layer, 'updates'):\n-            return self.layer.updates\n-        return []\n-\n-    def get_updates_for(self, inputs=None):\n-        # If the wrapper modifies the inputs, use the modified inputs to\n-        # get the updates from the inner layer.\n-        inner_inputs = inputs\n-        if inputs is not None:\n-            uid = object_list_uid(inputs)\n-            if uid in self._input_map:\n-                inner_inputs = self._input_map[uid]\n-\n-        updates = self.layer.get_updates_for(inner_inputs)\n-        updates += super(Wrapper, self).get_updates_for(inputs)\n-        return updates\n-\n-    @property\n-    def losses(self):\n-        if hasattr(self.layer, 'losses'):\n-            return self.layer.losses\n-        return []\n-\n-    def get_losses_for(self, inputs=None):\n-        if inputs is None:\n-            losses = self.layer.get_losses_for(None)\n-            return losses + super(Wrapper, self).get_losses_for(None)\n-        return super(Wrapper, self).get_losses_for(inputs)\n-\n-    def get_weights(self):\n-        return self.layer.get_weights()\n-\n-    def set_weights(self, weights):\n-        self.layer.set_weights(weights)\n-\n-    def get_config(self):\n-        config = {'layer': {'class_name': self.layer.__class__.__name__,\n-                            'config': self.layer.get_config()}}\n-        base_config = super(Wrapper, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        from . import deserialize as deserialize_layer\n-        layer = deserialize_layer(config.pop('layer'),\n-                                  custom_objects=custom_objects)\n-        return cls(layer, **config)\n-\n-\n-class TimeDistributed(Wrapper):\n-    \"\"\"This wrapper applies a layer to every temporal slice of an input.\n-\n-    The input should be at least 3D, and the dimension of index one\n-    will be considered to be the temporal dimension.\n-\n-    Consider a batch of 32 samples,\n-    where each sample is a sequence of 10 vectors of 16 dimensions.\n-    The batch input shape of the layer is then `(32, 10, 16)`,\n-    and the `input_shape`, not including the samples dimension, is `(10, 16)`.\n-\n-    You can then use `TimeDistributed` to apply a `Dense` layer\n-    to each of the 10 timesteps, independently:\n-\n-    ```python\n-        # as the first layer in a model\n-        model = Sequential()\n-        model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))\n-        # now model.output_shape == (None, 10, 8)\n-    ```\n-\n-    The output will then have shape `(32, 10, 8)`.\n-\n-    In subsequent layers, there is no need for the `input_shape`:\n-\n-    ```python\n-        model.add(TimeDistributed(Dense(32)))\n-        # now model.output_shape == (None, 10, 32)\n-    ```\n-\n-    The output will then have shape `(32, 10, 32)`.\n-\n-    `TimeDistributed` can be used with arbitrary layers, not just `Dense`,\n-    for instance with a `Conv2D` layer:\n-\n-    ```python\n-        model = Sequential()\n-        model.add(TimeDistributed(Conv2D(64, (3, 3)),\n-                                  input_shape=(10, 299, 299, 3)))\n-    ```\n-\n-    # Arguments\n-        layer: a layer instance.\n-    \"\"\"\n-\n-    def __init__(self, layer, **kwargs):\n-        super(TimeDistributed, self).__init__(layer, **kwargs)\n-        self.supports_masking = True\n-\n-    def _get_shape_tuple(self, init_tuple, tensor, start_idx, int_shape=None):\n-        \"\"\"Finds non-specific dimensions in the static shapes\n-        and replaces them by the corresponding dynamic shapes of the tensor.\n-\n-        # Arguments\n-            init_tuple: a tuple, the first part of the output shape\n-            tensor: the tensor from which to get the (static and dynamic) shapes\n-                as the last part of the output shape\n-            start_idx: int, which indicate the first dimension to take from\n-                the static shape of the tensor\n-            int_shape: an alternative static shape to take as the last part\n-                of the output shape\n-\n-        # Returns\n-            The new int_shape with the first part from init_tuple\n-            and the last part from either `int_shape` (if provided)\n-            or K.int_shape(tensor), where every `None` is replaced by\n-            the corresponding dimension from K.shape(tensor)\n-        \"\"\"\n-        # replace all None in int_shape by K.shape\n-        if int_shape is None:\n-            int_shape = K.int_shape(tensor)[start_idx:]\n-        if not any(not s for s in int_shape):\n-            return init_tuple + int_shape\n-        tensor_shape = K.shape(tensor)\n-        int_shape = list(int_shape)\n-        for i, s in enumerate(int_shape):\n-            if not s:\n-                int_shape[i] = tensor_shape[start_idx + i]\n-        return init_tuple + tuple(int_shape)\n-\n-    def build(self, input_shape):\n-        assert len(input_shape) >= 3\n-        self.input_spec = InputSpec(shape=input_shape)\n-        child_input_shape = (input_shape[0],) + input_shape[2:]\n-        if not self.layer.built:\n-            self.layer.build(child_input_shape)\n-            self.layer.built = True\n-        super(TimeDistributed, self).build()\n-\n-    def compute_output_shape(self, input_shape):\n-        child_input_shape = (input_shape[0],) + input_shape[2:]\n-        child_output_shape = self.layer.compute_output_shape(child_input_shape)\n-        timesteps = input_shape[1]\n-        return (child_output_shape[0], timesteps) + child_output_shape[1:]\n-\n-    def call(self, inputs, training=None, mask=None):\n-        kwargs = {}\n-        if has_arg(self.layer.call, 'training'):\n-            kwargs['training'] = training\n-        uses_learning_phase = False\n-\n-        input_shape = K.int_shape(inputs)\n-        if input_shape[0]:\n-            # batch size matters, use rnn-based implementation\n-            def step(x, _):\n-                global uses_learning_phase\n-                output = self.layer.call(x, **kwargs)\n-                if hasattr(output, '_uses_learning_phase'):\n-                    uses_learning_phase = (output._uses_learning_phase or\n-                                           uses_learning_phase)\n-                return output, []\n-\n-            _, outputs, _ = K.rnn(step, inputs,\n-                                  initial_states=[],\n-                                  input_length=input_shape[1],\n-                                  unroll=False)\n-            y = outputs\n-        else:\n-            # No batch size specified, therefore the layer will be able\n-            # to process batches of any size.\n-            # We can go with reshape-based implementation for performance.\n-            input_length = input_shape[1]\n-            if not input_length:\n-                input_length = K.shape(inputs)[1]\n-            inner_input_shape = self._get_shape_tuple((-1,), inputs, 2)\n-            # Shape: (num_samples * timesteps, ...). And track the\n-            # transformation in self._input_map.\n-            input_uid = object_list_uid(inputs)\n-            inputs = K.reshape(inputs, inner_input_shape)\n-            self._input_map[input_uid] = inputs\n-            # (num_samples * timesteps, ...)\n-            if has_arg(self.layer.call, 'mask') and mask is not None:\n-                inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n-                kwargs['mask'] = K.reshape(mask, inner_mask_shape)\n-            y = self.layer.call(inputs, **kwargs)\n-            if hasattr(y, '_uses_learning_phase'):\n-                uses_learning_phase = y._uses_learning_phase\n-            # Shape: (num_samples, timesteps, ...)\n-            output_shape = self.compute_output_shape(input_shape)\n-            output_shape = self._get_shape_tuple(\n-                (-1, input_length), y, 1, output_shape[2:])\n-            y = K.reshape(y, output_shape)\n-\n-        # Apply activity regularizer if any:\n-        if (hasattr(self.layer, 'activity_regularizer') and\n-           self.layer.activity_regularizer is not None):\n-            regularization_loss = self.layer.activity_regularizer(y)\n-            self.add_loss(regularization_loss, inputs)\n-\n-        if uses_learning_phase:\n-            y._uses_learning_phase = True\n-        return y\n-\n-    def compute_mask(self, inputs, mask=None):\n-        \"\"\"Computes an output mask tensor for Embedding layer\n-        based on the inputs, mask, and the inner layer.\n-\n-        If batch size is specified:\n-        Simply return the input `mask`. (An rnn-based implementation with\n-        more than one rnn inputs is required but not supported in Keras yet.)\n-\n-        Otherwise we call `compute_mask` of the inner layer at each time step.\n-        If the output mask at each time step is not `None`:\n-        (E.g., inner layer is Masking or RNN)\n-        Concatenate all of them and return the concatenation.\n-        If the output mask at each time step is `None` and\n-        the input mask is not `None`:\n-        (E.g., inner layer is Dense)\n-        Reduce the input_mask to 2 dimensions and return it.\n-        Otherwise (both the output mask and the input mask are `None`):\n-        (E.g., `mask` is not used at all)\n-        Return `None`.\n-\n-        # Arguments\n-            inputs: Tensor\n-            mask: Tensor\n-        # Returns\n-            None or a tensor\n-        \"\"\"\n-        # cases need to call the layer.compute_mask when input_mask is None:\n-        # Masking layer and Embedding layer with mask_zero\n-        input_shape = K.int_shape(inputs)\n-        if input_shape[0]:\n-            # batch size matters, we currently do not handle mask explicitly\n-            return mask\n-        inner_mask = mask\n-        if inner_mask is not None:\n-            inner_mask_shape = self._get_shape_tuple((-1,), mask, 2)\n-            inner_mask = K.reshape(inner_mask, inner_mask_shape)\n-        input_uid = object_list_uid(inputs)\n-        inner_inputs = self._input_map[input_uid]\n-        output_mask = self.layer.compute_mask(inner_inputs, inner_mask)\n-        if output_mask is None:\n-            if mask is None:\n-                return None\n-            # input_mask is not None, and output_mask is None:\n-            # we should return a not-None mask\n-            output_mask = mask\n-            for _ in range(2, len(K.int_shape(mask))):\n-                output_mask = K.any(output_mask, axis=-1)\n-        else:\n-            # output_mask is not None. We need to reshape it\n-            input_length = input_shape[1]\n-            if not input_length:\n-                input_length = K.shape(inputs)[1]\n-            output_mask_int_shape = K.int_shape(output_mask)\n-            if output_mask_int_shape is None:\n-                # if the output_mask does not have a static shape,\n-                # its shape must be the same as mask's\n-                if mask is not None:\n-                    output_mask_int_shape = K.int_shape(mask)\n-                else:\n-                    output_mask_int_shape = K.compute_output_shape(input_shape)[:-1]\n-            output_mask_shape = self._get_shape_tuple(\n-                (-1, input_length), output_mask, 1, output_mask_int_shape[1:])\n-            output_mask = K.reshape(output_mask, output_mask_shape)\n-        return output_mask\n-\n-\n-class Bidirectional(Wrapper):\n-    \"\"\"Bidirectional wrapper for RNNs.\n-\n-    # Arguments\n-        layer: `Recurrent` instance.\n-        merge_mode: Mode by which outputs of the\n-            forward and backward RNNs will be combined.\n-            One of {'sum', 'mul', 'concat', 'ave', None}.\n-            If None, the outputs will not be combined,\n-            they will be returned as a list.\n-        weights: Initial weights to load in the Bidirectional model\n-\n-    # Raises\n-        ValueError: In case of invalid `merge_mode` argument.\n-\n-    # Examples\n-\n-    ```python\n-        model = Sequential()\n-        model.add(Bidirectional(LSTM(10, return_sequences=True),\n-                                input_shape=(5, 10)))\n-        model.add(Bidirectional(LSTM(10)))\n-        model.add(Dense(5))\n-        model.add(Activation('softmax'))\n-        model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, layer, merge_mode='concat', weights=None, **kwargs):\n-        if merge_mode not in ['sum', 'mul', 'ave', 'concat', None]:\n-            raise ValueError('Invalid merge mode. '\n-                             'Merge mode should be one of '\n-                             '{\"sum\", \"mul\", \"ave\", \"concat\", None}')\n-        self._set_sublayers(layer)\n-        self.merge_mode = merge_mode\n-        if weights:\n-            nw = len(weights)\n-            self.forward_layer.initial_weights = weights[:nw // 2]\n-            self.backward_layer.initial_weights = weights[nw // 2:]\n-        self.stateful = layer.stateful\n-        self.return_sequences = layer.return_sequences\n-        self.return_state = layer.return_state\n-        self.supports_masking = True\n-        self._trainable = True\n-        super(Bidirectional, self).__init__(layer, **kwargs)\n-        self.input_spec = layer.input_spec\n-        self._num_constants = None\n-\n-    @disable_tracking\n-    def _set_sublayers(self, layer):\n-        # This is isolated in its own method in order to use\n-        # the disable_tracking decorator without altering the\n-        # visible signature of __init__.\n-        self.forward_layer = copy.copy(layer)\n-        config = layer.get_config()\n-        config['go_backwards'] = not config['go_backwards']\n-        self.backward_layer = layer.__class__.from_config(config)\n-        self.forward_layer.name = 'forward_' + self.forward_layer.name\n-        self.backward_layer.name = 'backward_' + self.backward_layer.name\n-\n-    @property\n-    def trainable(self):\n-        return self._trainable\n-\n-    @trainable.setter\n-    def trainable(self, value):\n-        self._trainable = value\n-        self.forward_layer.trainable = value\n-        self.backward_layer.trainable = value\n-\n-    def get_weights(self):\n-        return self.forward_layer.get_weights() + self.backward_layer.get_weights()\n-\n-    def set_weights(self, weights):\n-        nw = len(weights)\n-        self.forward_layer.set_weights(weights[:nw // 2])\n-        self.backward_layer.set_weights(weights[nw // 2:])\n-\n-    def compute_output_shape(self, input_shape):\n-        output_shape = self.forward_layer.compute_output_shape(input_shape)\n-        if self.return_state:\n-            state_shape = output_shape[1:]\n-            output_shape = output_shape[0]\n-\n-        if self.merge_mode == 'concat':\n-            output_shape = list(output_shape)\n-            output_shape[-1] *= 2\n-            output_shape = tuple(output_shape)\n-        elif self.merge_mode is None:\n-            output_shape = [output_shape, copy.copy(output_shape)]\n-\n-        if self.return_state:\n-            if self.merge_mode is None:\n-                return output_shape + state_shape + copy.copy(state_shape)\n-            return [output_shape] + state_shape + copy.copy(state_shape)\n-        return output_shape\n-\n-    def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n-        inputs, initial_state, constants = recurrent._standardize_args(\n-            inputs, initial_state, constants, self._num_constants)\n-\n-        if initial_state is None and constants is None:\n-            return super(Bidirectional, self).__call__(inputs, **kwargs)\n-\n-        # Applies the same workaround as in `RNN.__call__`\n-        additional_inputs = []\n-        additional_specs = []\n-        if initial_state is not None:\n-            # Check if `initial_state` can be splitted into half\n-            num_states = len(initial_state)\n-            if num_states % 2 > 0:\n-                raise ValueError(\n-                    'When passing `initial_state` to a Bidirectional RNN, '\n-                    'the state should be a list containing the states of '\n-                    'the underlying RNNs. '\n-                    'Found: ' + str(initial_state))\n-\n-            kwargs['initial_state'] = initial_state\n-            additional_inputs += initial_state\n-            state_specs = [InputSpec(shape=K.int_shape(state))\n-                           for state in initial_state]\n-            self.forward_layer.state_spec = state_specs[:num_states // 2]\n-            self.backward_layer.state_spec = state_specs[num_states // 2:]\n-            additional_specs += state_specs\n-        if constants is not None:\n-            kwargs['constants'] = constants\n-            additional_inputs += constants\n-            constants_spec = [InputSpec(shape=K.int_shape(constant))\n-                              for constant in constants]\n-            self.forward_layer.constants_spec = constants_spec\n-            self.backward_layer.constants_spec = constants_spec\n-            additional_specs += constants_spec\n-\n-            self._num_constants = len(constants)\n-            self.forward_layer._num_constants = self._num_constants\n-            self.backward_layer._num_constants = self._num_constants\n-\n-        is_keras_tensor = K.is_keras_tensor(additional_inputs[0])\n-        for tensor in additional_inputs:\n-            if K.is_keras_tensor(tensor) != is_keras_tensor:\n-                raise ValueError('The initial state of a Bidirectional'\n-                                 ' layer cannot be specified with a mix of'\n-                                 ' Keras tensors and non-Keras tensors'\n-                                 ' (a \"Keras tensor\" is a tensor that was'\n-                                 ' returned by a Keras layer, or by `Input`)')\n-\n-        if is_keras_tensor:\n-            # Compute the full input spec, including state\n-            full_input = [inputs] + additional_inputs\n-            full_input_spec = self.input_spec + additional_specs\n-\n-            # Perform the call with temporarily replaced input_spec\n-            original_input_spec = self.input_spec\n-            self.input_spec = full_input_spec\n-            if 'initial_state' in kwargs:\n-                kwargs.pop('initial_state')\n-            if 'constants' in kwargs:\n-                kwargs.pop('constants')\n-            output = super(Bidirectional, self).__call__(full_input, **kwargs)\n-            self.input_spec = original_input_spec\n-            return output\n-        else:\n-            return super(Bidirectional, self).__call__(inputs, **kwargs)\n-\n-    def call(self,\n-             inputs,\n-             mask=None,\n-             training=None,\n-             initial_state=None,\n-             constants=None):\n-        kwargs = {}\n-        if has_arg(self.layer.call, 'training'):\n-            kwargs['training'] = training\n-        if has_arg(self.layer.call, 'mask'):\n-            kwargs['mask'] = mask\n-        if has_arg(self.layer.call, 'constants'):\n-            if self._num_constants is not None and constants is None:\n-                    constants = inputs[-self._num_constants:]\n-                    inputs = inputs[:-self._num_constants]\n-            kwargs['constants'] = constants\n-        if has_arg(self.layer.call, 'initial_state'):\n-            if isinstance(inputs, list) and len(inputs) > 1:\n-                if initial_state is not None:\n-                    raise ValueError('Layer was passed initial state ' +\n-                                     'via both kwarg and inputs list)')\n-                initial_state = inputs[1:]\n-                inputs = [inputs[0]]\n-            if initial_state is None:\n-                forward_state = None\n-                backward_state = None\n-            else:\n-                pivot = len(initial_state) // 2\n-                forward_state = initial_state[:pivot]\n-                backward_state = initial_state[pivot:]\n-            y = self.forward_layer.call(inputs,\n-                                        initial_state=forward_state, **kwargs)\n-            y_rev = self.backward_layer.call(inputs,\n-                                             initial_state=backward_state, **kwargs)\n-        else:\n-            if isinstance(inputs, list) and len(inputs) > 1 or initial_state:\n-                raise ValueError('Layer does not accept initial_state argument.')\n-            y = self.forward_layer.call(inputs, **kwargs)\n-            y_rev = self.backward_layer.call(inputs, **kwargs)\n-\n-        if self.return_state:\n-            states = y[1:] + y_rev[1:]\n-            y = y[0]\n-            y_rev = y_rev[0]\n-\n-        if self.return_sequences:\n-            y_rev = K.reverse(y_rev, 1)\n-        if self.merge_mode == 'concat':\n-            output = K.concatenate([y, y_rev])\n-        elif self.merge_mode == 'sum':\n-            output = y + y_rev\n-        elif self.merge_mode == 'ave':\n-            output = (y + y_rev) / 2\n-        elif self.merge_mode == 'mul':\n-            output = y * y_rev\n-        elif self.merge_mode is None:\n-            output = [y, y_rev]\n-        else:\n-            raise ValueError('Unrecognized value for argument '\n-                             'merge_mode: %s' % (self.merge_mode))\n-\n-        # Properly set learning phase\n-        if (getattr(y, '_uses_learning_phase', False) or\n-           getattr(y_rev, '_uses_learning_phase', False)):\n-            if self.merge_mode is None:\n-                for out in output:\n-                    out._uses_learning_phase = True\n-            else:\n-                output._uses_learning_phase = True\n-\n-        if self.return_state:\n-            if self.merge_mode is None:\n-                return output + states\n-            return [output] + states\n-        return output\n-\n-    def reset_states(self):\n-        self.forward_layer.reset_states()\n-        self.backward_layer.reset_states()\n-\n-    def build(self, input_shape):\n-        with K.name_scope(self.forward_layer.name):\n-            self.forward_layer.build(input_shape)\n-        with K.name_scope(self.backward_layer.name):\n-            self.backward_layer.build(input_shape)\n-        self.built = True\n-\n-    def compute_mask(self, inputs, mask):\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-        if self.return_sequences:\n-            if not self.merge_mode:\n-                output_mask = [mask, mask]\n-            else:\n-                output_mask = mask\n-        else:\n-            output_mask = [None, None] if not self.merge_mode else None\n-\n-        if self.return_state:\n-            states = self.forward_layer.states\n-            state_mask = [None for _ in states]\n-            if isinstance(output_mask, list):\n-                return output_mask + state_mask * 2\n-            return [output_mask] + state_mask * 2\n-\n-        return output_mask\n-\n-    @property\n-    def trainable_weights(self):\n-        if hasattr(self.forward_layer, 'trainable_weights'):\n-            return (self.forward_layer.trainable_weights +\n-                    self.backward_layer.trainable_weights)\n-        return []\n-\n-    @property\n-    def non_trainable_weights(self):\n-        if hasattr(self.forward_layer, 'non_trainable_weights'):\n-            return (self.forward_layer.non_trainable_weights +\n-                    self.backward_layer.non_trainable_weights)\n-        return []\n-\n-    @property\n-    def updates(self):\n-        if hasattr(self.forward_layer, 'updates'):\n-            return self.forward_layer.updates + self.backward_layer.updates\n-        return []\n-\n-    def get_updates_for(self, inputs=None):\n-        forward_updates = self.forward_layer.get_updates_for(inputs)\n-        backward_updates = self.backward_layer.get_updates_for(inputs)\n-        return (super(Wrapper, self).get_updates_for(inputs) +\n-                forward_updates + backward_updates)\n-\n-    @property\n-    def losses(self):\n-        if hasattr(self.forward_layer, 'losses'):\n-            return self.forward_layer.losses + self.backward_layer.losses\n-        return []\n-\n-    def get_losses_for(self, inputs=None):\n-        forward_losses = self.forward_layer.get_losses_for(inputs)\n-        backward_losses = self.backward_layer.get_losses_for(inputs)\n-        return (super(Wrapper, self).get_losses_for(inputs) +\n-                forward_losses + backward_losses)\n-\n-    @property\n-    def constraints(self):\n-        constraints = {}\n-        if hasattr(self.forward_layer, 'constraints'):\n-            constraints.update(self.forward_layer.constraints)\n-            constraints.update(self.backward_layer.constraints)\n-        return constraints\n-\n-    def get_config(self):\n-        config = {'merge_mode': self.merge_mode}\n-        if self._num_constants is not None:\n-            config['num_constants'] = self._num_constants\n-\n-        base_config = super(Bidirectional, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        from . import deserialize as deserialize_layer\n-        rnn_layer = deserialize_layer(config.pop('layer'),\n-                                      custom_objects=custom_objects)\n-        num_constants = config.pop('num_constants', None)\n-        layer = cls(rnn_layer, **config)\n-        layer._num_constants = num_constants\n-        return layer\n+from tensorflow.keras.layers import Wrapper\n+from tensorflow.keras.layers import TimeDistributed\n+from tensorflow.keras.layers import Bidirectional\n\n\n@@ -1,668 +0,0 @@\n-\"\"\"Interface converters for Keras 1 support in Keras 2.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import six\n-import warnings\n-import functools\n-import numpy as np\n-\n-\n-def generate_legacy_interface(allowed_positional_args=None,\n-                              conversions=None,\n-                              preprocessor=None,\n-                              value_conversions=None,\n-                              object_type='class'):\n-    if allowed_positional_args is None:\n-        check_positional_args = False\n-    else:\n-        check_positional_args = True\n-    allowed_positional_args = allowed_positional_args or []\n-    conversions = conversions or []\n-    value_conversions = value_conversions or []\n-\n-    def legacy_support(func):\n-        @six.wraps(func)\n-        def wrapper(*args, **kwargs):\n-            if object_type == 'class':\n-                object_name = args[0].__class__.__name__\n-            else:\n-                object_name = func.__name__\n-            if preprocessor:\n-                args, kwargs, converted = preprocessor(args, kwargs)\n-            else:\n-                converted = []\n-            if check_positional_args:\n-                if len(args) > len(allowed_positional_args) + 1:\n-                    raise TypeError('`' + object_name +\n-                                    '` can accept only ' +\n-                                    str(len(allowed_positional_args)) +\n-                                    ' positional arguments ' +\n-                                    str(tuple(allowed_positional_args)) +\n-                                    ', but you passed the following '\n-                                    'positional arguments: ' +\n-                                    str(list(args[1:])))\n-            for key in value_conversions:\n-                if key in kwargs:\n-                    old_value = kwargs[key]\n-                    if old_value in value_conversions[key]:\n-                        kwargs[key] = value_conversions[key][old_value]\n-            for old_name, new_name in conversions:\n-                if old_name in kwargs:\n-                    value = kwargs.pop(old_name)\n-                    if new_name in kwargs:\n-                        raise_duplicate_arg_error(old_name, new_name)\n-                    kwargs[new_name] = value\n-                    converted.append((new_name, old_name))\n-            if converted:\n-                signature = '`' + object_name + '('\n-                for i, value in enumerate(args[1:]):\n-                    if isinstance(value, six.string_types):\n-                        signature += '\"' + value + '\"'\n-                    else:\n-                        if isinstance(value, np.ndarray):\n-                            str_val = 'array'\n-                        else:\n-                            str_val = str(value)\n-                        if len(str_val) > 10:\n-                            str_val = str_val[:10] + '...'\n-                        signature += str_val\n-                    if i < len(args[1:]) - 1 or kwargs:\n-                        signature += ', '\n-                for i, (name, value) in enumerate(kwargs.items()):\n-                    signature += name + '='\n-                    if isinstance(value, six.string_types):\n-                        signature += '\"' + value + '\"'\n-                    else:\n-                        if isinstance(value, np.ndarray):\n-                            str_val = 'array'\n-                        else:\n-                            str_val = str(value)\n-                        if len(str_val) > 10:\n-                            str_val = str_val[:10] + '...'\n-                        signature += str_val\n-                    if i < len(kwargs) - 1:\n-                        signature += ', '\n-                signature += ')`'\n-                warnings.warn('Update your `' + object_name + '` call to the ' +\n-                              'Keras 2 API: ' + signature, stacklevel=2)\n-            return func(*args, **kwargs)\n-        wrapper._original_function = func\n-        return wrapper\n-    return legacy_support\n-\n-\n-generate_legacy_method_interface = functools.partial(generate_legacy_interface,\n-                                                     object_type='method')\n-\n-\n-def raise_duplicate_arg_error(old_arg, new_arg):\n-    raise TypeError('For the `' + new_arg + '` argument, '\n-                    'the layer received both '\n-                    'the legacy keyword argument '\n-                    '`' + old_arg + '` and the Keras 2 keyword argument '\n-                    '`' + new_arg + '`. Stick to the latter!')\n-\n-\n-legacy_dense_support = generate_legacy_interface(\n-    allowed_positional_args=['units'],\n-    conversions=[('output_dim', 'units'),\n-                 ('init', 'kernel_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('W_constraint', 'kernel_constraint'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')])\n-\n-legacy_dropout_support = generate_legacy_interface(\n-    allowed_positional_args=['rate', 'noise_shape', 'seed'],\n-    conversions=[('p', 'rate')])\n-\n-\n-def embedding_kwargs_preprocessor(args, kwargs):\n-    converted = []\n-    if 'dropout' in kwargs:\n-        kwargs.pop('dropout')\n-        warnings.warn('The `dropout` argument is no longer support in `Embedding`. '\n-                      'You can apply a `keras.layers.SpatialDropout1D` layer '\n-                      'right after the `Embedding` layer to get the same behavior.',\n-                      stacklevel=3)\n-    return args, kwargs, converted\n-\n-legacy_embedding_support = generate_legacy_interface(\n-    allowed_positional_args=['input_dim', 'output_dim'],\n-    conversions=[('init', 'embeddings_initializer'),\n-                 ('W_regularizer', 'embeddings_regularizer'),\n-                 ('W_constraint', 'embeddings_constraint')],\n-    preprocessor=embedding_kwargs_preprocessor)\n-\n-legacy_pooling1d_support = generate_legacy_interface(\n-    allowed_positional_args=['pool_size', 'strides', 'padding'],\n-    conversions=[('pool_length', 'pool_size'),\n-                 ('stride', 'strides'),\n-                 ('border_mode', 'padding')])\n-\n-legacy_prelu_support = generate_legacy_interface(\n-    allowed_positional_args=['alpha_initializer'],\n-    conversions=[('init', 'alpha_initializer')])\n-\n-\n-legacy_gaussiannoise_support = generate_legacy_interface(\n-    allowed_positional_args=['stddev'],\n-    conversions=[('sigma', 'stddev')])\n-\n-\n-def recurrent_args_preprocessor(args, kwargs):\n-    converted = []\n-    if 'forget_bias_init' in kwargs:\n-        if kwargs['forget_bias_init'] == 'one':\n-            kwargs.pop('forget_bias_init')\n-            kwargs['unit_forget_bias'] = True\n-            converted.append(('forget_bias_init', 'unit_forget_bias'))\n-        else:\n-            kwargs.pop('forget_bias_init')\n-            warnings.warn('The `forget_bias_init` argument '\n-                          'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to initialize with ones.', stacklevel=3)\n-    if 'input_dim' in kwargs:\n-        input_length = kwargs.pop('input_length', None)\n-        input_dim = kwargs.pop('input_dim')\n-        input_shape = (input_length, input_dim)\n-        kwargs['input_shape'] = input_shape\n-        converted.append(('input_dim', 'input_shape'))\n-        warnings.warn('The `input_dim` and `input_length` arguments '\n-                      'in recurrent layers are deprecated. '\n-                      'Use `input_shape` instead.', stacklevel=3)\n-    return args, kwargs, converted\n-\n-legacy_recurrent_support = generate_legacy_interface(\n-    allowed_positional_args=['units'],\n-    conversions=[('output_dim', 'units'),\n-                 ('init', 'kernel_initializer'),\n-                 ('inner_init', 'recurrent_initializer'),\n-                 ('inner_activation', 'recurrent_activation'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('U_regularizer', 'recurrent_regularizer'),\n-                 ('dropout_W', 'dropout'),\n-                 ('dropout_U', 'recurrent_dropout'),\n-                 ('consume_less', 'implementation')],\n-    value_conversions={'consume_less': {'cpu': 0,\n-                                        'mem': 1,\n-                                        'gpu': 2}},\n-    preprocessor=recurrent_args_preprocessor)\n-\n-legacy_gaussiandropout_support = generate_legacy_interface(\n-    allowed_positional_args=['rate'],\n-    conversions=[('p', 'rate')])\n-\n-legacy_pooling2d_support = generate_legacy_interface(\n-    allowed_positional_args=['pool_size', 'strides', 'padding'],\n-    conversions=[('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_pooling3d_support = generate_legacy_interface(\n-    allowed_positional_args=['pool_size', 'strides', 'padding'],\n-    conversions=[('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_global_pooling_support = generate_legacy_interface(\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_upsampling1d_support = generate_legacy_interface(\n-    allowed_positional_args=['size'],\n-    conversions=[('length', 'size')])\n-\n-legacy_upsampling2d_support = generate_legacy_interface(\n-    allowed_positional_args=['size'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_upsampling3d_support = generate_legacy_interface(\n-    allowed_positional_args=['size'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-\n-def conv1d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if 'input_dim' in kwargs:\n-        if 'input_length' in kwargs:\n-            length = kwargs.pop('input_length')\n-        else:\n-            length = None\n-        input_shape = (length, kwargs.pop('input_dim'))\n-        kwargs['input_shape'] = input_shape\n-        converted.append(('input_shape', 'input_dim'))\n-    return args, kwargs, converted\n-\n-legacy_conv1d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('filter_length', 'kernel_size'),\n-                 ('subsample_length', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('init', 'kernel_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('W_constraint', 'kernel_constraint'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')],\n-    preprocessor=conv1d_args_preprocessor)\n-\n-\n-def conv2d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if len(args) > 4:\n-        raise TypeError('Layer can receive at most 3 positional arguments.')\n-    elif len(args) == 4:\n-        if isinstance(args[2], int) and isinstance(args[3], int):\n-            new_keywords = ['padding', 'strides', 'data_format']\n-            for kwd in new_keywords:\n-                if kwd in kwargs:\n-                    raise ValueError(\n-                        'It seems that you are using the Keras 2 '\n-                        'and you are passing both `kernel_size` and `strides` '\n-                        'as integer positional arguments. For safety reasons, '\n-                        'this is disallowed. Pass `strides` '\n-                        'as a keyword argument instead.')\n-            kernel_size = (args[2], args[3])\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'nb_row/nb_col'))\n-    elif len(args) == 3 and isinstance(args[2], int):\n-        if 'nb_col' in kwargs:\n-            kernel_size = (args[2], kwargs.pop('nb_col'))\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'nb_row/nb_col'))\n-    elif len(args) == 2:\n-        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n-            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'nb_row/nb_col'))\n-    elif len(args) == 1:\n-        if 'nb_row' in kwargs and 'nb_col' in kwargs:\n-            kernel_size = (kwargs.pop('nb_row'), kwargs.pop('nb_col'))\n-            kwargs['kernel_size'] = kernel_size\n-            converted.append(('kernel_size', 'nb_row/nb_col'))\n-    return args, kwargs, converted\n-\n-legacy_conv2d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('subsample', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format'),\n-                 ('init', 'kernel_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('W_constraint', 'kernel_constraint'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=conv2d_args_preprocessor)\n-\n-\n-def separable_conv2d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if 'init' in kwargs:\n-        init = kwargs.pop('init')\n-        kwargs['depthwise_initializer'] = init\n-        kwargs['pointwise_initializer'] = init\n-        converted.append(('init', 'depthwise_initializer/pointwise_initializer'))\n-    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n-    return args, kwargs, converted + _converted\n-\n-legacy_separable_conv2d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('subsample', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=separable_conv2d_args_preprocessor)\n-\n-\n-def deconv2d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if len(args) == 5:\n-        if isinstance(args[4], tuple):\n-            args = args[:-1]\n-            converted.append(('output_shape', None))\n-    if 'output_shape' in kwargs:\n-        kwargs.pop('output_shape')\n-        converted.append(('output_shape', None))\n-    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n-    return args, kwargs, converted + _converted\n-\n-legacy_deconv2d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('subsample', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format'),\n-                 ('init', 'kernel_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('W_constraint', 'kernel_constraint'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=deconv2d_args_preprocessor)\n-\n-\n-def conv3d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if len(args) > 5:\n-        raise TypeError('Layer can receive at most 4 positional arguments.')\n-    if len(args) == 5:\n-        if all([isinstance(x, int) for x in args[2:5]]):\n-            kernel_size = (args[2], args[3], args[4])\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'kernel_dim*'))\n-    elif len(args) == 4 and isinstance(args[3], int):\n-        if isinstance(args[2], int) and isinstance(args[3], int):\n-            new_keywords = ['padding', 'strides', 'data_format']\n-            for kwd in new_keywords:\n-                if kwd in kwargs:\n-                    raise ValueError(\n-                        'It seems that you are using the Keras 2 '\n-                        'and you are passing both `kernel_size` and `strides` '\n-                        'as integer positional arguments. For safety reasons, '\n-                        'this is disallowed. Pass `strides` '\n-                        'as a keyword argument instead.')\n-        if 'kernel_dim3' in kwargs:\n-            kernel_size = (args[2], args[3], kwargs.pop('kernel_dim3'))\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'kernel_dim*'))\n-    elif len(args) == 3:\n-        if all([x in kwargs for x in ['kernel_dim2', 'kernel_dim3']]):\n-            kernel_size = (args[2],\n-                           kwargs.pop('kernel_dim2'),\n-                           kwargs.pop('kernel_dim3'))\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'kernel_dim*'))\n-    elif len(args) == 2:\n-        if all([x in kwargs for x in ['kernel_dim1', 'kernel_dim2', 'kernel_dim3']]):\n-            kernel_size = (kwargs.pop('kernel_dim1'),\n-                           kwargs.pop('kernel_dim2'),\n-                           kwargs.pop('kernel_dim3'))\n-            args = [args[0], args[1], kernel_size]\n-            converted.append(('kernel_size', 'kernel_dim*'))\n-    elif len(args) == 1:\n-        if all([x in kwargs for x in ['kernel_dim1', 'kernel_dim2', 'kernel_dim3']]):\n-            kernel_size = (kwargs.pop('kernel_dim1'),\n-                           kwargs.pop('kernel_dim2'),\n-                           kwargs.pop('kernel_dim3'))\n-            kwargs['kernel_size'] = kernel_size\n-            converted.append(('kernel_size', 'nb_row/nb_col'))\n-    return args, kwargs, converted\n-\n-legacy_conv3d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('subsample', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format'),\n-                 ('init', 'kernel_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('W_constraint', 'kernel_constraint'),\n-                 ('b_constraint', 'bias_constraint'),\n-                 ('bias', 'use_bias')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=conv3d_args_preprocessor)\n-\n-\n-def batchnorm_args_preprocessor(args, kwargs):\n-    converted = []\n-    if len(args) > 1:\n-        raise TypeError('The `BatchNormalization` layer '\n-                        'does not accept positional arguments. '\n-                        'Use keyword arguments instead.')\n-    if 'mode' in kwargs:\n-        value = kwargs.pop('mode')\n-        if value != 0:\n-            raise TypeError('The `mode` argument of `BatchNormalization` '\n-                            'no longer exists. `mode=1` and `mode=2` '\n-                            'are no longer supported.')\n-        converted.append(('mode', None))\n-    return args, kwargs, converted\n-\n-\n-def convlstm2d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if 'forget_bias_init' in kwargs:\n-        value = kwargs.pop('forget_bias_init')\n-        if value == 'one':\n-            kwargs['unit_forget_bias'] = True\n-            converted.append(('forget_bias_init', 'unit_forget_bias'))\n-        else:\n-            warnings.warn('The `forget_bias_init` argument '\n-                          'has been ignored. Use `unit_forget_bias=True` '\n-                          'instead to initialize with ones.', stacklevel=3)\n-    args, kwargs, _converted = conv2d_args_preprocessor(args, kwargs)\n-    return args, kwargs, converted + _converted\n-\n-legacy_convlstm2d_support = generate_legacy_interface(\n-    allowed_positional_args=['filters', 'kernel_size'],\n-    conversions=[('nb_filter', 'filters'),\n-                 ('subsample', 'strides'),\n-                 ('border_mode', 'padding'),\n-                 ('dim_ordering', 'data_format'),\n-                 ('init', 'kernel_initializer'),\n-                 ('inner_init', 'recurrent_initializer'),\n-                 ('W_regularizer', 'kernel_regularizer'),\n-                 ('U_regularizer', 'recurrent_regularizer'),\n-                 ('b_regularizer', 'bias_regularizer'),\n-                 ('inner_activation', 'recurrent_activation'),\n-                 ('dropout_W', 'dropout'),\n-                 ('dropout_U', 'recurrent_dropout'),\n-                 ('bias', 'use_bias')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=convlstm2d_args_preprocessor)\n-\n-legacy_batchnorm_support = generate_legacy_interface(\n-    allowed_positional_args=[],\n-    conversions=[('beta_init', 'beta_initializer'),\n-                 ('gamma_init', 'gamma_initializer')],\n-    preprocessor=batchnorm_args_preprocessor)\n-\n-\n-def zeropadding2d_args_preprocessor(args, kwargs):\n-    converted = []\n-    if 'padding' in kwargs and isinstance(kwargs['padding'], dict):\n-        if set(kwargs['padding'].keys()) <= {'top_pad', 'bottom_pad',\n-                                             'left_pad', 'right_pad'}:\n-            top_pad = kwargs['padding'].get('top_pad', 0)\n-            bottom_pad = kwargs['padding'].get('bottom_pad', 0)\n-            left_pad = kwargs['padding'].get('left_pad', 0)\n-            right_pad = kwargs['padding'].get('right_pad', 0)\n-            kwargs['padding'] = ((top_pad, bottom_pad), (left_pad, right_pad))\n-            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n-                          'accepts dict types. You can now input argument as: '\n-                          '`padding=(top_pad, bottom_pad, left_pad, right_pad)`.',\n-                          stacklevel=3)\n-    elif len(args) == 2 and isinstance(args[1], dict):\n-        if set(args[1].keys()) <= {'top_pad', 'bottom_pad',\n-                                   'left_pad', 'right_pad'}:\n-            top_pad = args[1].get('top_pad', 0)\n-            bottom_pad = args[1].get('bottom_pad', 0)\n-            left_pad = args[1].get('left_pad', 0)\n-            right_pad = args[1].get('right_pad', 0)\n-            args = (args[0], ((top_pad, bottom_pad), (left_pad, right_pad)))\n-            warnings.warn('The `padding` argument in the Keras 2 API no longer'\n-                          'accepts dict types. You can now input argument as: '\n-                          '`padding=((top_pad, bottom_pad), (left_pad, right_pad))`',\n-                          stacklevel=3)\n-    return args, kwargs, converted\n-\n-legacy_zeropadding2d_support = generate_legacy_interface(\n-    allowed_positional_args=['padding'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}},\n-    preprocessor=zeropadding2d_args_preprocessor)\n-\n-legacy_zeropadding3d_support = generate_legacy_interface(\n-    allowed_positional_args=['padding'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_cropping2d_support = generate_legacy_interface(\n-    allowed_positional_args=['cropping'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_cropping3d_support = generate_legacy_interface(\n-    allowed_positional_args=['cropping'],\n-    conversions=[('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_spatialdropout1d_support = generate_legacy_interface(\n-    allowed_positional_args=['rate'],\n-    conversions=[('p', 'rate')])\n-\n-legacy_spatialdropoutNd_support = generate_legacy_interface(\n-    allowed_positional_args=['rate'],\n-    conversions=[('p', 'rate'),\n-                 ('dim_ordering', 'data_format')],\n-    value_conversions={'dim_ordering': {'tf': 'channels_last',\n-                                        'th': 'channels_first',\n-                                        'default': None}})\n-\n-legacy_lambda_support = generate_legacy_interface(\n-    allowed_positional_args=['function', 'output_shape'])\n-\n-\n-# Model methods\n-\n-def generator_methods_args_preprocessor(args, kwargs):\n-    converted = []\n-    if len(args) < 3:\n-        if 'samples_per_epoch' in kwargs:\n-            samples_per_epoch = kwargs.pop('samples_per_epoch')\n-            if len(args) > 1:\n-                generator = args[1]\n-            else:\n-                generator = kwargs['generator']\n-            if hasattr(generator, 'batch_size'):\n-                kwargs['steps_per_epoch'] = samples_per_epoch // generator.batch_size\n-            else:\n-                kwargs['steps_per_epoch'] = samples_per_epoch\n-            converted.append(('samples_per_epoch', 'steps_per_epoch'))\n-\n-    keras1_args = {'samples_per_epoch', 'val_samples',\n-                   'nb_epoch', 'nb_val_samples', 'nb_worker'}\n-    if keras1_args.intersection(kwargs.keys()):\n-        warnings.warn('The semantics of the Keras 2 argument '\n-                      '`steps_per_epoch` is not the same as the '\n-                      'Keras 1 argument `samples_per_epoch`. '\n-                      '`steps_per_epoch` is the number of batches '\n-                      'to draw from the generator at each epoch. '\n-                      'Basically steps_per_epoch = samples_per_epoch/batch_size. '\n-                      'Similarly `nb_val_samples`->`validation_steps` and '\n-                      '`val_samples`->`steps` arguments have changed. '\n-                      'Update your method calls accordingly.', stacklevel=3)\n-\n-    return args, kwargs, converted\n-\n-\n-legacy_generator_methods_support = generate_legacy_method_interface(\n-    allowed_positional_args=['generator', 'steps_per_epoch', 'epochs'],\n-    conversions=[('samples_per_epoch', 'steps_per_epoch'),\n-                 ('val_samples', 'steps'),\n-                 ('nb_epoch', 'epochs'),\n-                 ('nb_val_samples', 'validation_steps'),\n-                 ('nb_worker', 'workers'),\n-                 ('pickle_safe', 'use_multiprocessing'),\n-                 ('max_q_size', 'max_queue_size')],\n-    preprocessor=generator_methods_args_preprocessor)\n-\n-\n-legacy_model_constructor_support = generate_legacy_interface(\n-    allowed_positional_args=None,\n-    conversions=[('input', 'inputs'),\n-                 ('output', 'outputs')])\n-\n-legacy_input_support = generate_legacy_interface(\n-    allowed_positional_args=None,\n-    conversions=[('input_dtype', 'dtype')])\n-\n-\n-def add_weight_args_preprocessing(args, kwargs):\n-    if len(args) > 1:\n-        if isinstance(args[1], (tuple, list)):\n-            kwargs['shape'] = args[1]\n-            args = (args[0],) + args[2:]\n-            if len(args) > 1:\n-                if isinstance(args[1], six.string_types):\n-                    kwargs['name'] = args[1]\n-                    args = (args[0],) + args[2:]\n-    return args, kwargs, []\n-\n-\n-legacy_add_weight_support = generate_legacy_interface(\n-    allowed_positional_args=['name', 'shape'],\n-    preprocessor=add_weight_args_preprocessing)\n-\n-\n-def get_updates_arg_preprocessing(args, kwargs):\n-    # Old interface: (params, constraints, loss)\n-    # New interface: (loss, params)\n-    if len(args) > 4:\n-        raise TypeError('`get_update` call received more arguments '\n-                        'than expected.')\n-    elif len(args) == 4:\n-        # Assuming old interface.\n-        opt, params, _, loss = args\n-        kwargs['loss'] = loss\n-        kwargs['params'] = params\n-        return [opt], kwargs, []\n-    elif len(args) == 3:\n-        if isinstance(args[1], (list, tuple)):\n-            assert isinstance(args[2], dict)\n-            assert 'loss' in kwargs\n-            opt, params, _ = args\n-            kwargs['params'] = params\n-            return [opt], kwargs, []\n-    return args, kwargs, []\n-\n-legacy_get_updates_support = generate_legacy_interface(\n-    allowed_positional_args=None,\n-    conversions=[],\n-    preprocessor=get_updates_arg_preprocessing)\n\n@@ -1,810 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-import warnings\n-\n-from ..engine import Layer, InputSpec\n-from .. import backend as K\n-from ..utils import conv_utils\n-from ..utils.generic_utils import to_list\n-from .. import regularizers\n-from .. import constraints\n-from .. import activations\n-from .. import initializers\n-\n-\n-class MaxoutDense(Layer):\n-    \"\"\"A dense maxout layer.\n-    A `MaxoutDense` layer takes the element-wise maximum of\n-    `nb_feature` `Dense(input_dim, output_dim)` linear layers.\n-    This allows the layer to learn a convex,\n-    piecewise linear activation function over the inputs.\n-    Note that this is a *linear* layer;\n-    if you wish to apply activation function\n-    (you shouldn't need to --they are universal function approximators),\n-    an `Activation` layer must be added after.\n-    # Arguments\n-        output_dim: int > 0.\n-        nb_feature: number of Dense layers to use internally.\n-        init: name of initialization function for the weights of the layer\n-            (see [initializations](../initializations.md)),\n-            or alternatively, Theano function to use for weights\n-            initialization. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-    # Input shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-    # Output shape\n-        2D tensor with shape: `(nb_samples, output_dim)`.\n-    # References\n-        - [Maxout Networks](http://arxiv.org/abs/1302.4389)\n-    \"\"\"\n-\n-    def __init__(self, output_dim,\n-                 nb_feature=4,\n-                 init='glorot_uniform',\n-                 weights=None,\n-                 W_regularizer=None,\n-                 b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None,\n-                 b_constraint=None,\n-                 bias=True,\n-                 input_dim=None,\n-                 **kwargs):\n-        warnings.warn('The `MaxoutDense` layer is deprecated '\n-                      'and will be removed after 06/2017.')\n-        self.output_dim = output_dim\n-        self.nb_feature = nb_feature\n-        self.init = initializers.get(init)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = InputSpec(ndim=2)\n-\n-        self.input_dim = input_dim\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_dim,)\n-        super(MaxoutDense, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[1]\n-        self.input_spec = InputSpec(dtype=K.floatx(),\n-                                    shape=(None, input_dim))\n-\n-        self.W = self.add_weight(shape=(self.nb_feature, input_dim, self.output_dim),\n-                                 initializer=self.init,\n-                                 name='W',\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        if self.bias:\n-            self.b = self.add_weight(shape=(self.nb_feature, self.output_dim,),\n-                                     initializer='zero',\n-                                     name='b',\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-        else:\n-            self.b = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def compute_output_shape(self, input_shape):\n-        assert input_shape and len(input_shape) == 2\n-        return (input_shape[0], self.output_dim)\n-\n-    def call(self, x):\n-        # no activation, this layer is only linear.\n-        output = K.dot(x, self.W)\n-        if self.bias:\n-            output += self.b\n-        output = K.max(output, axis=1)\n-        return output\n-\n-    def get_config(self):\n-        config = {'output_dim': self.output_dim,\n-                  'init': initializers.serialize(self.init),\n-                  'nb_feature': self.nb_feature,\n-                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n-                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'W_constraint': constraints.serialize(self.W_constraint),\n-                  'b_constraint': constraints.serialize(self.b_constraint),\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim}\n-        base_config = super(MaxoutDense, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Highway(Layer):\n-    \"\"\"Densely connected highway network.\n-    Highway layers are a natural extension of LSTMs to feedforward networks.\n-    # Arguments\n-        init: name of initialization function for the weights of the layer\n-            (see [initializations](../initializations.md)),\n-            or alternatively, Theano function to use for weights\n-            initialization. This parameter is only relevant\n-            if you don't pass a `weights` argument.\n-        activation: name of activation function to use\n-            (see [activations](../activations.md)),\n-            or alternatively, elementwise Theano function.\n-            If you don't specify anything, no activation is applied\n-            (ie. \"linear\" activation: a(x) = x).\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 2 elements, of shape `(input_dim, output_dim)`\n-            and (output_dim,) for weights and biases respectively.\n-        W_regularizer: instance of [WeightRegularizer](../regularizers.md)\n-            (eg. L1 or L2 regularization), applied to the main weights matrix.\n-        b_regularizer: instance of [WeightRegularizer](../regularizers.md),\n-            applied to the bias.\n-        activity_regularizer: instance of [ActivityRegularizer](../regularizers.md),\n-            applied to the network output.\n-        W_constraint: instance of the [constraints](../constraints.md) module\n-            (eg. maxnorm, nonneg), applied to the main weights matrix.\n-        b_constraint: instance of the [constraints](../constraints.md) module,\n-            applied to the bias.\n-        bias: whether to include a bias\n-            (i.e. make the layer affine rather than linear).\n-        input_dim: dimensionality of the input (integer). This argument\n-            (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-    # Input shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-    # Output shape\n-        2D tensor with shape: `(nb_samples, input_dim)`.\n-    # References\n-        - [Highway Networks](http://arxiv.org/abs/1505.00387v2)\n-    \"\"\"\n-\n-    def __init__(self,\n-                 init='glorot_uniform',\n-                 activation=None,\n-                 weights=None,\n-                 W_regularizer=None,\n-                 b_regularizer=None,\n-                 activity_regularizer=None,\n-                 W_constraint=None,\n-                 b_constraint=None,\n-                 bias=True,\n-                 input_dim=None,\n-                 **kwargs):\n-        warnings.warn('The `Highway` layer is deprecated '\n-                      'and will be removed after 06/2017.')\n-        if 'transform_bias' in kwargs:\n-            kwargs.pop('transform_bias')\n-            warnings.warn('`transform_bias` argument is deprecated and '\n-                          'has been removed.')\n-        self.init = initializers.get(init)\n-        self.activation = activations.get(activation)\n-\n-        self.W_regularizer = regularizers.get(W_regularizer)\n-        self.b_regularizer = regularizers.get(b_regularizer)\n-        self.activity_regularizer = regularizers.get(activity_regularizer)\n-\n-        self.W_constraint = constraints.get(W_constraint)\n-        self.b_constraint = constraints.get(b_constraint)\n-\n-        self.bias = bias\n-        self.initial_weights = weights\n-        self.input_spec = InputSpec(ndim=2)\n-\n-        self.input_dim = input_dim\n-        if self.input_dim:\n-            kwargs['input_shape'] = (self.input_dim,)\n-        super(Highway, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        input_dim = input_shape[1]\n-        self.input_spec = InputSpec(dtype=K.floatx(),\n-                                    shape=(None, input_dim))\n-\n-        self.W = self.add_weight(shape=(input_dim, input_dim),\n-                                 initializer=self.init,\n-                                 name='W',\n-                                 regularizer=self.W_regularizer,\n-                                 constraint=self.W_constraint)\n-        self.W_carry = self.add_weight(shape=(input_dim, input_dim),\n-                                       initializer=self.init,\n-                                       name='W_carry')\n-        if self.bias:\n-            self.b = self.add_weight(shape=(input_dim,),\n-                                     initializer='zero',\n-                                     name='b',\n-                                     regularizer=self.b_regularizer,\n-                                     constraint=self.b_constraint)\n-            self.b_carry = self.add_weight(shape=(input_dim,),\n-                                           initializer='one',\n-                                           name='b_carry')\n-        else:\n-            self.b_carry = None\n-\n-        if self.initial_weights is not None:\n-            self.set_weights(self.initial_weights)\n-            del self.initial_weights\n-        self.built = True\n-\n-    def call(self, x):\n-        y = K.dot(x, self.W_carry)\n-        if self.bias:\n-            y += self.b_carry\n-        transform_weight = activations.sigmoid(y)\n-        y = K.dot(x, self.W)\n-        if self.bias:\n-            y += self.b\n-        act = self.activation(y)\n-        act *= transform_weight\n-        output = act + (1 - transform_weight) * x\n-        return output\n-\n-    def get_config(self):\n-        config = {'init': initializers.serialize(self.init),\n-                  'activation': activations.serialize(self.activation),\n-                  'W_regularizer': regularizers.serialize(self.W_regularizer),\n-                  'b_regularizer': regularizers.serialize(self.b_regularizer),\n-                  'activity_regularizer':\n-                      regularizers.serialize(self.activity_regularizer),\n-                  'W_constraint': constraints.serialize(self.W_constraint),\n-                  'b_constraint': constraints.serialize(self.b_constraint),\n-                  'bias': self.bias,\n-                  'input_dim': self.input_dim}\n-        base_config = super(Highway, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-def AtrousConvolution1D(*args, **kwargs):\n-    from ..layers import Conv1D\n-    if 'atrous_rate' in kwargs:\n-        rate = kwargs.pop('atrous_rate')\n-    else:\n-        rate = 1\n-    kwargs['dilation_rate'] = rate\n-    warnings.warn('The `AtrousConvolution1D` layer '\n-                  ' has been deprecated. Use instead '\n-                  'the `Conv1D` layer with the `dilation_rate` '\n-                  'argument.')\n-    return Conv1D(*args, **kwargs)\n-\n-\n-def AtrousConvolution2D(*args, **kwargs):\n-    from ..layers import Conv2D\n-    if 'atrous_rate' in kwargs:\n-        rate = kwargs.pop('atrous_rate')\n-    else:\n-        rate = 1\n-    kwargs['dilation_rate'] = rate\n-    warnings.warn('The `AtrousConvolution2D` layer '\n-                  ' has been deprecated. Use instead '\n-                  'the `Conv2D` layer with the `dilation_rate` '\n-                  'argument.')\n-    return Conv2D(*args, **kwargs)\n-\n-\n-class Recurrent(Layer):\n-    \"\"\"Abstract base class for recurrent layers.\n-\n-    Do not use in a model -- it's not a valid layer!\n-    Use its children classes `LSTM`, `GRU` and `SimpleRNN` instead.\n-    All recurrent layers (`LSTM`, `GRU`, `SimpleRNN`) also\n-    follow the specifications of this class and accept\n-    the keyword arguments listed below.\n-\n-    # Example\n-\n-    ```python\n-        # as the first layer in a Sequential model\n-        model = Sequential()\n-        model.add(LSTM(32, input_shape=(10, 64)))\n-        # now model.output_shape == (None, 32)\n-        # note: `None` is the batch dimension.\n-        # for subsequent layers, no need to specify the input size:\n-        model.add(LSTM(16))\n-        # to stack recurrent layers, you must use return_sequences=True\n-        # on any recurrent layer that feeds into another recurrent layer.\n-        # note that you only need to specify the input size on the first layer.\n-        model = Sequential()\n-        model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n-        model.add(LSTM(32, return_sequences=True))\n-        model.add(LSTM(10))\n-    ```\n-\n-    # Arguments\n-        weights: list of Numpy arrays to set as initial weights.\n-            The list should have 3 elements, of shapes:\n-            `[(input_dim, output_dim), (output_dim, output_dim), (output_dim,)]`.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-        implementation: one of {0, 1, or 2}.\n-            If set to 0, the RNN will use\n-            an implementation that uses fewer, larger matrix products,\n-            thus running faster on CPU but consuming more memory.\n-            If set to 1, the RNN will use more matrix products,\n-            but smaller ones, thus running slower\n-            (may actually be faster on GPU) while consuming less memory.\n-            If set to 2 (LSTM/GRU only),\n-            the RNN will combine the input gate,\n-            the forget gate and the output gate into a single matrix,\n-            enabling more time-efficient parallelization on the GPU.\n-            Note: RNN dropout must be shared for all gates,\n-            resulting in a slightly reduced regularization.\n-        input_dim: dimensionality of the input (integer).\n-            This argument (or alternatively, the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, to be specified\n-            when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-            Note that if the recurrent layer is not the first layer\n-            in your model, you would need to specify the input length\n-            at the level of the first layer\n-            (e.g. via the `input_shape` argument)\n-\n-    # Input shapes\n-        3D tensor with shape `(batch_size, timesteps, input_dim)`,\n-        (Optional) 2D tensors with shape `(batch_size, output_dim)`.\n-\n-    # Output shape\n-        - if `return_state`: a list of tensors. The first tensor is\n-            the output. The remaining tensors are the last states,\n-            each with shape `(batch_size, units)`.\n-        - if `return_sequences`: 3D tensor with shape\n-            `(batch_size, timesteps, units)`.\n-        - else, 2D tensor with shape `(batch_size, units)`.\n-\n-    # Masking\n-        This layer supports masking for input data with a variable number\n-        of timesteps. To introduce masks to your data,\n-        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-        set to `True`.\n-\n-    # Note on using statefulness in RNNs\n-        You can set RNN layers to be 'stateful', which means that the states\n-        computed for the samples in one batch will be reused as initial states\n-        for the samples in the next batch. This assumes a one-to-one mapping\n-        between samples in different successive batches.\n-        To enable statefulness:\n-            - specify `stateful=True` in the layer constructor.\n-            - specify a fixed batch size for your model, by passing\n-                if sequential model:\n-                  `batch_input_shape=(...)` to the first layer in your model.\n-                else for functional model with 1 or more Input layers:\n-                  `batch_shape=(...)` to all the first layers in your model.\n-                This is the expected shape of your inputs\n-                *including the batch size*.\n-                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n-            - specify `shuffle=False` when calling fit().\n-        To reset the states of your model, call `.reset_states()` on either\n-        a specific layer, or on your entire model.\n-\n-    # Note on specifying the initial state of RNNs\n-        You can specify the initial state of RNN layers symbolically by\n-        calling them with the keyword argument `initial_state`. The value of\n-        `initial_state` should be a tensor or list of tensors representing\n-        the initial state of the RNN layer.\n-        You can specify the initial state of RNN layers numerically by\n-        calling `reset_states` with the keyword argument `states`. The value of\n-        `states` should be a numpy array or list of numpy arrays representing\n-        the initial state of the RNN layer.\n-    \"\"\"\n-\n-    def __init__(self, return_sequences=False,\n-                 return_state=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 unroll=False,\n-                 implementation=0,\n-                 **kwargs):\n-        super(Recurrent, self).__init__(**kwargs)\n-        self.return_sequences = return_sequences\n-        self.return_state = return_state\n-        self.go_backwards = go_backwards\n-\n-        self.stateful = stateful\n-        self.unroll = unroll\n-        self.implementation = implementation\n-        self.supports_masking = True\n-        self.input_spec = [InputSpec(ndim=3)]\n-        self.state_spec = None\n-        self.dropout = 0\n-        self.recurrent_dropout = 0\n-\n-    def compute_output_shape(self, input_shape):\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-\n-        if self.return_sequences:\n-            output_shape = (input_shape[0], input_shape[1], self.units)\n-        else:\n-            output_shape = (input_shape[0], self.units)\n-\n-        if self.return_state:\n-            state_shape = [(input_shape[0], self.units) for _ in self.states]\n-            return [output_shape] + state_shape\n-        else:\n-            return output_shape\n-\n-    def compute_mask(self, inputs, mask):\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-        output_mask = mask if self.return_sequences else None\n-        if self.return_state:\n-            state_mask = [None for _ in self.states]\n-            return [output_mask] + state_mask\n-        else:\n-            return output_mask\n-\n-    def step(self, inputs, states):\n-        raise NotImplementedError\n-\n-    def get_constants(self, inputs, training=None):\n-        return []\n-\n-    def get_initial_state(self, inputs):\n-        # build an all-zero tensor of shape (samples, output_dim)\n-        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n-        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n-        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n-        # (samples, output_dim)\n-        initial_state = K.tile(initial_state, [1, self.units])\n-        initial_state = [initial_state for _ in range(len(self.states))]\n-        return initial_state\n-\n-    def preprocess_input(self, inputs, training=None):\n-        return inputs\n-\n-    def __call__(self, inputs, initial_state=None, **kwargs):\n-\n-        # If there are multiple inputs, then\n-        # they should be the main input and `initial_state`\n-        # e.g. when loading model from file\n-        if (isinstance(inputs, (list, tuple))\n-                and len(inputs) > 1 and initial_state is None):\n-            initial_state = inputs[1:]\n-            inputs = inputs[0]\n-\n-        # If `initial_state` is specified,\n-        # and if it a Keras tensor,\n-        # then add it to the inputs and temporarily\n-        # modify the input spec to include the state.\n-        if initial_state is None:\n-            return super(Recurrent, self).__call__(inputs, **kwargs)\n-\n-        initial_state = to_list(initial_state, allow_tuple=True)\n-\n-        is_keras_tensor = hasattr(initial_state[0], '_keras_history')\n-        for tensor in initial_state:\n-            if hasattr(tensor, '_keras_history') != is_keras_tensor:\n-                raise ValueError('The initial state of an RNN layer cannot be'\n-                                 ' specified with a mix of Keras tensors and'\n-                                 ' non-Keras tensors')\n-\n-        if is_keras_tensor:\n-            # Compute the full input spec, including state\n-            input_spec = self.input_spec\n-            state_spec = self.state_spec\n-            input_spec = to_list(input_spec)\n-            state_spec = to_list(state_spec)\n-            self.input_spec = input_spec + state_spec\n-\n-            # Compute the full inputs, including state\n-            inputs = [inputs] + list(initial_state)\n-\n-            # Perform the call\n-            output = super(Recurrent, self).__call__(inputs, **kwargs)\n-\n-            # Restore original input spec\n-            self.input_spec = input_spec\n-            return output\n-        else:\n-            kwargs['initial_state'] = initial_state\n-            return super(Recurrent, self).__call__(inputs, **kwargs)\n-\n-    def call(self, inputs, mask=None, training=None, initial_state=None):\n-        # input shape: `(samples, time (padded with zeros), input_dim)`\n-        # note that the .build() method of subclasses MUST define\n-        # self.input_spec and self.state_spec with complete input shapes.\n-        if isinstance(inputs, list):\n-            initial_state = inputs[1:]\n-            inputs = inputs[0]\n-        elif initial_state is not None:\n-            pass\n-        elif self.stateful:\n-            initial_state = self.states\n-        else:\n-            initial_state = self.get_initial_state(inputs)\n-\n-        if isinstance(mask, list):\n-            mask = mask[0]\n-\n-        if len(initial_state) != len(self.states):\n-            raise ValueError('Layer has ' + str(len(self.states)) +\n-                             ' states but was passed ' +\n-                             str(len(initial_state)) +\n-                             ' initial states.')\n-        input_shape = K.int_shape(inputs)\n-        timesteps = input_shape[1]\n-        if self.unroll and timesteps in [None, 1]:\n-            raise ValueError('Cannot unroll a RNN if the '\n-                             'time dimension is undefined or equal to 1. \\n'\n-                             '- If using a Sequential model, '\n-                             'specify the time dimension by passing '\n-                             'an `input_shape` or `batch_input_shape` '\n-                             'argument to your first layer. If your '\n-                             'first layer is an Embedding, you can '\n-                             'also use the `input_length` argument.\\n'\n-                             '- If using the functional API, specify '\n-                             'the time dimension by passing a `shape` '\n-                             'or `batch_shape` argument to your Input layer.')\n-        constants = self.get_constants(inputs, training=None)\n-        preprocessed_input = self.preprocess_input(inputs, training=None)\n-        last_output, outputs, states = K.rnn(self.step,\n-                                             preprocessed_input,\n-                                             initial_state,\n-                                             go_backwards=self.go_backwards,\n-                                             mask=mask,\n-                                             constants=constants,\n-                                             unroll=self.unroll,\n-                                             input_length=timesteps)\n-        if self.stateful:\n-            updates = []\n-            for i in range(len(states)):\n-                updates.append((self.states[i], states[i]))\n-            self.add_update(updates, inputs)\n-\n-        # Properly set learning phase\n-        if 0 < self.dropout + self.recurrent_dropout:\n-            last_output._uses_learning_phase = True\n-            outputs._uses_learning_phase = True\n-\n-        if self.return_sequences:\n-            output = outputs\n-        else:\n-            output = last_output\n-\n-        if self.return_state:\n-            states = to_list(states, allow_tuple=True)\n-            return [output] + states\n-        else:\n-            return output\n-\n-    def reset_states(self, states=None):\n-        if not self.stateful:\n-            raise AttributeError('Layer must be stateful.')\n-        batch_size = self.input_spec[0].shape[0]\n-        if not batch_size:\n-            raise ValueError('If a RNN is stateful, it needs to know '\n-                             'its batch size. Specify the batch size '\n-                             'of your input tensors: \\n'\n-                             '- If using a Sequential model, '\n-                             'specify the batch size by passing '\n-                             'a `batch_input_shape` '\n-                             'argument to your first layer.\\n'\n-                             '- If using the functional API, specify '\n-                             'the time dimension by passing a '\n-                             '`batch_shape` argument to your Input layer.')\n-        # initialize state if None\n-        if self.states[0] is None:\n-            self.states = [K.zeros((batch_size, self.units))\n-                           for _ in self.states]\n-        elif states is None:\n-            for state in self.states:\n-                K.set_value(state, np.zeros((batch_size, self.units)))\n-        else:\n-            states = to_list(states, allow_tuple=True)\n-            if len(states) != len(self.states):\n-                raise ValueError('Layer ' + self.name + ' expects ' +\n-                                 str(len(self.states)) + ' states, '\n-                                 'but it received ' + str(len(states)) +\n-                                 ' state values. Input received: ' +\n-                                 str(states))\n-            for index, (value, state) in enumerate(zip(states, self.states)):\n-                if value.shape != (batch_size, self.units):\n-                    raise ValueError('State ' + str(index) +\n-                                     ' is incompatible with layer ' +\n-                                     self.name + ': expected shape=' +\n-                                     str((batch_size, self.units)) +\n-                                     ', found shape=' + str(value.shape))\n-                K.set_value(state, value)\n-\n-    def get_config(self):\n-        config = {'return_sequences': self.return_sequences,\n-                  'return_state': self.return_state,\n-                  'go_backwards': self.go_backwards,\n-                  'stateful': self.stateful,\n-                  'unroll': self.unroll,\n-                  'implementation': self.implementation}\n-        base_config = super(Recurrent, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class ConvRecurrent2D(Recurrent):\n-    \"\"\"Abstract base class for convolutional recurrent layers.\n-\n-    Do not use in a model -- it's not a functional layer!\n-\n-    # Arguments\n-        filters: Integer, the dimensionality of the output space\n-            (i.e. the number output of filters in the convolution).\n-        kernel_size: An integer or tuple/list of n integers, specifying the\n-            dimensions of the convolution window.\n-        strides: An integer or tuple/list of n integers,\n-            specifying the strides of the convolution.\n-            Specifying any stride value != 1 is incompatible with specifying\n-            any `dilation_rate` value != 1.\n-        padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n-        data_format: A string,\n-            one of `channels_last` (default) or `channels_first`.\n-            The ordering of the dimensions in the inputs.\n-            `channels_last` corresponds to inputs with shape\n-            `(batch, time, ..., channels)`\n-            while `channels_first` corresponds to\n-            inputs with shape `(batch, time, channels, ...)`.\n-            It defaults to the `image_data_format` value found in your\n-            Keras config file at `~/.keras/keras.json`.\n-            If you never set it, then it will be \"channels_last\".\n-        dilation_rate: An integer or tuple/list of n integers, specifying\n-            the dilation rate to use for dilated convolution.\n-            Currently, specifying any `dilation_rate` value != 1 is\n-            incompatible with specifying any `strides` value != 1.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-\n-    # Input shape\n-        5D tensor with shape `(num_samples, timesteps, channels, rows, cols)`.\n-\n-    # Output shape\n-        - if `return_sequences`: 5D tensor with shape\n-            `(num_samples, timesteps, channels, rows, cols)`.\n-        - else, 4D tensor with shape `(num_samples, channels, rows, cols)`.\n-\n-    # Masking\n-        This layer supports masking for input data with a variable number\n-        of timesteps. To introduce masks to your data,\n-        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-        set to `True`.\n-        **Note:** for the time being, masking is only supported with Theano.\n-\n-    # Note on using statefulness in RNNs\n-        You can set RNN layers to be 'stateful', which means that the states\n-        computed for the samples in one batch will be reused as initial states\n-        for the samples in the next batch.\n-        This assumes a one-to-one mapping between\n-        samples in different successive batches.\n-\n-        To enable statefulness:\n-            - specify `stateful=True` in the layer constructor.\n-            - specify a fixed batch size for your model, by passing\n-                a `batch_input_size=(...)` to the first layer in your model.\n-                This is the expected shape of your inputs *including the batch\n-                size*.\n-                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n-\n-        To reset the states of your model, call `.reset_states()` on either\n-        a specific layer, or on your entire model.\n-    \"\"\"\n-\n-    def __init__(self, filters,\n-                 kernel_size,\n-                 strides=(1, 1),\n-                 padding='valid',\n-                 data_format=None,\n-                 dilation_rate=(1, 1),\n-                 return_sequences=False,\n-                 go_backwards=False,\n-                 stateful=False,\n-                 **kwargs):\n-        super(ConvRecurrent2D, self).__init__(**kwargs)\n-        self.filters = filters\n-        self.kernel_size = conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')\n-        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n-        self.padding = conv_utils.normalize_padding(padding)\n-        self.data_format = K.normalize_data_format(data_format)\n-        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, 2,\n-                                                        'dilation_rate')\n-        self.return_sequences = return_sequences\n-        self.go_backwards = go_backwards\n-        self.stateful = stateful\n-        self.input_spec = [InputSpec(ndim=5)]\n-        self.state_spec = None\n-\n-    def compute_output_shape(self, input_shape):\n-        if isinstance(input_shape, list):\n-            input_shape = input_shape[0]\n-        if self.data_format == 'channels_first':\n-            rows = input_shape[3]\n-            cols = input_shape[4]\n-        elif self.data_format == 'channels_last':\n-            rows = input_shape[2]\n-            cols = input_shape[3]\n-        rows = conv_utils.conv_output_length(rows,\n-                                             self.kernel_size[0],\n-                                             padding=self.padding,\n-                                             stride=self.strides[0],\n-                                             dilation=self.dilation_rate[0])\n-        cols = conv_utils.conv_output_length(cols,\n-                                             self.kernel_size[1],\n-                                             padding=self.padding,\n-                                             stride=self.strides[1],\n-                                             dilation=self.dilation_rate[1])\n-        if self.return_sequences:\n-            if self.data_format == 'channels_first':\n-                output_shape = (input_shape[0], input_shape[1],\n-                                self.filters, rows, cols)\n-            elif self.data_format == 'channels_last':\n-                output_shape = (input_shape[0], input_shape[1],\n-                                rows, cols, self.filters)\n-        else:\n-            if self.data_format == 'channels_first':\n-                output_shape = (input_shape[0], self.filters, rows, cols)\n-            elif self.data_format == 'channels_last':\n-                output_shape = (input_shape[0], rows, cols, self.filters)\n-\n-        if self.return_state:\n-            if self.data_format == 'channels_first':\n-                state_shape = (input_shape[0], self.filters, rows, cols)\n-            elif self.data_format == 'channels_last':\n-                state_shape = (input_shape[0], rows, cols, self.filters)\n-            output_shape = [output_shape, state_shape, state_shape]\n-\n-        return output_shape\n-\n-    def get_config(self):\n-        config = {'filters': self.filters,\n-                  'kernel_size': self.kernel_size,\n-                  'strides': self.strides,\n-                  'padding': self.padding,\n-                  'data_format': self.data_format,\n-                  'dilation_rate': self.dilation_rate,\n-                  'return_sequences': self.return_sequences,\n-                  'go_backwards': self.go_backwards,\n-                  'stateful': self.stateful}\n-        base_config = super(ConvRecurrent2D, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n\n@@ -1,802 +1,2 @@\n-\"\"\"Built-in loss functions.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import abc\n-import six\n-\n-from . import backend as K\n-from .utils import losses_utils\n-from .utils.generic_utils import deserialize_keras_object\n-from .utils.generic_utils import serialize_keras_object\n-\n-\n-@six.add_metaclass(abc.ABCMeta)\n-class Loss(object):\n-    \"\"\"Loss base class.\n-\n-    To be implemented by subclasses:\n-        * `call()`: Contains the logic for loss calculation using `y_true`, `y_pred`.\n-\n-    Example subclass implementation:\n-    ```python\n-    class MeanSquaredError(Loss):\n-        def call(self, y_true, y_pred):\n-            y_pred = ops.convert_to_tensor(y_pred)\n-            y_true = math_ops.cast(y_true, y_pred.dtype)\n-            return K.mean(math_ops.square(y_pred - y_true), axis=-1)\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss Reduction to apply to loss.\n-          Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: Optional name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name=None):\n-        self.reduction = reduction\n-        self.name = name\n-\n-    def __call__(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Invokes the `Loss` instance.\n-\n-        # Arguments\n-            y_true: Ground truth values.\n-            y_pred: The predicted values.\n-            sample_weight: Optional `Tensor` whose rank is either 0, or the same rank\n-            as `y_true`, or is broadcastable to `y_true`. `sample_weight` acts as a\n-            coefficient for the loss. If a scalar is provided, then the loss is\n-            simply scaled by the given value. If `sample_weight` is a tensor of size\n-            `[batch_size]`, then the total loss for each sample of the batch is\n-            rescaled by the corresponding element in the `sample_weight` vector. If\n-            the shape of `sample_weight` matches the shape of `y_pred`, then the\n-            loss of each measurable element of `y_pred` is scaled by the\n-            corresponding value of `sample_weight`.\n-\n-        # Returns\n-            Weighted loss float `Tensor`. If `reduction` is `NONE`, this has the same\n-                shape as `y_true`; otherwise, it is scalar.\n-\n-        # Raises\n-            ValueError: If the shape of `sample_weight` is invalid.\n-        \"\"\"\n-        # If we are wrapping a lambda function strip '<>' from the name as it is not\n-        # accepted in scope name.\n-        scope_name = 'lambda' if self.name == '<lambda>' else self.name\n-        with K.name_scope(scope_name):\n-            losses = self.call(y_true, y_pred)\n-            return losses_utils.compute_weighted_loss(\n-                losses, sample_weight, reduction=self.reduction)\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        \"\"\"Instantiates a `Loss` from its config (output of `get_config()`).\n-\n-        # Arguments\n-            config: Output of `get_config()`.\n-\n-        # Returns\n-            A `Loss` instance.\n-        \"\"\"\n-        return cls(**config)\n-\n-    def get_config(self):\n-        return {'reduction': self.reduction, 'name': self.name}\n-\n-    @abc.abstractmethod\n-    def call(self, y_true, y_pred):\n-        \"\"\"Invokes the `Loss` instance.\n-\n-        # Arguments\n-            y_true: Ground truth values, with the same shape as 'y_pred'.\n-            y_pred: The predicted values.\n-        \"\"\"\n-        raise NotImplementedError('Must be implemented in subclasses.')\n-\n-\n-class LossFunctionWrapper(Loss):\n-    \"\"\"Wraps a loss function in the `Loss` class.\n-\n-    # Arguments\n-        fn: The loss function to wrap, with signature `fn(y_true, y_pred,\n-            **kwargs)`.\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) name for the loss.\n-        **kwargs: The keyword arguments that are passed on to `fn`.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 fn,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name=None,\n-                 **kwargs):\n-        super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n-        self.fn = fn\n-        self._fn_kwargs = kwargs\n-\n-    def call(self, y_true, y_pred):\n-        \"\"\"Invokes the `LossFunctionWrapper` instance.\n-\n-        # Arguments\n-            y_true: Ground truth values.\n-            y_pred: The predicted values.\n-\n-        # Returns\n-            Loss values per sample.\n-        \"\"\"\n-        return self.fn(y_true, y_pred, **self._fn_kwargs)\n-\n-    def get_config(self):\n-        config = {}\n-        for k, v in six.iteritems(self._fn_kwargs):\n-            config[k] = K.eval(v) if K.is_tensor(v) or K.is_variable(v) else v\n-        base_config = super(LossFunctionWrapper, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MeanSquaredError(LossFunctionWrapper):\n-    \"\"\"Computes the mean of squares of errors between labels and predictions.\n-\n-    Standalone usage:\n-\n-    ```python\n-    mse = keras.losses.MeanSquaredError()\n-    loss = mse([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.MeanSquaredError())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) name for the loss.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='mean_squared_error'):\n-        super(MeanSquaredError, self).__init__(\n-            mean_squared_error, name=name, reduction=reduction)\n-\n-\n-class MeanAbsoluteError(LossFunctionWrapper):\n-    \"\"\"Computes the mean of absolute difference between labels and predictions.\n-\n-    Standalone usage:\n-\n-    ```python\n-    mae = keras.losses.MeanAbsoluteError()\n-    loss = mae([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.MeanAbsoluteError())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) name for the loss.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='mean_absolute_error'):\n-        super(MeanAbsoluteError, self).__init__(\n-            mean_absolute_error, name=name, reduction=reduction)\n-\n-\n-class MeanAbsolutePercentageError(LossFunctionWrapper):\n-    \"\"\"Computes the mean absolute percentage error between `y_true` and `y_pred`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    mape = keras.losses.MeanAbsolutePercentageError()\n-    loss = mape([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.MeanAbsolutePercentageError())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) name for the loss.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='mean_absolute_percentage_error'):\n-        super(MeanAbsolutePercentageError, self).__init__(\n-            mean_absolute_percentage_error, name=name, reduction=reduction)\n-\n-\n-class MeanSquaredLogarithmicError(LossFunctionWrapper):\n-    \"\"\"Computes the mean squared logarithmic error between `y_true` and `y_pred`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    msle = keras.losses.MeanSquaredLogarithmicError()\n-    loss = msle([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.MeanSquaredLogarithmicError())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) name for the loss.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='mean_squared_logarithmic_error'):\n-        super(MeanSquaredLogarithmicError, self).__init__(\n-            mean_squared_logarithmic_error, name=name, reduction=reduction)\n-\n-\n-class BinaryCrossentropy(LossFunctionWrapper):\n-    \"\"\"Computes the cross-entropy loss between true labels and predicted labels.\n-\n-    Use this cross-entropy loss when there are only two label classes (assumed to\n-    be 0 and 1). For each example, there should be a single floating-point value\n-    per prediction.\n-\n-    In the snippet below, each of the four examples has only a single\n-    floating-pointing value, and both `y_pred` and `y_true` have the shape\n-    `[batch_size]`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    bce = keras.losses.BinaryCrossentropy()\n-    loss = bce([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.BinaryCrossentropy())\n-    ```\n-\n-    # Arguments\n-        from_logits: Whether to interpret `y_pred` as a tensor of\n-            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n-            we assume that `y_pred` contains probabilities\n-            (i.e., values in [0, 1]).\n-        label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0, we\n-            compute the loss between the predicted labels and a smoothed version of\n-            the true labels, where the smoothing squeezes the labels towards 0.5.\n-            Larger values of `label_smoothing` correspond to heavier smoothing.\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 from_logits=False,\n-                 label_smoothing=0,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='binary_crossentropy'):\n-        super(BinaryCrossentropy, self).__init__(\n-            binary_crossentropy,\n-            name=name,\n-            reduction=reduction,\n-            from_logits=from_logits,\n-            label_smoothing=label_smoothing)\n-        self.from_logits = from_logits\n-\n-\n-class CategoricalCrossentropy(LossFunctionWrapper):\n-    \"\"\"Computes the crossentropy loss between the labels and predictions.\n-\n-    Use this crossentropy loss function when there are two or more label classes.\n-    We expect labels to be provided in a `one_hot` representation. If you want to\n-    provide labels as integers, please use `SparseCategoricalCrossentropy` loss.\n-    There should be `# classes` floating point values per feature.\n-\n-    In the snippet below, there is `# classes` floating pointing values per\n-    example. The shape of both `y_pred` and `y_true` are\n-    `[batch_size, num_classes]`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    cce = keras.losses.CategoricalCrossentropy()\n-    loss = cce(\n-        [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]],\n-        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.CategoricalCrossentropy())\n-    ```\n-\n-    # Arguments\n-        from_logits: Whether to interpret `y_pred` as a tensor of\n-            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n-            we assume that `y_pred` contains probabilities\n-            (i.e., values in [0, 1]).\n-        label_smoothing: Float in [0, 1]. When 0, no smoothing occurs. When > 0, we\n-            compute the loss between the predicted labels and a smoothed version of\n-            the true labels, where the smoothing squeezes the labels towards 0.5.\n-            Larger values of `label_smoothing` correspond to heavier smoothing.\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 from_logits=False,\n-                 label_smoothing=0,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='categorical_crossentropy'):\n-        super(CategoricalCrossentropy, self).__init__(\n-            categorical_crossentropy,\n-            name=name,\n-            reduction=reduction,\n-            from_logits=from_logits,\n-            label_smoothing=label_smoothing)\n-\n-\n-class SparseCategoricalCrossentropy(LossFunctionWrapper):\n-    \"\"\"Computes the crossentropy loss between the labels and predictions.\n-\n-    Use this crossentropy loss function when there are two or more label classes.\n-    We expect labels to be provided as integers. If you want to provide labels\n-    using `one-hot` representation, please use `CategoricalCrossentropy` loss.\n-    There should be `# classes` floating point values per feature for `y_pred`\n-    and a single floating point value per feature for `y_true`.\n-\n-    In the snippet below, there is a single floating point value per example for\n-    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n-    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n-    `[batch_size, num_classes]`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    cce = keras.losses.SparseCategoricalCrossentropy()\n-    loss = cce(\n-        [0, 1, 2],\n-        [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.SparseCategoricalCrossentropy())\n-    ```\n-\n-    # Arguments\n-        from_logits: Whether to interpret `y_pred` as a tensor of\n-            [logit](https://en.wikipedia.org/wiki/Logit) values. By default,\n-            we assume that `y_pred` contains probabilities\n-            (i.e., values in [0, 1]).\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 from_logits=False,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='sparse_categorical_crossentropy'):\n-        super(SparseCategoricalCrossentropy, self).__init__(\n-            sparse_categorical_crossentropy,\n-            name=name,\n-            reduction=reduction,\n-            from_logits=from_logits)\n-\n-\n-class Hinge(LossFunctionWrapper):\n-    \"\"\"Computes the hinge loss between `y_true` and `y_pred`.\n-\n-    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n-    provided we will convert them to -1 or 1.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.Hinge())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='hinge'):\n-        super(Hinge, self).__init__(hinge, name=name, reduction=reduction)\n-\n-\n-class SquaredHinge(LossFunctionWrapper):\n-    \"\"\"Computes the squared hinge loss between `y_true` and `y_pred`.\n-\n-    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n-    provided we will convert them to -1 or 1.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.SquaredHinge())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='squared_hinge'):\n-        super(SquaredHinge, self).__init__(\n-            squared_hinge, name=name, reduction=reduction)\n-\n-\n-class CategoricalHinge(LossFunctionWrapper):\n-    \"\"\"Computes the categorical hinge loss between `y_true` and `y_pred`.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.CategoricalHinge())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='categorical_hinge'):\n-        super(CategoricalHinge, self).__init__(\n-            categorical_hinge, name=name, reduction=reduction)\n-\n-\n-class Poisson(LossFunctionWrapper):\n-    \"\"\"Computes the Poisson loss between `y_true` and `y_pred`.\n-\n-    `loss = y_pred - y_true * log(y_pred)`\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.Poisson())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='poisson'):\n-        super(Poisson, self).__init__(poisson, name=name, reduction=reduction)\n-\n-\n-class LogCosh(LossFunctionWrapper):\n-    \"\"\"Computes the logarithm of the hyperbolic cosine of the prediction error.\n-\n-    `logcosh = log((exp(x) + exp(-x))/2)`,\n-    where x is the error (y_pred - y_true)\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.LogCosh())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='logcosh'):\n-        super(LogCosh, self).__init__(logcosh, name=name, reduction=reduction)\n-\n-\n-class KLDivergence(LossFunctionWrapper):\n-    \"\"\"Computes Kullback-Leibler divergence loss between `y_true` and `y_pred`.\n-\n-    `loss = y_true * log(y_true / y_pred)`\n-\n-    See: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.KLDivergence())\n-    ```\n-\n-    # Arguments\n-        reduction: (Optional) Type of loss reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: (Optional) Name for the object.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='kullback_leibler_divergence'):\n-        super(KLDivergence, self).__init__(\n-            kullback_leibler_divergence, name=name, reduction=reduction)\n-\n-\n-class Huber(LossFunctionWrapper):\n-    \"\"\"Computes the Huber loss between `y_true` and `y_pred`.\n-\n-    Given `x = y_true - y_pred`:\n-    ```\n-    loss = 0.5 * x^2                  if |x| <= d\n-    loss = 0.5 * d^2 + d * (|x| - d)  if |x| > d\n-    ```\n-    where d is `delta`. See: https://en.wikipedia.org/wiki/Huber_loss\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss=keras.losses.Huber())\n-    ```\n-\n-    # Arguments\n-        delta: A float, the point where the Huber loss function changes from a\n-            quadratic to linear.\n-        reduction: (Optional) Type of reduction to apply to loss.\n-        name: Optional name for the object.\n-    \"\"\"\n-    def __init__(self,\n-                 delta=1.0,\n-                 reduction=losses_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                 name='huber_loss'):\n-        super(Huber, self).__init__(\n-            huber_loss, name=name, reduction=reduction, delta=delta)\n-\n-\n-def mean_squared_error(y_true, y_pred):\n-    if not K.is_tensor(y_pred):\n-        y_pred = K.constant(y_pred)\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    return K.mean(K.square(y_pred - y_true), axis=-1)\n-\n-\n-def mean_absolute_error(y_true, y_pred):\n-    if not K.is_tensor(y_pred):\n-        y_pred = K.constant(y_pred)\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    return K.mean(K.abs(y_pred - y_true), axis=-1)\n-\n-\n-def mean_absolute_percentage_error(y_true, y_pred):\n-    if not K.is_tensor(y_pred):\n-        y_pred = K.constant(y_pred)\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n-                                            K.epsilon(),\n-                                            None))\n-    return 100. * K.mean(diff, axis=-1)\n-\n-\n-def mean_squared_logarithmic_error(y_true, y_pred):\n-    if not K.is_tensor(y_pred):\n-        y_pred = K.constant(y_pred)\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n-    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n-    return K.mean(K.square(first_log - second_log), axis=-1)\n-\n-\n-def squared_hinge(y_true, y_pred):\n-    y_true = _maybe_convert_labels(y_true)\n-    return K.mean(K.square(K.maximum(1. - y_true * y_pred, 0.)), axis=-1)\n-\n-\n-def hinge(y_true, y_pred):\n-    y_true = _maybe_convert_labels(y_true)\n-    return K.mean(K.maximum(1. - y_true * y_pred, 0.), axis=-1)\n-\n-\n-def categorical_hinge(y_true, y_pred):\n-    pos = K.sum(y_true * y_pred, axis=-1)\n-    neg = K.max((1. - y_true) * y_pred, axis=-1)\n-    return K.maximum(0., neg - pos + 1.)\n-\n-\n-def logcosh(y_true, y_pred):\n-    \"\"\"Logarithm of the hyperbolic cosine of the prediction error.\n-\n-    `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n-    to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n-    like the mean squared error, but will not be so strongly affected by the\n-    occasional wildly incorrect prediction.\n-\n-    # Arguments\n-        y_true: tensor of true targets.\n-        y_pred: tensor of predicted targets.\n-\n-    # Returns\n-        Tensor with one scalar loss entry per sample.\n-    \"\"\"\n-    def _logcosh(x):\n-        return x + K.softplus(-2. * x) - K.log(2.)\n-    return K.mean(_logcosh(y_pred - y_true), axis=-1)\n-\n-\n-def huber_loss(y_true, y_pred, delta=1.0):\n-    error = y_pred - y_true\n-    abs_error = K.abs(error)\n-    quadratic = K.minimum(abs_error, delta)\n-    linear = abs_error - quadratic\n-    return 0.5 * K.square(quadratic) + delta * linear\n-\n-\n-def categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n-    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n-    y_true = K.cast(y_true, y_pred.dtype)\n-\n-    if label_smoothing is not 0:\n-        smoothing = K.cast_to_floatx(label_smoothing)\n-\n-        def _smooth_labels():\n-            num_classes = K.cast(K.shape(y_true)[1], y_pred.dtype)\n-            return y_true * (1.0 - smoothing) + (smoothing / num_classes)\n-\n-        y_true = K.switch(K.greater(smoothing, 0), _smooth_labels, lambda: y_true)\n-    return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n-\n-\n-def sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1):\n-    return K.sparse_categorical_crossentropy(\n-        y_true, y_pred, from_logits=from_logits, axis=axis)\n-\n-\n-def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n-    y_pred = K.constant(y_pred) if not K.is_tensor(y_pred) else y_pred\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    if label_smoothing is not 0:\n-        smoothing = K.cast_to_floatx(label_smoothing)\n-        y_true = K.switch(K.greater(smoothing, 0),\n-                          lambda: y_true * (1.0 - smoothing) + 0.5 * smoothing,\n-                          lambda: y_true)\n-    return K.mean(\n-        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n-\n-\n-def kullback_leibler_divergence(y_true, y_pred):\n-    y_true = K.clip(y_true, K.epsilon(), 1)\n-    y_pred = K.clip(y_pred, K.epsilon(), 1)\n-    return K.sum(y_true * K.log(y_true / y_pred), axis=-1)\n-\n-\n-def poisson(y_true, y_pred):\n-    return K.mean(y_pred - y_true * K.log(y_pred + K.epsilon()), axis=-1)\n-\n-\n-def cosine_proximity(y_true, y_pred, axis=-1):\n-    y_true = K.l2_normalize(y_true, axis=axis)\n-    y_pred = K.l2_normalize(y_pred, axis=axis)\n-    return - K.sum(y_true * y_pred, axis=axis)\n-\n-\n-def _maybe_convert_labels(y_true):\n-    \"\"\"Converts binary labels into -1/1.\"\"\"\n-    are_zeros = K.equal(y_true, 0)\n-    are_ones = K.equal(y_true, 1)\n-\n-    are_zeros = K.expand_dims(are_zeros, 0)\n-    are_ones = K.expand_dims(are_ones, 0)\n-\n-    are_different = K.concatenate([are_zeros, are_ones], axis=0)\n-    are_different = K.any(are_different, axis=0)\n-    is_binary = K.all(are_different)\n-\n-    def _convert_binary_labels():\n-        # Convert the binary labels to -1 or 1.\n-        return 2. * y_true - 1.\n-\n-    updated_y_true = K.switch(is_binary,\n-                              _convert_binary_labels,\n-                              lambda: y_true)\n-    return updated_y_true\n-\n-\n-# Aliases.\n-\n-mse = MSE = mean_squared_error\n-mae = MAE = mean_absolute_error\n-mape = MAPE = mean_absolute_percentage_error\n-msle = MSLE = mean_squared_logarithmic_error\n-kld = KLD = kullback_leibler_divergence\n-cosine = cosine_similarity = cosine_proximity\n-\n-\n-def is_categorical_crossentropy(loss):\n-    return (isinstance(loss, CategoricalCrossentropy) or\n-            (isinstance(loss, LossFunctionWrapper) and\n-                loss.fn == categorical_crossentropy) or\n-            (hasattr(loss, '__name__') and\n-                loss.__name__ == 'categorical_crossentropy') or\n-            loss == 'categorical_crossentropy')\n-\n-\n-def serialize(loss):\n-    return serialize_keras_object(loss)\n-\n-\n-def deserialize(name, custom_objects=None):\n-    return deserialize_keras_object(name,\n-                                    module_objects=globals(),\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='loss function')\n-\n-\n-def get(identifier):\n-    \"\"\"Get the `identifier` loss function.\n-\n-    # Arguments\n-        identifier: None or str, name of the function.\n-\n-    # Returns\n-        The loss function or None if `identifier` is None.\n-\n-    # Raises\n-        ValueError if unknown identifier.\n-    \"\"\"\n-    if identifier is None:\n-        return None\n-    if isinstance(identifier, six.string_types):\n-        identifier = str(identifier)\n-        return deserialize(identifier)\n-    if isinstance(identifier, dict):\n-        return deserialize(identifier)\n-    elif callable(identifier):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret '\n-                         'loss function identifier:', identifier)\n+\"\"\"Built-in loss functions.\"\"\"\n+from tensorflow.keras.losses import *\n\n@@ -1,1983 +1,2 @@\n-\"\"\"Built-in metrics.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import abc\n-import numpy as np\n-import six\n-import types\n-\n-from . import backend as K\n-from .layers import Layer\n-from .losses import mean_squared_error\n-from .losses import mean_absolute_error\n-from .losses import mean_absolute_percentage_error\n-from .losses import mean_squared_logarithmic_error\n-from .losses import hinge\n-from .losses import logcosh\n-from .losses import squared_hinge\n-from .losses import categorical_hinge\n-from .losses import categorical_crossentropy\n-from .losses import sparse_categorical_crossentropy\n-from .losses import binary_crossentropy\n-from .losses import kullback_leibler_divergence\n-from .losses import poisson\n-from .utils import losses_utils\n-from .utils import metrics_utils\n-from .utils.generic_utils import deserialize_keras_object\n-from .utils.generic_utils import serialize_keras_object\n-\n-\n-@six.add_metaclass(abc.ABCMeta)\n-class Metric(Layer):\n-    \"\"\"Encapsulates metric logic and state.\n-\n-    Standalone usage:\n-    ```python\n-    m = SomeMetric(...)\n-    for input in ...:\n-        m.update_state(input)\n-    m.result()\n-    ```\n-\n-    Usage with the `compile` API:\n-    ```python\n-    model.compile(optimizer='rmsprop',\n-                  loss=keras.losses.categorical_crossentropy,\n-                  metrics=[keras.metrics.CategoricalAccuracy()])\n-    ```\n-\n-    To be implemented by subclasses:\n-    * `__init__()`: All state variables should be created in this method by\n-        calling `self.add_weight()` like: `self.var = self.add_weight(...)`\n-    * `update_state()`: Has all updates to the state variables like:\n-        self.var.assign_add(...).\n-    * `result()`: Computes and returns a value for the metric\n-        from the state variables.\n-    \"\"\"\n-\n-    def __init__(self, name=None, dtype=None, **kwargs):\n-        super(Metric, self).__init__(name=name, dtype=dtype, **kwargs)\n-        self.stateful = True  # All metric layers are stateful.\n-        self.built = True\n-        self.dtype = dtype or K.floatx()\n-\n-    def __new__(cls, *args, **kwargs):\n-        obj = super(Metric, cls).__new__(cls)\n-\n-        obj.update_state = types.MethodType(\n-            metrics_utils.update_state_wrapper(obj.update_state), obj)\n-\n-        obj.result = types.MethodType(\n-            metrics_utils.result_wrapper(obj.result), obj)\n-        return obj\n-\n-    @K.symbolic\n-    def __call__(self, *args, **kwargs):\n-        \"\"\"Accumulates statistics and then computes metric result value.\"\"\"\n-        update_op = self.update_state(*args, **kwargs)\n-        with K.control_dependencies(update_op):  # For TF\n-            result_t = self.result()\n-\n-            # We are adding the metric object as metadata on the result tensor.\n-            # This is required when we want to use a metric with `add_metric` API on\n-            # a Model/Layer in graph mode. This metric instance will later be used\n-            # to reset variable state after each epoch of training.\n-            # Example:\n-            #   model = Model()\n-            #   mean = Mean()\n-            #   model.add_metric(mean(values), name='mean')\n-            result_t._metric_obj = self\n-            return result_t\n-\n-    def get_config(self):\n-        \"\"\"Returns the serializable config of the metric.\"\"\"\n-        return {'name': self.name, 'dtype': self.dtype}\n-\n-    def reset_states(self):\n-        \"\"\"Resets all of the metric state variables.\n-\n-        This function is called between epochs/steps,\n-        when a metric is evaluated during training.\n-        \"\"\"\n-        K.batch_set_value([(v, 0) for v in self.weights])\n-\n-    @abc.abstractmethod\n-    def update_state(self, *args, **kwargs):\n-        \"\"\"Accumulates statistics for the metric. \"\"\"\n-        raise NotImplementedError('Must be implemented in subclasses.')\n-\n-    @abc.abstractmethod\n-    def result(self):\n-        \"\"\"Computes and returns the metric value tensor.\n-\n-        Result computation is an idempotent operation that simply calculates the\n-        metric value using the state variables.\n-        \"\"\"\n-        raise NotImplementedError('Must be implemented in subclasses.')\n-\n-    # For use by subclasses #\n-    def add_weight(self,\n-                   name,\n-                   shape=(),\n-                   initializer=None,\n-                   dtype=None):\n-        \"\"\"Adds state variable. Only for use by subclasses.\"\"\"\n-        return super(Metric, self).add_weight(\n-            name=name,\n-            shape=shape,\n-            dtype=self.dtype if dtype is None else dtype,\n-            trainable=False,\n-            initializer=initializer)\n-\n-    # End: For use by subclasses ###\n-\n-\n-class Reduce(Metric):\n-    \"\"\"Encapsulates metrics that perform a reduce operation on the values.\"\"\"\n-\n-    def __init__(self, reduction, name, dtype=None):\n-        \"\"\"Creates a `Reduce` instance.\n-\n-        # Arguments\n-            reduction: a metrics `Reduction` enum value.\n-            name: string name of the metric instance.\n-            dtype: (Optional) data type of the metric result.\n-        \"\"\"\n-        super(Reduce, self).__init__(name=name, dtype=dtype)\n-        self.reduction = reduction\n-        self.total = self.add_weight(\n-            'total', initializer='zeros')\n-        if reduction in [metrics_utils.Reduction.SUM_OVER_BATCH_SIZE,\n-                         metrics_utils.Reduction.WEIGHTED_MEAN]:\n-            self.count = self.add_weight(\n-                'count', initializer='zeros')\n-\n-    def update_state(self, values, sample_weight=None):\n-        \"\"\"Accumulates statistics for computing the reduction metric.\n-\n-        For example, if `values` is [1, 3, 5, 7] and reduction=SUM_OVER_BATCH_SIZE,\n-        then the value of `result()` is 4. If the `sample_weight` is specified as\n-        [1, 1, 0, 0] then value of `result()` would be 2.\n-\n-        # Arguments\n-            values: Per-example value.\n-            sample_weight: Optional weighting of each example. Defaults to 1.\n-\n-        # Returns\n-            List of update ops.\n-        \"\"\"\n-        values = K.cast(values, self.dtype)\n-        if sample_weight is not None:\n-            sample_weight = K.cast(sample_weight, self.dtype)\n-\n-            # Update dimensions of weights to match with values if possible.\n-            values, _, sample_weight = losses_utils.squeeze_or_expand_dimensions(\n-                values, sample_weight=sample_weight)\n-\n-            # Broadcast weights if possible.\n-            sample_weight = losses_utils.broadcast_weights(values, sample_weight)\n-\n-            values = values * sample_weight\n-\n-        value_sum = K.sum(values)\n-        update_total_op = K.update_add(self.total, value_sum)\n-\n-        # Exit early if the reduction doesn't have a denominator.\n-        if self.reduction == metrics_utils.Reduction.SUM:\n-            return [update_total_op]\n-\n-        # Update `count` for reductions that require a denominator.\n-        if self.reduction == metrics_utils.Reduction.SUM_OVER_BATCH_SIZE:\n-            num_values = K.cast(K.size(values), self.dtype)\n-        elif self.reduction == metrics_utils.Reduction.WEIGHTED_MEAN:\n-            if sample_weight is None:\n-                num_values = K.cast(K.size(values), self.dtype)\n-            else:\n-                num_values = K.sum(sample_weight)\n-        else:\n-            raise NotImplementedError(\n-                'reduction [%s] not implemented' % self.reduction)\n-\n-        return [update_total_op, K.update_add(self.count, num_values)]\n-\n-    def result(self):\n-        if self.reduction == metrics_utils.Reduction.SUM:\n-            return self.total\n-        elif self.reduction in [\n-            metrics_utils.Reduction.WEIGHTED_MEAN,\n-            metrics_utils.Reduction.SUM_OVER_BATCH_SIZE\n-        ]:\n-            return self.total / self.count\n-        else:\n-            raise NotImplementedError(\n-                'reduction [%s] not implemented' % self.reduction)\n-\n-\n-class Sum(Reduce):\n-    \"\"\"Computes the (weighted) sum of the given values.\n-\n-    For example, if values is [1, 3, 5, 7] then the sum is 16.\n-    If the weights were specified as [1, 1, 0, 0] then the sum would be 4.\n-\n-    This metric creates one variable, `total`, that is used to compute the sum of\n-    `values`. This is ultimately returned as `sum`.\n-    If `sample_weight` is `None`, weights default to 1.  Use `sample_weight` of 0\n-    to mask values.\n-\n-    Standalone usage:\n-    ```python\n-    m = keras.metrics.Sum()\n-    m.update_state([1, 3, 5, 7])\n-    m.result()\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='sum', dtype=None):\n-        \"\"\"Creates a `Sum` instance.\n-\n-        # Arguments\n-            name: (Optional) string name of the metric instance.\n-            dtype: (Optional) data type of the metric result.\n-        \"\"\"\n-        super(Sum, self).__init__(reduction=metrics_utils.Reduction.SUM,\n-                                  name=name, dtype=dtype)\n-\n-\n-class Mean(Reduce):\n-    \"\"\"Computes the (weighted) mean of the given values.\n-\n-    For example, if values is [1, 3, 5, 7] then the mean is 4.\n-    If the weights were specified as [1, 1, 0, 0] then the mean would be 2.\n-\n-    This metric creates two variables, `total` and `count` that are used to\n-    compute the average of `values`. This average is ultimately returned as `mean`\n-    which is an idempotent operation that simply divides `total` by `count`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage:\n-\n-    ```python\n-    m = keras.metrics.Mean()\n-    m.update_state([1, 3, 5, 7])\n-    m.result()\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean', dtype=None):\n-        \"\"\"Creates a `Mean` instance.\n-\n-        #Arguments\n-            name: (Optional) string name of the metric instance.\n-            dtype: (Optional) data type of the metric result.\n-        \"\"\"\n-        super(Mean, self).__init__(\n-            reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\n-\n-\n-class MeanMetricWrapper(Mean):\n-    \"\"\"Wraps a stateless metric function with the Mean metric.\"\"\"\n-\n-    def __init__(self, fn, name=None, dtype=None, **kwargs):\n-        \"\"\"Creates a `MeanMetricWrapper` instance.\n-\n-        # Arguments\n-            fn: The metric function to wrap, with signature\n-                `fn(y_true, y_pred, **kwargs)`.\n-            name: (Optional) string name of the metric instance.\n-            dtype: (Optional) data type of the metric result.\n-            **kwargs: The keyword arguments that are passed on to `fn`.\n-        \"\"\"\n-        super(MeanMetricWrapper, self).__init__(name=name, dtype=dtype)\n-        self._fn = fn\n-        self._fn_kwargs = kwargs\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates metric statistics.\n-\n-        `y_true` and `y_pred` should have the same shape.\n-\n-        # Arguments\n-            y_true: The ground truth values.\n-            y_pred: The predicted values.\n-            sample_weight: Optional weighting of each example. Defaults to 1. Can be\n-                a `Tensor` whose rank is either 0, or the same rank as `y_true`,\n-                and must be broadcastable to `y_true`.\n-\n-        # Returns\n-            Update op.\n-        \"\"\"\n-        y_true = K.cast(y_true, self.dtype)\n-        y_pred = K.cast(y_pred, self.dtype)\n-        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n-\n-        matches = self._fn(y_true, y_pred, **self._fn_kwargs)\n-        return super(MeanMetricWrapper, self).update_state(\n-            matches, sample_weight=sample_weight)\n-\n-    def get_config(self):\n-        config = {}\n-        for k, v in six.iteritems(self._fn_kwargs):\n-            config[k] = K.eval(v) if K.is_tensor(v) else v\n-        base_config = super(MeanMetricWrapper, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class MeanSquaredError(MeanMetricWrapper):\n-    \"\"\"Computes the mean squared error between `y_true` and `y_pred`.\n-\n-    Standalone usage:\n-\n-    ```python\n-    m = keras.metrics.MeanSquaredError()\n-    m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    m.result()\n-    ```\n-\n-    Usage with compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.MeanSquaredError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean_squared_error', dtype=None):\n-        super(MeanSquaredError, self).__init__(\n-            mean_squared_error, name, dtype=dtype)\n-\n-\n-class Hinge(MeanMetricWrapper):\n-    \"\"\"Computes the hinge metric between `y_true` and `y_pred`.\n-\n-    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n-    provided we will convert them to -1 or 1.\n-    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n-    the hinge metric value is 1.6.\n-\n-    Usage:\n-\n-    ```python\n-    m = keras.metrics.Hinge()\n-    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n-    # result = max(0, 1-y_true * y_pred) = [1.6 + 1.7 + 1.5] / 3\n-    # Final result: 1.6\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.Hinge()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='hinge', dtype=None):\n-        super(Hinge, self).__init__(hinge, name, dtype=dtype)\n-\n-\n-class SquaredHinge(MeanMetricWrapper):\n-    \"\"\"Computes the squared hinge metric between `y_true` and `y_pred`.\n-\n-    `y_true` values are expected to be -1 or 1. If binary (0 or 1) labels are\n-    provided we will convert them to -1 or 1.\n-    For example, if `y_true` is [-1., 1., 1.], and `y_pred` is [0.6, -0.7, -0.5]\n-    the squared hinge metric value is 2.6.\n-\n-    Usage:\n-\n-    ```python\n-    m = keras.metrics.SquaredHinge()\n-    m.update_state([-1., 1., 1.], [0.6, -0.7, -0.5])\n-    # result = max(0, 1-y_true * y_pred) = [1.6^2 + 1.7^2 + 1.5^2] / 3\n-    # Final result: 2.6\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.SquaredHinge()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='squared_hinge', dtype=None):\n-        super(SquaredHinge, self).__init__(squared_hinge, name, dtype=dtype)\n-\n-\n-class CategoricalHinge(MeanMetricWrapper):\n-    \"\"\"Computes the categorical hinge metric between `y_true` and `y_pred`.\n-\n-    For example, if `y_true` is [0., 1., 1.], and `y_pred` is [1., 0., 1.]\n-    the categorical hinge metric value is 1.0.\n-\n-    Usage:\n-\n-    ```python\n-    m = keras.metrics.CategoricalHinge()\n-    m.update_state([0., 1., 1.], [1., 0., 1.])\n-    # Final result: 1.0\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.CategoricalHinge()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='categorical_hinge', dtype=None):\n-        super(CategoricalHinge, self).__init__(\n-            categorical_hinge, name, dtype=dtype)\n-\n-\n-class Accuracy(MeanMetricWrapper):\n-    \"\"\"Calculates how often predictions matches labels.\n-\n-    For example, if `y_true` is [1, 2, 3, 4] and `y_pred` is [0, 2, 3, 4]\n-    then the accuracy is 3/4 or .75.  If the weights were specified as\n-    [1, 1, 0, 0] then the accuracy would be 1/2 or .5.\n-\n-    This metric creates two local variables, `total` and `count` that are used to\n-    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n-    ultimately returned as `binary accuracy`: an idempotent operation that simply\n-    divides `total` by `count`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    ```\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.Accuracy()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='accuracy', dtype=None):\n-        super(Accuracy, self).__init__(accuracy, name, dtype=dtype)\n-\n-\n-class BinaryAccuracy(MeanMetricWrapper):\n-    \"\"\"Calculates how often predictions matches labels.\n-\n-    For example, if `y_true` is [1, 1, 0, 0] and `y_pred` is [0.98, 1, 0, 0.6]\n-    then the binary accuracy is 3/4 or .75.  If the weights were specified as\n-    [1, 0, 0, 1] then the binary accuracy would be 1/2 or .5.\n-\n-    This metric creates two local variables, `total` and `count` that are used to\n-    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n-    ultimately returned as `binary accuracy`: an idempotent operation that simply\n-    divides `total` by `count`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.BinaryAccuracy()])\n-    ```\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        threshold: (Optional) Float representing the threshold for deciding\n-            whether prediction values are 1 or 0.\n-    \"\"\"\n-\n-    def __init__(self, name='binary_accuracy', dtype=None, threshold=0.5):\n-        super(BinaryAccuracy, self).__init__(\n-            binary_accuracy, name, dtype=dtype, threshold=threshold)\n-\n-\n-class CategoricalAccuracy(MeanMetricWrapper):\n-    \"\"\"Calculates how often predictions matches labels.\n-\n-    For example, if `y_true` is [[0, 0, 1], [0, 1, 0]] and `y_pred` is\n-    [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5.\n-    If the weights were specified as [0.7, 0.3] then the categorical accuracy\n-    would be .3. You can provide logits of classes as `y_pred`, since argmax of\n-    logits and probabilities are same.\n-\n-    This metric creates two local variables, `total` and `count` that are used to\n-    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n-    ultimately returned as `categorical accuracy`: an idempotent operation that\n-    simply divides `total` by `count`.\n-\n-    `y_pred` and `y_true` should be passed in as vectors of probabilities, rather\n-    than as labels. If necessary, use `K.one_hot` to expand `y_true` as a vector.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        loss='mse',\n-        metrics=[keras.metrics.CategoricalAccuracy()])\n-    ```\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, name='categorical_accuracy', dtype=None):\n-        super(CategoricalAccuracy, self).__init__(\n-            categorical_accuracy, name, dtype=dtype)\n-\n-\n-class SparseCategoricalAccuracy(MeanMetricWrapper):\n-    \"\"\"Calculates how often predictions matches integer labels.\n-\n-    For example, if `y_true` is [[2], [1]] and `y_pred` is\n-    [[0.1, 0.9, 0.8], [0.05, 0.95, 0]] then the categorical accuracy is 1/2 or .5.\n-    If the weights were specified as [0.7, 0.3] then the categorical accuracy\n-    would be .3. You can provide logits of classes as `y_pred`, since argmax of\n-    logits and probabilities are same.\n-\n-    This metric creates two local variables, `total` and `count` that are used to\n-    compute the frequency with which `y_pred` matches `y_true`. This frequency is\n-    ultimately returned as `sparse categorical accuracy`: an idempotent operation\n-    that simply divides `total` by `count`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        loss='mse',\n-        metrics=[keras.metrics.SparseCategoricalAccuracy()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='sparse_categorical_accuracy', dtype=None):\n-        super(SparseCategoricalAccuracy, self).__init__(\n-            sparse_categorical_accuracy, name, dtype=dtype)\n-\n-\n-class TopKCategoricalAccuracy(MeanMetricWrapper):\n-    \"\"\"Computes how often targets are in the top `K` predictions.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.TopKCategoricalAccuracy()])\n-    ```\n-\n-    # Arguments\n-        k: (Optional) Number of top elements to look at for computing accuracy.\n-            Defaults to 5.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, k=5, name='top_k_categorical_accuracy', dtype=None):\n-        super(TopKCategoricalAccuracy, self).__init__(\n-            top_k_categorical_accuracy, name, dtype=dtype, k=k)\n-\n-\n-class SparseTopKCategoricalAccuracy(MeanMetricWrapper):\n-    \"\"\"Computes how often integer targets are in the top `K` predictions.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        metrics=[keras.metrics.SparseTopKCategoricalAccuracy()])\n-    ```\n-\n-    # Arguments\n-        k: (Optional) Number of top elements to look at for computing accuracy.\n-            Defaults to 5.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, k=5, name='sparse_top_k_categorical_accuracy', dtype=None):\n-        super(SparseTopKCategoricalAccuracy, self).__init__(\n-            sparse_top_k_categorical_accuracy, name, dtype=dtype, k=k)\n-\n-\n-class LogCoshError(MeanMetricWrapper):\n-    \"\"\"Computes the logarithm of the hyperbolic cosine of the prediction error.\n-\n-    `metric = log((exp(x) + exp(-x))/2)`, where x is the error (y_pred - y_true)\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.LogCoshError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='logcosh', dtype=None):\n-        super(LogCoshError, self).__init__(logcosh, name, dtype=dtype)\n-\n-\n-class Poisson(MeanMetricWrapper):\n-    \"\"\"Computes the Poisson metric between `y_true` and `y_pred`.\n-\n-    `metric = y_pred - y_true * log(y_pred)`\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.Poisson()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='poisson', dtype=None):\n-        super(Poisson, self).__init__(poisson, name, dtype=dtype)\n-\n-\n-class KLDivergence(MeanMetricWrapper):\n-    \"\"\"Computes Kullback-Leibler divergence metric between `y_true` and `y_pred`.\n-\n-    `metric = y_true * log(y_true / y_pred)`\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.KLDivergence()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='kullback_leibler_divergence', dtype=None):\n-        super(KLDivergence, self).__init__(\n-            kullback_leibler_divergence, name, dtype=dtype)\n-\n-\n-class CosineSimilarity(MeanMetricWrapper):\n-    \"\"\"Computes the cosine similarity between the labels and predictions.\n-\n-    cosine similarity = (a . b) / ||a|| ||b||\n-    [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n-    For example, if `y_true` is [0, 1, 1], and `y_pred` is [1, 0, 1], the cosine\n-    similarity is 0.5.\n-\n-    This metric keeps the average cosine similarity between `predictions` and\n-    `labels` over a stream of data.\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        axis: (Optional) Defaults to -1. The dimension along which the cosine\n-        similarity is computed.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-      'sgd',\n-      loss='mse',\n-      metrics=[keras.metrics.CosineSimilarity(axis=1)])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='cosine_similarity', dtype=None, axis=-1):\n-        super(CosineSimilarity, self).__init__(\n-            cosine_similarity, name, dtype=dtype, axis=axis)\n-\n-\n-class MeanAbsoluteError(MeanMetricWrapper):\n-    \"\"\"Computes the mean absolute error between the labels and predictions.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.MeanAbsoluteError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean_absolute_error', dtype=None):\n-        super(MeanAbsoluteError, self).__init__(\n-            mean_absolute_error, name, dtype=dtype)\n-\n-\n-class MeanAbsolutePercentageError(MeanMetricWrapper):\n-    \"\"\"Computes the mean absolute percentage error between `y_true` and `y_pred`.\n-\n-    For example, if `y_true` is [0., 0., 1., 1.], and `y_pred` is [1., 1., 1., 0.]\n-    the mean absolute percentage error is 5e+08.\n-\n-    Usage:\n-\n-    ```python\n-    m = keras.metrics.MeanAbsolutePercentageError()\n-    m.update_state([0., 0., 1., 1.], [1., 1., 1., 0.])\n-    # Final result: 5e+08\n-    ```\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.MeanAbsolutePercentageError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean_absolute_percentage_error', dtype=None):\n-        super(MeanAbsolutePercentageError, self).__init__(\n-            mean_absolute_percentage_error, name, dtype=dtype)\n-\n-\n-class MeanSquaredError(MeanMetricWrapper):\n-    \"\"\"Computes the mean squared error between `y_true` and `y_pred`.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.MeanSquaredError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean_squared_error', dtype=None):\n-        super(MeanSquaredError, self).__init__(\n-            mean_squared_error, name, dtype=dtype)\n-\n-\n-class MeanSquaredLogarithmicError(MeanMetricWrapper):\n-    \"\"\"Computes the mean squared logarithmic error between `y_true` and `y_pred`.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.MeanSquaredLogarithmicError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='mean_squared_logarithmic_error', dtype=None):\n-        super(MeanSquaredLogarithmicError, self).__init__(\n-            mean_squared_logarithmic_error, name, dtype=dtype)\n-\n-\n-class RootMeanSquaredError(Mean):\n-    \"\"\"Computes root mean squared error metric between `y_true` and `y_pred`.\n-\n-    Usage with the `compile` API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', metrics=[keras.metrics.RootMeanSquaredError()])\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name='root_mean_squared_error', dtype=None):\n-        super(RootMeanSquaredError, self).__init__(name, dtype=dtype)\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates root mean squared error statistics.\n-\n-        # Arguments\n-            y_true: The ground truth values.\n-            y_pred: The predicted values.\n-            sample_weight: Optional weighting of each example. Defaults to 1.\n-                Can be a `Tensor` whose rank is either 0,\n-                or the same rank as `y_true`,\n-                and must be broadcastable to `y_true`.\n-\n-        # Returns\n-            List of update ops.\n-        \"\"\"\n-        error_sq = K.square(y_pred - y_true)\n-        return super(RootMeanSquaredError, self).update_state(\n-            error_sq, sample_weight=sample_weight)\n-\n-    def result(self):\n-        return K.sqrt(self.total / self.count)\n-\n-\n-class BinaryCrossentropy(MeanMetricWrapper):\n-    \"\"\"Computes the crossentropy metric between the labels and predictions.\n-\n-    This is the crossentropy metric class to be used when there are only two\n-    label classes (0 and 1).\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-      'sgd',\n-      loss='mse',\n-      metrics=[keras.metrics.BinaryCrossentropy()])\n-    ```\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        from_logits: (Optional )Whether output is expected to be a logits tensor.\n-            By default, we consider that output encodes a probability distribution.\n-        label_smoothing: (Optional) Float in [0, 1]. When > 0, label values are\n-            smoothed, meaning the confidence on label values are relaxed.\n-            e.g. `label_smoothing=0.2` means that we will use a value of `0.1` for\n-            label `0` and `0.9` for label `1`\"\n-    \"\"\"\n-\n-    def __init__(self,\n-                 name='binary_crossentropy',\n-                 dtype=None,\n-                 from_logits=False,\n-                 label_smoothing=0):\n-        super(BinaryCrossentropy, self).__init__(\n-            binary_crossentropy,\n-            name,\n-            dtype=dtype,\n-            from_logits=from_logits,\n-            label_smoothing=label_smoothing)\n-\n-\n-class CategoricalCrossentropy(MeanMetricWrapper):\n-    \"\"\"Computes the crossentropy metric between the labels and predictions.\n-\n-    This is the crossentropy metric class to be used when there are multiple\n-    label classes (2 or more). Here we assume that labels are given as a `one_hot`\n-    representation. eg., When labels values are [2, 0, 1],\n-    `y_true` = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-    'sgd',\n-    loss='mse',\n-    metrics=[keras.metrics.CategoricalCrossentropy()])\n-    ```\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n-            By default, we assume that `y_pred` encodes a probability distribution.\n-        label_smoothing: Float in [0, 1]. When > 0, label values are smoothed,\n-            meaning the confidence on label values are relaxed. e.g.\n-            `label_smoothing=0.2` means that we will use a value of `0.1` for label\n-            `0` and `0.9` for label `1`\"\n-    \"\"\"\n-\n-    def __init__(self,\n-                 name='categorical_crossentropy',\n-                 dtype=None,\n-                 from_logits=False,\n-                 label_smoothing=0):\n-        super(CategoricalCrossentropy, self).__init__(\n-            categorical_crossentropy,\n-            name,\n-            dtype=dtype,\n-            from_logits=from_logits,\n-            label_smoothing=label_smoothing)\n-\n-\n-class SparseCategoricalCrossentropy(MeanMetricWrapper):\n-    \"\"\"Computes the crossentropy metric between the labels and predictions.\n-\n-    Use this crossentropy metric when there are two or more label classes.\n-    We expect labels to be provided as integers. If you want to provide labels\n-    using `one-hot` representation, please use `CategoricalCrossentropy` metric.\n-    There should be `# classes` floating point values per feature for `y_pred`\n-    and a single floating point value per feature for `y_true`.\n-\n-    In the snippet below, there is a single floating point value per example for\n-    `y_true` and `# classes` floating pointing values per example for `y_pred`.\n-    The shape of `y_true` is `[batch_size]` and the shape of `y_pred` is\n-    `[batch_size, num_classes]`.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-    'sgd',\n-    loss='mse',\n-    metrics=[keras.metrics.SparseCategoricalCrossentropy()])\n-    ```\n-\n-    # Arguments\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        from_logits: (Optional ) Whether `y_pred` is expected to be a logits tensor.\n-            By default, we assume that `y_pred` encodes a probability distribution.\n-        axis: (Optional) Defaults to -1. The dimension along which the metric is\n-            computed.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 name='sparse_categorical_crossentropy',\n-                 dtype=None,\n-                 from_logits=False,\n-                 axis=-1):\n-        super(SparseCategoricalCrossentropy, self).__init__(\n-            sparse_categorical_crossentropy,\n-            name,\n-            dtype=dtype,\n-            from_logits=from_logits,\n-            axis=axis)\n-\n-\n-class _ConfusionMatrixConditionCount(Metric):\n-    \"\"\"Calculates the number of the given confusion matrix condition.\n-\n-    # Arguments\n-        confusion_matrix_cond: One of `metrics_utils.ConfusionMatrix` conditions.\n-        thresholds: (Optional) Defaults to 0.5. A float value or a python\n-            list/tuple of float threshold values in [0, 1]. A threshold is compared\n-            with prediction values to determine the truth value of predictions\n-            (i.e., above the threshold is `true`, below is `false`). One metric\n-            value is generated for each threshold value.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 confusion_matrix_cond,\n-                 thresholds=None,\n-                 name=None,\n-                 dtype=None):\n-        super(_ConfusionMatrixConditionCount, self).__init__(name=name, dtype=dtype)\n-        self._confusion_matrix_cond = confusion_matrix_cond\n-        self.init_thresholds = thresholds\n-        self.thresholds = metrics_utils.parse_init_thresholds(\n-            thresholds, default_threshold=0.5)\n-        self.accumulator = self.add_weight(\n-            'accumulator',\n-            shape=(len(self.thresholds),),\n-            initializer='zeros')\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        return metrics_utils.update_confusion_matrix_variables(\n-            {self._confusion_matrix_cond: self.accumulator},\n-            y_true,\n-            y_pred,\n-            thresholds=self.thresholds,\n-            sample_weight=sample_weight)\n-\n-    def result(self):\n-        if len(self.thresholds) == 1:\n-            return self.accumulator[0]\n-        return self.accumulator\n-\n-    def reset_states(self):\n-        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n-        K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n-\n-    def get_config(self):\n-        config = {'thresholds': self.init_thresholds}\n-        base_config = super(_ConfusionMatrixConditionCount, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class FalsePositives(_ConfusionMatrixConditionCount):\n-    \"\"\"Calculates the number of false positives.\n-\n-    For example, if `y_true` is [0, 1, 0, 0] and `y_pred` is [0, 0, 1, 1]\n-    then the false positives value is 2.  If the weights were specified as\n-    [0, 0, 1, 0] then the false positives value would be 1.\n-\n-    If `sample_weight` is given, calculates the sum of the weights of\n-    false positives. This metric creates one local variable, `accumulator`\n-    that is used to keep track of the number of false positives.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.FalsePositives()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) Defaults to 0.5. A float value or a python\n-            list/tuple of float threshold values in [0, 1]. A threshold is\n-            compared with prediction values to determine the truth value of\n-            predictions (i.e., above the threshold is `true`, below is `false`).\n-            One metric value is generated for each threshold value.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, thresholds=None, name=None, dtype=None):\n-        super(FalsePositives, self).__init__(\n-            confusion_matrix_cond=metrics_utils.ConfusionMatrix.FALSE_POSITIVES,\n-            thresholds=thresholds,\n-            name=name,\n-            dtype=dtype)\n-\n-\n-class TruePositives(_ConfusionMatrixConditionCount):\n-    \"\"\"Calculates the number of true positives.\n-\n-    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n-    then the true positives value is 2.  If the weights were specified as\n-    [0, 0, 1, 0] then the true positives value would be 1.\n-\n-    If `sample_weight` is given, calculates the sum of the weights of\n-    true positives. This metric creates one local variable, `accumulator`\n-    that is used to keep track of the number of true positives.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.TruePositives()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) Defaults to 0.5. A float value or a python\n-            list/tuple of float threshold values in [0, 1]. A threshold is compared\n-            with prediction values to determine the truth value of predictions\n-            (i.e., above the threshold is `true`, below is `false`). One metric\n-            value is generated for each threshold value.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, thresholds=None, name=None, dtype=None):\n-        super(TruePositives, self).__init__(\n-            confusion_matrix_cond=metrics_utils.ConfusionMatrix.TRUE_POSITIVES,\n-            thresholds=thresholds,\n-            name=name,\n-            dtype=dtype)\n-\n-\n-class TrueNegatives(_ConfusionMatrixConditionCount):\n-    \"\"\"Calculates the number of true negatives.\n-\n-    For example, if `y_true` is [0, 1, 0, 0] and `y_pred` is [1, 1, 0, 0]\n-    then the true negatives value is 2.  If the weights were specified as\n-    [0, 0, 1, 0] then the true negatives value would be 1.\n-\n-    If `sample_weight` is given, calculates the sum of the weights of\n-    true negatives. This metric creates one local variable, `accumulator`\n-    that is used to keep track of the number of true negatives.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.TrueNegatives()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) Defaults to 0.5. A float value or a python\n-            list/tuple of float threshold values in [0, 1]. A threshold is compared\n-            with prediction values to determine the truth value of predictions\n-            (i.e., above the threshold is `true`, below is `false`). One metric\n-            value is generated for each threshold value.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, thresholds=None, name=None, dtype=None):\n-        super(TrueNegatives, self).__init__(\n-            confusion_matrix_cond=metrics_utils.ConfusionMatrix.TRUE_NEGATIVES,\n-            thresholds=thresholds,\n-            name=name,\n-            dtype=dtype)\n-\n-\n-class FalseNegatives(_ConfusionMatrixConditionCount):\n-    \"\"\"Calculates the number of false negatives.\n-\n-    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [0, 1, 0, 0]\n-    then the false negatives value is 2.  If the weights were specified as\n-    [0, 0, 1, 0] then the false negatives value would be 1.\n-\n-    If `sample_weight` is given, calculates the sum of the weights of\n-    false negatives. This metric creates one local variable, `accumulator`\n-    that is used to keep track of the number of false negatives.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.FalseNegatives()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) Defaults to 0.5. A float value or a python\n-            list/tuple of float threshold values in [0, 1]. A threshold is compared\n-            with prediction values to determine the truth value of predictions\n-            (i.e., above the threshold is `true`, below is `false`). One metric\n-            value is generated for each threshold value.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, thresholds=None, name=None, dtype=None):\n-        super(FalseNegatives, self).__init__(\n-            confusion_matrix_cond=metrics_utils.ConfusionMatrix.FALSE_NEGATIVES,\n-            thresholds=thresholds,\n-            name=name,\n-            dtype=dtype)\n-\n-\n-class SensitivitySpecificityBase(Metric):\n-    \"\"\"Abstract base class for computing sensitivity and specificity.\n-\n-    For additional information about specificity and sensitivity, see the\n-    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n-    \"\"\"\n-\n-    def __init__(self, value, num_thresholds=200, name=None, dtype=None):\n-        super(SensitivitySpecificityBase, self).__init__(name=name, dtype=dtype)\n-        if num_thresholds <= 0:\n-            raise ValueError('`num_thresholds` must be > 0.')\n-        self.value = value\n-        self.true_positives = self.add_weight(\n-            'true_positives',\n-            shape=(num_thresholds,),\n-            initializer='zeros')\n-        self.true_negatives = self.add_weight(\n-            'true_negatives',\n-            shape=(num_thresholds,),\n-            initializer='zeros')\n-        self.false_positives = self.add_weight(\n-            'false_positives',\n-            shape=(num_thresholds,),\n-            initializer='zeros')\n-        self.false_negatives = self.add_weight(\n-            'false_negatives',\n-            shape=(num_thresholds,),\n-            initializer='zeros')\n-\n-        # Compute `num_thresholds` thresholds in [0, 1]\n-        if num_thresholds == 1:\n-            self.thresholds = [0.5]\n-        else:\n-            thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n-                          for i in range(num_thresholds - 2)]\n-            self.thresholds = [0.0] + thresholds + [1.0]\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        return metrics_utils.update_confusion_matrix_variables(\n-            {\n-                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n-                metrics_utils.ConfusionMatrix.TRUE_NEGATIVES: self.true_negatives,\n-                metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives,\n-                metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives,\n-            },\n-            y_true,\n-            y_pred,\n-            thresholds=self.thresholds,\n-            sample_weight=sample_weight)\n-\n-    def reset_states(self):\n-        num_thresholds = len(self.thresholds)\n-        K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n-\n-\n-class SensitivityAtSpecificity(SensitivitySpecificityBase):\n-    \"\"\"Computes the sensitivity at a given specificity.\n-\n-    `Sensitivity` measures the proportion of actual positives that are correctly\n-    identified as such (tp / (tp + fn)).\n-    `Specificity` measures the proportion of actual negatives that are correctly\n-    identified as such (tn / (tn + fp)).\n-\n-    This metric creates four local variables, `true_positives`, `true_negatives`,\n-    `false_positives` and `false_negatives` that are used to compute the\n-    sensitivity at the given specificity. The threshold for the given specificity\n-    value is computed and used to evaluate the corresponding sensitivity.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    For additional information about specificity and sensitivity, see the\n-    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        loss='mse',\n-        metrics=[keras.metrics.SensitivityAtSpecificity()])\n-    ```\n-\n-    # Arguments\n-        specificity: A scalar value in range `[0, 1]`.\n-        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n-            use for matching the given specificity.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, specificity, num_thresholds=200, name=None, dtype=None):\n-        if specificity < 0 or specificity > 1:\n-            raise ValueError('`specificity` must be in the range [0, 1].')\n-        self.specificity = specificity\n-        self.num_thresholds = num_thresholds\n-        super(SensitivityAtSpecificity, self).__init__(\n-            specificity, num_thresholds=num_thresholds, name=name, dtype=dtype)\n-\n-    def result(self):\n-        # Calculate specificities at all the thresholds.\n-        specificities = K.switch(\n-            K.greater(self.true_negatives + self.false_positives, 0),\n-            (self.true_negatives / (self.true_negatives + self.false_positives)),\n-            K.zeros_like(self.thresholds))\n-\n-        # Find the index of the threshold where the specificity is closest to the\n-        # given specificity.\n-        min_index = K.argmin(\n-            K.abs(specificities - self.value), axis=0)\n-        min_index = K.cast(min_index, 'int32')\n-\n-        # Compute sensitivity at that index.\n-        denom = self.true_positives[min_index] + self.false_negatives[min_index]\n-        return K.switch(\n-            K.greater(denom, 0),\n-            self.true_positives[min_index] / denom,\n-            K.zeros_like(self.true_positives[min_index]))\n-\n-    def get_config(self):\n-        config = {\n-            'num_thresholds': self.num_thresholds,\n-            'specificity': self.specificity\n-        }\n-        base_config = super(SensitivityAtSpecificity, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class SpecificityAtSensitivity(SensitivitySpecificityBase):\n-    \"\"\"Computes the specificity at a given sensitivity.\n-\n-    `Sensitivity` measures the proportion of actual positives that are correctly\n-    identified as such (tp / (tp + fn)).\n-    `Specificity` measures the proportion of actual negatives that are correctly\n-    identified as such (tn / (tn + fp)).\n-\n-    This metric creates four local variables, `true_positives`, `true_negatives`,\n-    `false_positives` and `false_negatives` that are used to compute the\n-    specificity at the given sensitivity. The threshold for the given sensitivity\n-    value is computed and used to evaluate the corresponding specificity.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    For additional information about specificity and sensitivity, see the\n-    following: https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n-\n-    Usage with the compile API:\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        loss='mse',\n-        metrics=[keras.metrics.SpecificityAtSensitivity()])\n-    ```\n-\n-    # Arguments\n-        sensitivity: A scalar value in range `[0, 1]`.\n-        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n-            use for matching the given specificity.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self, sensitivity, num_thresholds=200, name=None, dtype=None):\n-        if sensitivity < 0 or sensitivity > 1:\n-            raise ValueError('`sensitivity` must be in the range [0, 1].')\n-        self.sensitivity = sensitivity\n-        self.num_thresholds = num_thresholds\n-        super(SpecificityAtSensitivity, self).__init__(\n-            sensitivity, num_thresholds=num_thresholds, name=name, dtype=dtype)\n-\n-    def result(self):\n-        # Calculate sensitivities at all the thresholds.\n-        sensitivities = K.switch(\n-            K.greater(self.true_positives + self.false_negatives, 0),\n-            (self.true_positives / (self.true_positives + self.false_negatives)),\n-            K.zeros_like(self.thresholds))\n-\n-        # Find the index of the threshold where the sensitivity is closest to the\n-        # given specificity.\n-        min_index = K.argmin(\n-            K.abs(sensitivities - self.value), axis=0)\n-        min_index = K.cast(min_index, 'int32')\n-\n-        # Compute specificity at that index.\n-        denom = (self.true_negatives[min_index] + self.false_positives[min_index])\n-        return K.switch(\n-            K.greater(denom, 0),\n-            self.true_negatives[min_index] / denom,\n-            K.zeros_like(self.true_negatives[min_index]))\n-\n-    def get_config(self):\n-        config = {\n-            'num_thresholds': self.num_thresholds,\n-            'sensitivity': self.sensitivity\n-        }\n-        base_config = super(SpecificityAtSensitivity, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Precision(Metric):\n-    \"\"\"Computes the precision of the predictions with respect to the labels.\n-\n-    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n-    then the precision value is 2/(2+1) ie. 0.66. If the weights were specified as\n-    [0, 0, 1, 0] then the precision value would be 1.\n-\n-    The metric creates two local variables, `true_positives` and `false_positives`\n-    that are used to compute the precision. This value is ultimately returned as\n-    `precision`, an idempotent operation that simply divides `true_positives`\n-    by the sum of `true_positives` and `false_positives`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    If `top_k` is set, we'll calculate precision as how often on average a class\n-    among the top-k classes with the highest predicted values of a batch entry is\n-    correct and can be found in the label for that entry.\n-\n-    If `class_id` is specified, we calculate precision by considering only the\n-    entries in the batch for which `class_id` is above the threshold and/or in the\n-    top-k highest predictions, and computing the fraction of them for which\n-    `class_id` is indeed a correct label.\n-\n-    Usage with the compile API:\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.Precision()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) A float value or a python list/tuple of float\n-            threshold values in [0, 1]. A threshold is compared with prediction\n-            values to determine the truth value of predictions (i.e., above the\n-            threshold is `true`, below is `false`). One metric value is generated\n-            for each threshold value. If neither thresholds nor top_k are set, the\n-            default is to calculate precision with `thresholds=0.5`.\n-        top_k: (Optional) Unset by default. An int value specifying the top-k\n-            predictions to consider when calculating precision.\n-        class_id: (Optional) Integer class ID for which we want binary metrics.\n-            This must be in the half-open interval `[0, num_classes)`, where\n-            `num_classes` is the last dimension of predictions.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 thresholds=None,\n-                 top_k=None,\n-                 class_id=None,\n-                 name=None,\n-                 dtype=None):\n-        super(Precision, self).__init__(name=name, dtype=dtype)\n-        self.init_thresholds = thresholds\n-        if top_k is not None and K.backend() != 'tensorflow':\n-            raise RuntimeError(\n-                '`top_k` argument for `Precision` metric is currently supported '\n-                'only with TensorFlow backend.')\n-\n-        self.top_k = top_k\n-        self.class_id = class_id\n-\n-        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\n-        self.thresholds = metrics_utils.parse_init_thresholds(\n-            thresholds, default_threshold=default_threshold)\n-        self.true_positives = self.add_weight(\n-            'true_positives',\n-            shape=(len(self.thresholds),),\n-            initializer='zeros')\n-        self.false_positives = self.add_weight(\n-            'false_positives',\n-            shape=(len(self.thresholds),),\n-            initializer='zeros')\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        return metrics_utils.update_confusion_matrix_variables(\n-            {\n-                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n-                metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives\n-            },\n-            y_true,\n-            y_pred,\n-            thresholds=self.thresholds,\n-            top_k=self.top_k,\n-            class_id=self.class_id,\n-            sample_weight=sample_weight)\n-\n-    def result(self):\n-        denom = (self.true_positives + self.false_positives)\n-        result = K.switch(\n-            K.greater(denom, 0),\n-            self.true_positives / denom,\n-            K.zeros_like(self.true_positives))\n-\n-        return result[0] if len(self.thresholds) == 1 else result\n-\n-    def reset_states(self):\n-        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n-        K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n-\n-    def get_config(self):\n-        config = {\n-            'thresholds': self.init_thresholds,\n-            'top_k': self.top_k,\n-            'class_id': self.class_id\n-        }\n-        base_config = super(Precision, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Recall(Metric):\n-    \"\"\"Computes the recall of the predictions with respect to the labels.\n-\n-    For example, if `y_true` is [0, 1, 1, 1] and `y_pred` is [1, 0, 1, 1]\n-    then the recall value is 2/(2+1) ie. 0.66. If the weights were specified as\n-    [0, 0, 1, 0] then the recall value would be 1.\n-\n-    This metric creates two local variables, `true_positives` and\n-    `false_negatives`, that are used to compute the recall. This value is\n-    ultimately returned as `recall`, an idempotent operation that simply divides\n-    `true_positives` by the sum of `true_positives` and `false_negatives`.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    If `top_k` is set, recall will be computed as how often on average a class\n-    among the labels of a batch entry is in the top-k predictions.\n-\n-    If `class_id` is specified, we calculate recall by considering only the\n-    entries in the batch for which `class_id` is in the label, and computing the\n-    fraction of them for which `class_id` is above the threshold and/or in the\n-    top-k predictions.\n-\n-    Usage with the compile API:\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.Recall()])\n-    ```\n-\n-    # Arguments\n-        thresholds: (Optional) A float value or a python list/tuple of float\n-            threshold values in [0, 1]. A threshold is compared with prediction\n-            values to determine the truth value of predictions (i.e., above the\n-            threshold is `true`, below is `false`). One metric value is generated\n-            for each threshold value. If neither thresholds nor top_k are set, the\n-            default is to calculate recall with `thresholds=0.5`.\n-        top_k: (Optional) Unset by default. An int value specifying the top-k\n-            predictions to consider when calculating recall.\n-        class_id: (Optional) Integer class ID for which we want binary metrics.\n-            This must be in the half-open interval `[0, num_classes)`, where\n-            `num_classes` is the last dimension of predictions.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 thresholds=None,\n-                 top_k=None,\n-                 class_id=None,\n-                 name=None,\n-                 dtype=None):\n-        super(Recall, self).__init__(name=name, dtype=dtype)\n-        self.init_thresholds = thresholds\n-        if top_k is not None and K.backend() != 'tensorflow':\n-            raise RuntimeError(\n-                '`top_k` argument for `Recall` metric is currently supported only '\n-                'with TensorFlow backend.')\n-\n-        self.top_k = top_k\n-        self.class_id = class_id\n-\n-        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF\n-        self.thresholds = metrics_utils.parse_init_thresholds(\n-            thresholds, default_threshold=default_threshold)\n-        self.true_positives = self.add_weight(\n-            'true_positives',\n-            shape=(len(self.thresholds),),\n-            initializer='zeros')\n-        self.false_negatives = self.add_weight(\n-            'false_negatives',\n-            shape=(len(self.thresholds),),\n-            initializer='zeros')\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        return metrics_utils.update_confusion_matrix_variables(\n-            {\n-                metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n-                metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives\n-            },\n-            y_true,\n-            y_pred,\n-            thresholds=self.thresholds,\n-            top_k=self.top_k,\n-            class_id=self.class_id,\n-            sample_weight=sample_weight)\n-\n-    def result(self):\n-        denom = (self.true_positives + self.false_negatives)\n-        result = K.switch(\n-            K.greater(denom, 0),\n-            self.true_positives / denom,\n-            K.zeros_like(self.true_positives))\n-        return result[0] if len(self.thresholds) == 1 else result\n-\n-    def reset_states(self):\n-        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n-        K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n-\n-    def get_config(self):\n-        config = {\n-            'thresholds': self.init_thresholds,\n-            'top_k': self.top_k,\n-            'class_id': self.class_id\n-        }\n-        base_config = super(Recall, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class AUC(Metric):\n-    \"\"\"Computes the approximate AUC (Area under the curve) via a Riemann sum.\n-\n-    This metric creates four local variables, `true_positives`, `true_negatives`,\n-    `false_positives` and `false_negatives` that are used to compute the AUC.\n-    To discretize the AUC curve, a linearly spaced set of thresholds is used to\n-    compute pairs of recall and precision values. The area under the ROC-curve is\n-    therefore computed using the height of the recall values by the false positive\n-    rate, while the area under the PR-curve is the computed using the height of\n-    the precision values by the recall.\n-\n-    This value is ultimately returned as `auc`, an idempotent operation that\n-    computes the area under a discretized curve of precision versus recall values\n-    (computed using the aforementioned variables). The `num_thresholds` variable\n-    controls the degree of discretization with larger numbers of thresholds more\n-    closely approximating the true AUC. The quality of the approximation may vary\n-    dramatically depending on `num_thresholds`. The `thresholds` parameter can be\n-    used to manually specify thresholds which split the predictions more evenly.\n-\n-    For best results, `predictions` should be distributed approximately uniformly\n-    in the range [0, 1] and not peaked around 0 or 1. The quality of the AUC\n-    approximation may be poor if this is not the case. Setting `summation_method`\n-    to 'minoring' or 'majoring' can help quantify the error in the approximation\n-    by providing lower or upper bound estimate of the AUC.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile('sgd', loss='mse', metrics=[keras.metrics.AUC()])\n-    ```\n-\n-    # Arguments\n-        num_thresholds: (Optional) Defaults to 200. The number of thresholds to\n-            use when discretizing the roc curve. Values must be > 1.\n-            curve: (Optional) Specifies the name of the curve to be computed, 'ROC'\n-            [default] or 'PR' for the Precision-Recall-curve.\n-        summation_method: (Optional) Specifies the Riemann summation method used\n-            (https://en.wikipedia.org/wiki/Riemann_sum): 'interpolation' [default],\n-              applies mid-point summation scheme for `ROC`. For PR-AUC, interpolates\n-              (true/false) positives but not the ratio that is precision (see Davis\n-              & Goadrich 2006 for details); 'minoring' that applies left summation\n-              for increasing intervals and right summation for decreasing intervals;\n-              'majoring' that does the opposite.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-        thresholds: (Optional) A list of floating point values to use as the\n-            thresholds for discretizing the curve. If set, the `num_thresholds`\n-            parameter is ignored. Values should be in [0, 1]. Endpoint thresholds\n-            equal to {-epsilon, 1+epsilon} for a small positive epsilon value will\n-            be automatically included with these to correctly handle predictions\n-            equal to exactly 0 or 1.\n-    \"\"\"\n-\n-    def __init__(self,\n-                 num_thresholds=200,\n-                 curve='ROC',\n-                 summation_method='interpolation',\n-                 name=None,\n-                 dtype=None,\n-                 thresholds=None):\n-        # Validate configurations.\n-        if (isinstance(curve, metrics_utils.AUCCurve) and\n-                curve not in list(metrics_utils.AUCCurve)):\n-            raise ValueError('Invalid curve: \"{}\". Valid options are: \"{}\"'.format(\n-                curve, list(metrics_utils.AUCCurve)))\n-        if isinstance(\n-            summation_method,\n-            metrics_utils.AUCSummationMethod) and summation_method not in list(\n-                metrics_utils.AUCSummationMethod):\n-            raise ValueError(\n-                'Invalid summation method: \"{}\". Valid options are: \"{}\"'.format(\n-                    summation_method, list(metrics_utils.AUCSummationMethod)))\n-\n-        # Update properties.\n-        if thresholds is not None:\n-            # If specified, use the supplied thresholds.\n-            self.num_thresholds = len(thresholds) + 2\n-            thresholds = sorted(thresholds)\n-        else:\n-            if num_thresholds <= 1:\n-                raise ValueError('`num_thresholds` must be > 1.')\n-\n-            # Otherwise, linearly interpolate (num_thresholds - 2) thresholds in\n-            # (0, 1).\n-            self.num_thresholds = num_thresholds\n-            thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n-                          for i in range(num_thresholds - 2)]\n-\n-        # Add an endpoint \"threshold\" below zero and above one for either\n-        # threshold method to account for floating point imprecisions.\n-        self.thresholds = [0.0 - K.epsilon()] + thresholds + [1.0 + K.epsilon()]\n-\n-        if isinstance(curve, metrics_utils.AUCCurve):\n-            self.curve = curve\n-        else:\n-            self.curve = metrics_utils.AUCCurve.from_str(curve)\n-        if isinstance(summation_method, metrics_utils.AUCSummationMethod):\n-            self.summation_method = summation_method\n-        else:\n-            self.summation_method = metrics_utils.AUCSummationMethod.from_str(\n-                summation_method)\n-        super(AUC, self).__init__(name=name, dtype=dtype)\n-\n-        # Create metric variables\n-        self.true_positives = self.add_weight(\n-            'true_positives',\n-            shape=(self.num_thresholds,),\n-            initializer='zeros')\n-        self.true_negatives = self.add_weight(\n-            'true_negatives',\n-            shape=(self.num_thresholds,),\n-            initializer='zeros')\n-        self.false_positives = self.add_weight(\n-            'false_positives',\n-            shape=(self.num_thresholds,),\n-            initializer='zeros')\n-        self.false_negatives = self.add_weight(\n-            'false_negatives',\n-            shape=(self.num_thresholds,),\n-            initializer='zeros')\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        return metrics_utils.update_confusion_matrix_variables({\n-            metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,\n-            metrics_utils.ConfusionMatrix.TRUE_NEGATIVES: self.true_negatives,\n-            metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives,\n-            metrics_utils.ConfusionMatrix.FALSE_NEGATIVES: self.false_negatives,\n-        }, y_true, y_pred, self.thresholds, sample_weight=sample_weight)\n-\n-    def interpolate_pr_auc(self):\n-        \"\"\"Interpolation formula inspired by section 4 of Davis & Goadrich 2006.\n-\n-        https://www.biostat.wisc.edu/~page/rocpr.pdf\n-\n-        Note here we derive & use a closed formula not present in the paper\n-        as follows:\n-\n-          Precision = TP / (TP + FP) = TP / P\n-\n-        Modeling all of TP (true positive), FP (false positive) and their sum\n-        P = TP + FP (predicted positive) as varying linearly within each interval\n-        [A, B] between successive thresholds, we get\n-\n-          Precision slope = dTP / dP\n-                          = (TP_B - TP_A) / (P_B - P_A)\n-                          = (TP - TP_A) / (P - P_A)\n-          Precision = (TP_A + slope * (P - P_A)) / P\n-\n-        The area within the interval is (slope / total_pos_weight) times\n-\n-          int_A^B{Precision.dP} = int_A^B{(TP_A + slope * (P - P_A)) * dP / P}\n-          int_A^B{Precision.dP} = int_A^B{slope * dP + intercept * dP / P}\n-\n-        where intercept = TP_A - slope * P_A = TP_B - slope * P_B, resulting in\n-\n-          int_A^B{Precision.dP} = TP_B - TP_A + intercept * log(P_B / P_A)\n-\n-        Bringing back the factor (slope / total_pos_weight) we'd put aside, we get\n-\n-          slope * [dTP + intercept *  log(P_B / P_A)] / total_pos_weight\n-\n-        where dTP == TP_B - TP_A.\n-\n-        Note that when P_A == 0 the above calculation simplifies into\n-\n-          int_A^B{Precision.dTP} = int_A^B{slope * dTP} = slope * (TP_B - TP_A)\n-\n-        which is really equivalent to imputing constant precision throughout the\n-        first bucket having >0 true positives.\n-\n-        # Returns\n-            pr_auc: an approximation of the area under the P-R curve.\n-        \"\"\"\n-        dtp = self.true_positives[:self.num_thresholds -\n-                                  1] - self.true_positives[1:]\n-        p = self.true_positives + self.false_positives\n-        dp = p[:self.num_thresholds - 1] - p[1:]\n-\n-        dp = K.maximum(dp, 0)\n-        prec_slope = K.switch(\n-            K.greater(dp, 0),\n-            dtp / dp,\n-            K.zeros_like(dtp))\n-        intercept = self.true_positives[1:] - (prec_slope * p[1:])\n-\n-        # Logical and\n-        pMin = K.expand_dims(p[:self.num_thresholds - 1] > 0, 0)\n-        pMax = K.expand_dims(p[1:] > 0, 0)\n-        are_different = K.concatenate([pMin, pMax], axis=0)\n-        switch_condition = K.all(are_different, axis=0)\n-\n-        safe_p_ratio = K.switch(\n-            switch_condition,\n-            K.switch(\n-                K.greater(p[1:], 0),\n-                p[:self.num_thresholds - 1] / p[1:],\n-                K.zeros_like(p[:self.num_thresholds - 1])),\n-            K.ones_like(p[1:]))\n-\n-        numer = prec_slope * (dtp + intercept * K.log(safe_p_ratio))\n-        denom = K.maximum(self.true_positives[1:] + self.false_negatives[1:], 0)\n-        return K.sum(K.switch(\n-            K.greater(denom, 0),\n-            numer / denom,\n-            K.zeros_like(numer)))\n-\n-    def result(self):\n-        if (self.curve == metrics_utils.AUCCurve.PR and\n-                (self.summation_method ==\n-                 metrics_utils.AUCSummationMethod.INTERPOLATION)):\n-            # This use case is different and is handled separately.\n-            return self.interpolate_pr_auc()\n-\n-        # Set `x` and `y` values for the curves based on `curve` config.\n-        recall = K.switch(\n-            K.greater((self.true_positives), 0),\n-            (self.true_positives /\n-                (self.true_positives + self.false_negatives)),\n-            K.zeros_like(self.true_positives))\n-        if self.curve == metrics_utils.AUCCurve.ROC:\n-            fp_rate = K.switch(\n-                K.greater((self.false_positives), 0),\n-                (self.false_positives /\n-                    (self.false_positives + self.true_negatives)),\n-                K.zeros_like(self.false_positives))\n-            x = fp_rate\n-            y = recall\n-        else:  # curve == 'PR'.\n-            precision = K.switch(\n-                K.greater((self.true_positives), 0),\n-                (self.true_positives / (self.true_positives + self.false_positives)),\n-                K.zeros_like(self.true_positives))\n-            x = recall\n-            y = precision\n-\n-        # Find the rectangle heights based on `summation_method`.\n-        if self.summation_method == metrics_utils.AUCSummationMethod.INTERPOLATION:\n-            # Note: the case ('PR', 'interpolation') has been handled above.\n-            heights = (y[:self.num_thresholds - 1] + y[1:]) / 2.\n-        elif self.summation_method == metrics_utils.AUCSummationMethod.MINORING:\n-            heights = K.minimum(y[:self.num_thresholds - 1], y[1:])\n-        else:  # self.summation_method = metrics_utils.AUCSummationMethod.MAJORING:\n-            heights = K.maximum(y[:self.num_thresholds - 1], y[1:])\n-\n-        # Sum up the areas of all the rectangles.\n-        return K.sum((x[:self.num_thresholds - 1] - x[1:]) * heights)\n-\n-    def reset_states(self):\n-        K.batch_set_value(\n-            [(v, np.zeros((self.num_thresholds,))) for v in self.weights])\n-\n-    def get_config(self):\n-        config = {\n-            'num_thresholds': self.num_thresholds,\n-            'curve': self.curve.value,\n-            'summation_method': self.summation_method.value,\n-            # We remove the endpoint thresholds as an inverse of how the thresholds\n-            # were initialized. This ensures that a metric initialized from this\n-            # config has the same thresholds.\n-            'thresholds': self.thresholds[1:-1],\n-        }\n-        base_config = super(AUC, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-BaseMeanIoU = object\n-if K.backend() == 'tensorflow':\n-    import tensorflow as tf\n-    if tf.__version__ >= '2.0.0':\n-        BaseMeanIoU = tf.keras.metrics.MeanIoU\n-\n-\n-class MeanIoU(BaseMeanIoU):\n-    \"\"\"Computes the mean Intersection-Over-Union metric.\n-\n-    Mean Intersection-Over-Union is a common evaluation metric for semantic image\n-    segmentation, which first computes the IOU for each semantic class and then\n-    computes the average over classes. IOU is defined as follows:\n-    IOU = true_positive / (true_positive + false_positive + false_negative).\n-    The predictions are accumulated in a confusion matrix, weighted by\n-    `sample_weight` and the metric is then calculated from it.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use `sample_weight` of 0 to mask values.\n-\n-    Usage with the compile API:\n-\n-    ```python\n-    model = keras.Model(inputs, outputs)\n-    model.compile(\n-        'sgd',\n-        loss='mse',\n-        metrics=[keras.metrics.MeanIoU(num_classes=2)])\n-    ```\n-\n-    # Arguments\n-        num_classes: The possible number of labels the prediction task can have.\n-            This value must be provided, since a confusion matrix of dimension =\n-            [num_classes, num_classes] will be allocated.\n-        name: (Optional) string name of the metric instance.\n-        dtype: (Optional) data type of the metric result.\n-    \"\"\"\n-    def __init__(self, num_classes, name=None, dtype=None):\n-        if K.backend() != 'tensorflow' or BaseMeanIoU is object:\n-            raise RuntimeError(\n-                '`MeanIoU` metric is currently supported only '\n-                'with TensorFlow backend and TF version >= 2.0.0.')\n-        super(MeanIoU, self).__init__(num_classes, name=name, dtype=dtype)\n-\n-\n-def accuracy(y_true, y_pred):\n-    if not K.is_tensor(y_pred):\n-        y_pred = K.constant(y_pred)\n-    y_true = K.cast(y_true, y_pred.dtype)\n-    return K.cast(K.equal(y_true, y_pred), K.floatx())\n-\n-\n-def binary_accuracy(y_true, y_pred, threshold=0.5):\n-    if threshold != 0.5:\n-        threshold = K.cast(threshold, y_pred.dtype)\n-        y_pred = K.cast(y_pred > threshold, y_pred.dtype)\n-    return K.mean(K.equal(y_true, K.round(y_pred)), axis=-1)\n-\n-\n-def categorical_accuracy(y_true, y_pred):\n-    return K.cast(K.equal(K.argmax(y_true, axis=-1),\n-                          K.argmax(y_pred, axis=-1)),\n-                  K.floatx())\n-\n-\n-def sparse_categorical_accuracy(y_true, y_pred):\n-    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n-    if K.ndim(y_true) == K.ndim(y_pred):\n-        y_true = K.squeeze(y_true, -1)\n-    # convert dense predictions to labels\n-    y_pred_labels = K.argmax(y_pred, axis=-1)\n-    y_pred_labels = K.cast(y_pred_labels, K.floatx())\n-    return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n-\n-\n-def top_k_categorical_accuracy(y_true, y_pred, k=5):\n-    return K.cast(K.in_top_k(y_pred, K.argmax(y_true, axis=-1), k), K.floatx())\n-\n-\n-def sparse_top_k_categorical_accuracy(y_true, y_pred, k=5):\n-    # If the shape of y_true is (num_samples, 1), flatten to (num_samples,)\n-    return K.cast(K.in_top_k(y_pred, K.cast(K.flatten(y_true), 'int32'), k),\n-                  K.floatx())\n-\n-\n-def cosine_proximity(y_true, y_pred, axis=-1):\n-    y_true = K.l2_normalize(y_true, axis=axis)\n-    y_pred = K.l2_normalize(y_pred, axis=axis)\n-    return K.sum(y_true * y_pred, axis=axis)\n-\n-\n-def clone_metric(metric):\n-    \"\"\"Returns a clone of the metric if stateful, otherwise returns it as is.\"\"\"\n-    if isinstance(metric, Metric):\n-        return metric.__class__.from_config(metric.get_config())\n-    return metric\n-\n-\n-def clone_metrics(metrics):\n-    \"\"\"Clones the given metric list/dict.\"\"\"\n-    if metrics is None:\n-        return None\n-    if isinstance(metrics, dict):\n-        return {key: clone_metric(value) for key, value in metrics.items()}\n-    return [clone_metric(metric) for metric in metrics]\n-\n-\n-# Aliases\n-\n-mse = MSE = mean_squared_error\n-mae = MAE = mean_absolute_error\n-mape = MAPE = mean_absolute_percentage_error\n-msle = MSLE = mean_squared_logarithmic_error\n-cosine = cosine_similarity = cosine_proximity\n-\n-\n-def serialize(metric):\n-    return serialize_keras_object(metric)\n-\n-\n-def deserialize(config, custom_objects=None):\n-    return deserialize_keras_object(config,\n-                                    module_objects=globals(),\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='metric function')\n-\n-\n-def get(identifier):\n-    if isinstance(identifier, dict):\n-        config = {'class_name': str(identifier), 'config': {}}\n-        return deserialize(config)\n-    elif isinstance(identifier, six.string_types):\n-        return deserialize(str(identifier))\n-    elif callable(identifier):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret '\n-                         'metric function identifier:', identifier)\n+\"\"\"Built-in metrics.\"\"\"\n+from tensorflow.keras.metrics import *\n\n@@ -1,12 +1,4 @@\n-\"\"\"Model-related utilities.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from . import backend as K\n-from .utils.generic_utils import has_arg\n-from .utils.generic_utils import to_list\n+\"\"\"Model-related utilities.\"\"\"\n from .engine.input_layer import Input\n from .engine.input_layer import InputLayer\n from .engine.training import Model\n@@ -17,241 +9,4 @@ from .engine.saving import model_from_config\n from .engine.saving import model_from_yaml\n from .engine.saving import model_from_json\n \n-try:\n-    import h5py\n-except ImportError:\n-    h5py = None\n-\n-\n-def _clone_functional_model(model, input_tensors=None):\n-    \"\"\"Clone a functional `Model` instance.\n-\n-    Model cloning is similar to calling a model on new inputs,\n-    except that it creates new layers (and thus new weights) instead\n-    of sharing the weights of the existing layers.\n-\n-    # Arguments\n-        model: Instance of `Model`.\n-        input_tensors: optional list of input tensors\n-            to build the model upon. If not provided,\n-            placeholders will be created.\n-\n-    # Returns\n-        An instance of `Model` reproducing the behavior\n-        of the original model, on top of new inputs tensors,\n-        using newly instantiated weights.\n-\n-    # Raises\n-        ValueError: in case of invalid `model` argument value.\n-    \"\"\"\n-    if not isinstance(model, Model):\n-        raise ValueError('Expected `model` argument '\n-                         'to be a `Model` instance, got ', model)\n-    if isinstance(model, Sequential):\n-        raise ValueError('Expected `model` argument '\n-                         'to be a functional `Model` instance, '\n-                         'got a `Sequential` instance instead:', model)\n-\n-    layer_map = {}  # Cache for created layers.\n-    tensor_map = {}  # Map {reference_tensor: (corresponding_tensor, mask)}\n-    if input_tensors is None:\n-        # Create placeholders to build the model on top of.\n-        input_layers = []\n-        input_tensors = []\n-        for layer in model._input_layers:\n-            input_tensor = Input(batch_shape=layer.batch_input_shape,\n-                                 dtype=layer.dtype,\n-                                 sparse=layer.sparse,\n-                                 name=layer.name)\n-            input_tensors.append(input_tensor)\n-            # Cache newly created input layer.\n-            newly_created_input_layer = input_tensor._keras_history[0]\n-            layer_map[layer] = newly_created_input_layer\n-        for _original, _cloned in zip(model._input_layers, input_layers):\n-            layer_map[_original] = _cloned\n-    else:\n-        # Make sure that all input tensors come from a Keras layer.\n-        # If tensor comes from an input layer: cache the input layer.\n-        input_tensors = to_list(input_tensors)\n-        _input_tensors = []\n-        for i, x in enumerate(input_tensors):\n-            if not K.is_keras_tensor(x):\n-                name = model._input_layers[i].name\n-                input_tensor = Input(tensor=x,\n-                                     name='input_wrapper_for_' + name)\n-                _input_tensors.append(input_tensor)\n-                # Cache newly created input layer.\n-                original_input_layer = x._keras_history[0]\n-                newly_created_input_layer = input_tensor._keras_history[0]\n-                layer_map[original_input_layer] = newly_created_input_layer\n-            else:\n-                _input_tensors.append(x)\n-        input_tensors = _input_tensors\n-\n-    for x, y in zip(model.inputs, input_tensors):\n-        tensor_map[id(x)] = (y, None)  # tensor, mask\n-\n-    # Iterated over every node in the reference model, in depth order.\n-    depth_keys = list(model._nodes_by_depth.keys())\n-    depth_keys.sort(reverse=True)\n-    for depth in depth_keys:\n-        nodes = model._nodes_by_depth[depth]\n-        for node in nodes:\n-            # Recover the corresponding layer.\n-            layer = node.outbound_layer\n-\n-            # Get or create layer.\n-            if layer not in layer_map:\n-                # Clone layer.\n-                new_layer = layer.__class__.from_config(layer.get_config())\n-                layer_map[layer] = new_layer\n-                layer = new_layer\n-            else:\n-                # Reuse previously cloned layer.\n-                layer = layer_map[layer]\n-                # Don't call InputLayer multiple times.\n-                if isinstance(layer, InputLayer):\n-                    continue\n-\n-            # Gather inputs to call the new layer.\n-            reference_input_tensors = node.input_tensors\n-            reference_output_tensors = node.output_tensors\n-\n-            # If all previous input tensors are available in tensor_map,\n-            # then call node.inbound_layer on them.\n-            computed_data = []  # List of tuples (input, mask).\n-            for x in reference_input_tensors:\n-                if id(x) in tensor_map:\n-                    computed_data.append(tensor_map[id(x)])\n-\n-            if len(computed_data) == len(reference_input_tensors):\n-                # Call layer.\n-                if node.arguments:\n-                    kwargs = node.arguments\n-                else:\n-                    kwargs = {}\n-                if len(computed_data) == 1:\n-                    computed_tensor, computed_mask = computed_data[0]\n-                    if has_arg(layer.call, 'mask'):\n-                        if 'mask' not in kwargs:\n-                            kwargs['mask'] = computed_mask\n-                    output_tensors = to_list(\n-                        layer(computed_tensor, **kwargs))\n-                    if layer.supports_masking:\n-                        output_masks = to_list(\n-                            layer.compute_mask(computed_tensor,\n-                                               computed_mask))\n-                    else:\n-                        output_masks = [None] * len(output_tensors)\n-                    computed_tensors = [computed_tensor]\n-                    computed_masks = [computed_mask]\n-                else:\n-                    computed_tensors = [x[0] for x in computed_data]\n-                    computed_masks = [x[1] for x in computed_data]\n-                    if has_arg(layer.call, 'mask'):\n-                        if 'mask' not in kwargs:\n-                            kwargs['mask'] = computed_masks\n-                    output_tensors = to_list(\n-                        layer(computed_tensors, **kwargs))\n-                    if layer.supports_masking:\n-                        output_masks = to_list(\n-                            layer.compute_mask(computed_tensors,\n-                                               computed_masks))\n-                    else:\n-                        output_masks = [None] * len(output_tensors)\n-                # Update tensor_map.\n-                for x, y, mask in zip(reference_output_tensors,\n-                                      output_tensors,\n-                                      output_masks):\n-                    tensor_map[id(x)] = (y, mask)\n-\n-    # Check that we did compute the model outputs,\n-    # then instantiate a new model from inputs and outputs.\n-    output_tensors = []\n-    for x in model.outputs:\n-        assert id(x) in tensor_map, 'Could not compute output ' + str(x)\n-        tensor, _ = tensor_map[id(x)]\n-        output_tensors.append(tensor)\n-    return Model(input_tensors, output_tensors, name=model.name)\n-\n-\n-def _clone_sequential_model(model, input_tensors=None):\n-    \"\"\"Clone a `Sequential` model instance.\n-\n-    Model cloning is similar to calling a model on new inputs,\n-    except that it creates new layers (and thus new weights) instead\n-    of sharing the weights of the existing layers.\n-\n-    # Arguments\n-        model: Instance of `Sequential`.\n-        input_tensors: optional list of input tensors\n-            to build the model upon. If not provided,\n-            placeholders will be created.\n-\n-    # Returns\n-        An instance of `Sequential` reproducing the behavior\n-        of the original model, on top of new inputs tensors,\n-        using newly instantiated weights.\n-\n-    # Raises\n-        ValueError: in case of invalid `model` argument value.\n-    \"\"\"\n-    if not isinstance(model, Sequential):\n-        raise ValueError('Expected `model` argument '\n-                         'to be a `Sequential` model instance, '\n-                         'but got:', model)\n-\n-    def clone(layer):\n-        return layer.__class__.from_config(layer.get_config())\n-\n-    layers = [clone(layer) for layer in model.layers]\n-    if input_tensors is None:\n-        return Sequential(layers=layers, name=model.name)\n-    else:\n-        if len(to_list(input_tensors)) != 1:\n-            raise ValueError('To clone a `Sequential` model, we expect '\n-                             ' at most one tensor '\n-                             'as part of `input_tensors`.')\n-        x = to_list(input_tensors)[0]\n-        if K.is_keras_tensor(x):\n-            origin_layer = x._keras_history[0]\n-            if isinstance(origin_layer, InputLayer):\n-                return Sequential(layers=[origin_layer] + layers,\n-                                  name=model.name)\n-            else:\n-                raise ValueError('Cannot clone a `Sequential` model on top '\n-                                 'of a tensor that comes from a Keras layer '\n-                                 'other than an `InputLayer`. '\n-                                 'Use the functional API instead.')\n-        input_tensor = Input(tensor=x,\n-                             name='input_wrapper_for_' + str(x.name))\n-        input_layer = input_tensor._keras_history[0]\n-        return Sequential(layers=[input_layer] + layers, name=model.name)\n-\n-\n-def clone_model(model, input_tensors=None):\n-    \"\"\"Clone any `Model` instance.\n-\n-    Model cloning is similar to calling a model on new inputs,\n-    except that it creates new layers (and thus new weights) instead\n-    of sharing the weights of the existing layers.\n-\n-    # Arguments\n-        model: Instance of `Model`\n-            (could be a functional model or a Sequential model).\n-        input_tensors: optional list of input tensors\n-            to build the model upon. If not provided,\n-            placeholders will be created.\n-\n-    # Returns\n-        An instance of `Model` reproducing the behavior\n-        of the original model, on top of new inputs tensors,\n-        using newly instantiated weights.\n-\n-    # Raises\n-        ValueError: in case of invalid `model` argument value.\n-    \"\"\"\n-    if isinstance(model, Sequential):\n-        return _clone_sequential_model(model, input_tensors=input_tensors)\n-    else:\n-        return _clone_functional_model(model, input_tensors=input_tensors)\n+from tensorflow.keras.models import clone_model\n\n@@ -1,873 +0,0 @@\n-\"\"\"Built-in optimizer classes.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import six\n-import copy\n-import numpy as np\n-from six.moves import zip\n-\n-from . import backend as K\n-from .utils.generic_utils import serialize_keras_object\n-from .utils.generic_utils import deserialize_keras_object\n-from .legacy import interfaces\n-\n-if K.backend() == 'tensorflow':\n-    import tensorflow as tf\n-\n-\n-def clip_norm(g, c, n):\n-    \"\"\"Clip the gradient `g` if the L2 norm `n` exceeds `c`.\n-\n-    # Arguments\n-        g: Tensor, the gradient tensor\n-        c: float >= 0. Gradients will be clipped\n-            when their L2 norm exceeds this value.\n-        n: Tensor, actual norm of `g`.\n-\n-    # Returns\n-        Tensor, the gradient clipped if required.\n-    \"\"\"\n-    if c <= 0:  # if clipnorm == 0 no need to add ops to the graph\n-        return g\n-\n-    # tf require using a special op to multiply IndexedSliced by scalar\n-    if K.backend() == 'tensorflow':\n-        condition = n >= c\n-        then_expression = tf.scalar_mul(c / n, g)\n-        else_expression = g\n-\n-        # saving the shape to avoid converting sparse tensor to dense\n-        if isinstance(then_expression, tf.Tensor):\n-            g_shape = copy.copy(then_expression.get_shape())\n-        elif isinstance(then_expression, tf.IndexedSlices):\n-            g_shape = copy.copy(then_expression.dense_shape)\n-        if condition.dtype != tf.bool:\n-            condition = tf.cast(condition, 'bool')\n-        g = tf.cond(condition,\n-                    lambda: then_expression,\n-                    lambda: else_expression)\n-        if isinstance(then_expression, tf.Tensor):\n-            g.set_shape(g_shape)\n-        elif isinstance(then_expression, tf.IndexedSlices):\n-            g._dense_shape = g_shape\n-    else:\n-        g = K.switch(K.greater_equal(n, c), g * c / n, g)\n-    return g\n-\n-\n-class Optimizer(object):\n-    \"\"\"Abstract optimizer base class.\n-\n-    Note: this is the parent class of all optimizers, not an actual optimizer\n-    that can be used for training models.\n-\n-    All Keras optimizers support the following keyword arguments:\n-\n-        clipnorm: float >= 0. Gradients will be clipped\n-            when their L2 norm exceeds this value.\n-        clipvalue: float >= 0. Gradients will be clipped\n-            when their absolute value exceeds this value.\n-    \"\"\"\n-\n-    def __init__(self, **kwargs):\n-        allowed_kwargs = {'clipnorm', 'clipvalue'}\n-        for k in kwargs:\n-            if k not in allowed_kwargs:\n-                raise TypeError('Unexpected keyword argument '\n-                                'passed to optimizer: ' + str(k))\n-        self.__dict__.update(kwargs)\n-        self.updates = []\n-        self.weights = []\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        raise NotImplementedError\n-\n-    def get_gradients(self, loss, params):\n-        grads = K.gradients(loss, params)\n-        if any(x is None for x in grads):\n-            raise ValueError('An operation has `None` for gradient. '\n-                             'Please make sure that all of your ops have a '\n-                             'gradient defined (i.e. are differentiable). '\n-                             'Common ops without gradient: '\n-                             'K.argmax, K.round, K.eval.')\n-        if hasattr(self, 'clipnorm') and self.clipnorm > 0:\n-            norm = K.sqrt(sum([K.sum(K.square(g)) for g in grads]))\n-            grads = [clip_norm(g, self.clipnorm, norm) for g in grads]\n-        if hasattr(self, 'clipvalue') and self.clipvalue > 0:\n-            grads = [K.clip(g, -self.clipvalue, self.clipvalue) for g in grads]\n-        return grads\n-\n-    def set_weights(self, weights):\n-        \"\"\"Sets the weights of the optimizer, from Numpy arrays.\n-\n-        Should only be called after computing the gradients\n-        (otherwise the optimizer has no weights).\n-\n-        # Arguments\n-            weights: a list of Numpy arrays. The number\n-                of arrays and their shape must match\n-                number of the dimensions of the weights\n-                of the optimizer (i.e. it should match the\n-                output of `get_weights`).\n-\n-        # Raises\n-            ValueError: in case of incompatible weight shapes.\n-        \"\"\"\n-        params = self.weights\n-        if len(params) != len(weights):\n-            raise ValueError('Length of the specified weight list (' +\n-                             str(len(weights)) +\n-                             ') does not match the number of weights ' +\n-                             'of the optimizer (' + str(len(params)) + ')')\n-        weight_value_tuples = []\n-        param_values = K.batch_get_value(params)\n-        for pv, p, w in zip(param_values, params, weights):\n-            if pv.shape != w.shape:\n-                raise ValueError('Optimizer weight shape ' +\n-                                 str(pv.shape) +\n-                                 ' not compatible with '\n-                                 'provided weight shape ' + str(w.shape))\n-            weight_value_tuples.append((p, w))\n-        K.batch_set_value(weight_value_tuples)\n-\n-    def get_weights(self):\n-        \"\"\"Returns the current value of the weights of the optimizer.\n-\n-        # Returns\n-            A list of numpy arrays.\n-        \"\"\"\n-        return K.batch_get_value(self.weights)\n-\n-    def get_config(self):\n-        config = {}\n-        if hasattr(self, 'clipnorm'):\n-            config['clipnorm'] = self.clipnorm\n-        if hasattr(self, 'clipvalue'):\n-            config['clipvalue'] = self.clipvalue\n-        return config\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        return cls(**config)\n-\n-    @property\n-    def lr(self):\n-        # Legacy support.\n-        return self.learning_rate\n-\n-\n-class SGD(Optimizer):\n-    \"\"\"Stochastic gradient descent optimizer.\n-\n-    Includes support for momentum,\n-    learning rate decay, and Nesterov momentum.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Learning rate.\n-        momentum: float >= 0. Parameter that accelerates SGD\n-            in the relevant direction and dampens oscillations.\n-        nesterov: boolean. Whether to apply Nesterov momentum.\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.01, momentum=0.,\n-                 nesterov=False, **kwargs):\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        super(SGD, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.momentum = K.variable(momentum, name='momentum')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-        self.nesterov = nesterov\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-        # momentum\n-        shapes = [K.int_shape(p) for p in params]\n-        moments = [K.zeros(shape, name='moment_' + str(i))\n-                   for (i, shape) in enumerate(shapes)]\n-        self.weights = [self.iterations] + moments\n-        for p, g, m in zip(params, grads, moments):\n-            v = self.momentum * m - lr * g  # velocity\n-            self.updates.append(K.update(m, v))\n-\n-            if self.nesterov:\n-                new_p = p + self.momentum * v - lr * g\n-            else:\n-                new_p = p + v\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'momentum': float(K.get_value(self.momentum)),\n-                  'decay': float(K.get_value(self.decay)),\n-                  'nesterov': self.nesterov}\n-        base_config = super(SGD, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class RMSprop(Optimizer):\n-    \"\"\"RMSProp optimizer.\n-\n-    It is recommended to leave the parameters of this optimizer\n-    at their default values\n-    (except the learning rate, which can be freely tuned).\n-\n-    # Arguments\n-        learning_rate: float >= 0. Learning rate.\n-        rho: float >= 0.\n-\n-    # References\n-        - [rmsprop: Divide the gradient by a running average of its recent magnitude\n-           ](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.001, rho=0.9, **kwargs):\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(RMSprop, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.rho = K.variable(rho, name='rho')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        accumulators = [K.zeros(K.int_shape(p),\n-                        dtype=K.dtype(p),\n-                        name='accumulator_' + str(i))\n-                        for (i, p) in enumerate(params)]\n-        self.weights = [self.iterations] + accumulators\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-\n-        for p, g, a in zip(params, grads, accumulators):\n-            # update accumulator\n-            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n-            self.updates.append(K.update(a, new_a))\n-            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def set_weights(self, weights):\n-        params = self.weights\n-        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n-        # since it does not include iteration at head of the weight list. Set\n-        # iteration to 0.\n-        if len(params) == len(weights) + 1:\n-            weights = [np.array(0)] + weights\n-        super(RMSprop, self).set_weights(weights)\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'rho': float(K.get_value(self.rho)),\n-                  'decay': float(K.get_value(self.decay)),\n-                  'epsilon': self.epsilon}\n-        base_config = super(RMSprop, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Adagrad(Optimizer):\n-    \"\"\"Adagrad optimizer.\n-\n-    Adagrad is an optimizer with parameter-specific learning rates,\n-    which are adapted relative to how frequently a parameter gets\n-    updated during training. The more updates a parameter receives,\n-    the smaller the learning rate.\n-\n-    It is recommended to leave the parameters of this optimizer\n-    at their default values.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Initial learning rate.\n-\n-    # References\n-        - [Adaptive Subgradient Methods for Online Learning and Stochastic\n-           Optimization](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.01, **kwargs):\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(Adagrad, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        shapes = [K.int_shape(p) for p in params]\n-        accumulators = [K.zeros(shape, name='accumulator_' + str(i))\n-                        for (i, shape) in enumerate(shapes)]\n-        self.weights = [self.iterations] + accumulators\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-\n-        for p, g, a in zip(params, grads, accumulators):\n-            new_a = a + K.square(g)  # update accumulator\n-            self.updates.append(K.update(a, new_a))\n-            new_p = p - lr * g / (K.sqrt(new_a) + self.epsilon)\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def set_weights(self, weights):\n-        params = self.weights\n-        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n-        # since it does not include iteration at head of the weight list. Set\n-        # iteration to 0.\n-        if len(params) == len(weights) + 1:\n-            weights = [np.array(0)] + weights\n-        super(Adagrad, self).set_weights(weights)\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'decay': float(K.get_value(self.decay)),\n-                  'epsilon': self.epsilon}\n-        base_config = super(Adagrad, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Adadelta(Optimizer):\n-    \"\"\"Adadelta optimizer.\n-\n-    Adadelta is a more robust extension of Adagrad\n-    that adapts learning rates based on a moving window of gradient updates,\n-    instead of accumulating all past gradients. This way, Adadelta continues\n-    learning even when many updates have been done. Compared to Adagrad, in the\n-    original version of Adadelta you don't have to set an initial learning\n-    rate. In this version, initial learning rate and decay factor can\n-    be set, as in most other Keras optimizers.\n-\n-    It is recommended to leave the parameters of this optimizer\n-    at their default values.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Initial learning rate, defaults to 1.\n-            It is recommended to leave it at the default value.\n-        rho: float >= 0. Adadelta decay factor, corresponding to fraction of\n-            gradient to keep at each time step.\n-\n-    # References\n-        - [Adadelta - an adaptive learning rate method](\n-           https://arxiv.org/abs/1212.5701)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=1.0, rho=0.95, **kwargs):\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(Adadelta, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-        self.rho = rho\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        shapes = [K.int_shape(p) for p in params]\n-        accumulators = [K.zeros(shape, name='accumulator_' + str(i))\n-                        for (i, shape) in enumerate(shapes)]\n-        delta_accumulators = [K.zeros(shape, name='delta_accumulator_' + str(i))\n-                              for (i, shape) in enumerate(shapes)]\n-        self.weights = [self.iterations] + accumulators + delta_accumulators\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-\n-        for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n-            # update accumulator\n-            new_a = self.rho * a + (1. - self.rho) * K.square(g)\n-            self.updates.append(K.update(a, new_a))\n-\n-            # use the new accumulator and the *old* delta_accumulator\n-            update = g * K.sqrt(d_a + self.epsilon) / K.sqrt(new_a + self.epsilon)\n-            new_p = p - lr * update\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-\n-            # update delta_accumulator\n-            new_d_a = self.rho * d_a + (1 - self.rho) * K.square(update)\n-            self.updates.append(K.update(d_a, new_d_a))\n-        return self.updates\n-\n-    def set_weights(self, weights):\n-        params = self.weights\n-        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n-        # since it does not include iteration at head of the weight list. Set\n-        # iteration to 0.\n-        if len(params) == len(weights) + 1:\n-            weights = [np.array(0)] + weights\n-        super(Adadelta, self).set_weights(weights)\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'rho': self.rho,\n-                  'decay': float(K.get_value(self.decay)),\n-                  'epsilon': self.epsilon}\n-        base_config = super(Adadelta, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Adam(Optimizer):\n-    \"\"\"Adam optimizer.\n-\n-    Default parameters follow those provided in the original paper.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Learning rate.\n-        beta_1: float, 0 < beta < 1. Generally close to 1.\n-        beta_2: float, 0 < beta < 1. Generally close to 1.\n-        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n-            algorithm from the paper \"On the Convergence of Adam and\n-            Beyond\".\n-\n-    # References\n-        - [Adam - A Method for Stochastic Optimization](\n-           https://arxiv.org/abs/1412.6980v8)\n-        - [On the Convergence of Adam and Beyond](\n-           https://openreview.net/forum?id=ryQu7f-RZ)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.001, beta_1=0.9, beta_2=0.999,\n-                 amsgrad=False, **kwargs):\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(Adam, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.beta_1 = K.variable(beta_1, name='beta_1')\n-            self.beta_2 = K.variable(beta_2, name='beta_2')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-        self.amsgrad = amsgrad\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-\n-        t = K.cast(self.iterations, K.floatx()) + 1\n-        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n-                     (1. - K.pow(self.beta_1, t)))\n-\n-        ms = [K.zeros(K.int_shape(p),\n-              dtype=K.dtype(p),\n-              name='m_' + str(i))\n-              for (i, p) in enumerate(params)]\n-        vs = [K.zeros(K.int_shape(p),\n-              dtype=K.dtype(p),\n-              name='v_' + str(i))\n-              for (i, p) in enumerate(params)]\n-\n-        if self.amsgrad:\n-            vhats = [K.zeros(K.int_shape(p),\n-                     dtype=K.dtype(p),\n-                     name='vhat_' + str(i))\n-                     for (i, p) in enumerate(params)]\n-        else:\n-            vhats = [K.zeros(1, name='vhat_' + str(i))\n-                     for i in range(len(params))]\n-        self.weights = [self.iterations] + ms + vs + vhats\n-\n-        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n-            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n-            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n-            if self.amsgrad:\n-                vhat_t = K.maximum(vhat, v_t)\n-                p_t = p - lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n-                self.updates.append(K.update(vhat, vhat_t))\n-            else:\n-                p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n-\n-            self.updates.append(K.update(m, m_t))\n-            self.updates.append(K.update(v, v_t))\n-            new_p = p_t\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'beta_1': float(K.get_value(self.beta_1)),\n-                  'beta_2': float(K.get_value(self.beta_2)),\n-                  'decay': float(K.get_value(self.decay)),\n-                  'epsilon': self.epsilon,\n-                  'amsgrad': self.amsgrad}\n-        base_config = super(Adam, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Adamax(Optimizer):\n-    \"\"\"Adamax optimizer from Adam paper's Section 7.\n-\n-    It is a variant of Adam based on the infinity norm.\n-    Default parameters follow those provided in the paper.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Learning rate.\n-        beta_1: float, 0 < beta < 1. Generally close to 1.\n-        beta_2: float, 0 < beta < 1. Generally close to 1.\n-\n-    # References\n-        - [Adam - A Method for Stochastic Optimization](\n-           https://arxiv.org/abs/1412.6980v8)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.002, beta_1=0.9, beta_2=0.999, **kwargs):\n-        self.initial_decay = kwargs.pop('decay', 0.0)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(Adamax, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.beta_1 = K.variable(beta_1, name='beta_1')\n-            self.beta_2 = K.variable(beta_2, name='beta_2')\n-            self.decay = K.variable(self.initial_decay, name='decay')\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        lr = self.learning_rate\n-        if self.initial_decay > 0:\n-            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n-                                                      K.dtype(self.decay))))\n-\n-        t = K.cast(self.iterations, K.floatx()) + 1\n-        lr_t = lr / (1. - K.pow(self.beta_1, t))\n-\n-        shapes = [K.int_shape(p) for p in params]\n-        # zero init of 1st moment\n-        ms = [K.zeros(shape, name='m_' + str(i))\n-              for (i, shape) in enumerate(shapes)]\n-        # zero init of exponentially weighted infinity norm\n-        us = [K.zeros(shape, name='u_' + str(i))\n-              for (i, shape) in enumerate(shapes)]\n-        self.weights = [self.iterations] + ms + us\n-\n-        for p, g, m, u in zip(params, grads, ms, us):\n-\n-            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n-            u_t = K.maximum(self.beta_2 * u, K.abs(g))\n-            p_t = p - lr_t * m_t / (u_t + self.epsilon)\n-\n-            self.updates.append(K.update(m, m_t))\n-            self.updates.append(K.update(u, u_t))\n-            new_p = p_t\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'beta_1': float(K.get_value(self.beta_1)),\n-                  'beta_2': float(K.get_value(self.beta_2)),\n-                  'decay': float(K.get_value(self.decay)),\n-                  'epsilon': self.epsilon}\n-        base_config = super(Adamax, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class Nadam(Optimizer):\n-    \"\"\"Nesterov Adam optimizer.\n-\n-    Much like Adam is essentially RMSprop with momentum,\n-    Nadam is RMSprop with Nesterov momentum.\n-\n-    Default parameters follow those provided in the paper.\n-    It is recommended to leave the parameters of this optimizer\n-    at their default values.\n-\n-    # Arguments\n-        learning_rate: float >= 0. Learning rate.\n-        beta_1: float, 0 < beta < 1. Generally close to 1.\n-        beta_2: float, 0 < beta < 1. Generally close to 1.\n-\n-    # References\n-        - [Nadam report](http://cs229.stanford.edu/proj2015/054_report.pdf)\n-        - [On the importance of initialization and momentum in deep learning](\n-           http://www.cs.toronto.edu/~fritz/absps/momentum.pdf)\n-    \"\"\"\n-\n-    def __init__(self, learning_rate=0.002, beta_1=0.9, beta_2=0.999, **kwargs):\n-        self.schedule_decay = kwargs.pop('schedule_decay', 0.004)\n-        self.epsilon = kwargs.pop('epsilon', K.epsilon())\n-        learning_rate = kwargs.pop('lr', learning_rate)\n-        super(Nadam, self).__init__(**kwargs)\n-        with K.name_scope(self.__class__.__name__):\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-            self.m_schedule = K.variable(1., name='m_schedule')\n-            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n-            self.beta_1 = K.variable(beta_1, name='beta_1')\n-            self.beta_2 = K.variable(beta_2, name='beta_2')\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        grads = self.get_gradients(loss, params)\n-        self.updates = [K.update_add(self.iterations, 1)]\n-\n-        t = K.cast(self.iterations, K.floatx()) + 1\n-\n-        # Due to the recommendations in [2], i.e. warming momentum schedule\n-        momentum_cache_t = self.beta_1 * (1. - 0.5 * (\n-            K.pow(K.cast_to_floatx(0.96), t * self.schedule_decay)))\n-        momentum_cache_t_1 = self.beta_1 * (1. - 0.5 * (\n-            K.pow(K.cast_to_floatx(0.96), (t + 1) * self.schedule_decay)))\n-        m_schedule_new = self.m_schedule * momentum_cache_t\n-        m_schedule_next = self.m_schedule * momentum_cache_t * momentum_cache_t_1\n-        self.updates.append((self.m_schedule, m_schedule_new))\n-\n-        shapes = [K.int_shape(p) for p in params]\n-        ms = [K.zeros(shape, name='m_' + str(i))\n-              for (i, shape) in enumerate(shapes)]\n-        vs = [K.zeros(shape, name='v_' + str(i))\n-              for (i, shape) in enumerate(shapes)]\n-\n-        self.weights = [self.iterations, self.m_schedule] + ms + vs\n-\n-        for p, g, m, v in zip(params, grads, ms, vs):\n-            # the following equations given in [1]\n-            g_prime = g / (1. - m_schedule_new)\n-            m_t = self.beta_1 * m + (1. - self.beta_1) * g\n-            m_t_prime = m_t / (1. - m_schedule_next)\n-            v_t = self.beta_2 * v + (1. - self.beta_2) * K.square(g)\n-            v_t_prime = v_t / (1. - K.pow(self.beta_2, t))\n-            m_t_bar = (1. - momentum_cache_t) * g_prime + (\n-                momentum_cache_t_1 * m_t_prime)\n-\n-            self.updates.append(K.update(m, m_t))\n-            self.updates.append(K.update(v, v_t))\n-\n-            p_t = (p - self.learning_rate * m_t_bar / (K.sqrt(v_t_prime) +\n-                   self.epsilon))\n-            new_p = p_t\n-\n-            # Apply constraints.\n-            if getattr(p, 'constraint', None) is not None:\n-                new_p = p.constraint(new_p)\n-\n-            self.updates.append(K.update(p, new_p))\n-        return self.updates\n-\n-    def set_weights(self, weights):\n-        params = self.weights\n-        # Override set_weights for backward compatibility of Keras 2.2.4 optimizer\n-        # since it does not include m_schedule at head of the weight list. Set\n-        # m_schedule to 1.\n-        if len(params) == len(weights) + 1:\n-            weights = [weights[0]] + [np.array(1.)] + weights[1:]\n-        super(Nadam, self).set_weights(weights)\n-\n-    def get_config(self):\n-        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n-                  'beta_1': float(K.get_value(self.beta_1)),\n-                  'beta_2': float(K.get_value(self.beta_2)),\n-                  'epsilon': self.epsilon,\n-                  'schedule_decay': self.schedule_decay}\n-        base_config = super(Nadam, self).get_config()\n-        return dict(list(base_config.items()) + list(config.items()))\n-\n-\n-class TFOptimizer(Optimizer):\n-    \"\"\"Wrapper class for native TensorFlow optimizers.\n-\n-    # Arguments\n-        optimizer: Selected optimizer\n-    \"\"\"\n-\n-    def __init__(self, optimizer):\n-        self.optimizer = optimizer\n-        with K.name_scope(self.__class__.__name__):\n-            self.iterations = K.variable(0, dtype='int64', name='iterations')\n-\n-    @interfaces.legacy_get_updates_support\n-    @K.symbolic\n-    def get_updates(self, loss, params):\n-        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n-            return self.optimizer.get_updates(loss, params)\n-        else:\n-            grads = self.optimizer.compute_gradients(loss, var_list=params)\n-        self.updates = [K.update_add(self.iterations, 1)]\n-        opt_update = self.optimizer.apply_gradients(\n-            grads, global_step=self.iterations)\n-        self.updates.append(opt_update)\n-        return self.updates\n-\n-    @property\n-    def weights(self):\n-        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n-            return self.optimizer.weights\n-        raise NotImplementedError\n-\n-    def get_config(self):\n-        if isinstance(self.optimizer, tf.keras.optimizers.Optimizer):\n-            return self.optimizer.get_config\n-        raise NotImplementedError\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        if tf.__version__.startswith('1.'):\n-            raise NotImplementedError\n-        return cls(**config)\n-\n-\n-# Aliases.\n-\n-sgd = SGD\n-rmsprop = RMSprop\n-adagrad = Adagrad\n-adadelta = Adadelta\n-adam = Adam\n-adamax = Adamax\n-nadam = Nadam\n-\n-\n-def serialize(optimizer):\n-    return serialize_keras_object(optimizer)\n-\n-\n-def deserialize(config, custom_objects=None):\n-    \"\"\"Inverse of the `serialize` function.\n-\n-    # Arguments\n-        config: Optimizer configuration dictionary.\n-        custom_objects: Optional dictionary mapping\n-            names (strings) to custom objects\n-            (classes and functions)\n-            to be considered during deserialization.\n-\n-    # Returns\n-        A Keras Optimizer instance.\n-    \"\"\"\n-    all_classes = {\n-        'sgd': SGD,\n-        'rmsprop': RMSprop,\n-        'adagrad': Adagrad,\n-        'adadelta': Adadelta,\n-        'adam': Adam,\n-        'adamax': Adamax,\n-        'nadam': Nadam,\n-        'tfoptimizer': TFOptimizer,\n-    }\n-    # Make deserialization case-insensitive for built-in optimizers.\n-    if config['class_name'].lower() in all_classes:\n-        config['class_name'] = config['class_name'].lower()\n-    return deserialize_keras_object(config,\n-                                    module_objects=all_classes,\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='optimizer')\n-\n-\n-def get(identifier):\n-    \"\"\"Retrieves a Keras Optimizer instance.\n-\n-    # Arguments\n-        identifier: Optimizer identifier, one of\n-            - String: name of an optimizer\n-            - Dictionary: configuration dictionary.\n-            - Keras Optimizer instance (it will be returned unchanged).\n-            - TensorFlow Optimizer instance\n-                (it will be wrapped as a Keras Optimizer).\n-\n-    # Returns\n-        A Keras Optimizer instance.\n-\n-    # Raises\n-        ValueError: If `identifier` cannot be interpreted.\n-    \"\"\"\n-    if K.backend() == 'tensorflow':\n-        # Wrap TF optimizer instances\n-        if tf.__version__.startswith('1.'):\n-            try:\n-                TFOpt = tf.compat.v1.train.Optimizer\n-            except AttributeError:\n-                TFOpt = tf.train.Optimizer\n-            if isinstance(identifier, TFOpt):\n-                return TFOptimizer(identifier)\n-        elif isinstance(identifier, tf.keras.optimizers.Optimizer):\n-            return TFOptimizer(identifier)\n-    if isinstance(identifier, dict):\n-        return deserialize(identifier)\n-    elif isinstance(identifier, six.string_types):\n-        config = {'class_name': str(identifier), 'config': {}}\n-        return deserialize(config)\n-    if isinstance(identifier, Optimizer):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret optimizer identifier: ' +\n-                         str(identifier))\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.optimizers import *\n\n@@ -0,0 +1 @@\n+from tensorflow.keras.optimizers.schedules import *\n\n@@ -1,12 +1 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from .. import backend\n-from .. import utils\n-\n-import keras_preprocessing\n-\n-from . import image\n-from . import sequence\n-from . import text\n+from tensorflow.keras.preprocessing import *\n\n@@ -1,600 +1,3 @@\n-\"\"\"Utilities for real-time data augmentation on image data.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Utilities for real-time data augmentation on image data.\"\"\"\n \n-from .. import backend\n-from .. import utils\n-from ..utils import generic_utils\n-\n-from keras_preprocessing import image\n-\n-random_rotation = image.random_rotation\n-random_shift = image.random_shift\n-random_shear = image.random_shear\n-random_zoom = image.random_zoom\n-apply_channel_shift = image.apply_channel_shift\n-random_channel_shift = image.random_channel_shift\n-apply_brightness_shift = image.apply_brightness_shift\n-random_brightness = image.random_brightness\n-apply_affine_transform = image.apply_affine_transform\n-load_img = image.load_img\n-\n-\n-def array_to_img(x, data_format=None, scale=True, dtype=None):\n-    \"\"\"Converts a 3D Numpy array to a PIL Image instance.\n-\n-    # Arguments\n-        x: Input Numpy array.\n-        data_format: Image data format.\n-            either \"channels_first\" or \"channels_last\".\n-            If omitted (`None`), then `backend.image_data_format()` is used.\n-        scale: Whether to rescale image values\n-            to be within `[0, 255]`.\n-        dtype: Dtype to use.\n-            If omitted (`None`), then `backend.floatx()` or `float32` are used.\n-\n-    # Returns\n-        A PIL Image instance.\n-\n-    # Raises\n-        ImportError: if PIL is not available.\n-        ValueError: if invalid `x` or `data_format` is passed.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = backend.image_data_format()\n-    if dtype is None:\n-        dtype = backend.floatx()\n-    return image.array_to_img(x,\n-                              data_format=data_format,\n-                              scale=scale,\n-                              dtype=dtype)\n-\n-\n-def img_to_array(img, data_format=None, dtype=None):\n-    \"\"\"Converts a PIL Image instance to a Numpy array.\n-\n-    # Arguments\n-        img: PIL Image instance.\n-        data_format: Image data format, either \"channels_first\" or \"channels_last\".\n-            If omitted (`None`), then `backend.image_data_format()` is used.\n-        dtype: Dtype to use for the returned array.\n-            If omitted (`None`), then `backend.floatx()` or `float32` are used.\n-\n-    # Returns\n-        A 3D Numpy array.\n-\n-    # Raises\n-        ValueError: if invalid `img` or `data_format` is passed.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = backend.image_data_format()\n-    if dtype is None:\n-        dtype = backend.floatx()\n-    return image.img_to_array(img, data_format=data_format, dtype=dtype)\n-\n-\n-def save_img(path,\n-             x,\n-             data_format=None,\n-             file_format=None,\n-             scale=True, **kwargs):\n-    \"\"\"Saves an image stored as a Numpy array to a path or file object.\n-\n-    # Arguments\n-        path: Path or file object.\n-        x: Numpy array.\n-        data_format: Image data format,\n-            either \"channels_first\" or \"channels_last\".\n-            If omitted (`None`), then `backend.image_data_format()` is used.\n-        file_format: Optional file format override. If omitted, the\n-            format to use is determined from the filename extension.\n-            If a file object was used instead of a filename, this\n-            parameter should always be used.\n-        scale: Whether to rescale image values to be within `[0, 255]`.\n-        **kwargs: Additional keyword arguments passed to `PIL.Image.save()`.\n-    \"\"\"\n-    if data_format is None:\n-        data_format = backend.image_data_format()\n-    return image.save_img(path,\n-                          x,\n-                          data_format=data_format,\n-                          file_format=file_format,\n-                          scale=scale, **kwargs)\n-\n-\n-class Iterator(image.Iterator, utils.Sequence):\n-    pass\n-\n-\n-class DirectoryIterator(image.DirectoryIterator, Iterator):\n-    __doc__ = image.DirectoryIterator.__doc__\n-\n-    def __init__(self, directory, image_data_generator,\n-                 target_size=(256, 256),\n-                 color_mode='rgb',\n-                 classes=None,\n-                 class_mode='categorical',\n-                 batch_size=32,\n-                 shuffle=True,\n-                 seed=None,\n-                 data_format=None,\n-                 save_to_dir=None,\n-                 save_prefix='',\n-                 save_format='png',\n-                 follow_links=False,\n-                 subset=None,\n-                 interpolation='nearest',\n-                 dtype=None):\n-        if data_format is None:\n-            data_format = backend.image_data_format()\n-        if dtype is None:\n-            dtype = backend.floatx()\n-        super(DirectoryIterator, self).__init__(\n-            directory, image_data_generator,\n-            target_size=target_size,\n-            color_mode=color_mode,\n-            classes=classes,\n-            class_mode=class_mode,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            seed=seed,\n-            data_format=data_format,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            follow_links=follow_links,\n-            subset=subset,\n-            interpolation=interpolation,\n-            dtype=dtype)\n-\n-\n-class NumpyArrayIterator(image.NumpyArrayIterator, Iterator):\n-    __doc__ = image.NumpyArrayIterator.__doc__\n-\n-    def __init__(self, x, y, image_data_generator,\n-                 batch_size=32,\n-                 shuffle=False,\n-                 sample_weight=None,\n-                 seed=None,\n-                 data_format=None,\n-                 save_to_dir=None,\n-                 save_prefix='',\n-                 save_format='png',\n-                 subset=None,\n-                 dtype=None):\n-        if data_format is None:\n-            data_format = backend.image_data_format()\n-        if dtype is None:\n-            dtype = backend.floatx()\n-        super(NumpyArrayIterator, self).__init__(\n-            x, y, image_data_generator,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            sample_weight=sample_weight,\n-            seed=seed,\n-            data_format=data_format,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            subset=subset,\n-            dtype=dtype)\n-\n-\n-class DataFrameIterator(image.DataFrameIterator, Iterator):\n-    __doc__ = image.DataFrameIterator.__doc__\n-\n-    def __init__(self,\n-                 dataframe,\n-                 directory=None,\n-                 image_data_generator=None,\n-                 x_col='filename',\n-                 y_col='class',\n-                 weight_col=None,\n-                 target_size=(256, 256),\n-                 color_mode='rgb',\n-                 classes=None,\n-                 class_mode='categorical',\n-                 batch_size=32,\n-                 shuffle=True,\n-                 seed=None,\n-                 data_format='channels_last',\n-                 save_to_dir=None,\n-                 save_prefix='',\n-                 save_format='png',\n-                 subset=None,\n-                 interpolation='nearest',\n-                 dtype='float32',\n-                 validate_filenames=True):\n-        if data_format is None:\n-            data_format = backend.image_data_format()\n-        if dtype is None:\n-            dtype = backend.floatx()\n-        super(DataFrameIterator, self).__init__(\n-            dataframe,\n-            directory=directory,\n-            image_data_generator=image_data_generator,\n-            x_col=x_col,\n-            y_col=y_col,\n-            weight_col=weight_col,\n-            target_size=target_size,\n-            color_mode=color_mode,\n-            classes=classes,\n-            class_mode=class_mode,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            seed=seed,\n-            data_format=data_format,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            subset=subset,\n-            interpolation=interpolation,\n-            dtype=dtype,\n-            validate_filenames=validate_filenames)\n-\n-\n-class ImageDataGenerator(image.ImageDataGenerator):\n-    __doc__ = image.ImageDataGenerator.__doc__\n-\n-    def __init__(self,\n-                 featurewise_center=False,\n-                 samplewise_center=False,\n-                 featurewise_std_normalization=False,\n-                 samplewise_std_normalization=False,\n-                 zca_whitening=False,\n-                 zca_epsilon=1e-6,\n-                 rotation_range=0,\n-                 width_shift_range=0.,\n-                 height_shift_range=0.,\n-                 brightness_range=None,\n-                 shear_range=0.,\n-                 zoom_range=0.,\n-                 channel_shift_range=0.,\n-                 fill_mode='nearest',\n-                 cval=0.,\n-                 horizontal_flip=False,\n-                 vertical_flip=False,\n-                 rescale=None,\n-                 preprocessing_function=None,\n-                 data_format='channels_last',\n-                 validation_split=0.0,\n-                 interpolation_order=1,\n-                 dtype='float32'):\n-        if data_format is None:\n-            data_format = backend.image_data_format()\n-        if dtype is None:\n-            dtype = backend.floatx()\n-        super(ImageDataGenerator, self).__init__(\n-            featurewise_center=featurewise_center,\n-            samplewise_center=samplewise_center,\n-            featurewise_std_normalization=featurewise_std_normalization,\n-            samplewise_std_normalization=samplewise_std_normalization,\n-            zca_whitening=zca_whitening,\n-            zca_epsilon=zca_epsilon,\n-            rotation_range=rotation_range,\n-            width_shift_range=width_shift_range,\n-            height_shift_range=height_shift_range,\n-            brightness_range=brightness_range,\n-            shear_range=shear_range,\n-            zoom_range=zoom_range,\n-            channel_shift_range=channel_shift_range,\n-            fill_mode=fill_mode,\n-            cval=cval,\n-            horizontal_flip=horizontal_flip,\n-            vertical_flip=vertical_flip,\n-            rescale=rescale,\n-            preprocessing_function=preprocessing_function,\n-            data_format=data_format,\n-            validation_split=validation_split,\n-            interpolation_order=interpolation_order,\n-            dtype=dtype)\n-\n-    def flow(self,\n-             x,\n-             y=None,\n-             batch_size=32,\n-             shuffle=True,\n-             sample_weight=None,\n-             seed=None,\n-             save_to_dir=None,\n-             save_prefix='',\n-             save_format='png',\n-             subset=None):\n-        \"\"\"Takes data & label arrays, generates batches of augmented data.\n-\n-        # Arguments\n-            x: Input data. Numpy array of rank 4 or a tuple.\n-                If tuple, the first element\n-                should contain the images and the second element\n-                another numpy array or a list of numpy arrays\n-                that gets passed to the output\n-                without any modifications.\n-                Can be used to feed the model miscellaneous data\n-                along with the images.\n-                In case of grayscale data, the channels axis of the image array\n-                should have value 1, in case\n-                of RGB data, it should have value 3, and in case\n-                of RGBA data, it should have value 4.\n-            y: Labels.\n-            batch_size: Int (default: 32).\n-            shuffle: Boolean (default: True).\n-            sample_weight: Sample weights.\n-            seed: Int (default: None).\n-            save_to_dir: None or str (default: None).\n-                This allows you to optionally specify a directory\n-                to which to save the augmented pictures being generated\n-                (useful for visualizing what you are doing).\n-            save_prefix: Str (default: `''`).\n-                Prefix to use for filenames of saved pictures\n-                (only relevant if `save_to_dir` is set).\n-            save_format: one of \"png\", \"jpeg\"\n-                (only relevant if `save_to_dir` is set). Default: \"png\".\n-            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n-                `validation_split` is set in `ImageDataGenerator`.\n-\n-        # Returns\n-            An `Iterator` yielding tuples of `(x, y)`\n-                where `x` is a numpy array of image data\n-                (in the case of a single image input) or a list\n-                of numpy arrays (in the case with\n-                additional inputs) and `y` is a numpy array\n-                of corresponding labels. If 'sample_weight' is not None,\n-                the yielded tuples are of the form `(x, y, sample_weight)`.\n-                If `y` is None, only the numpy array `x` is returned.\n-        \"\"\"\n-        return NumpyArrayIterator(\n-            x,\n-            y,\n-            self,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            sample_weight=sample_weight,\n-            seed=seed,\n-            data_format=self.data_format,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            subset=subset\n-        )\n-\n-    def flow_from_directory(self,\n-                            directory,\n-                            target_size=(256, 256),\n-                            color_mode='rgb',\n-                            classes=None,\n-                            class_mode='categorical',\n-                            batch_size=32,\n-                            shuffle=True,\n-                            seed=None,\n-                            save_to_dir=None,\n-                            save_prefix='',\n-                            save_format='png',\n-                            follow_links=False,\n-                            subset=None,\n-                            interpolation='nearest'):\n-        \"\"\"Takes the path to a directory & generates batches of augmented data.\n-\n-        # Arguments\n-            directory: string, path to the target directory.\n-                It should contain one subdirectory per class.\n-                Any PNG, JPG, BMP, PPM or TIF images\n-                inside each of the subdirectories directory tree\n-                will be included in the generator.\n-                See [this script](\n-                https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d)\n-                for more details.\n-            target_size: Tuple of integers `(height, width)`,\n-                default: `(256, 256)`.\n-                The dimensions to which all images found will be resized.\n-            color_mode: One of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n-                Whether the images will be converted to\n-                have 1, 3, or 4 channels.\n-            classes: Optional list of class subdirectories\n-                (e.g. `['dogs', 'cats']`). Default: None.\n-                If not provided, the list of classes will be automatically\n-                inferred from the subdirectory names/structure\n-                under `directory`, where each subdirectory will\n-                be treated as a different class\n-                (and the order of the classes, which will map to the label\n-                indices, will be alphanumeric).\n-                The dictionary containing the mapping from class names to class\n-                indices can be obtained via the attribute `class_indices`.\n-            class_mode: One of \"categorical\", \"binary\", \"sparse\",\n-                \"input\", or None. Default: \"categorical\".\n-                Determines the type of label arrays that are returned:\n-                - \"categorical\" will be 2D one-hot encoded labels,\n-                - \"binary\" will be 1D binary labels,\n-                    \"sparse\" will be 1D integer labels,\n-                - \"input\" will be images identical\n-                    to input images (mainly used to work with autoencoders).\n-                - If None, no labels are returned\n-                  (the generator will only yield batches of image data,\n-                  which is useful to use with `model.predict_generator()`).\n-                  Please note that in case of class_mode None,\n-                  the data still needs to reside in a subdirectory\n-                  of `directory` for it to work correctly.\n-            batch_size: Size of the batches of data (default: 32).\n-            shuffle: Whether to shuffle the data (default: True)\n-                If set to False, sorts the data in alphanumeric order.\n-            seed: Optional random seed for shuffling and transformations.\n-            save_to_dir: None or str (default: None).\n-                This allows you to optionally specify\n-                a directory to which to save\n-                the augmented pictures being generated\n-                (useful for visualizing what you are doing).\n-            save_prefix: Str. Prefix to use for filenames of saved pictures\n-                (only relevant if `save_to_dir` is set).\n-            save_format: One of \"png\", \"jpeg\"\n-                (only relevant if `save_to_dir` is set). Default: \"png\".\n-            follow_links: Whether to follow symlinks inside\n-                class subdirectories (default: False).\n-            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n-                `validation_split` is set in `ImageDataGenerator`.\n-            interpolation: Interpolation method used to\n-                resample the image if the\n-                target size is different from that of the loaded image.\n-                Supported methods are `\"nearest\"`, `\"bilinear\"`,\n-                and `\"bicubic\"`.\n-                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n-                supported. If PIL version 3.4.0 or newer is installed,\n-                `\"box\"` and `\"hamming\"` are also supported.\n-                By default, `\"nearest\"` is used.\n-\n-        # Returns\n-            A `DirectoryIterator` yielding tuples of `(x, y)`\n-                where `x` is a numpy array containing a batch\n-                of images with shape `(batch_size, *target_size, channels)`\n-                and `y` is a numpy array of corresponding labels.\n-        \"\"\"\n-        return DirectoryIterator(\n-            directory,\n-            self,\n-            target_size=target_size,\n-            color_mode=color_mode,\n-            classes=classes,\n-            class_mode=class_mode,\n-            data_format=self.data_format,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            seed=seed,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            follow_links=follow_links,\n-            subset=subset,\n-            interpolation=interpolation\n-        )\n-\n-    def flow_from_dataframe(self,\n-                            dataframe,\n-                            directory=None,\n-                            x_col=\"filename\",\n-                            y_col=\"class\",\n-                            weight_col=None,\n-                            target_size=(256, 256),\n-                            color_mode='rgb',\n-                            classes=None,\n-                            class_mode='categorical',\n-                            batch_size=32,\n-                            shuffle=True,\n-                            seed=None,\n-                            save_to_dir=None,\n-                            save_prefix='',\n-                            save_format='png',\n-                            subset=None,\n-                            interpolation='nearest',\n-                            validate_filenames=True,\n-                            **kwargs):\n-        \"\"\"Takes the dataframe and the path to a directory\n-         and generates batches of augmented/normalized data.\n-\n-        **A simple tutorial can be found **[here](\n-                                    http://bit.ly/keras_flow_from_dataframe).\n-\n-        # Arguments\n-            dataframe: Pandas dataframe containing the filepaths relative to\n-                `directory` (or absolute paths if `directory` is None) of the\n-                images in a string column. It should include other column/s\n-                depending on the `class_mode`:\n-                - if `class_mode` is `\"categorical\"` (default value) it must\n-                    include the `y_col` column with the class/es of each image.\n-                    Values in column can be string/list/tuple if a single class\n-                    or list/tuple if multiple classes.\n-                - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n-                    the given `y_col` column with class values as strings.\n-                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n-                the columns specified in `y_col`.\n-                - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n-            directory: string, path to the directory to read images from. If `None`,\n-                data in `x_col` column should be absolute paths.\n-            x_col: string, column in `dataframe` that contains the filenames (or\n-                absolute paths if `directory` is `None`).\n-            y_col: string or list, column/s in `dataframe` that has the target data.\n-            weight_col: string, column in `dataframe` that contains the sample\n-                weights. Default: `None`.\n-            target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n-                The dimensions to which all images found will be resized.\n-            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n-                Whether the images will be converted to have 1 or 3 color channels.\n-            classes: optional list of classes (e.g. `['dogs', 'cats']`).\n-                Default: None. If not provided, the list of classes will be\n-                automatically inferred from the `y_col`,\n-                which will map to the label indices, will be alphanumeric).\n-                The dictionary containing the mapping from class names to class\n-                indices can be obtained via the attribute `class_indices`.\n-            class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n-                \"raw\", sparse\" or None. Default: \"categorical\".\n-                Mode for yielding the targets:\n-                - `\"binary\"`: 1D numpy array of binary labels,\n-                - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n-                    Supports multi-label output.\n-                - `\"input\"`: images identical to input images (mainly used to\n-                    work with autoencoders),\n-                - `\"multi_output\"`: list with the values of the different columns,\n-                - `\"raw\"`: numpy array of values in `y_col` column(s),\n-                - `\"sparse\"`: 1D numpy array of integer labels,\n-                - `None`, no targets are returned (the generator will only yield\n-                    batches of image data, which is useful to use in\n-                    `model.predict_generator()`).\n-            batch_size: size of the batches of data (default: 32).\n-            shuffle: whether to shuffle the data (default: True)\n-            seed: optional random seed for shuffling and transformations.\n-            save_to_dir: None or str (default: None).\n-                This allows you to optionally specify a directory\n-                to which to save the augmented pictures being generated\n-                (useful for visualizing what you are doing).\n-            save_prefix: str. Prefix to use for filenames of saved pictures\n-                (only relevant if `save_to_dir` is set).\n-            save_format: one of \"png\", \"jpeg\"\n-                (only relevant if `save_to_dir` is set). Default: \"png\".\n-            follow_links: whether to follow symlinks inside class subdirectories\n-                (default: False).\n-            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n-                `validation_split` is set in `ImageDataGenerator`.\n-            interpolation: Interpolation method used to resample the image if the\n-                target size is different from that of the loaded image.\n-                Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n-                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n-                supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n-                `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n-            validate_filenames: Boolean, whether to validate image filenames in\n-                `x_col`. If `True`, invalid images will be ignored. Disabling this\n-                option can lead to speed-up in the execution of this function.\n-                Default: `True`.\n-\n-        # Returns\n-            A `DataFrameIterator` yielding tuples of `(x, y)`\n-            where `x` is a numpy array containing a batch\n-            of images with shape `(batch_size, *target_size, channels)`\n-            and `y` is a numpy array of corresponding labels.\n-        \"\"\"\n-        return DataFrameIterator(\n-            dataframe,\n-            directory,\n-            self,\n-            x_col=x_col,\n-            y_col=y_col,\n-            weight_col=weight_col,\n-            target_size=target_size,\n-            color_mode=color_mode,\n-            classes=classes,\n-            class_mode=class_mode,\n-            data_format=self.data_format,\n-            batch_size=batch_size,\n-            shuffle=shuffle,\n-            seed=seed,\n-            save_to_dir=save_to_dir,\n-            save_prefix=save_prefix,\n-            save_format=save_format,\n-            subset=subset,\n-            interpolation=interpolation,\n-            validate_filenames=validate_filenames,\n-            **kwargs\n-        )\n-\n-\n-array_to_img.__doc__ = image.array_to_img.__doc__\n-img_to_array.__doc__ = image.img_to_array.__doc__\n-save_img.__doc__ = image.save_img.__doc__\n+from tensorflow.keras.preprocessing.image import *\n\n@@ -1,78 +1,3 @@\n-\"\"\"Utilities for preprocessing sequence data.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Utilities for preprocessing sequence data.\"\"\"\n \n-from keras_preprocessing import sequence\n-from .. import utils\n-\n-pad_sequences = sequence.pad_sequences\n-make_sampling_table = sequence.make_sampling_table\n-skipgrams = sequence.skipgrams\n-_remove_long_seq = sequence._remove_long_seq  # TODO: make it public?\n-\n-\n-class TimeseriesGenerator(sequence.TimeseriesGenerator, utils.Sequence):\n-    \"\"\"Utility class for generating batches of temporal data.\n-\n-    This class takes in a sequence of data-points gathered at\n-    equal intervals, along with time series parameters such as\n-    stride, length of history, etc., to produce batches for\n-    training/validation.\n-\n-    # Arguments\n-        data: Indexable generator (such as list or Numpy array)\n-            containing consecutive data points (timesteps).\n-            The data should be at 2D, and axis 0 is expected\n-            to be the time dimension.\n-        targets: Targets corresponding to timesteps in `data`.\n-            It should have same length as `data`.\n-        length: Length of the output sequences (in number of timesteps).\n-        sampling_rate: Period between successive individual timesteps\n-            within sequences. For rate `r`, timesteps\n-            `data[i]`, `data[i-r]`, ... `data[i - length]`\n-            are used for create a sample sequence.\n-        stride: Period between successive output sequences.\n-            For stride `s`, consecutive output samples would\n-            be centered around `data[i]`, `data[i+s]`, `data[i+2*s]`, etc.\n-        start_index: Data points earlier than `start_index` will not be used\n-            in the output sequences. This is useful to reserve part of the\n-            data for test or validation.\n-        end_index: Data points later than `end_index` will not be used\n-            in the output sequences. This is useful to reserve part of the\n-            data for test or validation.\n-        shuffle: Whether to shuffle output samples,\n-            or instead draw them in chronological order.\n-        reverse: Boolean: if `true`, timesteps in each output sample will be\n-            in reverse chronological order.\n-        batch_size: Number of timeseries samples in each batch\n-            (except maybe the last one).\n-\n-    # Returns\n-        A [Sequence](/utils/#sequence) instance.\n-\n-    # Examples\n-\n-    ```python\n-    from keras.preprocessing.sequence import TimeseriesGenerator\n-    import numpy as np\n-\n-    data = np.array([[i] for i in range(50)])\n-    targets = np.array([[i] for i in range(50)])\n-\n-    data_gen = TimeseriesGenerator(data, targets,\n-                                   length=10, sampling_rate=2,\n-                                   batch_size=2)\n-    assert len(data_gen) == 20\n-\n-    batch_0 = data_gen[0]\n-    x, y = batch_0\n-    assert np.array_equal(x,\n-                          np.array([[[0], [2], [4], [6], [8]],\n-                                    [[1], [3], [5], [7], [9]]]))\n-    assert np.array_equal(y,\n-                          np.array([[10], [11]]))\n-    ```\n-    \"\"\"\n-    pass\n+from tensorflow.keras.preprocessing.sequence import *\n\n@@ -1,13 +1,3 @@\n-\"\"\"Utilities for text input preprocessing.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Utilities for text input preprocessing.\"\"\"\n \n-from keras_preprocessing import text\n-\n-text_to_word_sequence = text.text_to_word_sequence\n-one_hot = text.one_hot\n-hashing_trick = text.hashing_trick\n-Tokenizer = text.Tokenizer\n-tokenizer_from_json = text.tokenizer_from_json\n+from tensorflow.keras.preprocessing.text import *\n\\ No newline at end of file\n\n@@ -1,88 +1,2 @@\n-\"\"\"Built-in regularizers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import six\n-from . import backend as K\n-from .utils.generic_utils import serialize_keras_object\n-from .utils.generic_utils import deserialize_keras_object\n-\n-\n-class Regularizer(object):\n-    \"\"\"Regularizer base class.\n-    \"\"\"\n-\n-    def __call__(self, x):\n-        return 0.\n-\n-    @classmethod\n-    def from_config(cls, config):\n-        return cls(**config)\n-\n-\n-class L1L2(Regularizer):\n-    \"\"\"Regularizer for L1 and L2 regularization.\n-\n-    # Arguments\n-        l1: Float; L1 regularization factor.\n-        l2: Float; L2 regularization factor.\n-    \"\"\"\n-\n-    def __init__(self, l1=0., l2=0.):\n-        self.l1 = K.cast_to_floatx(l1)\n-        self.l2 = K.cast_to_floatx(l2)\n-\n-    def __call__(self, x):\n-        regularization = 0.\n-        if self.l1:\n-            regularization += self.l1 * K.sum(K.abs(x))\n-        if self.l2:\n-            regularization += self.l2 * K.sum(K.square(x))\n-        return regularization\n-\n-    def get_config(self):\n-        return {'l1': float(self.l1),\n-                'l2': float(self.l2)}\n-\n-\n-# Aliases.\n-\n-\n-def l1(l=0.01):\n-    return L1L2(l1=l)\n-\n-\n-def l2(l=0.01):\n-    return L1L2(l2=l)\n-\n-\n-def l1_l2(l1=0.01, l2=0.01):\n-    return L1L2(l1=l1, l2=l2)\n-\n-\n-def serialize(regularizer):\n-    return serialize_keras_object(regularizer)\n-\n-\n-def deserialize(config, custom_objects=None):\n-    return deserialize_keras_object(config,\n-                                    module_objects=globals(),\n-                                    custom_objects=custom_objects,\n-                                    printable_module_name='regularizer')\n-\n-\n-def get(identifier):\n-    if identifier is None:\n-        return None\n-    if isinstance(identifier, dict):\n-        return deserialize(identifier)\n-    elif isinstance(identifier, six.string_types):\n-        config = {'class_name': str(identifier), 'config': {}}\n-        return deserialize(config)\n-    elif callable(identifier):\n-        return identifier\n-    else:\n-        raise ValueError('Could not interpret regularizer identifier: ' +\n-                         str(identifier))\n+\"\"\"Built-in regularizers.\"\"\"\n+from tensorflow.keras.regularizers import *\n\n@@ -1,30 +1 @@\n-from __future__ import absolute_import\n-from . import np_utils\n-from . import generic_utils\n-from . import data_utils\n-from . import io_utils\n-from . import conv_utils\n-from . import losses_utils\n-from . import metrics_utils\n-\n-# Globally-importable utils.\n-from .io_utils import HDF5Matrix\n-from .io_utils import H5Dict\n-from .data_utils import get_file\n-from .data_utils import Sequence\n-from .data_utils import GeneratorEnqueuer\n-from .data_utils import OrderedEnqueuer\n-from .generic_utils import CustomObjectScope\n-from .generic_utils import custom_object_scope\n-from .generic_utils import get_custom_objects\n-from .generic_utils import serialize_keras_object\n-from .generic_utils import deserialize_keras_object\n-from .generic_utils import Progbar\n-from .layer_utils import convert_all_kernels_in_model\n-from .layer_utils import get_source_inputs\n-from .layer_utils import print_summary\n-from .vis_utils import model_to_dot\n-from .vis_utils import plot_model\n-from .np_utils import to_categorical\n-from .np_utils import normalize\n-from .multi_gpu_utils import multi_gpu_model\n+from tensorflow.keras.utils import *\n\n@@ -1,12 +1,6 @@\n-\"\"\"Utilities used in convolutional layers.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Utilities used in convolutional layers.\"\"\"\n \n-from six.moves import range\n import numpy as np\n-from .. import backend as K\n \n \n def normalize_tuple(value, n, name):\n@@ -51,8 +45,6 @@ def normalize_tuple(value, n, name):\n def normalize_padding(value):\n     padding = value.lower()\n     allowed = {'valid', 'same', 'causal'}\n-    if K.backend() == 'theano':\n-        allowed.add('full')\n     if padding not in allowed:\n         raise ValueError('The `padding` argument must be one of \"valid\", \"same\" '\n                          '(or \"causal\" for Conv1D). Received: {}'.format(padding))\n\n@@ -1,742 +1,8 @@\n \"\"\"Utilities for file download and caching.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n \n-import hashlib\n-import multiprocessing as mp\n-import os\n-import random\n-import shutil\n-import sys\n-import tarfile\n-import threading\n-import time\n-import warnings\n-import zipfile\n-from abc import abstractmethod\n-from contextlib import closing\n-from multiprocessing.pool import ThreadPool\n+from tensorflow.keras.utils import get_file\n \n-import numpy as np\n-import six\n-from six.moves.urllib.error import HTTPError\n-from six.moves.urllib.error import URLError\n-from six.moves.urllib.request import urlopen\n-\n-try:\n-    import queue\n-except ImportError:\n-    import Queue as queue\n-\n-from ..utils.generic_utils import Progbar\n-\n-if sys.version_info[0] == 2:\n-    def urlretrieve(url, filename, reporthook=None, data=None):\n-        \"\"\"Replacement for `urlretrieve` for Python 2.\n-\n-        Under Python 2, `urlretrieve` relies on `FancyURLopener` from legacy\n-        `urllib` module, known to have issues with proxy management.\n-\n-        # Arguments\n-            url: url to retrieve.\n-            filename: where to store the retrieved data locally.\n-            reporthook: a hook function that will be called once\n-                on establishment of the network connection and once\n-                after each block read thereafter.\n-                The hook will be passed three arguments;\n-                a count of blocks transferred so far,\n-                a block size in bytes, and the total size of the file.\n-            data: `data` argument passed to `urlopen`.\n-        \"\"\"\n-\n-        def chunk_read(response, chunk_size=8192, reporthook=None):\n-            content_type = response.info().get('Content-Length')\n-            total_size = -1\n-            if content_type is not None:\n-                total_size = int(content_type.strip())\n-            count = 0\n-            while True:\n-                chunk = response.read(chunk_size)\n-                count += 1\n-                if reporthook is not None:\n-                    reporthook(count, chunk_size, total_size)\n-                if chunk:\n-                    yield chunk\n-                else:\n-                    break\n-\n-        with closing(urlopen(url, data)) as response, open(filename, 'wb') as fd:\n-            for chunk in chunk_read(response, reporthook=reporthook):\n-                fd.write(chunk)\n-else:\n-    from six.moves.urllib.request import urlretrieve\n-\n-\n-def _extract_archive(file_path, path='.', archive_format='auto'):\n-    \"\"\"Extracts an archive if it matches tar, tar.gz, tar.bz, or zip formats.\n-\n-    # Arguments\n-        file_path: path to the archive file\n-        path: path to extract the archive file\n-        archive_format: Archive format to try for extracting the file.\n-            Options are 'auto', 'tar', 'zip', and None.\n-            'tar' includes tar, tar.gz, and tar.bz files.\n-            The default 'auto' is ['tar', 'zip'].\n-            None or an empty list will return no matches found.\n-\n-    # Returns\n-        True if a match was found and an archive extraction was completed,\n-        False otherwise.\n-    \"\"\"\n-    if archive_format is None:\n-        return False\n-    if archive_format == 'auto':\n-        archive_format = ['tar', 'zip']\n-    if isinstance(archive_format, six.string_types):\n-        archive_format = [archive_format]\n-\n-    for archive_type in archive_format:\n-        if archive_type == 'tar':\n-            open_fn = tarfile.open\n-            is_match_fn = tarfile.is_tarfile\n-        if archive_type == 'zip':\n-            open_fn = zipfile.ZipFile\n-            is_match_fn = zipfile.is_zipfile\n-\n-        if is_match_fn(file_path):\n-            with open_fn(file_path) as archive:\n-                try:\n-                    archive.extractall(path)\n-                except (tarfile.TarError, RuntimeError,\n-                        KeyboardInterrupt):\n-                    if os.path.exists(path):\n-                        if os.path.isfile(path):\n-                            os.remove(path)\n-                        else:\n-                            shutil.rmtree(path)\n-                    raise\n-            return True\n-    return False\n-\n-\n-def get_file(fname,\n-             origin,\n-             untar=False,\n-             md5_hash=None,\n-             file_hash=None,\n-             cache_subdir='datasets',\n-             hash_algorithm='auto',\n-             extract=False,\n-             archive_format='auto',\n-             cache_dir=None):\n-    \"\"\"Downloads a file from a URL if it not already in the cache.\n-\n-    By default the file at the url `origin` is downloaded to the\n-    cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n-    and given the filename `fname`. The final location of a file\n-    `example.txt` would therefore be `~/.keras/datasets/example.txt`.\n-\n-    Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n-    Passing a hash will verify the file after download. The command line\n-    programs `shasum` and `sha256sum` can compute the hash.\n-\n-    # Arguments\n-        fname: Name of the file. If an absolute path `/path/to/file.txt` is\n-            specified the file will be saved at that location.\n-        origin: Original URL of the file.\n-        untar: Deprecated in favor of 'extract'.\n-            boolean, whether the file should be decompressed\n-        md5_hash: Deprecated in favor of 'file_hash'.\n-            md5 hash of the file for verification\n-        file_hash: The expected hash string of the file after download.\n-            The sha256 and md5 hash algorithms are both supported.\n-        cache_subdir: Subdirectory under the Keras cache dir where the file is\n-            saved. If an absolute path `/path/to/folder` is\n-            specified the file will be saved at that location.\n-        hash_algorithm: Select the hash algorithm to verify the file.\n-            options are 'md5', 'sha256', and 'auto'.\n-            The default 'auto' detects the hash algorithm in use.\n-        extract: True tries extracting the file as an Archive, like tar or zip.\n-        archive_format: Archive format to try for extracting the file.\n-            Options are 'auto', 'tar', 'zip', and None.\n-            'tar' includes tar, tar.gz, and tar.bz files.\n-            The default 'auto' is ['tar', 'zip'].\n-            None or an empty list will return no matches found.\n-        cache_dir: Location to store cached files, when None it\n-            defaults to the [Keras Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n-\n-    # Returns\n-        Path to the downloaded file\n-    \"\"\"  # noqa\n-    if cache_dir is None:\n-        if 'KERAS_HOME' in os.environ:\n-            cache_dir = os.environ.get('KERAS_HOME')\n-        else:\n-            cache_dir = os.path.join(os.path.expanduser('~'), '.keras')\n-    if md5_hash is not None and file_hash is None:\n-        file_hash = md5_hash\n-        hash_algorithm = 'md5'\n-    datadir_base = os.path.expanduser(cache_dir)\n-    if not os.access(datadir_base, os.W_OK):\n-        datadir_base = os.path.join('/tmp', '.keras')\n-    datadir = os.path.join(datadir_base, cache_subdir)\n-    if not os.path.exists(datadir):\n-        os.makedirs(datadir)\n-\n-    if untar:\n-        untar_fpath = os.path.join(datadir, fname)\n-        fpath = untar_fpath + '.tar.gz'\n-    else:\n-        fpath = os.path.join(datadir, fname)\n-\n-    download = False\n-    if os.path.exists(fpath):\n-        # File found; verify integrity if a hash was provided.\n-        if file_hash is not None:\n-            if not validate_file(fpath, file_hash, algorithm=hash_algorithm):\n-                print('A local file was found, but it seems to be incomplete'\n-                      ' or outdated because the {} file hash does not match '\n-                      'the original value of {} so we will re-download the '\n-                      'data.'.format(hash_algorithm, file_hash))\n-                download = True\n-    else:\n-        download = True\n-\n-    if download:\n-        print('Downloading data from', origin)\n-\n-        class ProgressTracker(object):\n-            # Maintain progbar for the lifetime of download.\n-            # This design was chosen for Python 2.7 compatibility.\n-            progbar = None\n-\n-        def dl_progress(count, block_size, total_size):\n-            if ProgressTracker.progbar is None:\n-                if total_size == -1:\n-                    total_size = None\n-                ProgressTracker.progbar = Progbar(total_size)\n-            else:\n-                ProgressTracker.progbar.update(count * block_size)\n-\n-        error_msg = 'URL fetch failure on {} : {} -- {}'\n-        try:\n-            try:\n-                urlretrieve(origin, fpath, dl_progress)\n-            except HTTPError as e:\n-                raise Exception(error_msg.format(origin, e.code, e.msg))\n-            except URLError as e:\n-                raise Exception(error_msg.format(origin, e.errno, e.reason))\n-        except (Exception, KeyboardInterrupt):\n-            if os.path.exists(fpath):\n-                os.remove(fpath)\n-            raise\n-        ProgressTracker.progbar = None\n-\n-    if untar:\n-        if not os.path.exists(untar_fpath):\n-            _extract_archive(fpath, datadir, archive_format='tar')\n-        return untar_fpath\n-\n-    if extract:\n-        _extract_archive(fpath, datadir, archive_format)\n-\n-    return fpath\n-\n-\n-def _hash_file(fpath, algorithm='sha256', chunk_size=65535):\n-    \"\"\"Calculates a file sha256 or md5 hash.\n-\n-    # Example\n-\n-    ```python\n-        >>> from keras.utils.data_utils import _hash_file\n-        >>> _hash_file('/path/to/file.zip')\n-        'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'\n-    ```\n-\n-    # Arguments\n-        fpath: path to the file being validated\n-        algorithm: hash algorithm, one of 'auto', 'sha256', or 'md5'.\n-            The default 'auto' detects the hash algorithm in use.\n-        chunk_size: Bytes to read at a time, important for large files.\n-\n-    # Returns\n-        The file hash\n-    \"\"\"\n-    if (algorithm == 'sha256') or (algorithm == 'auto' and len(hash) == 64):\n-        hasher = hashlib.sha256()\n-    else:\n-        hasher = hashlib.md5()\n-\n-    with open(fpath, 'rb') as fpath_file:\n-        for chunk in iter(lambda: fpath_file.read(chunk_size), b''):\n-            hasher.update(chunk)\n-\n-    return hasher.hexdigest()\n-\n-\n-def validate_file(fpath, file_hash, algorithm='auto', chunk_size=65535):\n-    \"\"\"Validates a file against a sha256 or md5 hash.\n-\n-    # Arguments\n-        fpath: path to the file being validated\n-        file_hash:  The expected hash string of the file.\n-            The sha256 and md5 hash algorithms are both supported.\n-        algorithm: Hash algorithm, one of 'auto', 'sha256', or 'md5'.\n-            The default 'auto' detects the hash algorithm in use.\n-        chunk_size: Bytes to read at a time, important for large files.\n-\n-    # Returns\n-        Whether the file is valid\n-    \"\"\"\n-    if ((algorithm == 'sha256') or\n-            (algorithm == 'auto' and len(file_hash) == 64)):\n-        hasher = 'sha256'\n-    else:\n-        hasher = 'md5'\n-\n-    if str(_hash_file(fpath, hasher, chunk_size)) == str(file_hash):\n-        return True\n-    else:\n-        return False\n-\n-\n-class Sequence(object):\n-    \"\"\"Base object for fitting to a sequence of data, such as a dataset.\n-\n-    Every `Sequence` must implement the `__getitem__` and the `__len__` methods.\n-    If you want to modify your dataset between epochs you may implement\n-    `on_epoch_end`. The method `__getitem__` should return a complete batch.\n-\n-    # Notes\n-\n-    `Sequence` are a safer way to do multiprocessing. This structure guarantees\n-    that the network will only train once on each sample per epoch which is not\n-    the case with generators.\n-\n-    # Examples\n-\n-    ```python\n-        from skimage.io import imread\n-        from skimage.transform import resize\n-        import numpy as np\n-\n-        # Here, `x_set` is list of path to the images\n-        # and `y_set` are the associated classes.\n-\n-        class CIFAR10Sequence(Sequence):\n-\n-            def __init__(self, x_set, y_set, batch_size):\n-                self.x, self.y = x_set, y_set\n-                self.batch_size = batch_size\n-\n-            def __len__(self):\n-                return int(np.ceil(len(self.x) / float(self.batch_size)))\n-\n-            def __getitem__(self, idx):\n-                batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n-                batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n-\n-                return np.array([\n-                    resize(imread(file_name), (200, 200))\n-                       for file_name in batch_x]), np.array(batch_y)\n-    ```\n-    \"\"\"\n-\n-    use_sequence_api = True\n-\n-    @abstractmethod\n-    def __getitem__(self, index):\n-        \"\"\"Gets batch at position `index`.\n-\n-        # Arguments\n-            index: position of the batch in the Sequence.\n-\n-        # Returns\n-            A batch\n-        \"\"\"\n-        raise NotImplementedError\n-\n-    @abstractmethod\n-    def __len__(self):\n-        \"\"\"Number of batch in the Sequence.\n-\n-        # Returns\n-            The number of batches in the Sequence.\n-        \"\"\"\n-        raise NotImplementedError\n-\n-    def on_epoch_end(self):\n-        \"\"\"Method called at the end of every epoch.\n-        \"\"\"\n-        pass\n-\n-    def __iter__(self):\n-        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n-        for item in (self[i] for i in range(len(self))):\n-            yield item\n-\n-\n-# Global variables to be shared across processes\n-_SHARED_SEQUENCES = {}\n-# We use a Value to provide unique id to different processes.\n-_SEQUENCE_COUNTER = None\n-\n-\n-def init_pool(seqs):\n-    global _SHARED_SEQUENCES\n-    _SHARED_SEQUENCES = seqs\n-\n-\n-def get_index(uid, i):\n-    \"\"\"Get the value from the Sequence `uid` at index `i`.\n-\n-    To allow multiple Sequences to be used at the same time, we use `uid` to\n-    get a specific one. A single Sequence would cause the validation to\n-    overwrite the training Sequence.\n-\n-    # Arguments\n-        uid: int, Sequence identifier\n-        i: index\n-\n-    # Returns\n-        The value at index `i`.\n-    \"\"\"\n-    return _SHARED_SEQUENCES[uid][i]\n-\n-\n-class SequenceEnqueuer(object):\n-    \"\"\"Base class to enqueue inputs.\n-\n-    The task of an Enqueuer is to use parallelism to speed up preprocessing.\n-    This is done with processes or threads.\n-\n-    # Examples\n-\n-    ```python\n-        enqueuer = SequenceEnqueuer(...)\n-        enqueuer.start()\n-        datas = enqueuer.get()\n-        for data in datas:\n-            # Use the inputs; training, evaluating, predicting.\n-            # ... stop sometime.\n-        enqueuer.close()\n-    ```\n-\n-    The `enqueuer.get()` should be an infinite stream of datas.\n-\n-    \"\"\"\n-    def __init__(self, sequence,\n-                 use_multiprocessing=False):\n-        self.sequence = sequence\n-        self.use_multiprocessing = use_multiprocessing\n-\n-        global _SEQUENCE_COUNTER\n-        if _SEQUENCE_COUNTER is None:\n-            try:\n-                _SEQUENCE_COUNTER = mp.Value('i', 0)\n-            except OSError:\n-                # In this case the OS does not allow us to use\n-                # multiprocessing. We resort to an int\n-                # for enqueuer indexing.\n-                _SEQUENCE_COUNTER = 0\n-\n-        if isinstance(_SEQUENCE_COUNTER, int):\n-            self.uid = _SEQUENCE_COUNTER\n-            _SEQUENCE_COUNTER += 1\n-        else:\n-            # Doing Multiprocessing.Value += x is not process-safe.\n-            with _SEQUENCE_COUNTER.get_lock():\n-                self.uid = _SEQUENCE_COUNTER.value\n-                _SEQUENCE_COUNTER.value += 1\n-\n-        self.workers = 0\n-        self.executor_fn = None\n-        self.queue = None\n-        self.run_thread = None\n-        self.stop_signal = None\n-\n-    def is_running(self):\n-        return self.stop_signal is not None and not self.stop_signal.is_set()\n-\n-    def start(self, workers=1, max_queue_size=10):\n-        \"\"\"Start the handler's workers.\n-\n-        # Arguments\n-            workers: number of worker threads\n-            max_queue_size: queue size\n-                (when full, workers could block on `put()`)\n-        \"\"\"\n-        if self.use_multiprocessing:\n-            self.executor_fn = self._get_executor_init(workers)\n-        else:\n-            # We do not need the init since it's threads.\n-            self.executor_fn = lambda _: ThreadPool(workers)\n-        self.workers = workers\n-        self.queue = queue.Queue(max_queue_size)\n-        self.stop_signal = threading.Event()\n-        self.run_thread = threading.Thread(target=self._run)\n-        self.run_thread.daemon = True\n-        self.run_thread.start()\n-\n-    def _send_sequence(self):\n-        \"\"\"Send current Iterable to all workers.\"\"\"\n-        # For new processes that may spawn\n-        _SHARED_SEQUENCES[self.uid] = self.sequence\n-\n-    def stop(self, timeout=None):\n-        \"\"\"Stops running threads and wait for them to exit, if necessary.\n-\n-        Should be called by the same thread which called `start()`.\n-\n-        # Arguments\n-            timeout: maximum time to wait on `thread.join()`\n-        \"\"\"\n-        self.stop_signal.set()\n-        with self.queue.mutex:\n-            self.queue.queue.clear()\n-            self.queue.unfinished_tasks = 0\n-            self.queue.not_full.notify()\n-        self.run_thread.join(timeout)\n-        _SHARED_SEQUENCES[self.uid] = None\n-\n-    @abstractmethod\n-    def _run(self):\n-        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n-        raise NotImplementedError\n-\n-    @abstractmethod\n-    def _get_executor_init(self, workers):\n-        \"\"\"Get the Pool initializer for multiprocessing.\n-\n-        # Returns\n-            Function, a Function to initialize the pool\n-        \"\"\"\n-        raise NotImplementedError\n-\n-    @abstractmethod\n-    def get(self):\n-        \"\"\"Creates a generator to extract data from the queue.\n-\n-        Skip the data if it is `None`.\n-\n-        # Returns\n-            Generator yielding tuples `(inputs, targets)`\n-                or `(inputs, targets, sample_weights)`.\n-        \"\"\"\n-        raise NotImplementedError\n-\n-\n-class OrderedEnqueuer(SequenceEnqueuer):\n-    \"\"\"Builds a Enqueuer from a Sequence.\n-\n-    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n-\n-    # Arguments\n-        sequence: A `keras.utils.data_utils.Sequence` object.\n-        use_multiprocessing: use multiprocessing if True, otherwise threading\n-        shuffle: whether to shuffle the data at the beginning of each epoch\n-    \"\"\"\n-    def __init__(self, sequence, use_multiprocessing=False, shuffle=False):\n-        super(OrderedEnqueuer, self).__init__(sequence, use_multiprocessing)\n-        self.shuffle = shuffle\n-        self.end_of_epoch_signal = threading.Event()\n-\n-    def _get_executor_init(self, workers):\n-        \"\"\"Get the Pool initializer for multiprocessing.\n-\n-        # Returns\n-            Function, a Function to initialize the pool\n-        \"\"\"\n-        return lambda seqs: mp.Pool(workers,\n-                                    initializer=init_pool,\n-                                    initargs=(seqs,))\n-\n-    def _wait_queue(self):\n-        \"\"\"Wait for the queue to be empty.\"\"\"\n-        while True:\n-            time.sleep(0.1)\n-            if self.queue.unfinished_tasks == 0 or self.stop_signal.is_set():\n-                return\n-\n-    def _run(self):\n-        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n-        while True:\n-            sequence = list(range(len(self.sequence)))\n-            self._send_sequence()  # Share the initial sequence\n-\n-            if self.shuffle:\n-                random.shuffle(sequence)\n-\n-            with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n-                for i in sequence:\n-                    if self.stop_signal.is_set():\n-                        return\n-                    future = executor.apply_async(get_index, (self.uid, i))\n-                    future.idx = i\n-                    self.queue.put(future, block=True)\n-\n-                # Done with the current epoch, waiting for the final batches\n-                self._wait_queue()\n-\n-                if self.stop_signal.is_set():\n-                    # We're done\n-                    return\n-\n-            # Call the internal on epoch end.\n-            self.sequence.on_epoch_end()\n-            # communicate on_epoch_end to the main thread\n-            self.end_of_epoch_signal.set()\n-\n-    def join_end_of_epoch(self):\n-        self.end_of_epoch_signal.wait(timeout=30)\n-        self.end_of_epoch_signal.clear()\n-\n-    def get(self):\n-        \"\"\"Creates a generator to extract data from the queue.\n-\n-        Skip the data if it is `None`.\n-\n-        # Yields\n-            The next element in the queue, i.e. a tuple\n-            `(inputs, targets)` or\n-            `(inputs, targets, sample_weights)`.\n-        \"\"\"\n-        try:\n-            while self.is_running():\n-                try:\n-                    future = self.queue.get(block=True)\n-                    inputs = future.get(timeout=30)\n-                except mp.TimeoutError:\n-                    idx = future.idx\n-                    warnings.warn(\n-                        'The input {} could not be retrieved.'\n-                        ' It could be because a worker has died.'.format(idx),\n-                        UserWarning)\n-                    inputs = self.sequence[idx]\n-                finally:\n-                    self.queue.task_done()\n-\n-                if inputs is not None:\n-                    yield inputs\n-        except Exception:\n-            self.stop()\n-            six.reraise(*sys.exc_info())\n-\n-\n-def init_pool_generator(gens, random_seed=None):\n-    global _SHARED_SEQUENCES\n-    _SHARED_SEQUENCES = gens\n-\n-    if random_seed is not None:\n-        ident = mp.current_process().ident\n-        np.random.seed(random_seed + ident)\n-\n-\n-def next_sample(uid):\n-    \"\"\"Get the next value from the generator `uid`.\n-\n-    To allow multiple generators to be used at the same time, we use `uid` to\n-    get a specific one. A single generator would cause the validation to\n-    overwrite the training generator.\n-\n-    # Arguments\n-        uid: int, generator identifier\n-\n-    # Returns\n-        The next value of generator `uid`.\n-    \"\"\"\n-    return six.next(_SHARED_SEQUENCES[uid])\n-\n-\n-class GeneratorEnqueuer(SequenceEnqueuer):\n-    \"\"\"Builds a queue out of a data generator.\n-\n-    The provided generator can be finite in which case the class will throw\n-    a `StopIteration` exception.\n-\n-    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n-\n-    # Arguments\n-        sequence: a sequence function which yields data\n-        use_multiprocessing: use multiprocessing if True, otherwise threading\n-        wait_time: time to sleep in-between calls to `put()`\n-        random_seed: Initial seed for workers,\n-            will be incremented by one for each worker.\n-    \"\"\"\n-\n-    def __init__(self, sequence, use_multiprocessing=False, wait_time=None,\n-                 random_seed=None):\n-        super(GeneratorEnqueuer, self).__init__(sequence, use_multiprocessing)\n-        self.random_seed = random_seed\n-        if wait_time is not None:\n-            warnings.warn('`wait_time` is not used anymore.',\n-                          DeprecationWarning)\n-\n-    def _get_executor_init(self, workers):\n-        \"\"\"Get the Pool initializer for multiprocessing.\n-\n-        # Returns\n-            Function, a Function to initialize the pool\n-        \"\"\"\n-        return lambda seqs: mp.Pool(workers,\n-                                    initializer=init_pool_generator,\n-                                    initargs=(seqs, self.random_seed))\n-\n-    def _run(self):\n-        \"\"\"Submits request to the executor and queue the `Future` objects.\"\"\"\n-        self._send_sequence()  # Share the initial generator\n-        with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n-            while True:\n-                if self.stop_signal.is_set():\n-                    return\n-                self.queue.put(\n-                    executor.apply_async(next_sample, (self.uid,)), block=True)\n-\n-    def get(self):\n-        \"\"\"Creates a generator to extract data from the queue.\n-\n-        Skip the data if it is `None`.\n-\n-        # Yields\n-            The next element in the queue, i.e. a tuple\n-            `(inputs, targets)` or\n-            `(inputs, targets, sample_weights)`.\n-        \"\"\"\n-        try:\n-            while self.is_running():\n-                try:\n-                    future = self.queue.get(block=True)\n-                    inputs = future.get(timeout=30)\n-                    self.queue.task_done()\n-                except mp.TimeoutError:\n-                    warnings.warn(\n-                        'An input could not be retrieved.'\n-                        ' It could be because a worker has died.'\n-                        'We do not have any information on the lost sample.',\n-                        UserWarning)\n-                    continue\n-                if inputs is not None:\n-                    yield inputs\n-        except StopIteration:\n-            # Special case for finite generators\n-            last_ones = []\n-            while self.queue.qsize() > 0:\n-                last_ones.append(self.queue.get(block=True))\n-            # Wait for them to complete\n-            [f.wait() for f in last_ones]\n-            # Keep the good ones\n-            last_ones = (future.get() for future in last_ones if future.successful())\n-            for inputs in last_ones:\n-                if inputs is not None:\n-                    yield inputs\n-        except Exception as e:\n-            self.stop()\n-            if 'generator already executing' in str(e):\n-                raise RuntimeError(\n-                    \"Your generator is NOT thread-safe.\"\n-                    \"Keras requires a thread-safe generator when\"\n-                    \"`use_multiprocessing=False, workers > 1`.\"\n-                    \"For more information see issue #1638.\")\n-            six.reraise(*sys.exc_info())\n+from tensorflow.keras.utils import Sequence\n+from tensorflow.keras.utils import SequenceEnqueuer\n+from tensorflow.keras.utils import OrderedEnqueuer\n+from tensorflow.keras.utils import GeneratorEnqueuer\n\n@@ -1,476 +1,14 @@\n \"\"\"Python utilities required by Keras.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n \n-import binascii\n-import numpy as np\n-\n-import time\n-import sys\n-import six\n-import marshal\n-import types as python_types\n import inspect\n-import codecs\n-import collections\n-\n-_GLOBAL_CUSTOM_OBJECTS = {}\n-\n-\n-class CustomObjectScope(object):\n-    \"\"\"Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n-\n-    Code within a `with` statement will be able to access custom objects\n-    by name. Changes to global custom objects persist\n-    within the enclosing `with` statement. At end of the `with` statement,\n-    global custom objects are reverted to state\n-    at beginning of the `with` statement.\n-\n-    # Example\n-\n-    Consider a custom object `MyObject` (e.g. a class):\n-\n-    ```python\n-        with CustomObjectScope({'MyObject':MyObject}):\n-            layer = Dense(..., kernel_regularizer='MyObject')\n-            # save, load, etc. will recognize custom object by name\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, *args):\n-        self.custom_objects = args\n-        self.backup = None\n-\n-    def __enter__(self):\n-        self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n-        for objects in self.custom_objects:\n-            _GLOBAL_CUSTOM_OBJECTS.update(objects)\n-        return self\n-\n-    def __exit__(self, *args, **kwargs):\n-        _GLOBAL_CUSTOM_OBJECTS.clear()\n-        _GLOBAL_CUSTOM_OBJECTS.update(self.backup)\n-\n-\n-def custom_object_scope(*args):\n-    \"\"\"Provides a scope that changes to `_GLOBAL_CUSTOM_OBJECTS` cannot escape.\n-\n-    Convenience wrapper for `CustomObjectScope`.\n-    Code within a `with` statement will be able to access custom objects\n-    by name. Changes to global custom objects persist\n-    within the enclosing `with` statement. At end of the `with` statement,\n-    global custom objects are reverted to state\n-    at beginning of the `with` statement.\n-\n-    # Example\n-\n-    Consider a custom object `MyObject`\n-\n-    ```python\n-        with custom_object_scope({'MyObject':MyObject}):\n-            layer = Dense(..., kernel_regularizer='MyObject')\n-            # save, load, etc. will recognize custom object by name\n-    ```\n-\n-    # Arguments\n-        *args: Variable length list of dictionaries of name,\n-            class pairs to add to custom objects.\n-\n-    # Returns\n-        Object of type `CustomObjectScope`.\n-    \"\"\"\n-    return CustomObjectScope(*args)\n-\n-\n-def get_custom_objects():\n-    \"\"\"Retrieves a live reference to the global dictionary of custom objects.\n-\n-    Updating and clearing custom objects using `custom_object_scope`\n-    is preferred, but `get_custom_objects` can\n-    be used to directly access `_GLOBAL_CUSTOM_OBJECTS`.\n-\n-    # Example\n-\n-    ```python\n-        get_custom_objects().clear()\n-        get_custom_objects()['MyObject'] = MyObject\n-    ```\n-\n-    # Returns\n-        Global dictionary of names to classes (`_GLOBAL_CUSTOM_OBJECTS`).\n-    \"\"\"\n-    return _GLOBAL_CUSTOM_OBJECTS\n-\n-\n-def serialize_keras_object(instance):\n-    if instance is None:\n-        return None\n-    if hasattr(instance, 'get_config'):\n-        return {\n-            'class_name': instance.__class__.__name__,\n-            'config': instance.get_config()\n-        }\n-    if hasattr(instance, '__name__'):\n-        return instance.__name__\n-    else:\n-        raise ValueError('Cannot serialize', instance)\n-\n-\n-def deserialize_keras_object(identifier, module_objects=None,\n-                             custom_objects=None,\n-                             printable_module_name='object'):\n-    if identifier is None:\n-        return None\n-    if isinstance(identifier, dict):\n-        # In this case we are dealing with a Keras config dictionary.\n-        config = identifier\n-        if 'class_name' not in config or 'config' not in config:\n-            raise ValueError('Improper config format: {}'.format(config))\n-        class_name = config['class_name']\n-        if custom_objects and class_name in custom_objects:\n-            cls = custom_objects[class_name]\n-        elif class_name in _GLOBAL_CUSTOM_OBJECTS:\n-            cls = _GLOBAL_CUSTOM_OBJECTS[class_name]\n-        else:\n-            module_objects = module_objects or {}\n-            cls = module_objects.get(class_name)\n-            if cls is None:\n-                raise ValueError('Unknown {}: {}'.format(printable_module_name,\n-                                                         class_name))\n-        if hasattr(cls, 'from_config'):\n-            custom_objects = custom_objects or {}\n-            if has_arg(cls.from_config, 'custom_objects'):\n-                return cls.from_config(\n-                    config['config'],\n-                    custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n-                                        list(custom_objects.items())))\n-            with CustomObjectScope(custom_objects):\n-                return cls.from_config(config['config'])\n-        else:\n-            # Then `cls` may be a function returning a class.\n-            # in this case by convention `config` holds\n-            # the kwargs of the function.\n-            custom_objects = custom_objects or {}\n-            with CustomObjectScope(custom_objects):\n-                return cls(**config['config'])\n-    elif isinstance(identifier, six.string_types):\n-        function_name = identifier\n-        if custom_objects and function_name in custom_objects:\n-            fn = custom_objects.get(function_name)\n-        elif function_name in _GLOBAL_CUSTOM_OBJECTS:\n-            fn = _GLOBAL_CUSTOM_OBJECTS[function_name]\n-        else:\n-            fn = module_objects.get(function_name)\n-            if fn is None:\n-                raise ValueError('Unknown {}: {}'.format(printable_module_name,\n-                                                         function_name))\n-        return fn\n-    else:\n-        raise ValueError('Could not interpret serialized '\n-                         '{}: {}'.format(printable_module_name, identifier))\n-\n-\n-def func_dump(func):\n-    \"\"\"Serializes a user defined function.\n-\n-    # Arguments\n-        func: the function to serialize.\n-\n-    # Returns\n-        A tuple `(code, defaults, closure)`.\n-    \"\"\"\n-    raw_code = marshal.dumps(func.__code__)\n-    code = codecs.encode(raw_code, 'base64').decode('ascii')\n-    defaults = func.__defaults__\n-    if func.__closure__:\n-        closure = tuple(c.cell_contents for c in func.__closure__)\n-    else:\n-        closure = None\n-    return code, defaults, closure\n-\n-\n-def func_load(code, defaults=None, closure=None, globs=None):\n-    \"\"\"Deserializes a user defined function.\n-\n-    # Arguments\n-        code: bytecode of the function.\n-        defaults: defaults of the function.\n-        closure: closure of the function.\n-        globs: dictionary of global objects.\n-\n-    # Returns\n-        A function object.\n-    \"\"\"\n-    if isinstance(code, (tuple, list)):  # unpack previous dump\n-        code, defaults, closure = code\n-        if isinstance(defaults, list):\n-            defaults = tuple(defaults)\n-\n-    def ensure_value_to_cell(value):\n-        \"\"\"Ensures that a value is converted to a python cell object.\n-\n-        # Arguments\n-            value: Any value that needs to be casted to the cell type\n-\n-        # Returns\n-            A value wrapped as a cell object (see function \"func_load\")\n-\n-        \"\"\"\n-        def dummy_fn():\n-            value  # just access it so it gets captured in .__closure__\n-\n-        cell_value = dummy_fn.__closure__[0]\n-        if not isinstance(value, type(cell_value)):\n-            return cell_value\n-        else:\n-            return value\n-\n-    if closure is not None:\n-        closure = tuple(ensure_value_to_cell(_) for _ in closure)\n-    try:\n-        raw_code = codecs.decode(code.encode('ascii'), 'base64')\n-        code = marshal.loads(raw_code)\n-    except (UnicodeEncodeError, binascii.Error, ValueError):\n-        # backwards compatibility for models serialized prior to 2.1.2\n-        raw_code = code.encode('raw_unicode_escape')\n-        code = marshal.loads(raw_code)\n-    if globs is None:\n-        globs = globals()\n-    return python_types.FunctionType(code, globs,\n-                                     name=code.co_name,\n-                                     argdefs=defaults,\n-                                     closure=closure)\n-\n-\n-def getargspec(fn):\n-    \"\"\"Python 2/3 compatible `getargspec`.\n-\n-    Calls `getfullargspec` and assigns args, varargs,\n-    varkw, and defaults to a python 2/3 compatible `ArgSpec`.\n-    The parameter name 'varkw' is changed to 'keywords' to fit the\n-    `ArgSpec` struct.\n-\n-    # Arguments\n-        fn: the target function to inspect.\n-\n-    # Returns\n-        An ArgSpec with args, varargs, keywords, and defaults parameters\n-        from FullArgSpec.\n-    \"\"\"\n-    if sys.version_info < (3,):\n-        arg_spec = inspect.getargspec(fn)\n-    else:\n-        full_arg_spec = inspect.getfullargspec(fn)\n-        arg_spec = inspect.ArgSpec(\n-            args=full_arg_spec.args,\n-            varargs=full_arg_spec.varargs,\n-            keywords=full_arg_spec.varkw,\n-            defaults=full_arg_spec.defaults)\n-    return arg_spec\n-\n-\n-def has_arg(fn, name, accept_all=False):\n-    \"\"\"Checks if a callable accepts a given keyword argument.\n-\n-    For Python 2, checks if there is an argument with the given name.\n-\n-    For Python 3, checks if there is an argument with the given name, and\n-    also whether this argument can be called with a keyword (i.e. if it is\n-    not a positional-only argument).\n-\n-    # Arguments\n-        fn: Callable to inspect.\n-        name: Check if `fn` can be called with `name` as a keyword argument.\n-        accept_all: What to return if there is no parameter called `name`\n-                    but the function accepts a `**kwargs` argument.\n-\n-    # Returns\n-        bool, whether `fn` accepts a `name` keyword argument.\n-    \"\"\"\n-    if sys.version_info < (3,):\n-        arg_spec = inspect.getargspec(fn)\n-        if accept_all and arg_spec.keywords is not None:\n-            return True\n-        return (name in arg_spec.args)\n-    elif sys.version_info < (3, 3):\n-        arg_spec = inspect.getfullargspec(fn)\n-        if accept_all and arg_spec.varkw is not None:\n-            return True\n-        return (name in arg_spec.args or\n-                name in arg_spec.kwonlyargs)\n-    else:\n-        signature = inspect.signature(fn)\n-        parameter = signature.parameters.get(name)\n-        if parameter is None:\n-            if accept_all:\n-                for param in signature.parameters.values():\n-                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n-                        return True\n-            return False\n-        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n-                                   inspect.Parameter.KEYWORD_ONLY))\n-\n-\n-class Progbar(object):\n-    \"\"\"Displays a progress bar.\n-\n-    # Arguments\n-        target: Total number of steps expected, None if unknown.\n-        width: Progress bar width on screen.\n-        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n-        stateful_metrics: Iterable of string names of metrics that\n-            should *not* be averaged over time. Metrics in this list\n-            will be displayed as-is. All others will be averaged\n-            by the progbar before display.\n-        interval: Minimum visual progress update interval (in seconds).\n-    \"\"\"\n-\n-    def __init__(self, target, width=30, verbose=1, interval=0.05,\n-                 stateful_metrics=None):\n-        self.target = target\n-        self.width = width\n-        self.verbose = verbose\n-        self.interval = interval\n-        if stateful_metrics:\n-            self.stateful_metrics = set(stateful_metrics)\n-        else:\n-            self.stateful_metrics = set()\n-\n-        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n-                                  sys.stdout.isatty()) or\n-                                 'ipykernel' in sys.modules)\n-        self._total_width = 0\n-        self._seen_so_far = 0\n-        self._values = collections.OrderedDict()\n-        self._start = time.time()\n-        self._last_update = 0\n-\n-    def update(self, current, values=None):\n-        \"\"\"Updates the progress bar.\n-\n-        # Arguments\n-            current: Index of current step.\n-            values: List of tuples:\n-                `(name, value_for_last_step)`.\n-                If `name` is in `stateful_metrics`,\n-                `value_for_last_step` will be displayed as-is.\n-                Else, an average of the metric over time will be displayed.\n-        \"\"\"\n-        values = values or []\n-        for k, v in values:\n-            if k not in self.stateful_metrics:\n-                if k not in self._values:\n-                    self._values[k] = [v * (current - self._seen_so_far),\n-                                       current - self._seen_so_far]\n-                else:\n-                    self._values[k][0] += v * (current - self._seen_so_far)\n-                    self._values[k][1] += (current - self._seen_so_far)\n-            else:\n-                # Stateful metrics output a numeric value.  This representation\n-                # means \"take an average from a single value\" but keeps the\n-                # numeric formatting.\n-                self._values[k] = [v, 1]\n-        self._seen_so_far = current\n-\n-        now = time.time()\n-        info = ' - %.0fs' % (now - self._start)\n-        if self.verbose == 1:\n-            if (now - self._last_update < self.interval and\n-                    self.target is not None and current < self.target):\n-                return\n-\n-            prev_total_width = self._total_width\n-            if self._dynamic_display:\n-                sys.stdout.write('\\b' * prev_total_width)\n-                sys.stdout.write('\\r')\n-            else:\n-                sys.stdout.write('\\n')\n-\n-            if self.target is not None:\n-                numdigits = int(np.floor(np.log10(self.target))) + 1\n-                barstr = '%%%dd/%d [' % (numdigits, self.target)\n-                bar = barstr % current\n-                prog = float(current) / self.target\n-                prog_width = int(self.width * prog)\n-                if prog_width > 0:\n-                    bar += ('=' * (prog_width - 1))\n-                    if current < self.target:\n-                        bar += '>'\n-                    else:\n-                        bar += '='\n-                bar += ('.' * (self.width - prog_width))\n-                bar += ']'\n-            else:\n-                bar = '%7d/Unknown' % current\n-\n-            self._total_width = len(bar)\n-            sys.stdout.write(bar)\n-\n-            if current:\n-                time_per_unit = (now - self._start) / current\n-            else:\n-                time_per_unit = 0\n-            if self.target is not None and current < self.target:\n-                eta = time_per_unit * (self.target - current)\n-                if eta > 3600:\n-                    eta_format = ('%d:%02d:%02d' %\n-                                  (eta // 3600, (eta % 3600) // 60, eta % 60))\n-                elif eta > 60:\n-                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n-                else:\n-                    eta_format = '%ds' % eta\n-\n-                info = ' - ETA: %s' % eta_format\n-            else:\n-                if time_per_unit >= 1:\n-                    info += ' %.0fs/step' % time_per_unit\n-                elif time_per_unit >= 1e-3:\n-                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n-                else:\n-                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n-\n-            for k in self._values:\n-                info += ' - %s:' % k\n-                if isinstance(self._values[k], list):\n-                    avg = np.mean(\n-                        self._values[k][0] / max(1, self._values[k][1]))\n-                    if abs(avg) > 1e-3:\n-                        info += ' %.4f' % avg\n-                    else:\n-                        info += ' %.4e' % avg\n-                else:\n-                    info += ' %s' % self._values[k]\n-\n-            self._total_width += len(info)\n-            if prev_total_width > self._total_width:\n-                info += (' ' * (prev_total_width - self._total_width))\n-\n-            if self.target is not None and current >= self.target:\n-                info += '\\n'\n-\n-            sys.stdout.write(info)\n-            sys.stdout.flush()\n-\n-        elif self.verbose == 2:\n-            if self.target is None or current >= self.target:\n-                for k in self._values:\n-                    info += ' - %s:' % k\n-                    avg = np.mean(\n-                        self._values[k][0] / max(1, self._values[k][1]))\n-                    if avg > 1e-3:\n-                        info += ' %.4f' % avg\n-                    else:\n-                        info += ' %.4e' % avg\n-                info += '\\n'\n-\n-                sys.stdout.write(info)\n-                sys.stdout.flush()\n-\n-        self._last_update = now\n-\n-    def add(self, n, values=None):\n-        self.update(self._seen_so_far + n, values)\n+import sys\n+\n+from tensorflow.keras.utils import CustomObjectScope\n+from tensorflow.keras.utils import custom_object_scope\n+from tensorflow.keras.utils import get_custom_objects\n+from tensorflow.keras.utils import serialize_keras_object\n+from tensorflow.keras.utils import deserialize_keras_object\n+from tensorflow.keras.utils import Progbar\n \n \n def to_list(x, allow_tuple=False):\n@@ -621,3 +159,41 @@ def check_for_unexpected_keys(name, input_dict, expected_values):\n         raise ValueError('Unknown entries in {} dictionary: {}. Only expected '\n                          'following keys: {}'.format(name, list(unknown),\n                                                      expected_values))\n+\n+\n+def has_arg(fn, name, accept_all=False):\n+    \"\"\"Checks if a callable accepts a given keyword argument.\n+    For Python 2, checks if there is an argument with the given name.\n+    For Python 3, checks if there is an argument with the given name, and\n+    also whether this argument can be called with a keyword (i.e. if it is\n+    not a positional-only argument).\n+    # Arguments\n+        fn: Callable to inspect.\n+        name: Check if `fn` can be called with `name` as a keyword argument.\n+        accept_all: What to return if there is no parameter called `name`\n+                    but the function accepts a `**kwargs` argument.\n+    # Returns\n+        bool, whether `fn` accepts a `name` keyword argument.\n+    \"\"\"\n+    if sys.version_info < (3,):\n+        arg_spec = inspect.getargspec(fn)\n+        if accept_all and arg_spec.keywords is not None:\n+            return True\n+        return (name in arg_spec.args)\n+    elif sys.version_info < (3, 3):\n+        arg_spec = inspect.getfullargspec(fn)\n+        if accept_all and arg_spec.varkw is not None:\n+            return True\n+        return (name in arg_spec.args or\n+                name in arg_spec.kwonlyargs)\n+    else:\n+        signature = inspect.signature(fn)\n+        parameter = signature.parameters.get(name)\n+        if parameter is None:\n+            if accept_all:\n+                for param in signature.parameters.values():\n+                    if param.kind == inspect.Parameter.VAR_KEYWORD:\n+                        return True\n+            return False\n+        return (parameter.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD,\n+                                   inspect.Parameter.KEYWORD_ONLY))\n\n@@ -1,430 +1,3 @@\n \"\"\"Utilities related to disk I/O.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n \n-import numpy as np\n-from collections import defaultdict\n-import sys\n-import contextlib\n-\n-\n-import six\n-try:\n-    import h5py\n-    HDF5_OBJECT_HEADER_LIMIT = 64512\n-except ImportError:\n-    h5py = None\n-\n-\n-if sys.version_info[0] == 3:\n-    import pickle\n-else:\n-    import cPickle as pickle\n-\n-\n-class HDF5Matrix(object):\n-    \"\"\"Representation of HDF5 dataset to be used instead of a NumPy array.\n-\n-    # Example\n-\n-    ```python\n-        x_data = HDF5Matrix('input/file.hdf5', 'data')\n-        model.predict(x_data)\n-    ```\n-\n-    Providing `start` and `end` allows use of a slice of the dataset.\n-\n-    Optionally, a normalizer function (or lambda) can be given. This will\n-    be called on every slice of data retrieved.\n-\n-    # Arguments\n-        datapath: string, path to a HDF5 file\n-        dataset: string, name of the HDF5 dataset in the file specified\n-            in datapath\n-        start: int, start of desired slice of the specified dataset\n-        end: int, end of desired slice of the specified dataset\n-        normalizer: function to be called on data when retrieved\n-\n-    # Returns\n-        An array-like HDF5 dataset.\n-    \"\"\"\n-    refs = defaultdict(int)\n-\n-    def __init__(self, datapath, dataset, start=0, end=None, normalizer=None):\n-        if h5py is None:\n-            raise ImportError('The use of HDF5Matrix requires '\n-                              'HDF5 and h5py installed.')\n-\n-        if datapath not in list(self.refs.keys()):\n-            f = h5py.File(datapath)\n-            self.refs[datapath] = f\n-        else:\n-            f = self.refs[datapath]\n-        self.data = f[dataset]\n-        self.start = start\n-        if end is None:\n-            self.end = self.data.shape[0]\n-        else:\n-            self.end = end\n-        self.normalizer = normalizer\n-        if self.normalizer is not None:\n-            first_val = self.normalizer(self.data[0:1])\n-        else:\n-            first_val = self.data[0:1]\n-        self._base_shape = first_val.shape[1:]\n-        self._base_dtype = first_val.dtype\n-\n-    def __len__(self):\n-        return self.end - self.start\n-\n-    def __getitem__(self, key):\n-        if isinstance(key, slice):\n-            start, stop = key.start, key.stop\n-            if start is None:\n-                start = 0\n-            if stop is None:\n-                stop = self.shape[0]\n-            if stop + self.start <= self.end:\n-                idx = slice(start + self.start, stop + self.start)\n-            else:\n-                raise IndexError\n-        elif isinstance(key, (int, np.integer)):\n-            if key + self.start < self.end:\n-                idx = key + self.start\n-            else:\n-                raise IndexError\n-        elif isinstance(key, np.ndarray):\n-            if np.max(key) + self.start < self.end:\n-                idx = (self.start + key).tolist()\n-            else:\n-                raise IndexError\n-        else:\n-            # Assume list/iterable\n-            if max(key) + self.start < self.end:\n-                idx = [x + self.start for x in key]\n-            else:\n-                raise IndexError\n-        if self.normalizer is not None:\n-            return self.normalizer(self.data[idx])\n-        else:\n-            return self.data[idx]\n-\n-    @property\n-    def shape(self):\n-        \"\"\"Gets a numpy-style shape tuple giving the dataset dimensions.\n-\n-        # Returns\n-            A numpy-style shape tuple.\n-        \"\"\"\n-        return (self.end - self.start,) + self._base_shape\n-\n-    @property\n-    def dtype(self):\n-        \"\"\"Gets the datatype of the dataset.\n-\n-        # Returns\n-            A numpy dtype string.\n-        \"\"\"\n-        return self._base_dtype\n-\n-    @property\n-    def ndim(self):\n-        \"\"\"Gets the number of dimensions (rank) of the dataset.\n-\n-        # Returns\n-            An integer denoting the number of dimensions (rank) of the dataset.\n-        \"\"\"\n-        return self.data.ndim\n-\n-    @property\n-    def size(self):\n-        \"\"\"Gets the total dataset size (number of elements).\n-\n-        # Returns\n-            An integer denoting the number of elements in the dataset.\n-        \"\"\"\n-        return np.prod(self.shape)\n-\n-\n-def ask_to_proceed_with_overwrite(filepath):\n-    \"\"\"Produces a prompt asking about overwriting a file.\n-\n-    # Arguments\n-        filepath: the path to the file to be overwritten.\n-\n-    # Returns\n-        True if we can proceed with overwrite, False otherwise.\n-    \"\"\"\n-    overwrite = six.moves.input('[WARNING] %s already exists - overwrite? '\n-                                '[y/n]' % (filepath)).strip().lower()\n-    while overwrite not in ('y', 'n'):\n-        overwrite = six.moves.input('Enter \"y\" (overwrite) or \"n\" '\n-                                    '(cancel).').strip().lower()\n-    if overwrite == 'n':\n-        return False\n-    print('[TIP] Next time specify overwrite=True!')\n-    return True\n-\n-\n-class H5Dict(object):\n-    \"\"\" A dict-like wrapper around h5py groups (or dicts).\n-\n-    This allows us to have a single serialization logic\n-    for both pickling and saving to disk.\n-\n-    Note: This is not intended to be a generic wrapper.\n-    There are lot of edge cases which have been hardcoded,\n-    and makes sense only in the context of model serialization/\n-    deserialization.\n-\n-    # Arguments\n-        path: Either a string (path on disk), a Path, a dict, or a HDF5 Group.\n-        mode: File open mode (one of `{\"a\", \"r\", \"w\"}`).\n-    \"\"\"\n-\n-    def __init__(self, path, mode='a'):\n-        if isinstance(path, h5py.Group):\n-            self.data = path\n-            self._is_file = False\n-        elif isinstance(path, six.string_types) or _is_path_instance(path):\n-            self.data = h5py.File(path, mode=mode)\n-            self._is_file = True\n-        elif isinstance(path, dict):\n-            self.data = path\n-            self._is_file = False\n-            if mode == 'w':\n-                self.data.clear()\n-            # Flag to check if a dict is user defined data or a sub group:\n-            self.data['_is_group'] = True\n-        else:\n-            raise TypeError('Required Group, str, Path or dict. '\n-                            'Received: {}.'.format(type(path)))\n-        self.read_only = mode == 'r'\n-\n-    @staticmethod\n-    def is_supported_type(path):\n-        \"\"\"Check if `path` is of supported type for instantiating a `H5Dict`\"\"\"\n-        return (\n-            isinstance(path, h5py.Group) or\n-            isinstance(path, dict) or\n-            isinstance(path, six.string_types) or\n-            _is_path_instance(path)\n-        )\n-\n-    def __setitem__(self, attr, val):\n-        if self.read_only:\n-            raise ValueError('Cannot set item in read-only mode.')\n-        is_np = type(val).__module__ == np.__name__\n-        if isinstance(self.data, dict):\n-            if isinstance(attr, bytes):\n-                attr = attr.decode('utf-8')\n-            if is_np:\n-                self.data[attr] = pickle.dumps(val)\n-                # We have to remember to unpickle in __getitem__\n-                self.data['_{}_pickled'.format(attr)] = True\n-            else:\n-                self.data[attr] = val\n-            return\n-        if isinstance(self.data, h5py.Group) and attr in self.data:\n-            raise KeyError('Cannot set attribute. '\n-                           'Group with name \"{}\" exists.'.format(attr))\n-        if is_np:\n-            dataset = self.data.create_dataset(attr, val.shape, dtype=val.dtype)\n-            if not val.shape:\n-                # scalar\n-                dataset[()] = val\n-            else:\n-                dataset[:] = val\n-        elif isinstance(val, (list, tuple)):\n-            # Check that no item in `data` is larger than `HDF5_OBJECT_HEADER_LIMIT`\n-            # because in that case even chunking the array would not make the saving\n-            # possible.\n-            bad_attributes = [x for x in val if len(x) > HDF5_OBJECT_HEADER_LIMIT]\n-\n-            # Expecting this to never be true.\n-            if bad_attributes:\n-                raise RuntimeError('The following attributes cannot be saved to '\n-                                   'HDF5 file because they are larger than '\n-                                   '%d bytes: %s' % (HDF5_OBJECT_HEADER_LIMIT,\n-                                                     ', '.join(bad_attributes)))\n-\n-            if (val and sys.version_info[0] == 3 and isinstance(\n-                    val[0], six.string_types)):\n-                # convert to bytes\n-                val = [x.encode('utf-8') for x in val]\n-\n-            data_npy = np.asarray(val)\n-\n-            num_chunks = 1\n-            chunked_data = np.array_split(data_npy, num_chunks)\n-\n-            # This will never loop forever thanks to the test above.\n-            is_too_big = lambda x: x.nbytes > HDF5_OBJECT_HEADER_LIMIT\n-            while any(map(is_too_big, chunked_data)):\n-                num_chunks += 1\n-                chunked_data = np.array_split(data_npy, num_chunks)\n-\n-            if num_chunks > 1:\n-                for chunk_id, chunk_data in enumerate(chunked_data):\n-                    self.data.attrs['%s%d' % (attr, chunk_id)] = chunk_data\n-            else:\n-                self.data.attrs[attr] = val\n-        else:\n-            self.data.attrs[attr] = val\n-\n-    def __getitem__(self, attr):\n-        if isinstance(self.data, dict):\n-            if isinstance(attr, bytes):\n-                attr = attr.decode('utf-8')\n-            if attr in self.data:\n-                val = self.data[attr]\n-                if isinstance(val, dict) and val.get('_is_group'):\n-                    val = H5Dict(val)\n-                elif '_{}_pickled'.format(attr) in self.data:\n-                    val = pickle.loads(val)\n-                return val\n-            else:\n-                if self.read_only:\n-                    raise ValueError('Cannot create group in read-only mode.')\n-                val = {'_is_group': True}\n-                self.data[attr] = val\n-                return H5Dict(val)\n-        if attr in self.data.attrs:\n-            val = self.data.attrs[attr]\n-            if type(val).__module__ == np.__name__:\n-                if val.dtype.type == np.string_:\n-                    val = val.tolist()\n-        elif attr in self.data:\n-            val = self.data[attr]\n-            if isinstance(val, h5py.Dataset):\n-                val = np.asarray(val)\n-            else:\n-                val = H5Dict(val)\n-        else:\n-            # could be chunked\n-            chunk_attr = '%s%d' % (attr, 0)\n-            is_chunked = chunk_attr in self.data.attrs\n-            if is_chunked:\n-                val = []\n-                chunk_id = 0\n-                while chunk_attr in self.data.attrs:\n-                    chunk = self.data.attrs[chunk_attr]\n-                    val.extend([x.decode('utf8') for x in chunk])\n-                    chunk_id += 1\n-                    chunk_attr = '%s%d' % (attr, chunk_id)\n-            else:\n-                if self.read_only:\n-                    raise ValueError('Cannot create group in read-only mode.')\n-                val = H5Dict(self.data.create_group(attr))\n-        return val\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __iter__(self):\n-        return iter(self.data)\n-\n-    def iter(self):\n-        return iter(self.data)\n-\n-    def __getattr__(self, attr):\n-\n-        def wrapper(f):\n-            def h5wrapper(*args, **kwargs):\n-                out = f(*args, **kwargs)\n-                if isinstance(self.data, type(out)):\n-                    return H5Dict(out)\n-                else:\n-                    return out\n-            return h5wrapper\n-\n-        return wrapper(getattr(self.data, attr))\n-\n-    def close(self):\n-        if isinstance(self.data, h5py.Group):\n-            self.data.file.flush()\n-            if self._is_file:\n-                self.data.close()\n-\n-    def update(self, *args):\n-        if isinstance(self.data, dict):\n-            self.data.update(*args)\n-        raise NotImplementedError\n-\n-    def __contains__(self, key):\n-        if isinstance(self.data, dict):\n-            return key in self.data\n-        else:\n-            return (key in self.data) or (key in self.data.attrs)\n-\n-    def get(self, key, default=None):\n-        if key in self:\n-            return self[key]\n-        return default\n-\n-    def __enter__(self):\n-        return self\n-\n-    def __exit__(self, exc_type, exc_val, exc_tb):\n-        self.close()\n-\n-\n-h5dict = H5Dict\n-\n-\n-def load_from_binary_h5py(load_function, stream):\n-    \"\"\"Calls `load_function` on a `h5py.File` read from the binary `stream`.\n-\n-    # Arguments\n-        load_function: A function that takes a `h5py.File`, reads from it, and\n-            returns any object.\n-        stream: Any file-like object implementing the method `read` that returns\n-            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n-\n-    # Returns\n-        The object returned by `load_function`.\n-    \"\"\"\n-    # Implementation based on suggestion solution here:\n-    #   https://github.com/keras-team/keras/issues/9343#issuecomment-440903847\n-    binary_data = stream.read()\n-    file_access_property_list = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\n-    file_access_property_list.set_fapl_core(backing_store=False)\n-    file_access_property_list.set_file_image(binary_data)\n-    file_id_args = {'fapl': file_access_property_list,\n-                    'flags': h5py.h5f.ACC_RDONLY,\n-                    'name': b'in-memory-h5py'}  # name does not matter\n-    h5_file_args = {'backing_store': False,\n-                    'driver': 'core',\n-                    'mode': 'r'}\n-    with contextlib.closing(h5py.h5f.open(**file_id_args)) as file_id:\n-        with h5py.File(file_id, **h5_file_args) as h5_file:\n-            return load_function(h5_file)\n-\n-\n-def save_to_binary_h5py(save_function, stream):\n-    \"\"\"Calls `save_function` on an in memory `h5py.File`.\n-\n-    The file is subsequently written to the binary `stream`.\n-\n-     # Arguments\n-        save_function: A function that takes a `h5py.File`, writes to it and\n-            (optionally) returns any object.\n-        stream: Any file-like object implementing the method `write` that accepts\n-            `bytes` data (e.g. `io.BytesIO`).\n-     \"\"\"\n-    with h5py.File('in-memory-h5py', driver='core', backing_store=False) as h5file:\n-        # note that filename does not matter here.\n-        return_value = save_function(h5file)\n-        h5file.flush()\n-        binary_data = h5file.fid.get_file_image()\n-    stream.write(binary_data)\n-\n-    return return_value\n-\n-\n-def _is_path_instance(path):\n-    # We can't use isinstance here because it would require\n-    # us to add pathlib2 to the Python 2 dependencies.\n-    class_name = type(path).__name__\n-    return class_name == 'PosixPath' or class_name == 'WindowsPath'\n+from tensorflow.keras.utils import HDF5Matrix\n\n@@ -1,14 +1,14 @@\n \"\"\"Utilities related to layer/model functionality.\n \"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n from .conv_utils import convert_kernel\n from .. import backend as K\n import numpy as np\n \n \n+from tensorflow.keras.utils import get_source_inputs\n+from tensorflow.python.keras.utils.layer_utils import print_summary\n+\n+\n def count_params(weights):\n     \"\"\"Count the total number of scalars composing the weights.\n \n@@ -27,170 +27,6 @@ def count_params(weights):\n     return total\n \n \n-def print_summary(model, line_length=None, positions=None, print_fn=None):\n-    \"\"\"Prints a summary of a model.\n-\n-    # Arguments\n-        model: Keras model instance.\n-        line_length: Total length of printed lines\n-            (e.g. set this to adapt the display to different\n-            terminal window sizes).\n-        positions: Relative or absolute positions of log elements in each line.\n-            If not provided, defaults to `[.33, .55, .67, 1.]`.\n-        print_fn: Print function to use.\n-            It will be called on each line of the summary.\n-            You can set it to a custom function\n-            in order to capture the string summary.\n-            It defaults to `print` (prints to stdout).\n-    \"\"\"\n-    if print_fn is None:\n-        print_fn = print\n-\n-    if model.__class__.__name__ == 'Sequential':\n-        sequential_like = True\n-    elif not model._is_graph_network:\n-        # We treat subclassed models as a simple sequence of layers,\n-        # for logging purposes.\n-        sequential_like = True\n-    else:\n-        sequential_like = True\n-        nodes_by_depth = model._nodes_by_depth.values()\n-        nodes = []\n-        for v in nodes_by_depth:\n-            if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n-                # if the model has multiple nodes\n-                # or if the nodes have multiple inbound_layers\n-                # the model is no longer sequential\n-                sequential_like = False\n-                break\n-            nodes += v\n-        if sequential_like:\n-            # search for shared layers\n-            for layer in model.layers:\n-                flag = False\n-                for node in layer._inbound_nodes:\n-                    if node in nodes:\n-                        if flag:\n-                            sequential_like = False\n-                            break\n-                        else:\n-                            flag = True\n-                if not sequential_like:\n-                    break\n-\n-    if sequential_like:\n-        line_length = line_length or 65\n-        positions = positions or [.45, .85, 1.]\n-        if positions[-1] <= 1:\n-            positions = [int(line_length * p) for p in positions]\n-        # header names for the different log elements\n-        to_display = ['Layer (type)', 'Output Shape', 'Param #']\n-    else:\n-        line_length = line_length or 98\n-        positions = positions or [.33, .55, .67, 1.]\n-        if positions[-1] <= 1:\n-            positions = [int(line_length * p) for p in positions]\n-        # header names for the different log elements\n-        to_display = ['Layer (type)',\n-                      'Output Shape',\n-                      'Param #',\n-                      'Connected to']\n-        relevant_nodes = []\n-        for v in model._nodes_by_depth.values():\n-            relevant_nodes += v\n-\n-    def print_row(fields, positions):\n-        line = ''\n-        for i in range(len(fields)):\n-            if i > 0:\n-                line = line[:-1] + ' '\n-            line += str(fields[i])\n-            line = line[:positions[i]]\n-            line += ' ' * (positions[i] - len(line))\n-        print_fn(line)\n-\n-    print_fn('Model: \"{}\"'.format(model.name))\n-    print_fn('_' * line_length)\n-    print_row(to_display, positions)\n-    print_fn('=' * line_length)\n-\n-    def print_layer_summary(layer):\n-        try:\n-            output_shape = layer.output_shape\n-        except AttributeError:\n-            output_shape = 'multiple'\n-        name = layer.name\n-        cls_name = layer.__class__.__name__\n-        fields = [name + ' (' + cls_name + ')',\n-                  output_shape, layer.count_params()]\n-        print_row(fields, positions)\n-\n-    def print_layer_summary_with_connections(layer):\n-        \"\"\"Prints a summary for a single layer.\n-\n-        # Arguments\n-            layer: target layer.\n-        \"\"\"\n-        try:\n-            output_shape = layer.output_shape\n-        except AttributeError:\n-            output_shape = 'multiple'\n-        connections = []\n-        for node in layer._inbound_nodes:\n-            if relevant_nodes and node not in relevant_nodes:\n-                # node is not part of the current network\n-                continue\n-            for i in range(len(node.inbound_layers)):\n-                inbound_layer = node.inbound_layers[i].name\n-                inbound_node_index = node.node_indices[i]\n-                inbound_tensor_index = node.tensor_indices[i]\n-                connections.append(inbound_layer +\n-                                   '[' + str(inbound_node_index) + '][' +\n-                                   str(inbound_tensor_index) + ']')\n-\n-        name = layer.name\n-        cls_name = layer.__class__.__name__\n-        if not connections:\n-            first_connection = ''\n-        else:\n-            first_connection = connections[0]\n-        fields = [name +\n-                  ' (' + cls_name + ')',\n-                  output_shape,\n-                  layer.count_params(),\n-                  first_connection]\n-        print_row(fields, positions)\n-        if len(connections) > 1:\n-            for i in range(1, len(connections)):\n-                fields = ['', '', '', connections[i]]\n-                print_row(fields, positions)\n-\n-    layers = model.layers\n-    for i in range(len(layers)):\n-        if sequential_like:\n-            print_layer_summary(layers[i])\n-        else:\n-            print_layer_summary_with_connections(layers[i])\n-        if i == len(layers) - 1:\n-            print_fn('=' * line_length)\n-        else:\n-            print_fn('_' * line_length)\n-\n-    model._check_trainable_weights_consistency()\n-    if hasattr(model, '_collected_trainable_weights'):\n-        trainable_count = count_params(model._collected_trainable_weights)\n-    else:\n-        trainable_count = count_params(model.trainable_weights)\n-\n-    non_trainable_count = count_params(model.non_trainable_weights)\n-\n-    print_fn(\n-        'Total params: {:,}'.format(trainable_count + non_trainable_count))\n-    print_fn('Trainable params: {:,}'.format(trainable_count))\n-    print_fn('Non-trainable params: {:,}'.format(non_trainable_count))\n-    print_fn('_' * line_length)\n-\n-\n def convert_all_kernels_in_model(model):\n     \"\"\"Converts all convolution kernels in a model from Theano to TensorFlow.\n \n@@ -253,48 +89,3 @@ def convert_dense_weights_data_format(dense,\n             ki = np.transpose(ki, (1, 2, 0))  # first -> last\n         kernel[:, i] = np.reshape(ki, (np.prod(previous_feature_map_shape),))\n     dense.set_weights([kernel, bias])\n-\n-\n-def get_source_inputs(tensor, layer=None, node_index=None):\n-    \"\"\"Returns the list of input tensors necessary to compute `tensor`.\n-\n-    Output will always be a list of tensors\n-    (potentially with 1 element).\n-\n-    # Arguments\n-        tensor: The tensor to start from.\n-        layer: Origin layer of the tensor. Will be\n-            determined via tensor._keras_history if not provided.\n-        node_index: Origin node index of the tensor.\n-\n-    # Returns\n-        List of input tensors.\n-    \"\"\"\n-    if not hasattr(tensor, '_keras_history'):\n-        return tensor\n-\n-    if layer is None or node_index:\n-        layer, node_index, _ = tensor._keras_history\n-    if not layer._inbound_nodes:\n-        return [tensor]\n-    else:\n-        node = layer._inbound_nodes[node_index]\n-        if not node.inbound_layers:\n-            # Reached an Input layer, stop recursion.\n-            return node.input_tensors\n-        else:\n-            source_tensors = []\n-            source_tensors_ids = set()\n-            for i in range(len(node.inbound_layers)):\n-                x = node.input_tensors[i]\n-                layer = node.inbound_layers[i]\n-                node_index = node.node_indices[i]\n-                previous_sources = get_source_inputs(x,\n-                                                     layer,\n-                                                     node_index)\n-                # Avoid input redundancy.\n-                for x in previous_sources:\n-                    if id(x) not in source_tensors_ids:\n-                        source_tensors.append(x)\n-                        source_tensors_ids.add(id(x))\n-            return source_tensors\n\n@@ -1,178 +0,0 @@\n-\"\"\"Utilities related to losses.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import numpy as np\n-\n-from .. import backend as K\n-\n-\n-class Reduction(object):\n-    \"\"\"Types of loss reduction.\n-\n-    Contains the following values:\n-\n-    * `NONE`: Un-reduced weighted losses with the same shape as input. When this\n-        reduction type used with built-in Keras training loops like\n-        `fit`/`evaluate`, the unreduced vector loss is passed to the optimizer but\n-        the reported loss will be a scalar value.\n-    * `SUM`: Scalar sum of weighted losses.\n-    * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` divided by number of elements in losses.\n-    \"\"\"\n-\n-    NONE = 'none'\n-    SUM = 'sum'\n-    SUM_OVER_BATCH_SIZE = 'sum_over_batch_size'\n-\n-    @classmethod\n-    def all(cls):\n-        return (cls.NONE, cls.SUM, cls.SUM_OVER_BATCH_SIZE)\n-\n-    @classmethod\n-    def validate(cls, key):\n-        if key not in cls.all():\n-            raise ValueError('Invalid Reduction Key %s.' % key)\n-\n-\n-def squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n-    \"\"\"Squeeze or expand last dimension if needed.\n-\n-    1. Squeezes last dim of `y_pred` or `y_true` if their rank differs by 1.\n-    2. Squeezes or expands last dim of `sample_weight` if its rank differs by 1\n-    from the new rank of `y_pred`.\n-    If `sample_weight` is scalar, it is kept scalar.\n-\n-    # Arguments\n-        y_pred: Predicted values, a `Tensor` of arbitrary dimensions.\n-        y_true: Optional label `Tensor` whose dimensions match `y_pred`.\n-        sample_weight: Optional weight scalar or `Tensor` whose dimensions match\n-            `y_pred`.\n-\n-    # Returns\n-        Tuple of `y_pred`, `y_true` and `sample_weight`. Each of them possibly has\n-        the last dimension squeezed, `sample_weight` could be extended by one\n-        dimension.\n-    \"\"\"\n-    if y_true is not None:\n-        y_pred_rank = K.ndim(y_pred)\n-        y_pred_shape = K.int_shape(y_pred)\n-        y_true_rank = K.ndim(y_true)\n-        y_true_shape = K.int_shape(y_true)\n-\n-        if (y_pred_rank - y_true_rank == 1) and (y_pred_shape[-1] == 1):\n-            y_pred = K.squeeze(y_pred, -1)\n-        elif (y_true_rank - y_pred_rank == 1) and (y_true_shape[-1] == 1):\n-            y_true = K.squeeze(y_true, -1)\n-\n-    if sample_weight is None:\n-        return y_pred, y_true\n-\n-    y_pred_rank = K.ndim(y_pred)\n-    weights_rank = K.ndim(sample_weight)\n-    if weights_rank != 0:\n-        if y_pred_rank == 0 and weights_rank == 1:\n-            y_pred = K.expand_dims(y_pred, -1)\n-        elif weights_rank - y_pred_rank == 1:\n-            sample_weight = K.squeeze(sample_weight, -1)\n-        elif y_pred_rank - weights_rank == 1:\n-            sample_weight = K.expand_dims(sample_weight, -1)\n-    return y_pred, y_true, sample_weight\n-\n-\n-def _num_elements(losses):\n-    \"\"\"Computes the number of elements in `losses` tensor.\"\"\"\n-    with K.name_scope('num_elements') as scope:\n-        return K.cast(K.size(losses, name=scope), losses.dtype)\n-\n-\n-def reduce_weighted_loss(weighted_losses, reduction=Reduction.SUM_OVER_BATCH_SIZE):\n-    \"\"\"Reduces the individual weighted loss measurements.\"\"\"\n-    if reduction == Reduction.NONE:\n-        loss = weighted_losses\n-    else:\n-        loss = K.sum(weighted_losses)\n-        if reduction == Reduction.SUM_OVER_BATCH_SIZE:\n-            loss = loss / _num_elements(weighted_losses)\n-    return loss\n-\n-\n-def broadcast_weights(values, sample_weight):\n-    # Broadcast weights if possible.\n-    weights_shape = K.int_shape(sample_weight)\n-    values_shape = K.int_shape(values)\n-\n-    if values_shape != weights_shape:\n-        weights_rank = K.ndim(sample_weight)\n-        values_rank = K.ndim(values)\n-\n-        # Raise error if ndim of weights is > values.\n-        if weights_rank > values_rank:\n-            raise ValueError(\n-                'Incompatible shapes: `values` {} vs `sample_weight` {}'.format(\n-                    values_shape, weights_shape))\n-\n-        # Expand dim of weights to match ndim of values, if required.\n-        for i in range(weights_rank, values_rank):\n-            sample_weight = K.expand_dims(sample_weight, axis=i)\n-\n-        if weights_shape is not None and values_shape is not None:\n-            for i in range(weights_rank):\n-                if (weights_shape[i] is not None and\n-                    values_shape[i] is not None and\n-                        weights_shape[i] != values_shape[i]):\n-                    # Cannot be broadcasted.\n-                    if weights_shape[i] != 1:\n-                        raise ValueError(\n-                            'Incompatible shapes: `values` {} vs '\n-                            '`sample_weight` {}'.format(\n-                                values_shape, weights_shape))\n-                    sample_weight = K.repeat_elements(\n-                        sample_weight, values_shape[i], axis=i)\n-    return sample_weight\n-\n-\n-def compute_weighted_loss(losses,\n-                          sample_weight=None,\n-                          reduction=Reduction.SUM_OVER_BATCH_SIZE,\n-                          name=None):\n-    \"\"\"Computes the weighted loss.\n-\n-    # Arguments\n-        losses: `Tensor` of shape `[batch_size, d1, ... dN]`.\n-        sample_weight: Optional `Tensor` whose rank is either 0, or the same rank as\n-        `   losses`, or be broadcastable to `losses`.\n-        reduction: (Optional) Type of Reduction to apply to loss.\n-            Default value is `SUM_OVER_BATCH_SIZE`.\n-        name: Optional name for the op.\n-\n-    # Raises\n-        ValueError: If the shape of `sample_weight` is not compatible with `losses`.\n-\n-    # Returns\n-        Weighted loss `Tensor` of the same type as `losses`. If `reduction` is\n-            `NONE`, this has the same shape as `losses`; otherwise, it is scalar.\n-    \"\"\"\n-    Reduction.validate(reduction)\n-    if sample_weight is None:\n-        sample_weight = 1.0\n-    with K.name_scope(name or 'weighted_loss'):\n-        input_dtype = K.dtype(losses)\n-        losses = K.cast(losses, K.floatx())\n-        sample_weight = K.cast(sample_weight, K.floatx())\n-\n-        # Update dimensions of `sample_weight` to match with `losses` if possible.\n-        losses, _, sample_weight = squeeze_or_expand_dimensions(\n-            losses, None, sample_weight)\n-\n-        # Broadcast weights if possible.\n-        sample_weight = broadcast_weights(losses, sample_weight)\n-\n-        # Apply weights to losses.\n-        weighted_losses = sample_weight * losses\n-\n-        # Apply reduction function to the individual weighted losses.\n-        loss = reduce_weighted_loss(weighted_losses, reduction)\n-        # Convert the result back to the input type.\n-        loss = K.cast(loss, input_dtype)\n-        return loss\n\n@@ -1,324 +0,0 @@\n-\"\"\"Utilities related to metrics.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from enum import Enum\n-\n-from .. import backend as K\n-from . import losses_utils\n-\n-\n-NEG_INF = -1e10\n-\n-\n-class Reduction(object):\n-    \"\"\"Types of metrics reduction.\n-\n-    Contains the following values:\n-    * `SUM`: Scalar sum of weighted values.\n-    * `SUM_OVER_BATCH_SIZE`: Scalar `SUM` of weighted values divided by\n-        number of elements in values.\n-    * `WEIGHTED_MEAN`: Scalar sum of weighted values divided by sum of weights.\n-    \"\"\"\n-\n-    SUM = 'sum'\n-    SUM_OVER_BATCH_SIZE = 'sum_over_batch_size'\n-    WEIGHTED_MEAN = 'weighted_mean'\n-\n-\n-def update_state_wrapper(update_state_fn):\n-    \"\"\"Decorator to wrap metric `update_state()` with `add_update()`.\n-\n-    # Arguments\n-        update_state_fn: function that accumulates metric statistics.\n-\n-    # Returns\n-        Decorated function that wraps `update_state_fn()` with `add_update()`.\n-    \"\"\"\n-    def decorated(metric_obj, *args, **kwargs):\n-        \"\"\"Decorated function with `add_update()`.\"\"\"\n-\n-        update_op = update_state_fn(*args, **kwargs)\n-        metric_obj.add_update(update_op)\n-        return update_op\n-\n-    return decorated\n-\n-\n-def result_wrapper(result_fn):\n-    \"\"\"Decorator to wrap metric `result()` with identity op.\n-\n-    Wrapping result in identity so that control dependency between\n-    update_op from `update_state` and result works in case result returns\n-    a tensor.\n-\n-    # Arguments\n-        result_fn: function that computes the metric result.\n-\n-    # Returns\n-        Decorated function that wraps `result()` with identity op.\n-    \"\"\"\n-    def decorated(metric_obj, *args, **kwargs):\n-        result_t = K.identity(result_fn(*args, **kwargs))\n-        metric_obj._call_result = result_t\n-        result_t._is_metric = True\n-        return result_t\n-\n-    return decorated\n-\n-\n-def filter_top_k(x, k):\n-    \"\"\"Filters top-k values in the last dim of x and set the rest to NEG_INF.\n-    Used for computing top-k prediction values in dense labels (which has the same\n-    shape as predictions) for recall and precision top-k metrics.\n-\n-    # Arguments\n-        x: tensor with any dimensions.\n-        k: the number of values to keep.\n-\n-    # Returns\n-        tensor with same shape and dtype as x.\n-    \"\"\"\n-    import tensorflow as tf\n-    _, top_k_idx = tf.nn.top_k(x, k, sorted=False)\n-    top_k_mask = K.sum(\n-        K.one_hot(top_k_idx, x.shape[-1]), axis=-2)\n-    return x * top_k_mask + NEG_INF * (1 - top_k_mask)\n-\n-\n-def to_list(x):\n-    if isinstance(x, list):\n-        return x\n-    return [x]\n-\n-\n-def assert_thresholds_range(thresholds):\n-    if thresholds is not None:\n-        invalid_thresholds = [t for t in thresholds if t is None or t < 0 or t > 1]\n-    if invalid_thresholds:\n-        raise ValueError(\n-            'Threshold values must be in [0, 1]. Invalid values: {}'.format(\n-                invalid_thresholds))\n-\n-\n-def parse_init_thresholds(thresholds, default_threshold=0.5):\n-    if thresholds is not None:\n-        assert_thresholds_range(to_list(thresholds))\n-    thresholds = to_list(default_threshold if thresholds is None else thresholds)\n-    return thresholds\n-\n-\n-class ConfusionMatrix(Enum):\n-    TRUE_POSITIVES = 'tp'\n-    FALSE_POSITIVES = 'fp'\n-    TRUE_NEGATIVES = 'tn'\n-    FALSE_NEGATIVES = 'fn'\n-\n-\n-class AUCCurve(Enum):\n-    \"\"\"Type of AUC Curve (ROC or PR).\"\"\"\n-    ROC = 'ROC'\n-    PR = 'PR'\n-\n-    @staticmethod\n-    def from_str(key):\n-        if key in ('pr', 'PR'):\n-            return AUCCurve.PR\n-        elif key in ('roc', 'ROC'):\n-            return AUCCurve.ROC\n-        else:\n-            raise ValueError('Invalid AUC curve value \"%s\".' % key)\n-\n-\n-class AUCSummationMethod(Enum):\n-    \"\"\"Type of AUC summation method.\n-\n-    https://en.wikipedia.org/wiki/Riemann_sum)\n-\n-    Contains the following values:\n-    * 'interpolation': Applies mid-point summation scheme for `ROC` curve. For\n-    `PR` curve, interpolates (true/false) positives but not the ratio that is\n-    precision (see Davis & Goadrich 2006 for details).\n-    * 'minoring': Applies left summation for increasing intervals and right\n-    summation for decreasing intervals.\n-    * 'majoring': Applies right summation for increasing intervals and left\n-    summation for decreasing intervals.\n-    \"\"\"\n-    INTERPOLATION = 'interpolation'\n-    MAJORING = 'majoring'\n-    MINORING = 'minoring'\n-\n-    @staticmethod\n-    def from_str(key):\n-        if key in ('interpolation', 'Interpolation'):\n-            return AUCSummationMethod.INTERPOLATION\n-        elif key in ('majoring', 'Majoring'):\n-            return AUCSummationMethod.MAJORING\n-        elif key in ('minoring', 'Minoring'):\n-            return AUCSummationMethod.MINORING\n-        else:\n-            raise ValueError('Invalid AUC summation method value \"%s\".' % key)\n-\n-\n-def weighted_assign_add(label, pred, weights, var):\n-    # Logical and\n-    label = K.expand_dims(label, 0)\n-    pred = K.expand_dims(pred, 0)\n-    are_different = K.concatenate([label, pred], axis=0)\n-    label_and_pred = K.all(are_different, axis=0)\n-\n-    label_and_pred = K.cast(label_and_pred, dtype=K.floatx())\n-    if weights is not None:\n-        label_and_pred *= weights\n-    return K.update_add(var, K.sum(label_and_pred, 1))\n-\n-\n-def update_confusion_matrix_variables(variables_to_update,\n-                                      y_true,\n-                                      y_pred,\n-                                      thresholds=0.5,\n-                                      top_k=None,\n-                                      class_id=None,\n-                                      sample_weight=None):\n-    \"\"\"Returns op to update the given confusion matrix variables.\n-\n-    For every pair of values in y_true and y_pred:\n-\n-    true_positive: y_true == True and y_pred > thresholds\n-    false_negatives: y_true == True and y_pred <= thresholds\n-    true_negatives: y_true == False and y_pred <= thresholds\n-    false_positive: y_true == False and y_pred > thresholds\n-\n-    The results will be weighted and added together. When multiple thresholds are\n-    provided, we will repeat the same for every threshold.\n-\n-    For estimation of these metrics over a stream of data, the function creates an\n-    `update_op` operation that updates the given variables.\n-\n-    If `sample_weight` is `None`, weights default to 1.\n-    Use weights of 0 to mask values.\n-\n-    # Arguments\n-    variables_to_update: Dictionary with 'tp', 'fn', 'tn', 'fp' as valid keys\n-      and corresponding variables to update as values.\n-    y_true: A `Tensor` whose shape matches `y_pred`. Will be cast to `bool`.\n-    y_pred: A floating point `Tensor` of arbitrary shape and whose values are in\n-      the range `[0, 1]`.\n-    thresholds: A float value or a python list or tuple of float thresholds in\n-      `[0, 1]`, or NEG_INF (used when top_k is set).\n-    top_k: Optional int, indicates that the positive labels should be limited to\n-      the top k predictions.\n-    class_id: Optional int, limits the prediction and labels to the class\n-      specified by this argument.\n-    sample_weight: Optional `Tensor` whose rank is either 0, or the same rank as\n-      `y_true`, and must be broadcastable to `y_true` (i.e., all dimensions must\n-      be either `1`, or the same as the corresponding `y_true` dimension).\n-\n-    # Returns\n-        Update ops.\n-\n-    # Raises\n-        ValueError: If `y_pred` and `y_true` have mismatched shapes, or if\n-            `sample_weight` is not `None` and its shape doesn't match `y_pred`, or if\n-            `variables_to_update` contains invalid keys.\n-    \"\"\"\n-    if variables_to_update is None:\n-        return\n-    y_true = K.cast(y_true, dtype=K.floatx())\n-    y_pred = K.cast(y_pred, dtype=K.floatx())\n-    if sample_weight is not None:\n-        sample_weight = K.cast(sample_weight, dtype=K.floatx())\n-\n-    if not any(key\n-               for key in variables_to_update\n-               if key in list(ConfusionMatrix)):\n-        raise ValueError(\n-            'Please provide at least one valid confusion matrix '\n-            'variable to update. Valid variable key options are: \"{}\". '\n-            'Received: \"{}\"'.format(\n-                list(ConfusionMatrix), variables_to_update.keys()))\n-\n-    invalid_keys = [\n-        key for key in variables_to_update if key not in list(ConfusionMatrix)\n-    ]\n-    if invalid_keys:\n-        raise ValueError(\n-            'Invalid keys: {}. Valid variable key options are: \"{}\"'.format(\n-                invalid_keys, list(ConfusionMatrix)))\n-\n-    if sample_weight is None:\n-        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n-            y_pred, y_true=y_true)\n-    else:\n-        y_pred, y_true, sample_weight = (\n-            losses_utils.squeeze_or_expand_dimensions(\n-                y_pred, y_true=y_true, sample_weight=sample_weight))\n-\n-    if top_k is not None:\n-        y_pred = filter_top_k(y_pred, top_k)\n-    if class_id is not None:\n-        y_true = y_true[..., class_id]\n-        y_pred = y_pred[..., class_id]\n-\n-    thresholds = to_list(thresholds)\n-    num_thresholds = len(thresholds)\n-    num_predictions = K.size(y_pred)\n-\n-    # Reshape predictions and labels.\n-    predictions_2d = K.reshape(y_pred, [1, -1])\n-    labels_2d = K.reshape(\n-        K.cast(y_true, dtype='bool'), [1, -1])\n-\n-    # Tile the thresholds for every prediction.\n-    thresh_tiled = K.tile(\n-        K.expand_dims(K.constant(thresholds), 1),\n-        K.cast(\n-            K.stack([1, num_predictions]),\n-            dtype='int32',\n-        )\n-    )\n-\n-    # Tile the predictions for every threshold.\n-    preds_tiled = K.tile(predictions_2d, [num_thresholds, 1])\n-\n-    # Compare predictions and threshold.\n-    pred_is_pos = K.greater(preds_tiled, thresh_tiled)\n-\n-    # Tile labels by number of thresholds\n-    label_is_pos = K.tile(labels_2d, [num_thresholds, 1])\n-\n-    if sample_weight is not None:\n-        weights = losses_utils.broadcast_weights(\n-            y_pred, K.cast(sample_weight, dtype=K.floatx()))\n-        weights_tiled = K.tile(\n-            K.reshape(weights, [1, -1]), [num_thresholds, 1])\n-    else:\n-        weights_tiled = None\n-\n-    update_ops = []\n-    loop_vars = {\n-        ConfusionMatrix.TRUE_POSITIVES: (label_is_pos, pred_is_pos),\n-    }\n-    update_tn = ConfusionMatrix.TRUE_NEGATIVES in variables_to_update\n-    update_fp = ConfusionMatrix.FALSE_POSITIVES in variables_to_update\n-    update_fn = ConfusionMatrix.FALSE_NEGATIVES in variables_to_update\n-\n-    if update_fn or update_tn:\n-        pred_is_neg = K.equal(\n-            pred_is_pos, K.zeros_like(pred_is_pos, dtype=pred_is_pos.dtype))\n-        loop_vars[ConfusionMatrix.FALSE_NEGATIVES] = (label_is_pos, pred_is_neg)\n-\n-    if update_fp or update_tn:\n-        label_is_neg = K.equal(\n-            label_is_pos, K.zeros_like(label_is_pos, dtype=label_is_pos.dtype))\n-        loop_vars[ConfusionMatrix.FALSE_POSITIVES] = (label_is_neg, pred_is_pos)\n-        if update_tn:\n-            loop_vars[ConfusionMatrix.TRUE_NEGATIVES] = (label_is_neg, pred_is_neg)\n-\n-    for matrix_cond, (label, pred) in loop_vars.items():\n-        if matrix_cond in variables_to_update:\n-            update_ops.append(\n-                weighted_assign_add(label, pred, weights_tiled,\n-                                    variables_to_update[matrix_cond]))\n-    return update_ops\n\n@@ -1,258 +1,3 @@\n-\"\"\"Multi-GPU training utilities.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n+\"\"\"Multi-GPU training utilities.\"\"\"\n \n-from ..layers.merge import concatenate\n-from .. import backend as K\n-from ..layers.core import Lambda\n-from ..engine.training import Model\n-from ..models import clone_model\n-from ..utils.generic_utils import to_list\n-\n-\n-def _get_available_devices():\n-    return K.tensorflow_backend._get_available_gpus() + ['/cpu:0']\n-\n-\n-def _normalize_device_name(name):\n-    name = '/' + ':'.join(name.lower().replace('/', '').split(':')[-2:])\n-    return name\n-\n-\n-def multi_gpu_model(model, gpus=None, cpu_merge=True, cpu_relocation=False):\n-    \"\"\"Replicates a model on different GPUs.\n-\n-    Specifically, this function implements single-machine\n-    multi-GPU data parallelism. It works in the following way:\n-\n-    - Divide the model's input(s) into multiple sub-batches.\n-    - Apply a model copy on each sub-batch. Every model copy\n-        is executed on a dedicated GPU.\n-    - Concatenate the results (on CPU) into one big batch.\n-\n-    E.g. if your `batch_size` is 64 and you use `gpus=2`,\n-    then we will divide the input into 2 sub-batches of 32 samples,\n-    process each sub-batch on one GPU, then return the full\n-    batch of 64 processed samples.\n-\n-    This induces quasi-linear speedup on up to 8 GPUs.\n-\n-    This function is only available with the TensorFlow backend\n-    for the time being.\n-\n-    # Arguments\n-        model: A Keras model instance. To avoid OOM errors,\n-            this model could have been built on CPU, for instance\n-            (see usage example below).\n-        gpus: Integer >= 2 or list of integers, number of GPUs or\n-            list of GPU IDs on which to create model replicas.\n-        cpu_merge: A boolean value to identify whether to force\n-            merging model weights under the scope of the CPU or not.\n-        cpu_relocation: A boolean value to identify whether to\n-            create the model's weights under the scope of the CPU.\n-            If the model is not defined under any preceding device\n-            scope, you can still rescue it by activating this option.\n-\n-    # Returns\n-        A Keras `Model` instance which can be used just like the initial\n-        `model` argument, but which distributes its workload on multiple GPUs.\n-\n-    # Examples\n-\n-    Example 1 - Training models with weights merge on CPU\n-\n-    ```python\n-        import tensorflow as tf\n-        from keras.applications import Xception\n-        from keras.utils import multi_gpu_model\n-        import numpy as np\n-\n-        num_samples = 1000\n-        height = 224\n-        width = 224\n-        num_classes = 1000\n-\n-        # Instantiate the base model (or \"template\" model).\n-        # We recommend doing this with under a CPU device scope,\n-        # so that the model's weights are hosted on CPU memory.\n-        # Otherwise they may end up hosted on a GPU, which would\n-        # complicate weight sharing.\n-        with tf.device('/cpu:0'):\n-            model = Xception(weights=None,\n-                             input_shape=(height, width, 3),\n-                             classes=num_classes)\n-\n-        # Replicates the model on 8 GPUs.\n-        # This assumes that your machine has 8 available GPUs.\n-        parallel_model = multi_gpu_model(model, gpus=8)\n-        parallel_model.compile(loss='categorical_crossentropy',\n-                               optimizer='rmsprop')\n-\n-        # Generate dummy data.\n-        x = np.random.random((num_samples, height, width, 3))\n-        y = np.random.random((num_samples, num_classes))\n-\n-        # This `fit` call will be distributed on 8 GPUs.\n-        # Since the batch size is 256, each GPU will process 32 samples.\n-        parallel_model.fit(x, y, epochs=20, batch_size=256)\n-\n-        # Save model via the template model (which shares the same weights):\n-        model.save('my_model.h5')\n-    ```\n-\n-    Example 2 - Training models with weights merge on CPU using cpu_relocation\n-\n-    ```python\n-         ..\n-         # Not needed to change the device scope for model definition:\n-         model = Xception(weights=None, ..)\n-\n-         try:\n-             parallel_model = multi_gpu_model(model, cpu_relocation=True)\n-             print(\"Training using multiple GPUs..\")\n-         except ValueError:\n-             parallel_model = model\n-             print(\"Training using single GPU or CPU..\")\n-         parallel_model.compile(..)\n-         ..\n-    ```\n-\n-    Example 3 - Training models with weights merge on GPU (recommended for NV-link)\n-\n-    ```python\n-         ..\n-         # Not needed to change the device scope for model definition:\n-         model = Xception(weights=None, ..)\n-\n-         try:\n-             parallel_model = multi_gpu_model(model, cpu_merge=False)\n-             print(\"Training using multiple GPUs..\")\n-         except:\n-             parallel_model = model\n-             print(\"Training using single GPU or CPU..\")\n-\n-         parallel_model.compile(..)\n-         ..\n-    ```\n-\n-    # On model saving\n-\n-    To save the multi-gpu model, use `.save(fname)` or `.save_weights(fname)`\n-    with the template model (the argument you passed to `multi_gpu_model`),\n-    rather than the model returned by `multi_gpu_model`.\n-    \"\"\"\n-    if K.backend() != 'tensorflow':\n-        raise ValueError('`multi_gpu_model` is only available '\n-                         'with the TensorFlow backend.')\n-\n-    available_devices = _get_available_devices()\n-    available_devices = [_normalize_device_name(name)\n-                         for name in available_devices]\n-    if not gpus:\n-        # Using all visible GPUs when not specifying `gpus`\n-        # e.g. CUDA_VISIBLE_DEVICES=0,2 python keras_mgpu.py\n-        gpus = len((x for x in available_devices if '/gpu:' in x))\n-\n-    if isinstance(gpus, (list, tuple)):\n-        if len(gpus) <= 1:\n-            raise ValueError('For multi-gpu usage to be effective, '\n-                             'call `multi_gpu_model` with `len(gpus) >= 2`. '\n-                             'Received: `gpus=%s`' % gpus)\n-        num_gpus = len(gpus)\n-        target_gpu_ids = gpus\n-    else:\n-        if gpus <= 1:\n-            raise ValueError('For multi-gpu usage to be effective, '\n-                             'call `multi_gpu_model` with `gpus >= 2`. '\n-                             'Received: `gpus=%d`' % gpus)\n-        num_gpus = gpus\n-        target_gpu_ids = range(num_gpus)\n-\n-    import tensorflow as tf\n-\n-    target_devices = ['/cpu:0'] + ['/gpu:%d' % i for i in target_gpu_ids]\n-    for device in target_devices:\n-        if device not in available_devices:\n-            raise ValueError(\n-                'To call `multi_gpu_model` with `gpus=%s`, '\n-                'we expect the following devices to be available: %s. '\n-                'However this machine only has: %s. '\n-                'Try reducing `gpus`.' % (gpus,\n-                                          target_devices,\n-                                          available_devices))\n-\n-    def get_slice(data, i, parts):\n-        shape = K.shape(data)\n-        batch_size = shape[:1]\n-        input_shape = shape[1:]\n-        step = batch_size // parts\n-        if i == parts - 1:\n-            size = batch_size - step * i\n-        else:\n-            size = step\n-        size = K.concatenate([size, input_shape], axis=0)\n-        stride = K.concatenate([step, input_shape * 0], axis=0)\n-        start = stride * i\n-        return K.slice(data, start, size)\n-\n-    # Relocate the model definition under CPU device scope if needed\n-    if cpu_relocation:\n-        with tf.device('/cpu:0'):\n-            model = clone_model(model)\n-\n-    all_outputs = []\n-    for i in range(len(model.outputs)):\n-        all_outputs.append([])\n-\n-    # Place a copy of the model on each GPU,\n-    # each getting a slice of the inputs.\n-    for i, gpu_id in enumerate(target_gpu_ids):\n-        with tf.device('/gpu:%d' % gpu_id):\n-            with tf.name_scope('replica_%d' % gpu_id):\n-                inputs = []\n-                # Retrieve a slice of the input.\n-                for x in model.inputs:\n-                    # In-place input splitting which is not only\n-                    # 5% ~ 12% faster but also less GPU memory\n-                    # duplication.\n-                    with tf.device(x.device):\n-                        input_shape = K.int_shape(x)[1:]\n-                        slice_i = Lambda(get_slice,\n-                                         output_shape=input_shape,\n-                                         arguments={'i': i,\n-                                                    'parts': num_gpus})(x)\n-                        inputs.append(slice_i)\n-\n-                # Apply model on slice\n-                # (creating a model replica on the target device).\n-                outputs = model(inputs)\n-                outputs = to_list(outputs)\n-\n-                # Save the outputs for merging back together later.\n-                for o in range(len(outputs)):\n-                    all_outputs[o].append(outputs[o])\n-\n-    # Deduplicate output names to handle Siamese networks.\n-    occurrences = {}\n-    for n in model.output_names:\n-        if n not in occurrences:\n-            occurrences[n] = 1\n-        else:\n-            occurrences[n] += 1\n-    conflict_counter = {n: 0 for n, count in occurrences.items() if count > 1}\n-    output_names = []\n-    for n in model.output_names:\n-        if n in conflict_counter:\n-            conflict_counter[n] += 1\n-            n += '_%d' % conflict_counter[n]\n-        output_names.append(n)\n-\n-    # Merge outputs under expected scope.\n-    with tf.device('/cpu:0' if cpu_merge else '/gpu:%d' % target_gpu_ids[0]):\n-        merged = []\n-        for name, outputs in zip(output_names, all_outputs):\n-            merged.append(concatenate(outputs,\n-                                      axis=0, name=name))\n-        return Model(model.inputs, merged)\n+from tensorflow.keras.utils import multi_gpu_model\n\n@@ -1,71 +1,4 @@\n \"\"\"Numpy-related utilities.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n \n-import numpy as np\n-\n-\n-def to_categorical(y, num_classes=None, dtype='float32'):\n-    \"\"\"Converts a class vector (integers) to binary class matrix.\n-\n-    E.g. for use with categorical_crossentropy.\n-\n-    # Arguments\n-        y: class vector to be converted into a matrix\n-            (integers from 0 to num_classes).\n-        num_classes: total number of classes.\n-        dtype: The data type expected by the input, as a string\n-            (`float32`, `float64`, `int32`...)\n-\n-    # Returns\n-        A binary matrix representation of the input. The classes axis\n-        is placed last.\n-\n-    # Example\n-\n-    ```python\n-    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n-    > labels\n-    array([0, 2, 1, 2, 0])\n-    # `to_categorical` converts this into a matrix with as many\n-    # columns as there are classes. The number of rows\n-    # stays the same.\n-    > to_categorical(labels)\n-    array([[ 1.,  0.,  0.],\n-           [ 0.,  0.,  1.],\n-           [ 0.,  1.,  0.],\n-           [ 0.,  0.,  1.],\n-           [ 1.,  0.,  0.]], dtype=float32)\n-    ```\n-    \"\"\"\n-\n-    y = np.array(y, dtype='int')\n-    input_shape = y.shape\n-    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n-        input_shape = tuple(input_shape[:-1])\n-    y = y.ravel()\n-    if not num_classes:\n-        num_classes = np.max(y) + 1\n-    n = y.shape[0]\n-    categorical = np.zeros((n, num_classes), dtype=dtype)\n-    categorical[np.arange(n), y] = 1\n-    output_shape = input_shape + (num_classes,)\n-    categorical = np.reshape(categorical, output_shape)\n-    return categorical\n-\n-\n-def normalize(x, axis=-1, order=2):\n-    \"\"\"Normalizes a NumPy array.\n-\n-    # Arguments\n-        x: NumPy array to normalize.\n-        axis: axis along which to normalize.\n-        order: Normalization order (e.g. 2 for L2 norm).\n-\n-    # Returns\n-        A normalized copy of the array.\n-    \"\"\"\n-    l2 = np.atleast_1d(np.linalg.norm(x, order, axis))\n-    l2[l2 == 0] = 1\n-    return x / np.expand_dims(l2, axis)\n+from tensorflow.keras.utils import to_categorical\n+from tensorflow.keras.utils import normalize\n\n@@ -1,10 +1,5 @@\n \"\"\"Utilities related to Keras unit tests.\"\"\"\n from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import os\n-from io import BytesIO\n \n import numpy as np\n from numpy.testing import assert_allclose\n@@ -13,15 +8,6 @@ from .generic_utils import has_arg\n from ..engine import Model, Input\n from .. import backend as K\n \n-try:\n-    from tensorflow.python.lib.io import file_io as tf_file_io\n-except ImportError:\n-    tf_file_io = None\n-\n-try:\n-    from unittest.mock import patch, Mock, MagicMock\n-except:\n-    from mock import patch, Mock, MagicMock\n \n \n def get_test_data(num_train=1000, num_test=500, input_shape=(10,),\n@@ -129,182 +115,3 @@ def layer_test(layer_cls, kwargs={}, input_shape=None, input_dtype=None,\n \n     # for further checks in the caller function\n     return actual_output\n-\n-\n-class tf_file_io_proxy(object):\n-    \"\"\"Context manager for mock patching `tensorflow.python.lib.io.file_io` in tests.\n-\n-    The purpose of this class is to be able to tests model saving/loading to/from\n-    Google Cloud Storage, for witch the tensorflow `file_io` package is used.\n-\n-    If a `bucket_name` is provided, either as an input argument or by setting the\n-    environment variable GCS_TEST_BUCKET, *NO mocking* will be done and files will be\n-    transferred to the real GCS bucket. For this to work, valid Google application\n-    credentials must be available, see:\n-        https://cloud.google.com/video-intelligence/docs/common/auth\n-    for further details.\n-\n-    If a `bucket_name` is not provided, an identifier of the import of the file_io\n-    module to mock must be provided, using the `file_io_module` argument.\n-    NOTE that only part of the module is mocked and that the same Exceptions\n-    are not raised in mock implementation.\n-\n-    Since the bucket name can be provided using an environment variable, it is\n-    recommended to use method `get_filepath(filename)` in tests to make them\n-    pass with and without a real GCS bucket during testing. See example below.\n-\n-    # Arguments\n-        file_io_module: String identifier of the file_io module import to patch. E.g\n-            'keras.engine.saving.tf_file_io'\n-        bucket_name: String identifier of *a real* GCS bucket (with or without the\n-            'gs://' prefix). A bucket name provided with argument precedes what is\n-            specified using the GCS_TEST_BUCKET environment variable.\n-\n-    # Example\n-    ```python\n-    model = Sequential()\n-    model.add(Dense(2, input_shape=(3,)))\n-\n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(filename='model.h5')\n-        save_model(model, gcs_filepath)\n-        file_io_proxy.assert_exists(gcs_filepath)\n-        new_model_gcs = load_model(gcs_filepath)\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-    ```\n-    \"\"\"\n-    _gcs_prefix = 'gs://'\n-    _test_bucket_env_key = 'GCS_TEST_BUCKET'\n-\n-    def __init__(self, file_io_module=None, bucket_name=None):\n-        if bucket_name is None:\n-            bucket_name = os.environ.get(self._test_bucket_env_key, None)\n-        if bucket_name is None:\n-            # will mock gcs locally for tests\n-            if file_io_module is None:\n-                raise ValueError('`file_io_module` must be provided for mocking')\n-            self.mock_gcs = True\n-            self.file_io_module = file_io_module\n-            self.local_objects = {}\n-            self.bucket_name = 'mock-bucket'\n-        else:\n-            # will use real bucket for tests\n-            if bucket_name.startswith(self._gcs_prefix):\n-                bucket_name = bucket_name[len(self._gcs_prefix):]\n-            self.bucket_name = bucket_name\n-            if tf_file_io is None:\n-                raise ImportError(\n-                    'tensorflow must be installed to read/write to GCS')\n-            try:\n-                # check that bucket exists and is accessible\n-                tf_file_io.is_directory(self.bucket_path)\n-            except:\n-                raise IOError(\n-                    'could not access provided bucket {}'.format(self.bucket_path))\n-            self.mock_gcs = False\n-            self.file_io_module = None\n-            self.local_objects = None\n-\n-        self.patched_file_io = None\n-        self._is_started = False\n-\n-    @property\n-    def bucket_path(self):\n-        \"\"\"Returns the full GCS bucket path\"\"\"\n-        return self._gcs_prefix + self.bucket_name\n-\n-    def get_filepath(self, filename):\n-        \"\"\"Returns filename appended to bucketpath\"\"\"\n-        return os.path.join(self.bucket_path, filename)\n-\n-    def FileIO(self, name, mode):\n-        \"\"\"Proxy for tensorflow.python.lib.io.file_io.FileIO class. Mocks the class\n-        if a real GCS bucket is not available for testing.\n-        \"\"\"\n-        self._check_started()\n-        if not self.mock_gcs:\n-            return tf_file_io.FileIO(name, mode)\n-\n-        filepath = name\n-        if filepath.startswith(self._gcs_prefix):\n-            mock_fio = MagicMock()\n-            mock_fio.__enter__ = Mock(return_value=mock_fio)\n-            if mode == 'rb':\n-                if filepath not in self.local_objects:\n-                    raise IOError('{} does not exist'.format(filepath))\n-                self.local_objects[filepath].seek(0)\n-                mock_fio.read = self.local_objects[filepath].read\n-            elif mode == 'wb':\n-                self.local_objects[filepath] = BytesIO()\n-                mock_fio.write = self.local_objects[filepath].write\n-            else:\n-                raise ValueError(\n-                    '{} only supports wrapping of FileIO for `mode` \"rb\" or \"wb\"')\n-            return mock_fio\n-\n-        return open(filepath, mode)\n-\n-    def file_exists(self, filename):\n-        \"\"\"Proxy for tensorflow.python.lib.io.file_io.file_exists class. Mocks the\n-        function if a real GCS bucket is not available for testing.\n-        \"\"\"\n-        self._check_started()\n-        if not self.mock_gcs:\n-            return tf_file_io.file_exists(filename)\n-\n-        if filename.startswith(self._gcs_prefix):\n-            return filename in self.local_objects\n-\n-        return os.path.exists(filename)\n-\n-    def delete_file(self, filename):\n-        \"\"\"Proxy for tensorflow.python.lib.io.file_io.delete_file function. Mocks\n-        the function if a real GCS bucket is not available for testing.\n-        \"\"\"\n-        if not self.mock_gcs:\n-            tf_file_io.delete_file(filename)\n-        elif filename.startswith(self._gcs_prefix):\n-            self.local_objects.pop(filename)\n-        else:\n-            os.remove(filename)\n-\n-    def assert_exists(self, filepath):\n-        \"\"\"Convenience method for verifying that a file exists after writing.\"\"\"\n-        self._check_started()\n-        if not self.file_exists(filepath):\n-            raise AssertionError('{} does not exist'.format(filepath))\n-\n-    def _check_started(self):\n-        if not self._is_started:\n-            raise RuntimeError('tf_file_io_proxy is not started')\n-\n-    def start(self):\n-        \"\"\"Start mocking of `self.file_io_module` if real bucket not\n-        available for testing\"\"\"\n-        if self._is_started:\n-            raise RuntimeError('start called on already started tf_file_io_proxy')\n-        if self.mock_gcs:\n-            mock_module = Mock()\n-            mock_module.FileIO = self.FileIO\n-            mock_module.file_exists = self.file_exists\n-            mock_module.delete_file = self.delete_file\n-            patched_file_io = patch(self.file_io_module, new=mock_module)\n-            self.patched_file_io = patched_file_io\n-            self.patched_file_io.start()\n-        self._is_started = True\n-\n-    def stop(self):\n-        \"\"\"Stop mocking of `self.file_io_module` if real bucket not\n-        available for testing\"\"\"\n-        if not self._is_started:\n-            raise RuntimeError('stop called on unstarted tf_file_io_proxy')\n-        if self.mock_gcs:\n-            self.patched_file_io.stop()\n-        self._is_started = False\n-\n-    def __enter__(self):\n-        self.start()\n-        return self\n-\n-    def __exit__(self, exc_type, exc_val, exc_tb):\n-        self.stop()\n\n@@ -1,253 +1,4 @@\n \"\"\"Utilities related to model visualization.\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n \n-import os\n-from ..models import Model\n-from ..layers.wrappers import Wrapper\n-\n-# `pydot` is an optional dependency,\n-# see `extras_require` in `setup.py`.\n-try:\n-    import pydot\n-except ImportError:\n-    pydot = None\n-\n-\n-def _check_pydot():\n-    \"\"\"Raise errors if `pydot` or GraphViz unavailable.\"\"\"\n-    if pydot is None:\n-        raise ImportError(\n-            'Failed to import `pydot`. '\n-            'Please install `pydot`. '\n-            'For example with `pip install pydot`.')\n-    try:\n-        # Attempt to create an image of a blank graph\n-        # to check the pydot/graphviz installation.\n-        pydot.Dot.create(pydot.Dot())\n-    except OSError:\n-        raise OSError(\n-            '`pydot` failed to call GraphViz.'\n-            'Please install GraphViz (https://www.graphviz.org/) '\n-            'and ensure that its executables are in the $PATH.')\n-\n-\n-def is_model(layer):\n-    return isinstance(layer, Model)\n-\n-\n-def is_wrapped_model(layer):\n-    return isinstance(layer, Wrapper) and isinstance(layer.layer, Model)\n-\n-\n-def add_edge(dot, src, dst):\n-    if not dot.get_edge(src, dst):\n-        dot.add_edge(pydot.Edge(src, dst))\n-\n-\n-def model_to_dot(model,\n-                 show_shapes=False,\n-                 show_layer_names=True,\n-                 rankdir='TB',\n-                 expand_nested=False,\n-                 dpi=96,\n-                 subgraph=False):\n-    \"\"\"Convert a Keras model to dot format.\n-\n-    # Arguments\n-        model: A Keras model instance.\n-        show_shapes: whether to display shape information.\n-        show_layer_names: whether to display layer names.\n-        rankdir: `rankdir` argument passed to PyDot,\n-            a string specifying the format of the plot:\n-            'TB' creates a vertical plot;\n-            'LR' creates a horizontal plot.\n-        expand_nested: whether to expand nested models into clusters.\n-        dpi: dot DPI.\n-        subgraph: whether to return a pydot.Cluster instance.\n-\n-    # Returns\n-        A `pydot.Dot` instance representing the Keras model or\n-        a `pydot.Cluster` instance representing nested model if\n-        `subgraph=True`.\n-    \"\"\"\n-    from ..layers.wrappers import Wrapper\n-    from ..models import Model\n-    from ..models import Sequential\n-\n-    _check_pydot()\n-    if subgraph:\n-        dot = pydot.Cluster(style='dashed', graph_name=model.name)\n-        dot.set('label', model.name)\n-        dot.set('labeljust', 'l')\n-    else:\n-        dot = pydot.Dot()\n-        dot.set('rankdir', rankdir)\n-        dot.set('concentrate', True)\n-        dot.set('dpi', dpi)\n-        dot.set_node_defaults(shape='record')\n-\n-    sub_n_first_node = {}\n-    sub_n_last_node = {}\n-    sub_w_first_node = {}\n-    sub_w_last_node = {}\n-\n-    if isinstance(model, Sequential):\n-        if not model.built:\n-            model.build()\n-    layers = model._layers\n-\n-    # Create graph nodes.\n-    for i, layer in enumerate(layers):\n-        layer_id = str(id(layer))\n-\n-        # Append a wrapped layer's label to node's label, if it exists.\n-        layer_name = layer.name\n-        class_name = layer.__class__.__name__\n-\n-        if isinstance(layer, Wrapper):\n-            if expand_nested and isinstance(layer.layer, Model):\n-                submodel_wrapper = model_to_dot(layer.layer, show_shapes,\n-                                                show_layer_names, rankdir,\n-                                                expand_nested,\n-                                                subgraph=True)\n-                # sub_w : submodel_wrapper\n-                sub_w_nodes = submodel_wrapper.get_nodes()\n-                sub_w_first_node[layer.layer.name] = sub_w_nodes[0]\n-                sub_w_last_node[layer.layer.name] = sub_w_nodes[-1]\n-                dot.add_subgraph(submodel_wrapper)\n-            else:\n-                layer_name = '{}({})'.format(layer_name, layer.layer.name)\n-                child_class_name = layer.layer.__class__.__name__\n-                class_name = '{}({})'.format(class_name, child_class_name)\n-\n-        if expand_nested and isinstance(layer, Model):\n-            submodel_not_wrapper = model_to_dot(layer, show_shapes,\n-                                                show_layer_names, rankdir,\n-                                                expand_nested,\n-                                                subgraph=True)\n-            # sub_n : submodel_not_wrapper\n-            sub_n_nodes = submodel_not_wrapper.get_nodes()\n-            sub_n_first_node[layer.name] = sub_n_nodes[0]\n-            sub_n_last_node[layer.name] = sub_n_nodes[-1]\n-            dot.add_subgraph(submodel_not_wrapper)\n-\n-        # Create node's label.\n-        if show_layer_names:\n-            label = '{}: {}'.format(layer_name, class_name)\n-        else:\n-            label = class_name\n-\n-        # Rebuild the label as a table including input/output shapes.\n-        if show_shapes:\n-            try:\n-                outputlabels = str(layer.output_shape)\n-            except AttributeError:\n-                outputlabels = 'multiple'\n-            if hasattr(layer, 'input_shape'):\n-                inputlabels = str(layer.input_shape)\n-            elif hasattr(layer, 'input_shapes'):\n-                inputlabels = ', '.join(\n-                    (str(ishape) for ishape in layer.input_shapes))\n-            else:\n-                inputlabels = 'multiple'\n-            label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label,\n-                                                           inputlabels,\n-                                                           outputlabels)\n-\n-        if not expand_nested or not isinstance(layer, Model):\n-            node = pydot.Node(layer_id, label=label)\n-            dot.add_node(node)\n-\n-    # Connect nodes with edges.\n-    for layer in layers:\n-        layer_id = str(id(layer))\n-        for i, node in enumerate(layer._inbound_nodes):\n-            node_key = layer.name + '_ib-' + str(i)\n-            if node_key in model._network_nodes:\n-                for inbound_layer in node.inbound_layers:\n-                    inbound_layer_id = str(id(inbound_layer))\n-                    if not expand_nested:\n-                        assert dot.get_node(inbound_layer_id)\n-                        assert dot.get_node(layer_id)\n-                        dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n-                    else:\n-                        # if inbound_layer is not Model or wrapped Model\n-                        if not is_model(inbound_layer) and (\n-                                not is_wrapped_model(inbound_layer)):\n-                            # if current layer is not Model or wrapped Model\n-                            if not is_model(layer) and (\n-                                    not is_wrapped_model(layer)):\n-                                assert dot.get_node(inbound_layer_id)\n-                                assert dot.get_node(layer_id)\n-                                dot.add_edge(pydot.Edge(inbound_layer_id,\n-                                                        layer_id))\n-                            # if current layer is Model\n-                            elif is_model(layer):\n-                                add_edge(dot, inbound_layer_id,\n-                                         sub_n_first_node[layer.name].get_name())\n-                            # if current layer is wrapped Model\n-                            elif is_wrapped_model(layer):\n-                                dot.add_edge(pydot.Edge(inbound_layer_id,\n-                                                        layer_id))\n-                                name = sub_w_first_node[layer.layer.name].get_name()\n-                                dot.add_edge(pydot.Edge(layer_id,\n-                                                        name))\n-                        # if inbound_layer is Model\n-                        elif is_model(inbound_layer):\n-                            name = sub_n_last_node[inbound_layer.name].get_name()\n-                            if is_model(layer):\n-                                output_name = sub_n_first_node[layer.name].get_name()\n-                                add_edge(dot, name, output_name)\n-                            else:\n-                                add_edge(dot, name, layer_id)\n-                        # if inbound_layer is wrapped Model\n-                        elif is_wrapped_model(inbound_layer):\n-                            inbound_layer_name = inbound_layer.layer.name\n-                            add_edge(dot,\n-                                     sub_w_last_node[inbound_layer_name].get_name(),\n-                                     layer_id)\n-    return dot\n-\n-\n-def plot_model(model,\n-               to_file='model.png',\n-               show_shapes=False,\n-               show_layer_names=True,\n-               rankdir='TB',\n-               expand_nested=False,\n-               dpi=96):\n-    \"\"\"Converts a Keras model to dot format and save to a file.\n-\n-    # Arguments\n-        model: A Keras model instance\n-        to_file: File name of the plot image.\n-        show_shapes: whether to display shape information.\n-        show_layer_names: whether to display layer names.\n-        rankdir: `rankdir` argument passed to PyDot,\n-            a string specifying the format of the plot:\n-            'TB' creates a vertical plot;\n-            'LR' creates a horizontal plot.\n-        expand_nested: whether to expand nested models into clusters.\n-        dpi: dot DPI.\n-\n-    # Returns\n-        A Jupyter notebook Image object if Jupyter is installed.\n-        This enables in-line display of the model plots in notebooks.\n-    \"\"\"\n-    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n-                       expand_nested, dpi)\n-    _, extension = os.path.splitext(to_file)\n-    if not extension:\n-        extension = 'png'\n-    else:\n-        extension = extension[1:]\n-    dot.write(to_file, format=extension)\n-    # Return the image as a Jupyter Image object, to be displayed in-line.\n-    if extension != 'pdf':\n-        try:\n-            from IPython import display\n-            return display.Image(filename=to_file)\n-        except ImportError:\n-            pass\n+from tensorflow.keras.utils import model_to_dot\n+from tensorflow.keras.utils import plot_model\n\n@@ -1,3 +1 @@\n-from __future__ import absolute_import\r\n-\r\n from . import scikit_learn\r\n\n@@ -1,347 +1,2 @@\n-\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\n-\"\"\"\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import copy\n-import types\n-\n-import numpy as np\n-\n-from .. import losses\n-from ..utils.np_utils import to_categorical\n-from ..utils.generic_utils import has_arg\n-from ..utils.generic_utils import to_list\n-from ..models import Sequential\n-\n-\n-class BaseWrapper(object):\n-    \"\"\"Base class for the Keras scikit-learn wrapper.\n-\n-    Warning: This class should not be used directly.\n-    Use descendant classes instead.\n-\n-    # Arguments\n-        build_fn: callable function or class instance\n-        **sk_params: model parameters & fitting parameters\n-\n-    The `build_fn` should construct, compile and return a Keras model, which\n-    will then be used to fit/predict. One of the following\n-    three values could be passed to `build_fn`:\n-    1. A function\n-    2. An instance of a class that implements the `__call__` method\n-    3. None. This means you implement a class that inherits from either\n-    `KerasClassifier` or `KerasRegressor`. The `__call__` method of the\n-    present class will then be treated as the default `build_fn`.\n-\n-    `sk_params` takes both model parameters and fitting parameters. Legal model\n-    parameters are the arguments of `build_fn`. Note that like all other\n-    estimators in scikit-learn, `build_fn` should provide default values for\n-    its arguments, so that you could create the estimator without passing any\n-    values to `sk_params`.\n-\n-    `sk_params` could also accept parameters for calling `fit`, `predict`,\n-    `predict_proba`, and `score` methods (e.g., `epochs`, `batch_size`).\n-    fitting (predicting) parameters are selected in the following order:\n-\n-    1. Values passed to the dictionary arguments of\n-    `fit`, `predict`, `predict_proba`, and `score` methods\n-    2. Values passed to `sk_params`\n-    3. The default values of the `keras.models.Sequential`\n-    `fit`, `predict`, `predict_proba` and `score` methods\n-\n-    When using scikit-learn's `grid_search` API, legal tunable parameters are\n-    those you could pass to `sk_params`, including fitting parameters.\n-    In other words, you could use `grid_search` to search for the best\n-    `batch_size` or `epochs` as well as the model parameters.\n-    \"\"\"\n-\n-    def __init__(self, build_fn=None, **sk_params):\n-        self.build_fn = build_fn\n-        self.sk_params = sk_params\n-        self.check_params(sk_params)\n-\n-    def check_params(self, params):\n-        \"\"\"Checks for user typos in `params`.\n-\n-        # Arguments\n-            params: dictionary; the parameters to be checked\n-\n-        # Raises\n-            ValueError: if any member of `params` is not a valid argument.\n-        \"\"\"\n-        legal_params_fns = [Sequential.fit, Sequential.predict,\n-                            Sequential.predict_classes, Sequential.evaluate]\n-        if self.build_fn is None:\n-            legal_params_fns.append(self.__call__)\n-        elif (not isinstance(self.build_fn, types.FunctionType) and\n-              not isinstance(self.build_fn, types.MethodType)):\n-            legal_params_fns.append(self.build_fn.__call__)\n-        else:\n-            legal_params_fns.append(self.build_fn)\n-\n-        for params_name in params:\n-            for fn in legal_params_fns:\n-                if has_arg(fn, params_name):\n-                    break\n-            else:\n-                if params_name != 'nb_epoch':\n-                    raise ValueError(\n-                        '{} is not a legal parameter'.format(params_name))\n-\n-    def get_params(self, **params):\n-        \"\"\"Gets parameters for this estimator.\n-\n-        # Arguments\n-            **params: ignored (exists for API compatibility).\n-\n-        # Returns\n-            Dictionary of parameter names mapped to their values.\n-        \"\"\"\n-        res = copy.deepcopy(self.sk_params)\n-        res.update({'build_fn': self.build_fn})\n-        return res\n-\n-    def set_params(self, **params):\n-        \"\"\"Sets the parameters of this estimator.\n-\n-        # Arguments\n-            **params: Dictionary of parameter names mapped to their values.\n-\n-        # Returns\n-            self\n-        \"\"\"\n-        self.check_params(params)\n-        self.sk_params.update(params)\n-        return self\n-\n-    def fit(self, x, y, **kwargs):\n-        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n-\n-        # Arguments\n-            x : array-like, shape `(n_samples, n_features)`\n-                Training samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for `x`.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.fit`\n-\n-        # Returns\n-            history : object\n-                details about the training history at each epoch.\n-        \"\"\"\n-        if self.build_fn is None:\n-            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n-        elif (not isinstance(self.build_fn, types.FunctionType) and\n-              not isinstance(self.build_fn, types.MethodType)):\n-            self.model = self.build_fn(\n-                **self.filter_sk_params(self.build_fn.__call__))\n-        else:\n-            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n-\n-        if (losses.is_categorical_crossentropy(self.model.loss) and\n-                len(y.shape) != 2):\n-            y = to_categorical(y)\n-\n-        fit_args = copy.deepcopy(self.filter_sk_params(Sequential.fit))\n-        fit_args.update(kwargs)\n-\n-        history = self.model.fit(x, y, **fit_args)\n-\n-        return history\n-\n-    def filter_sk_params(self, fn, override=None):\n-        \"\"\"Filters `sk_params` and returns those in `fn`'s arguments.\n-\n-        # Arguments\n-            fn : arbitrary function\n-            override: dictionary, values to override `sk_params`\n-\n-        # Returns\n-            res : dictionary containing variables\n-                in both `sk_params` and `fn`'s arguments.\n-        \"\"\"\n-        override = override or {}\n-        res = {}\n-        for name, value in self.sk_params.items():\n-            if has_arg(fn, name):\n-                res.update({name: value})\n-        res.update(override)\n-        return res\n-\n-\n-class KerasClassifier(BaseWrapper):\n-    \"\"\"Implementation of the scikit-learn classifier API for Keras.\n-    \"\"\"\n-\n-    def fit(self, x, y, sample_weight=None, **kwargs):\n-        \"\"\"Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n-\n-        # Arguments\n-            x : array-like, shape `(n_samples, n_features)`\n-                Training samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            y : array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for `x`.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.fit`\n-\n-        # Returns\n-            history : object\n-                details about the training history at each epoch.\n-\n-        # Raises\n-            ValueError: In case of invalid shape for `y` argument.\n-        \"\"\"\n-        y = np.array(y)\n-        if len(y.shape) == 2 and y.shape[1] > 1:\n-            self.classes_ = np.arange(y.shape[1])\n-        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n-            self.classes_ = np.unique(y)\n-            y = np.searchsorted(self.classes_, y)\n-        else:\n-            raise ValueError('Invalid shape for y: ' + str(y.shape))\n-        self.n_classes_ = len(self.classes_)\n-        if sample_weight is not None:\n-            kwargs['sample_weight'] = sample_weight\n-        return super(KerasClassifier, self).fit(x, y, **kwargs)\n-\n-    def predict(self, x, **kwargs):\n-        \"\"\"Returns the class predictions for the given test data.\n-\n-        # Arguments\n-            x: array-like, shape `(n_samples, n_features)`\n-                Test samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments\n-                of `Sequential.predict_classes`.\n-\n-        # Returns\n-            preds: array-like, shape `(n_samples,)`\n-                Class predictions.\n-        \"\"\"\n-        kwargs = self.filter_sk_params(Sequential.predict_classes, kwargs)\n-\n-        proba = self.model.predict(x, **kwargs)\n-        if proba.shape[-1] > 1:\n-            classes = proba.argmax(axis=-1)\n-        else:\n-            classes = (proba > 0.5).astype('int32')\n-        return self.classes_[classes]\n-\n-    def predict_proba(self, x, **kwargs):\n-        \"\"\"Returns class probability estimates for the given test data.\n-\n-        # Arguments\n-            x: array-like, shape `(n_samples, n_features)`\n-                Test samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments\n-                of `Sequential.predict_classes`.\n-\n-        # Returns\n-            proba: array-like, shape `(n_samples, n_outputs)`\n-                Class probability estimates.\n-                In the case of binary classification,\n-                to match the scikit-learn API,\n-                will return an array of shape `(n_samples, 2)`\n-                (instead of `(n_sample, 1)` as in Keras).\n-        \"\"\"\n-        kwargs = self.filter_sk_params(Sequential.predict_proba, kwargs)\n-        probs = self.model.predict(x, **kwargs)\n-\n-        # check if binary classification\n-        if probs.shape[1] == 1:\n-            # first column is probability of class 0 and second is of class 1\n-            probs = np.hstack([1 - probs, probs])\n-        return probs\n-\n-    def score(self, x, y, **kwargs):\n-        \"\"\"Returns the mean accuracy on the given test data and labels.\n-\n-        # Arguments\n-            x: array-like, shape `(n_samples, n_features)`\n-                Test samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            y: array-like, shape `(n_samples,)` or `(n_samples, n_outputs)`\n-                True labels for `x`.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.evaluate`.\n-\n-        # Returns\n-            score: float\n-                Mean accuracy of predictions on `x` wrt. `y`.\n-\n-        # Raises\n-            ValueError: If the underlying model isn't configured to\n-                compute accuracy. You should pass `metrics=[\"accuracy\"]` to\n-                the `.compile()` method of the model.\n-        \"\"\"\n-        y = np.searchsorted(self.classes_, y)\n-        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n-\n-        loss_name = self.model.loss\n-        if hasattr(loss_name, '__name__'):\n-            loss_name = loss_name.__name__\n-        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n-            y = to_categorical(y)\n-\n-        outputs = self.model.evaluate(x, y, **kwargs)\n-        outputs = to_list(outputs)\n-        for name, output in zip(self.model.metrics_names, outputs):\n-            if name in ['accuracy', 'acc']:\n-                return output\n-        raise ValueError('The model is not configured to compute accuracy. '\n-                         'You should pass `metrics=[\"accuracy\"]` to '\n-                         'the `model.compile()` method.')\n-\n-\n-class KerasRegressor(BaseWrapper):\n-    \"\"\"Implementation of the scikit-learn regressor API for Keras.\n-    \"\"\"\n-\n-    def predict(self, x, **kwargs):\n-        \"\"\"Returns predictions for the given test data.\n-\n-        # Arguments\n-            x: array-like, shape `(n_samples, n_features)`\n-                Test samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.predict`.\n-\n-        # Returns\n-            preds: array-like, shape `(n_samples,)`\n-                Predictions.\n-        \"\"\"\n-        kwargs = self.filter_sk_params(Sequential.predict, kwargs)\n-        preds = np.array(self.model.predict(x, **kwargs))\n-        if preds.shape[-1] == 1:\n-            return np.squeeze(preds, axis=-1)\n-        return preds\n-\n-    def score(self, x, y, **kwargs):\n-        \"\"\"Returns the mean loss on the given test data and labels.\n-\n-        # Arguments\n-            x: array-like, shape `(n_samples, n_features)`\n-                Test samples where `n_samples` is the number of samples\n-                and `n_features` is the number of features.\n-            y: array-like, shape `(n_samples,)`\n-                True labels for `x`.\n-            **kwargs: dictionary arguments\n-                Legal arguments are the arguments of `Sequential.evaluate`.\n-\n-        # Returns\n-            score: float\n-                Mean accuracy of predictions on `x` wrt. `y`.\n-        \"\"\"\n-        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n-        loss = self.model.evaluate(x, y, **kwargs)\n-        if isinstance(loss, list):\n-            return -loss[0]\n-        return -loss\n+\"\"\"Wrapper for using the Scikit-Learn API with Keras models.\"\"\"\n+from tensorflow.keras.wrappers.scikit_learn import *\n\n@@ -24,7 +24,7 @@ and is distributed under the MIT license.\n '''\n \n setup(name='Keras',\n-      version='2.3.1',\n+      version='2.4.0',\n       description='Deep Learning for humans',\n       long_description=long_description,\n       author='Francois Chollet',\n@@ -32,13 +32,11 @@ setup(name='Keras',\n       url='https://github.com/keras-team/keras',\n       download_url='https://github.com/keras-team/keras/tarball/2.3.0',\n       license='MIT',\n-      install_requires=['numpy>=1.9.1',\n+      install_requires=['tensorflow>=2.2.0',\n+                        'numpy>=1.9.1',\n                         'scipy>=0.14',\n-                        'six>=1.9.0',\n                         'pyyaml',\n-                        'h5py',\n-                        'keras_applications>=1.0.6',\n-                        'keras_preprocessing>=1.0.5'],\n+                        'h5py'],\n       extras_require={\n           'visualize': ['pydot>=1.2.4'],\n           'tests': ['pytest',\n\n@@ -1,422 +0,0 @@\n-import os\n-from markdown import markdown\n-from docs import autogen\n-import pytest\n-from keras import backend as K\n-\n-\n-if K.backend() != 'tensorflow':\n-    pytestmark = pytest.mark.skip\n-\n-\n-test_doc1 = {\n-    'doc': \"\"\"Base class for recurrent layers.\n-\n-    # Arguments\n-        cell: A RNN cell instance. A RNN cell is a class that has:\n-            - a `call(input_at_t, states_at_t)` method, returning\n-                `(output_at_t, states_at_t_plus_1)`. The call method of the\n-                cell can also take the optional argument `constants`, see\n-                section \"Note on passing external constants\" below.\n-            - a `state_size` attribute. This can be a single integer\n-                (single state) in which case it is\n-                the size of the recurrent state\n-                (which should be the same as the size of the cell output).\n-                This can also be a list/tuple of integers\n-                (one size per state). In this case, the first entry\n-                (`state_size[0]`) should be the same as\n-                the size of the cell output.\n-            It is also possible for `cell` to be a list of RNN cell instances,\n-            in which cases the cells get stacked on after the other in the RNN,\n-            implementing an efficient stacked RNN.\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-        go_backwards: Boolean (default False).\n-            If True, process the input sequence backwards and return the\n-            reversed sequence.\n-        stateful: Boolean (default False). If True, the last state\n-            for each sample at index i in a batch will be used as initial\n-            state for the sample of index i in the following batch.\n-        unroll: Boolean (default False).\n-            If True, the network will be unrolled,\n-            else a symbolic loop will be used.\n-            Unrolling can speed-up a RNN,\n-            although it tends to be more memory-intensive.\n-            Unrolling is only suitable for short sequences.\n-        input_dim: dimensionality of the input (integer).\n-            This argument (or alternatively,\n-            the keyword argument `input_shape`)\n-            is required when using this layer as the first layer in a model.\n-        input_length: Length of input sequences, to be specified\n-            when it is constant.\n-            This argument is required if you are going to connect\n-            `Flatten` then `Dense` layers upstream\n-            (without it, the shape of the dense outputs cannot be computed).\n-            Note that if the recurrent layer is not the first layer\n-            in your model, you would need to specify the input length\n-            at the level of the first layer\n-            (e.g. via the `input_shape` argument)\n-\n-    # Input shape\n-        3D tensor with shape `(batch_size, timesteps, input_dim)`.\n-\n-    # Output shape\n-        - if `return_state`: a list of tensors. The first tensor is\n-            the output. The remaining tensors are the last states,\n-            each with shape `(batch_size, units)`.\n-        - if `return_sequences`: 3D tensor with shape\n-            `(batch_size, timesteps, units)`.\n-        - else, 2D tensor with shape `(batch_size, units)`.\n-\n-    # Masking\n-        This layer supports masking for input data with a variable number\n-        of timesteps. To introduce masks to your data,\n-        use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-        set to `True`.\n-\n-    # Note on using statefulness in RNNs\n-        You can set RNN layers to be 'stateful', which means that the states\n-        computed for the samples in one batch will be reused as initial states\n-        for the samples in the next batch. This assumes a one-to-one mapping\n-        between samples in different successive batches.\n-\n-        To enable statefulness:\n-            - specify `stateful=True` in the layer constructor.\n-            - specify a fixed batch size for your model, by passing\n-                if sequential model:\n-                  `batch_input_shape=(...)` to the first layer in your model.\n-                else for functional model with 1 or more Input layers:\n-                  `batch_shape=(...)` to all the first layers in your model.\n-                This is the expected shape of your inputs\n-                *including the batch size*.\n-                It should be a tuple of integers, e.g. `(32, 10, 100)`.\n-            - specify `shuffle=False` when calling fit().\n-\n-        To reset the states of your model, call `.reset_states()` on either\n-        a specific layer, or on your entire model.\n-\n-    # Note on specifying the initial state of RNNs\n-    Note: that\n-        One: You can specify the initial state of RNN layers symbolically by\n-            calling them with the keyword argument `initial_state`.\n-        Two: The value of `initial_state` should be a tensor or list of\n-            tensors representing\n-            the initial state of the RNN layer.\n-        You can specify the initial state of RNN layers numerically by:\n-        One: calling `reset_states`\n-            - With the keyword argument `states`.\n-                - The value of\n-            `states` should be a numpy array or\n-            list of numpy arrays representing\n-        the initial state of the RNN layer.\n-\n-    # Note on passing external constants to RNNs\n-        You can pass \"external\" constants to the cell using the `constants`\n-        keyword: argument of `RNN.__call__` (as well as `RNN.call`) method.\n-        This: requires that the `cell.call` method accepts the same keyword argument\n-        `constants`. Such constants can be used to condition the cell\n-        transformation on additional static inputs (not changing over time),\n-        a.k.a. an attention mechanism.\n-\n-    # Examples\n-\n-    ```python\n-        # First, let's define a RNN Cell, as a layer subclass.\n-\n-        class MinimalRNNCell(keras.layers.Layer):\n-\n-            def __init__(self, units, **kwargs):\n-                self.units = units\n-                self.state_size = units\n-                super(MinimalRNNCell, self).__init__(**kwargs)\n-\n-            def build(self, input_shape):\n-                self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n-                                              initializer='uniform',\n-                                              name='kernel')\n-                self.recurrent_kernel = self.add_weight(\n-                    shape=(self.units, self.units),\n-                    initializer='uniform',\n-                    name='recurrent_kernel')\n-                self.built = True\n-\n-            def call(self, inputs, states):\n-                prev_output = states[0]\n-                h = K.dot(inputs, self.kernel)\n-                output = h + K.dot(prev_output, self.recurrent_kernel)\n-                return output, [output]\n-\n-        # Let's use this cell in a RNN layer:\n-\n-        cell = MinimalRNNCell(32)\n-        x = keras.Input((None, 5))\n-        layer = RNN(cell)\n-        y = layer(x)\n-\n-        # Here's how to use the cell to build a stacked RNN:\n-\n-        cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n-        x = keras.Input((None, 5))\n-        layer = RNN(cells)\n-        y = layer(x)\n-    ```\n-    \"\"\",\n-    'result': '''Base class for recurrent layers.\n-\n-__Arguments__\n-\n-- __cell__: A RNN cell instance. A RNN cell is a class that has:\n-    - a `call(input_at_t, states_at_t)` method, returning\n-        `(output_at_t, states_at_t_plus_1)`. The call method of the\n-        cell can also take the optional argument `constants`, see\n-        section \"Note on passing external constants\" below.\n-    - a `state_size` attribute. This can be a single integer\n-        (single state) in which case it is\n-        the size of the recurrent state\n-        (which should be the same as the size of the cell output).\n-        This can also be a list/tuple of integers\n-        (one size per state). In this case, the first entry\n-        (`state_size[0]`) should be the same as\n-        the size of the cell output.\n-\n-    It is also possible for `cell` to be a list of RNN cell instances,\n-    in which cases the cells get stacked on after the other in the RNN,\n-    implementing an efficient stacked RNN.\n-\n-- __return_sequences__: Boolean. Whether to return the last output\n-    in the output sequence, or the full sequence.\n-- __return_state__: Boolean. Whether to return the last state\n-    in addition to the output.\n-- __go_backwards__: Boolean (default False).\n-    If True, process the input sequence backwards and return the\n-    reversed sequence.\n-- __stateful__: Boolean (default False). If True, the last state\n-    for each sample at index i in a batch will be used as initial\n-    state for the sample of index i in the following batch.\n-- __unroll__: Boolean (default False).\n-    If True, the network will be unrolled,\n-    else a symbolic loop will be used.\n-    Unrolling can speed-up a RNN,\n-    although it tends to be more memory-intensive.\n-    Unrolling is only suitable for short sequences.\n-- __input_dim__: dimensionality of the input (integer).\n-    This argument (or alternatively,\n-    the keyword argument `input_shape`)\n-    is required when using this layer as the first layer in a model.\n-- __input_length__: Length of input sequences, to be specified\n-    when it is constant.\n-    This argument is required if you are going to connect\n-    `Flatten` then `Dense` layers upstream\n-    (without it, the shape of the dense outputs cannot be computed).\n-    Note that if the recurrent layer is not the first layer\n-    in your model, you would need to specify the input length\n-    at the level of the first layer\n-    (e.g. via the `input_shape` argument)\n-\n-__Input shape__\n-\n-3D tensor with shape `(batch_size, timesteps, input_dim)`.\n-\n-__Output shape__\n-\n-- if `return_state`: a list of tensors. The first tensor is\n-    the output. The remaining tensors are the last states,\n-    each with shape `(batch_size, units)`.\n-- if `return_sequences`: 3D tensor with shape\n-    `(batch_size, timesteps, units)`.\n-- else, 2D tensor with shape `(batch_size, units)`.\n-\n-__Masking__\n-\n-This layer supports masking for input data with a variable number\n-of timesteps. To introduce masks to your data,\n-use an [Embedding](embeddings.md) layer with the `mask_zero` parameter\n-set to `True`.\n-\n-__Note on using statefulness in RNNs__\n-\n-You can set RNN layers to be 'stateful', which means that the states\n-computed for the samples in one batch will be reused as initial states\n-for the samples in the next batch. This assumes a one-to-one mapping\n-between samples in different successive batches.\n-\n-To enable statefulness:\n-- specify `stateful=True` in the layer constructor.\n-- specify a fixed batch size for your model, by passing\n-if sequential model:\n-`batch_input_shape=(...)` to the first layer in your model.\n-else for functional model with 1 or more Input layers:\n-`batch_shape=(...)` to all the first layers in your model.\n-This is the expected shape of your inputs\n-*including the batch size*.\n-It should be a tuple of integers, e.g. `(32, 10, 100)`.\n-- specify `shuffle=False` when calling fit().\n-\n-To reset the states of your model, call `.reset_states()` on either\n-a specific layer, or on your entire model.\n-\n-__Note on specifying the initial state of RNNs__\n-\n-Note: that\n-- __One__: You can specify the initial state of RNN layers symbolically by\n-    calling them with the keyword argument `initial_state`.\n-- __Two__: The value of `initial_state` should be a tensor or list of\n-    tensors representing\n-    the initial state of the RNN layer.\n-\n-You can specify the initial state of RNN layers numerically by:\n-\n-- __One__: calling `reset_states`\n-    - With the keyword argument `states`.\n-        - The value of\n-\n-    `states` should be a numpy array or\n-    list of numpy arrays representing\n-\n-the initial state of the RNN layer.\n-\n-__Note on passing external constants to RNNs__\n-\n-You can pass \"external\" constants to the cell using the `constants`\n-- __keyword__: argument of `RNN.__call__` (as well as `RNN.call`) method.\n-- __This__: requires that the `cell.call` method accepts the same keyword argument\n-\n-`constants`. Such constants can be used to condition the cell\n-transformation on additional static inputs (not changing over time),\n-a.k.a. an attention mechanism.\n-\n-__Examples__\n-\n-\n-```python\n-# First, let's define a RNN Cell, as a layer subclass.\n-\n-class MinimalRNNCell(keras.layers.Layer):\n-\n-    def __init__(self, units, **kwargs):\n-        self.units = units\n-        self.state_size = units\n-        super(MinimalRNNCell, self).__init__(**kwargs)\n-\n-    def build(self, input_shape):\n-        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n-                                      initializer='uniform',\n-                                      name='kernel')\n-        self.recurrent_kernel = self.add_weight(\n-            shape=(self.units, self.units),\n-            initializer='uniform',\n-            name='recurrent_kernel')\n-        self.built = True\n-\n-    def call(self, inputs, states):\n-        prev_output = states[0]\n-        h = K.dot(inputs, self.kernel)\n-        output = h + K.dot(prev_output, self.recurrent_kernel)\n-        return output, [output]\n-\n-# Let's use this cell in a RNN layer:\n-\n-cell = MinimalRNNCell(32)\n-x = keras.Input((None, 5))\n-layer = RNN(cell)\n-y = layer(x)\n-\n-# Here's how to use the cell to build a stacked RNN:\n-\n-cells = [MinimalRNNCell(32), MinimalRNNCell(64)]\n-x = keras.Input((None, 5))\n-layer = RNN(cells)\n-y = layer(x)\n-```\n-'''}\n-\n-\n-test_doc_with_arguments_as_last_block = {\n-    'doc': \"\"\"Base class for recurrent layers.\n-\n-    # Arguments\n-        return_sequences: Boolean. Whether to return the last output\n-            in the output sequence, or the full sequence.\n-        return_state: Boolean. Whether to return the last state\n-            in addition to the output.\n-    \"\"\",\n-    'result': '''Base class for recurrent layers.\n-\n-__Arguments__\n-\n-- __return_sequences__: Boolean. Whether to return the last output\n-    in the output sequence, or the full sequence.\n-- __return_state__: Boolean. Whether to return the last state\n-    in addition to the output.\n-'''}\n-\n-\n-@pytest.mark.parametrize('docs_descriptor', [\n-    test_doc1,\n-    test_doc_with_arguments_as_last_block,\n-])\n-def test_doc_lists(docs_descriptor):\n-    docstring = autogen.process_docstring(docs_descriptor['doc'])\n-    assert markdown(docstring) == markdown(docs_descriptor['result'])\n-\n-\n-dummy_docstring = \"\"\"Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n-\n-    When attempting to multiply a nD tensor\n-    with a nD tensor, it reproduces the Theano behavior.\n-    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n-\n-    # Examples\n-    ```python\n-        # Theano-like behavior example\n-        >>> x = K.random_uniform_variable(shape=(2, 3), low=0, high=1)\n-        >>> y = K.ones((4, 3, 5))\n-        >>> xy = K.dot(x, y)\n-        >>> K.int_shape(xy)\n-        (2, 4, 5)\n-    ```\n-\n-    # Numpy implementation\n-    ```python\n-        def dot(x, y):\n-            return dot(x, y)\n-    ```\n-    \"\"\"\n-\n-\n-def test_doc_multiple_sections_code():\n-    \"\"\" Checks that we can have code blocks in multiple sections.\"\"\"\n-    generated = autogen.process_docstring(dummy_docstring)\n-    assert '# Theano-like behavior example' in generated\n-    assert 'def dot(x, y):' in generated\n-\n-\n-def test_docs_in_custom_destination_dir(tmpdir):\n-    autogen.generate(tmpdir)\n-    assert os.path.isdir(os.path.join(tmpdir, 'layers'))\n-    assert os.path.isdir(os.path.join(tmpdir, 'models'))\n-    assert os.path.isdir(os.path.join(tmpdir, 'examples'))\n-    assert os.listdir(os.path.join(tmpdir, 'examples'))\n-\n-\n-def test_module_name():\n-    for page in autogen.PAGES:\n-        list_of_classes = autogen.read_page_data(page, 'classes')\n-        for element in list_of_classes:\n-            if isinstance(element, (list, tuple)):\n-                cls = element[0]\n-            else:\n-                cls = element\n-            signature = autogen.get_class_signature(cls)\n-            assert signature.startswith('keras.')\n-\n-        list_of_functions = autogen.read_page_data(page, 'functions')\n-        for function_ in list_of_functions:\n-            signature = autogen.get_function_signature(function_)\n-            assert signature.startswith('keras.')\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -1,180 +0,0 @@\n-import importlib\n-import inspect\n-import re\n-import sys\n-from itertools import compress\n-from keras import backend as K\n-\n-import pytest\n-\n-if K.backend() != 'tensorflow':\n-    pytestmark = pytest.mark.skip\n-\n-modules = ['keras.layers', 'keras.models', 'keras',\n-           'keras.backend', 'keras.engine',\n-           'keras.wrappers', 'keras.utils',\n-           'keras.callbacks', 'keras.activations',\n-           'keras.losses', 'keras.models', 'keras.optimizers']\n-accepted_name = ['from_config']\n-accepted_module = ['keras.legacy.layers', 'keras.utils.generic_utils']\n-\n-# Functions or classes with less than 'MIN_CODE_SIZE' lines can be ignored\n-MIN_CODE_SIZE = 15\n-\n-\n-def handle_class_init(name, member):\n-    init_args = [\n-        arg for arg in list(inspect.signature(member.__init__).parameters.keys())\n-        if arg not in ['self', 'args', 'kwargs']\n-    ]\n-    assert_args_presence(init_args, member.__doc__, member, name)\n-\n-\n-def handle_class(name, member):\n-    if is_accepted(name, member):\n-        return\n-\n-    if member.__doc__ is None and not member_too_small(member):\n-        raise ValueError(\"{} class doesn't have any documentation\".format(name),\n-                         member.__module__, inspect.getmodule(member).__file__)\n-\n-    handle_class_init(name, member)\n-\n-    for n, met in inspect.getmembers(member):\n-        if inspect.ismethod(met):\n-            handle_method(n, met)\n-\n-\n-def handle_function(name, member):\n-    if name.startswith('_'):\n-        return\n-    if is_accepted(name, member) or member_too_small(member):\n-        # We don't need to check this one.\n-        return\n-    doc = member.__doc__\n-    if doc is None:\n-        raise ValueError(\"{} function doesn't have any documentation\".format(name),\n-                         member.__module__, inspect.getmodule(member).__file__)\n-\n-    args = list(inspect.signature(member).parameters.keys())\n-    assert_args_presence(args, doc, member, name)\n-    assert_function_style(name, member, doc, args)\n-    assert_doc_style(name, member, doc)\n-\n-\n-def assert_doc_style(name, member, doc):\n-    lines = doc.split(\"\\n\")\n-    first_line = lines[0]\n-    if len(first_line.strip()) == 0:\n-        raise ValueError(\n-            \"{} the documentation should be on the first line.\".format(name),\n-            member.__module__)\n-    if first_line.strip()[-1] != '.':\n-        raise ValueError(\"{} first line should end with a '.'\".format(name),\n-                         member.__module__)\n-\n-\n-def assert_function_style(name, member, doc, args):\n-    code = inspect.getsource(member)\n-    has_return = re.findall(r\"\\s*return \\S+\", code, re.MULTILINE)\n-    if has_return and \"# Returns\" not in doc:\n-        innerfunction = [inspect.getsource(x) for x in member.__code__.co_consts if\n-                         inspect.iscode(x)]\n-        return_in_sub = [ret for code_inner in innerfunction for ret in\n-                         re.findall(r\"\\s*return \\S+\", code_inner, re.MULTILINE)]\n-        if len(return_in_sub) < len(has_return):\n-            raise ValueError(\"{} needs a '# Returns' section\".format(name),\n-                             member.__module__)\n-\n-    has_raise = re.findall(r\"^\\s*raise \\S+\", code, re.MULTILINE)\n-    if has_raise and \"# Raises\" not in doc:\n-        innerfunction = [inspect.getsource(x) for x in member.__code__.co_consts if\n-                         inspect.iscode(x)]\n-        raise_in_sub = [ret for code_inner in innerfunction for ret in\n-                        re.findall(r\"\\s*raise \\S+\", code_inner, re.MULTILINE)]\n-        if len(raise_in_sub) < len(has_raise):\n-            raise ValueError(\"{} needs a '# Raises' section\".format(name),\n-                             member.__module__)\n-\n-    if len(args) > 0 and \"# Arguments\" not in doc:\n-        raise ValueError(\"{} needs a '# Arguments' section\".format(name),\n-                         member.__module__)\n-\n-    assert_blank_before(name, member, doc, ['# Arguments', '# Raises', '# Returns'])\n-\n-\n-def assert_blank_before(name, member, doc, keywords):\n-    doc_lines = [x.strip() for x in doc.split('\\n')]\n-    for keyword in keywords:\n-        if keyword in doc_lines:\n-            index = doc_lines.index(keyword)\n-            if doc_lines[index - 1] != '':\n-                raise ValueError(\n-                    \"{} '{}' should have a blank line above.\".format(name, keyword),\n-                    member.__module__)\n-\n-\n-def is_accepted(name, member):\n-    if 'keras' not in str(member.__module__):\n-        return True\n-    return name in accepted_name or member.__module__ in accepted_module\n-\n-\n-def member_too_small(member):\n-    code = inspect.getsource(member).split('\\n')\n-    return len(code) < MIN_CODE_SIZE\n-\n-\n-def assert_args_presence(args, doc, member, name):\n-    if not doc:\n-        raise ValueError('{} needs a docstring.'.format(name),\n-                         member.__module__)\n-    args_not_in_doc = [arg not in doc for arg in args]\n-    if any(args_not_in_doc):\n-        raise ValueError(\n-            \"{} {} arguments are not present in documentation \".format(name, list(\n-                compress(args, args_not_in_doc))), member.__module__)\n-    words = doc.replace('*', '').split()\n-    # Check arguments styling\n-    styles = [arg + \":\" not in words for arg in args]\n-    if any(styles):\n-        raise ValueError(\n-            \"{} {} are not style properly 'argument': documentation\".format(\n-                name,\n-                list(compress(args, styles))),\n-            member.__module__)\n-\n-    # Check arguments order\n-    indexes = [words.index(arg + \":\") for arg in args]\n-    if indexes != sorted(indexes):\n-        raise ValueError(\n-            \"{} arguments order is different from the documentation\".format(name),\n-            member.__module__)\n-\n-\n-def handle_method(name, member):\n-    if name in accepted_name or member.__module__ in accepted_module:\n-        return\n-    handle_function(name, member)\n-\n-\n-def handle_module(mod):\n-    for name, mem in inspect.getmembers(mod):\n-        if inspect.isclass(mem):\n-            handle_class(name, mem)\n-        elif inspect.isfunction(mem):\n-            handle_function(name, mem)\n-        elif 'keras' in name and inspect.ismodule(mem):\n-            # Only test keras' modules\n-            handle_module(mem)\n-\n-\n-@pytest.mark.skipif(sys.version_info < (3, 3), reason=\"requires python3.3\")\n-def test_doc():\n-    for module in modules:\n-        mod = importlib.import_module(module)\n-        handle_module(mod)\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -8,7 +8,6 @@ import pytest\n from keras.preprocessing.sequence import pad_sequences\n from keras.preprocessing.sequence import make_sampling_table\n from keras.preprocessing.sequence import skipgrams\n-from keras.preprocessing.sequence import _remove_long_seq\n from keras.preprocessing.sequence import TimeseriesGenerator\n \n \n@@ -86,18 +85,6 @@ def test_skipgrams():\n         assert len(l) == 2\n \n \n-def test_remove_long_seq():\n-    maxlen = 5\n-    seq = [\n-        [1, 2, 3],\n-        [1, 2, 3, 4, 5, 6],\n-    ]\n-    label = ['a', 'b']\n-    new_seq, new_label = _remove_long_seq(maxlen, seq, label)\n-    assert new_seq == [[1, 2, 3]]\n-    assert new_label == ['a']\n-\n-\n def test_TimeseriesGenerator():\n     data = np.array([[i] for i in range(50)])\n     targets = np.array([[i] for i in range(50)])\n\n@@ -34,10 +34,10 @@ def test_image_classification():\n                   optimizer='rmsprop',\n                   metrics=['accuracy'])\n     model.summary()\n-    history = model.fit(x_train, y_train, epochs=12, batch_size=16,\n+    history = model.fit(x_train, y_train, epochs=15, batch_size=16,\n                         validation_data=(x_test, y_test),\n                         verbose=0)\n-    assert history.history['val_accuracy'][-1] > 0.75\n+    assert history.history['val_accuracy'][-1] > 0.6\n     config = model.get_config()\n     model = Sequential.from_config(config)\n \n@@ -72,7 +72,7 @@ def test_image_data_generator_training():\n                                   validation_data=img_gen.flow(x_test, y_test,\n                                                                batch_size=16),\n                                   verbose=0)\n-    assert history.history['val_accuracy'][-1] > 0.70\n+    assert history.history['val_accuracy'][-1] > 0.6\n     model.evaluate_generator(img_gen.flow(x_train, y_train, batch_size=16))\n \n \n\n@@ -69,7 +69,7 @@ def test_temporal_classification_functional():\n     history = model.fit(x_train, y_train, epochs=5, batch_size=10,\n                         validation_data=(x_test, y_test),\n                         verbose=0)\n-    assert(history.history['accuracy'][-1] >= 0.75)\n+    assert(history.history['accuracy'][-1] >= 0.6)\n \n \n def test_temporal_regression():\n@@ -89,7 +89,7 @@ def test_temporal_regression():\n     model.compile(loss='hinge', optimizer='adam')\n     history = model.fit(x_train, y_train, epochs=5, batch_size=16,\n                         validation_data=(x_test, y_test), verbose=0)\n-    assert(history.history['loss'][-1] < 1.)\n+    assert(history.history['loss'][-1] < 1.1)\n \n \n def test_3d_to_3d():\n@@ -112,7 +112,7 @@ def test_3d_to_3d():\n     model.compile(loss='hinge', optimizer='rmsprop')\n     history = model.fit(x_train, y_train, epochs=20, batch_size=16,\n                         validation_data=(x_test, y_test), verbose=0)\n-    assert(history.history['loss'][-1] < 1.)\n+    assert(history.history['loss'][-1] < 1.2)\n \n \n def test_stacked_lstm_char_prediction():\n\n@@ -37,17 +37,17 @@ def test_get_fn():\n     a = activations.get(None)\n     assert a == activations.linear\n \n-    # 2. Passing in a layer raises a warning\n-    layer = Dense(32)\n-    with pytest.warns(UserWarning):\n-        a = activations.get(layer)\n+    # # 2. Passing in a layer raises a warning\n+    # layer = Dense(32)\n+    # with pytest.warns(UserWarning):\n+    #     a = activations.get(layer)\n \n-    # 3. Callables return themselves for some reason\n+    # 3. Callables return themselves\n     a = activations.get(lambda x: 5)\n     assert a(None) == 5\n \n     # 4. Anything else is not a valid argument\n-    with pytest.raises(ValueError):\n+    with pytest.raises(TypeError):\n         a = activations.get(6)\n \n \n\n@@ -1,2151 +0,0 @@\n-import pytest\n-from numpy.testing import assert_allclose\n-import numpy as np\n-import scipy.sparse as sparse\n-import warnings\n-\n-from keras import backend as K\n-from keras.utils.conv_utils import convert_kernel\n-from keras.backend import numpy_backend as KNP\n-\n-\n-try:\n-    from keras.backend import cntk_backend as KC\n-except ImportError:\n-    KC = None\n-    warnings.warn('Could not import the CNTK backend')\n-\n-try:\n-    from keras.backend import tensorflow_backend as KTF\n-except ImportError:\n-    KTF = None\n-    warnings.warn('Could not import the TensorFlow backend.')\n-\n-try:\n-    from keras.backend import theano_backend as KTH\n-except ImportError:\n-    KTH = None\n-    warnings.warn('Could not import the Theano backend')\n-\n-if K.backend() == 'theano':\n-    WITH_NP = [KTH, KNP]\n-elif K.backend() == 'cntk':\n-    WITH_NP = [KC, KNP]\n-else:\n-    WITH_NP = [KTF, KNP]\n-\n-if K.backend() == 'cntk':\n-    supports_sparse = False\n-elif K.backend() == 'theano' and not KTH.th_sparse_module:\n-    supports_sparse = False\n-elif K.backend() == 'tensorflow':\n-    # Must wait for tf.keras to support sparse ops.\n-    supports_sparse = False\n-else:\n-    supports_sparse = True\n-\n-\n-def check_dtype(var, dtype):\n-    if K.backend() == 'tensorflow':\n-        assert dtype in str(var.dtype.name)\n-    else:\n-        assert dtype in str(var.dtype)\n-\n-\n-def cntk_func_tensors(function_name, shapes_or_vals, **kwargs):\n-    placeholders = []\n-    variables = []\n-    for shape_or_val in shapes_or_vals:\n-        if isinstance(shape_or_val, tuple):\n-            shape = shape_or_val\n-            placeholders.append(KC.placeholder(shape))\n-        else:\n-            value = shape_or_val\n-            variables.append(KC.variable(value))\n-\n-    output_cntk = getattr(KC, function_name)(*(placeholders + variables), **kwargs)\n-    cntk_func = KC.function(placeholders, [output_cntk])\n-    return output_cntk, cntk_func\n-\n-\n-def parse_shape_or_val(shape_or_val):\n-    if isinstance(shape_or_val, np.ndarray):\n-        return shape_or_val.shape, shape_or_val\n-    else:\n-        return shape_or_val, np.random.random(shape_or_val).astype(np.float32) - 0.5\n-\n-\n-def assert_list_pairwise(z_list,\n-                         shape=True,\n-                         allclose=True,\n-                         itself=False,\n-                         atol=1e-05):\n-    for (z1, z2) in zip(z_list[1:], z_list[:-1]):\n-        if shape:\n-            assert z1.shape == z2.shape\n-        if allclose:\n-            assert_allclose(z1, z2, atol=atol)\n-        if itself:\n-            assert z1 == z2\n-\n-\n-def assert_list_keras_shape(t_list, z_list):\n-    for t, z in zip(t_list, z_list):\n-        if hasattr(t, '_keras_shape') and len(t._keras_shape) > 1:\n-            for i, s in enumerate(t._keras_shape):\n-                if s:\n-                    assert t._keras_shape[i] == z.shape[i]\n-\n-\n-def check_single_tensor_operation(function_name,\n-                                  x_shape_or_val,\n-                                  backend_list,\n-                                  **kwargs):\n-    shape_or_val = kwargs.pop('shape_or_val', True)\n-    assert_value_equality = kwargs.pop('assert_value_equality', True)\n-    cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n-\n-    if shape_or_val:\n-        x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n-\n-    t_list = []\n-    z_list = []\n-    for k in backend_list:\n-        if shape_or_val:\n-            if (k == KC) & (cntk_dynamicity):\n-                t, f = cntk_func_tensors(function_name, [x_shape], **kwargs)\n-                z = f([x_val])[0]\n-            else:\n-                t = getattr(k, function_name)(k.variable(x_val), **kwargs)\n-                z = k.eval(t)\n-        else:\n-            t = getattr(k, function_name)(x_shape_or_val, **kwargs)\n-            z = k.eval(t)\n-        t_list += [t]\n-        z_list += [z]\n-\n-    assert_list_pairwise(z_list, allclose=assert_value_equality)\n-    assert_list_keras_shape(t_list, z_list)\n-\n-\n-def check_two_tensor_operation(function_name,\n-                               x_shape_or_val,\n-                               y_shape_or_val,\n-                               backend_list,\n-                               **kwargs):\n-    concat_args = kwargs.pop('concat_args', False)\n-    cntk_dynamicity = kwargs.pop('cntk_dynamicity', False)\n-    cntk_two_dynamicity = kwargs.pop('cntk_two_dynamicity', False)\n-\n-    x_shape, x_val = parse_shape_or_val(x_shape_or_val)\n-    y_shape, y_val = parse_shape_or_val(y_shape_or_val)\n-\n-    t_list = []\n-    z_list = []\n-    for k in backend_list:\n-        if (k == KC) & (cntk_dynamicity):\n-            t, f = cntk_func_tensors(function_name, [x_shape, y_val], **kwargs)\n-            z = f([x_val])[0]\n-        elif (k == KC) & (cntk_two_dynamicity):\n-            t, f = cntk_func_tensors(function_name, [x_shape, y_shape], **kwargs)\n-            z = f([x_val, y_val])[0]\n-        elif (k == KTH) & (function_name[:4] == 'conv'):\n-            t = getattr(k, function_name)(\n-                k.variable(x_val), k.variable(convert_kernel(y_val)), **kwargs)\n-            z = k.eval(t)\n-        elif concat_args:\n-            t = getattr(k, function_name)(\n-                [k.variable(x_val), k.variable(y_val)], **kwargs)\n-            z = k.eval(t)\n-        else:\n-            t = getattr(k, function_name)(\n-                k.variable(x_val), k.variable(y_val), **kwargs)\n-            z = k.eval(t)\n-        t_list += [t]\n-        z_list += [z]\n-\n-    assert_list_pairwise(z_list)\n-    assert_list_keras_shape(t_list, z_list)\n-\n-\n-def check_composed_tensor_operations(first_function_name,\n-                                     first_function_args,\n-                                     second_function_name,\n-                                     second_function_args,\n-                                     input_shape,\n-                                     backend_list):\n-    val = np.random.random(input_shape) - 0.5\n-\n-    z_list = []\n-    for k in backend_list:\n-        x = k.variable(val)\n-        y = getattr(k, first_function_name)(x, **first_function_args)\n-        z = k.eval(getattr(k, second_function_name)(y, **second_function_args))\n-        z_list += [z]\n-\n-    assert_list_pairwise(z_list)\n-\n-\n-def check_rnn_operation(step_function_k,\n-                        step_function_np,\n-                        inputs_np,\n-                        initial_states_np,\n-                        mask_np=None,\n-                        constants_np=None,\n-                        **kwargs):\n-    inputs_k = K.variable(inputs_np)\n-    initial_states_k = [K.variable(s) for s in initial_states_np]\n-    if mask_np is not None:\n-        mask_k = K.variable(mask_np)\n-    else:\n-        mask_k = None\n-    if constants_np is not None:\n-        constants_k = [K.variable(c) for c in constants_np]\n-    else:\n-        constants_k = None\n-\n-    last_output_np, output_np, last_states_np = KNP.rnn(\n-        step_function_np,\n-        inputs_np,\n-        initial_states_np,\n-        mask=mask_np,\n-        constants=constants_np,\n-        **kwargs)\n-    # note that numpy reference implementation is independent of `unroll` argument\n-    if 'unroll' in kwargs:\n-        unroll_options = [kwargs.pop('unroll')]\n-    else:\n-        unroll_options = [True, False]\n-    for unroll in unroll_options:\n-        last_output_k, output_k, last_states_k = K.rnn(\n-            step_function_k,\n-            inputs_k,\n-            initial_states_k,\n-            mask=mask_k,\n-            constants=constants_k,\n-            unroll=unroll,\n-            input_length=inputs_np.shape[1] if unroll else None,\n-            **kwargs)\n-\n-        last_states_k = [K.eval(s) for s in last_states_k]\n-        last_output_k = K.eval(last_output_k)\n-        output_k = K.eval(output_k)\n-\n-        assert_allclose(last_output_k, last_output_np, atol=1e-05)\n-        assert_allclose(output_k, output_np, atol=1e-05)\n-        assert len(last_states_k) == len(last_states_np)\n-        for s_k, s_np in zip(last_states_k, last_states_np):\n-            assert_allclose(s_k, s_np, atol=1e-05)\n-\n-\n-class TestBackend(object):\n-\n-    def test_is_keras_tensor(self):\n-        np_var = np.array([1, 2])\n-        with pytest.raises(ValueError):\n-            K.is_keras_tensor(np_var)\n-\n-        keras_var = K.variable(np_var)\n-        assert K.is_keras_tensor(keras_var) is False\n-        keras_placeholder = K.placeholder(shape=(2, 4, 5))\n-        assert K.is_keras_tensor(keras_placeholder) is False\n-\n-    def test_set_learning_phase(self):\n-        # not supported learning_phase\n-        with pytest.raises(ValueError):\n-            K.set_learning_phase(2)\n-\n-    def test_creation_operations(self):\n-        check_single_tensor_operation('eye', 3, WITH_NP, shape_or_val=False)\n-        check_single_tensor_operation('eye', (3, 2), WITH_NP, shape_or_val=False)\n-        check_single_tensor_operation('eye', (3, 4), WITH_NP, shape_or_val=False)\n-\n-        check_single_tensor_operation('ones', (3, 5, 10, 8),\n-                                      WITH_NP, shape_or_val=False)\n-        check_single_tensor_operation('zeros', (3, 5, 10, 8),\n-                                      WITH_NP, shape_or_val=False)\n-\n-        check_single_tensor_operation('ones_like', (3, 5, 10, 8), WITH_NP)\n-        check_single_tensor_operation('zeros_like', (3, 5, 10, 8), WITH_NP)\n-\n-    def test_linear_operations(self):\n-        check_two_tensor_operation('dot', (4, 2), (2, 4), WITH_NP)\n-        check_two_tensor_operation('dot', (4, 2), (5, 2, 3), WITH_NP)\n-\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),\n-                                   WITH_NP, cntk_two_dynamicity=True, axes=(2, 2))\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 3),\n-                                   WITH_NP, cntk_two_dynamicity=True, axes=(2, 1))\n-        check_two_tensor_operation('batch_dot', (4, 2), (4, 2, 3),\n-                                   WITH_NP, cntk_two_dynamicity=True, axes=(1, 1))\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20),\n-                                   WITH_NP, cntk_two_dynamicity=True, axes=1)\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20),\n-                                   WITH_NP, cntk_two_dynamicity=True, axes=(1, 1))\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),\n-                                   WITH_NP, axes=(2, 2))\n-        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 3),\n-                                   WITH_NP, axes=(2, 1))\n-        check_two_tensor_operation('batch_dot', (4, 2), (4, 2, 3),\n-                                   WITH_NP, axes=(1, 1))\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20),\n-                                   WITH_NP, axes=1)\n-        check_two_tensor_operation('batch_dot', (32, 20), (32, 20),\n-                                   WITH_NP, axes=(1, 1))\n-\n-        check_single_tensor_operation('transpose', (4, 2), WITH_NP)\n-        check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=1)\n-        check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=(1, 2))\n-        check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=(0, -1))\n-\n-    def test_random_variables(self):\n-        check_single_tensor_operation('random_uniform_variable', (2, 3), WITH_NP,\n-                                      low=0., high=1.,\n-                                      shape_or_val=False,\n-                                      assert_value_equality=False)\n-        check_single_tensor_operation('random_normal_variable', (2, 3), WITH_NP,\n-                                      mean=0., scale=1.,\n-                                      shape_or_val=False,\n-                                      assert_value_equality=False)\n-\n-    def test_batch_dot_shape(self):\n-        # Note : batch_dot implementation is different for\n-        # placeholders and variables in CNTK backend\n-\n-        test_cases = []\n-        test_cases.append([(None, 3, 4, 5), (None, 2, 3, 4), (2, 3)])\n-        test_cases.append([(None, 3, 4, 5), (None, 2, 4), 2])\n-        test_cases.append([(None, 3, 4), (None, 2, 3, 4), (2, 3)])\n-        test_cases.append([(None, 4, 3), (None, 3, 5), (2, 1)])\n-        test_cases.append([(None, 4), (None, 3, 4), (1, 2)])\n-        test_cases.append([(None, 4), (None, 4), None])\n-\n-        batch_size = 7\n-\n-        def batch_shape(shape):\n-            return (batch_size, ) + shape[1:]\n-\n-        def random(shape):\n-            return np.random.random(batch_shape(shape))\n-\n-        for x_shape, y_shape, axes in test_cases:\n-            x_np = random(x_shape)\n-            y_np = random(y_shape)\n-            z_np = KNP.batch_dot(x_np, y_np, axes)\n-\n-            # test with placeholders\n-            x = K.placeholder(shape=x_shape)\n-            y = K.placeholder(shape=y_shape)\n-            z = K.batch_dot(x, y, axes)\n-\n-            z_shape = K.int_shape(z)\n-            if z_shape is not None:\n-                assert z_shape[1:] == z_np.shape[1:]\n-\n-            f = K.function([x, y], [z])\n-\n-            assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n-\n-            # test with placeholders (no shape info)\n-            if K.backend() != 'cntk':\n-                x = K.placeholder(ndim=len(x_shape))\n-                y = K.placeholder(ndim=len(y_shape))\n-                z = K.batch_dot(x, y, axes)\n-\n-                z_shape = K.int_shape(z)\n-                if z_shape is not None:\n-                    assert len(z_shape) == z_np.ndim\n-                    assert set(z_shape) <= set((None, 1))\n-\n-                f = K.function([x, y], [z])\n-\n-                assert_allclose(f([x_np, y_np])[0], z_np, atol=1e-05)\n-\n-            # test with variables\n-            x = K.variable(x_np)\n-            y = K.variable(y_np)\n-            z = K.batch_dot(x, y, axes)\n-\n-            z_shape = K.int_shape(z)\n-            if z_shape is not None:\n-                assert z_shape[1:] == z_np.shape[1:]\n-\n-            z = K.eval(z)\n-            assert_allclose(z, z_np, atol=1e-05)\n-\n-    def test_shape_operations(self):\n-        check_single_tensor_operation('reshape', (4, 2), WITH_NP, shape=(8, 1))\n-        check_single_tensor_operation('permute_dimensions', (4, 2, 3), WITH_NP,\n-                                      pattern=(2, 0, 1))\n-        check_single_tensor_operation('repeat', (4, 1), WITH_NP, n=3)\n-        check_single_tensor_operation('flatten', (4, 1), WITH_NP)\n-        check_single_tensor_operation('batch_flatten', (20, 2, 5), WITH_NP,\n-                                      cntk_dynamicity=True)\n-        check_single_tensor_operation('expand_dims', (4, 3), WITH_NP, axis=-1)\n-        check_single_tensor_operation('expand_dims', (4, 3, 2), WITH_NP, axis=1)\n-        check_single_tensor_operation('squeeze', (4, 3, 1), WITH_NP, axis=2)\n-        check_single_tensor_operation('squeeze', (4, 1, 1), WITH_NP, axis=1)\n-        check_composed_tensor_operations('reshape', {'shape': (4, 3, 1, 1)},\n-                                         'squeeze', {'axis': 2},\n-                                         (4, 3, 1, 1), WITH_NP)\n-\n-    @pytest.mark.skipif(K.backend() != 'theano',\n-                        reason='We only test the shape inference of the '\n-                               'theano backend.')\n-    def test_none_shape_operations(self):\n-        # Test shape inference when input\n-        # shape has `None` entries\n-        x = K.placeholder((3, None, 4))\n-\n-        y = K.batch_flatten(x)\n-        if hasattr(y, '_keras_shape'):\n-            assert y._keras_shape == (3, None)\n-\n-        y = K.flatten(x)\n-        if hasattr(y, '_keras_shape'):\n-            assert y._keras_shape == (None,)\n-\n-    def test_repeat_elements(self):\n-        reps = 3\n-        for ndims in [1, 2, 3]:\n-            shape = np.arange(2, 2 + ndims)\n-            arr = np.arange(np.prod(shape)).reshape(shape)\n-\n-            for rep_axis in range(ndims):\n-                check_single_tensor_operation('repeat_elements', arr, WITH_NP,\n-                                              rep=reps, axis=rep_axis)\n-\n-                if K.backend() != 'cntk':\n-                    shape = list(shape)\n-                    shape[rep_axis] = None\n-                    x = K.placeholder(shape=shape)\n-                    y = K.repeat_elements(x, reps, axis=rep_axis)\n-                    assert y._keras_shape == tuple(shape)\n-                    assert y._keras_shape == K.int_shape(y)\n-\n-    def test_tile(self):\n-        check_single_tensor_operation('tile', (3, 4), WITH_NP, n=2)\n-        check_single_tensor_operation('tile', (3, 4), WITH_NP, n=(2, 1))\n-        check_single_tensor_operation('tile', (3, 4, 5), WITH_NP, n=2)\n-        check_single_tensor_operation('tile', (3, 4, 5), WITH_NP, n=(1, 2))\n-        check_single_tensor_operation('tile', (3, 4, 5), WITH_NP, n=(3, 1, 2))\n-\n-        # test theano shape inference when\n-        # input shape has None entries\n-        if K.backend() == 'theano':\n-            x = K.placeholder(shape=(None, 4))\n-            n = 2\n-            y = K.tile(x, n)\n-            assert y._keras_shape == (None, 8)\n-            n = (4, 3)\n-            y = K.tile(x, n)\n-            assert y._keras_shape == (None, 12)\n-\n-    def test_gather(self):\n-        shape = (10, 2, 3)\n-        ref = np.arange(np.prod(shape)).reshape(shape)\n-        inds = [1, 3, 7, 9]\n-        t_list = [k.gather(k.variable(ref), k.variable(inds, dtype='int32'))\n-                  for k in WITH_NP]\n-        z_list = [k.eval(k.gather(k.variable(ref), k.variable(inds, dtype='int32')))\n-                  for k in WITH_NP]\n-\n-        assert_list_pairwise(z_list)\n-        assert_list_keras_shape(t_list, z_list)\n-\n-        # test theano shape inference when\n-        # input shape has None entries\n-        if K.backend() == 'theano':\n-            x = K.placeholder(shape=(None, 3, 4))\n-            indices = K.placeholder(shape=(5, 6), dtype='int32')\n-            y = K.gather(x, indices)\n-            assert y._keras_shape == (5, 6, 3, 4)\n-\n-    @pytest.mark.parametrize('function_name',\n-                             ['get_value', 'count_params',\n-                              'int_shape', 'get_variable_shape'])\n-    def test_value_manipulation(self, function_name):\n-        val = np.random.random((4, 2))\n-        v_list = [getattr(k, function_name)(k.variable(val))\n-                  for k in WITH_NP]\n-\n-        if function_name == 'get_value':\n-            assert_list_pairwise(v_list)\n-        else:\n-            assert_list_pairwise(v_list,\n-                                 shape=False,\n-                                 allclose=False,\n-                                 itself=True)\n-\n-    def test_print_tensor(self, capsys):\n-        # TODO: somehow this capture mechanism doesn't work for TF\n-        # even though the TF op does print to stdout.\n-        for k in [KTH]:\n-            x = k.placeholder((1, 1))\n-            y = k.print_tensor(x, 'msg')\n-            fn = k.function([x], [y])\n-            _ = fn([np.ones((1, 1))])\n-            out, err = capsys.readouterr()\n-            # Theano inserts \"__str__ = \" for no good reason\n-            assert out.replace('__str__ = ', '') == 'msg [[1.]]\\n'\n-\n-    def test_elementwise_operations(self):\n-        check_single_tensor_operation('max', (4, 2), WITH_NP)\n-        check_single_tensor_operation('max', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('max', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('min', (4, 2), WITH_NP)\n-        check_single_tensor_operation('min', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('min', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('mean', (4, 2), WITH_NP)\n-        check_single_tensor_operation('mean', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('mean', (4, 2, 3),\n-                                      WITH_NP, axis=-1, keepdims=True)\n-        check_single_tensor_operation('mean', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('var', (4, 2), WITH_NP)\n-        check_single_tensor_operation('var', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('var', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('std', (4, 2), WITH_NP)\n-        check_single_tensor_operation('std', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('std', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('prod', (4, 2), WITH_NP)\n-        check_single_tensor_operation('prod', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('prod', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('any', (4, 2), WITH_NP)\n-        check_single_tensor_operation('any', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('any', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('all', (4, 2), WITH_NP)\n-        check_single_tensor_operation('all', (4, 2), WITH_NP, axis=1, keepdims=True)\n-        check_single_tensor_operation('all', (4, 2, 3), WITH_NP, axis=[1, -1])\n-\n-        check_single_tensor_operation('argmax', (4, 2), WITH_NP)\n-        check_single_tensor_operation('argmax', (4, 2), WITH_NP, axis=1)\n-\n-        check_single_tensor_operation('argmin', (4, 2), WITH_NP)\n-        check_single_tensor_operation('argmin', (4, 2), WITH_NP, axis=1)\n-\n-        check_single_tensor_operation('square', (4, 2), WITH_NP)\n-        check_single_tensor_operation('abs', (4, 2), WITH_NP)\n-        check_single_tensor_operation('sqrt', (4, 2), WITH_NP)\n-        check_single_tensor_operation('exp', (4, 2), WITH_NP)\n-\n-        check_single_tensor_operation('round', (4, 2), WITH_NP)\n-        check_single_tensor_operation('sign', (4, 2), WITH_NP)\n-        check_single_tensor_operation('pow', (4, 2), WITH_NP, a=3)\n-        check_single_tensor_operation('clip', (4, 2), WITH_NP, min_value=0.4,\n-                                      max_value=0.6)\n-\n-        check_single_tensor_operation('cos', (4, 2), WITH_NP)\n-        check_single_tensor_operation('sin', (4, 2), WITH_NP)\n-\n-        # two-tensor ops\n-        check_two_tensor_operation('equal', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('not_equal', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('greater', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('greater_equal', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('less', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('less_equal', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('maximum', (4, 2), (4, 2), WITH_NP)\n-        check_two_tensor_operation('minimum', (4, 2), (4, 2), WITH_NP)\n-\n-    # assumes first uid will always be the same\n-    def test_reset_uids(self):\n-        first = K.get_uid()\n-        K.get_uid()\n-        K.reset_uids()\n-        assert K.get_uid() == first\n-\n-    def test_cumsum(self):\n-        check_single_tensor_operation('cumsum', (4, 2), WITH_NP)\n-        check_single_tensor_operation('cumsum', (4, 2), WITH_NP, axis=1)\n-\n-    def test_cumprod(self):\n-        check_single_tensor_operation('cumprod', (4, 2), WITH_NP)\n-        check_single_tensor_operation('cumprod', (4, 2), WITH_NP, axis=1)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk',\n-                        reason='cntk return -85.1 for zero or '\n-                               'negative number, not nan, so can\\'t '\n-                               'compare with other backend.')\n-    def test_log(self):\n-        check_single_tensor_operation('log', (4, 2), WITH_NP)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='theano returns tuples for updates; cntk buggy')\n-    def test_update(self):\n-        x = np.ones((3, 4))\n-        x_var = K.variable(x)\n-        new_x = np.random.random((3, 4))\n-\n-        op = K.update(x_var, new_x)\n-        K.eval(op)\n-\n-        assert_allclose(new_x, K.eval(x_var), atol=1e-05)\n-\n-    @pytest.mark.skipif(K.backend() == 'theano',\n-                        reason='theano returns tuples for update ops')\n-    def test_update_add(self):\n-        x = np.ones((3, 4))\n-        x_var = K.variable(x)\n-        increment = np.random.random((3, 4))\n-\n-        op = K.update_add(x_var, increment)\n-        K.eval(op)\n-\n-        assert_allclose(x + increment, K.eval(x_var), atol=1e-05)\n-\n-    @pytest.mark.skipif(K.backend() == 'theano',\n-                        reason='theano returns tuples for update ops')\n-    def test_update_sub(self):\n-        x = np.ones((3, 4))\n-        x_var = K.variable(x)\n-        decrement = np.random.random((3, 4))\n-\n-        op = K.update_sub(x_var, decrement)\n-        K.eval(op)\n-\n-        assert_allclose(x - decrement, K.eval(x_var), atol=1e-05)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk',\n-                        reason='cntk doesn\\'t support gradient in this way.')\n-    def test_gradient(self):\n-        val = np.random.random((4, 2))\n-        x_list = [k.placeholder(shape=(4, 2)) for k in [KTH, KTF]]\n-        z_list = []\n-        zero_list = []\n-        for x, k in zip(x_list, [KTH, KTF]):\n-            exp = x * k.exp(x)\n-            loss = k.sum(exp)\n-            zero_loss = k.stop_gradient(loss)\n-            grad = k.gradients(loss, [exp])\n-\n-            zero_grad = k.gradients(loss + zero_loss, [exp])\n-            grad_eval_fn = k.function([x], [grad[0]])\n-            zero_grad_eval_fn = k.function([x], [zero_grad[0]])\n-            z_list.append(grad_eval_fn([val])[0])\n-            zero_list.append(zero_grad_eval_fn([val])[0])\n-\n-        assert_list_pairwise(z_list)\n-        assert_list_pairwise(zero_list)\n-        for i in range(len(z_list)):\n-            assert_allclose(zero_list[i], z_list[i], atol=1e-05)\n-\n-    def test_stop_gradient(self):\n-        # This test checks the consistency of the stop_gradient backend API.\n-        # It doesn't check the functionality (which is checked at the\n-        # test_gradient test).\n-        val = np.random.random((4, 2))\n-        a = K.variable(val)\n-        b = K.square(a)\n-        c, d = K.stop_gradient([a, b])\n-        e = K.stop_gradient(b)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk',\n-                        reason='cntk currently not support function in this '\n-                               'way, so can\\'t test as this.')\n-    def test_function(self):\n-        test_backend = [KTH, KTF]\n-        val = np.random.random((4, 2))\n-        input_val = np.random.random((4, 2))\n-\n-        f_list = []\n-        x_list = []\n-        for k in test_backend:\n-            x = k.variable(val)\n-            x_list.append(x)\n-            y = k.placeholder(ndim=2)\n-            exp = k.square(x) + y\n-            # Need to use `identity` to make this symbolic\n-            # (TODO: fix in tf.keras)\n-            update = k.identity(x) * 2\n-            f = k.function([y], [exp], updates=[(x, update)])\n-            f_list.append(f)\n-\n-        function_outputs_list = [f([input_val])[0] for f in f_list]\n-        assert_list_pairwise(function_outputs_list)\n-\n-        new_val_list = [k.get_value(x) for x, k in zip(x_list, test_backend)]\n-        assert_list_pairwise(new_val_list)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow' or not KTF._is_tf_1(),\n-                        reason='Uses the `fetches` argument.')\n-    def test_function_tf_fetches(self):\n-        # Additional operations can be passed to tf.Session().run() via its\n-        # `fetches` arguments. In contrast to `updates` argument of\n-        # KTF.function() these do not have control dependency on `outputs`, so\n-        # they can run in parallel. Also they should not contribute to output of\n-        # KTF.function().\n-\n-        x = K.variable(0.)\n-        y = K.variable(0.)\n-        x_placeholder = K.placeholder(shape=())\n-        y_placeholder = K.placeholder(shape=())\n-\n-        f = K.function(inputs=[x_placeholder, y_placeholder],\n-                       outputs=[x_placeholder + y_placeholder],\n-                       updates=[(x, x_placeholder + 1.)],\n-                       fetches=[K.update(y, 5.)])\n-        output = f([10., 20.])\n-        assert output == [30.]\n-        assert K.get_session().run(fetches=[x, y]) == [11., 5.]\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow' or not KTF._is_tf_1(),\n-                        reason='Uses the `feed_dict` argument.')\n-    def test_function_tf_feed_dict(self):\n-        # Additional substitutions can be passed to `tf.Session().run()` via its\n-        # `feed_dict` arguments. Note that the feed_dict is passed once in the\n-        # constructor but we can modify the values in the dictionary. Through\n-        # this feed_dict we can provide additional substitutions besides Keras\n-        # inputs.\n-\n-        x = K.variable(0.)\n-        y = K.variable(0.)\n-        x_placeholder = K.placeholder(shape=())\n-        y_placeholder = K.placeholder(shape=())\n-\n-        feed_dict = {y_placeholder: 3.}\n-\n-        f = K.function(inputs=[x_placeholder],\n-                       outputs=[x_placeholder + 1.],\n-                       updates=[(x, x_placeholder + 10.)],\n-                       feed_dict=feed_dict,\n-                       fetches=[K.update(y, y_placeholder * 10.)])\n-        output = f([10.])\n-        assert output == [11.]\n-        assert K.get_session().run(fetches=[x, y]) == [20., 30.]\n-\n-        # updated value in feed_dict will be modified within the K.function()\n-        feed_dict[y_placeholder] = 4.\n-        output = f([20.])\n-        assert output == [21.]\n-        assert K.get_session().run(fetches=[x, y]) == [30., 40.]\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow' or not KTF._is_tf_1(),\n-                        reason='Uses the `options` and `run_metadata` arguments.')\n-    def test_function_tf_run_options_with_run_metadata(self):\n-        from tensorflow.core.protobuf import config_pb2\n-        x_placeholder = K.placeholder(shape=())\n-        y_placeholder = K.placeholder(shape=())\n-\n-        run_options = config_pb2.RunOptions(output_partition_graphs=True)\n-        run_metadata = config_pb2.RunMetadata()\n-        # enable run_options.\n-        f = K.function(inputs=[x_placeholder, y_placeholder],\n-                       outputs=[x_placeholder + y_placeholder],\n-                       options=run_options,\n-                       run_metadata=run_metadata)\n-        output = f([10., 20.])\n-        assert output == [30.]\n-        assert len(run_metadata.partition_graphs) > 0\n-        # disable run_options.\n-        f = K.function(inputs=[x_placeholder, y_placeholder],\n-                       outputs=[x_placeholder + y_placeholder],\n-                       run_metadata=run_metadata)\n-        output = f([10., 20.])\n-        assert output == [30.]\n-        assert len(run_metadata.partition_graphs) == 0\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='Uses the `string` type for a tensor.')\n-    def test_function_tf_string_input(self):\n-        # Test functions with string inputs.\n-\n-        x_placeholder = K.placeholder(shape=(), dtype=\"string\")\n-        x_identity = K.identity(x_placeholder)\n-\n-        f = K.function(inputs=[x_placeholder], outputs=[x_identity])\n-        output = f([b'test'])\n-        assert output == [b'test']\n-\n-    def test_rnn(self):\n-        # implement a simple RNN\n-        num_samples = 4\n-        input_dim = 5\n-        output_dim = 3\n-        timesteps = 6\n-\n-        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n-        _, h0 = parse_shape_or_val((num_samples, output_dim))\n-        _, wi = parse_shape_or_val((input_dim, output_dim))\n-        _, wh = parse_shape_or_val((output_dim, output_dim))\n-        mask = np.random.randint(2, size=(num_samples, timesteps))\n-\n-        wi_k = K.variable(wi)\n-        wh_k = K.variable(wh)\n-\n-        def get_step_function(backend, w_i, w_h):\n-\n-            def simple_rnn(inputs, states):\n-                assert len(states) == 1\n-                h = states[0]\n-                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n-                return y, [y]\n-\n-            return simple_rnn\n-\n-        kwargs_list = [\n-            {'go_backwards': False, 'mask': None},\n-            {'go_backwards': True, 'mask': None},\n-            {'go_backwards': False, 'mask': mask},\n-            {'go_backwards': True, 'mask': mask},\n-        ]\n-        for kwargs in kwargs_list:\n-            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n-                                step_function_np=get_step_function(KNP, wi, wh),\n-                                inputs_np=x,\n-                                initial_states_np=[h0],\n-                                mask_np=kwargs.pop('mask', None),\n-                                **kwargs)\n-\n-    @pytest.mark.skipif(K.backend() == 'theano', reason='Not supported')\n-    def test_rnn_unroll_with_len_1(self):\n-        num_samples = 4\n-        input_dim = 5\n-        output_dim = 3\n-\n-        _, x = parse_shape_or_val((num_samples, 1, input_dim))\n-        _, h0 = parse_shape_or_val((num_samples, output_dim))\n-        _, wi = parse_shape_or_val((input_dim, output_dim))\n-        _, wh = parse_shape_or_val((output_dim, output_dim))\n-\n-        wi_k = K.variable(wi)\n-        wh_k = K.variable(wh)\n-\n-        def get_step_function(backend, w_i, w_h):\n-\n-            def simple_rnn(inputs, states):\n-                assert len(states) == 1\n-                h = states[0]\n-                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n-                return y, [y]\n-\n-            return simple_rnn\n-\n-        kwargs_list = [\n-            {'go_backwards': False},\n-            {'go_backwards': True},\n-        ]\n-        for kwargs in kwargs_list:\n-            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n-                                step_function_np=get_step_function(KNP, wi, wh),\n-                                inputs_np=x,\n-                                initial_states_np=[h0],\n-                                unroll=True,\n-                                **kwargs)\n-\n-    def test_rnn_additional_states(self):\n-        # implement a simple RNN with an additional state\n-        # whose shape is different from that of the output\n-        num_samples = 4\n-        input_dim = 5\n-        output_dim = 3\n-        timesteps = 6\n-\n-        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n-        _, h0 = parse_shape_or_val((num_samples, output_dim))\n-        h1 = np.concatenate([h0, h0], axis=-1)\n-        _, wi = parse_shape_or_val((input_dim, output_dim))\n-        _, wh = parse_shape_or_val((output_dim, output_dim))\n-        mask = np.random.randint(2, size=(num_samples, timesteps))\n-\n-        wi_k = K.variable(wi)\n-        wh_k = K.variable(wh)\n-\n-        def get_step_function(backend, w_i, w_h):\n-\n-            def simple_rnn_with_extra_mock_state(inputs, states):\n-                assert len(states) == 2\n-                h = states[0]\n-                y = backend.dot(inputs, w_i) + backend.dot(h, w_h)\n-                return y, [y, backend.concatenate([y, y], axis=-1)]\n-\n-            return simple_rnn_with_extra_mock_state\n-\n-        kwargs_list = [\n-            {'go_backwards': False, 'mask': None},\n-            {'go_backwards': True, 'mask': None},\n-            {'go_backwards': False, 'mask': mask},\n-            {'go_backwards': True, 'mask': mask},\n-        ]\n-        for kwargs in kwargs_list:\n-            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n-                                step_function_np=get_step_function(KNP, wi, wh),\n-                                inputs_np=x,\n-                                initial_states_np=[h0, h1],\n-                                mask_np=kwargs.pop('mask', None),\n-                                **kwargs)\n-\n-    def test_rnn_no_states(self):\n-        # implement a simple RNN without states\n-        num_samples = 3\n-        input_dim = 8\n-        output_dim = 4\n-        timesteps = 5\n-\n-        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n-        _, wi = parse_shape_or_val((input_dim, output_dim))\n-        mask = np.random.randint(2, size=(num_samples, timesteps))\n-\n-        wi_k = K.variable(wi)\n-\n-        def get_step_function(backend, w_i):\n-\n-            def simple_no_states(inputs, states):\n-                assert len(states) == 0\n-                y = backend.dot(inputs, w_i)\n-                return y, []\n-\n-            return simple_no_states\n-\n-        kwargs_list = [\n-            {'go_backwards': False},\n-            {'go_backwards': True},\n-        ]\n-        for kwargs in kwargs_list:\n-            check_rnn_operation(step_function_k=get_step_function(K, wi_k),\n-                                step_function_np=get_step_function(KNP, wi),\n-                                inputs_np=x,\n-                                initial_states_np=[],\n-                                mask_np=None,\n-                                **kwargs)\n-\n-    def test_rnn_constants(self):\n-        # implement a simple RNN\n-        num_samples = 4\n-        input_dim = 5\n-        output_dim = 3\n-        timesteps = 6\n-\n-        _, x = parse_shape_or_val((num_samples, timesteps, input_dim))\n-        _, h0 = parse_shape_or_val((num_samples, output_dim))\n-        _, c = parse_shape_or_val((num_samples, output_dim))\n-        _, wi = parse_shape_or_val((input_dim, output_dim))\n-        _, wh = parse_shape_or_val((output_dim, output_dim))\n-        mask = np.random.randint(2, size=(num_samples, timesteps))\n-\n-        wi_k = K.variable(wi)\n-        wh_k = K.variable(wh)\n-\n-        def get_step_function(backend, w_i, w_h):\n-\n-            def simple_rnn_add_constant(inputs, states_and_constants):\n-                # constants are appended to states in K.rnn\n-                [h, c] = states_and_constants\n-                y = backend.dot(inputs, w_i) + backend.dot(h, w_h) + c\n-                return y, [y]\n-\n-            return simple_rnn_add_constant\n-\n-        kwargs_list = [\n-            {'go_backwards': False, 'mask': None},\n-            {'go_backwards': True, 'mask': None},\n-            {'go_backwards': False, 'mask': mask},\n-            {'go_backwards': True, 'mask': mask},\n-        ]\n-        for kwargs in kwargs_list:\n-            check_rnn_operation(step_function_k=get_step_function(K, wi_k, wh_k),\n-                                step_function_np=get_step_function(KNP, wi, wh),\n-                                inputs_np=x,\n-                                initial_states_np=[h0],\n-                                mask_np=kwargs.pop('mask', None),\n-                                constants_np=[c],\n-                                **kwargs)\n-\n-    def test_rnn_output_and_state_masking_independent(self):\n-        num_samples = 2\n-        num_timesteps = 4\n-        state_and_io_size = 5\n-        mask_last_num_timesteps = 2  # for second sample only\n-\n-        # a step function that just outputs inputs,\n-        # but increments states +1 per timestep\n-        def step_function(inputs, states):\n-            return inputs, [s + 1 for s in states]\n-\n-        inputs_vals = np.random.random(\n-            (num_samples, num_timesteps, state_and_io_size))\n-        initial_state_vals = np.random.random((num_samples, state_and_io_size))\n-        # masking of two last timesteps for second sample only\n-        mask_vals = np.ones((num_samples, num_timesteps))\n-        mask_vals[1, -mask_last_num_timesteps:] = 0\n-\n-        # outputs expected to be same as inputs for the first sample\n-        expected_outputs = inputs_vals.copy()\n-        # but for the second sample all outputs in masked region should be the same\n-        # as last output before masked region\n-        expected_outputs[1, -mask_last_num_timesteps:] = expected_outputs[\n-            1, -(mask_last_num_timesteps + 1)]\n-\n-        expected_state = initial_state_vals.copy()\n-        # first state should be incremented for every timestep (no masking)\n-        expected_state[0] += num_timesteps\n-        # second state should not be incremented for last two timesteps\n-        expected_state[1] += (num_timesteps - mask_last_num_timesteps)\n-\n-        # verify same expected output for `unroll=true/false`\n-        inputs = K.constant(inputs_vals)\n-        initial_states = [K.constant(initial_state_vals)]\n-        mask = K.constant(mask_vals)\n-        for unroll in [True, False]:\n-            last_output, outputs, last_states = K.rnn(\n-                step_function,\n-                inputs,\n-                initial_states,\n-                mask=mask,\n-                unroll=unroll,\n-                input_length=num_timesteps if unroll else None)\n-\n-            assert_allclose(K.eval(outputs), expected_outputs)\n-            assert_allclose(K.eval(last_states[0]), expected_state)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n-    def test_rnn_output_num_dim_larger_than_2_masking(self):\n-        num_samples = 3\n-        num_timesteps = 4\n-        num_features = 5\n-\n-        def step_function(inputs, states):\n-            outputs = K.tile(K.expand_dims(inputs), [1, 1, 2])\n-            return outputs, states\n-\n-        inputs_vals = np.random.random((num_samples, num_timesteps, num_features))\n-        initial_state_vals = np.random.random((num_samples, 6))\n-        mask_vals = np.ones((num_samples, num_timesteps))\n-        mask_vals[-1, -1] = 0  # final timestep masked for last sample\n-\n-        expected_outputs = np.repeat(inputs_vals[..., None], repeats=2, axis=-1)\n-        # for the last sample, the final timestep (in masked region) should be the\n-        # same as the second to final output (before masked region)\n-        expected_outputs[-1, -1] = expected_outputs[-1, -2]\n-\n-        inputs = K.constant(inputs_vals)\n-        initial_states = [K.constant(initial_state_vals)]\n-        mask = K.constant(mask_vals)\n-        for unroll in [True, False]:\n-            last_output, outputs, last_states = K.rnn(\n-                step_function,\n-                inputs,\n-                initial_states,\n-                mask=mask,\n-                unroll=unroll,\n-                input_length=num_timesteps if unroll else None)\n-\n-            assert_allclose(K.eval(outputs), expected_outputs)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n-    def test_rnn_state_num_dim_larger_than_2_masking(self):\n-        num_samples = 3\n-        num_timesteps = 4\n-\n-        def step_function(inputs, states):\n-            return inputs, [s + 1 for s in states]\n-\n-        inputs_vals = np.random.random((num_samples, num_timesteps, 5))\n-        initial_state_vals = np.random.random((num_samples, 6, 7))\n-        mask_vals = np.ones((num_samples, num_timesteps))\n-        mask_vals[0, -2:] = 0  # final two timesteps masked for first sample\n-\n-        expected_last_state = initial_state_vals.copy()\n-        expected_last_state[0] += (num_timesteps - 2)\n-        expected_last_state[1:] += num_timesteps\n-\n-        inputs = K.variable(inputs_vals)\n-        initial_states = [K.variable(initial_state_vals)]\n-        mask = K.variable(mask_vals)\n-        for unroll in [True, False]:\n-            last_output, outputs, last_states = K.rnn(\n-                step_function,\n-                inputs,\n-                initial_states,\n-                mask=mask,\n-                unroll=unroll,\n-                input_length=num_timesteps if unroll else None)\n-\n-            # not updated last timestep:\n-            assert_allclose(K.eval(last_states[0]), expected_last_state)\n-\n-    @pytest.mark.parametrize('shape', [(3, ), (1, 3), (2, 1), (4, 2), (4, 2, 3)])\n-    def test_logsumexp(self, shape):\n-        check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=None)\n-        check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=0)\n-        check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=-1)\n-        check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=-1,\n-                                      keepdims=True)\n-        if len(shape) > 1:\n-            check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=1)\n-            check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=1,\n-                                          keepdims=True)\n-        if len(shape) > 2:\n-            check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=[1, -1])\n-            check_single_tensor_operation('logsumexp', shape, WITH_NP, axis=[1, -1],\n-                                          keepdims=True)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='The optimization is applied only with TensorFlow.')\n-    def test_logsumexp_optim(self):\n-        '''\n-        Check if optimization works.\n-        '''\n-        x_np = np.array([1e+4, 1e-4])\n-        result = K.eval(K.logsumexp(K.variable(x_np), axis=0))\n-        assert_allclose(result, 1e4, rtol=1e-5)\n-\n-    def test_switch(self):\n-        # scalar\n-        val = np.random.random()\n-        z_list = []\n-        for k in WITH_NP:\n-            x = k.variable(val)\n-            x = k.switch(k.greater_equal(x, 0.5), x * 0.1, x * 0.2)\n-            z_list.append(k.eval(x))\n-        assert_list_pairwise(z_list)\n-        # non scalar\n-        shapes = []\n-        shapes.append([(4, 3, 2), (4, 3, 2), (4, 3, 2)])\n-        for s in shapes:\n-            z_list = []\n-            arrays = list(map(np.random.random, s))\n-            for k in WITH_NP:\n-                x, then_expr, else_expr = map(k.variable, arrays)\n-                cond = k.greater_equal(x, 0.5)\n-                z_list.append(k.eval(k.switch(cond, then_expr, else_expr)))\n-            assert_list_pairwise(z_list)\n-\n-    def test_dropout(self):\n-        val = np.random.random((100, 100))\n-        z_list = [k.eval(k.dropout(k.variable(val), level=0.2))\n-                  for k in WITH_NP]\n-        assert_list_pairwise(z_list, allclose=False)\n-        # dropout patterns are different, only check mean\n-        for i in range(len(z_list) - 1):\n-            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05\n-\n-        z_list = [k.eval(k.dropout(k.variable(val), level=0.2,\n-                                   noise_shape=list(val.shape)))\n-                  for k in WITH_NP]\n-        assert_list_pairwise(z_list, allclose=False)\n-        # dropout patterns are different, only check mean\n-        for i in range(len(z_list) - 1):\n-            assert np.abs(z_list[i].mean() - z_list[i + 1].mean()) < 0.05\n-\n-        # Test invalid use cases\n-        with pytest.raises(ValueError):\n-            z = K.dropout(K.variable(val), level=-0.5)\n-\n-    @pytest.mark.parametrize('alpha,max_value,threshold', [\n-        (0.0, None, 0.0),  # standard relu\n-        (0.1, None, 0.0),  # set alpha only\n-        (0.0, 5.0, 0.0),   # set max_value only\n-        (0.0, None, 0.8),  # set threshold only\n-        (0.1, 5.0, 0.0),   # set alpha and max_value\n-        (0.1, None, 0.8),  # set alpha and threshold\n-        (0.0, 5.0, 0.8),   # set max_value and threshold\n-        (0.1, 5.0, 0.8),   # set all\n-        (0.1, 0.0, 0.8),   # max_value is zero\n-        (0.1, 5.0, -2.8),  # threshold is negative\n-        (0.1, 9.0, 0.8),   # max_value > 6\n-    ])\n-    def test_relu(self, alpha, max_value, threshold):\n-        check_single_tensor_operation('relu', (4, 2), WITH_NP, alpha=alpha,\n-                                      max_value=max_value, threshold=threshold)\n-\n-    def test_nn_operations(self):\n-        check_single_tensor_operation('softsign', (4, 10), WITH_NP)\n-        check_single_tensor_operation('softplus', (4, 10), WITH_NP)\n-        check_single_tensor_operation('elu', (4, 10), WITH_NP, alpha=0.5)\n-\n-        check_single_tensor_operation('sigmoid', (4, 2), WITH_NP)\n-        check_single_tensor_operation('hard_sigmoid', (4, 2), WITH_NP)\n-        check_single_tensor_operation('tanh', (4, 2), WITH_NP)\n-\n-        check_single_tensor_operation('softmax', (4, 10), WITH_NP)\n-        check_single_tensor_operation('softmax', (4, 5, 3), WITH_NP, axis=1)\n-        check_single_tensor_operation('softmax', (4, 5, 3, 10), WITH_NP, axis=2)\n-\n-        check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=-1)\n-        check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=1)\n-\n-    def test_crossentropy(self):\n-        # toy label matrix (4 samples, 2 classes)\n-        label = np.array([[.4, .6], [.3, .7], [.1, .9], [.2, .8]], dtype=np.float32)\n-        binary_targets = np.array([[.3, .7], [.2, .8], [.4, .6], [.1, .9]],\n-                                  dtype=np.float32)\n-        categorical_targets = np.array([[1, 0], [1, 0], [0, 1], [0, 1]],\n-                                       dtype=np.float32)\n-        check_two_tensor_operation(\n-            'binary_crossentropy', label, binary_targets, WITH_NP)\n-        check_two_tensor_operation('binary_crossentropy', label, (4, 2),\n-                                   WITH_NP, from_logits=True)\n-        check_two_tensor_operation(\n-            'categorical_crossentropy', label, categorical_targets,\n-            WITH_NP, cntk_two_dynamicity=True)\n-        check_two_tensor_operation('categorical_crossentropy', label, (4, 2),\n-                                   WITH_NP, cntk_two_dynamicity=True,\n-                                   from_logits=True)\n-\n-        # toy label matrix (2 samples, 3 classes)\n-        label = np.array([[.4, .1, .5], [.2, .6, .2]], dtype=np.float32)\n-        categorical_targets = np.array([[0, 1, 0], [1, 0, 0]], dtype=np.float32)\n-        check_two_tensor_operation(\n-            'categorical_crossentropy', label, categorical_targets,\n-            WITH_NP, cntk_two_dynamicity=True)\n-        check_two_tensor_operation('categorical_crossentropy', label, (2, 3),\n-                                   WITH_NP, cntk_two_dynamicity=True,\n-                                   from_logits=True)\n-\n-    def test_in_top_k(self):\n-        batch_size = 20\n-        num_classes = 10\n-\n-        # Random prediction test case\n-        predictions = np.random.random((batch_size, num_classes)).astype('float32')\n-        targets = np.random.randint(num_classes, size=batch_size, dtype='int32')\n-\n-        # (k == 0 or k > num_classes) does not raise an error\n-        # but just return an unmeaningful tensor.\n-        for k in range(1, 2 if K.backend() == 'cntk' else (num_classes + 1)):\n-            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),\n-                                        b.variable(targets, dtype='int32'), k))\n-                      for b in WITH_NP]\n-            assert_list_pairwise(z_list)\n-\n-        # Identical prediction test case:\n-        # randomly set half of the predictions to an identical value\n-        num_identical = num_classes // 2\n-        for i in range(batch_size):\n-            idx_identical = np.random.choice(num_classes,\n-                                             size=num_identical, replace=False)\n-            predictions[i, idx_identical] = predictions[i, 0]\n-        targets = np.zeros(batch_size, dtype='int32')\n-\n-        for k in range(1, 2 if K.backend() == 'cntk' else (num_classes + 1)):\n-            z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),\n-                                        b.variable(targets, dtype='int32'), k))\n-                      for b in WITH_NP]\n-            assert_list_pairwise(z_list)\n-\n-    @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [\n-        ('conv1d', (2, 8, 2), (3, 2, 3), 'same', 'channels_last'),\n-        ('conv1d', (1, 8, 2), (3, 2, 3), 'valid', 'channels_last'),\n-        ('conv1d', (1, 2, 8), (3, 2, 3), 'valid', 'channels_first'),\n-        ('conv2d', (2, 3, 4, 5), (3, 3, 3, 2), 'same', 'channels_first'),\n-        ('conv2d', (2, 3, 5, 6), (4, 3, 3, 4), 'valid', 'channels_first'),\n-        ('conv2d', (1, 6, 5, 3), (3, 4, 3, 2), 'valid', 'channels_last'),\n-        ('conv2d', (1, 7, 6, 3), (3, 3, 3, 4), 'same', 'channels_last'),\n-        ('conv3d', (2, 3, 4, 5, 4), (3, 3, 3, 3, 4), 'same', 'channels_first'),\n-        ('conv3d', (2, 3, 5, 4, 6), (3, 2, 4, 3, 4), 'valid', 'channels_first'),\n-        ('conv3d', (1, 2, 2, 2, 1), (2, 2, 2, 1, 1), 'valid', 'channels_last'),\n-        ('conv3d', (1, 3, 5, 4, 2), (3, 3, 3, 2, 3), 'same', 'channels_last'),\n-    ])\n-    def test_conv(self, op, input_shape, kernel_shape, padding, data_format):\n-        check_two_tensor_operation(\n-            op, input_shape, kernel_shape, WITH_NP,\n-            padding=padding, data_format=data_format,\n-            cntk_dynamicity=True)\n-\n-    @pytest.mark.parametrize(\n-        'op,input_shape,kernel_shape,output_shape,padding,data_format', [\n-            ('conv2d_transpose', (2, 5, 6, 3), (3, 3, 2, 3), (2, 5, 6, 2),\n-             'same', 'channels_last'),\n-            ('conv2d_transpose', (2, 3, 8, 9), (3, 3, 2, 3), (2, 2, 8, 9),\n-             'same', 'channels_first'),\n-        ])\n-    def test_conv_transpose(self,\n-                            op,\n-                            input_shape,\n-                            kernel_shape,\n-                            output_shape,\n-                            padding,\n-                            data_format):\n-        check_two_tensor_operation(\n-            op, input_shape, kernel_shape, WITH_NP,\n-            output_shape=output_shape, padding=padding, data_format=data_format,\n-            cntk_dynamicity=True)\n-\n-    @pytest.mark.skipif((K.backend() == 'cntk' and KC.dev.type() == 0),\n-                        reason='cntk only supports dilated conv on GPU')\n-    @pytest.mark.parametrize(\n-        'op,input_shape,kernel_shape,padding,data_format,dilation_rate', [\n-            ('conv1d', (2, 8, 3), (4, 3, 2), 'valid', 'channels_last', 2),\n-            ('conv1d', (2, 3, 8), (4, 3, 2), 'valid', 'channels_first', 2),\n-            ('conv2d', (2, 8, 9, 3), (3, 3, 3, 2),\n-             'same', 'channels_last', (2, 2)),\n-            ('conv2d', (2, 3, 9, 8), (4, 3, 3, 4),\n-             'valid', 'channels_first', (2, 2)),\n-            ('conv3d', (2, 5, 4, 6, 3), (2, 2, 3, 3, 4),\n-             'valid', 'channels_last', (2, 2, 2)),\n-            ('conv3d', (2, 3, 5, 4, 6), (2, 2, 3, 3, 4),\n-             'same', 'channels_first', (2, 2, 2)),\n-        ])\n-    def test_dilated_conv(self,\n-                          op,\n-                          input_shape,\n-                          kernel_shape,\n-                          padding,\n-                          data_format,\n-                          dilation_rate):\n-        check_two_tensor_operation(\n-            op, input_shape, kernel_shape, WITH_NP,\n-            padding=padding, data_format=data_format,\n-            dilation_rate=dilation_rate, cntk_dynamicity=True)\n-\n-    @pytest.mark.skipif((K.backend() == 'cntk' and KC.dev.type() == 0),\n-                        reason='cntk only supports dilated conv transpose on GPU')\n-    @pytest.mark.parametrize(\n-        'op,input_shape,kernel_shape,output_shape,padding,data_format,dilation_rate',\n-        [\n-            ('conv2d_transpose', (2, 5, 6, 3), (3, 3, 2, 3), (2, 5, 6, 2),\n-             'same', 'channels_last', (2, 2)),\n-            ('conv2d_transpose', (2, 3, 8, 9), (3, 3, 2, 3), (2, 2, 8, 9),\n-             'same', 'channels_first', (2, 2)),\n-        ])\n-    def test_dilated_conv_transpose(self,\n-                                    op,\n-                                    input_shape,\n-                                    kernel_shape,\n-                                    output_shape,\n-                                    padding,\n-                                    data_format,\n-                                    dilation_rate):\n-        check_two_tensor_operation(\n-            op, input_shape, kernel_shape, WITH_NP, output_shape=output_shape,\n-            padding=padding, data_format=data_format, dilation_rate=dilation_rate,\n-            cntk_dynamicity=True)\n-\n-    @pytest.mark.parametrize('op,input_shape,kernel_shape,padding,data_format', [\n-        ('depthwise_conv2d', (2, 3, 4, 5), (3, 3, 3, 2), 'same', 'channels_first'),\n-        ('depthwise_conv2d', (2, 3, 5, 6), (4, 3, 3, 4), 'valid', 'channels_first'),\n-        ('depthwise_conv2d', (1, 6, 5, 3), (3, 4, 3, 2), 'valid', 'channels_last'),\n-        ('depthwise_conv2d', (1, 7, 6, 3), (3, 3, 3, 4), 'same', 'channels_last'),\n-    ])\n-    def test_depthwise_conv(self,\n-                            op,\n-                            input_shape,\n-                            kernel_shape,\n-                            padding,\n-                            data_format):\n-        check_two_tensor_operation(\n-            op, input_shape, kernel_shape, WITH_NP,\n-            padding=padding, data_format=data_format,\n-            cntk_dynamicity=True)\n-\n-    @pytest.mark.parametrize(\n-        'op,input_shape,pool_size,strides,padding,data_format,pool_mode', [\n-            ('pool2d', (2, 3, 7, 7), (3, 3), (1, 1),\n-             'same', 'channels_first', 'avg'),\n-            ('pool2d', (3, 3, 8, 5), (2, 3), (1, 1),\n-             'valid', 'channels_first', 'max'),\n-            ('pool2d', (2, 9, 5, 3), (3, 2), (1, 1),\n-             'valid', 'channels_last', 'avg'),\n-            ('pool2d', (3, 6, 7, 3), (3, 3), (1, 1),\n-             'same', 'channels_last', 'max'),\n-            ('pool3d', (2, 3, 7, 7, 7), (3, 3, 3), (1, 1, 1),\n-             'same', 'channels_first', 'avg'),\n-            ('pool3d', (3, 3, 8, 5, 9), (2, 3, 2), (1, 1, 1),\n-             'valid', 'channels_first', 'max'),\n-            ('pool3d', (2, 8, 9, 5, 3), (3, 2, 3), (1, 1, 1),\n-             'valid', 'channels_last', 'avg'),\n-            ('pool3d', (3, 5, 6, 7, 3), (3, 3, 3), (1, 1, 1),\n-             'same', 'channels_last', 'max'),\n-        ])\n-    def test_pool(self,\n-                  op,\n-                  input_shape,\n-                  pool_size,\n-                  strides,\n-                  padding,\n-                  data_format,\n-                  pool_mode):\n-        check_single_tensor_operation(\n-            op, input_shape, WITH_NP,\n-            pool_size=pool_size, strides=strides,\n-            padding=padding, data_format=data_format, pool_mode=pool_mode,\n-            cntk_dynamicity=True)\n-\n-    @pytest.mark.parametrize(\n-        'op,input_shape,kernel_shape,depth_multiplier,padding,data_format', [\n-            ('separable_conv1d', (2, 8, 2), (3,), 1, 'same', 'channels_last'),\n-            ('separable_conv1d', (1, 8, 2), (3,), 2, 'valid', 'channels_last'),\n-            ('separable_conv2d', (2, 3, 4, 5), (3, 3), 1, 'same', 'channels_first'),\n-            ('separable_conv2d', (2, 3, 5, 6), (4, 3), 2, 'valid', 'channels_first'),\n-            ('separable_conv2d', (1, 6, 5, 3), (3, 4), 1, 'valid', 'channels_last'),\n-            ('separable_conv2d', (1, 7, 6, 3), (3, 3), 2, 'same', 'channels_last'),\n-        ])\n-    def test_separable_conv(self,\n-                            op,\n-                            input_shape,\n-                            kernel_shape,\n-                            depth_multiplier,\n-                            padding,\n-                            data_format):\n-        if data_format == 'channels_first':\n-            input_depth = input_shape[1]\n-        else:\n-            input_depth = input_shape[-1]\n-        _, x = parse_shape_or_val(input_shape)\n-        _, depthwise = parse_shape_or_val(kernel_shape +\n-                                          (input_depth, depth_multiplier))\n-        _, pointwise = parse_shape_or_val((1,) * len(kernel_shape) +\n-                                          (input_depth * depth_multiplier, 7))\n-        y1 = KNP.separable_conv(x, depthwise, pointwise,\n-                                padding=padding, data_format=data_format)\n-        if K.backend() == 'cntk':\n-            _, cntk_func = cntk_func_tensors(\n-                op, [input_shape, depthwise, pointwise],\n-                padding=padding, data_format=data_format)\n-            y2 = cntk_func([x])[0]\n-        else:\n-            y2 = K.eval(getattr(K, op)(\n-                K.variable(x),\n-                K.variable(depthwise), K.variable(pointwise),\n-                padding=padding, data_format=data_format))\n-        assert_allclose(y1, y2, atol=1e-05)\n-\n-    def test_random_normal(self):\n-        # TODO: make this a parameterized test\n-        for mean, std in [(0., 1.), (-10., 5.)]:\n-            rand = K.eval(K.random_normal((200, 200),\n-                                          mean=mean,\n-                                          stddev=std))\n-            assert rand.shape == (200, 200)\n-            assert np.abs(np.mean(rand) - mean) < std * 0.015\n-            assert np.abs(np.std(rand) - std) < std * 0.015\n-\n-    def test_random_uniform(self):\n-        min_val = -1.\n-        max_val = 1.\n-        rand = K.eval(K.random_uniform((200, 200), min_val, max_val))\n-        assert rand.shape == (200, 200)\n-        assert np.abs(np.mean(rand)) < 0.015\n-        assert max_val - 0.015 < np.max(rand) <= max_val\n-        assert min_val + 0.015 > np.min(rand) >= min_val\n-\n-    def test_random_binomial(self):\n-        p = 0.5\n-        rand = K.eval(K.random_binomial((200, 200), p))\n-        assert rand.shape == (200, 200)\n-        assert np.abs(np.mean(rand) - p) < 0.015\n-        assert np.max(rand) == 1\n-        assert np.min(rand) == 0\n-\n-    def test_truncated_normal(self):\n-        mean = 0.\n-        std = 1.\n-        min_val = -2.\n-        max_val = 2.\n-        rand = K.eval(K.truncated_normal((200, 200),\n-                                         mean=mean,\n-                                         stddev=std))\n-        assert rand.shape == (200, 200)\n-        assert np.abs(np.mean(rand) - mean) < 0.016\n-        assert np.max(rand) <= max_val\n-        assert np.min(rand) >= min_val\n-\n-        # assumption in initializers.VarianceScaling\n-        assert np.abs(np.std(rand) - std * 0.87962) < 0.015\n-\n-    def test_conv_invalid_use(self):\n-        dummy_x_1d = K.variable(np.ones((4, 8, 2)))\n-        dummy_w_1d = K.variable(np.ones((3, 2, 3)))\n-        dummy_x_2d = K.variable(np.ones((2, 3, 4, 5)))\n-        dummy_w_2d = K.variable(np.ones((2, 2, 3, 4)))\n-        dummy_x_3d = K.variable(np.ones((2, 3, 4, 5, 4)))\n-        dummy_w_3d = K.variable(np.ones((2, 2, 2, 3, 4)))\n-        dummy_w1x1_2d = K.variable(np.ones((1, 1, 12, 7)))\n-\n-        with pytest.raises(ValueError):\n-            K.conv1d(dummy_x_1d, dummy_w_1d, data_format='channels_middle')\n-\n-        with pytest.raises(ValueError):\n-            K.conv2d(dummy_x_2d, dummy_w_2d, data_format='channels_middle')\n-\n-        with pytest.raises(ValueError):\n-            K.conv3d(dummy_x_3d, dummy_w_3d, data_format='channels_middle')\n-\n-        with pytest.raises(ValueError):\n-            K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n-                               data_format='channels_middle')\n-\n-        with pytest.raises(ValueError):\n-            K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n-                               data_format='channels_middle')\n-\n-        if K.backend() == 'cntk':\n-            with pytest.raises(ValueError):\n-                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n-                                   dilation_rate=(1, 2))\n-            with pytest.raises(ValueError):\n-                K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n-                                   strides=(2, 2), dilation_rate=(1, 2))\n-            with pytest.raises(ValueError):\n-                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n-                                   dilation_rate=(1, 2))\n-            with pytest.raises(ValueError):\n-                K.depthwise_conv2d(dummy_x_2d, dummy_w_2d,\n-                                   strides=(2, 2), dilation_rate=(1, 2))\n-\n-    def test_pooling_invalid_use(self):\n-        for (input_shape, pool_size) in zip([(5, 10, 12, 3), (5, 10, 12, 6, 3)],\n-                                            [(2, 2), (2, 2, 2)]):\n-            x = K.variable(np.random.random(input_shape))\n-            if len(pool_size) == 2:\n-                with pytest.raises(ValueError):\n-                    K.pool2d(x, pool_size=pool_size, data_format='channels_middle')\n-                with pytest.raises(ValueError):\n-                    K.pool2d(x, pool_size=pool_size, padding='twice')\n-                with pytest.raises(ValueError):\n-                    K.pool2d(x, pool_size=pool_size, pool_mode='median')\n-            else:\n-                with pytest.raises(ValueError):\n-                    K.pool3d(x, pool_size=pool_size, data_format='channels_middle')\n-                with pytest.raises(ValueError):\n-                    K.pool3d(x, pool_size=pool_size, padding='twice')\n-                with pytest.raises(ValueError):\n-                    K.pool3d(x, pool_size=pool_size, pool_mode='median')\n-\n-    def test_resize_images(self):\n-        for data_format in ['channels_first', 'channels_last']:\n-            shape = (5, 5)\n-            if data_format == 'channels_first':\n-                x_shape = (2, 3) + shape\n-            elif data_format == 'channels_last':\n-                x_shape = (2,) + shape + (3,)\n-            check_single_tensor_operation('resize_images', x_shape,\n-                                          WITH_NP, cntk_dynamicity=True,\n-                                          height_factor=2,\n-                                          width_factor=2,\n-                                          data_format=data_format)\n-\n-        # Test invalid use cases\n-        xval = np.random.random(x_shape)\n-        with pytest.raises(ValueError):\n-            K.resize_images(K.variable(xval), 2, 2,\n-                            data_format='channels_middle')\n-\n-    @staticmethod\n-    def _helper_bilinear(data_format, height_factor, width_factor):\n-        x_shape = (2, 3, 4, 5)\n-        check_single_tensor_operation('resize_images', x_shape,\n-                                      [KTF, KTH],\n-                                      height_factor=height_factor,\n-                                      width_factor=width_factor,\n-                                      data_format=data_format,\n-                                      interpolation='bilinear')\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n-    @pytest.mark.parametrize('data_format', ['channels_first', 'channels_last'])\n-    def test_resize_images_bilinear(self, data_format):\n-        self._helper_bilinear(data_format, 2, 2)\n-        with pytest.raises(NotImplementedError):\n-            self._helper_bilinear(data_format, 4, 4)\n-\n-    def test_resize_volumes(self):\n-        for data_format in ['channels_first', 'channels_last']:\n-            shape = (5, 5, 5)\n-            if data_format == 'channels_first':\n-                x_shape = (2, 3) + shape\n-            elif data_format == 'channels_last':\n-                x_shape = (2,) + shape + (3,)\n-            check_single_tensor_operation('resize_volumes', x_shape,\n-                                          WITH_NP, cntk_dynamicity=True,\n-                                          depth_factor=2,\n-                                          height_factor=2,\n-                                          width_factor=2,\n-                                          data_format=data_format)\n-\n-        # Test invalid use cases\n-        xval = np.random.random(x_shape)\n-        with pytest.raises(ValueError):\n-            K.resize_volumes(K.variable(xval), 2, 2, 2,\n-                             data_format='channels_middle')\n-\n-    def test_temporal_padding(self):\n-        check_single_tensor_operation('temporal_padding', (4, 3, 3),\n-                                      WITH_NP)\n-        check_single_tensor_operation('temporal_padding', (2, 3, 4),\n-                                      WITH_NP, padding=(1, 2))\n-\n-    def test_spatial_2d_padding(self):\n-        padding = ((1, 2), (2, 1))\n-        for data_format in ['channels_first', 'channels_last']:\n-            shape = (5, 5)\n-            if data_format == 'channels_first':\n-                x_shape = (1, 3) + shape\n-            else:\n-                x_shape = (1,) + shape + (3,)\n-            check_single_tensor_operation('spatial_2d_padding', x_shape, WITH_NP,\n-                                          padding=padding, data_format=data_format)\n-        # Check handling of dynamic shapes.\n-        if K in [KTF, KTH]:\n-            x = K.placeholder(shape=(1, None, None, 1))\n-            y = K.spatial_2d_padding(x, padding=padding, data_format='channels_last')\n-            assert K.int_shape(y) == (1, None, None, 1)\n-\n-        # Test invalid use cases\n-        xval = np.random.random(x_shape)\n-        with pytest.raises(ValueError):\n-            K.spatial_2d_padding(K.variable(xval), padding=padding,\n-                                 data_format='channels_middle')\n-\n-    def test_spatial_3d_padding(self):\n-        padding = ((1, 2), (2, 1), (1, 2))\n-        for data_format in ['channels_first', 'channels_last']:\n-            shape = (5, 5, 5)\n-            if data_format == 'channels_first':\n-                x_shape = (1, 3) + shape\n-            else:\n-                x_shape = (1,) + shape + (3,)\n-            check_single_tensor_operation('spatial_3d_padding', x_shape, WITH_NP,\n-                                          padding=padding, data_format=data_format)\n-        # Check handling of dynamic shapes.\n-        if K in [KTF, KTH]:\n-            x = K.placeholder(shape=(1, None, None, None, 1))\n-            y = K.spatial_3d_padding(x, padding=padding, data_format='channels_last')\n-            assert K.int_shape(y) == (1, None, None, None, 1)\n-\n-        # Test invalid use cases\n-        xval = np.random.random(x_shape)\n-        with pytest.raises(ValueError):\n-            K.spatial_3d_padding(K.variable(xval), padding=padding,\n-                                 data_format='channels_middle')\n-\n-    def test_bias_add(self):\n-        for data_format in ['channels_first', 'channels_last']:\n-            for shape in [(), (3,), (2, 3), (5, 3, 2)]:\n-                if data_format == 'channels_first':\n-                    x_shape = (1, 4) + shape\n-                else:\n-                    x_shape = (1,) + shape + (4,)\n-                bias_shape = (4,)\n-                check_two_tensor_operation('bias_add', x_shape, bias_shape,\n-                                           WITH_NP, cntk_dynamicity=True,\n-                                           data_format=data_format)\n-\n-            if data_format == 'channels_first':\n-                x_shape = (20, 6, 10)\n-            else:\n-                x_shape = (20, 10, 6)\n-            check_two_tensor_operation('bias_add', x_shape, (10, 6),\n-                                       WITH_NP, cntk_dynamicity=True,\n-                                       data_format=data_format)\n-\n-        # Test invalid use cases\n-        x = K.variable(np.random.random(x_shape))\n-        b = K.variable(np.random.random(bias_shape))\n-        with pytest.raises(ValueError):\n-            K.bias_add(x, b, data_format='channels_middle')\n-\n-    @pytest.mark.skipif(K.backend() == 'theano',\n-                        reason='Theano behaves differently '\n-                               'because of the broadcast.')\n-    @pytest.mark.parametrize('axis', [1, -1])\n-    @pytest.mark.parametrize('x_shape', [(3, 2, 4, 5), (3, 2, 4)])\n-    def test_batch_normalization(self, axis, x_shape):\n-        other_shape = [1] * len(x_shape)\n-        other_shape[axis] = x_shape[axis]\n-        other_shape = tuple(other_shape)\n-        x_np = np.random.random(x_shape)\n-        mean_np = np.random.random(other_shape)\n-        var_np = np.random.random(other_shape)\n-        beta_np = np.random.random(other_shape)\n-        gamma_np = np.random.random(other_shape)\n-        output_tensors = []\n-        output_arrays = []\n-        for k in WITH_NP:\n-            x = k.variable(x_np)\n-            mean = k.variable(mean_np)\n-            var = k.variable(var_np)\n-            beta = k.variable(beta_np)\n-            gamma = k.variable(gamma_np)\n-            output = k.batch_normalization(x, mean, var, beta, gamma, axis=axis)\n-            output_tensors.append(output)\n-            output_arrays.append(k.eval(output))\n-        assert_list_pairwise(output_arrays)\n-        assert_list_keras_shape(output_tensors, output_arrays)\n-\n-    @pytest.mark.skipif(K.backend() != 'theano',\n-                        reason='Specific to Theano.')\n-    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n-    def test_batchnorm_th(self, x_shape):\n-        x_val = np.random.random(x_shape).astype(np.float32)\n-        x = K.variable(x_val)\n-        z, _, _ = K.normalize_batch_in_training(\n-            x, None, None, reduction_axes='per-activation')\n-        z = K.eval(z)\n-        assert z.shape == x_shape\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='Specific to Tensorflow.')\n-    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n-    def test_batchnorm_tf(self, x_shape):\n-        x_val = np.random.random(x_shape).astype(np.float32)\n-        x = K.variable(x_val)\n-        z, _, _ = K.normalize_batch_in_training(\n-            x, None, None, reduction_axes=[0, 1, 2, 3])\n-        z = K.eval(z)\n-        assert z.shape == x_shape\n-\n-    @pytest.mark.skipif(K.backend() != 'cntk', reason='Specific to CNTK.')\n-    @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n-    def test_batchnorm_cntk(self, x_shape):\n-        x_val = np.random.random(x_shape).astype(np.float32)\n-        x = K.placeholder(x_shape)\n-        z, _, _ = K.normalize_batch_in_training(\n-            x, None, None, reduction_axes=[0, 1, 2, 3])\n-        z = K.function([x], [z])([x_val])[0]\n-        assert z.shape == x_shape\n-\n-    # the Theano and TensorFlow CTC code use different methods to ensure\n-    # numerical stability.  The Theano code subtracts out the max\n-    # before the final log, so the results are different but scale\n-    # identically and still train properly\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n-    def test_ctc(self):\n-        if K.backend() == 'theano':\n-            ref = [1.73308, 3.81351]\n-        else:\n-            ref = [3.34211, 5.42262]\n-        # simplified version of TensorFlow's test\n-\n-        label_lens = np.expand_dims(np.asarray([5, 4]), 1)\n-        input_lens = np.expand_dims(np.asarray([5, 5]), 1)  # number of timesteps\n-\n-        # dimensions are batch x time x categories\n-        labels = np.asarray([[0, 1, 2, 1, 0], [0, 1, 1, 0, -1]])\n-        inputs = np.asarray(\n-            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n-              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n-              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n-              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n-              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]],\n-             [[0.30176, 0.28562, 0.0831517, 0.0862751, 0.0816851, 0.161508],\n-              [0.24082, 0.397533, 0.0557226, 0.0546814, 0.0557528, 0.19549],\n-              [0.230246, 0.450868, 0.0389607, 0.038309, 0.0391602, 0.202456],\n-              [0.280884, 0.429522, 0.0326593, 0.0339046, 0.0326856, 0.190345],\n-              [0.423286, 0.315517, 0.0338439, 0.0393744, 0.0339315, 0.154046]]],\n-            dtype=np.float32)\n-\n-        k_labels = K.variable(labels, dtype=\"int32\")\n-        k_inputs = K.variable(inputs, dtype=\"float32\")\n-        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n-        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n-        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens,\n-                                      k_label_lens))\n-        if K.backend() == 'theano':\n-            assert_allclose(res[0, :], ref, atol=1e-05)\n-        else:\n-            assert_allclose(res[:, 0], ref, atol=1e-05)\n-\n-        # test when batch_size = 1, that is, one sample only\n-        # get only first sample from above test case\n-        if K.backend() == 'theano':\n-            ref = [1.73308]\n-        else:\n-            ref = [3.34211]\n-\n-        input_lens = np.expand_dims(np.asarray([5]), 1)\n-        label_lens = np.expand_dims(np.asarray([5]), 1)\n-\n-        labels = np.asarray([[0, 1, 2, 1, 0]])\n-        inputs = np.asarray(\n-            [[[0.633766, 0.221185, 0.0917319, 0.0129757, 0.0142857, 0.0260553],\n-              [0.111121, 0.588392, 0.278779, 0.0055756, 0.00569609, 0.010436],\n-              [0.0357786, 0.633813, 0.321418, 0.00249248, 0.00272882, 0.0037688],\n-              [0.0663296, 0.643849, 0.280111, 0.00283995, 0.0035545, 0.00331533],\n-              [0.458235, 0.396634, 0.123377, 0.00648837, 0.00903441, 0.00623107]]],\n-            dtype=np.float32)\n-\n-        k_labels = K.variable(labels, dtype=\"int32\")\n-        k_inputs = K.variable(inputs, dtype=\"float32\")\n-        k_input_lens = K.variable(input_lens, dtype=\"int32\")\n-        k_label_lens = K.variable(label_lens, dtype=\"int32\")\n-        res = K.eval(K.ctc_batch_cost(k_labels, k_inputs, k_input_lens,\n-                                      k_label_lens))\n-        if K.backend() == 'theano':\n-            assert_allclose(res[0, :], ref, atol=1e-05)\n-        else:\n-            assert_allclose(res[:, 0], ref, atol=1e-05)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='Test adapted from tensorflow.')\n-    def test_ctc_decode_greedy(self):\n-        \"\"\"Test two batch entries - best path decoder.\"\"\"\n-        max_time_steps = 6\n-\n-        seq_len_0 = 4\n-        input_prob_matrix_0 = np.asarray(\n-            [[1.0, 0.0, 0.0, 0.0],  # t=0\n-             [0.0, 0.0, 0.4, 0.6],  # t=1\n-             [0.0, 0.0, 0.4, 0.6],  # t=2\n-             [0.0, 0.9, 0.1, 0.0],  # t=3\n-             [0.0, 0.0, 0.0, 0.0],  # t=4 (ignored)\n-             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n-            dtype=np.float32)\n-\n-        seq_len_1 = 5\n-        # dimensions are time x depth\n-\n-        input_prob_matrix_1 = np.asarray(\n-            [[0.1, 0.9, 0.0, 0.0],  # t=0\n-             [0.0, 0.9, 0.1, 0.0],  # t=1\n-             [0.0, 0.0, 0.1, 0.9],  # t=2\n-             [0.0, 0.9, 0.1, 0.1],  # t=3\n-             [0.9, 0.1, 0.0, 0.0],  # t=4\n-             [0.0, 0.0, 0.0, 0.0]],  # t=5 (ignored)\n-            dtype=np.float32)\n-\n-        # len max_time_steps array of batch_size x depth matrices\n-        inputs = [np.vstack([input_prob_matrix_0[t, :],\n-                             input_prob_matrix_1[t, :]])\n-                  for t in range(max_time_steps)]\n-\n-        # change tensorflow order to keras backend order\n-        inputs = np.asarray(inputs).transpose((1, 0, 2))\n-\n-        # batch_size length vector of sequence_lengths\n-        input_length = np.array([seq_len_0, seq_len_1], dtype=np.int32)\n-\n-        decode_pred_np, log_prob_pred_np = KNP.ctc_decode(inputs,\n-                                                          input_length, greedy=True)\n-        inputs = K.variable(inputs)\n-        input_length = K.variable(input_length)\n-        decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n-                                                        input_length, greedy=True)\n-\n-        assert len(decode_pred_tf) == 1\n-\n-        decode_pred = K.eval(decode_pred_tf[0])\n-        log_prob_pred = K.eval(log_prob_pred_tf)\n-\n-        assert np.alltrue(decode_pred_np == decode_pred)\n-        assert np.allclose(log_prob_pred_np, log_prob_pred)\n-\n-    @pytest.mark.parametrize('shape,start,size', [\n-        ((2, 5), (0, 1), (2, 3)),\n-        ((2, 5), (1, 0), (1, 4)),\n-        ((3, 2, 3), (1, 1, 0), (1, 1, 3)),\n-        ((3, 2, 3), (1, 0, 0), (1, 2, 3)),\n-        ((3, 2, 3), (1, 0, 0), (2, 1, 3)),\n-    ])\n-    def test_slice(self, shape, start, size):\n-        check_single_tensor_operation('slice', shape, WITH_NP,\n-                                      start=start, size=size)\n-        with pytest.raises(ValueError):\n-            K.slice(K.variable(np.random.random(shape)),\n-                    start=[1, 0, 0, 0], size=size)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='Beam search is only implemented with '\n-                               'the TensorFlow backend.')\n-    def test_ctc_decode_beam_search(self):\n-        \"\"\"Test one batch, two beams - hibernating beam search.\"\"\"\n-\n-        depth = 6\n-\n-        seq_len_0 = 5\n-        input_prob_matrix_0 = np.asarray(\n-            [[0.30999, 0.309938, 0.0679938, 0.0673362, 0.0708352, 0.173908],\n-             [0.215136, 0.439699, 0.0370931, 0.0393967, 0.0381581, 0.230517],\n-             [0.199959, 0.489485, 0.0233221, 0.0251417, 0.0233289, 0.238763],\n-             [0.279611, 0.452966, 0.0204795, 0.0209126, 0.0194803, 0.20655],\n-             [0.51286, 0.288951, 0.0243026, 0.0220788, 0.0219297, 0.129878],\n-             # Random entry added in at time=5\n-             [0.155251, 0.164444, 0.173517, 0.176138, 0.169979, 0.160671]],\n-            dtype=np.float32)\n-\n-        # Add arbitrary offset - this is fine\n-        input_prob_matrix_0 = input_prob_matrix_0 + 2.0\n-\n-        # len max_time_steps array of batch_size x depth matrices\n-        inputs = ([input_prob_matrix_0[t, :][np.newaxis, :]\n-                   for t in range(seq_len_0)] +  # Pad to max_time_steps = 8\n-                  2 * [np.zeros((1, depth), dtype=np.float32)])\n-\n-        # Take exponential as we directly apply ctc_decode_beam_search\n-        inputs = np.exp(inputs)\n-\n-        # change tensorflow order to keras backend order\n-        inputs = K.variable(inputs.transpose((1, 0, 2)))\n-\n-        # batch_size length vector of sequence_lengths\n-        input_length = K.variable(np.array([seq_len_0], dtype=np.int32))\n-        # batch_size length vector of log probabilities\n-        log_prob_truth = np.array(\n-            [\n-                -5.811451,  # output beam 0\n-                -6.63339  # output beam 1\n-            ],\n-            np.float32)[np.newaxis, :]\n-\n-        decode_truth = [np.array([1, 0]), np.array([[1]])]\n-\n-        beam_width = 2\n-        top_paths = 2\n-\n-        decode_pred_tf, log_prob_pred_tf = K.ctc_decode(inputs,\n-                                                        input_length,\n-                                                        greedy=False,\n-                                                        beam_width=beam_width,\n-                                                        top_paths=top_paths)\n-\n-        assert len(decode_pred_tf) == top_paths\n-\n-        log_prob_pred = K.eval(log_prob_pred_tf)\n-\n-        for i in range(top_paths):\n-            assert np.alltrue(decode_truth[i] == K.eval(decode_pred_tf[i]))\n-\n-        assert np.allclose(log_prob_truth, log_prob_pred)\n-\n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='Beam search is only implemented with '\n-                               'the TensorFlow backend.')\n-    def test_ctc_decode_beam_search_no_merge(self):\n-        # A simple CTC probability map with some repeating characters,\n-        # shape(batch, input_width, char_count)\n-        # Without merging should be decoded as: \"AABB\", with merging as: \"AB\".\n-        input_prob = np.array([\n-            [  # blank, A ,B\n-                [0, 0, 1],  # blank\n-                [1, 0, 0],  # A\n-                [0, 0, 1],  # blank\n-                [1, 0, 0],  # A\n-                [0, 1, 0],  # B\n-                [0, 0, 1],  # blank\n-                [0, 1, 0]  # B\n-            ]\n-        ])\n-        input_len = np.array(input_prob.shape[0] * [input_prob.shape[1]])\n-\n-        def decode(merge_repeated):\n-            input_prob_tensor = K.placeholder(shape=(None, None, None),\n-                                              dtype='float32')\n-            input_len_tensor = K.placeholder(shape=(None), dtype='int64')\n-            paths_tensors, _ = K.ctc_decode(input_prob_tensor, input_len_tensor,\n-                                            greedy=False, beam_width=1, top_paths=1,\n-                                            merge_repeated=merge_repeated)\n-            decode_func = K.function([input_prob_tensor, input_len_tensor],\n-                                     paths_tensors)\n-            paths = decode_func([input_prob, input_len])\n-            return paths\n-\n-        # merged: A B\n-        assert np.allclose(decode(merge_repeated=True), [np.array([[0, 1]])])\n-        # not merged: A A B B\n-        assert np.allclose(decode(merge_repeated=False), [np.array([[0, 0, 1, 1]])])\n-\n-    def test_one_hot(self):\n-        input_length = 10\n-        num_classes = 20\n-        batch_size = 30\n-        indices = np.random.randint(0, num_classes, size=(batch_size, input_length))\n-        oh = KNP.one_hot(np.int32(indices), num_classes)\n-        koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))\n-        assert np.all(koh == oh)\n-\n-    @pytest.mark.skipif(not supports_sparse,\n-                        reason='Sparse tensors are not supported in cntk '\n-                               'and Theano has some dependency issues for sparse.')\n-    def test_sparse_dot(self):\n-        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n-        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n-        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n-\n-        x_sparse = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n-        x_dense = x_sparse.toarray()\n-\n-        W = np.random.random((5, 4))\n-        t_W = K.variable(W)\n-        k_s = K.eval(K.dot(K.variable(x_sparse), t_W))\n-        k_d = K.eval(K.dot(K.variable(x_dense), t_W))\n-\n-        assert k_s.shape == k_d.shape\n-        assert_allclose(k_s, k_d, atol=1e-05)\n-\n-    @pytest.mark.skipif(not supports_sparse,\n-                        reason='Sparse tensors are not supported in cntk '\n-                               'and Theano has some dependency issues for sparse.')\n-    def test_sparse_concat(self):\n-        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n-        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n-        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n-\n-        x_sparse_1 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n-\n-        x_d = np.array([0, 7, 2, 3], dtype=np.float32)\n-        x_r = np.array([0, 2, 2, 3], dtype=np.int64)\n-        x_c = np.array([4, 3, 2, 3], dtype=np.int64)\n-\n-        x_sparse_2 = sparse.csr_matrix((x_d, (x_r, x_c)), shape=(4, 5))\n-\n-        x_dense_1 = x_sparse_1.toarray()\n-        x_dense_2 = x_sparse_2.toarray()\n-\n-        k_s = K.concatenate([K.variable(x_sparse_1), K.variable(x_sparse_2)])\n-        assert K.is_sparse(k_s)\n-\n-        k_s_d = K.eval(k_s)\n-\n-        k_d = K.eval(K.concatenate([K.variable(x_dense_1), K.variable(x_dense_2)]))\n-\n-        assert k_s_d.shape == k_d.shape\n-        assert_allclose(k_s_d, k_d, atol=1e-05)\n-\n-    @pytest.mark.parametrize('shape,shape2,axis', [\n-        ((5, 2), (7, 2), 0),\n-        ((5, 4, 6), (5, 3, 6), 1),\n-        ((5, 4, 6, 10), (5, 4, 6, 2), 3),\n-        ((5, 4, 6, 3), (5, 4, 6, 2), -1),\n-    ])\n-    def test_concat_operations(self, shape, shape2, axis):\n-        # In stack, each array must have the same shape.\n-        check_two_tensor_operation('stack', shape, shape, WITH_NP,\n-                                   axis=axis, concat_args=True)\n-        check_two_tensor_operation('concatenate', shape, shape2, WITH_NP,\n-                                   axis=axis, concat_args=True)\n-        check_two_tensor_operation('concatenate', shape, shape2, WITH_NP,\n-                                   axis=axis, concat_args=True)\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n-    def test_map(self):\n-        x = np.random.rand(10, 3).astype(np.float32)\n-        vx = K.variable(x)\n-        kx = K.eval(K.map_fn(K.sum, vx))\n-        # make sure we can also walk the indexes in tensorflow which we\n-        # can't without specifying dtype\n-        kx2 = K.eval(K.map_fn(\n-            lambda i: K.sum(vx[i]),\n-            K.arange(10),\n-            dtype=K.floatx()\n-        ))\n-\n-        assert (10,) == kx.shape\n-        assert (10,) == kx2.shape\n-        assert_allclose(x.sum(axis=1), kx, atol=1e-05)\n-        assert_allclose(kx, kx2, atol=1e-05)\n-\n-    def test_foldl(self):\n-        x = np.random.rand(10, 3).astype(np.float32)\n-        kx = K.eval(K.foldl(lambda a, b: a + b, K.variable(x)))\n-\n-        assert (3,) == kx.shape\n-        assert_allclose(x.sum(axis=0), kx, atol=1e-05)\n-\n-    def test_foldr(self):\n-        # This test aims to make sure that we walk the array from right to left\n-        # and checks it in the following way: multiplying left to right 1e-40\n-        # cannot be held into a float32 so it causes an underflow while from\n-        # right to left we have no such problem and the result is larger\n-        x = np.array([1e-20, 1e-20, 10, 10, 10], dtype=np.float32)\n-        vx = K.variable(x)\n-        p1 = K.eval(K.foldl(lambda a, b: a * b, vx))\n-        p2 = K.eval(K.foldr(lambda a, b: a * b, vx))\n-\n-        assert p1 < p2\n-        assert 9e-38 < p2 <= 1e-37\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk',\n-                        reason='cntk has issues with negative number.')\n-    def test_arange(self):\n-        for test_value in (-20, 0, 1, 10):\n-            a_list = []\n-            dtype_list = []\n-            for k in WITH_NP:\n-                t = k.arange(test_value)\n-                a = k.eval(t)\n-                assert np.array_equal(a, np.arange(test_value))\n-                dtype_list.append(k.dtype(t))\n-                a_list.append(a)\n-\n-            for i in range(len(a_list) - 1):\n-                assert np.array_equal(a_list[i], a_list[i + 1])\n-\n-        for start, stop, step in ((0, 5, 1), (-5, 5, 2), (0, 1, 2)):\n-            a_list = []\n-            for k in WITH_NP:\n-                a = k.eval(k.arange(start, stop, step))\n-                assert np.array_equal(a, np.arange(start, stop, step))\n-                a_list.append(a)\n-            for i in range(len(a_list) - 1):\n-                assert np.array_equal(a_list[i], a_list[i + 1])\n-\n-        for dtype in ('int32', 'int64', 'float32', 'float64'):\n-            for k in WITH_NP:\n-                t = k.arange(10, dtype=dtype)\n-                assert k.dtype(t) == dtype\n-\n-        start = K.constant(1, dtype='int32')\n-        t = K.arange(start)\n-        assert len(K.eval(t)) == 1\n-\n-        start = K.constant(-1, dtype='int32')\n-        t = K.arange(start)\n-        assert len(K.eval(t)) == 0\n-\n-    @pytest.mark.parametrize('training', [True, False])\n-    def test_in_train_phase(self, training):\n-        check_two_tensor_operation('in_train_phase', (3, 3), (2, 2), WITH_NP,\n-                                   training=training)\n-        check_two_tensor_operation('in_train_phase', (2, 3), (2, 3), WITH_NP,\n-                                   training=training)\n-\n-    @pytest.mark.parametrize('training', [True, False])\n-    def test_in_test_phase(self, training):\n-        check_two_tensor_operation('in_test_phase', (3, 3), (2, 2), WITH_NP,\n-                                   training=training)\n-        check_two_tensor_operation('in_test_phase', (2, 3), (2, 3), WITH_NP,\n-                                   training=training)\n-\n-    @pytest.mark.parametrize('dtype', ['', 'beerfloat', 123])\n-    def test_setfloatx_incorrect_values(self, dtype):\n-        # Keep track of the old value\n-        old_floatx = K.floatx()\n-        with pytest.raises(ValueError):\n-            K.set_floatx(dtype)\n-        assert K.floatx() == old_floatx\n-\n-    @pytest.mark.parametrize('dtype', ['float16', 'float32', 'float64'])\n-    def test_setfloatx_correct_values(self, dtype):\n-        # Keep track of the old value\n-        old_floatx = K.floatx()\n-        # Check correct values\n-        K.set_floatx(dtype)\n-        assert K.floatx() == dtype\n-        # Make sure that changes to the global floatx are effectively\n-        # taken into account by the backend.\n-        check_dtype(K.variable([10]), dtype)\n-        # Restore old value\n-        K.set_floatx(old_floatx)\n-\n-    @pytest.mark.parametrize('dtype', ['float16', 'float32', 'float64'])\n-    def test_dtype(self, dtype):\n-        assert K.dtype(K.variable(1, dtype=dtype)) == dtype\n-\n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported')\n-    def test_variable_support_bool_dtype(self):\n-        assert K.dtype(K.variable(1, dtype='int16')) == 'int16'\n-        assert K.dtype(K.variable(False, dtype='bool')) == 'bool'\n-        with pytest.raises(TypeError):\n-            K.variable('', dtype='unsupported')\n-\n-    @pytest.mark.parametrize('shape', [(4, 2), (2, 3)])\n-    def test_clip_supports_tensor_arguments(self, shape):\n-        # GitHub issue: 11435\n-        _, x = parse_shape_or_val(shape)\n-        _, min_val = parse_shape_or_val(shape)\n-        max_val = min_val + 1.\n-        x_k = K.variable(x)\n-        min_val_k = K.variable(min_val)\n-        max_val_k = K.variable(max_val)\n-        assert np.allclose(K.eval(K.clip(x_k, min_val_k, max_val_k)),\n-                           KNP.eval(KNP.clip(x, min_val, max_val)))\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -370,7 +370,8 @@ def test_TerminateOnNaN():\n                         epochs=20)\n     loss = history.history['loss']\n     assert len(loss) == 1\n-    assert loss[0] == np.inf\n+    assert np.isnan(loss[0])\n+    assert len(history.history) < 20\n \n     history = model.fit_generator(data_generator(X_train, y_train, batch_size),\n                                   len(X_train),\n@@ -379,7 +380,8 @@ def test_TerminateOnNaN():\n                                   epochs=20)\n     loss = history.history['loss']\n     assert len(loss) == 1\n-    assert loss[0] == np.inf or np.isnan(loss[0])\n+    assert np.isnan(loss[0])\n+    assert len(history.history) < 20\n \n \n def test_stop_training_csv(tmpdir):\n@@ -798,7 +800,7 @@ def test_ReduceLROnPlateau_patience():\n     assert all([lr == 1.0 for lr in lrs[:-1]]) and lrs[-1] < 1.0\n \n \n-def test_ReduceLROnPlateau_backwards_compatibility():\n+def DISABLED_test_ReduceLROnPlateau_backwards_compatibility():\n     import warnings\n     with warnings.catch_warnings(record=True) as ws:\n         reduce_on_plateau = callbacks.ReduceLROnPlateau(epsilon=1e-13)\n@@ -865,7 +867,7 @@ def test_CSVLogger(tmpdir):\n     assert not tmpdir.listdir()\n \n \n-def test_CallbackValData():\n+def DISABLED_test_CallbackValData():\n     np.random.seed(1337)\n     (X_train, y_train), (X_test, y_test) = get_data_callbacks()\n     y_test = np_utils.to_categorical(y_test)\n\n@@ -55,7 +55,7 @@ def get_data_callbacks(num_train=train_samples,\n \n \n @pytest.mark.parametrize('update_freq', ['batch', 'epoch', 9])\n-def test_TensorBoard(tmpdir, update_freq):\n+def DISABLED_test_TensorBoard(tmpdir, update_freq):\n     np.random.seed(np.random.randint(1, 1e7))\n     filepath = str(tmpdir / 'logs')\n \n\n@@ -57,7 +57,7 @@ def fake_downloaded_reuters_path(monkeypatch):\n         yield f.name\n \n \n-def test_boston_load_does_not_affect_global_rng(fake_downloaded_boston_path):\n+def DISABLED_test_boston_load_does_not_affect_global_rng(fake_downloaded_boston_path):\n     np.random.seed(1337)\n     before = np.random.randint(0, 100, size=10)\n \n@@ -68,7 +68,7 @@ def test_boston_load_does_not_affect_global_rng(fake_downloaded_boston_path):\n     assert np.array_equal(before, after)\n \n \n-def test_imdb_load_does_not_affect_global_rng(fake_downloaded_imdb_path):\n+def DISABLED_test_imdb_load_does_not_affect_global_rng(fake_downloaded_imdb_path):\n     np.random.seed(1337)\n     before = np.random.randint(0, 100, size=10)\n \n@@ -79,7 +79,7 @@ def test_imdb_load_does_not_affect_global_rng(fake_downloaded_imdb_path):\n     assert np.array_equal(before, after)\n \n \n-def test_reuters_load_does_not_affect_global_rng(fake_downloaded_reuters_path):\n+def DISABLED_test_reuters_load_does_not_affect_global_rng(fake_downloaded_reuters_path):\n     np.random.seed(1337)\n     before = np.random.randint(0, 100, size=10)\n \n\n@@ -9,13 +9,9 @@ from keras.models import Model, Sequential\n from keras import backend as K\n from keras.models import model_from_json, model_from_yaml\n from keras.initializers import Constant\n+from tensorflow.python.keras.saving.hdf5_format import preprocess_weights_for_loading\n \n \n-skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow' or\n-     not K.tensorflow_backend._get_available_gpus()),\n-    reason='Requires TensorFlow backend and a GPU')\n-\n \n def test_get_updates_for():\n     a = Input(shape=(2,))\n@@ -23,18 +19,12 @@ def test_get_updates_for():\n     dense_layer.add_update(0, inputs=a)\n     dense_layer.add_update(1, inputs=None)\n \n-    assert dense_layer.get_updates_for(a) == [0]\n-    assert dense_layer.get_updates_for(None) == [1]\n-\n \n def test_get_losses_for():\n     a = Input(shape=(2,))\n     dense_layer = Dense(1)\n-    dense_layer.add_loss(0, inputs=a)\n-    dense_layer.add_loss(1, inputs=None)\n-\n-    assert dense_layer.get_losses_for(a) == [0]\n-    assert dense_layer.get_losses_for(None) == [1]\n+    dense_layer.add_loss(lambda: 0, inputs=a)\n+    dense_layer.add_loss(lambda: 1, inputs=None)\n \n \n def test_trainable_weights():\n@@ -110,7 +100,7 @@ def test_get_layer():\n         model.get_layer(name='conv')\n \n \n-def test_learning_phase():\n+def DISABLED_test_learning_phase():\n     a = Input(shape=(32,), name='input_a')\n     b = Input(shape=(32,), name='input_b')\n \n@@ -118,24 +108,17 @@ def test_learning_phase():\n     dp = Dropout(0.5, name='dropout')\n     b_2 = dp(b)\n \n-    assert not a_2._uses_learning_phase\n-    assert b_2._uses_learning_phase\n-\n     # test merge\n     m = layers.concatenate([a_2, b_2])\n-    assert m._uses_learning_phase\n \n     # Test recursion\n     model = Model([a, b], [a_2, b_2])\n     print(model.input_spec)\n-    assert model.uses_learning_phase\n \n     c = Input(shape=(32,), name='input_c')\n     d = Input(shape=(32,), name='input_d')\n \n     c_2, b_2 = model([c, d])\n-    assert c_2._uses_learning_phase\n-    assert b_2._uses_learning_phase\n \n     # try actually running graph\n     fn = K.function(model.inputs + [K.learning_phase()], model.outputs)\n@@ -155,17 +138,14 @@ def test_layer_call_arguments():\n     x = layers.Dense(3)(inp)\n     x = layers.Dropout(0.5)(x, training=True)\n     model = Model(inp, x)\n-    assert not model.uses_learning_phase\n \n     # Test that argument is kept when applying the model\n     inp2 = layers.Input(shape=(2,))\n     out2 = model(inp2)\n-    assert not out2._uses_learning_phase\n \n     # Test that argument is kept after loading a model\n     config = model.get_config()\n     model = Model.from_config(config)\n-    assert not model.uses_learning_phase\n \n \n def test_node_construction():\n@@ -175,7 +155,7 @@ def test_node_construction():\n     a = Input(shape=(32,), name='input_a')\n     b = Input(shape=(32,), name='input_b')\n \n-    assert a._keras_shape == (None, 32)\n+    assert tuple(a.shape) == (None, 32)\n     a_layer, a_node_index, a_tensor_index = a._keras_history\n     b_layer, b_node_index, b_tensor_index = b._keras_history\n     assert len(a_layer._inbound_nodes) == 1\n@@ -187,8 +167,6 @@ def test_node_construction():\n     assert node.inbound_layers == []\n     assert isinstance(node.input_tensors, list)\n     assert node.input_tensors == [a]\n-    assert isinstance(node.input_masks, list)\n-    assert node.input_masks == [None]\n     assert isinstance(node.input_shapes, list)\n     assert node.input_shapes == [(None, 32)]\n \n@@ -196,8 +174,6 @@ def test_node_construction():\n     assert node.output_tensors == [a]\n     assert isinstance(node.output_shapes, list)\n     assert node.output_shapes == [(None, 32)]\n-    assert isinstance(node.output_masks, list)\n-    assert node.output_masks == [None]\n \n     dense = Dense(16, name='dense_1')\n     a_2 = dense(a)\n@@ -205,17 +181,11 @@ def test_node_construction():\n \n     assert len(dense._inbound_nodes) == 2\n     assert len(dense._outbound_nodes) == 0\n-    assert dense._inbound_nodes[0].inbound_layers == [a_layer]\n+    assert dense._inbound_nodes[0].inbound_layers == a_layer\n     assert dense._inbound_nodes[0].outbound_layer == dense\n-    assert dense._inbound_nodes[1].inbound_layers == [b_layer]\n+    assert dense._inbound_nodes[1].inbound_layers == b_layer\n     assert dense._inbound_nodes[1].outbound_layer == dense\n \n-    assert dense._inbound_nodes[0].input_tensors == [a]\n-    assert dense._inbound_nodes[1].input_tensors == [b]\n-\n-    assert dense._inbound_nodes[0].get_config()['inbound_layers'] == ['input_a']\n-    assert dense._inbound_nodes[1].get_config()['inbound_layers'] == ['input_b']\n-\n     # test layer properties\n     test_layer = Dense(16, name='test_layer')\n     a_test = test_layer(a)\n@@ -227,14 +197,14 @@ def test_node_construction():\n     assert test_layer.input_shape == (None, 32)\n     assert test_layer.output_shape == (None, 16)\n \n-    with pytest.raises(AttributeError):\n-        dense.input\n-    with pytest.raises(AttributeError):\n-        dense.output\n-    with pytest.raises(AttributeError):\n-        dense.input_mask\n-    with pytest.raises(AttributeError):\n-        dense.output_mask\n+    # with pytest.raises(AttributeError):\n+    #     dense.input\n+    # with pytest.raises(AttributeError):\n+    #     dense.output\n+    # with pytest.raises(AttributeError):\n+    #     dense.input_mask\n+    # with pytest.raises(AttributeError):\n+    #     dense.output_mask\n \n     assert dense.get_input_at(0) is a\n     assert dense.get_input_at(1)is b\n@@ -261,7 +231,7 @@ def test_multi_input_layer():\n     b_2 = dense(b)\n \n     merged = layers.concatenate([a_2, b_2], name='merge')\n-    assert merged._keras_shape == (None, 16 * 2)\n+    assert tuple(merged.shape) == (None, 16 * 2)\n     merge_layer, merge_node_index, merge_tensor_index = merged._keras_history\n \n     assert merge_node_index == 0\n@@ -279,9 +249,9 @@ def test_multi_input_layer():\n     model = Model(inputs=[a, b], outputs=[c, d], name='model')\n     assert len(model.layers) == 6\n     expected_shapes = [(None, 64), (None, 5)]\n-    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n+    assert [tuple(s) for s in model.compute_output_shape([(None, 32), (None, 32)])] == expected_shapes\n     assert model.compute_mask([a, b], [None, None]) == [None, None]\n-    assert model.compute_output_shape([(None, 32), (None, 32)]) == expected_shapes\n+    assert [tuple(s) for s in model.compute_output_shape([(None, 32), (None, 32)])] == expected_shapes\n \n     # we don't check names of first 2 layers (inputs) because\n     # ordering of same-level layers is not fixed\n@@ -340,8 +310,8 @@ def test_recursion():\n \n     # g2, h2 = model([e, f])\n \n-    assert g._keras_shape == c._keras_shape\n-    assert h._keras_shape == d._keras_shape\n+    assert tuple(g.shape) == tuple(c.shape)\n+    assert tuple(h.shape) == tuple(d.shape)\n \n     # test separate manipulation of different layer outputs\n     i = Dense(7, name='dense_4')(h)\n@@ -387,10 +357,10 @@ def test_recursion():\n     p = Input(shape=(32,), name='input_p')\n     q, r = model([o, p])\n \n-    assert n._keras_shape == (None, 5)\n-    assert q._keras_shape == (None, 64)\n+    assert tuple(n.shape) == (None, 5)\n+    assert tuple(q.shape) == (None, 64)\n     s = layers.concatenate([n, q], name='merge_nq')\n-    assert s._keras_shape == (None, 64 + 5)\n+    assert tuple(s.shape) == (None, 64 + 5)\n \n     # test with single output as 1-elem list\n     multi_io_model = Model([j, k, o, p], [s])\n@@ -462,13 +432,6 @@ def test_recursion():\n     with pytest.raises(ValueError):\n         Model([j, k, j], [m, n])\n \n-    # i have not idea what I'm doing: garbage as inputs/outputs\n-    j = Input(shape=(32,), name='input_j')\n-    k = Input(shape=(32,), name='input_k')\n-    m, n = model([j, k])\n-    with pytest.raises(ValueError):\n-        Model([j, k], [m, n, 0])\n-\n     ####################################################\n     # test calling layers/models on placeholders\n     j = Input(shape=(32,), name='input_j')\n@@ -519,7 +482,7 @@ def test_load_layers():\n     weight_tensor_td_conv_old.append(np.zeros((15,)))\n     td_conv_layer = model.layers[1]\n     td_conv_layer.layer.data_format = 'channels_first'\n-    weight_tensor_td_conv_new = saving.preprocess_weights_for_loading(\n+    weight_tensor_td_conv_new = preprocess_weights_for_loading(\n         td_conv_layer,\n         weight_tensor_td_conv_old,\n         original_keras_version='1')\n@@ -538,7 +501,7 @@ def test_load_layers():\n             weights_bi_conv_old.append(np.zeros((10,)))  # bias\n \n     bi_convlstm_layer = model.layers[2]\n-    weights_bi_conv_new = saving.preprocess_weights_for_loading(\n+    weights_bi_conv_new = preprocess_weights_for_loading(\n         bi_convlstm_layer,\n         weights_bi_conv_old,\n         original_keras_version='1')\n@@ -584,7 +547,7 @@ def test_preprocess_weights_for_loading(layer):\n     # A model is needed to initialize weights.\n     _ = Sequential([layer])\n     weights1 = layer.get_weights()\n-    weights2 = saving.preprocess_weights_for_loading(\n+    weights2 = preprocess_weights_for_loading(\n         layer, convert_weights(layer, weights1),\n         original_keras_version='1')\n     assert all([np.allclose(x, y, 1e-5)\n@@ -600,7 +563,7 @@ def test_preprocess_weights_for_loading(layer):\n def test_preprocess_weights_for_loading_for_model(layer):\n     model = Sequential([layer])\n     weights1 = model.get_weights()\n-    weights2 = saving.preprocess_weights_for_loading(\n+    weights2 = preprocess_weights_for_loading(\n         model, convert_weights(layer, weights1),\n         original_keras_version='1')\n     assert all([np.allclose(x, y, 1e-5)\n@@ -621,20 +584,10 @@ def test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, ar\n     # A model is needed to initialize weights.\n     _ = Sequential([layer])\n     weights1 = layer.get_weights()\n-    weights2 = saving.preprocess_weights_for_loading(layer, weights1)\n+    weights2 = preprocess_weights_for_loading(layer, weights1)\n     assert all([np.allclose(x, y, 1e-5) for (x, y) in zip(weights1, weights2)])\n \n \n-@pytest.mark.parametrize('layer_class,args', [\n-    (layers.CuDNNGRU, {'units': 2, 'input_shape': [3, 5]}),\n-    (layers.CuDNNLSTM, {'units': 2, 'input_shape': [3, 5]}),\n-])\n-@skipif_no_tf_gpu\n-def test_preprocess_weights_for_loading_cudnn_rnn_should_be_idempotent(layer_class,\n-                                                                       args):\n-    test_preprocess_weights_for_loading_rnn_should_be_idempotent(layer_class, args)\n-\n-\n def test_recursion_with_bn_and_loss():\n     model1 = Sequential([\n         layers.Dense(5, input_dim=5, activity_regularizer='l1'),\n@@ -642,16 +595,10 @@ def test_recursion_with_bn_and_loss():\n         layers.Dense(5),\n     ])\n \n-    print('NEW MODEL')\n     inputs = layers.Input(shape=(5,))\n     outputs = model1(inputs)\n     model2 = Model(inputs=inputs, outputs=outputs)\n \n-    assert len(model1.updates) == 2\n-    assert len(model2.updates) == 2\n-    assert len(model1.losses) == 1\n-    assert len(model2.losses) == 1, model2.layers[1]._per_input_losses\n-\n     model1.compile(optimizer='sgd', loss='categorical_crossentropy')\n     model2.compile(optimizer='sgd', loss='categorical_crossentropy')\n \n@@ -699,16 +646,6 @@ def test_shared_layer_depth_is_correct():\n     transformed_input2 = Dense(6)(Dense(5)(Dense(3)(embedded_input2)))\n     final_output = Dense(2)(Concatenate()([embedded_input1, transformed_input2]))\n     model = Model(inputs=[input1, input2], outputs=final_output)\n-    input1_depth = -1\n-    input2_depth = -1\n-    for depth, layers in model._layers_by_depth.items():\n-        for layer in layers:\n-            if layer.name == 'input1':\n-                input1_depth = depth\n-            if layer.name == 'input2':\n-                input2_depth = depth\n-    assert input1_depth != -1\n-    assert input1_depth == input2_depth\n \n \n def test_layer_sharing_at_heterogeneous_depth():\n@@ -759,7 +696,7 @@ def test_layer_sharing_at_heterogeneous_depth_with_concat():\n     np.testing.assert_allclose(output_val, output_val_2, atol=1e-6)\n \n \n-def test_layer_sharing_at_heterogeneous_depth_order():\n+def DISABLED_test_layer_sharing_at_heterogeneous_depth_order():\n     # This tests for the bug in this issue\n     # https://github.com/keras-team/keras/issues/11159\n     # It occurs with layer sharing at heterogeneous depth when\n\n@@ -14,7 +14,6 @@ from keras import metrics\n from keras.layers import Layer, Activation, Dense, Dropout, Conv2D, Concatenate\n from keras.engine import Input\n from keras.engine.training import Model\n-from keras.engine import training_utils\n from keras.utils.generic_utils import slice_arrays\n from keras.models import Sequential\n from keras import backend as K\n@@ -97,7 +96,7 @@ def threadsafe_generator(f):\n     return g\n \n \n-def test_check_array_length_consistency():\n+def DISABLED_test_check_array_length_consistency():\n     training_utils.check_array_length_consistency(None, None, None)\n     a_np = np.random.random((4, 3, 3))\n     training_utils.check_array_length_consistency(a_np, a_np, a_np)\n@@ -138,7 +137,7 @@ def testslice_arrays():\n     slice_arrays(input_a, stop=2)\n \n \n-def test_weighted_masked_objective():\n+def DISABLED_test_weighted_masked_objective():\n     a = Input(shape=(3,), name='input_a')\n \n     # weighted_masked_objective\n@@ -410,67 +409,67 @@ def test_model_methods():\n     with pytest.raises(ValueError):\n         out = model.predict([None, input_a_np, input_b_np])\n \n-    # all input/output/weight arrays should have the same number of samples.\n-    with pytest.raises(ValueError):\n-        out = model.train_on_batch([input_a_np, input_b_np[:2]],\n-                                   [output_a_np, output_b_np],\n-                                   sample_weight=sample_weight)\n-    with pytest.raises(ValueError):\n-        out = model.train_on_batch([input_a_np, input_b_np],\n-                                   [output_a_np, output_b_np[:2]],\n-                                   sample_weight=sample_weight)\n-    with pytest.raises(ValueError):\n-        out = model.train_on_batch([input_a_np, input_b_np],\n-                                   [output_a_np, output_b_np],\n-                                   sample_weight=[sample_weight[1],\n-                                                  sample_weight[1][:2]])\n+    # # all input/output/weight arrays should have the same number of samples.\n+    # with pytest.raises(ValueError):\n+    #     out = model.train_on_batch([input_a_np, input_b_np[:2]],\n+    #                                [output_a_np, output_b_np],\n+    #                                sample_weight=sample_weight)\n+    # with pytest.raises(ValueError):\n+    #     out = model.train_on_batch([input_a_np, input_b_np],\n+    #                                [output_a_np, output_b_np[:2]],\n+    #                                sample_weight=sample_weight)\n+    # with pytest.raises(ValueError):\n+    #     out = model.train_on_batch([input_a_np, input_b_np],\n+    #                                [output_a_np, output_b_np],\n+    #                                sample_weight=[sample_weight[1],\n+    #                                               sample_weight[1][:2]])\n \n-    # `sample_weight` is neither a dict nor a list.\n-    with pytest.raises(TypeError):\n-        out = model.train_on_batch([input_a_np, input_b_np],\n-                                   [output_a_np, output_b_np],\n-                                   sample_weight=tuple(sample_weight))\n+    # # `sample_weight` is neither a dict nor a list.\n+    # with pytest.raises(TypeError):\n+    #     out = model.train_on_batch([input_a_np, input_b_np],\n+    #                                [output_a_np, output_b_np],\n+    #                                sample_weight=tuple(sample_weight))\n \n-    # `validation_data` is neither a tuple nor a triple.\n-    with pytest.raises(ValueError):\n-        out = model.fit([input_a_np, input_b_np],\n-                        [output_a_np, output_b_np],\n-                        epochs=1, batch_size=4,\n-                        validation_data=([input_a_np, input_b_np],))\n+    # # `validation_data` is neither a tuple nor a triple.\n+    # with pytest.raises(ValueError):\n+    #     out = model.fit([input_a_np, input_b_np],\n+    #                     [output_a_np, output_b_np],\n+    #                     epochs=1, batch_size=4,\n+    #                     validation_data=([input_a_np, input_b_np],))\n \n-    # `loss` does not match outputs.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n+    # # `loss` does not match outputs.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss=['mse', 'mae', 'mape'])\n \n-    # `loss_weights` does not match output_names.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n+    # # `loss_weights` does not match output_names.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss='mse', loss_weights={'lstm': 0.5})\n \n-    # `loss_weights` does not match outputs.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss='mse', loss_weights=[0.5])\n+    # # `loss_weights` does not match outputs.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss='mse', loss_weights=[0.5])\n \n-    # `loss_weights` is invalid type.\n-    with pytest.raises(TypeError):\n-        model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n+    # # `loss_weights` is invalid type.\n+    # with pytest.raises(TypeError):\n+    #     model.compile(optimizer, loss='mse', loss_weights=(0.5, 0.5))\n \n-    # `sample_weight_mode` does not match output_names.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss='mse',\n-                      sample_weight_mode={'lstm': 'temporal'})\n+    # # `sample_weight_mode` does not match output_names.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss='mse',\n+    #                   sample_weight_mode={'lstm': 'temporal'})\n \n-    # `sample_weight_mode` does not match output_names.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n+    # # `sample_weight_mode` does not match output_names.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss='mse', sample_weight_mode=['temporal'])\n \n-    # `sample_weight_mode` matches output_names partially.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss='mse',\n-                      sample_weight_mode={'dense_1': 'temporal'})\n+    # # `sample_weight_mode` matches output_names partially.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss='mse',\n+    #                   sample_weight_mode={'dense_1': 'temporal'})\n \n-    # `loss` does not exist.\n-    with pytest.raises(ValueError):\n-        model.compile(optimizer, loss=[])\n+    # # `loss` does not exist.\n+    # with pytest.raises(ValueError):\n+    #     model.compile(optimizer, loss=[])\n \n     model.compile(optimizer, loss=['mse', 'mae'])\n     model.compile(optimizer, loss='mse', loss_weights={'dense_1': 0.2,\n@@ -488,16 +487,16 @@ def test_model_methods():\n                   sample_weight_mode={'dense_1': None, 'dropout': 'temporal'})\n     model.compile(optimizer, loss='mse', sample_weight_mode=[None, 'temporal'])\n \n-    # the rank of output arrays should be at least 3D.\n-    with pytest.raises(ValueError):\n-        out = model.train_on_batch([input_a_np, input_b_np],\n-                                   [output_a_np, output_b_np],\n-                                   sample_weight=sample_weight)\n+    # # the rank of output arrays should be at least 3D.\n+    # with pytest.raises(ValueError):\n+    #     out = model.train_on_batch([input_a_np, input_b_np],\n+    #                                [output_a_np, output_b_np],\n+    #                                sample_weight=sample_weight)\n \n \n # TODO: resolve flakyness issue. Tracked with #11560\n @flaky(rerun_filter=lambda err, *args: issubclass(err[0], AssertionError))\n-def test_fit_generator():\n+def DISABLED_test_fit_generator():\n     model = get_model(num_outputs=2)\n     optimizer = 'rmsprop'\n     loss = 'mse'\n@@ -517,7 +516,8 @@ def test_fit_generator():\n                               callbacks=[tracker_cb])\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(3)) * 5\n-    assert len(val_seq.logs) <= 4 * 5\n+    # print('val_seq.logs', val_seq.logs)\n+    # assert len(val_seq.logs) <= 4 * 5\n \n     tracker_cb = TrackerCallback()\n     val_seq = RandomSequence(4)\n@@ -531,7 +531,7 @@ def test_fit_generator():\n                     callbacks=[tracker_cb])\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(3)) * 5\n-    assert len(val_seq.logs) <= 4 * 5\n+    # assert len(val_seq.logs) <= 4 * 5\n \n     # steps_per_epoch will be equal to len of sequence if it's unspecified\n     tracker_cb = TrackerCallback()\n@@ -544,7 +544,7 @@ def test_fit_generator():\n                               max_queue_size=1)\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(12)) * 5\n-    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n+    # assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n \n     tracker_cb = TrackerCallback()\n     val_seq = RandomSequence(4)\n@@ -556,7 +556,7 @@ def test_fit_generator():\n                     max_queue_size=1)\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(12)) * 5\n-    assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n+    # assert 12 * 5 <= len(val_seq.logs) <= (12 * 5) + 2  # the queue may be full.\n \n     # test for workers = 0\n     tracker_cb = TrackerCallback()\n@@ -568,7 +568,7 @@ def test_fit_generator():\n                               workers=0)\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(12)) * 5\n-    assert len(val_seq.logs) == 12 * 5\n+    # assert len(val_seq.logs) == 12 * 5\n \n     tracker_cb = TrackerCallback()\n     val_seq = RandomSequence(4)\n@@ -582,7 +582,7 @@ def test_fit_generator():\n                     callbacks=[tracker_cb])\n     assert tracker_cb.trained_epochs == [0, 1, 2, 3, 4]\n     assert tracker_cb.trained_batches == list(range(3)) * 5\n-    assert len(val_seq.logs) <= 4 * 5\n+    # assert len(val_seq.logs) <= 4 * 5\n \n     # fit_generator will throw an exception\n     # if steps is unspecified for regular generator\n@@ -633,7 +633,7 @@ def test_fit_generator():\n     assert 3 <= gen_counters[0] <= 12\n \n \n-def test_fit_generator_dynamic_size_sequence_with_workers():\n+def DISABLED_test_fit_generator_dynamic_size_sequence_with_workers():\n     model = get_model(num_outputs=2)\n     optimizer = 'rmsprop'\n     loss = 'mse'\n@@ -697,7 +697,7 @@ def test_fit_generator_dynamic_size_sequence_with_workers():\n     assert tracker_cb.steps_per_epoch_log[0:5] == [202, 101, 51, 26, 13]\n \n \n-def test_fit_generator_dynamic_size_sequence_main_thread():\n+def DISABLED_test_fit_generator_dynamic_size_sequence_main_thread():\n     model = get_model(num_outputs=2)\n     optimizer = 'rmsprop'\n     loss = 'mse'\n@@ -954,7 +954,7 @@ def test_trainable_argument():\n     assert_allclose(out, out_2)\n \n \n-def test_with_list_as_targets():\n+def DISABLED_test_with_list_as_targets():\n     model = Sequential()\n     model.add(Dense(1, input_dim=3, trainable=False))\n     model.compile('rmsprop', 'mse')\n@@ -964,7 +964,7 @@ def test_with_list_as_targets():\n     model.train_on_batch(x, y)\n \n \n-def test_check_not_failing():\n+def DISABLED_test_check_not_failing():\n     a = np.random.random((2, 1, 3))\n     training_utils.check_loss_and_target_compatibility(\n         [a], [losses.categorical_crossentropy], [a.shape])\n@@ -972,7 +972,7 @@ def test_check_not_failing():\n         [a], [losses.categorical_crossentropy], [(2, None, 3)])\n \n \n-def test_check_last_is_one():\n+def DISABLED_test_check_last_is_one():\n     a = np.random.random((2, 3, 1))\n     with pytest.raises(ValueError,\n                        match='You are passing a target array'):\n@@ -980,7 +980,7 @@ def test_check_last_is_one():\n             [a], [losses.CategoricalCrossentropy()], [a.shape])\n \n \n-def test_check_bad_shape():\n+def DISABLED_test_check_bad_shape():\n     a = np.random.random((2, 3, 5))\n     with pytest.raises(ValueError,\n                        match='targets to have the same shape'):\n@@ -990,7 +990,7 @@ def test_check_bad_shape():\n \n @pytest.mark.skipif(K.backend() != 'tensorflow',\n                     reason='Requires TensorFlow backend')\n-def test_model_with_input_feed_tensor():\n+def DISABLED_test_model_with_input_feed_tensor():\n     \"\"\"We test building a model with a TF variable as input.\n     We should be able to call fit, evaluate, predict,\n     by only passing them data for the placeholder inputs\n@@ -1131,7 +1131,7 @@ def test_model_with_input_feed_tensor():\n     assert out.shape == (10 * 3, 4)\n \n \n-def test_model_with_partial_loss():\n+def DISABLED_test_model_with_partial_loss():\n     a = Input(shape=(3,), name='input_a')\n     a_2 = Dense(4, name='dense_1')(a)\n     dp = Dropout(0.5, name='dropout')\n@@ -1149,9 +1149,9 @@ def test_model_with_partial_loss():\n     out = model.train_on_batch(input_a_np, output_a_np)\n     out = model.test_on_batch(input_a_np, output_a_np)\n     # fit\n-    out = model.fit(input_a_np, [output_a_np])\n+    out = model.fit(input_a_np, output_a_np)\n     # evaluate\n-    out = model.evaluate(input_a_np, [output_a_np])\n+    out = model.evaluate(input_a_np, output_a_np)\n \n     # Same without dropout.\n     a = Input(shape=(3,), name='input_a')\n@@ -1167,14 +1167,14 @@ def test_model_with_partial_loss():\n     out = model.train_on_batch(input_a_np, output_a_np)\n     out = model.test_on_batch(input_a_np, output_a_np)\n     # fit\n-    out = model.fit(input_a_np, [output_a_np])\n+    out = model.fit(input_a_np, output_a_np)\n     # evaluate\n-    out = model.evaluate(input_a_np, [output_a_np])\n+    out = model.evaluate(input_a_np, output_a_np)\n \n \n @pytest.mark.skipif((K.backend() == 'cntk'),\n                     reason='cntk does not support external loss yet')\n-def test_model_with_external_loss():\n+def DISABLED_test_model_with_external_loss():\n     # None loss, only regularization loss.\n     a = Input(shape=(3,), name='input_a')\n     a_2 = Dense(4, name='dense_1',\n@@ -1326,7 +1326,7 @@ def test_model_with_external_loss():\n         assert out[1].shape == (10 * 3, 4)\n \n \n-def test_target_tensors():\n+def DISABLED_test_target_tensors():\n     # single-output, as list\n     model = keras.models.Sequential()\n     model.add(keras.layers.Dense(4, input_shape=(4,), name='dense'))\n@@ -1406,7 +1406,7 @@ def test_target_tensors():\n @pytest.mark.skipif(K.backend() == 'tensorflow' and\n                     tf.__version__.startswith('2'),\n                     reason='Cannot have tensors as dict keys in TF2')\n-def test_model_custom_target_tensors():\n+def DISABLED_test_model_custom_target_tensors():\n     a = Input(shape=(3,), name='input_a')\n     b = Input(shape=(3,), name='input_b')\n \n@@ -1467,7 +1467,7 @@ def test_model_custom_target_tensors():\n \n @pytest.mark.skipif(sys.version_info < (3,),\n                     reason='Cannot catch warnings in python 2')\n-def test_trainable_weights_count_consistency():\n+def DISABLED_test_trainable_weights_count_consistency():\n     \"\"\"Tests the trainable weights consistency check of Model.\n \n     This verifies that a warning is shown if model.trainable is modified\n@@ -1589,7 +1589,7 @@ def test_pandas_dataframe():\n \n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')\n-def test_training_and_eval_methods_on_symbolic_tensors_single_io():\n+def DISABLED_test_training_and_eval_methods_on_backend_tensors_single_io():\n     x = keras.layers.Input(shape=(3,), name='input')\n     y = keras.layers.Dense(4, name='dense')(x)\n     model = keras.Model(x, y)\n@@ -1613,7 +1613,7 @@ def test_training_and_eval_methods_on_symbolic_tensors_single_io():\n \n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='Requires TensorFlow')\n-def test_training_and_eval_methods_on_symbolic_tensors_multi_io():\n+def DISABLED_test_training_and_eval_methods_on_backend_tensors_multi_io():\n     a = keras.layers.Input(shape=(3,), name='input_a')\n     b = keras.layers.Input(shape=(3,), name='input_b')\n \n@@ -1706,7 +1706,7 @@ def test_training_and_eval_methods_on_symbolic_tensors_multi_io():\n     model.test_on_batch([input_a_tf, input_b_tf], [output_d_tf, output_e_tf])\n \n \n-def test_model_with_crossentropy_losses_channels_first():\n+def DISABLED_test_model_with_crossentropy_losses_channels_first():\n     \"\"\"Tests use of all crossentropy losses with `channels_first`.\n \n     Tests `sparse_categorical_crossentropy`, `categorical_crossentropy`,\n@@ -1789,7 +1789,7 @@ def test_model_with_crossentropy_losses_channels_first():\n                                           'channels_first and channels_last.'))\n \n \n-def test_dynamic_set_inputs():\n+def DISABLED_test_dynamic_set_inputs():\n     model = Sequential()\n     model.add(Dense(16, input_dim=32))\n     model.add(Activation('relu'))\n@@ -1797,7 +1797,7 @@ def test_dynamic_set_inputs():\n     model2 = Sequential()\n     model2.add(model.layers[-1])\n     model2.add(Dense(8))\n-    preds2 = model2.predict([np.random.random((1, 32))])\n+    preds2 = model2.predict(np.random.random((1, 32)))\n     assert preds2.shape == (1, 8)\n \n     model3 = Model(inputs=model.inputs, outputs=model.outputs)\n@@ -1806,7 +1806,7 @@ def test_dynamic_set_inputs():\n \n     model3.inputs = None\n     model3._set_inputs(model.inputs)\n-    preds3 = model3.predict([np.random.random((1, 32))])\n+    preds3 = model3.predict(np.random.random((1, 32)))\n     assert preds3.shape == (1, 16)\n \n     model3.inputs = None\n@@ -1825,7 +1825,7 @@ def test_dynamic_set_inputs():\n     assert preds4.shape == (1, 19)\n \n \n-def test_sample_weights():\n+def DISABLED_test_sample_weights():\n     y = np.array([0, 1, 0, 0, 2])\n     sample_weights = np.array([0.5, 1., 1., 0., 2.])\n     class_weights = {0: 0.5, 1: 1., 2: 1.5}\n@@ -1909,7 +1909,7 @@ def test_loss_correctness():\n     np.allclose(history.history['loss'], [1., 0.9, 0.8, 0.7, 0.6])\n \n \n-def test_model_metrics_list():\n+def DISABLED_test_model_metrics_list():\n \n     class LayerWithAddMetric(Layer):\n \n@@ -1944,10 +1944,10 @@ def test_model_metrics_list():\n         loss='mse',\n         metrics=[metrics.MeanSquaredError('metric_1')])\n \n-    # Verify that the metrics added using `compile` and `add_metric` API are\n-    # included\n-    for m1, m2 in zip([m.name for m in model._compile_metrics], ['metric_1']):\n-        assert m1 == m2\n+    # # Verify that the metrics added using `compile` and `add_metric` API are\n+    # # included\n+    # for m1, m2 in zip([m.name for m in model._compile_metrics], ['metric_1']):\n+    #     assert m1 == m2\n \n     for m1, m2 in zip(\n             [m.name for m in model.metrics],\n@@ -1976,15 +1976,14 @@ def test_model_metrics_list_in_call():\n     y = np.ones(shape=(10, 2))\n     model.fit(x, y, epochs=2, batch_size=5, validation_data=(x, y))\n \n-    # Verify that the metrics added using `compile` and `add_metric` API are\n-    # included\n-    for m1, m2 in zip([m.name for m in model._compile_metrics], ['metric_1']):\n-        assert m1 == m2\n+    # # Verify that the metrics added using `compile` and `add_metric` API are\n+    # # included\n+    # for m1, m2 in zip([m.name for m in model._compile_metrics], ['metric_1']):\n+    #     assert m1 == m2\n \n-    for m1, m2 in zip(\n-            [m.name for m in model.metrics],\n-            ['metric_1', 'metric_2']):\n-        assert m1 == m2\n+    names = [m.name for m in model.metrics]\n+    assert 'metric_1' in names\n+    assert 'metric_2' in names\n \n \n def test_duplicate_metric_name_in_add_metric():\n@@ -2015,7 +2014,7 @@ def test_add_metric_on_model():\n     y = Dense(1, kernel_initializer='ones', trainable=False)(x)\n     model = Model(x, y)\n     model.add_metric(K.sum(y), name='metric_1')\n-    model.add_metric(metrics.Mean(name='metric_2')(y))\n+    model.add_metric(K.mean(y), name='metric_2')\n     model.compile('sgd', loss='mse', metrics=['mse'])\n \n     inputs = np.ones(shape=(10, 1))\n\n@@ -1,166 +0,0 @@\n-import pytest\n-import numpy as np\n-\n-from keras import initializers\n-from keras import backend as K\n-\n-# 2D tensor test fixture\n-FC_SHAPE = (200, 100)\n-\n-# 4D convolution in th order. This shape has the same effective shape as FC_SHAPE\n-CONV_SHAPE = (25, 25, 20, 20)\n-\n-\n-def _runner(init, shape, target_mean=None, target_std=None,\n-            target_max=None, target_min=None):\n-    variable = K.variable(init(shape))\n-    output = K.get_value(variable)\n-    lim = 3e-2\n-    if target_std is not None:\n-        assert abs(output.std() - target_std) < lim\n-    if target_mean is not None:\n-        assert abs(output.mean() - target_mean) < lim\n-    if target_max is not None:\n-        assert abs(output.max() - target_max) < lim\n-    if target_min is not None:\n-        assert abs(output.min() - target_min) < lim\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_uniform(tensor_shape):\n-    _runner(initializers.RandomUniform(minval=-1, maxval=1), tensor_shape,\n-            target_mean=0., target_max=1, target_min=-1)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_normal(tensor_shape):\n-    _runner(initializers.RandomNormal(mean=0, stddev=1), tensor_shape,\n-            target_mean=0., target_std=1)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_truncated_normal(tensor_shape):\n-    _runner(initializers.TruncatedNormal(mean=0, stddev=1), tensor_shape,\n-            target_mean=0., target_max=2, target_min=-2)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_constant(tensor_shape):\n-    _runner(initializers.Constant(2), tensor_shape,\n-            target_mean=2, target_max=2, target_min=2)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_lecun_uniform(tensor_shape):\n-    fan_in, _ = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(1. / fan_in)\n-    _runner(initializers.lecun_uniform(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_glorot_uniform(tensor_shape):\n-    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(2. / (fan_in + fan_out))\n-    _runner(initializers.glorot_uniform(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_he_uniform(tensor_shape):\n-    fan_in, _ = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(2. / fan_in)\n-    _runner(initializers.he_uniform(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_lecun_normal(tensor_shape):\n-    fan_in, _ = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(1. / fan_in)\n-    _runner(initializers.lecun_normal(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_glorot_normal(tensor_shape):\n-    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(2. / (fan_in + fan_out))\n-    _runner(initializers.glorot_normal(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_he_normal(tensor_shape):\n-    fan_in, _ = initializers._compute_fans(tensor_shape)\n-    std = np.sqrt(2. / fan_in)\n-    _runner(initializers.he_normal(), tensor_shape,\n-            target_mean=0., target_std=std)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_orthogonal(tensor_shape):\n-    _runner(initializers.orthogonal(), tensor_shape,\n-            target_mean=0.)\n-\n-\n-def test_orthogonal_init_does_not_affect_global_rng():\n-    np.random.seed(1337)\n-    before = np.random.randint(0, 100, size=10)\n-\n-    np.random.seed(1337)\n-    init = initializers.orthogonal(seed=9876)\n-    init(shape=(10, 5))\n-    after = np.random.randint(0, 100, size=10)\n-\n-    assert np.array_equal(before, after)\n-\n-\n-@pytest.mark.parametrize('tensor_shape',\n-                         [(100, 100), (10, 20), (30, 80), (1, 2, 3, 4)],\n-                         ids=['FC', 'RNN', 'RNN_INVALID', 'CONV'])\n-def test_identity(tensor_shape):\n-    target_mean = (1. * min(tensor_shape)) / (tensor_shape[0] * tensor_shape[1])\n-    if len(tensor_shape) > 2:\n-        with pytest.raises(ValueError):\n-            _runner(initializers.identity(), tensor_shape,\n-                    target_mean=target_mean, target_max=1.)\n-    else:\n-        _runner(initializers.identity(), tensor_shape,\n-                target_mean=target_mean, target_max=1.)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_zero(tensor_shape):\n-    _runner(initializers.zeros(), tensor_shape,\n-            target_mean=0., target_max=0.)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_one(tensor_shape):\n-    _runner(initializers.ones(), tensor_shape,\n-            target_mean=1., target_max=1.)\n-\n-\n-@pytest.mark.parametrize('initializer',\n-                         [initializers.orthogonal,\n-                          initializers.uniform,\n-                          initializers.normal,\n-                          initializers.truncated_normal,\n-                          initializers.VarianceScaling],\n-                         ids=['orthogonal',\n-                              'uniform',\n-                              'normal',\n-                              'truncated_normal',\n-                              'variance_scaling'])\n-def test_statefulness(initializer):\n-    # Test that calling a same seeded random initializer\n-    # in succession results in different values.\n-    init = initializer(seed=1337)\n-    samples = [init((2, 2)) for _ in range(2)]\n-    samples = [K.get_value(K.variable(x)) for x in samples]\n-    assert np.mean(np.abs(samples[0] - samples[1])) > 0.\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -59,20 +59,6 @@ def test_relu():\n                    input_shape=(2, 3, 4))\n \n \n-@pytest.mark.skipif((K.backend() != 'tensorflow'),\n-                    reason='TF-specific implementation.')\n-def test_relu_tf_ops():\n-    inputs = layers.Input((3,))\n-    # Test that `relu` op gets used.\n-    outputs = layers.ReLU()(inputs)\n-    assert outputs.op.name.lower().endswith('/relu')\n-    # Test that `leakyrelu` op gets used.\n-    outputs = layers.ReLU(negative_slope=0.2)(inputs)\n-    assert outputs.op.name.lower().endswith('/leakyrelu')\n-    # Test that `relu6` op gets used.\n-    outputs = layers.ReLU(max_value=6)(inputs)\n-    assert outputs.op.name.lower().endswith('/relu6')\n-\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -21,7 +21,7 @@ sequence_len = 2\n @pytest.mark.parametrize('data_format', ['channels_first', 'channels_last'])\n @pytest.mark.parametrize('return_sequences', [True, False])\n @pytest.mark.parametrize('use_mask', [True, False])\n-def test_convolutional_recurrent(data_format, return_sequences, use_mask):\n+def DISABLED_test_convolutional_recurrent(data_format, return_sequences, use_mask):\n \n     class Masking5D(Masking):\n         \"\"\"Regular masking layer returns wrong shape of mask for RNN\"\"\"\n\n@@ -6,7 +6,6 @@ from keras.utils.test_utils import layer_test\n from keras import backend as K\n from keras.layers import convolutional\n from keras.models import Sequential\n-from keras.backend import load_backend\n \n \n # TensorFlow does not support full convolution.\n@@ -16,8 +15,6 @@ else:\n     _convolution_paddings = ['valid', 'same']\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n-                    reason='cntk only support dilated conv on GPU')\n @pytest.mark.parametrize(\n     'layer_kwargs,input_length,expected_output',\n     [\n@@ -76,8 +73,6 @@ def test_conv_1d(padding, strides):\n                input_shape=(batch_size, steps, input_dim))\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n-                    reason='cntk only support dilated conv on GPU')\n def test_conv_1d_dilation():\n     batch_size = 2\n     steps = 8\n@@ -94,7 +89,7 @@ def test_conv_1d_dilation():\n                input_shape=(batch_size, steps, input_dim))\n \n \n-def test_conv_1d_channels_first():\n+def DISABLED_test_conv_1d_channels_first():\n     batch_size = 2\n     steps = 8\n     input_dim = 2\n@@ -128,36 +123,10 @@ def test_convolution_2d(strides, padding):\n                        'kernel_size': kernel_size,\n                        'padding': padding,\n                        'strides': strides,\n-                       'data_format': 'channels_first'},\n+                       'data_format': 'channels_last'},\n                input_shape=(num_samples, stack_size, num_row, num_col))\n \n \n-def test_convolution_2d_channels_last():\n-    num_samples = 2\n-    filters = 2\n-    stack_size = 3\n-    num_row = 7\n-    num_col = 6\n-    padding = 'valid'\n-    strides = (2, 2)\n-\n-    layer_test(convolutional.Conv2D,\n-               kwargs={'filters': filters,\n-                       'kernel_size': 3,\n-                       'padding': padding,\n-                       'data_format': 'channels_last',\n-                       'activation': None,\n-                       'kernel_regularizer': 'l2',\n-                       'bias_regularizer': 'l2',\n-                       'activity_regularizer': 'l2',\n-                       'kernel_constraint': 'max_norm',\n-                       'bias_constraint': 'max_norm',\n-                       'strides': strides},\n-               input_shape=(num_samples, num_row, num_col, stack_size))\n-\n-\n-@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n-                    reason='cntk only supports dilated conv on GPU')\n def test_convolution_2d_dilation():\n     num_samples = 2\n     filters = 2\n@@ -213,8 +182,6 @@ def test_conv2d_transpose(padding, out_padding, strides):\n                fixed_batch_size=True)\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n-                    reason='cntk only supports dilated conv transpose on GPU')\n def test_conv2d_transpose_dilation():\n \n     layer_test(convolutional.Conv2DTranspose,\n@@ -343,7 +310,7 @@ def test_separable_conv_1d_additional_args():\n                kwargs={'filters': filters,\n                        'kernel_size': 3,\n                        'padding': padding,\n-                       'data_format': 'channels_first',\n+                       # 'data_format': 'channels_first',\n                        'activation': None,\n                        'depthwise_regularizer': 'l2',\n                        'pointwise_regularizer': 'l2',\n@@ -410,7 +377,7 @@ def test_separable_conv_2d_additional_args():\n                kwargs={'filters': filters,\n                        'kernel_size': 3,\n                        'padding': padding,\n-                       'data_format': 'channels_first',\n+                       # 'data_format': 'channels_first',\n                        'activation': None,\n                        'depthwise_regularizer': 'l2',\n                        'pointwise_regularizer': 'l2',\n@@ -474,7 +441,7 @@ def test_depthwise_conv_2d_additional_args():\n     layer_test(convolutional.DepthwiseConv2D,\n                kwargs={'kernel_size': 3,\n                        'padding': padding,\n-                       'data_format': 'channels_first',\n+                       # 'data_format': 'channels_first',\n                        'activation': None,\n                        'depthwise_regularizer': 'l2',\n                        'bias_regularizer': 'l2',\n@@ -554,7 +521,8 @@ def test_convolution_3d_additional_args():\n      for padding in _convolution_paddings\n      for out_padding in [None, (0, 0, 0), (1, 1, 1)]\n      for strides in [(1, 1, 1), (2, 2, 2)]\n-     for data_format in ['channels_first', 'channels_last']\n+     # for data_format in ['channels_first', 'channels_last']\n+     for data_format in ['channels_last']\n      if (not (padding == 'same' and strides != (1, 1, 1))\n          and not (strides == (1, 1, 1) and out_padding == (1, 1, 1)))]\n )\n@@ -590,7 +558,7 @@ def test_conv3d_transpose_additional_args():\n                kwargs={'filters': filters,\n                        'kernel_size': 3,\n                        'padding': padding,\n-                       'data_format': 'channels_first',\n+                       # 'data_format': 'channels_first',\n                        'activation': None,\n                        'kernel_regularizer': 'l2',\n                        'bias_regularizer': 'l2',\n@@ -757,7 +725,7 @@ def test_zero_padding_2d_correctness(data_format):\n      for data_format in ['channels_first', 'channels_last']\n      for padding in [(2, 2, 2), ((1, 2), (3, 4), (0, 2))]]\n )\n-def test_zero_padding_3d(data_format, padding):\n+def DISABLED_test_zero_padding_3d(data_format, padding):\n     num_samples = 2\n     stack_size = 2\n     input_len_dim1 = 4\n@@ -877,8 +845,6 @@ def test_upsampling_2d(data_format):\n             assert_allclose(np_output, expected_out)\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason='cntk does not support it yet')\n @pytest.mark.parametrize('data_format',\n                          ['channels_first', 'channels_last'])\n def test_upsampling_2d_bilinear(data_format):\n@@ -917,8 +883,6 @@ def test_upsampling_2d_bilinear(data_format):\n                 assert np_output.shape[2] == length_col * input_num_col\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support it yet\")\n @pytest.mark.parametrize('data_format',\n                          ['channels_first', 'channels_last'])\n def test_upsampling_3d(data_format):\n@@ -973,8 +937,6 @@ def test_upsampling_3d(data_format):\n                 assert_allclose(np_output, expected_out)\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason=\"cntk does not support slice to 0 dimension\")\n def test_cropping_1d():\n     num_samples = 2\n     time_length = 4\n@@ -1117,8 +1079,6 @@ def test_cropping_3d():\n         layer = convolutional.Cropping3D(cropping=lambda x: x)\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk'),\n-                    reason='CNTK does not support float64')\n @pytest.mark.parametrize(\n     'input_shape,conv_class',\n     [((2, 4, 2), convolutional.Conv1D),\n\n@@ -198,8 +198,6 @@ def test_lambda():\n                           mask=mask)(i)\n \n         o1, o2 = o\n-        assert o1._keras_shape == (None, 3, 2, 1)\n-        assert o2._keras_shape == (None, 3, 2, 1)\n \n         model = Model(i, o)\n \n@@ -225,9 +223,6 @@ def test_lambda():\n         o = layers.Lambda(function=func,\n                           output_shape=output_shape)(i)\n \n-        assert o[0]._keras_shape == (None, 3, 2, 1)\n-        assert o[1]._keras_shape == (None, 3, 2, 1)\n-\n         o = layers.add(o)\n         model = Model(i, o)\n \n@@ -242,18 +237,6 @@ def test_lambda():\n \n     test_multiple_outputs_no_mask()\n \n-    def test_dtypes():\n-        def func(x):\n-            if K.dtype(x) != 'float16':\n-                raise TypeError('x dtype is not float16, it is', K.dtype(x))\n-            return x\n-\n-        i = layers.Input(shape=(3, 2, 1), dtype='float16')\n-        o = layers.Lambda(func)\n-        _ = o(i)\n-        assert o._input_dtypes == 'float16'\n-    test_dtypes()\n-\n     # test serialization with function\n     def f(x):\n         return x + 1\n@@ -341,14 +324,14 @@ def test_activity_regularization():\n     model.compile('rmsprop', 'mse')\n \n \n-def test_sequential_as_downstream_of_masking_layer():\n+def DISABLED_test_sequential_as_downstream_of_masking_layer():\n \n     inputs = layers.Input(shape=(3, 4))\n     x = layers.Masking(mask_value=0., input_shape=(3, 4))(inputs)\n     s = Sequential()\n     s.add(layers.Dense(5, input_shape=(4,)))\n     s.add(layers.Activation('relu'))\n-    x = layers.wrappers.TimeDistributed(s)(x)\n+    x = layers.TimeDistributed(s)(x)\n     model = Model(inputs=inputs, outputs=x)\n     model.compile(optimizer='rmsprop', loss='mse')\n     model_input = np.random.randint(low=1, high=5, size=(10, 3, 4))\n@@ -360,7 +343,7 @@ def test_sequential_as_downstream_of_masking_layer():\n     mask_outputs = [model.layers[1].compute_mask(model.layers[1].input)]\n     mask_outputs += [model.layers[2].compute_mask(model.layers[2].input,\n                                                   mask_outputs[-1])]\n-    func = K.function([model.input], mask_outputs)\n+    func = K.function([inputs], mask_outputs)\n     mask_outputs_val = func([model_input])\n     assert np.array_equal(mask_outputs_val[0], np.any(model_input, axis=-1))\n     assert np.array_equal(mask_outputs_val[1], np.any(model_input, axis=-1))\n\n@@ -1,384 +0,0 @@\n-import pytest\n-import numpy as np\n-from numpy.testing import assert_allclose\n-import keras\n-import keras.backend as K\n-from keras.utils.test_utils import layer_test\n-import time\n-\n-\n-skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow' or\n-     not K.tensorflow_backend._get_available_gpus()),\n-    reason='Requires TensorFlow backend and a GPU')\n-\n-\n-@skipif_no_tf_gpu\n-def test_cudnn_rnn_canonical_to_params_lstm():\n-    units = 1\n-    input_size = 1\n-    layer = keras.layers.CuDNNLSTM(units)\n-    layer.build((None, None, input_size))\n-\n-    params = layer._canonical_to_params(\n-        weights=[\n-            layer.kernel_i,\n-            layer.kernel_f,\n-            layer.kernel_c,\n-            layer.kernel_o,\n-            layer.recurrent_kernel_i,\n-            layer.recurrent_kernel_f,\n-            layer.recurrent_kernel_c,\n-            layer.recurrent_kernel_o,\n-        ],\n-        biases=[\n-            layer.bias_i_i,\n-            layer.bias_f_i,\n-            layer.bias_c_i,\n-            layer.bias_o_i,\n-            layer.bias_i,\n-            layer.bias_f,\n-            layer.bias_c,\n-            layer.bias_o,\n-        ],\n-    )\n-    ref_params = layer._cudnn_lstm.canonical_to_params(\n-        weights=[\n-            layer.kernel_i,\n-            layer.kernel_f,\n-            layer.kernel_c,\n-            layer.kernel_o,\n-            layer.recurrent_kernel_i,\n-            layer.recurrent_kernel_f,\n-            layer.recurrent_kernel_c,\n-            layer.recurrent_kernel_o,\n-        ],\n-        biases=[\n-            layer.bias_i_i,\n-            layer.bias_f_i,\n-            layer.bias_c_i,\n-            layer.bias_o_i,\n-            layer.bias_i,\n-            layer.bias_f,\n-            layer.bias_c,\n-            layer.bias_o,\n-        ],\n-    )\n-    ref_params_value = keras.backend.get_value(ref_params)\n-    params_value = keras.backend.get_value(params)\n-    diff = np.mean(ref_params_value - params_value)\n-    assert diff < 1e-8\n-\n-\n-@skipif_no_tf_gpu\n-def test_cudnn_rnn_canonical_to_params_gru():\n-    units = 7\n-    input_size = 9\n-    layer = keras.layers.CuDNNGRU(units)\n-    layer.build((None, None, input_size))\n-\n-    ref_params = layer._cudnn_gru.canonical_to_params(\n-        weights=[\n-            layer.kernel_r,\n-            layer.kernel_z,\n-            layer.kernel_h,\n-            layer.recurrent_kernel_r,\n-            layer.recurrent_kernel_z,\n-            layer.recurrent_kernel_h,\n-        ],\n-        biases=[\n-            layer.bias_r_i,\n-            layer.bias_z_i,\n-            layer.bias_h_i,\n-            layer.bias_r,\n-            layer.bias_z,\n-            layer.bias_h,\n-        ],\n-    )\n-    params = layer._canonical_to_params(\n-        weights=[\n-            layer.kernel_r,\n-            layer.kernel_z,\n-            layer.kernel_h,\n-            layer.recurrent_kernel_r,\n-            layer.recurrent_kernel_z,\n-            layer.recurrent_kernel_h,\n-        ],\n-        biases=[\n-            layer.bias_r_i,\n-            layer.bias_z_i,\n-            layer.bias_h_i,\n-            layer.bias_r,\n-            layer.bias_z,\n-            layer.bias_h,\n-        ],\n-    )\n-    ref_params_value = keras.backend.get_value(ref_params)\n-    params_value = keras.backend.get_value(params)\n-    diff = np.mean(ref_params_value - params_value)\n-    assert diff < 1e-8\n-\n-\n-@pytest.mark.parametrize('rnn_type', ['lstm', 'gru'], ids=['LSTM', 'GRU'])\n-@skipif_no_tf_gpu\n-def test_cudnn_rnn_timing(rnn_type):\n-    input_size = 1000\n-    timesteps = 60\n-    units = 256\n-    num_samples = 10000\n-\n-    times = []\n-    for use_cudnn in [True, False]:\n-        start_time = time.time()\n-        inputs = keras.layers.Input(shape=(None, input_size))\n-        if use_cudnn:\n-            if rnn_type == 'lstm':\n-                layer = keras.layers.CuDNNLSTM(units)\n-            else:\n-                layer = keras.layers.CuDNNGRU(units)\n-        else:\n-            if rnn_type == 'lstm':\n-                layer = keras.layers.LSTM(units)\n-            else:\n-                layer = keras.layers.GRU(units)\n-        outputs = layer(inputs)\n-\n-        model = keras.models.Model(inputs, outputs)\n-        model.compile('sgd', 'mse')\n-\n-        x = np.random.random((num_samples, timesteps, input_size))\n-        y = np.random.random((num_samples, units))\n-        model.fit(x, y, epochs=4, batch_size=32)\n-\n-        times.append(time.time() - start_time)\n-\n-    speedup = times[1] / times[0]\n-    print(rnn_type, 'speedup', speedup)\n-    assert speedup > 3\n-\n-\n-@skipif_no_tf_gpu\n-def test_cudnn_rnn_basics():\n-    input_size = 10\n-    timesteps = 6\n-    units = 2\n-    num_samples = 32\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        for return_sequences in [True, False]:\n-            with keras.utils.CustomObjectScope(\n-                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,\n-                     'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):\n-                layer_test(\n-                    layer_class,\n-                    kwargs={'units': units,\n-                            'return_sequences': return_sequences},\n-                    input_shape=(num_samples, timesteps, input_size))\n-        for go_backwards in [True, False]:\n-            with keras.utils.CustomObjectScope(\n-                    {'keras.layers.CuDNNGRU': keras.layers.CuDNNGRU,\n-                     'keras.layers.CuDNNLSTM': keras.layers.CuDNNLSTM}):\n-                layer_test(\n-                    layer_class,\n-                    kwargs={'units': units,\n-                            'go_backwards': go_backwards},\n-                    input_shape=(num_samples, timesteps, input_size))\n-\n-\n-@skipif_no_tf_gpu\n-def test_trainability():\n-    input_size = 10\n-    units = 2\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        layer = layer_class(units)\n-        layer.build((None, None, input_size))\n-        assert len(layer.weights) == 3\n-        assert len(layer.trainable_weights) == 3\n-        assert len(layer.non_trainable_weights) == 0\n-        layer.trainable = False\n-        assert len(layer.weights) == 3\n-        assert len(layer.non_trainable_weights) == 3\n-        assert len(layer.trainable_weights) == 0\n-        layer.trainable = True\n-        assert len(layer.weights) == 3\n-        assert len(layer.trainable_weights) == 3\n-        assert len(layer.non_trainable_weights) == 0\n-\n-\n-@skipif_no_tf_gpu\n-def test_regularizer():\n-    input_size = 10\n-    timesteps = 6\n-    units = 2\n-    num_samples = 32\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        layer = layer_class(units, return_sequences=False,\n-                            input_shape=(timesteps, input_size),\n-                            kernel_regularizer=keras.regularizers.l1(0.01),\n-                            recurrent_regularizer=keras.regularizers.l1(0.01),\n-                            bias_regularizer='l2')\n-        layer.build((None, None, input_size))\n-        assert len(layer.losses) == 3\n-\n-        layer = layer_class(units, return_sequences=False,\n-                            input_shape=(timesteps, input_size),\n-                            activity_regularizer='l2')\n-        assert layer.activity_regularizer\n-        x = keras.backend.variable(np.ones((num_samples,\n-                                            timesteps,\n-                                            input_size)))\n-        layer(x)\n-        assert len(layer.get_losses_for(x)) == 1\n-\n-\n-@skipif_no_tf_gpu\n-def test_return_state():\n-    input_size = 10\n-    timesteps = 6\n-    units = 2\n-    num_samples = 32\n-\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        num_states = 2 if layer_class is keras.layers.CuDNNLSTM else 1\n-\n-        inputs = keras.Input(batch_shape=(num_samples, timesteps, input_size))\n-        layer = layer_class(units, return_state=True, stateful=True)\n-        outputs = layer(inputs)\n-        output, state = outputs[0], outputs[1:]\n-        assert len(state) == num_states\n-        model = keras.models.Model(inputs, state[0])\n-\n-        inputs = np.random.random((num_samples, timesteps, input_size))\n-        state = model.predict(inputs)\n-        np.testing.assert_allclose(\n-            keras.backend.eval(layer.states[0]), state, atol=1e-4)\n-\n-\n-@skipif_no_tf_gpu\n-def test_specify_initial_state_keras_tensor():\n-    input_size = 10\n-    timesteps = 6\n-    units = 2\n-    num_samples = 32\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        num_states = 2 if layer_class is keras.layers.CuDNNLSTM else 1\n-\n-        inputs = keras.Input((timesteps, input_size))\n-        initial_state = [keras.Input((units,)) for _ in range(num_states)]\n-        layer = layer_class(units)\n-        if len(initial_state) == 1:\n-            output = layer(inputs, initial_state=initial_state[0])\n-        else:\n-            output = layer(inputs, initial_state=initial_state)\n-        assert initial_state[0] in layer._inbound_nodes[0].input_tensors\n-\n-        model = keras.models.Model([inputs] + initial_state, output)\n-        model.compile(loss='categorical_crossentropy', optimizer='adam')\n-\n-        inputs = np.random.random((num_samples, timesteps, input_size))\n-        initial_state = [np.random.random((num_samples, units))\n-                         for _ in range(num_states)]\n-        targets = np.random.random((num_samples, units))\n-        model.fit([inputs] + initial_state, targets)\n-\n-\n-@skipif_no_tf_gpu\n-def test_statefulness():\n-    input_size = 10\n-    timesteps = 6\n-    units = 2\n-    num_samples = 32\n-\n-    for layer_class in [keras.layers.CuDNNGRU, keras.layers.CuDNNLSTM]:\n-        model = keras.models.Sequential()\n-        model.add(keras.layers.Embedding(10, input_size,\n-                                         input_length=timesteps,\n-                                         batch_input_shape=(num_samples,\n-                                                            timesteps)))\n-        layer = layer_class(units,\n-                            return_sequences=False,\n-                            stateful=True,\n-                            weights=None)\n-        model.add(layer)\n-        model.compile(optimizer='sgd', loss='mse')\n-        out1 = model.predict(np.ones((num_samples, timesteps)))\n-        assert(out1.shape == (num_samples, units))\n-\n-        # train once so that the states change\n-        model.train_on_batch(np.ones((num_samples, timesteps)),\n-                             np.ones((num_samples, units)))\n-        out2 = model.predict(np.ones((num_samples, timesteps)))\n-\n-        # if the state is not reset, output should be different\n-        assert(out1.max() != out2.max())\n-\n-        # check that output changes after states are reset\n-        # (even though the model itself didn't change)\n-        layer.reset_states()\n-        out3 = model.predict(np.ones((num_samples, timesteps)))\n-        assert(out2.max() != out3.max())\n-\n-        # check that container-level reset_states() works\n-        model.reset_states()\n-        out4 = model.predict(np.ones((num_samples, timesteps)))\n-        assert_allclose(out3, out4, atol=1e-5)\n-\n-        # check that the call to `predict` updated the states\n-        out5 = model.predict(np.ones((num_samples, timesteps)))\n-        assert(out4.max() != out5.max())\n-\n-\n-@skipif_no_tf_gpu\n-def test_cudnnrnn_bidirectional():\n-    rnn = keras.layers.CuDNNGRU\n-    samples = 2\n-    dim = 2\n-    timesteps = 2\n-    output_dim = 2\n-    mode = 'concat'\n-\n-    x = np.random.random((samples, timesteps, dim))\n-    target_dim = 2 * output_dim if mode == 'concat' else output_dim\n-    y = np.random.random((samples, target_dim))\n-\n-    # test with Sequential model\n-    model = keras.Sequential()\n-    model.add(keras.layers.Bidirectional(rnn(output_dim),\n-                                         merge_mode=mode,\n-                                         input_shape=(None, dim)))\n-    model.compile(loss='mse', optimizer='sgd')\n-    model.fit(x, y, epochs=1, batch_size=1)\n-\n-    # test config\n-    model.get_config()\n-    model = keras.models.model_from_json(model.to_json())\n-    model.summary()\n-\n-    # test stacked bidirectional layers\n-    model = keras.Sequential()\n-    model.add(keras.layers.Bidirectional(rnn(output_dim,\n-                                             return_sequences=True),\n-                                         merge_mode=mode,\n-                                         input_shape=(None, dim)))\n-    model.add(keras.layers.Bidirectional(rnn(output_dim), merge_mode=mode))\n-    model.compile(loss='mse', optimizer='sgd')\n-    model.fit(x, y, epochs=1, batch_size=1)\n-\n-    # test with functional API\n-    inputs = keras.Input((timesteps, dim))\n-    outputs = keras.layers.Bidirectional(rnn(output_dim),\n-                                         merge_mode=mode)(inputs)\n-    model = keras.Model(inputs, outputs)\n-    model.compile(loss='mse', optimizer='sgd')\n-    model.fit(x, y, epochs=1, batch_size=1)\n-\n-    # Bidirectional and stateful\n-    inputs = keras.Input(batch_shape=(1, timesteps, dim))\n-    outputs = keras.layers.Bidirectional(rnn(output_dim, stateful=True),\n-                                         merge_mode=mode)(inputs)\n-    model = keras.Model(inputs, outputs)\n-    model.compile(loss='mse', optimizer='sgd')\n-    model.fit(x, y, epochs=1, batch_size=1)\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -32,7 +32,7 @@ def test_embedding():\n @pytest.mark.parametrize('input_shape',\n                          [(3, 4, 5),\n                           (3, 5)])\n-def test_embedding_invalid(input_shape):\n+def DISABLED_test_embedding_invalid(input_shape):\n \n     # len(input_length) should be equal to len(input_shape) - 1\n     with pytest.raises(ValueError):\n\n@@ -13,7 +13,7 @@ def test_merge_add():\n     i2 = layers.Input(shape=(4, 5))\n     i3 = layers.Input(shape=(4, 5))\n     o = layers.add([i1, i2, i3])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2, i3], o)\n \n     add_layer = layers.Add()\n@@ -46,7 +46,7 @@ def test_merge_subtract():\n     i3 = layers.Input(shape=(4, 5))\n     i4 = layers.Input(shape=(3, 5))\n     o = layers.subtract([i1, i2])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2], o)\n \n     subtract_layer = layers.Subtract()\n@@ -79,7 +79,7 @@ def test_merge_multiply():\n     i2 = layers.Input(shape=(4, 5))\n     i3 = layers.Input(shape=(4, 5))\n     o = layers.multiply([i1, i2, i3])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2, i3], o)\n \n     mul_layer = layers.Multiply()\n@@ -98,7 +98,7 @@ def test_merge_average():\n     i1 = layers.Input(shape=(4, 5))\n     i2 = layers.Input(shape=(4, 5))\n     o = layers.average([i1, i2])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2], o)\n \n     avg_layer = layers.Average()\n@@ -116,7 +116,7 @@ def test_merge_maximum():\n     i1 = layers.Input(shape=(4, 5))\n     i2 = layers.Input(shape=(4, 5))\n     o = layers.maximum([i1, i2])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2], o)\n \n     max_layer = layers.Maximum()\n@@ -134,7 +134,7 @@ def test_merge_minimum():\n     i1 = layers.Input(shape=(4, 5))\n     i2 = layers.Input(shape=(4, 5))\n     o = layers.minimum([i1, i2])\n-    assert o._keras_shape == (None, 4, 5)\n+    assert K.int_shape(o) == (None, 4, 5)\n     model = models.Model([i1, i2], o)\n \n     max_layer = layers.Minimum()\n@@ -152,13 +152,13 @@ def test_merge_concatenate():\n     i1 = layers.Input(shape=(None, 5))\n     i2 = layers.Input(shape=(None, 5))\n     o = layers.concatenate([i1, i2], axis=1)\n-    assert o._keras_shape == (None, None, 5)\n+    assert K.int_shape(o) == (None, None, 5)\n     model = models.Model([i1, i2], o)\n \n     i1 = layers.Input(shape=(4, 5))\n     i2 = layers.Input(shape=(4, 5))\n     o = layers.concatenate([i1, i2], axis=1)\n-    assert o._keras_shape == (None, 8, 5)\n+    assert K.int_shape(o) == (None, 8, 5)\n     model = models.Model([i1, i2], o)\n \n     concat_layer = layers.Concatenate(axis=1)\n@@ -190,6 +190,7 @@ def test_merge_concatenate():\n         [i1, i2], [K.variable(x1), K.variable(x2)])).reshape(-1))\n \n     # Test invalid use case\n+    concat_layer = layers.Concatenate(axis=1)\n     with pytest.raises(ValueError):\n         concat_layer.compute_mask([i1, i2], x1)\n     with pytest.raises(ValueError):\n@@ -204,7 +205,7 @@ def test_merge_dot():\n     i1 = layers.Input(shape=(4,))\n     i2 = layers.Input(shape=(4,))\n     o = layers.dot([i1, i2], axes=1)\n-    assert o._keras_shape == (None, 1)\n+    assert K.int_shape(o) == (None, 1)\n     model = models.Model([i1, i2], o)\n \n     dot_layer = layers.Dot(axes=1)\n@@ -222,7 +223,7 @@ def test_merge_dot():\n \n     # Test with negative tuple of axes.\n     o = layers.dot([i1, i2], axes=(-1, -1))\n-    assert o._keras_shape == (None, 1)\n+    assert K.int_shape(o) == (None, 1)\n     model = models.Model([i1, i2], o)\n     out = model.predict([x1, x2])\n     assert out.shape == (2, 1)\n@@ -236,7 +237,7 @@ def test_merge_broadcast():\n     ops = [layers.add, layers.maximum]\n     for op in ops:\n         o = op([i1, i2])\n-        assert o._keras_shape == (None, 4, 5)\n+        assert K.int_shape(o) == (None, 4, 5)\n         model = models.Model([i1, i2], o)\n \n         x1 = np.random.random((2, 4, 5))\n@@ -250,7 +251,7 @@ def test_merge_broadcast():\n     ops = [layers.add, layers.maximum]\n     for op in ops:\n         o = op([i1, i2])\n-        assert o._keras_shape == (None, None, None)\n+        assert K.int_shape(o) == (None, None, None)\n         model = models.Model([i1, i2], o)\n \n         x1 = np.random.random((2, 4, 5))\n@@ -268,7 +269,7 @@ def test_merge_broadcast():\n         ops = [layers.add, layers.maximum]\n         for op in ops:\n             o = op([i1, i2])\n-            assert o._keras_shape == (None, None, None)\n+            assert K.int_shape(o) == (None, None, None)\n             model = models.Model([i1, i2], o)\n \n             x1 = np.random.random((2, 4, 5))\n@@ -284,7 +285,7 @@ def test_masking_concatenate():\n     x1 = layers.Embedding(10, 5, input_length=6, mask_zero=True)(input1)\n     x2 = layers.Embedding(10, 5, input_length=6, mask_zero=True)(input2)\n     x = layers.concatenate([x1, x2])\n-    x = layers.wrappers.TimeDistributed(layers.Dense(3, activation='softmax'))(x)\n+    x = layers.TimeDistributed(layers.Dense(3, activation='softmax'))(x)\n     models.Model(inputs=[input1, input2], outputs=[x])\n \n \n\n@@ -170,7 +170,6 @@ def test_shared_batchnorm():\n \n     x = np.random.normal(loc=5.0, scale=10.0, size=(2, 10))\n     model = Model(x2, y2)\n-    assert len(model.updates) == 2\n     model.compile('sgd', 'mse')\n     model.train_on_batch(x, x)\n \n@@ -178,7 +177,6 @@ def test_shared_batchnorm():\n     x3 = Input(shape=(10,))\n     y3 = model(x3)\n     new_model = Model(x3, y3)\n-    assert len(model.updates) == 2\n     new_model.compile('sgd', 'mse')\n     new_model.train_on_batch(x, x)\n \n@@ -233,10 +231,9 @@ def test_batchnorm_trainable():\n                            np.array([bn_mean]), np.array([bn_std ** 2])])\n         return model\n     # Simulates training-mode with trainable layer. Should use mini-batch statistics.\n-    K.set_learning_phase(1)\n     model = get_model(bn_mean, bn_std)\n     model.compile(loss='mse', optimizer='rmsprop')\n-    out = model.predict(input_4)\n+    out = model(input_4, training=True).numpy()\n     assert_allclose((input_4 - np.mean(input_4)) / np.std(input_4), out, atol=1e-3)\n \n \n\n@@ -2,9 +2,7 @@ import numpy as np\n import pytest\n \n from keras.utils.test_utils import layer_test\n-from keras.layers import pooling\n-from keras.layers import Masking\n-from keras.layers import convolutional\n+from keras import layers\n from keras.models import Sequential\n \n \n@@ -16,7 +14,7 @@ from keras.models import Sequential\n      for data_format in ['channels_first', 'channels_last']]\n )\n def test_maxpooling_1d(padding, stride, data_format):\n-    layer_test(convolutional.MaxPooling1D,\n+    layer_test(layers.MaxPooling1D,\n                kwargs={'strides': stride,\n                        'padding': padding,\n                        'data_format': data_format},\n@@ -29,7 +27,7 @@ def test_maxpooling_1d(padding, stride, data_format):\n )\n def test_maxpooling_2d(strides):\n     pool_size = (3, 3)\n-    layer_test(convolutional.MaxPooling2D,\n+    layer_test(layers.MaxPooling2D,\n                kwargs={'strides': strides,\n                        'padding': 'valid',\n                        'pool_size': pool_size},\n@@ -43,7 +41,7 @@ def test_maxpooling_2d(strides):\n )\n def test_maxpooling_3d(strides, data_format, input_shape):\n     pool_size = (3, 3, 3)\n-    layer_test(convolutional.MaxPooling3D,\n+    layer_test(layers.MaxPooling3D,\n                kwargs={'strides': strides,\n                        'padding': 'valid',\n                        'data_format': data_format,\n@@ -59,7 +57,7 @@ def test_maxpooling_3d(strides, data_format, input_shape):\n      for data_format in ['channels_first', 'channels_last']]\n )\n def test_averagepooling_1d(padding, stride, data_format):\n-    layer_test(convolutional.AveragePooling1D,\n+    layer_test(layers.AveragePooling1D,\n                kwargs={'strides': stride,\n                        'padding': padding,\n                        'data_format': data_format},\n@@ -69,11 +67,10 @@ def test_averagepooling_1d(padding, stride, data_format):\n @pytest.mark.parametrize(\n     'strides,padding,data_format,input_shape',\n     [((2, 2), 'same', None, (3, 5, 6, 4)),\n-     ((2, 2), 'valid', None, (3, 5, 6, 4)),\n-     ((1, 1), 'valid', 'channels_first', (3, 4, 5, 6))]\n+     ((2, 2), 'valid', None, (3, 5, 6, 4))]\n )\n def test_averagepooling_2d(strides, padding, data_format, input_shape):\n-    layer_test(convolutional.AveragePooling2D,\n+    layer_test(layers.AveragePooling2D,\n                kwargs={'strides': strides,\n                        'padding': padding,\n                        'pool_size': (2, 2),\n@@ -89,7 +86,7 @@ def test_averagepooling_2d(strides, padding, data_format, input_shape):\n def test_averagepooling_3d(strides, data_format, input_shape):\n     pool_size = (3, 3, 3)\n \n-    layer_test(convolutional.AveragePooling3D,\n+    layer_test(layers.AveragePooling3D,\n                kwargs={'strides': strides,\n                        'padding': 'valid',\n                        'data_format': data_format,\n@@ -101,8 +98,8 @@ def test_averagepooling_3d(strides, data_format, input_shape):\n     'data_format,pooling_class',\n     [(data_format, pooling_class)\n      for data_format in ['channels_first', 'channels_last']\n-     for pooling_class in [pooling.GlobalMaxPooling1D,\n-                           pooling.GlobalAveragePooling1D]]\n+     for pooling_class in [layers.GlobalMaxPooling1D,\n+                           layers.GlobalAveragePooling1D]]\n )\n def test_globalpooling_1d(data_format, pooling_class):\n     layer_test(pooling_class,\n@@ -113,8 +110,8 @@ def test_globalpooling_1d(data_format, pooling_class):\n def test_globalpooling_1d_supports_masking():\n     # Test GlobalAveragePooling1D supports masking\n     model = Sequential()\n-    model.add(Masking(mask_value=0., input_shape=(3, 4)))\n-    model.add(pooling.GlobalAveragePooling1D())\n+    model.add(layers.Masking(mask_value=0., input_shape=(3, 4)))\n+    model.add(layers.GlobalAveragePooling1D())\n     model.compile(loss='mae', optimizer='adam')\n \n     model_input = np.random.randint(low=1, high=5, size=(2, 3, 4))\n@@ -127,8 +124,8 @@ def test_globalpooling_1d_supports_masking():\n     'data_format,pooling_class',\n     [(data_format, pooling_class)\n      for data_format in ['channels_first', 'channels_last']\n-     for pooling_class in [pooling.GlobalMaxPooling2D,\n-                           pooling.GlobalAveragePooling2D]]\n+     for pooling_class in [layers.GlobalMaxPooling2D,\n+                           layers.GlobalAveragePooling2D]]\n )\n def test_globalpooling_2d(data_format, pooling_class):\n     layer_test(pooling_class,\n@@ -140,8 +137,8 @@ def test_globalpooling_2d(data_format, pooling_class):\n     'data_format,pooling_class',\n     [(data_format, pooling_class)\n      for data_format in ['channels_first', 'channels_last']\n-     for pooling_class in [pooling.GlobalMaxPooling3D,\n-                           pooling.GlobalAveragePooling3D]]\n+     for pooling_class in [layers.GlobalMaxPooling3D,\n+                           layers.GlobalAveragePooling3D]]\n )\n def test_globalpooling_3d(data_format, pooling_class):\n     layer_test(pooling_class,\n\n@@ -49,7 +49,7 @@ def test_dynamic_behavior(layer_class):\n \n \n @rnn_test\n-def test_stateful_invalid_use(layer_class):\n+def DISABLED_test_stateful_invalid_use(layer_class):\n     layer = layer_class(units,\n                         stateful=True,\n                         batch_input_shape=(num_samples,\n@@ -83,10 +83,8 @@ def test_dropout(layer_class):\n         layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n                             input_shape=(timesteps, embedding_dim))\n         y = layer(x)\n-        assert y._uses_learning_phase\n \n         y = layer(x, training=True)\n-        assert not getattr(y, '_uses_learning_phase')\n \n         # Test that dropout is not applied during testing\n         x = np.random.random((num_samples, timesteps, embedding_dim))\n@@ -94,7 +92,6 @@ def test_dropout(layer_class):\n                             unroll=unroll,\n                             input_shape=(timesteps, embedding_dim))\n         model = Sequential([layer])\n-        assert model.uses_learning_phase\n         y1 = model.predict(x)\n         y2 = model.predict(x)\n         assert_allclose(y1, y2)\n@@ -319,8 +316,6 @@ def test_regularizer(layer_class):\n     assert layer.activity_regularizer\n     x = K.variable(np.ones((num_samples, timesteps, embedding_dim)))\n     layer(x)\n-    assert len(layer.cell.get_losses_for(x)) == 0\n-    assert len(layer.get_losses_for(x)) == 1\n \n \n @rnn_test\n@@ -599,7 +594,6 @@ def test_minimal_rnn_cell_non_layer_multiple_states():\n              MinimalRNNCell(16, 8),\n              MinimalRNNCell(32, 16)]\n     layer = recurrent.RNN(cells)\n-    assert layer.cell.state_size == (8, 8, 16, 16, 32, 32)\n     y = layer(x)\n     model = keras.models.Model(x, y)\n     model.compile(optimizer='rmsprop', loss='mse')\n@@ -762,11 +756,9 @@ def test_stacked_rnn_attributes():\n     assert len(layer.trainable_weights) == 3\n     assert len(layer.non_trainable_weights) == 3\n \n-    # Test `get_losses_for`\n     x = keras.Input((None, 5))\n     y = K.sum(x)\n     cells[0].add_loss(y, inputs=x)\n-    assert layer.get_losses_for(x) == [y]\n \n \n def test_stacked_rnn_compute_output_shape():\n@@ -779,7 +771,7 @@ def test_stacked_rnn_compute_output_shape():\n                              (None, 3),\n                              (None, 6),\n                              (None, 6)]\n-    assert output_shape == expected_output_shape\n+    assert [tuple(s) for s in output_shape] == expected_output_shape\n \n     # Test reverse_state_order = True for stacked cell.\n     stacked_cell = recurrent.StackedRNNCells(\n@@ -792,7 +784,7 @@ def test_stacked_rnn_compute_output_shape():\n                              (None, 6),\n                              (None, 3),\n                              (None, 3)]\n-    assert output_shape == expected_output_shape\n+    assert [tuple(s) for s in output_shape] == expected_output_shape\n \n \n @rnn_test\n@@ -807,7 +799,7 @@ def test_batch_size_equal_one(layer_class):\n     model.train_on_batch(x, y)\n \n \n-def test_rnn_cell_with_constants_layer():\n+def DISABLED_test_rnn_cell_with_constants_layer():\n \n     class RNNCellWithConstants(keras.layers.Layer):\n \n@@ -818,7 +810,7 @@ def test_rnn_cell_with_constants_layer():\n \n         def build(self, input_shape):\n             if not isinstance(input_shape, list):\n-                raise TypeError('expects constants shape')\n+                raise TypeError('expects `constants` shape')\n             [input_shape, constant_shape] = input_shape\n             # will (and should) raise if more than one constant passed\n \n@@ -915,7 +907,7 @@ def test_rnn_cell_with_constants_layer():\n     assert_allclose(y_np, y_np_2, atol=1e-4)\n \n \n-def test_rnn_cell_with_constants_layer_passing_initial_state():\n+def DISABLED_test_rnn_cell_with_constants_layer_passing_initial_state():\n \n     class RNNCellWithConstants(keras.layers.Layer):\n \n@@ -1004,14 +996,14 @@ def test_rnn_cell_with_constants_layer_passing_initial_state():\n \n \n @rnn_test\n-def test_rnn_cell_identity_initializer(layer_class):\n-    inputs = Input(shape=(timesteps, embedding_dim))\n-    layer = layer_class(units, recurrent_initializer='identity')\n+def DISABLED_test_rnn_cell_identity_initializer(layer_class):\n+    inputs = Input(shape=(1, 2))\n+    layer = layer_class(2, recurrent_initializer='identity')\n     layer(inputs)\n     recurrent_kernel = layer.get_weights()[1]\n     num_kernels = recurrent_kernel.shape[1] // recurrent_kernel.shape[0]\n     assert np.array_equal(recurrent_kernel,\n-                          np.concatenate([np.identity(units)] * num_kernels, axis=1))\n+                          np.concatenate([np.identity(2)] * num_kernels, axis=1))\n \n \n @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n\n@@ -118,11 +118,6 @@ def test_TimeDistributed():\n     # Assert that mean and variance changed.\n     assert not np.array_equal(td.get_weights()[2], np.array([0, 0]))\n     assert not np.array_equal(td.get_weights()[3], np.array([1, 1]))\n-    # Verify input_map has one mapping from inputs to reshaped inputs.\n-    uid = object_list_uid(model.inputs)\n-    assert len(td._input_map.keys()) == 1\n-    assert uid in td._input_map\n-    assert K.int_shape(td._input_map[uid]) == (None, 2)\n \n \n @pytest.mark.skipif((K.backend() == 'cntk'),\n@@ -142,13 +137,10 @@ def test_TimeDistributed_trainable():\n     x = Input(shape=(3, 2))\n     layer = wrappers.TimeDistributed(layers.BatchNormalization())\n     _ = layer(x)\n-    assert len(layer.updates) == 2\n     assert len(layer.trainable_weights) == 2\n     layer.trainable = False\n-    assert len(layer.updates) == 0\n     assert len(layer.trainable_weights) == 0\n     layer.trainable = True\n-    assert len(layer.updates) == 2\n     assert len(layer.trainable_weights) == 2\n \n \n@@ -367,16 +359,14 @@ def test_Bidirectional_dropout(merge_mode):\n     wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, recurrent_dropout=0.2),\n                                      merge_mode=merge_mode)\n     outputs = to_list(wrapped(inputs, training=True))\n-    assert all(not getattr(x, '_uses_learning_phase') for x in outputs)\n \n     inputs = Input((timesteps, dim))\n     wrapped = wrappers.Bidirectional(rnn(units, dropout=0.2, return_state=True),\n                                      merge_mode=merge_mode)\n     outputs = to_list(wrapped(inputs))\n-    assert all(x._uses_learning_phase for x in outputs)\n \n     model = Model(inputs, outputs)\n-    assert model.uses_learning_phase\n+\n     y1 = to_list(model.predict(X))\n     y2 = to_list(model.predict(X))\n     for x1, x2 in zip(y1, y2):\n@@ -410,7 +400,7 @@ def test_Bidirectional_state_reuse():\n     outputs = model.predict(inputs)\n \n \n-def test_Bidirectional_with_constants():\n+def DISABLED_test_Bidirectional_with_constants():\n     class RNNCellWithConstants(Layer):\n         def __init__(self, units, **kwargs):\n             self.units = units\n@@ -490,7 +480,7 @@ def test_Bidirectional_with_constants():\n     assert_allclose(y_np, y_np_3, atol=1e-4)\n \n \n-def test_Bidirectional_with_constants_layer_passing_initial_state():\n+def DISABLED_test_Bidirectional_with_constants_layer_passing_initial_state():\n     class RNNCellWithConstants(Layer):\n         def __init__(self, units, **kwargs):\n             self.units = units\n@@ -595,16 +585,10 @@ def test_Bidirectional_trainable():\n def test_Bidirectional_updates():\n     x = Input(shape=(3, 2))\n     layer = wrappers.Bidirectional(layers.SimpleRNN(3))\n-    assert len(layer.updates) == 0\n-    assert len(layer.get_updates_for(None)) == 0\n-    assert len(layer.get_updates_for(x)) == 0\n     layer.forward_layer.add_update(0, inputs=x)\n     layer.forward_layer.add_update(1, inputs=None)\n     layer.backward_layer.add_update(0, inputs=x)\n     layer.backward_layer.add_update(1, inputs=None)\n-    assert len(layer.updates) == 4\n-    assert len(layer.get_updates_for(None)) == 2\n-    assert len(layer.get_updates_for(x)) == 2\n \n \n def test_Bidirectional_losses():\n@@ -612,16 +596,10 @@ def test_Bidirectional_losses():\n     layer = wrappers.Bidirectional(\n         layers.SimpleRNN(3, kernel_regularizer='l1', bias_regularizer='l1'))\n     _ = layer(x)\n-    assert len(layer.losses) == 4\n-    assert len(layer.get_losses_for(None)) == 4\n-    assert len(layer.get_losses_for(x)) == 0\n-    layer.forward_layer.add_loss(0, inputs=x)\n-    layer.forward_layer.add_loss(1, inputs=None)\n-    layer.backward_layer.add_loss(0, inputs=x)\n-    layer.backward_layer.add_loss(1, inputs=None)\n-    assert len(layer.losses) == 8\n-    assert len(layer.get_losses_for(None)) == 6\n-    assert len(layer.get_losses_for(x)) == 2\n+    layer.forward_layer.add_loss(lambda: 0)\n+    layer.forward_layer.add_loss(lambda: 1)\n+    layer.backward_layer.add_loss(lambda: 0)\n+    layer.backward_layer.add_loss(lambda: 1)\n \n \n if __name__ == '__main__':\n\n@@ -1,12 +0,0 @@\n-import warnings\r\n-import pytest\r\n-\r\n-\r\n-@pytest.fixture(autouse=True)\r\n-def clear_session_after_test():\r\n-    \"\"\"This wrapper runs for all the tests in the legacy directory (recursively).\r\n-    \"\"\"\r\n-    with warnings.catch_warnings():\r\n-        warnings.filterwarnings('ignore', message=r'(.+) Keras 2 ',\r\n-                                category=UserWarning)\r\n-        yield\r\n\n@@ -1,889 +0,0 @@\n-import pytest\n-import json\n-import keras\n-import keras.backend as K\n-import numpy as np\n-import os\n-\n-\n-def test_dense_legacy_interface():\n-    old_layer = keras.layers.Dense(input_dim=3, output_dim=2, name='d')\n-    new_layer = keras.layers.Dense(2, input_shape=(3,), name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Dense(2, bias=False, init='normal',\n-                                   W_regularizer='l1',\n-                                   W_constraint='maxnorm', name='d')\n-    new_layer = keras.layers.Dense(2, use_bias=False,\n-                                   kernel_initializer='normal',\n-                                   kernel_regularizer='l1',\n-                                   kernel_constraint='max_norm', name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Dense(2, bias=True,\n-                                   b_regularizer='l1',\n-                                   b_constraint='maxnorm', name='d')\n-    new_layer = keras.layers.Dense(2, use_bias=True,\n-                                   bias_regularizer='l1',\n-                                   bias_constraint='max_norm', name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_dropout_legacy_interface():\n-    old_layer = keras.layers.Dropout(p=3, name='drop')\n-    new_layer1 = keras.layers.Dropout(rate=3, name='drop')\n-    new_layer2 = keras.layers.Dropout(3, name='drop')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer2.get_config())\n-\n-\n-def test_embedding_legacy_interface():\n-    old_layer = keras.layers.Embedding(4, 2, name='d')\n-    new_layer = keras.layers.Embedding(output_dim=2, input_dim=4, name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n-                                       init='normal',\n-                                       W_regularizer='l1',\n-                                       W_constraint='maxnorm')\n-    new_layer = keras.layers.Embedding(input_dim=4, output_dim=2, name='d',\n-                                       embeddings_initializer='normal',\n-                                       embeddings_regularizer='l1',\n-                                       embeddings_constraint='max_norm')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Embedding(1, 1, dropout=0.0, name='d')\n-    new_layer = keras.layers.Embedding(1, 1, name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_maxpooling1d_legacy_interface():\n-    old_layer = keras.layers.MaxPool1D(pool_length=2,\n-                                       border_mode='valid',\n-                                       name='maxpool1d')\n-    new_layer = keras.layers.MaxPool1D(pool_size=2,\n-                                       padding='valid',\n-                                       name='maxpool1d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPool1D(2, padding='valid', name='maxpool1d')\n-    new_layer = keras.layers.MaxPool1D(pool_size=2,\n-                                       padding='valid',\n-                                       name='maxpool1d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_avgpooling1d_legacy_interface():\n-    old_layer = keras.layers.AvgPool1D(pool_length=2,\n-                                       border_mode='valid',\n-                                       name='d')\n-    new_layer = keras.layers.AvgPool1D(pool_size=2, padding='valid', name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AvgPool1D(2, padding='valid', name='d')\n-    new_layer = keras.layers.AvgPool1D(pool_size=2, padding='valid', name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_prelu_legacy_interface():\n-    old_layer = keras.layers.PReLU(init='zero', name='p')\n-    new_layer = keras.layers.PReLU('zero', name='p')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_gaussiannoise_legacy_interface():\n-    old_layer = keras.layers.GaussianNoise(sigma=0.5, name='gn')\n-    new_layer = keras.layers.GaussianNoise(stddev=0.5, name='gn')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_lstm_legacy_interface():\n-    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name='d')\n-    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name='d',\n-                                  consume_less='mem')\n-    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d', implementation=1)\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(input_dim=5, input_length=3,\n-                                  output_dim=2, name='d', consume_less='mem')\n-    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d', implementation=1)\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(input_dim=5,\n-                                  output_dim=2, name='d', consume_less='mem')\n-    new_layer = keras.layers.LSTM(2, input_shape=[None, 5], name='d',\n-                                  implementation=1)\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(input_shape=[3, 5], output_dim=2, name='d',\n-                                  consume_less='gpu')\n-    new_layer = keras.layers.LSTM(2, input_shape=[3, 5], name='d', implementation=2)\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(2, init='normal',\n-                                  inner_init='glorot_uniform',\n-                                  forget_bias_init='one',\n-                                  inner_activation='hard_sigmoid',\n-                                  W_regularizer='l1',\n-                                  U_regularizer='l1',\n-                                  b_regularizer='l1',\n-                                  dropout_W=0.1,\n-                                  dropout_U=0.1,\n-                                  name='LSTM')\n-\n-    new_layer = keras.layers.LSTM(2, kernel_initializer='normal',\n-                                  recurrent_initializer='glorot_uniform',\n-                                  unit_forget_bias=True,\n-                                  recurrent_activation='hard_sigmoid',\n-                                  kernel_regularizer='l1',\n-                                  recurrent_regularizer='l1',\n-                                  bias_regularizer='l1',\n-                                  dropout=0.1,\n-                                  recurrent_dropout=0.1,\n-                                  name='LSTM')\n-\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.LSTM(2, init='normal',\n-                                  inner_init='glorot_uniform',\n-                                  forget_bias_init='zero',\n-                                  inner_activation='hard_sigmoid',\n-                                  W_regularizer='l1',\n-                                  U_regularizer='l1',\n-                                  b_regularizer='l1',\n-                                  dropout_W=0.1,\n-                                  dropout_U=0.1,\n-                                  name='LSTM')\n-\n-    new_layer = keras.layers.LSTM(2, kernel_initializer='normal',\n-                                  recurrent_initializer='glorot_uniform',\n-                                  unit_forget_bias=True,\n-                                  recurrent_activation='hard_sigmoid',\n-                                  kernel_regularizer='l1',\n-                                  recurrent_regularizer='l1',\n-                                  bias_regularizer='l1',\n-                                  dropout=0.1,\n-                                  recurrent_dropout=0.1,\n-                                  name='LSTM')\n-\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_simplernn_legacy_interface():\n-    old_layer = keras.layers.SimpleRNN(input_shape=[3, 5], output_dim=2, name='d')\n-    new_layer = keras.layers.SimpleRNN(2, input_shape=[3, 5], name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.SimpleRNN(2, init='normal',\n-                                       inner_init='glorot_uniform',\n-                                       W_regularizer='l1',\n-                                       U_regularizer='l1',\n-                                       b_regularizer='l1',\n-                                       dropout_W=0.1,\n-                                       dropout_U=0.1,\n-                                       name='SimpleRNN')\n-    new_layer = keras.layers.SimpleRNN(2, kernel_initializer='normal',\n-                                       recurrent_initializer='glorot_uniform',\n-                                       kernel_regularizer='l1',\n-                                       recurrent_regularizer='l1',\n-                                       bias_regularizer='l1',\n-                                       dropout=0.1,\n-                                       recurrent_dropout=0.1,\n-                                       name='SimpleRNN')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_gru_legacy_interface():\n-    old_layer = keras.layers.GRU(input_shape=[3, 5], output_dim=2, name='d')\n-    new_layer = keras.layers.GRU(2, input_shape=[3, 5], name='d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GRU(2, init='normal',\n-                                 inner_init='glorot_uniform',\n-                                 inner_activation='hard_sigmoid',\n-                                 W_regularizer='l1',\n-                                 U_regularizer='l1',\n-                                 b_regularizer='l1',\n-                                 dropout_W=0.1,\n-                                 dropout_U=0.1,\n-                                 name='GRU')\n-    new_layer = keras.layers.GRU(2, kernel_initializer='normal',\n-                                 recurrent_initializer='glorot_uniform',\n-                                 recurrent_activation='hard_sigmoid',\n-                                 kernel_regularizer='l1',\n-                                 recurrent_regularizer='l1',\n-                                 bias_regularizer='l1',\n-                                 dropout=0.1,\n-                                 recurrent_dropout=0.1,\n-                                 name='GRU')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_gaussiandropout_legacy_interface():\n-    old_layer = keras.layers.GaussianDropout(p=0.6, name='drop')\n-    new_layer1 = keras.layers.GaussianDropout(rate=0.6, name='drop')\n-    new_layer2 = keras.layers.GaussianDropout(0.6, name='drop')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer2.get_config())\n-\n-\n-def test_maxpooling2d_legacy_interface():\n-    old_layer = keras.layers.MaxPooling2D(\n-        pool_size=(2, 2), border_mode='valid', name='maxpool2d')\n-    new_layer = keras.layers.MaxPool2D(\n-        pool_size=2, padding='valid', name='maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling2D((2, 2), 2, 'valid', name='maxpool2d')\n-    new_layer = keras.layers.MaxPool2D(\n-        pool_size=2, strides=2, padding='valid', name='maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling2D(\n-        (2, 2), padding='valid', dim_ordering='tf', name='maxpool2d')\n-    new_layer = keras.layers.MaxPool2D(\n-        pool_size=2, padding='valid', data_format='channels_last', name='maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling2D(\n-        (2, 2), padding='valid', dim_ordering='th', name='maxpool2d')\n-    new_layer = keras.layers.MaxPool2D(\n-        pool_size=2, padding='valid', data_format='channels_first',\n-        name='maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling2D(\n-        (2, 2), padding='valid', dim_ordering='default', name='maxpool2d')\n-    new_layer = keras.layers.MaxPool2D(\n-        pool_size=2, padding='valid', name='maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_avgpooling2d_legacy_interface():\n-    old_layer = keras.layers.AveragePooling2D(\n-        pool_size=(2, 2), border_mode='valid', name='avgpooling2d')\n-    new_layer = keras.layers.AvgPool2D(\n-        pool_size=(2, 2), padding='valid', name='avgpooling2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling2D(\n-        (2, 2), (2, 2), 'valid', name='avgpooling2d')\n-    new_layer = keras.layers.AvgPool2D(\n-        pool_size=(2, 2), strides=(2, 2), padding='valid', name='avgpooling2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling2D(\n-        (2, 2), padding='valid', dim_ordering='tf', name='avgpooling2d')\n-    new_layer = keras.layers.AvgPool2D(\n-        pool_size=2, padding='valid', data_format='channels_last',\n-        name='avgpooling2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling2D(\n-        (2, 2), padding='valid', dim_ordering='th', name='avgpooling2d')\n-    new_layer = keras.layers.AvgPool2D(\n-        pool_size=2, padding='valid', data_format='channels_first',\n-        name='avgpooling2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling2D(\n-        (2, 2), padding='valid', dim_ordering='default', name='avgpooling2d')\n-    new_layer = keras.layers.AvgPool2D(\n-        pool_size=2, padding='valid', name='avgpooling2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_maxpooling3d_legacy_interface():\n-    old_layer = keras.layers.MaxPooling3D(\n-        pool_size=(2, 2, 2), border_mode='valid', name='maxpool3d')\n-    new_layer = keras.layers.MaxPool3D(\n-        pool_size=(2, 2, 2), padding='valid', name='maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling3D(\n-        (2, 2, 2), (2, 2, 2), 'valid', name='maxpool3d')\n-    new_layer = keras.layers.MaxPool3D(\n-        pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid', name='maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='tf', name='maxpool3d')\n-    new_layer = keras.layers.MaxPool3D(\n-        pool_size=(2, 2, 2), padding='valid', data_format='channels_last',\n-        name='maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='th', name='maxpool3d')\n-    new_layer = keras.layers.MaxPool3D(\n-        pool_size=(2, 2, 2), padding='valid', data_format='channels_first',\n-        name='maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.MaxPooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='default', name='maxpool3d')\n-    new_layer = keras.layers.MaxPool3D(\n-        pool_size=(2, 2, 2), padding='valid', name='maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_avgpooling3d_legacy_interface():\n-    old_layer = keras.layers.AveragePooling3D(\n-        pool_size=(2, 2, 2), border_mode='valid', name='avgpooling3d')\n-    new_layer = keras.layers.AvgPool3D(\n-        pool_size=(2, 2, 2), padding='valid', name='avgpooling3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling3D(\n-        (2, 2, 2), (2, 2, 2), 'valid', name='avgpooling3d')\n-    new_layer = keras.layers.AvgPool3D(\n-        pool_size=(2, 2, 2), strides=(2, 2, 2), padding='valid',\n-        name='avgpooling3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='tf', name='avgpooling3d')\n-    new_layer = keras.layers.AvgPool3D(\n-        pool_size=(2, 2, 2), padding='valid', data_format='channels_last',\n-        name='avgpooling3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='th', name='avgpooling3d')\n-    new_layer = keras.layers.AvgPool3D(\n-        pool_size=(2, 2, 2), padding='valid', data_format='channels_first',\n-        name='avgpooling3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.AveragePooling3D(\n-        (2, 2, 2), padding='valid', dim_ordering='default', name='avgpooling3d')\n-    new_layer = keras.layers.AvgPool3D(\n-        pool_size=(2, 2, 2), padding='valid', name='avgpooling3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_global_maxpooling2d_legacy_interface():\n-    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='tf',\n-                                                name='global_maxpool2d')\n-    new_layer = keras.layers.GlobalMaxPool2D(data_format='channels_last',\n-                                             name='global_maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='th',\n-                                                name='global_maxpool2d')\n-    new_layer = keras.layers.GlobalMaxPool2D(data_format='channels_first',\n-                                             name='global_maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalMaxPooling2D(dim_ordering='default',\n-                                                name='global_maxpool2d')\n-    new_layer = keras.layers.GlobalMaxPool2D(name='global_maxpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_global_avgpooling2d_legacy_interface():\n-    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='tf',\n-                                                    name='global_avgpool2d')\n-    new_layer = keras.layers.GlobalAvgPool2D(data_format='channels_last',\n-                                             name='global_avgpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='th',\n-                                                    name='global_avgpool2d')\n-    new_layer = keras.layers.GlobalAvgPool2D(data_format='channels_first',\n-                                             name='global_avgpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalAveragePooling2D(dim_ordering='default',\n-                                                    name='global_avgpool2d')\n-    new_layer = keras.layers.GlobalAvgPool2D(name='global_avgpool2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_global_maxpooling3d_legacy_interface():\n-    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='tf',\n-                                                name='global_maxpool3d')\n-    new_layer = keras.layers.GlobalMaxPool3D(data_format='channels_last',\n-                                             name='global_maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='th',\n-                                                name='global_maxpool3d')\n-    new_layer = keras.layers.GlobalMaxPool3D(data_format='channels_first',\n-                                             name='global_maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalMaxPooling3D(dim_ordering='default',\n-                                                name='global_maxpool3d')\n-    new_layer = keras.layers.GlobalMaxPool3D(name='global_maxpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_global_avgpooling3d_legacy_interface():\n-    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='tf',\n-                                                    name='global_avgpool3d')\n-    new_layer = keras.layers.GlobalAvgPool3D(data_format='channels_last',\n-                                             name='global_avgpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='th',\n-                                                    name='global_avgpool3d')\n-    new_layer = keras.layers.GlobalAvgPool3D(data_format='channels_first',\n-                                             name='global_avgpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.GlobalAveragePooling3D(dim_ordering='default',\n-                                                    name='global_avgpool3d')\n-    new_layer = keras.layers.GlobalAvgPool3D(name='global_avgpool3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_upsampling1d_legacy_interface():\n-    old_layer = keras.layers.UpSampling1D(length=3, name='us1d')\n-    new_layer_1 = keras.layers.UpSampling1D(size=3, name='us1d')\n-    new_layer_2 = keras.layers.UpSampling1D(3, name='us1d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n-\n-\n-def test_upsampling2d_legacy_interface():\n-    old_layer = keras.layers.UpSampling2D((2, 2), dim_ordering='tf', name='us2d')\n-    new_layer = keras.layers.UpSampling2D((2, 2), data_format='channels_last',\n-                                          name='us2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_upsampling3d_legacy_interface():\n-    old_layer = keras.layers.UpSampling3D((2, 2, 2),\n-                                          dim_ordering='tf',\n-                                          name='us3d')\n-    new_layer = keras.layers.UpSampling3D((2, 2, 2),\n-                                          data_format='channels_last',\n-                                          name='us3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_conv2d_legacy_interface():\n-    old_layer = keras.layers.Convolution2D(5, 3, 3, name='conv')\n-    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution2D(5, 3, nb_col=3, name='conv')\n-    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution2D(5, nb_row=3, nb_col=3, name='conv')\n-    new_layer = keras.layers.Conv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution2D(5, 3, 3,\n-                                           init='normal',\n-                                           subsample=(2, 2),\n-                                           border_mode='valid',\n-                                           dim_ordering='th',\n-                                           W_regularizer='l1',\n-                                           b_regularizer='l2',\n-                                           W_constraint='maxnorm',\n-                                           b_constraint='unitnorm',\n-                                           name='conv')\n-    new_layer = keras.layers.Conv2D(5, (3, 3),\n-                                    kernel_initializer='normal',\n-                                    strides=(2, 2),\n-                                    padding='valid',\n-                                    kernel_regularizer='l1',\n-                                    bias_regularizer='l2',\n-                                    kernel_constraint='max_norm',\n-                                    bias_constraint='unit_norm',\n-                                    data_format='channels_first',\n-                                    name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_deconv2d_legacy_interface():\n-    old_layer = keras.layers.Deconvolution2D(5, 3, 3, (6, 7, 5), name='deconv')\n-    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Deconvolution2D(5, 3, 3, output_shape=(6, 7, 5),\n-                                             name='deconv')\n-    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Deconvolution2D(5, 3, nb_col=3, output_shape=(6, 7, 5),\n-                                             name='deconv')\n-    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Deconvolution2D(5, nb_row=3, nb_col=3,\n-                                             output_shape=(6, 7, 5), name='deconv')\n-    new_layer = keras.layers.Conv2DTranspose(5, (3, 3), name='deconv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Deconvolution2D(5, 3, 3,\n-                                             output_shape=(6, 7, 5),\n-                                             init='normal',\n-                                             subsample=(2, 2),\n-                                             border_mode='valid',\n-                                             dim_ordering='th',\n-                                             W_regularizer='l1',\n-                                             b_regularizer='l2',\n-                                             W_constraint='maxnorm',\n-                                             b_constraint='unitnorm',\n-                                             name='conv')\n-    new_layer = keras.layers.Conv2DTranspose(\n-        5, (3, 3),\n-        kernel_initializer='normal',\n-        strides=(2, 2),\n-        padding='valid',\n-        kernel_regularizer='l1',\n-        bias_regularizer='l2',\n-        kernel_constraint='max_norm',\n-        bias_constraint='unit_norm',\n-        data_format='channels_first',\n-        name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_conv1d_legacy_interface():\n-    old_layer = keras.layers.Convolution1D(5,\n-                                           filter_length=3,\n-                                           input_dim=3,\n-                                           input_length=4,\n-                                           name='conv')\n-    new_layer = keras.layers.Conv1D(5, 3, name='conv', input_shape=(4, 3))\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution1D(5, 3,\n-                                           init='normal',\n-                                           subsample_length=2,\n-                                           border_mode='valid',\n-                                           W_regularizer='l1',\n-                                           b_regularizer='l2',\n-                                           W_constraint='maxnorm',\n-                                           b_constraint='unitnorm',\n-                                           name='conv')\n-    new_layer = keras.layers.Conv1D(5, 3,\n-                                    kernel_initializer='normal',\n-                                    strides=2,\n-                                    padding='valid',\n-                                    kernel_regularizer='l1',\n-                                    bias_regularizer='l2',\n-                                    kernel_constraint='max_norm',\n-                                    bias_constraint='unit_norm',\n-                                    name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_separable_conv2d_legacy_interface():\n-    old_layer = keras.layers.SeparableConv2D(5, 3, 3, name='conv')\n-    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.SeparableConv2D(5, 3, nb_col=3, name='conv')\n-    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.SeparableConv2D(5, nb_row=3, nb_col=3, name='conv')\n-    new_layer = keras.layers.SeparableConv2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.SeparableConv2D(5, 3, 3,\n-                                             init='normal',\n-                                             subsample=(2, 2),\n-                                             border_mode='valid',\n-                                             dim_ordering='th',\n-                                             depthwise_regularizer='l1',\n-                                             b_regularizer='l2',\n-                                             depthwise_constraint='maxnorm',\n-                                             b_constraint='unitnorm',\n-                                             name='conv')\n-    new_layer = keras.layers.SeparableConv2D(5, (3, 3),\n-                                             depthwise_initializer='normal',\n-                                             pointwise_initializer='normal',\n-                                             strides=(2, 2),\n-                                             padding='valid',\n-                                             depthwise_regularizer='l1',\n-                                             bias_regularizer='l2',\n-                                             depthwise_constraint='max_norm',\n-                                             bias_constraint='unit_norm',\n-                                             data_format='channels_first',\n-                                             name='conv')\n-    old_config = json.dumps(old_layer.get_config())\n-    new_config = json.dumps(new_layer.get_config())\n-    assert old_config == new_config\n-\n-\n-def test_conv3d_legacy_interface():\n-    old_layer = keras.layers.Convolution3D(5, 3, 3, 4, name='conv')\n-    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution3D(5, 3, 3, kernel_dim3=4, name='conv')\n-    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution3D(5, 3,\n-                                           kernel_dim2=3,\n-                                           kernel_dim3=4,\n-                                           name='conv')\n-    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution3D(5,\n-                                           kernel_dim1=3,\n-                                           kernel_dim2=3,\n-                                           kernel_dim3=4,\n-                                           name='conv')\n-    new_layer = keras.layers.Conv3D(5, (3, 3, 4), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.Convolution3D(5, 3, 3, 4,\n-                                           init='normal',\n-                                           subsample=(2, 2, 2),\n-                                           border_mode='valid',\n-                                           dim_ordering='th',\n-                                           W_regularizer='l1',\n-                                           b_regularizer='l2',\n-                                           W_constraint='maxnorm',\n-                                           b_constraint='unitnorm',\n-                                           name='conv')\n-    new_layer = keras.layers.Conv3D(5, (3, 3, 4),\n-                                    kernel_initializer='normal',\n-                                    strides=(2, 2, 2),\n-                                    padding='valid',\n-                                    kernel_regularizer='l1',\n-                                    bias_regularizer='l2',\n-                                    kernel_constraint='max_norm',\n-                                    bias_constraint='unit_norm',\n-                                    data_format='channels_first',\n-                                    name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_convlstm2d_legacy_interface():\n-    old_layer = keras.layers.ConvLSTM2D(5, 3, 3, name='conv')\n-    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.ConvLSTM2D(5, 3, nb_col=3, name='conv')\n-    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.ConvLSTM2D(5, nb_row=3, nb_col=3, name='conv')\n-    new_layer = keras.layers.ConvLSTM2D(5, (3, 3), name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.ConvLSTM2D(5, 3, 3,\n-                                        init='normal',\n-                                        inner_init='uniform',\n-                                        forget_bias_init='one',\n-                                        inner_activation='relu',\n-                                        subsample=(2, 2),\n-                                        border_mode='valid',\n-                                        dim_ordering='th',\n-                                        W_regularizer='l1',\n-                                        U_regularizer='l2',\n-                                        b_regularizer='l2',\n-                                        dropout_W=0.2,\n-                                        dropout_U=0.1,\n-                                        name='conv')\n-    new_layer = keras.layers.ConvLSTM2D(5, (3, 3),\n-                                        kernel_initializer='normal',\n-                                        recurrent_initializer='uniform',\n-                                        unit_forget_bias=True,\n-                                        recurrent_activation='relu',\n-                                        strides=(2, 2),\n-                                        padding='valid',\n-                                        kernel_regularizer='l1',\n-                                        recurrent_regularizer='l2',\n-                                        bias_regularizer='l2',\n-                                        data_format='channels_first',\n-                                        dropout=0.2,\n-                                        recurrent_dropout=0.1,\n-                                        name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_batchnorm_legacy_interface():\n-    old_layer = keras.layers.BatchNormalization(mode=0, name='bn')\n-    new_layer = keras.layers.BatchNormalization(name='bn')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-    old_layer = keras.layers.BatchNormalization(mode=0,\n-                                                beta_init='one',\n-                                                gamma_init='uniform',\n-                                                name='bn')\n-    new_layer = keras.layers.BatchNormalization(beta_initializer='ones',\n-                                                gamma_initializer='uniform',\n-                                                name='bn')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_atrousconv1d_legacy_interface():\n-    old_layer = keras.layers.AtrousConvolution1D(5, 3,\n-                                                 init='normal',\n-                                                 subsample_length=2,\n-                                                 border_mode='valid',\n-                                                 W_regularizer='l1',\n-                                                 b_regularizer='l2',\n-                                                 W_constraint='maxnorm',\n-                                                 b_constraint='unitnorm',\n-                                                 atrous_rate=2,\n-                                                 name='conv')\n-    new_layer = keras.layers.Conv1D(5, 3,\n-                                    kernel_initializer='normal',\n-                                    strides=2,\n-                                    padding='valid',\n-                                    kernel_regularizer='l1',\n-                                    bias_regularizer='l2',\n-                                    kernel_constraint='max_norm',\n-                                    bias_constraint='unit_norm',\n-                                    dilation_rate=2,\n-                                    name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_atrousconv2d_legacy_interface():\n-    old_layer = keras.layers.AtrousConvolution2D(\n-        5, 3, 3,\n-        atrous_rate=(2, 2),\n-        init='normal',\n-        subsample=(2, 2),\n-        border_mode='valid',\n-        dim_ordering='th',\n-        W_regularizer='l1',\n-        b_regularizer='l2',\n-        W_constraint='maxnorm',\n-        b_constraint='unitnorm',\n-        name='conv')\n-    new_layer = keras.layers.Conv2D(5, (3, 3),\n-                                    kernel_initializer='normal',\n-                                    strides=(2, 2),\n-                                    padding='valid',\n-                                    kernel_regularizer='l1',\n-                                    bias_regularizer='l2',\n-                                    kernel_constraint='max_norm',\n-                                    bias_constraint='unit_norm',\n-                                    data_format='channels_first',\n-                                    dilation_rate=(2, 2),\n-                                    name='conv')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_zeropadding2d_legacy_interface():\n-    old_layer = keras.layers.ZeroPadding2D(padding={'right_pad': 4,\n-                                                    'bottom_pad': 2,\n-                                                    'top_pad': 1,\n-                                                    'left_pad': 3},\n-                                           dim_ordering='tf',\n-                                           name='zp2d')\n-    new_layer = keras.layers.ZeroPadding2D(((1, 2), (3, 4)),\n-                                           data_format='channels_last',\n-                                           name='zp2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_zeropadding3d_legacy_interface():\n-    old_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n-                                           dim_ordering='tf',\n-                                           name='zp3d')\n-    new_layer = keras.layers.ZeroPadding3D((2, 2, 2),\n-                                           data_format='channels_last',\n-                                           name='zp3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_cropping2d_legacy_interface():\n-    old_layer = keras.layers.Cropping2D(dim_ordering='tf', name='c2d')\n-    new_layer = keras.layers.Cropping2D(data_format='channels_last', name='c2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def test_cropping3d_legacy_interface():\n-    old_layer = keras.layers.Cropping3D(dim_ordering='tf', name='c3d')\n-    new_layer = keras.layers.Cropping3D(data_format='channels_last', name='c3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer.get_config())\n-\n-\n-def DISABLED_test_generator_methods_interface():\n-    \"\"\"This test may cause Travis to hang.\"\"\"\n-\n-    def train_generator():\n-        x = np.random.randn(2, 2)\n-        y = np.random.randint(0, 2, size=[2, 1])\n-        while True:\n-            yield (x, y)\n-\n-    def val_generator():\n-        x = np.random.randn(2, 2)\n-        y = np.random.randint(0, 2, size=[2, 1])\n-        while True:\n-            yield (x, y)\n-\n-    def pred_generator():\n-        x = np.random.randn(1, 2)\n-        while True:\n-            yield x\n-\n-    x = keras.layers.Input(shape=(2, ))\n-    y = keras.layers.Dense(2)(x)\n-\n-    model = keras.models.Model(inputs=x, outputs=y)\n-    model.compile(optimizer='rmsprop',\n-                  loss='sparse_categorical_crossentropy',\n-                  metrics=['accuracy'])\n-    model.fit_generator(generator=train_generator(),\n-                        samples_per_epoch=1,\n-                        validation_data=val_generator(),\n-                        nb_val_samples=1,\n-                        nb_worker=1, pickle_safe=True, max_q_size=3)\n-\n-    model.evaluate_generator(generator=train_generator(),\n-                             val_samples=2,\n-                             nb_worker=1, pickle_safe=False, max_q_size=3)\n-    model.predict_generator(generator=pred_generator(),\n-                            val_samples=2,\n-                            nb_worker=1, pickle_safe=False, max_q_size=3)\n-\n-\n-def test_spatialdropout1d_legacy_interface():\n-    old_layer = keras.layers.SpatialDropout1D(p=0.6, name='sd1d')\n-    new_layer_1 = keras.layers.SpatialDropout1D(rate=0.6, name='sd1d')\n-    new_layer_2 = keras.layers.SpatialDropout1D(0.6, name='sd1d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n-\n-\n-def test_spatialdropout2d_legacy_interface():\n-    old_layer = keras.layers.SpatialDropout2D(p=0.5,\n-                                              dim_ordering='tf',\n-                                              name='sd2d')\n-    new_layer_1 = keras.layers.SpatialDropout2D(rate=0.5,\n-                                                data_format='channels_last',\n-                                                name='sd2d')\n-    new_layer_2 = keras.layers.SpatialDropout2D(0.5,\n-                                                data_format='channels_last',\n-                                                name='sd2d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n-\n-\n-def test_spatialdropout3d_legacy_interface():\n-    old_layer = keras.layers.SpatialDropout3D(p=0.5,\n-                                              dim_ordering='tf',\n-                                              name='sd3d')\n-    new_layer_1 = keras.layers.SpatialDropout3D(rate=0.5,\n-                                                data_format='channels_last',\n-                                                name='sd3d')\n-    new_layer_2 = keras.layers.SpatialDropout3D(0.5,\n-                                                data_format='channels_last',\n-                                                name='sd3d')\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_1.get_config())\n-    assert json.dumps(old_layer.get_config()) == json.dumps(new_layer_2.get_config())\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -1,39 +0,0 @@\n-import pytest\n-\n-from keras.utils.test_utils import layer_test\n-from keras.legacy import layers as legacy_layers\n-from keras import regularizers\n-from keras import constraints\n-\n-\n-def test_highway():\n-    layer_test(legacy_layers.Highway,\n-               kwargs={},\n-               input_shape=(3, 2))\n-\n-    layer_test(legacy_layers.Highway,\n-               kwargs={'W_regularizer': regularizers.l2(0.01),\n-                       'b_regularizer': regularizers.l1(0.01),\n-                       'activity_regularizer': regularizers.l2(0.01),\n-                       'W_constraint': constraints.MaxNorm(1),\n-                       'b_constraint': constraints.MaxNorm(1)},\n-               input_shape=(3, 2))\n-\n-\n-def test_maxout_dense():\n-    layer_test(legacy_layers.MaxoutDense,\n-               kwargs={'output_dim': 3},\n-               input_shape=(3, 2))\n-\n-    layer_test(legacy_layers.MaxoutDense,\n-               kwargs={'output_dim': 3,\n-                       'W_regularizer': regularizers.l2(0.01),\n-                       'b_regularizer': regularizers.l1(0.01),\n-                       'activity_regularizer': regularizers.l2(0.01),\n-                       'W_constraint': constraints.MaxNorm(1),\n-                       'b_constraint': constraints.MaxNorm(1)},\n-               input_shape=(3, 2))\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -3,9 +3,9 @@ import numpy as np\n \n import keras\n from keras import losses\n+from keras.losses import Reduction\n from keras import backend as K\n-from keras.utils import losses_utils\n-from keras.utils.generic_utils import custom_object_scope\n+from keras.utils import custom_object_scope\n \n \n all_functions = [losses.mean_squared_error,\n@@ -18,7 +18,7 @@ all_functions = [losses.mean_squared_error,\n                  losses.binary_crossentropy,\n                  losses.kullback_leibler_divergence,\n                  losses.poisson,\n-                 losses.cosine_proximity,\n+                 losses.cosine_similarity,\n                  losses.logcosh,\n                  losses.categorical_hinge]\n all_classes = [\n@@ -38,11 +38,12 @@ all_classes = [\n ]\n \n \n-class MSE_MAE_loss(object):\n+class MSE_MAE_loss(losses.Loss):\n     \"\"\"Loss function with internal state, for testing serialization code.\"\"\"\n \n     def __init__(self, mse_fraction):\n         self.mse_fraction = mse_fraction\n+        super(MSE_MAE_loss, self).__init__()\n \n     def __call__(self, y_true, y_pred, sample_weight=None):\n         return (self.mse_fraction * losses.mse(y_true, y_pred) +\n@@ -140,24 +141,6 @@ class TestLossFunctions(object):\n             loaded_model = keras.models.load_model(model_filename)\n             loaded_model.predict(np.random.rand(128, 2))\n \n-    def test_loss_wrapper(self):\n-        loss_fn = losses.get('mse')\n-        mse_obj = losses.LossFunctionWrapper(loss_fn, name=loss_fn.__name__)\n-\n-        assert mse_obj.name == 'mean_squared_error'\n-        assert (mse_obj.reduction == losses_utils.Reduction.SUM_OVER_BATCH_SIZE)\n-\n-        y_true = K.constant([[1., 9.], [2., 5.]])\n-        y_pred = K.constant([[4., 8.], [12., 3.]])\n-        sample_weight = K.constant([1.2, 0.5])\n-        loss = mse_obj(y_true, y_pred, sample_weight=sample_weight)\n-\n-        # mse = [((4 - 1)^2 + (8 - 9)^2) / 2, ((12 - 2)^2 + (3 - 5)^2) / 2]\n-        # mse = [5, 52]\n-        # weighted_mse = [5 * 1.2, 52 * 0.5] = [6, 26]\n-        # reduced_weighted_mse = (6 + 26) / 2 =\n-        np.allclose(K.eval(loss), 16, atol=1e-2)\n-\n \n skipif_not_tf = pytest.mark.skipif(\n     K.backend() != 'tensorflow',\n@@ -190,9 +173,9 @@ class TestMeanSquaredError:\n \n     def test_config(self):\n         mse_obj = losses.MeanSquaredError(\n-            reduction=losses_utils.Reduction.SUM, name='mse_1')\n+            reduction=Reduction.SUM, name='mse_1')\n         assert mse_obj.name == 'mse_1'\n-        assert mse_obj.reduction == losses_utils.Reduction.SUM\n+        assert mse_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         mse_obj = losses.MeanSquaredError()\n@@ -247,7 +230,7 @@ class TestMeanSquaredError:\n \n     def test_no_reduction(self):\n         mse_obj = losses.MeanSquaredError(\n-            reduction=losses_utils.Reduction.NONE)\n+            reduction=Reduction.NONE)\n         y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n         y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n         loss = mse_obj(y_true, y_pred, sample_weight=2.3)\n@@ -255,7 +238,7 @@ class TestMeanSquaredError:\n \n     def test_sum_reduction(self):\n         mse_obj = losses.MeanSquaredError(\n-            reduction=losses_utils.Reduction.SUM)\n+            reduction=Reduction.SUM)\n         y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n         y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n         loss = mse_obj(y_true, y_pred, sample_weight=2.3)\n@@ -267,9 +250,9 @@ class TestMeanAbsoluteError(object):\n \n     def test_config(self):\n         mae_obj = losses.MeanAbsoluteError(\n-            reduction=losses_utils.Reduction.SUM, name='mae_1')\n+            reduction=Reduction.SUM, name='mae_1')\n         assert mae_obj.name == 'mae_1'\n-        assert mae_obj.reduction == losses_utils.Reduction.SUM\n+        assert mae_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         mae_obj = losses.MeanAbsoluteError()\n@@ -324,7 +307,7 @@ class TestMeanAbsoluteError(object):\n \n     def test_no_reduction(self):\n         mae_obj = losses.MeanAbsoluteError(\n-            reduction=losses_utils.Reduction.NONE)\n+            reduction=Reduction.NONE)\n         y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n         y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n         loss = mae_obj(y_true, y_pred, sample_weight=2.3)\n@@ -332,7 +315,7 @@ class TestMeanAbsoluteError(object):\n \n     def test_sum_reduction(self):\n         mae_obj = losses.MeanAbsoluteError(\n-            reduction=losses_utils.Reduction.SUM)\n+            reduction=Reduction.SUM)\n         y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n         y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n         loss = mae_obj(y_true, y_pred, sample_weight=2.3)\n@@ -344,9 +327,9 @@ class TestMeanAbsolutePercentageError(object):\n \n     def test_config(self):\n         mape_obj = losses.MeanAbsolutePercentageError(\n-            reduction=losses_utils.Reduction.SUM, name='mape_1')\n+            reduction=Reduction.SUM, name='mape_1')\n         assert mape_obj.name == 'mape_1'\n-        assert mape_obj.reduction == losses_utils.Reduction.SUM\n+        assert mape_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         mape_obj = losses.MeanAbsolutePercentageError()\n@@ -393,7 +376,7 @@ class TestMeanAbsolutePercentageError(object):\n \n     def test_no_reduction(self):\n         mape_obj = losses.MeanAbsolutePercentageError(\n-            reduction=losses_utils.Reduction.NONE)\n+            reduction=Reduction.NONE)\n         y_true = K.constant([1, 9, 2, -5, -2, 6], shape=(2, 3))\n         y_pred = K.constant([4, 8, 12, 8, 1, 3], shape=(2, 3))\n         loss = mape_obj(y_true, y_pred, sample_weight=2.3)\n@@ -405,9 +388,9 @@ class TestMeanSquaredLogarithmicError(object):\n \n     def test_config(self):\n         msle_obj = losses.MeanSquaredLogarithmicError(\n-            reduction=losses_utils.Reduction .SUM, name='mape_1')\n+            reduction=Reduction .SUM, name='mape_1')\n         assert msle_obj.name == 'mape_1'\n-        assert msle_obj.reduction == losses_utils.Reduction .SUM\n+        assert msle_obj.reduction == Reduction .SUM\n \n     def test_unweighted(self):\n         msle_obj = losses.MeanSquaredLogarithmicError()\n@@ -452,9 +435,9 @@ class TestBinaryCrossentropy(object):\n \n     def test_config(self):\n         bce_obj = losses.BinaryCrossentropy(\n-            reduction=losses_utils.Reduction.SUM, name='bce_1')\n+            reduction=Reduction.SUM, name='bce_1')\n         assert bce_obj.name == 'bce_1'\n-        assert bce_obj.reduction == losses_utils.Reduction.SUM\n+        assert bce_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         y_true = K.constant([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])\n@@ -578,7 +561,7 @@ class TestBinaryCrossentropy(object):\n         y_true = K.constant([[1, 0, 1], [0, 1, 1]])\n         logits = K.constant([[100.0, -100.0, 100.0], [100.0, 100.0, -100.0]])\n         bce_obj = losses.BinaryCrossentropy(\n-            from_logits=True, reduction=losses_utils.Reduction.NONE)\n+            from_logits=True, reduction=Reduction.NONE)\n         loss = bce_obj(y_true, logits)\n \n         # Loss = max(x, 0) - x * z + log(1 + exp(-abs(x)))\n@@ -613,9 +596,9 @@ class TestCategoricalCrossentropy(object):\n \n     def test_config(self):\n         cce_obj = losses.CategoricalCrossentropy(\n-            reduction=losses_utils.Reduction.SUM, name='bce_1')\n+            reduction=Reduction.SUM, name='bce_1')\n         assert cce_obj.name == 'bce_1'\n-        assert cce_obj.reduction == losses_utils.Reduction.SUM\n+        assert cce_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n@@ -677,7 +660,7 @@ class TestCategoricalCrossentropy(object):\n         y_true = K.constant([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n         logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n         cce_obj = losses.CategoricalCrossentropy(\n-            from_logits=True, reduction=losses_utils.Reduction.NONE)\n+            from_logits=True, reduction=Reduction.NONE)\n         loss = cce_obj(y_true, logits)\n         assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n \n@@ -709,9 +692,9 @@ class TestSparseCategoricalCrossentropy(object):\n \n     def test_config(self):\n         cce_obj = losses.SparseCategoricalCrossentropy(\n-            reduction=losses_utils.Reduction.SUM, name='scc')\n+            reduction=Reduction.SUM, name='scc')\n         assert cce_obj.name == 'scc'\n-        assert cce_obj.reduction == losses_utils.Reduction.SUM\n+        assert cce_obj.reduction == Reduction.SUM\n \n     def test_all_correct_unweighted(self):\n         y_true = K.constant([[0], [1], [2]])\n@@ -773,7 +756,7 @@ class TestSparseCategoricalCrossentropy(object):\n         y_true = K.constant([[0], [1], [2]])\n         logits = K.constant([[8., 1., 1.], [0., 9., 1.], [2., 3., 5.]])\n         cce_obj = losses.SparseCategoricalCrossentropy(\n-            from_logits=True, reduction=losses_utils.Reduction.NONE)\n+            from_logits=True, reduction=Reduction.NONE)\n         loss = cce_obj(y_true, logits)\n         assert np.allclose(K.eval(loss), (0.001822, 0.000459, 0.169846), atol=1e-3)\n \n\n@@ -4,7 +4,7 @@ import numpy as np\n \n from keras import metrics\n from keras import backend as K\n-from keras.utils import metrics_utils\n+from tensorflow.python.keras.utils import metrics_utils\n \n if K.backend() != 'tensorflow':\n     # Need TensorFlow to use metric.__call__\n@@ -337,7 +337,7 @@ class TestSpecificityAtSensitivity(object):\n         result = s_obj(y_true, y_pred)\n         assert np.isclose(1, K.eval(result))\n \n-    def test_unweighted_high_sensitivity(self):\n+    def DISABLED_test_unweighted_high_sensitivity(self):\n         s_obj = metrics.SpecificityAtSensitivity(0.8)\n         pred_values = [0.0, 0.1, 0.2, 0.3, 0.4, 0.1, 0.45, 0.5, 0.8, 0.9]\n         label_values = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n@@ -188,7 +188,7 @@ class TestMetricsCorrectnessMultiIO(object):\n         for key, value in self.expected_fit_result_with_weights_output_2.items():\n             np.allclose(history.history[key], value, 1e-3)\n \n-    def test_fit_with_class_weight(self):\n+    def DISABLED_test_fit_with_class_weight(self):\n         self.setUp()\n         model = self._get_compiled_multi_io_model()\n         history = model.fit([self.x, self.x], [self.y1, self.y2],\n@@ -268,7 +268,7 @@ class TestMetricsCorrectnessMultiIO(object):\n                                           'output_2': self.sample_weight_2})\n         np.allclose(result, self.expected_batch_result_with_weights_output_2, 1e-3)\n \n-    def test_train_on_batch_with_class_weight(self):\n+    def DISABLED_test_train_on_batch_with_class_weight(self):\n         self.setUp()\n         model = self._get_compiled_multi_io_model()\n         result = model.train_on_batch([self.x, self.x], [self.y1, self.y2],\n@@ -314,7 +314,7 @@ class TestMetricsCorrectnessMultiIO(object):\n         for key, value in self.expected_fit_result.items():\n             np.allclose(history.history[key], value, 1e-3)\n \n-    def test_fit_generator_with_sample_weight(self):\n+    def DISABLED_test_fit_generator_with_sample_weight(self):\n         self.setUp()\n         model = self._get_compiled_multi_io_model()\n         history = model.fit_generator(\n@@ -333,7 +333,7 @@ class TestMetricsCorrectnessMultiIO(object):\n         for key, value in self.expected_fit_result_with_weights_output_2.items():\n             np.allclose(history.history[key], value, 1e-3)\n \n-    def test_fit_generator_with_class_weight(self):\n+    def DISABLED_test_fit_generator_with_class_weight(self):\n         self.setUp()\n         model = self._get_compiled_multi_io_model()\n         history = model.fit_generator(\n@@ -362,7 +362,7 @@ class TestMetricsCorrectnessMultiIO(object):\n         eval_result = model.evaluate_generator(custom_generator_multi_io(), steps=2)\n         np.allclose(eval_result, self.expected_batch_result, 1e-3)\n \n-    def test_eval_generator_with_sample_weight(self):\n+    def DISABLED_test_eval_generator_with_sample_weight(self):\n         self.setUp()\n         model = self._get_compiled_multi_io_model()\n         eval_result = model.evaluate_generator(\n\n@@ -19,8 +19,6 @@ all_metrics = [\n     metrics.categorical_crossentropy,\n     metrics.binary_crossentropy,\n     metrics.poisson,\n-    metrics.cosine_proximity,\n-    metrics.logcosh,\n ]\n \n all_sparse_metrics = [\n\n@@ -49,10 +49,10 @@ SPARSE_METRICS = [\n \n @pytest.mark.parametrize('metric_cls', METRICS)\n def test_training_and_eval(metric_cls):\n-    model = Sequential([Dense(2, input_shape=(3,))])\n+    model = Sequential([Dense(2, activation='sigmoid', input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metric_cls()])\n-    x = np.random.random((10, 3))\n-    y = np.random.random((10, 2))\n+    x = np.random.uniform(0, 1, size=(10, 3))\n+    y = np.random.uniform(0, 1, size=(10, 2))\n     model.fit(x, y)\n     model.evaluate(x, y)\n \n@@ -61,8 +61,8 @@ def test_training_and_eval(metric_cls):\n def test_sparse_metrics(metric_cls):\n     model = Sequential([Dense(1, input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metric_cls()])\n-    x = np.random.random((10, 3))\n-    y = np.random.random((10,))\n+    x = np.random.uniform(0, 1, size=(10, 3))\n+    y = np.random.uniform(0, 1, size=(10,))\n     model.fit(x, y)\n     model.evaluate(x, y)\n \n@@ -72,10 +72,10 @@ def test_sensitivity_metrics():\n         metrics.SensitivityAtSpecificity(0.5),\n         metrics.SpecificityAtSensitivity(0.5),\n     ]\n-    model = Sequential([Dense(2, input_shape=(3,))])\n+    model = Sequential([Dense(2, activation='sigmoid', input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=metrics_list)\n-    x = np.random.random((10, 3))\n-    y = np.random.random((10, 2))\n+    x = np.random.uniform(0, 1, size=(10, 3))\n+    y = np.random.uniform(0, 1, size=(10, 2))\n     model.fit(x, y)\n     model.evaluate(x, y)\n \n@@ -86,9 +86,9 @@ def test_mean_iou():\n     if not tf.__version__.startswith('2.'):\n         return\n \n-    model = Sequential([Dense(1, input_shape=(3,))])\n+    model = Sequential([Dense(1, activation='sigmoid', input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metrics.MeanIoU(2)])\n-    x = np.random.random((10, 3))\n-    y = np.random.random((10,))\n+    x = np.random.uniform(0, 1, size=(10, 3))\n+    y = np.random.uniform(0, 1, size=(10,))\n     model.fit(x, y)\n     model.evaluate(x, y)\n\n@@ -26,7 +26,7 @@ def get_test_data():\n     return x_train, y_train\n \n \n-def _test_optimizer(optimizer, target=0.75):\n+def _test_optimizer(optimizer, target=0.6):\n     x_train, y_train = get_test_data()\n \n     model = Sequential()\n@@ -44,7 +44,9 @@ def _test_optimizer(optimizer, target=0.75):\n     optim = optimizers.deserialize(config)\n     new_config = optimizers.serialize(optim)\n     new_config['class_name'] = new_config['class_name'].lower()\n-    assert config == new_config\n+    assert sorted(config.keys()) == sorted(new_config.keys())\n+    # for k in config['config'].keys():\n+    #     assert config['config'][k] == new_config['config'][k]\n \n     # Test constraints.\n     model = Sequential()\n@@ -107,13 +109,13 @@ def test_rmsprop():\n \n \n def test_adagrad():\n-    _test_optimizer(optimizers.Adagrad())\n-    _test_optimizer(optimizers.Adagrad(decay=1e-3))\n+    _test_optimizer(optimizers.Adagrad(lr=1.))\n+    _test_optimizer(optimizers.Adagrad(lr=1., decay=1e-3))\n \n \n def test_adadelta():\n-    _test_optimizer(optimizers.Adadelta(), target=0.6)\n-    _test_optimizer(optimizers.Adadelta(decay=1e-3), target=0.6)\n+    _test_optimizer(optimizers.Adadelta(lr=1.), target=0.4)\n+    _test_optimizer(optimizers.Adadelta(lr=1., decay=1e-3), target=0.4)\n \n \n def test_adam():\n@@ -122,8 +124,8 @@ def test_adam():\n \n \n def test_adamax():\n-    _test_optimizer(optimizers.Adamax())\n-    _test_optimizer(optimizers.Adamax(decay=1e-3))\n+    _test_optimizer(optimizers.Adamax(lr=1.))\n+    _test_optimizer(optimizers.Adamax(lr=1., decay=1e-3))\n \n \n def test_nadam():\n\n@@ -41,8 +41,8 @@ def create_multi_input_model_from(layer1, layer2):\n     out = Average()([out1, out2])\n     model = Model([input_1, input_2], out)\n     model.add_loss(K.mean(out2))\n-    model.add_loss(1)\n-    model.add_loss(1)\n+    model.add_loss(lambda: 1)\n+    model.add_loss(lambda: 1)\n     return model\n \n \n@@ -86,7 +86,7 @@ def test_regularization_shared_model():\n \n     model = create_multi_input_model_from(dummy_model, dummy_model)\n     model.compile(loss='categorical_crossentropy', optimizer='sgd')\n-    assert len(model.losses) == 6\n+    # assert len(model.losses) == 6\n \n \n def test_regularization_shared_layer_in_different_models():\n@@ -102,7 +102,7 @@ def test_regularization_shared_layer_in_different_models():\n \n     model = create_multi_input_model_from(*models)\n     model.compile(loss='categorical_crossentropy', optimizer='sgd')\n-    assert len(model.losses) == 8\n+    # assert len(model.losses) == 8\n \n \n if __name__ == '__main__':\n\n@@ -13,7 +13,6 @@ from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data\n from keras.models import model_from_json, model_from_yaml\n from keras import losses\n-from keras.engine.training_utils import make_batches\n \n \n input_dim = 16\n@@ -23,6 +22,19 @@ batch_size = 32\n epochs = 1\n \n \n+def make_batches(size, batch_size):\n+    \"\"\"Returns a list of batch indices (tuples of indices).\n+    # Arguments\n+        size: Integer, total size of the data to slice into batches.\n+        batch_size: Integer, batch size.\n+    # Returns\n+        A list of tuples of array indices.\n+    \"\"\"\n+    num_batches = (size + batch_size - 1) // batch_size  # round up\n+    return [(i * batch_size, min(size, (i + 1) * batch_size))\n+            for i in range(num_batches)]\n+\n+\n @pytest.fixture\n def in_tmpdir(tmpdir):\n     \"\"\"Runs a function in a temporary directory.\n@@ -331,13 +343,13 @@ def test_clone_functional_model():\n     new_model.compile('rmsprop', 'mse')\n     new_model.train_on_batch([val_a, val_b], val_out)\n \n-    # On top of new, non-Keras tensors\n-    input_a = keras.backend.variable(val_a)\n-    input_b = keras.backend.variable(val_b)\n-    new_model = keras.models.clone_model(\n-        model, input_tensors=[input_a, input_b])\n-    new_model.compile('rmsprop', 'mse')\n-    new_model.train_on_batch(None, val_out)\n+    # # On top of new, non-Keras tensors\n+    # input_a = keras.backend.variable(val_a)\n+    # input_b = keras.backend.variable(val_b)\n+    # new_model = keras.models.clone_model(\n+    #     model, input_tensors=[input_a, input_b])\n+    # new_model.compile('rmsprop', 'mse')\n+    # new_model.train_on_batch(None, val_out)\n \n \n def test_clone_functional_model_with_multi_outputs():\n@@ -393,12 +405,12 @@ def test_clone_sequential_model():\n     new_model.compile('rmsprop', 'mse')\n     new_model.train_on_batch(val_a, val_out)\n \n-    # On top of new, non-Keras tensor\n-    input_a = keras.backend.variable(val_a)\n-    new_model = keras.models.clone_model(\n-        model, input_tensors=input_a)\n-    new_model.compile('rmsprop', 'mse')\n-    new_model.train_on_batch(None, val_out)\n+    # # On top of new, non-Keras tensor\n+    # input_a = keras.backend.variable(val_a)\n+    # new_model = keras.models.clone_model(\n+    #     model, input_tensors=input_a)\n+    # new_model.compile('rmsprop', 'mse')\n+    # new_model.train_on_batch(None, val_out)\n \n \n def test_sequential_update_disabling():\n@@ -436,7 +448,6 @@ def test_sequential_deferred_build():\n \n     assert model.built is False\n     assert len(model.layers) == 2\n-    assert len(model.weights) == 0\n \n     model.train_on_batch(\n         np.random.random((2, 4)), np.random.random((2, 3)))\n@@ -466,10 +477,8 @@ def test_nested_sequential_deferred_build():\n \n     assert inner_model.built is False\n     assert len(inner_model.layers) == 2\n-    assert len(inner_model.weights) == 0\n     assert model.built is False\n     assert len(model.layers) == 2\n-    assert len(model.weights) == 0\n \n     model.train_on_batch(\n         np.random.random((2, 4)), np.random.random((2, 5)))\n\n@@ -16,11 +16,6 @@ def test_normalize_tuple():\n         conv_utils.normalize_tuple(['str', 'impossible'], 2, 'kernel_size')\n \n \n-def test_invalid_data_format():\n-    with pytest.raises(ValueError):\n-        K.normalize_data_format('channels_middle')\n-\n-\n def test_invalid_padding():\n     with pytest.raises(ValueError):\n         conv_utils.normalize_padding('diagonal')\n\n@@ -22,11 +22,10 @@ from flaky import flaky\n from keras.utils import GeneratorEnqueuer\n from keras.utils import OrderedEnqueuer\n from keras.utils import Sequence\n-from keras.utils.data_utils import _hash_file\n+from tensorflow.python.keras.utils.data_utils import _hash_file\n from keras.utils.data_utils import get_file\n-from keras.utils.data_utils import validate_file\n+from tensorflow.python.keras.utils.data_utils import validate_file\n from keras import backend as K\n-from keras.backend import load_backend\n \n pytestmark = pytest.mark.skipif(\n     six.PY2 and 'TRAVIS_PYTHON_VERSION' in os.environ,\n@@ -90,21 +89,17 @@ def test_data_utils(in_tmpdir):\n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n     data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n-    assert data_keras_home == os.path.dirname(load_backend._config_path)\n     os.remove(filepath)\n \n     _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n     if not os.path.exists(_keras_home):\n         os.makedirs(_keras_home)\n     os.environ['KERAS_HOME'] = _keras_home\n-    reload_module(load_backend)\n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n     data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n-    assert data_keras_home == os.path.dirname(load_backend._config_path)\n     os.environ.pop('KERAS_HOME')\n     shutil.rmtree(_keras_home)\n-    reload_module(load_backend)\n \n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n@@ -355,7 +350,7 @@ def test_ordered_enqueuer_fail_threads():\n         next(gen_output)\n \n \n-def test_ordered_enqueuer_timeout_threads():\n+def DISABLED_test_ordered_enqueuer_timeout_threads():\n     enqueuer = OrderedEnqueuer(SlowSequence([3, 10, 10, 3]),\n                                use_multiprocessing=False)\n \n@@ -428,7 +423,7 @@ def test_context_switch():\n     enqueuer2.stop()\n \n \n-def test_on_epoch_end_threads():\n+def DISABLED_test_on_epoch_end_threads():\n     enqueuer = OrderedEnqueuer(DummySequence([3, 10, 10, 3]),\n                                use_multiprocessing=False)\n     enqueuer.start(3, 10)\n@@ -444,7 +439,7 @@ def test_on_epoch_end_threads():\n     enqueuer.stop()\n \n \n-def test_on_epoch_end_threads_sequence_change_length():\n+def DISABLED_test_on_epoch_end_threads_sequence_change_length():\n     seq = LengthChangingSequence([3, 10, 10, 3])\n     enqueuer = OrderedEnqueuer(seq,\n                                use_multiprocessing=False)\n\n@@ -5,8 +5,6 @@ import marshal\n from keras.utils.generic_utils import custom_object_scope\n from keras.utils.generic_utils import has_arg\n from keras.utils.generic_utils import Progbar\n-from keras.utils.generic_utils import func_dump\n-from keras.utils.generic_utils import func_load\n from keras import activations\n from keras import regularizers\n \n@@ -81,57 +79,5 @@ def test_has_arg_positional_only():\n     assert has_arg(pow, 'x') is False\n \n \n-@pytest.mark.parametrize(\n-    'test_function_type',\n-    ('simple function', 'closured function'))\n-def test_func_dump_and_load(test_function_type):\n-\n-    if test_function_type == 'simple function':\n-        def test_func():\n-            return r'\\u'\n-\n-    elif test_function_type == 'closured function':\n-        def get_test_func():\n-            x = r'\\u'\n-\n-            def test_func():\n-                return x\n-            return test_func\n-        test_func = get_test_func()\n-    else:\n-        raise Exception('Unknown test case for test_func_dump_and_load')\n-\n-    serialized = func_dump(test_func)\n-    deserialized = func_load(serialized)\n-    assert deserialized.__code__ == test_func.__code__\n-    assert deserialized.__defaults__ == test_func.__defaults__\n-    assert deserialized.__closure__ == test_func.__closure__\n-\n-\n-def test_func_dump_and_load_closure():\n-    y = 0\n-    test_func = lambda x: x + y\n-    serialized, _, closure = func_dump(test_func)\n-    deserialized = func_load(serialized, closure=closure)\n-    assert deserialized.__code__ == test_func.__code__\n-    assert deserialized.__defaults__ == test_func.__defaults__\n-    assert deserialized.__closure__ == test_func.__closure__\n-\n-\n-@pytest.mark.parametrize(\n-    'test_func', [activations.softmax, np.argmax, lambda x: x**2, lambda x: x])\n-def test_func_dump_and_load_backwards_compat(test_func):\n-    # this test ensures that models serialized prior to version 2.1.2 can still be\n-    # deserialized\n-\n-    # see:\n-    # https://github.com/evhub/keras/blob/2.1.1/keras/utils/generic_utils.py#L166\n-    serialized = marshal.dumps(test_func.__code__).decode('raw_unicode_escape')\n-\n-    deserialized = func_load(serialized, defaults=test_func.__defaults__)\n-    assert deserialized.__code__ == test_func.__code__\n-    assert deserialized.__defaults__ == test_func.__defaults__\n-    assert deserialized.__closure__ == test_func.__closure__\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -1,352 +0,0 @@\n-'''Tests for functions in io_utils.py.\n-'''\n-import os\n-import io\n-import pytest\n-\n-from contextlib import contextmanager\n-\n-from keras.models import Sequential\n-from keras.layers import Dense\n-from keras.utils.io_utils import HDF5Matrix\n-from keras.utils.io_utils import H5Dict\n-from keras.utils.io_utils import ask_to_proceed_with_overwrite\n-from keras.utils.io_utils import save_to_binary_h5py\n-from keras.utils.io_utils import load_from_binary_h5py\n-from numpy.testing import assert_allclose\n-from numpy.testing import assert_array_equal\n-import numpy as np\n-import six\n-import h5py\n-import tempfile\n-try:\n-    from pathlib import Path\n-    from unittest.mock import patch\n-except:\n-    from pathlib2 import Path\n-    from mock import patch\n-\n-\n-@pytest.fixture\n-def in_tmpdir(tmpdir):\n-    \"\"\"Runs a function in a temporary directory.\n-\n-    Checks that the directory is empty afterwards.\n-    \"\"\"\n-    with tmpdir.as_cwd():\n-        yield None\n-    assert not tmpdir.listdir()\n-\n-\n-def create_dataset(h5_path='test.h5'):\n-    X = np.random.randn(200, 10).astype('float32')\n-    y = np.random.randint(0, 2, size=(200, 1))\n-    with h5py.File(h5_path, 'w') as f:\n-        # Creating dataset to store features\n-        X_dset = f.create_dataset('my_data', (200, 10), dtype='f')\n-        X_dset[:] = X\n-        # Creating dataset to store labels\n-        y_dset = f.create_dataset('my_labels', (200, 1), dtype='i')\n-        y_dset[:] = y\n-\n-\n-def test_io_utils(in_tmpdir):\n-    '''Tests the HDF5Matrix code using the sample from @jfsantos at\n-    https://gist.github.com/jfsantos/e2ef822c744357a4ed16ec0c885100a3\n-    '''\n-    _, h5_path = tempfile.mkstemp('.h5')\n-    create_dataset(h5_path)\n-\n-    # Instantiating HDF5Matrix for the training set,\n-    # which is a slice of the first 150 elements\n-    X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150)\n-    y_train = HDF5Matrix(h5_path, 'my_labels', start=0, end=150)\n-\n-    # Likewise for the test set\n-    X_test = HDF5Matrix(h5_path, 'my_data', start=150, end=200)\n-    y_test = HDF5Matrix(h5_path, 'my_labels', start=150, end=200)\n-\n-    # HDF5Matrix behave more or less like Numpy matrices with regards to indexing\n-    assert y_train.shape == (150, 1), 'HDF5Matrix shape should match input array'\n-    # But they do not support negative indices, so don't try print(X_train[-1])\n-\n-    assert y_train.dtype == np.dtype('i'), (\n-        'HDF5Matrix dtype should match input array')\n-    assert y_train.ndim == 2, 'HDF5Matrix ndim should match input array'\n-    assert y_train.size == 150, 'HDF5Matrix ndim should match input array'\n-\n-    model = Sequential()\n-    model.add(Dense(64, input_shape=(10,), activation='relu'))\n-    model.add(Dense(1, activation='sigmoid'))\n-\n-    model.compile(loss='binary_crossentropy', optimizer='sgd')\n-\n-    # Note: you have to use shuffle='batch' or False with HDF5Matrix\n-    model.fit(X_train, y_train, batch_size=32, shuffle='batch', verbose=False)\n-    # test that evalutation and prediction don't crash and\n-    # return reasonable results\n-    out_pred = model.predict(X_test, batch_size=32, verbose=False)\n-    out_eval = model.evaluate(X_test, y_test, batch_size=32, verbose=False)\n-\n-    assert out_pred.shape == (50, 1), 'Prediction shape does not match'\n-    assert out_eval > 0, (\n-        'Evaluation value does not meet criteria: {}'.format(out_eval))\n-\n-    # test slicing for shortened array\n-    assert len(X_train[0:]) == len(X_train), 'Incorrect shape for sliced data'\n-\n-    # test __getitem__\n-    with pytest.raises(IndexError):\n-        X_train[1000]\n-    with pytest.raises(IndexError):\n-        X_train[1000:1001]\n-    with pytest.raises(IndexError):\n-        X_train[[1000, 1001]]\n-    with pytest.raises(IndexError):\n-        X_train[six.moves.range(1000, 1001)]\n-    with pytest.raises(IndexError):\n-        X_train[np.array([1000])]\n-    with pytest.raises(TypeError):\n-        X_train[None]\n-    assert (X_train[0] == X_train[:1][0]).all()\n-    assert (X_train[[0, 1]] == X_train[:2]).all()\n-    assert (X_train[np.array([0, 1])] == X_train[:2]).all()\n-\n-    # test normalizer\n-    normalizer = lambda x: x + 1\n-    normalized_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n-                                    normalizer=normalizer)\n-    assert np.isclose(normalized_X_train[0][0], X_train[0][0] + 1)\n-\n-    # test resizing normalizer\n-    normalizer_rs = lambda x: x[:, ::2]\n-    normalized_rs_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n-                                       normalizer=normalizer_rs)\n-    assert (normalized_rs_X_train.shape[1] == 5)\n-\n-    # test dtype changing normalizer\n-    normalizer_dtype = lambda x: x.astype(np.uint8)\n-    normalized_dtype_X_train = HDF5Matrix(h5_path, 'my_data', start=0, end=150,\n-                                          normalizer=normalizer_dtype)\n-    assert (normalized_dtype_X_train.dtype == np.uint8)\n-\n-    os.remove(h5_path)\n-\n-\n-def test_ask_to_proceed_with_overwrite():\n-    with patch('six.moves.input') as mock:\n-        mock.return_value = 'y'\n-        assert ask_to_proceed_with_overwrite('/tmp/not_exists')\n-\n-        mock.return_value = 'n'\n-        assert not ask_to_proceed_with_overwrite('/tmp/not_exists')\n-\n-\n-def test_H5Dict_attrs():\n-    _, h5_path = tempfile.mkstemp('.h5')\n-\n-    # test both HDF5 and dict implementations\n-    paths = [h5_path, dict()]\n-\n-    for path in paths:\n-        f = H5Dict(path, mode='w')\n-\n-        # str\n-        f['x'] = 'abcd'\n-        f['x2'] = u'abcd'\n-\n-        # list<bytes>\n-        f['y'] = [b'efg', b'hij', b'klmn']\n-        f['y2'] = (b'asd', b'sdf', b'dfg')\n-\n-        # ndarray\n-        array = np.random.random((4, 5, 512))\n-        f['z'] = array\n-\n-        f.close()\n-        del f\n-\n-        f = H5Dict(path, mode='r')\n-\n-        assert f['x'] == 'abcd'\n-        assert f['x2'] == u'abcd'\n-        assert f['y'] == [b'efg', b'hij', b'klmn']\n-        assert list(f['y2']) == [b'asd', b'sdf', b'dfg']\n-        assert_allclose(f['z'], array)\n-\n-        f.close()\n-    os.remove(h5_path)\n-\n-\n-def test_H5Dict_groups():\n-    _, h5_path = tempfile.mkstemp('.h5')\n-\n-    # test both HDF5 and dict implementations\n-    paths = [h5_path, dict()]\n-\n-    for path in paths:\n-        f = H5Dict(path, mode='w')\n-\n-        group1 = f['group1']\n-        group2 = group1['group2']\n-\n-        group2['x'] = 'abcd'\n-\n-        group3 = group2['group3']\n-        group3['y'] = [b'efg', b'hij', b'klmn']\n-\n-        group4 = group3['group4']\n-        array = np.random.random((4, 5, 512))\n-        group4['z'] = array\n-\n-        f.close()\n-\n-        f = H5Dict(path, mode='r')\n-\n-        assert 'group1' in f\n-        group1 = f['group1']\n-\n-        assert 'group2' in group1\n-        group2 = group1['group2']\n-        assert group2['x'] == 'abcd'\n-\n-        assert 'group3' in group2\n-        group3 = group2['group3']\n-        assert group3['y'] == [b'efg', b'hij', b'klmn']\n-\n-        assert 'group4' in group3\n-        group4 = group3['group4']\n-        assert_allclose(group4['z'], array)\n-\n-        f.close()\n-    os.remove(h5_path)\n-\n-\n-def test_H5Dict_accepts_pathlib_Path():\n-    \"\"\"GitHub issue: 11459\"\"\"\n-    _, h5_path = tempfile.mkstemp('.h5')\n-\n-    f = H5Dict(Path(h5_path), mode='w')\n-    f['x'] = 'abcd'\n-    f.close()\n-    del f\n-\n-    f = H5Dict(Path(h5_path), mode='r')\n-    assert f['x'] == 'abcd'\n-    f.close()\n-\n-    os.remove(h5_path)\n-\n-\n-@contextmanager\n-def temp_filename(suffix):\n-    \"\"\"Context that returns a temporary filename and deletes the file on exit if\n-    it still exists (so that this is not forgotten).\n-    \"\"\"\n-    _, temp_fname = tempfile.mkstemp(suffix=suffix)\n-    yield temp_fname\n-    if os.path.exists(temp_fname):\n-        os.remove(temp_fname)\n-\n-\n-def test_save_to_binary_h5py_direct_to_file():\n-    data = np.random.random((3, 5))\n-\n-    def save_function(h5file_):\n-        h5file_['data'] = data\n-\n-    with temp_filename('.h5') as fname:\n-        with open(fname, 'wb') as f:\n-            save_to_binary_h5py(save_function, f)\n-\n-        with h5py.File(fname) as h5file:\n-            data_rec = h5file['data'][:]\n-\n-    assert_array_equal(data_rec, data)\n-\n-\n-def test_save_to_binary_h5py_to_bytes_io():\n-    data = np.random.random((3, 5))\n-\n-    def save_function(h5file_):\n-        h5file_['data'] = data\n-\n-    file_like = io.BytesIO()\n-    save_to_binary_h5py(save_function, file_like)\n-\n-    file_like.seek(0)\n-\n-    with temp_filename('.h5') as fname:\n-        with open(fname, 'wb') as f:\n-            f.write(file_like.read())\n-\n-        with h5py.File(fname) as h5file:\n-            data_rec = h5file['data'][:]\n-\n-    assert_array_equal(data_rec, data)\n-\n-\n-def test_load_from_binary_h5py_direct_from_file():\n-    data = np.random.random((3, 5))\n-\n-    def load_function(h5file_):\n-        return h5file_['data'][:]\n-\n-    with temp_filename('.h5') as fname:\n-        with h5py.File(fname, 'w') as h5file:\n-            h5file['data'] = data\n-\n-        with open(fname, 'rb') as f:\n-            data_rec = load_from_binary_h5py(load_function, f)\n-\n-    assert_array_equal(data_rec, data)\n-\n-\n-def test_load_from_binary_h5py_from_bytes_io():\n-    data = np.random.random((3, 5))\n-\n-    def load_function(h5file_):\n-        return h5file_['data'][:]\n-\n-    with temp_filename('.h5') as fname:\n-        with h5py.File(fname, 'w') as h5file:\n-            h5file['data'] = data\n-\n-        file_like = io.BytesIO()\n-        with open(fname, 'rb') as f:\n-            file_like.write(f.read())\n-\n-    file_like.seek(0)\n-    data_rec = load_from_binary_h5py(load_function, file_like)\n-\n-    assert_array_equal(data_rec, data)\n-\n-\n-def test_save_load_binary_h5py():\n-\n-    data1 = np.random.random((3, 5))\n-    data2 = np.random.random((2, 3, 5))\n-    attr = 1\n-    datas = [data1, data2, attr]\n-\n-    def save_function(h5file_):\n-        h5file_['data1'] = data1\n-        h5file_['subgroup/data2'] = data2\n-        h5file_['data1'].attrs['attr'] = attr\n-\n-    def load_function(h5file_):\n-        d1 = h5file_['data1'][:]\n-        d2 = h5file_['subgroup/data2'][:]\n-        a = h5file_['data1'].attrs['attr']\n-        return d1, d2, a\n-\n-    file_like = io.BytesIO()\n-    save_to_binary_h5py(save_function, file_like)\n-    file_like.seek(0)\n-    datas_rec = load_from_binary_h5py(load_function, file_like)\n-    for d_rec, d in zip(datas_rec, datas):\n-        assert_array_equal(d_rec, d)\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -9,7 +9,7 @@ from keras.models import Sequential\n from keras.utils import layer_utils\n \n \n-def test_convert_weights():\n+def DISABLED_test_convert_weights():\n     def get_model(shape, data_format):\n         model = Sequential()\n         model.add(Conv2D(filters=2,\n\n@@ -1,304 +0,0 @@\n-\"\"\"These tests are not meant to be run on CI.\n-\"\"\"\n-from __future__ import print_function\n-\n-import keras\n-from keras import backend as K\n-from keras.utils import multi_gpu_model\n-\n-import numpy as np\n-import pytest\n-import time\n-import tempfile\n-import tensorflow as tf\n-from keras.preprocessing.image import ImageDataGenerator\n-\n-\n-pytestmark = pytest.mark.skipif(K.backend() != 'tensorflow',\n-                                reason='Requires TF.')\n-if K.backend() == 'tensorflow':\n-    available_devices = keras.utils.multi_gpu_utils._get_available_devices()\n-    available_devices = [keras.utils.multi_gpu_utils._normalize_device_name(name)\n-                         for name in available_devices]\n-    pytestmark = pytest.mark.skipif('/gpu:7' not in available_devices,\n-                                    reason='Requires 8 GPUs.')\n-\n-\n-def test_multi_gpu_simple_model():\n-    print('####### test simple model')\n-    num_samples = 1000\n-    input_dim = 10\n-    output_dim = 1\n-    hidden_dim = 10\n-    gpus = 8\n-    target_gpu_id = [0, 2, 4]\n-    epochs = 2\n-    model = keras.models.Sequential()\n-    model.add(keras.layers.Dense(hidden_dim,\n-                                 input_shape=(input_dim,)))\n-    model.add(keras.layers.Dense(output_dim))\n-\n-    x = np.random.random((num_samples, input_dim))\n-    y = np.random.random((num_samples, output_dim))\n-\n-    parallel_model = multi_gpu_model(model, gpus=gpus)\n-    parallel_model.compile(loss='mse', optimizer='rmsprop')\n-    parallel_model.fit(x, y, epochs=epochs)\n-\n-    parallel_model = multi_gpu_model(model, gpus=target_gpu_id)\n-    parallel_model.compile(loss='mse', optimizer='rmsprop')\n-    parallel_model.fit(x, y, epochs=epochs)\n-\n-\n-def test_multi_gpu_multi_io_model():\n-    print('####### test multi-io model')\n-    num_samples = 1000\n-    input_dim_a = 10\n-    input_dim_b = 5\n-    output_dim_a = 1\n-    output_dim_b = 2\n-    hidden_dim = 10\n-    gpus = 8\n-    target_gpu_id = [0, 2, 4]\n-    epochs = 2\n-\n-    input_a = keras.Input((input_dim_a,))\n-    input_b = keras.Input((input_dim_b,))\n-    a = keras.layers.Dense(hidden_dim)(input_a)\n-    b = keras.layers.Dense(hidden_dim)(input_b)\n-    c = keras.layers.concatenate([a, b])\n-    output_a = keras.layers.Dense(output_dim_a)(c)\n-    output_b = keras.layers.Dense(output_dim_b)(c)\n-    model = keras.models.Model([input_a, input_b], [output_a, output_b])\n-\n-    a_x = np.random.random((num_samples, input_dim_a))\n-    b_x = np.random.random((num_samples, input_dim_b))\n-    a_y = np.random.random((num_samples, output_dim_a))\n-    b_y = np.random.random((num_samples, output_dim_b))\n-\n-    parallel_model = multi_gpu_model(model, gpus=gpus)\n-    parallel_model.compile(loss='mse', optimizer='rmsprop')\n-    parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n-\n-    parallel_model = multi_gpu_model(model, gpus=target_gpu_id)\n-    parallel_model.compile(loss='mse', optimizer='rmsprop')\n-    parallel_model.fit([a_x, b_x], [a_y, b_y], epochs=epochs)\n-\n-\n-def test_multi_gpu_invalid_devices():\n-    input_shape = (1000, 10)\n-    model = keras.models.Sequential()\n-    model.add(keras.layers.Dense(10,\n-                                 activation='relu',\n-                                 input_shape=input_shape[1:]))\n-    model.add(keras.layers.Dense(1, activation='sigmoid'))\n-\n-    x = np.random.random(input_shape)\n-    y = np.random.random((input_shape[0], 1))\n-    with pytest.raises(ValueError):\n-        parallel_model = multi_gpu_model(model, gpus=10)\n-        parallel_model.compile(loss='mse', optimizer='rmsprop')\n-        parallel_model.fit(x, y, epochs=2)\n-\n-    with pytest.raises(ValueError):\n-        parallel_model = multi_gpu_model(model, gpus=[0, 2, 4, 6, 8])\n-        parallel_model.compile(loss='mse', optimizer='rmsprop')\n-        parallel_model.fit(x, y, epochs=2)\n-\n-    with pytest.raises(ValueError):\n-        parallel_model = multi_gpu_model(model, gpus=1)\n-        parallel_model.compile(loss='mse', optimizer='rmsprop')\n-        parallel_model.fit(x, y, epochs=2)\n-\n-    with pytest.raises(ValueError):\n-        parallel_model = multi_gpu_model(model, gpus=[0])\n-        parallel_model.compile(loss='mse', optimizer='rmsprop')\n-        parallel_model.fit(x, y, epochs=2)\n-\n-\n-def test_serialization():\n-    model = keras.models.Sequential()\n-    model.add(keras.layers.Dense(3,\n-                                 input_shape=(4,)))\n-    model.add(keras.layers.Dense(4))\n-\n-    x = np.random.random((100, 4))\n-    y = np.random.random((100, 4))\n-\n-    parallel_model = multi_gpu_model(model, gpus=2)\n-    parallel_model.compile(loss='mse', optimizer='rmsprop')\n-    parallel_model.fit(x, y, epochs=1)\n-\n-    ref_output = parallel_model.predict(x)\n-\n-    _, fname = tempfile.mkstemp('.h5')\n-    parallel_model.save(fname)\n-\n-    K.clear_session()\n-    parallel_model = keras.models.load_model(fname)\n-    output = parallel_model.predict(x)\n-    np.testing.assert_allclose(ref_output, output, atol=1e-5)\n-\n-\n-def multi_gpu_application_np_array_benchmark():\n-    print('####### Xception benchmark - np i/o')\n-    model_cls = keras.applications.Xception\n-\n-    num_samples = 1000\n-    height = 224\n-    width = 224\n-    num_classes = 1000\n-    epochs = 4\n-    batch_size = 40\n-    x = np.random.random((num_samples, height, width, 3))\n-    y = np.random.random((num_samples, num_classes))\n-\n-    # Baseline\n-    model = model_cls(weights=None,\n-                      input_shape=(height, width, 3),\n-                      classes=num_classes)\n-    model.compile(loss='categorical_crossentropy',\n-                  optimizer='rmsprop')\n-\n-    # Training\n-    start_time = time.time()\n-    model.fit(x, y, epochs=epochs)\n-    total_time = time.time() - start_time\n-    print('baseline training:', total_time)\n-\n-    # Inference\n-    start_time = time.time()\n-    model.predict(x)\n-    total_time = time.time() - start_time\n-    print('baseline inference:', total_time)\n-\n-    for i in range(2, 9, 2):\n-        K.clear_session()\n-        with tf.device('/cpu:0'):\n-            model = model_cls(weights=None,\n-                              input_shape=(height, width, 3),\n-                              classes=num_classes)\n-        parallel_model = multi_gpu_model(model, gpus=i)\n-        parallel_model.compile(loss='categorical_crossentropy',\n-                               optimizer='rmsprop')\n-\n-        start_time = time.time()\n-        parallel_model.fit(x, y, epochs=epochs, batch_size=batch_size)\n-        total_time = time.time() - start_time\n-        print('%d gpus training:' % i, total_time)\n-\n-        # Inference\n-        start_time = time.time()\n-        parallel_model.predict(x, batch_size=batch_size)\n-        total_time = time.time() - start_time\n-        print('%d gpus inference:' % i, total_time)\n-\n-\n-def multi_gpu_application_folder_generator_benchmark():\n-    \"\"\"Before running this test:\n-\n-    wget https://s3.amazonaws.com/img-datasets/cats_and_dogs_small.zip\n-    unzip cats_and_dogs_small.zip\n-    \"\"\"\n-    print('####### Xception benchmark - folder generator i/o')\n-    model_cls = keras.applications.Xception\n-\n-    height = 150\n-    width = 150\n-    num_classes = 2\n-    epochs = 3\n-    steps_per_epoch = 100\n-    batch_size = 64\n-\n-    # Baseline\n-    model = model_cls(weights=None,\n-                      input_shape=(height, width, 3),\n-                      classes=num_classes)\n-    model.compile(loss='categorical_crossentropy',\n-                  optimizer='rmsprop')\n-\n-    datagen = ImageDataGenerator(\n-        rotation_range=40,\n-        width_shift_range=0.2,\n-        height_shift_range=0.2,\n-        shear_range=0.2,\n-        zoom_range=0.2,\n-        horizontal_flip=True,\n-        fill_mode='nearest')\n-    train_dir = '/home/ubuntu/cats_and_dogs_small/train'  # Change this\n-    train_gen = datagen.flow_from_directory(\n-        train_dir,\n-        target_size=(height, width),\n-        batch_size=batch_size,\n-        class_mode='categorical')\n-\n-    # Training\n-    start_time = time.time()\n-    model.fit_generator(train_gen,\n-                        steps_per_epoch=steps_per_epoch,\n-                        epochs=epochs,\n-                        workers=4)\n-    total_time = time.time() - start_time\n-    print('baseline training:', total_time)\n-\n-    for i in range(2, 9):\n-        K.clear_session()\n-        with tf.device('/cpu:0'):\n-            model = model_cls(weights=None,\n-                              input_shape=(height, width, 3),\n-                              classes=num_classes)\n-        parallel_model = multi_gpu_model(model, gpus=i)\n-        parallel_model.compile(loss='categorical_crossentropy',\n-                               optimizer='rmsprop')\n-\n-        train_gen = datagen.flow_from_directory(\n-            train_dir,\n-            target_size=(height, width),\n-            batch_size=batch_size,\n-            class_mode='categorical')\n-\n-        start_time = time.time()\n-        parallel_model.fit_generator(\n-            train_gen,\n-            steps_per_epoch=steps_per_epoch,\n-            epochs=epochs,\n-            workers=4 * i)\n-        total_time = time.time() - start_time\n-        print('%d gpus training:' % i, total_time)\n-\n-\n-def test_multi_gpu_with_multi_input_layers():\n-    inputs = keras.Input((4, 3))\n-    init_state = keras.Input((3,))\n-    outputs = keras.layers.SimpleRNN(\n-        3, return_sequences=True)(inputs, initial_state=init_state)\n-    x = [np.random.randn(2, 4, 3), np.random.randn(2, 3)]\n-    y = np.random.randn(2, 4, 3)\n-    model = keras.models.Model([inputs, init_state], outputs)\n-    parallel_model = multi_gpu_model(model, 2)\n-    parallel_model.compile(loss='mean_squared_error', optimizer='adam')\n-    parallel_model.train_on_batch(x, y)\n-\n-\n-def test_multi_gpu_with_siamese():\n-    input_shape = (3,)\n-    nested_model = keras.models.Sequential([\n-        keras.layers.Dense(32, input_shape=input_shape),\n-        keras.layers.Dense(1)\n-    ], name='nested')\n-\n-    input1 = keras.Input(input_shape)\n-    input2 = keras.Input(input_shape)\n-    score1 = nested_model(input1)\n-    score2 = nested_model(input2)\n-    score_sum = keras.layers.Add(name='add')([score1, score2])\n-\n-    siamese = keras.models.Model(inputs=[input1, input2],\n-                                 outputs=[score_sum, score1, score2],\n-                                 name='siamese')\n-    parallel_siamese = multi_gpu_model(siamese, 2)\n-    assert parallel_siamese.output_names == ['add', 'nested_1', 'nested_2']\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -167,11 +167,11 @@ def assert_regression_works(reg):\n     assert preds.shape == (num_test, )\n \n \n-def test_regression_predict_shape_correct_num_test_0():\n+def DISABLED_test_regression_predict_shape_correct_num_test_0():\n     assert_regression_predict_shape_correct(num_test=0)\n \n \n-def test_regression_predict_shape_correct_num_test_1():\n+def DISABLED_test_regression_predict_shape_correct_num_test_1():\n     assert_regression_predict_shape_correct(num_test=1)\n \n \n\n@@ -2,7 +2,6 @@ import numpy as np\n import pytest\n \n from keras.models import Sequential\n-from keras.engine.training_utils import weighted_masked_objective\n from keras.layers import TimeDistributed, Masking, Dense\n from keras import losses\n from keras import backend as K\n@@ -34,22 +33,5 @@ def test_masking_is_all_zeros():\n     assert loss == 0\n \n \n-def test_loss_masking():\n-    weighted_loss = weighted_masked_objective(losses.get('mae'))\n-    shape = (3, 4, 2)\n-    x = np.arange(24).reshape(shape)\n-    y = 2 * x\n-\n-    # Normally the trailing 1 is added by standardize_weights\n-    weights = np.ones((3,))\n-    mask = np.ones((3, 4))\n-    mask[1, 0] = 0\n-\n-    out = K.eval(weighted_loss(K.variable(x),\n-                               K.variable(y),\n-                               K.variable(weights),\n-                               K.variable(mask)))\n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -1,147 +0,0 @@\n-import pytest\n-import sys\n-import numpy as np\n-from numpy.testing import assert_allclose\n-\n-import keras\n-from keras import layers\n-from keras import optimizers\n-from keras import losses\n-from keras import metrics\n-\n-if sys.version_info[0] == 3:\n-    import pickle\n-else:\n-    import cPickle as pickle\n-\n-\n-def test_sequential_model_pickling():\n-    model = keras.Sequential()\n-    model.add(layers.Dense(2, input_shape=(3,)))\n-    model.add(layers.RepeatVector(3))\n-    model.add(layers.TimeDistributed(layers.Dense(3)))\n-    model.compile(loss=losses.MSE,\n-                  optimizer=optimizers.RMSprop(lr=0.0001),\n-                  metrics=[metrics.categorical_accuracy],\n-                  sample_weight_mode='temporal')\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3, 3))\n-    model.train_on_batch(x, y)\n-\n-    out = model.predict(x)\n-\n-    state = pickle.dumps(model)\n-\n-    new_model = pickle.loads(state)\n-\n-    out2 = new_model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-    # test that new updates are the same with both models\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3, 3))\n-    model.train_on_batch(x, y)\n-    new_model.train_on_batch(x, y)\n-    out = model.predict(x)\n-    out2 = new_model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-\n-def test_sequential_model_pickling_custom_objects():\n-    # test with custom optimizer, loss\n-    class CustomSGD(optimizers.SGD):\n-        pass\n-\n-    def custom_mse(*args, **kwargs):\n-        return losses.mse(*args, **kwargs)\n-\n-    model = keras.Sequential()\n-    model.add(layers.Dense(2, input_shape=(3,)))\n-    model.add(layers.Dense(3))\n-    model.compile(loss=custom_mse, optimizer=CustomSGD(), metrics=['acc'])\n-\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-\n-    out = model.predict(x)\n-\n-    state = pickle.dumps(model)\n-\n-    with keras.utils.CustomObjectScope(\n-            {'CustomSGD': CustomSGD, 'custom_mse': custom_mse}):\n-        model = pickle.loads(state)\n-\n-    out2 = model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-\n-def test_functional_model_pickling():\n-    inputs = keras.Input(shape=(3,))\n-    x = layers.Dense(2)(inputs)\n-    outputs = layers.Dense(3)(x)\n-\n-    model = keras.Model(inputs, outputs)\n-    model.compile(loss=losses.MSE,\n-                  optimizer=optimizers.Adam(),\n-                  metrics=[metrics.categorical_accuracy])\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-\n-    out = model.predict(x)\n-    state = pickle.dumps(model)\n-\n-    model = pickle.loads(state)\n-\n-    out2 = model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-\n-def test_pickling_multiple_metrics_outputs():\n-    inputs = keras.Input(shape=(5,))\n-    x = layers.Dense(5)(inputs)\n-    output1 = layers.Dense(1, name='output1')(x)\n-    output2 = layers.Dense(1, name='output2')(x)\n-\n-    model = keras.Model(inputs=inputs, outputs=[output1, output2])\n-\n-    metrics = {'output1': ['mse', 'binary_accuracy'],\n-               'output2': ['mse', 'binary_accuracy']\n-               }\n-    loss = {'output1': 'mse', 'output2': 'mse'}\n-\n-    model.compile(loss=loss, optimizer='sgd', metrics=metrics)\n-\n-    # assure that model is working\n-    x = np.array([[1, 1, 1, 1, 1]])\n-    out = model.predict(x)\n-\n-    model = pickle.loads(pickle.dumps(model))\n-\n-    out2 = model.predict(x)\n-    assert_allclose(out, out2, atol=1e-05)\n-\n-\n-def test_pickling_without_compilation():\n-    \"\"\"Test pickling model without compiling.\n-    \"\"\"\n-    model = keras.Sequential()\n-    model.add(layers.Dense(2, input_shape=(3,)))\n-    model.add(layers.Dense(3))\n-\n-    model = pickle.loads(pickle.dumps(model))\n-\n-\n-def test_pickling_right_after_compilation():\n-    model = keras.Sequential()\n-    model.add(layers.Dense(2, input_shape=(3,)))\n-    model.add(layers.Dense(3))\n-    model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n-    model._make_train_function()\n-\n-    model = pickle.loads(pickle.dumps(model))\n-\n-\n-if __name__ == '__main__':\n-    pytest.main([__file__])\n\n@@ -10,10 +10,9 @@ from numpy.testing import assert_allclose\n from numpy.testing import assert_raises\n \n from keras import backend as K\n-from keras.engine.saving import preprocess_weights_for_loading\n from keras.models import Model, Sequential\n from keras.layers import Dense, Lambda, RepeatVector, TimeDistributed\n-from keras.layers import Bidirectional, GRU, LSTM, CuDNNGRU, CuDNNLSTM\n+from keras.layers import Bidirectional, GRU, LSTM\n from keras.layers import Conv2D, Flatten, Activation\n from keras.layers import Input, InputLayer\n from keras.initializers import Constant\n@@ -21,17 +20,13 @@ from keras import optimizers\n from keras import losses\n from keras import metrics\n from keras.models import save_model, load_model\n-from keras.utils.test_utils import tf_file_io_proxy\n try:\n     from unittest.mock import patch\n except:\n     from mock import patch\n \n \n-skipif_no_tf_gpu = pytest.mark.skipif(\n-    (K.backend() != 'tensorflow' or\n-     not K.tensorflow_backend._get_available_gpus()),\n-    reason='Requires TensorFlow backend and a GPU')\n+skipif_no_tf_gpu = True\n \n \n def test_sequential_model_saving():\n@@ -51,22 +46,14 @@ def test_sequential_model_saving():\n \n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n-    new_model_disk = load_model(fname)\n+    new_model = load_model(fname)\n     os.remove(fname)\n \n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n-        save_model(model, gcs_filepath)\n-        file_io_proxy.assert_exists(gcs_filepath)\n-        new_model_gcs = load_model(gcs_filepath)\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-\n     x2 = np.random.random((1, 3))\n     y2 = np.random.random((1, 3, 3))\n     model.train_on_batch(x2, y2)\n     out_2 = model.predict(x2)\n \n-    for new_model in [new_model_disk, new_model_gcs]:\n     new_out = new_model.predict(x)\n     assert_allclose(out, new_out, atol=1e-05)\n     # test that new updates are the same with both models\n@@ -77,7 +64,7 @@ def test_sequential_model_saving():\n \n def test_sequential_model_saving_2():\n     # test with custom optimizer, loss\n-    custom_opt = optimizers.rmsprop\n+    custom_opt = optimizers.RMSprop\n     custom_loss = losses.mse\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,)))\n@@ -93,17 +80,9 @@ def test_sequential_model_saving_2():\n                                       'custom_loss': custom_loss}}\n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n-    new_model_disk = load_model(fname, **load_kwargs)\n+    new_model = load_model(fname, **load_kwargs)\n     os.remove(fname)\n \n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n-        save_model(model, gcs_filepath)\n-        file_io_proxy.assert_exists(gcs_filepath)\n-        new_model_gcs = load_model(gcs_filepath, **load_kwargs)\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-\n-    for new_model in [new_model_disk, new_model_gcs]:\n     new_out = new_model.predict(x)\n     assert_allclose(out, new_out, atol=1e-05)\n \n@@ -129,22 +108,14 @@ def test_functional_model_saving():\n     out = model.predict(x)\n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n-    new_model_disk = load_model(fname)\n+    new_model = load_model(fname)\n     os.remove(fname)\n \n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(filename=fname)\n-        save_model(model, gcs_filepath)\n-        file_io_proxy.assert_exists(gcs_filepath)\n-        new_model_gcs = load_model(gcs_filepath)\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-\n-    for new_model in [new_model_disk, new_model_gcs]:\n     new_out = new_model.predict(x)\n     assert_allclose(out, new_out, atol=1e-05)\n \n \n-def test_model_saving_to_pre_created_h5py_file():\n+def DISABLED_test_model_saving_to_pre_created_h5py_file():\n     model, x = _get_sample_model_and_input()\n \n     out = model.predict(x)\n@@ -182,7 +153,7 @@ def temp_filename(filename):\n         os.remove(temp_fname)\n \n \n-def test_model_saving_to_binary_stream():\n+def DISABLED_test_model_saving_to_binary_stream():\n     model, x = _get_sample_model_and_input()\n     out = model.predict(x)\n \n@@ -197,7 +168,7 @@ def test_model_saving_to_binary_stream():\n     assert_allclose(out, out2, atol=1e-05)\n \n \n-def test_model_loading_from_binary_stream():\n+def DISABLED_test_model_loading_from_binary_stream():\n     model, x = _get_sample_model_and_input()\n     out = model.predict(x)\n \n@@ -212,7 +183,7 @@ def test_model_loading_from_binary_stream():\n     assert_allclose(out, out2, atol=1e-05)\n \n \n-def test_model_save_load_binary_in_memory():\n+def DISABLED_test_model_save_load_binary_in_memory():\n     model, x = _get_sample_model_and_input()\n     out = model.predict(x)\n \n@@ -270,7 +241,6 @@ def test_saving_right_after_compilation():\n     model.add(Dense(2, input_shape=(3,)))\n     model.add(Dense(3))\n     model.compile(loss='mse', optimizer='sgd', metrics=['acc'])\n-    model._make_train_function()\n \n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n@@ -291,103 +261,19 @@ def test_saving_unused_layers_is_ok():\n     os.remove(fname)\n \n \n-def test_loading_weights_by_name_and_reshape():\n-    \"\"\"\n-    test loading model weights by name on:\n-        - sequential model\n-    \"\"\"\n-\n-    # test with custom optimizer, loss\n-    custom_opt = optimizers.rmsprop\n-    custom_loss = losses.mse\n-\n-    # sequential model\n-    model = Sequential()\n-    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name='rick'))\n-    model.add(Flatten())\n-    model.add(Dense(3, name='morty'))\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n-\n-    x = np.random.random((1, 1, 1, 1))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-\n-    out = model.predict(x)\n-    old_weights = [layer.get_weights() for layer in model.layers]\n-    _, fname = tempfile.mkstemp('.h5')\n-\n-    model.save_weights(fname)\n-\n-    # delete and recreate model\n-    del(model)\n-    model = Sequential()\n-    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), name='rick'))\n-    model.add(Conv2D(3, (1, 1), name='morty'))\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n-\n-    # load weights from first model\n-    with pytest.raises(ValueError):\n-        model.load_weights(fname, by_name=True, reshape=False)\n-    with pytest.raises(ValueError):\n-        model.load_weights(fname, by_name=False, reshape=False)\n-    model.load_weights(fname, by_name=False, reshape=True)\n-    model.load_weights(fname, by_name=True, reshape=True)\n-\n-    out2 = model.predict(x)\n-    assert_allclose(np.squeeze(out), np.squeeze(out2), atol=1e-05)\n-    for i in range(len(model.layers)):\n-        new_weights = model.layers[i].get_weights()\n-        for j in range(len(new_weights)):\n-            # only compare layers that have weights, skipping Flatten()\n-            if old_weights[i]:\n-                assert_allclose(old_weights[i][j], new_weights[j], atol=1e-05)\n-\n-    # delete and recreate model with `use_bias=False`\n-    del(model)\n-    model = Sequential()\n-    model.add(Conv2D(2, (1, 1), input_shape=(1, 1, 1), use_bias=False, name='rick'))\n-    model.add(Flatten())\n-    model.add(Dense(3, name='morty'))\n-    with pytest.raises(ValueError,\n-                       match=r'.* expects [0-9]+ .* but the saved .* [0-9]+ .*'):\n-        model.load_weights(fname)\n-    with pytest.raises(ValueError,\n-                       match=r'.* expects [0-9]+ .* but the saved .* [0-9]+ .*'):\n-        model.load_weights(fname, by_name=True)\n-    with pytest.warns(UserWarning,\n-                      match=r'Skipping loading .* due to mismatch .*'):\n-        model.load_weights(fname, by_name=True, skip_mismatch=True)\n-\n-    # delete and recreate model with `filters=10`\n-    del(model)\n-    model = Sequential()\n-    model.add(Conv2D(10, (1, 1), input_shape=(1, 1, 1), name='rick'))\n-    with pytest.raises(ValueError,\n-                       match=r'.* has shape .* but the saved .* shape .*'):\n-        model.load_weights(fname, by_name=True)\n-    with pytest.raises(ValueError,\n-                       match=r'.* load .* [0-9]+ layers into .* [0-9]+ layers.'):\n-        model.load_weights(fname)\n-\n-    os.remove(fname)\n-\n-\n def test_loading_weights_by_name_2():\n     \"\"\"\n     test loading model weights by name on:\n         - both sequential and functional api models\n         - different architecture with shared names\n     \"\"\"\n-\n-    # test with custom optimizer, loss\n-    custom_opt = optimizers.rmsprop\n     custom_loss = losses.mse\n \n     # sequential model\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,), name='rick'))\n     model.add(Dense(3, name='morty'))\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+    model.compile(loss=custom_loss, optimizer='rmsprop', metrics=['acc'])\n \n     x = np.random.random((1, 3))\n     y = np.random.random((1, 3))\n@@ -408,7 +294,7 @@ def test_loading_weights_by_name_2():\n     morty = Dense(3, name='morty')(jessica)\n \n     model = Model(inputs=[data], outputs=[morty])\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+    model.compile(loss=custom_loss, optimizer='rmsprop', metrics=['acc'])\n \n     # load weights from first model\n     model.load_weights(fname, by_name=True)\n@@ -437,14 +323,13 @@ def test_loading_weights_by_name_skip_mismatch():\n     \"\"\"\n \n     # test with custom optimizer, loss\n-    custom_opt = optimizers.rmsprop\n     custom_loss = losses.mse\n \n     # sequential model\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,), name='rick'))\n     model.add(Dense(3, name='morty'))\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+    model.compile(loss=custom_loss, optimizer='rmsprop', metrics=['acc'])\n \n     x = np.random.random((1, 3))\n     y = np.random.random((1, 3))\n@@ -461,10 +346,9 @@ def test_loading_weights_by_name_skip_mismatch():\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,), name='rick'))\n     model.add(Dense(4, name='morty'))  # different shape w.r.t. previous model\n-    model.compile(loss=custom_loss, optimizer=custom_opt(), metrics=['acc'])\n+    model.compile(loss=custom_loss, optimizer='rmsprop', metrics=['acc'])\n \n     # load weights from first model\n-    with pytest.warns(UserWarning):  # expect UserWarning for skipping weights\n     model.load_weights(fname, by_name=True, skip_mismatch=True)\n     os.remove(fname)\n \n@@ -723,144 +607,6 @@ def test_saving_group_naming_h5py(tmpdir):\n     model.load_weights(p)\n \n \n-def test_save_load_weights_gcs():\n-    model = Sequential()\n-    model.add(Dense(2, input_shape=(3,)))\n-    org_weights = model.get_weights()\n-\n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(\n-            filename='test_save_load_weights_gcs.h5')\n-        # we should not use same filename in several tests to allow for parallel\n-        # execution\n-        model.save_weights(gcs_filepath)\n-        model.set_weights([np.random.random(w.shape) for w in org_weights])\n-        for w, org_w in zip(model.get_weights(), org_weights):\n-            assert not (w == org_w).all()\n-        model.load_weights(gcs_filepath)\n-        for w, org_w in zip(model.get_weights(), org_weights):\n-            assert_allclose(w, org_w)\n-\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-\n-\n-def test_saving_overwrite_option():\n-    model = Sequential()\n-    model.add(Dense(2, input_shape=(3,)))\n-    org_weights = model.get_weights()\n-    new_weights = [np.random.random(w.shape) for w in org_weights]\n-\n-    _, fname = tempfile.mkstemp('.h5')\n-    save_model(model, fname)\n-    model.set_weights(new_weights)\n-\n-    with patch('keras.engine.saving.ask_to_proceed_with_overwrite') as ask:\n-        ask.return_value = False\n-        save_model(model, fname, overwrite=False)\n-        ask.assert_called_once()\n-        new_model = load_model(fname)\n-        for w, org_w in zip(new_model.get_weights(), org_weights):\n-            assert_allclose(w, org_w)\n-\n-        ask.return_value = True\n-        save_model(model, fname, overwrite=False)\n-        assert ask.call_count == 2\n-        new_model = load_model(fname)\n-        for w, new_w in zip(new_model.get_weights(), new_weights):\n-            assert_allclose(w, new_w)\n-\n-    os.remove(fname)\n-\n-\n-def test_saving_overwrite_option_gcs():\n-    model = Sequential()\n-    model.add(Dense(2, input_shape=(3,)))\n-    org_weights = model.get_weights()\n-    new_weights = [np.random.random(w.shape) for w in org_weights]\n-\n-    with tf_file_io_proxy('keras.engine.saving.tf_file_io') as file_io_proxy:\n-        gcs_filepath = file_io_proxy.get_filepath(\n-            filename='test_saving_overwrite_option_gcs.h5')\n-        # we should not use same filename in several tests to allow for parallel\n-        # execution\n-        save_model(model, gcs_filepath)\n-        model.set_weights(new_weights)\n-\n-        with patch('keras.engine.saving.ask_to_proceed_with_overwrite') as ask:\n-            ask.return_value = False\n-            save_model(model, gcs_filepath, overwrite=False)\n-            ask.assert_called_once()\n-            new_model = load_model(gcs_filepath)\n-            for w, org_w in zip(new_model.get_weights(), org_weights):\n-                assert_allclose(w, org_w)\n-\n-            ask.return_value = True\n-            save_model(model, gcs_filepath, overwrite=False)\n-            assert ask.call_count == 2\n-            new_model = load_model(gcs_filepath)\n-            for w, new_w in zip(new_model.get_weights(), new_weights):\n-                assert_allclose(w, new_w)\n-\n-        file_io_proxy.delete_file(gcs_filepath)  # cleanup\n-\n-\n-@pytest.mark.parametrize('implementation', [1, 2], ids=['impl1', 'impl2'])\n-@pytest.mark.parametrize('bidirectional',\n-                         [False, True],\n-                         ids=['single', 'bidirectional'])\n-@pytest.mark.parametrize('to_cudnn', [False, True], ids=['from_cudnn', 'to_cudnn'])\n-@pytest.mark.parametrize('rnn_type', ['LSTM', 'GRU'], ids=['LSTM', 'GRU'])\n-@pytest.mark.parametrize('model_nest_level',\n-                         [1, 2],\n-                         ids=['model_plain', 'model_nested'])\n-@pytest.mark.parametrize('model_type',\n-                         ['func', 'seq'],\n-                         ids=['model_func', 'model_seq'])\n-@skipif_no_tf_gpu\n-def test_load_weights_between_noncudnn_rnn(rnn_type, to_cudnn, bidirectional,\n-                                           implementation, model_nest_level,\n-                                           model_type):\n-    input_size = 10\n-    timesteps = 6\n-    input_shape = (timesteps, input_size)\n-    units = 2\n-    num_samples = 32\n-    inputs = np.random.random((num_samples, timesteps, input_size))\n-\n-    rnn_layer_kwargs = {\n-        'recurrent_activation': 'sigmoid',\n-        # ensure biases are non-zero and properly converted\n-        'bias_initializer': 'random_uniform',\n-        'implementation': implementation\n-    }\n-    if rnn_type == 'LSTM':\n-        rnn_layer_class = LSTM\n-        cudnn_rnn_layer_class = CuDNNLSTM\n-    else:\n-        rnn_layer_class = GRU\n-        cudnn_rnn_layer_class = CuDNNGRU\n-        rnn_layer_kwargs['reset_after'] = True\n-\n-    layer = rnn_layer_class(units, **rnn_layer_kwargs)\n-    if bidirectional:\n-        layer = Bidirectional(layer)\n-\n-    cudnn_layer = cudnn_rnn_layer_class(units)\n-    if bidirectional:\n-        cudnn_layer = Bidirectional(cudnn_layer)\n-\n-    model = _make_nested_model(input_shape, layer, model_nest_level, model_type)\n-    cudnn_model = _make_nested_model(input_shape, cudnn_layer,\n-                                     model_nest_level, model_type)\n-\n-    if to_cudnn:\n-        _convert_model_weights(model, cudnn_model)\n-    else:\n-        _convert_model_weights(cudnn_model, model)\n-\n-    assert_allclose(model.predict(inputs), cudnn_model.predict(inputs), atol=1e-4)\n-\n-\n def _make_nested_model(input_shape, layer, level=1, model_type='func'):\n     # example: make_nested_seq_model((1,), Dense(10), level=2).summary()\n     def make_nested_seq_model(input_shape, layer, level=1):\n@@ -891,84 +637,6 @@ def _convert_model_weights(source_model, target_model):\n     os.remove(fname)\n \n \n-@pytest.mark.parametrize('to_cudnn', [False, True], ids=['from_cudnn', 'to_cudnn'])\n-@pytest.mark.parametrize('rnn_type', ['LSTM', 'GRU'], ids=['LSTM', 'GRU'])\n-@skipif_no_tf_gpu\n-def test_load_weights_between_noncudnn_rnn_time_distributed(rnn_type, to_cudnn):\n-    \"\"\"\n-    Similar test as  test_load_weights_between_noncudnn_rnn() but has different\n-    rank of input due to usage of TimeDistributed. Issue: #10356.\n-    \"\"\"\n-    input_size = 10\n-    steps = 6\n-    timesteps = 6\n-    input_shape = (timesteps, steps, input_size)\n-    units = 2\n-    num_samples = 32\n-    inputs = np.random.random((num_samples,) + input_shape)\n-\n-    rnn_layer_kwargs = {\n-        'recurrent_activation': 'sigmoid',\n-        # ensure biases are non-zero and properly converted\n-        'bias_initializer': 'random_uniform',\n-    }\n-    if rnn_type == 'LSTM':\n-        rnn_layer_class = LSTM\n-        cudnn_rnn_layer_class = CuDNNLSTM\n-    else:\n-        rnn_layer_class = GRU\n-        cudnn_rnn_layer_class = CuDNNGRU\n-        rnn_layer_kwargs['reset_after'] = True\n-\n-    layer = rnn_layer_class(units, **rnn_layer_kwargs)\n-    layer = TimeDistributed(layer)\n-\n-    cudnn_layer = cudnn_rnn_layer_class(units)\n-    cudnn_layer = TimeDistributed(cudnn_layer)\n-\n-    model = _make_nested_model(input_shape, layer)\n-    cudnn_model = _make_nested_model(input_shape, cudnn_layer)\n-\n-    if to_cudnn:\n-        _convert_model_weights(model, cudnn_model)\n-    else:\n-        _convert_model_weights(cudnn_model, model)\n-\n-    assert_allclose(model.predict(inputs), cudnn_model.predict(inputs), atol=1e-4)\n-\n-\n-@skipif_no_tf_gpu\n-def test_preprocess_weights_for_loading_gru_incompatible():\n-    \"\"\"\n-    Loading weights between incompatible layers should fail fast with an exception.\n-    \"\"\"\n-    def gru(cudnn=False, **kwargs):\n-        layer_class = CuDNNGRU if cudnn else GRU\n-        return layer_class(2, input_shape=[3, 5], **kwargs)\n-\n-    def initialize_weights(layer):\n-        # A model is needed to initialize weights.\n-        _ = Sequential([layer])\n-        return layer\n-\n-    def assert_not_compatible(src, dest, message):\n-        with pytest.raises(ValueError) as ex:\n-            preprocess_weights_for_loading(dest,\n-                                           initialize_weights(src).get_weights())\n-        assert message in ex.value.message\n-\n-    assert_not_compatible(gru(), gru(cudnn=True),\n-                          'GRU(reset_after=False) is not compatible with CuDNNGRU')\n-    assert_not_compatible(gru(cudnn=True), gru(),\n-                          'CuDNNGRU is not compatible with GRU(reset_after=False)')\n-    assert_not_compatible(gru(), gru(reset_after=True),\n-                          'GRU(reset_after=False) is not compatible with '\n-                          'GRU(reset_after=True)')\n-    assert_not_compatible(gru(reset_after=True), gru(),\n-                          'GRU(reset_after=True) is not compatible with '\n-                          'GRU(reset_after=False)')\n-\n-\n def test_model_saving_with_rnn_initial_state_and_args():\n     class CustomRNN(LSTM):\n         def call(self, inputs, arg=1, mask=None, training=None, initial_state=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
