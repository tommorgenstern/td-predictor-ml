{"custom_id": "keras#3555363d57fef64ce6c8245262ccbdb714733d82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 302 | Lines Deleted: 354 | Files Changed: 3 | Hunks: 55 | Methods Changed: 26 | Complexity Δ (Sum/Max): -26/16 | Churn Δ: 656 | Churn Cumulative: 8479 | Contributors (this commit): 44 | Commits (past 90d): 15 | Contributors (cumulative): 59 | DMM Complexity: 1.0\n\nDIFF:\n@@ -25,7 +25,6 @@ import tensorflow.compat.v2 as tf\n \n from keras import initializers\n from keras.utils import io_utils\n-from keras.utils import text_rendering\n \n # isort: off\n from tensorflow.python.util.tf_export import keras_export\n@@ -250,7 +249,7 @@ def print_dtensor_variable_summary(model, print_fn, line_length):\n \n def readable_memory_size(weight_memory_size):\n     \"\"\"Convert the weight memory size (Bytes) to a readable string.\"\"\"\n-    units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n+    units = [\"Byte\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n     scale = 1024\n     for unit in units:\n         if weight_memory_size / scale < 1:\n@@ -388,36 +387,83 @@ def print_summary(\n                     break\n \n     if sequential_like:\n-        line_length = line_length or 84\n+        line_length = line_length or 65\n         positions = positions or [0.45, 0.85, 1.0]\n+        if positions[-1] <= 1:\n+            positions = [int(line_length * p) for p in positions]\n         # header names for the different log elements\n-        header = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n+        to_display = [\"Layer (type)\", \"Output Shape\", \"Param #\"]\n     else:\n-        line_length = line_length or 100\n+        line_length = line_length or 98\n         positions = positions or [0.3, 0.6, 0.70, 1.0]\n+        if positions[-1] <= 1:\n+            positions = [int(line_length * p) for p in positions]\n         # header names for the different log elements\n-        header = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n+        to_display = [\"Layer (type)\", \"Output Shape\", \"Param #\", \"Connected to\"]\n         relevant_nodes = []\n         for v in model._nodes_by_depth.values():\n             relevant_nodes += v\n \n     if show_trainable:\n-        line_length += 8\n-        positions = [p * 0.86 for p in positions] + [1.0]\n-        header.append(\"Trainable\")\n+        line_length += 11\n+        positions.append(line_length)\n+        to_display.append(\"Trainable\")\n \n     layer_range = get_layer_index_bound_by_layer_name(model, layer_range)\n \n-    print_fn(text_rendering.highlight_msg(f' Model: \"{model.name}\"'))\n-    rows = []\n+    def print_row(fields, positions, nested_level=0):\n+        left_to_print = [str(x) for x in fields]\n+        while any(left_to_print):\n+            line = \"\"\n+            for col in range(len(left_to_print)):\n+                if col > 0:\n+                    start_pos = positions[col - 1]\n+                else:\n+                    start_pos = 0\n+                end_pos = positions[col]\n+                # Leave room for 2 spaces to delineate columns\n+                # we don't need any if we are printing the last column\n+                space = 2 if col != len(positions) - 1 else 0\n+                cutoff = end_pos - start_pos - space\n+                # Except for last col, offset by one to align the start of col\n+                if col != len(positions) - 1:\n+                    cutoff -= 1\n+                if col == 0:\n+                    cutoff -= nested_level\n+                fit_into_line = left_to_print[col][:cutoff]\n+                # For nicer formatting we line-break on seeing end of\n+                # tuple/dict etc.\n+                line_break_conditions = (\"),\", \"},\", \"],\", \"',\")\n+                candidate_cutoffs = [\n+                    fit_into_line.find(x) + len(x)\n+                    for x in line_break_conditions\n+                    if fit_into_line.find(x) >= 0\n+                ]\n+                if candidate_cutoffs:\n+                    cutoff = min(candidate_cutoffs)\n+                    fit_into_line = fit_into_line[:cutoff]\n \n-    def format_shape(shape):\n-        shape = tuple(shape)\n-        if len(shape) == 1 and isinstance(shape[0], tuple):\n-            shape = shape[0]\n-        return str(shape)\n+                if col == 0:\n+                    line += \"|\" * nested_level + \" \"\n+                line += fit_into_line\n+                line += \" \" * space if space else \"\"\n+                left_to_print[col] = left_to_print[col][cutoff:]\n \n-    def print_layer_summary(layer, prefix=\"\"):\n+                # Pad out to the next position\n+                # Make space for nested_level for last column\n+                if nested_level and col == len(positions) - 1:\n+                    line += \" \" * (positions[col] - len(line) - nested_level)\n+                else:\n+                    line += \" \" * (positions[col] - len(line))\n+            line += \"|\" * nested_level\n+            print_fn(line)\n+\n+    print_fn(f'Model: \"{model.name}\"')\n+    print_fn(\"_\" * line_length)\n+    print_row(to_display, positions)\n+    print_fn(\"=\" * line_length)\n+\n+    def print_layer_summary(layer, nested_level=0):\n         \"\"\"Prints a summary for a single layer.\n \n         Args:\n@@ -426,27 +472,28 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = format_shape(layer.output_shape)\n+            output_shape = layer.output_shape\n         except AttributeError:\n             output_shape = \"multiple\"\n         except RuntimeError:  # output_shape unknown in Eager mode.\n             output_shape = \"?\"\n-        name = prefix + layer.name\n+        name = layer.name\n         cls_name = layer.__class__.__name__\n-        if not layer.built:\n+        if not layer.built and not getattr(layer, \"_is_graph_network\", False):\n             # If a subclassed model has a layer that is not called in\n             # Model.call, the layer will not be built and we cannot call\n             # layer.count_params().\n             params = \"0 (unused)\"\n         else:\n             params = layer.count_params()\n-        fields = [name + \" (\" + cls_name + \")\", output_shape, str(params)]\n+        fields = [name + \" (\" + cls_name + \")\", output_shape, params]\n \n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n-        rows.append(fields)\n \n-    def print_layer_summary_with_connections(layer, prefix=\"\"):\n+        print_row(fields, positions, nested_level)\n+\n+    def print_layer_summary_with_connections(layer, nested_level=0):\n         \"\"\"Prints a summary for a single layer (including its connections).\n \n         Args:\n@@ -455,7 +502,7 @@ def print_summary(\n               (e.g. 0 for a top-level layer, 1 for a nested layer).\n         \"\"\"\n         try:\n-            output_shape = format_shape(layer.output_shape)\n+            output_shape = layer.output_shape\n         except AttributeError:\n             output_shape = \"multiple\"\n         connections = []\n@@ -463,57 +510,68 @@ def print_summary(\n             if relevant_nodes and node not in relevant_nodes:\n                 # node is not part of the current network\n                 continue\n-            for kt in node.keras_inputs:\n-                keras_history = kt._keras_history\n-                inbound_layer = keras_history.layer\n-                node_index = keras_history.node_index\n-                tensor_index = keras_history.tensor_index\n+\n+            for (\n+                inbound_layer,\n+                node_index,\n+                tensor_index,\n+                _,\n+            ) in node.iterate_inbound():\n                 connections.append(\n                     f\"{inbound_layer.name}[{node_index}][{tensor_index}]\"\n                 )\n-        name = prefix + layer.name\n+\n+        name = layer.name\n         cls_name = layer.__class__.__name__\n         fields = [\n             name + \" (\" + cls_name + \")\",\n             output_shape,\n-            str(layer.count_params()),\n+            layer.count_params(),\n             connections,\n         ]\n+\n         if show_trainable:\n             fields.append(\"Y\" if layer.trainable else \"N\")\n-        rows.append(fields)\n \n-    def print_layer(layer, nested_level=0):\n-        if nested_level:\n-            prefix = \"   \" * nested_level + \"└\" + \" \"\n-        else:\n-            prefix = \"\"\n+        print_row(fields, positions, nested_level)\n+\n+    def print_layer(layer, nested_level=0, is_nested_last=False):\n         if sequential_like:\n-            print_layer_summary(layer, prefix=prefix)\n+            print_layer_summary(layer, nested_level)\n         else:\n-            print_layer_summary_with_connections(layer, prefix=prefix)\n+            print_layer_summary_with_connections(layer, nested_level)\n \n         if expand_nested and hasattr(layer, \"layers\") and layer.layers:\n-            nested_layers = layer.layers\n-            nested_level += 1\n-            for i in range(len(nested_layers)):\n-                print_layer(nested_layers[i], nested_level=nested_level)\n+            print_fn(\n+                \"|\" * (nested_level + 1)\n+                + \"¯\" * (line_length - 2 * nested_level - 2)\n+                + \"|\" * (nested_level + 1)\n+            )\n+\n+            nested_layer = layer.layers\n+            is_nested_last = False\n+            for i in range(len(nested_layer)):\n+                if i == len(nested_layer) - 1:\n+                    is_nested_last = True\n+                print_layer(nested_layer[i], nested_level + 1, is_nested_last)\n+\n+            print_fn(\n+                \"|\" * nested_level\n+                + \"¯\" * (line_length - 2 * nested_level)\n+                + \"|\" * nested_level\n+            )\n+\n+        if not is_nested_last:\n+            print_fn(\n+                \"|\" * nested_level\n+                + \" \" * (line_length - 2 * nested_level)\n+                + \"|\" * nested_level\n+            )\n \n     for layer in model.layers[layer_range[0] : layer_range[1]]:\n         print_layer(layer)\n+    print_fn(\"=\" * line_length)\n \n-    # Render summary as a table.\n-    table = text_rendering.TextTable(\n-        header=header,\n-        rows=rows,\n-        positions=positions,\n-        # Left align layer name, center-align everything else\n-        alignments=[\"left\"] + [\"center\" for _ in range(len(header) - 1)],\n-        max_line_length=line_length,\n-    )\n-    print_fn(table.make())\n-\n-    # After the table, append information about parameter count and size.\n     if hasattr(model, \"_collected_trainable_weights\"):\n         trainable_count = count_params(model._collected_trainable_weights)\n         trainable_memory_size = weight_memory_size(\n@@ -529,23 +587,19 @@ def print_summary(\n     total_memory_size = trainable_memory_size + non_trainable_memory_size\n \n     print_fn(\n-        text_rendering.highlight_msg(\n         f\"Total params: {trainable_count + non_trainable_count} \"\n         f\"({readable_memory_size(total_memory_size)})\"\n     )\n-    )\n     print_fn(\n-        text_rendering.highlight_msg(\n         f\"Trainable params: {trainable_count} \"\n         f\"({readable_memory_size(trainable_memory_size)})\"\n     )\n-    )\n     print_fn(\n-        text_rendering.highlight_msg(\n         f\"Non-trainable params: {non_trainable_count} \"\n         f\"({readable_memory_size(non_trainable_memory_size)})\"\n     )\n-    )\n+    print_fn(\"_\" * line_length)\n+\n     print_dtensor_variable_summary(model, print_fn, line_length)\n \n \n\n@@ -93,7 +93,7 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            self.assertEqual(len(lines), 13)\n+            self.assertEqual(len(lines), 15)\n         except ImportError:\n             pass\n \n@@ -112,16 +112,10 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         model = keras.Sequential(\n             [\n                 keras.Input(shape),\n-                keras.layers.Conv2D(\n-                    4, 3, name=\"Really-really-really-really-Long-name-test\"\n-                ),\n-                keras.layers.Conv2D(\n-                    4, 3, name=\"Another-really-really-really-long-name-test\"\n-                ),\n+                keras.layers.Conv2D(4, 3, name=\"Really-Long-name-test\"),\n+                keras.layers.Conv2D(4, 3, name=\"Another-long-name-test\"),\n                 keras.layers.Flatten(),\n-                keras.layers.Dense(\n-                    2, name=\"Really-really-really-long-name-test-output\"\n-                ),\n+                keras.layers.Dense(2, name=\"long-name-test-output\"),\n             ]\n         )\n         file_name = \"sequential.txt\"\n@@ -136,33 +130,34 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         layer_utils.print_summary(model, print_fn=print_to_file)\n         self.assertTrue(tf.io.gfile.exists(fpath))\n         writer.close()\n-        ref_str = \"\"\" Model: \"sequential\"\n-┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n-┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n-┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n-│ Really-really-really-really-Lon  │       (None, 6, 6, 4)        │    112     │\n-│ g-name-test (Conv2D)             │                              │            │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│ Another-really-really-really-lo  │       (None, 4, 4, 4)        │    148     │\n-│ ng-name-test (Conv2D)            │                              │            │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│ flatten (Flatten)                │          (None, 64)          │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│ Really-really-really-long-name-  │          (None, 2)           │    130     │\n-│ test-output (Dense)              │                              │            │\n-└──────────────────────────────────┴──────────────────────────────┴────────────┘\n- Total params: 390 (1.52 KB)\n- Trainable params: 390 (1.52 KB)\n- Non-trainable params: 0 (0.00 B)\\n\"\"\"\n-        self._check_summary_string(ref_str, fpath)\n-\n-    def _check_summary_string(self, ref_str, fpath):\n         reader = open(fpath, \"r\")\n-        seen_str = reader.read()\n-        seen_str = seen_str.replace(\"\\x1b[1m\", \"\")\n-        seen_str = seen_str.replace(\"\\x1b[0m\", \"\")\n+        lines = reader.readlines()\n         reader.close()\n-        self.assertEqual(ref_str, seen_str)\n+        check_str = (\n+            'Model: \"sequential\"\\n'\n+            \"_________________________________________________________________\\n\"  # noqa: E501\n+            \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n+            \"=================================================================\\n\"  # noqa: E501\n+            \" Really-Long-name-test (Con  (None, 6, 6, 4)           112       \\n\"  # noqa: E501\n+            \" v2D)                                                            \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" Another-long-name-test (Co  (None, 4, 4, 4)           148       \\n\"  # noqa: E501\n+            \" nv2D)                                                           \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" flatten (Flatten)           (None, 64)                0         \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \" long-name-test-output (Den  (None, 2)                 130       \\n\"  # noqa: E501\n+            \" se)                                                             \\n\"  # noqa: E501\n+            \"                                                                 \\n\"  # noqa: E501\n+            \"=================================================================\\n\"  # noqa: E501\n+            \"Total params: 390 (1.52 KB)\\n\"\n+            \"Trainable params: 390 (1.52 KB)\\n\"\n+            \"Non-trainable params: 0 (0.00 Byte)\\n\"\n+            \"_________________________________________________________________\\n\"  # noqa: E501\n+        )\n+        fin_str = \"\".join(lines)\n+        self.assertIn(fin_str, check_str)\n+        self.assertEqual(len(lines), 20)\n \n     def test_print_summary_expand_nested(self):\n         shape = (None, None, 3)\n@@ -189,34 +184,49 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n+        try:\n             layer_utils.print_summary(\n                 model, print_fn=print_to_file, expand_nested=True\n             )\n             self.assertTrue(tf.io.gfile.exists(fpath))\n             writer.close()\n-        ref_str = \"\"\" Model: \"model_2\"\n-┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n-┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n-┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n-│ input_3 (InputLayer)             │    (None, None, None, 3)     │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│ model_1 (Functional)             │    (None, None, None, 3)     │     24     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│    └ input_1 (InputLayer)        │    (None, None, None, 3)     │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│    └ model (Functional)          │    (None, None, None, 3)     │     24     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ input_2 (InputLayer)     │    (None, None, None, 3)     │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ conv2d (Conv2D)          │    (None, None, None, 3)     │     12     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ batch_normalization      │    (None, None, None, 3)     │     12     │\n-│ (BatchNormalization)             │                              │            │\n-└──────────────────────────────────┴──────────────────────────────┴────────────┘\n- Total params: 24 (96.00 B)\n- Trainable params: 18 (72.00 B)\n- Non-trainable params: 6 (24.00 B)\\n\"\"\"\n-        self._check_summary_string(ref_str, fpath)\n+            reader = open(fpath, \"r\")\n+            lines = reader.readlines()\n+            reader.close()\n+            check_str = (\n+                'Model: \"model_2\"\\n'\n+                \"_________________________________________________________________\\n\"  # noqa: E501\n+                \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n+                \"=================================================================\\n\"  # noqa: E501\n+                \" input_3 (InputLayer)        [(None, None, None, 3)]   0         \\n\"  # noqa: E501\n+                \"                                                                 \\n\"  # noqa: E501\n+                \" model_1 (Functional)        (None, None, None, 3)     24        \\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"| input_1 (InputLayer)       [(None, None, None, 3)]   0        |\\n\"  # noqa: E501\n+                \"|                                                               |\\n\"  # noqa: E501\n+                \"| model (Functional)         (None, None, None, 3)     24       |\\n\"  # noqa: E501\n+                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n+                \"|| input_2 (InputLayer)      [(None, None, None, 3)]   0       ||\\n\"  # noqa: E501\n+                \"||                                                             ||\\n\"  # noqa: E501\n+                \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"||                                                             ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n+                \"=================================================================\\n\"  # noqa: E501\n+                \"Total params: 24 (96.00 Byte)\\n\"\n+                \"Trainable params: 18 (72.00 Byte)\\n\"\n+                \"Non-trainable params: 6 (24.00 Byte)\\n\"\n+                \"_________________________________________________________________\\n\"  # noqa: E501\n+            )\n+\n+            fin_str = \"\".join(lines)\n+\n+            self.assertIn(fin_str, check_str)\n+            self.assertEqual(len(lines), 25)\n+        except ImportError:\n+            pass\n \n     def test_summary_subclass_model_expand_nested(self):\n         class Sequential(keras.Model):\n@@ -284,7 +294,12 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            self.assertEqual(len(lines), 37)\n+            # The output content are slightly different for the input shapes\n+            # between v1 and v2.\n+            if tf.__internal__.tf2.enabled():\n+                self.assertEqual(len(lines), 39)\n+            else:\n+                self.assertEqual(len(lines), 40)\n         except ImportError:\n             pass\n \n@@ -308,25 +323,39 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n+        try:\n             layer_utils.print_summary(\n                 model, print_fn=print_to_file, show_trainable=True\n             )\n             self.assertTrue(tf.io.gfile.exists(fpath))\n             writer.close()\n-        ref_str = \"\"\" Model: \"trainable\"\n-┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n-┃         Layer (type)        ┃       Output Shape       ┃ Param #  ┃ Trainable ┃\n-┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n-│ conv (Conv2D)               │     (None, 2, 3, 2)      │    62    │     N     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│ flat (Flatten)              │        (None, 12)        │    0     │     Y     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│ dense (Dense)               │        (None, 5)         │    65    │     Y     │\n-└─────────────────────────────┴──────────────────────────┴──────────┴───────────┘\n- Total params: 127 (508.00 B)\n- Trainable params: 65 (260.00 B)\n- Non-trainable params: 62 (248.00 B)\\n\"\"\"  # noqa: E501\n-        self._check_summary_string(ref_str, fpath)\n+            with open(fpath, \"r\") as reader:\n+                lines = reader.readlines()\n+            check_str = (\n+                'Model: \"trainable\"\\n'\n+                \"____________________________________________________________________________\\n\"  # noqa: E501\n+                \" Layer (type)                Output Shape              Param #   Trainable  \\n\"  # noqa: E501\n+                \"============================================================================\\n\"  # noqa: E501\n+                \" conv (Conv2D)               (None, 2, 3, 2)           62        N          \\n\"  # noqa: E501\n+                \"                                                                            \\n\"  # noqa: E501\n+                \" flat (Flatten)              (None, 12)                0         Y          \\n\"  # noqa: E501\n+                \"                                                                            \\n\"  # noqa: E501\n+                \" dense (Dense)               (None, 5)                 65        Y          \\n\"  # noqa: E501\n+                \"                                                                            \\n\"  # noqa: E501\n+                \"============================================================================\\n\"  # noqa: E501\n+                \"Total params: 127 (508.00 Byte)\\n\"\n+                \"Trainable params: 65 (260.00 Byte)\\n\"\n+                \"Non-trainable params: 62 (248.00 Byte)\\n\"\n+                \"____________________________________________________________________________\\n\"  # noqa: E501\n+                \"____________________________________________________________________________\\n\"  # noqa: E501\n+            )\n+\n+            fin_str = \"\".join(lines)\n+\n+            self.assertIn(fin_str, check_str)\n+            self.assertEqual(len(lines), 15)\n+        except ImportError:\n+            pass\n \n     def test_print_summary_expand_nested_show_trainable(self):\n         shape = (None, None, 3)\n@@ -355,6 +384,7 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n+        try:\n             layer_utils.print_summary(\n                 model,\n                 print_fn=print_to_file,\n@@ -363,30 +393,42 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             )\n             self.assertTrue(tf.io.gfile.exists(fpath))\n             writer.close()\n-        ref_str = \"\"\" Model: \"model_2\"\n-┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n-┃         Layer (type)        ┃       Output Shape       ┃ Param #  ┃ Trainable ┃\n-┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n-│ input3 (InputLayer)         │  (None, None, None, 3)   │    0     │     Y     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│ model_1 (Functional)        │  (None, None, None, 3)   │    24    │     Y     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│    └ input1 (InputLayer)    │  (None, None, None, 3)   │    0     │     Y     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│    └ model (Functional)     │  (None, None, None, 3)   │    24    │     Y     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│       └ input2              │  (None, None, None, 3)   │    0     │     Y     │\n-│ (InputLayer)                │                          │          │           │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│       └ conv2d (Conv2D)     │  (None, None, None, 3)   │    12    │     N     │\n-├─────────────────────────────┼──────────────────────────┼──────────┼───────────┤\n-│       └ batch_normalizatio  │  (None, None, None, 3)   │    12    │     Y     │\n-│ n (BatchNormalization)      │                          │          │           │\n-└─────────────────────────────┴──────────────────────────┴──────────┴───────────┘\n- Total params: 24 (96.00 B)\n- Trainable params: 6 (24.00 B)\n- Non-trainable params: 18 (72.00 B)\\n\"\"\"  # noqa: E501\n-        self._check_summary_string(ref_str, fpath)\n+            with open(fpath, \"r\") as reader:\n+                lines = reader.readlines()\n+            check_str = (\n+                'Model: \"model_2\"\\n'\n+                \"____________________________________________________________________________\\n\"  # noqa: E501\n+                \" Layer (type)                Output Shape              Param #   Trainable  \\n\"  # noqa: E501\n+                \"============================================================================\\n\"  # noqa: E501\n+                \" input3 (InputLayer)         [(None, None, None, 3)]   0         Y          \\n\"  # noqa: E501\n+                \"                                                                            \\n\"  # noqa: E501\n+                \" model_1 (Functional)        (None, None, None, 3)     24        Y          \\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"| input1 (InputLayer)        [(None, None, None, 3)]   0         Y         |\\n\"  # noqa: E501\n+                \"|                                                                          |\\n\"  # noqa: E501\n+                \"| model (Functional)         (None, None, None, 3)     24        Y         |\\n\"  # noqa: E501\n+                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n+                \"|| input2 (InputLayer)       [(None, None, None, 3)]   0         Y        ||\\n\"  # noqa: E501\n+                \"||                                                                        ||\\n\"  # noqa: E501\n+                \"|| conv2d (Conv2D)           (None, None, None, 3)     12        N        ||\\n\"  # noqa: E501\n+                \"||                                                                        ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12        Y        ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                                       ||\\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n+                \"============================================================================\\n\"  # noqa: E501\n+                \"Total params: 24 (96.00 Byte)\\n\"\n+                \"Trainable params: 6 (24.00 Byte)\\n\"\n+                \"Non-trainable params: 18 (72.00 Byte)\\n\"\n+                \"____________________________________________________________________________\\n\"  # noqa: E501\n+            )\n+\n+            fin_str = \"\".join(lines)\n+\n+            self.assertIn(fin_str, check_str)\n+            self.assertEqual(len(lines), 25)\n+        except ImportError:\n+            pass\n \n     def test_print_summary_layer_range(self):\n         model = keras.Sequential()\n@@ -418,7 +460,9 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n             writer.close()\n             with open(fpath, \"r\") as reader:\n                 lines = reader.readlines()\n-            self.assertEqual(len(lines), 11)\n+            # The expected lenght with no layer filter is 15\n+            # we filtered out 2 lines by excluding the layer 'dense'\n+            self.assertEqual(len(lines), 15 - 2)\n         except ImportError:\n             pass\n \n@@ -447,35 +491,57 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         def print_to_file(text):\n             print(text, file=writer)\n \n+        try:\n             layer_utils.print_summary(\n                 model,\n                 print_fn=print_to_file,\n                 expand_nested=True,\n                 layer_range=[\"1st_inner\", \"1st_inner\"],\n             )\n+            layer_utils.print_summary(\n+                model,\n+                expand_nested=True,\n+                layer_range=[\"1st_inner\", \"1st_inner\"],\n+            )\n             self.assertTrue(tf.io.gfile.exists(fpath))\n             writer.close()\n-        ref_str = \"\"\" Model: \"model\"\n-┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n-┃           Layer (type)           ┃         Output Shape         ┃  Param #   ┃\n-┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n-│ 1st_inner (Functional)           │    (None, None, None, 3)     │     24     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│    └ input_1 (InputLayer)        │    (None, None, None, 3)     │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│    └ 2nd_inner (Functional)      │    (None, None, None, 3)     │     24     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ input_2 (InputLayer)     │    (None, None, None, 3)     │     0      │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ conv2d (Conv2D)          │    (None, None, None, 3)     │     12     │\n-├──────────────────────────────────┼──────────────────────────────┼────────────┤\n-│       └ batch_normalization      │    (None, None, None, 3)     │     12     │\n-│ (BatchNormalization)             │                              │            │\n-└──────────────────────────────────┴──────────────────────────────┴────────────┘\n- Total params: 24 (96.00 B)\n- Trainable params: 18 (72.00 B)\n- Non-trainable params: 6 (24.00 B)\\n\"\"\"\n-        self._check_summary_string(ref_str, fpath)\n+            with open(fpath, \"r\") as reader:\n+                lines = reader.readlines()\n+            check_str = (\n+                'Model: \"model\"\\n'\n+                \"_________________________________________________________________\\n\"  # noqa: E501\n+                \" Layer (type)                Output Shape              Param #   \\n\"  # noqa: E501\n+                \"=================================================================\\n\"  # noqa: E501\n+                \" 1st_inner (Functional)      (None, None, None, 3)     24        \\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"| input_1 (InputLayer)       [(None, None, None, 3)]   0        |\\n\"  # noqa: E501\n+                \"|                                                               |\\n\"  # noqa: E501\n+                \"| 2nd_inner (Functional)     (None, None, None, 3)     24       |\\n\"  # noqa: E501\n+                \"||¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯||\\n\"  # noqa: E501\n+                \"|| input_2 (InputLayer)      [(None, None, None, 3)]   0       ||\\n\"  # noqa: E501\n+                \"||                                                             ||\\n\"  # noqa: E501\n+                \"|| conv2d (Conv2D)           (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"||                                                             ||\\n\"  # noqa: E501\n+                \"|| batch_normalization (Bat  (None, None, None, 3)     12      ||\\n\"  # noqa: E501\n+                \"|| chNormalization)                                            ||\\n\"  # noqa: E501\n+                \"|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\\n\"  # noqa: E501\n+                \"¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\\n\"  # noqa: E501\n+                \"=================================================================\\n\"  # noqa: E501\n+                \"Total params: 24 (96.00 Byte)\\n\"\n+                \"Trainable params: 18 (72.00 Byte)\\n\"\n+                \"Non-trainable params: 6 (24.00 Byte)\\n\"\n+                \"_________________________________________________________________\\n\"  # noqa: E501\n+            )\n+\n+            check_lines = check_str.split(\"\\n\")[\n+                :-1\n+            ]  # Removing final empty string which is not a line\n+\n+            fin_str = \"\".join(lines)\n+            self.assertIn(fin_str, check_str)\n+            self.assertEqual(len(lines), len(check_lines))\n+        except ImportError:\n+            pass\n \n     def test_weight_memory_size(self):\n         v1 = tf.Variable(tf.zeros(shape=(1, 2), dtype=tf.float32))\n@@ -489,8 +555,8 @@ class LayerUtilsTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertEqual(weight_memory_size, expected_memory_size)\n \n     @parameterized.parameters(\n-        (0, \"0.00 B\"),\n-        (1000, \"1000.00 B\"),\n+        (0, \"0.00 Byte\"),\n+        (1000, \"1000.00 Byte\"),\n         (1024, \"1.00 KB\"),\n         (1024 * 2 - 1, \"2.00 KB\"),\n         (1024 * 2 + 1, \"2.00 KB\"),\n\n@@ -1,172 +0,0 @@\n-# Copyright 2023 The TensorFlow Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-import shutil\n-\n-\n-class TextTable:\n-    def __init__(\n-        self, header, rows, positions, alignments=None, max_line_length=80\n-    ):\n-        if len(header) != len(positions):\n-            raise ValueError(\"header and positions should be the same length.\")\n-        if not all(p <= 1.0 for p in positions):\n-            raise ValueError(\"All positions should be <= 1.\")\n-        self.alignments = alignments or [\"center\" for _ in header]\n-        if len(self.alignments) != len(header):\n-            raise ValueError(\"header and alignments should be the same length.\")\n-        last_p = 0.0\n-        for p in positions:\n-            if p <= last_p:\n-                raise ValueError(\n-                    \"All consecutive positions should be greater than the last.\"\n-                )\n-            last_p = p\n-        self.header = header\n-        self.rows = rows\n-\n-        # Compute columns widths\n-        line_length = min(\n-            max_line_length, shutil.get_terminal_size().columns - 4\n-        )\n-        column_widths = []\n-        current = 0\n-        for pos in positions:\n-            width = int(pos * line_length) - current\n-            if width < 4:\n-                raise ValueError(\"Insufficient console width to print summary.\")\n-            column_widths.append(width)\n-            current += width\n-        self.column_widths = column_widths\n-\n-    def make_separator(self, left, mid, right, horizontal):\n-        line = mid.join(horizontal * width for width in self.column_widths)\n-        return f\"{left}{line}{right}\"\n-\n-    @staticmethod\n-    def maybe_pad(field, alignment):\n-        if alignment == \"left\":\n-            return \" \" + field\n-        if alignment == \"right\":\n-            return field + \" \"\n-        return field\n-\n-    def print_row(\n-        self,\n-        fields,\n-        vertical_separator=\"│\",\n-        alignments=None,\n-        highlight=False,\n-    ):\n-        alignments = alignments or [\"center\" for _ in fields]\n-        lines = []\n-        line_break_chars_post = (\")\", \"}\", \"]\")\n-        line_break_chars_pre = (\"(\", \"{\", \"[\")\n-        for field, width, alignment in zip(\n-            fields, self.column_widths, alignments\n-        ):\n-            field = self.maybe_pad(str(field), alignment)\n-            buffered_width = width - 1\n-            if len(field) < buffered_width and \"\\n\" not in field:\n-                lines.append([field])\n-                continue\n-            subfields = []\n-            while len(field) >= buffered_width or \"\\n\" in field:\n-                if \"\\n\" in field[:buffered_width]:\n-                    # priority: break on line break\n-                    cutoff = field.find(\"\\n\")\n-                    subfield = field[:cutoff]\n-                    field = field[cutoff + 1 :]\n-                    field = self.maybe_pad(field, alignment)\n-                    subfields.append(subfield)\n-                    continue\n-                # secondary: break on certain characters\n-                candidate_cutoffs_post = [\n-                    field.find(x) + len(x)\n-                    for x in line_break_chars_post\n-                    if 0 < field.find(x) < buffered_width - len(x)\n-                ]\n-                candidate_cutoffs_pre = [\n-                    field.find(x)\n-                    for x in line_break_chars_pre\n-                    if 0 < field.find(x) < buffered_width\n-                ]\n-                cutoffs = candidate_cutoffs_post + candidate_cutoffs_pre\n-                if cutoffs:\n-                    cutoff = max(cutoffs)\n-                else:\n-                    cutoff = buffered_width - 1\n-                subfield = field[:cutoff]\n-                field = field[cutoff:]\n-                field = self.maybe_pad(field, alignment)\n-                subfields.append(subfield)\n-            if field:\n-                subfields.append(field)\n-            lines.append(subfields)\n-\n-        max_subfield_count = max(len(subs) for subs in lines)\n-        rendered_lines = []\n-        for i in range(max_subfield_count):\n-            fields = []\n-            for subfields in lines:\n-                if len(subfields) < i + 1:\n-                    field = \"\"\n-                else:\n-                    field = subfields[i]\n-                fields.append(field)\n-            aligned_fields = [\n-                self.align_field(field, width, alignment)\n-                for field, width, alignment in zip(\n-                    fields, self.column_widths, alignments\n-                )\n-            ]\n-            if highlight:\n-                aligned_fields = [\n-                    highlight_msg(field) for field in aligned_fields\n-                ]\n-            line = vertical_separator.join(aligned_fields)\n-            line = f\"{vertical_separator}{line}{vertical_separator}\"\n-            rendered_lines.append(line)\n-        return \"\\n\".join(rendered_lines)\n-\n-    @staticmethod\n-    def align_field(field, width, alignment):\n-        if alignment == \"center\":\n-            return field.center(width)\n-        if alignment == \"left\":\n-            return field.ljust(width)\n-        if alignment == \"right\":\n-            return field.rjust(width)\n-\n-    def make(self):\n-        lines = []\n-        # Print header\n-        lines.append(self.make_separator(*\"┏┳┓━\"))\n-        lines.append(\n-            self.print_row(self.header, vertical_separator=\"┃\", highlight=True)\n-        )\n-        lines.append(self.make_separator(*\"┡╇┩━\"))\n-\n-        # Print rows\n-        for i, row in enumerate(self.rows):\n-            lines.append(self.print_row(row, alignments=self.alignments))\n-            if i < len(self.rows) - 1:\n-                lines.append(self.make_separator(*\"├┼┤─\"))\n-\n-        lines.append(self.make_separator(*\"└┴┘─\"))\n-        return \"\\n\".join(lines)\n-\n-\n-def highlight_msg(msg):\n-    return f\"\\x1b[1m{msg}\\x1b[0m\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
