{"custom_id": "requests#056da86f6d547c727872f168608ab39a4fdbe16e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2487 | Contributors (this commit): 47 | Commits (past 90d): 9 | Contributors (cumulative): 47 | DMM Complexity: None\n\nDIFF:\n@@ -500,7 +500,7 @@ class Session(SessionRedirectMixin):\n \n     def close(self):\n         \"\"\"Closes all adapters and as such the session\"\"\"\n-        for _, v in self.adapters.items():\n+        for v in self.adapters.values():\n             v.close()\n \n     def mount(self, prefix, adapter):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#a829ef9b46b524cf13b40d86288cb338d45665a3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2489 | Contributors (this commit): 48 | Commits (past 90d): 10 | Contributors (cumulative): 48 | DMM Complexity: None\n\nDIFF:\n@@ -156,7 +156,7 @@ class SessionRedirectMixin(object):\n class Session(SessionRedirectMixin):\n     \"\"\"A Requests session.\n \n-    Provides cookie persistience, connection-pooling, and configuration.\n+    Provides cookie persistence, connection-pooling, and configuration.\n \n     Basic Usage::\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#0a52d9405ea23cd9aa7401dcfcebcbc248df3d25", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 643 | Contributors (this commit): 14 | Commits (past 90d): 4 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -184,7 +184,7 @@ class HTTPAdapter(BaseAdapter):\n     def get_connection(self, url, proxies=None):\n         \"\"\"Returns a urllib3 connection for the given URL. This should not be\n         called from user code, and is only exposed for use when subclassing the\n-        :class:`HTTPAdapter <reqeusts.adapters.HTTPAdapter>`.\n+        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n \n         :param url: The URL to connect to.\n         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#61421843bc794ce9f12e6c72d0f0d160df7bdbe7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 8895 | Contributors (this commit): 117 | Commits (past 90d): 18 | Contributors (cumulative): 117 | DMM Complexity: None\n\nDIFF:\n@@ -193,8 +193,8 @@ class Request(RequestHooksMixin):\n         url=None,\n         headers=None,\n         files=None,\n-        data=dict(),\n-        params=dict(),\n+        data=None,\n+        params=None,\n         auth=None,\n         cookies=None,\n         hooks=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#22e31b4b737c2a3b61b3ab4fccd534b2eee65a87", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 1122 | Contributors (this commit): 25 | Commits (past 90d): 4 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -105,7 +105,9 @@ class HTTPDigestAuth(AuthBase):\n         A1 = '%s:%s:%s' % (self.username, realm, self.password)\n         A2 = '%s:%s' % (method, path)\n \n-        if qop == 'auth':\n+        if qop is None:\n+            respdig = KD(hash_utf8(A1), \"%s:%s\" % (nonce, hash_utf8(A2)))\n+        elif qop == 'auth' or 'auth' in qop.split(','):\n             if nonce == self.last_nonce:\n                 self.nonce_count += 1\n             else:\n@@ -120,8 +122,6 @@ class HTTPDigestAuth(AuthBase):\n             cnonce = (hashlib.sha1(s).hexdigest()[:16])\n             noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, qop, hash_utf8(A2))\n             respdig = KD(hash_utf8(A1), noncebit)\n-        elif qop is None:\n-            respdig = KD(hash_utf8(A1), \"%s:%s\" % (nonce, hash_utf8(A2)))\n         else:\n             # XXX handle auth-int.\n             return None\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "requests#2f39e0e2aa791da13a8358f7a48c0365461029d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 837 | Lines Deleted: 92 | Files Changed: 9 | Hunks: 72 | Methods Changed: 41 | Complexity Δ (Sum/Max): 113/37 | Churn Δ: 929 | Churn Cumulative: 5438 | Contributors (this commit): 10 | Commits (past 90d): 14 | Contributors (cumulative): 33 | DMM Complexity: 0.24842767295597484\n\nDIFF:\n@@ -23,7 +23,7 @@ from . import exceptions\n from .filepost import encode_multipart_formdata\n from .poolmanager import PoolManager, ProxyManager, proxy_from_url\n from .response import HTTPResponse\n-from .util import make_headers, get_host\n+from .util import make_headers, get_host, Timeout\n \n \n # Set default logging handler to avoid \"No handler found\" warnings.\n\n@@ -4,12 +4,11 @@\n # This module is part of urllib3 and is released under\n # the MIT License: http://www.opensource.org/licenses/mit-license.php\n \n-import logging\n-import socket\n import errno\n+import logging\n \n from socket import error as SocketError, timeout as SocketTimeout\n-from .util import resolve_cert_reqs, resolve_ssl_version, assert_fingerprint\n+import socket\n \n try: # Python 3\n     from http.client import HTTPConnection, HTTPException\n@@ -22,6 +21,7 @@ try: # Python 3\n     from queue import LifoQueue, Empty, Full\n except ImportError:\n     from Queue import LifoQueue, Empty, Full\n+    import Queue as _  # Platform-specific: Windows\n \n \n try: # Compiled with SSL?\n@@ -44,21 +44,29 @@ except (ImportError, AttributeError): # Platform-specific: No SSL.\n     pass\n \n \n-from .request import RequestMethods\n-from .response import HTTPResponse\n-from .util import get_host, is_connection_dropped, ssl_wrap_socket\n from .exceptions import (\n     ClosedPoolError,\n+    ConnectTimeoutError,\n     EmptyPoolError,\n     HostChangedError,\n     MaxRetryError,\n     SSLError,\n-    TimeoutError,\n+    ReadTimeoutError,\n+    ProxyError,\n )\n-\n-from .packages.ssl_match_hostname import match_hostname, CertificateError\n+from .packages.ssl_match_hostname import CertificateError, match_hostname\n from .packages import six\n-\n+from .request import RequestMethods\n+from .response import HTTPResponse\n+from .util import (\n+    assert_fingerprint,\n+    get_host,\n+    is_connection_dropped,\n+    resolve_cert_reqs,\n+    resolve_ssl_version,\n+    ssl_wrap_socket,\n+    Timeout,\n+)\n \n xrange = six.moves.xrange\n \n@@ -96,7 +104,14 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n \n     def connect(self):\n         # Add certificate verification\n-        sock = socket.create_connection((self.host, self.port), self.timeout)\n+        try:\n+            sock = socket.create_connection(\n+                address=(self.host, self.port),\n+                timeout=self.timeout)\n+        except SocketTimeout:\n+                raise ConnectTimeoutError(\n+                    self, \"Connection to %s timed out. (connect timeout=%s)\" %\n+                    (self.host, self.timeout))\n \n         resolved_cert_reqs = resolve_cert_reqs(self.cert_reqs)\n         resolved_ssl_version = resolve_ssl_version(self.ssl_version)\n@@ -123,6 +138,7 @@ class VerifiedHTTPSConnection(HTTPSConnection):\n                 match_hostname(self.sock.getpeercert(),\n                                self.assert_hostname or self.host)\n \n+\n ## Pool objects\n \n class ConnectionPool(object):\n@@ -135,6 +151,9 @@ class ConnectionPool(object):\n     QueueCls = LifoQueue\n \n     def __init__(self, host, port=None):\n+        # httplib doesn't like it when we include brackets in ipv6 addresses\n+        host = host.strip('[]')\n+\n         self.host = host\n         self.port = port\n \n@@ -142,6 +161,8 @@ class ConnectionPool(object):\n         return '%s(host=%r, port=%r)' % (type(self).__name__,\n                                          self.host, self.port)\n \n+# This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252\n+_blocking_errnos = set([errno.EAGAIN, errno.EWOULDBLOCK])\n \n class HTTPConnectionPool(ConnectionPool, RequestMethods):\n     \"\"\"\n@@ -160,9 +181,15 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         as a valid HTTP/1.0 or 1.1 status line, passed into\n         :class:`httplib.HTTPConnection`.\n \n+        .. note::\n+           Only works in Python 2. This parameter is ignored in Python 3.\n+\n     :param timeout:\n-        Socket timeout in seconds for each individual connection, can be\n-        a float. None disables timeout.\n+        Socket timeout in seconds for each individual connection. This can\n+        be a float or integer, which sets the timeout for the HTTP request,\n+        or an instance of :class:`urllib3.util.Timeout` which gives you more\n+        fine-grained control over request timeouts. After the constructor has\n+        been parsed, this is always a `urllib3.util.Timeout` object.\n \n     :param maxsize:\n         Number of connections to save that can be reused. More than 1 is useful\n@@ -192,13 +219,21 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n     scheme = 'http'\n \n-    def __init__(self, host, port=None, strict=False, timeout=None, maxsize=1,\n-                 block=False, headers=None, _proxy=None, _proxy_headers=None):\n+    def __init__(self, host, port=None, strict=False,\n+                 timeout=Timeout.DEFAULT_TIMEOUT, maxsize=1, block=False,\n+                 headers=None, _proxy=None, _proxy_headers=None):\n         ConnectionPool.__init__(self, host, port)\n         RequestMethods.__init__(self, headers)\n \n         self.strict = strict\n+\n+        # This is for backwards compatibility and can be removed once a timeout\n+        # can only be set to a Timeout object\n+        if not isinstance(timeout, Timeout):\n+            timeout = Timeout.from_float(timeout)\n+\n         self.timeout = timeout\n+\n         self.pool = self.QueueCls(maxsize)\n         self.block = block\n \n@@ -220,9 +255,14 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         self.num_connections += 1\n         log.info(\"Starting new HTTP connection (%d): %s\" %\n                  (self.num_connections, self.host))\n-        return HTTPConnection(host=self.host,\n-                              port=self.port,\n-                              strict=self.strict)\n+        extra_params = {}\n+        if not six.PY3:  # Python 2\n+            extra_params['strict'] = self.strict\n+\n+        return HTTPConnection(host=self.host, port=self.port,\n+                              timeout=self.timeout.connect_timeout,\n+                              **extra_params)\n+\n \n     def _get_conn(self, timeout=None):\n         \"\"\"\n@@ -283,31 +323,89 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n                         % self.host)\n \n         # Connection never got put back into the pool, close it.\n+        if conn:\n             conn.close()\n \n+    def _get_timeout(self, timeout):\n+        \"\"\" Helper that always returns a :class:`urllib3.util.Timeout` \"\"\"\n+        if timeout is _Default:\n+            return self.timeout.clone()\n+\n+        if isinstance(timeout, Timeout):\n+            return timeout.clone()\n+        else:\n+            # User passed us an int/float. This is for backwards compatibility,\n+            # can be removed later\n+            return Timeout.from_float(timeout)\n+\n     def _make_request(self, conn, method, url, timeout=_Default,\n                       **httplib_request_kw):\n         \"\"\"\n         Perform a request on a given httplib connection object taken from our\n         pool.\n+\n+        :param conn:\n+            a connection from one of our connection pools\n+\n+        :param timeout:\n+            Socket timeout in seconds for the request. This can be a\n+            float or integer, which will set the same timeout value for\n+            the socket connect and the socket read, or an instance of\n+            :class:`urllib3.util.Timeout`, which gives you more fine-grained\n+            control over your timeouts.\n         \"\"\"\n         self.num_requests += 1\n \n-        if timeout is _Default:\n-            timeout = self.timeout\n+        timeout_obj = self._get_timeout(timeout)\n \n-        conn.timeout = timeout # This only does anything in Py26+\n+        try:\n+            timeout_obj.start_connect()\n+            conn.timeout = timeout_obj.connect_timeout\n+            # conn.request() calls httplib.*.request, not the method in\n+            # request.py. It also calls makefile (recv) on the socket\n             conn.request(method, url, **httplib_request_kw)\n+        except SocketTimeout:\n+            raise ConnectTimeoutError(\n+                self, \"Connection to %s timed out. (connect timeout=%s)\" %\n+                (self.host, timeout_obj.connect_timeout))\n \n-        # Set timeout\n-        sock = getattr(conn, 'sock', False) # AppEngine doesn't have sock attr.\n-        if sock:\n-            sock.settimeout(timeout)\n+        # Reset the timeout for the recv() on the socket\n+        read_timeout = timeout_obj.read_timeout\n+        log.debug(\"Setting read timeout to %s\" % read_timeout)\n+        # App Engine doesn't have a sock attr\n+        if hasattr(conn, 'sock') and \\\n+            read_timeout is not None and \\\n+            read_timeout is not Timeout.DEFAULT_TIMEOUT:\n+            # In Python 3 socket.py will catch EAGAIN and return None when you\n+            # try and read into the file pointer created by http.client, which\n+            # instead raises a BadStatusLine exception. Instead of catching\n+            # the exception and assuming all BadStatusLine exceptions are read\n+            # timeouts, check for a zero timeout before making the request.\n+            if read_timeout == 0:\n+                raise ReadTimeoutError(\n+                    self, url,\n+                    \"Read timed out. (read timeout=%s)\" % read_timeout)\n+            conn.sock.settimeout(read_timeout)\n \n+        # Receive the response from the server\n+        try:\n             try: # Python 2.7+, use buffering of HTTP responses\n                 httplib_response = conn.getresponse(buffering=True)\n             except TypeError: # Python 2.6 and older\n                 httplib_response = conn.getresponse()\n+        except SocketTimeout:\n+            raise ReadTimeoutError(\n+                self, url, \"Read timed out. (read timeout=%s)\" % read_timeout)\n+\n+        except SocketError as e: # Platform-specific: Python 2\n+            # See the above comment about EAGAIN in Python 3. In Python 2 we\n+            # have to specifically catch it and throw the timeout error\n+            if e.errno in _blocking_errnos:\n+                raise ReadTimeoutError(\n+                    self, url,\n+                    \"Read timed out. (read timeout=%s)\" % read_timeout)\n+            raise\n+\n \n         # AppEngine doesn't have a version attr.\n         http_version = getattr(conn, '_http_vsn_str', 'HTTP/?')\n@@ -387,7 +485,7 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n \n         :param redirect:\n             If True, automatically handle redirects (status codes 301, 302,\n-            303, 307). Each redirect counts as a retry.\n+            303, 307, 308). Each redirect counts as a retry.\n \n         :param assert_same_host:\n             If ``True``, will make sure that the host of the pool requests is\n@@ -395,8 +493,9 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             use the pool on an HTTP proxy and request foreign hosts.\n \n         :param timeout:\n-            If specified, overrides the default timeout for this one request.\n-            It may be a float (in seconds).\n+            If specified, overrides the default timeout for this one\n+            request. It may be a float (in seconds) or an instance of\n+            :class:`urllib3.util.Timeout`.\n \n         :param pool_timeout:\n             If set and the pool is set to block=True, then this method will\n@@ -423,9 +522,6 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n         if retries < 0:\n             raise MaxRetryError(self, url)\n \n-        if timeout is _Default:\n-            timeout = self.timeout\n-\n         if release_conn is None:\n             release_conn = response_kw.get('preload_content', True)\n \n@@ -461,20 +557,20 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             #     ``response.release_conn()`` is called (implicitly by\n             #     ``response.read()``)\n \n-        except Empty as e:\n+        except Empty:\n             # Timed out by queue\n-            raise TimeoutError(self, url,\n-                               \"Request timed out. (pool_timeout=%s)\" %\n-                               pool_timeout)\n+            raise ReadTimeoutError(\n+                self, url, \"Read timed out, no pool connections are available.\")\n \n-        except SocketTimeout as e:\n+        except SocketTimeout:\n             # Timed out by socket\n-            raise TimeoutError(self, url,\n-                               \"Request timed out. (timeout=%s)\" %\n-                               timeout)\n+            raise ReadTimeoutError(self, url, \"Read timed out.\")\n \n         except BaseSSLError as e:\n             # SSL certificate error\n+            if 'timed out' in str(e) or \\\n+               'did not complete (read)' in str(e): # Platform-specific: Python 2.6\n+                raise ReadTimeoutError(self, url, \"Read timed out.\")\n             raise SSLError(e)\n \n         except CertificateError as e:\n@@ -482,6 +578,10 @@ class HTTPConnectionPool(ConnectionPool, RequestMethods):\n             raise SSLError(e)\n \n         except (HTTPException, SocketError) as e:\n+            if isinstance(e, SocketError) and self.proxy is not None:\n+                raise ProxyError('Cannot connect to proxy. '\n+                                 'Socket error: %s.' % e)\n+\n             # Connection broken, discard. It will be replaced next _get_conn().\n             conn = None\n             # This is necessary so we can access e below\n@@ -548,8 +648,7 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n                  ca_certs=None, ssl_version=None,\n                  assert_hostname=None, assert_fingerprint=None):\n \n-        HTTPConnectionPool.__init__(self, host, port,\n-                                    strict, timeout, maxsize,\n+        HTTPConnectionPool.__init__(self, host, port, strict, timeout, maxsize,\n                                     block, headers, _proxy, _proxy_headers)\n         self.key_file = key_file\n         self.cert_file = cert_file\n@@ -609,8 +708,12 @@ class HTTPSConnectionPool(HTTPConnectionPool):\n         else:\n             connection_class = VerifiedHTTPSConnection\n \n+        extra_params = {}\n+        if not six.PY3:  # Python 2\n+            extra_params['strict'] = self.strict\n         connection = connection_class(host=actual_host, port=actual_port,\n-                                      strict=self.strict)\n+                                      timeout=self.timeout.connect_timeout,\n+                                      **extra_params)\n \n         return self._prepare_conn(connection)\n \n\n@@ -20,13 +20,13 @@ Now you can use :mod:`urllib3` as you normally would, and it will support SNI\n when the required modules are installed.\n '''\n \n-from ndg.httpsclient.ssl_peer_verification import (ServerSSLCertVerification,\n-                                                   SUBJ_ALT_NAME_SUPPORT)\n+from ndg.httpsclient.ssl_peer_verification import SUBJ_ALT_NAME_SUPPORT\n from ndg.httpsclient.subj_alt_name import SubjectAltName\n import OpenSSL.SSL\n from pyasn1.codec.der import decoder as der_decoder\n from socket import _fileobject\n import ssl\n+from cStringIO import StringIO\n \n from .. import connectionpool\n from .. import util\n@@ -99,6 +99,172 @@ def get_subj_alt_name(peer_cert):\n     return dns_name\n \n \n+class fileobject(_fileobject):\n+\n+    def read(self, size=-1):\n+        # Use max, disallow tiny reads in a loop as they are very inefficient.\n+        # We never leave read() with any leftover data from a new recv() call\n+        # in our internal buffer.\n+        rbufsize = max(self._rbufsize, self.default_bufsize)\n+        # Our use of StringIO rather than lists of string objects returned by\n+        # recv() minimizes memory usage and fragmentation that occurs when\n+        # rbufsize is large compared to the typical return value of recv().\n+        buf = self._rbuf\n+        buf.seek(0, 2)  # seek end\n+        if size < 0:\n+            # Read until EOF\n+            self._rbuf = StringIO()  # reset _rbuf.  we consume it via buf.\n+            while True:\n+                try:\n+                    data = self._sock.recv(rbufsize)\n+                except OpenSSL.SSL.WantReadError:\n+                    continue\n+                if not data:\n+                    break\n+                buf.write(data)\n+            return buf.getvalue()\n+        else:\n+            # Read until size bytes or EOF seen, whichever comes first\n+            buf_len = buf.tell()\n+            if buf_len >= size:\n+                # Already have size bytes in our buffer?  Extract and return.\n+                buf.seek(0)\n+                rv = buf.read(size)\n+                self._rbuf = StringIO()\n+                self._rbuf.write(buf.read())\n+                return rv\n+\n+            self._rbuf = StringIO()  # reset _rbuf.  we consume it via buf.\n+            while True:\n+                left = size - buf_len\n+                # recv() will malloc the amount of memory given as its\n+                # parameter even though it often returns much less data\n+                # than that.  The returned data string is short lived\n+                # as we copy it into a StringIO and free it.  This avoids\n+                # fragmentation issues on many platforms.\n+                try:\n+                    data = self._sock.recv(left)\n+                except OpenSSL.SSL.WantReadError:\n+                    continue\n+                if not data:\n+                    break\n+                n = len(data)\n+                if n == size and not buf_len:\n+                    # Shortcut.  Avoid buffer data copies when:\n+                    # - We have no data in our buffer.\n+                    # AND\n+                    # - Our call to recv returned exactly the\n+                    #   number of bytes we were asked to read.\n+                    return data\n+                if n == left:\n+                    buf.write(data)\n+                    del data  # explicit free\n+                    break\n+                assert n <= left, \"recv(%d) returned %d bytes\" % (left, n)\n+                buf.write(data)\n+                buf_len += n\n+                del data  # explicit free\n+                #assert buf_len == buf.tell()\n+            return buf.getvalue()\n+\n+    def readline(self, size=-1):\n+        buf = self._rbuf\n+        buf.seek(0, 2)  # seek end\n+        if buf.tell() > 0:\n+            # check if we already have it in our buffer\n+            buf.seek(0)\n+            bline = buf.readline(size)\n+            if bline.endswith('\\n') or len(bline) == size:\n+                self._rbuf = StringIO()\n+                self._rbuf.write(buf.read())\n+                return bline\n+            del bline\n+        if size < 0:\n+            # Read until \\n or EOF, whichever comes first\n+            if self._rbufsize <= 1:\n+                # Speed up unbuffered case\n+                buf.seek(0)\n+                buffers = [buf.read()]\n+                self._rbuf = StringIO()  # reset _rbuf.  we consume it via buf.\n+                data = None\n+                recv = self._sock.recv\n+                while True:\n+                    try:\n+                        while data != \"\\n\":\n+                            data = recv(1)\n+                            if not data:\n+                                break\n+                            buffers.append(data)\n+                    except OpenSSL.SSL.WantReadError:\n+                        continue\n+                    break\n+                return \"\".join(buffers)\n+\n+            buf.seek(0, 2)  # seek end\n+            self._rbuf = StringIO()  # reset _rbuf.  we consume it via buf.\n+            while True:\n+                try:\n+                    data = self._sock.recv(self._rbufsize)\n+                except OpenSSL.SSL.WantReadError:\n+                    continue\n+                if not data:\n+                    break\n+                nl = data.find('\\n')\n+                if nl >= 0:\n+                    nl += 1\n+                    buf.write(data[:nl])\n+                    self._rbuf.write(data[nl:])\n+                    del data\n+                    break\n+                buf.write(data)\n+            return buf.getvalue()\n+        else:\n+            # Read until size bytes or \\n or EOF seen, whichever comes first\n+            buf.seek(0, 2)  # seek end\n+            buf_len = buf.tell()\n+            if buf_len >= size:\n+                buf.seek(0)\n+                rv = buf.read(size)\n+                self._rbuf = StringIO()\n+                self._rbuf.write(buf.read())\n+                return rv\n+            self._rbuf = StringIO()  # reset _rbuf.  we consume it via buf.\n+            while True:\n+                try:\n+                    data = self._sock.recv(self._rbufsize)\n+                except OpenSSL.SSL.WantReadError:\n+                        continue\n+                if not data:\n+                    break\n+                left = size - buf_len\n+                # did we just receive a newline?\n+                nl = data.find('\\n', 0, left)\n+                if nl >= 0:\n+                    nl += 1\n+                    # save the excess data to _rbuf\n+                    self._rbuf.write(data[nl:])\n+                    if buf_len:\n+                        buf.write(data[:nl])\n+                        break\n+                    else:\n+                        # Shortcut.  Avoid data copy through buf when returning\n+                        # a substring of our first recv().\n+                        return data[:nl]\n+                n = len(data)\n+                if n == size and not buf_len:\n+                    # Shortcut.  Avoid data copy through buf when\n+                    # returning exactly all of our first recv().\n+                    return data\n+                if n >= left:\n+                    buf.write(data[:left])\n+                    self._rbuf.write(data[left:])\n+                    break\n+                buf.write(data)\n+                buf_len += n\n+                #assert buf_len == buf.tell()\n+            return buf.getvalue()\n+\n+\n class WrappedSocket(object):\n     '''API-compatibility wrapper for Python OpenSSL's Connection-class.'''\n \n@@ -110,7 +276,7 @@ class WrappedSocket(object):\n         return self.socket.fileno()\n \n     def makefile(self, mode, bufsize=-1):\n-        return _fileobject(self.connection, mode, bufsize)\n+        return fileobject(self.connection, mode, bufsize)\n \n     def settimeout(self, timeout):\n         return self.socket.settimeout(timeout)\n@@ -123,8 +289,9 @@ class WrappedSocket(object):\n \n     def getpeercert(self, binary_form=False):\n         x509 = self.connection.get_peer_certificate()\n+\n         if not x509:\n-            raise ssl.SSLError('')\n+            return x509\n \n         if binary_form:\n             return OpenSSL.crypto.dump_certificate(\n@@ -165,9 +332,13 @@ def ssl_wrap_socket(sock, keyfile=None, certfile=None, cert_reqs=None,\n     cnx = OpenSSL.SSL.Connection(ctx, sock)\n     cnx.set_tlsext_host_name(server_hostname)\n     cnx.set_connect_state()\n+    while True:\n         try:\n             cnx.do_handshake()\n+        except OpenSSL.SSL.WantReadError:\n+            continue\n         except OpenSSL.SSL.Error as e:\n             raise ssl.SSLError('bad handshake', e)\n+        break\n \n     return WrappedSocket(cnx, sock)\n\n@@ -39,6 +39,11 @@ class SSLError(HTTPError):\n     pass\n \n \n+class ProxyError(HTTPError):\n+    \"Raised when the connection to a proxy fails.\"\n+    pass\n+\n+\n class DecodeError(HTTPError):\n     \"Raised when automatic decoding based on Content-Type fails.\"\n     pass\n@@ -70,8 +75,29 @@ class HostChangedError(RequestError):\n         self.retries = retries\n \n \n-class TimeoutError(RequestError):\n-    \"Raised when a socket timeout occurs.\"\n+class TimeoutStateError(HTTPError):\n+    \"\"\" Raised when passing an invalid state to a timeout \"\"\"\n+    pass\n+\n+\n+class TimeoutError(HTTPError):\n+    \"\"\" Raised when a socket timeout error occurs.\n+\n+    Catching this error will catch both :exc:`ReadTimeoutErrors\n+    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.\n+    \"\"\"\n+    pass\n+\n+\n+class ReadTimeoutError(TimeoutError, RequestError):\n+    \"Raised when a socket timeout occurs while receiving data from a server\"\n+    pass\n+\n+\n+# This timeout error does not have a URL attached and needs to inherit from the\n+# base HTTPError\n+class ConnectTimeoutError(TimeoutError):\n+    \"Raised when a socket timeout occurs while connecting to a server\"\n     pass\n \n \n\n@@ -0,0 +1,177 @@\n+# urllib3/fields.py\n+# Copyright 2008-2013 Andrey Petrov and contributors (see CONTRIBUTORS.txt)\n+#\n+# This module is part of urllib3 and is released under\n+# the MIT License: http://www.opensource.org/licenses/mit-license.php\n+\n+import email.utils\n+import mimetypes\n+\n+from .packages import six\n+\n+\n+def guess_content_type(filename, default='application/octet-stream'):\n+    \"\"\"\n+    Guess the \"Content-Type\" of a file.\n+\n+    :param filename:\n+        The filename to guess the \"Content-Type\" of using :mod:`mimetimes`.\n+    :param default:\n+        If no \"Content-Type\" can be guessed, default to `default`.\n+    \"\"\"\n+    if filename:\n+        return mimetypes.guess_type(filename)[0] or default\n+    return default\n+\n+\n+def format_header_param(name, value):\n+    \"\"\"\n+    Helper function to format and quote a single header parameter.\n+\n+    Particularly useful for header parameters which might contain\n+    non-ASCII values, like file names. This follows RFC 2231, as\n+    suggested by RFC 2388 Section 4.4.\n+\n+    :param name:\n+        The name of the parameter, a string expected to be ASCII only.\n+    :param value:\n+        The value of the parameter, provided as a unicode string.\n+    \"\"\"\n+    if not any(ch in value for ch in '\"\\\\\\r\\n'):\n+        result = '%s=\"%s\"' % (name, value)\n+        try:\n+            result.encode('ascii')\n+        except UnicodeEncodeError:\n+            pass\n+        else:\n+            return result\n+    if not six.PY3:  # Python 2:\n+        value = value.encode('utf-8')\n+    value = email.utils.encode_rfc2231(value, 'utf-8')\n+    value = '%s*=%s' % (name, value)\n+    return value\n+\n+\n+class RequestField(object):\n+    \"\"\"\n+    A data container for request body parameters.\n+\n+    :param name:\n+        The name of this request field.\n+    :param data:\n+        The data/value body.\n+    :param filename:\n+        An optional filename of the request field.\n+    :param headers:\n+        An optional dict-like object of headers to initially use for the field.\n+    \"\"\"\n+    def __init__(self, name, data, filename=None, headers=None):\n+        self._name = name\n+        self._filename = filename\n+        self.data = data\n+        self.headers = {}\n+        if headers:\n+            self.headers = dict(headers)\n+\n+    @classmethod\n+    def from_tuples(cls, fieldname, value):\n+        \"\"\"\n+        A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.\n+\n+        Supports constructing :class:`~urllib3.fields.RequestField` from parameter\n+        of key/value strings AND key/filetuple. A filetuple is a (filename, data, MIME type)\n+        tuple where the MIME type is optional. For example: ::\n+\n+            'foo': 'bar',\n+            'fakefile': ('foofile.txt', 'contents of foofile'),\n+            'realfile': ('barfile.txt', open('realfile').read()),\n+            'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),\n+            'nonamefile': 'contents of nonamefile field',\n+\n+        Field names and filenames must be unicode.\n+        \"\"\"\n+        if isinstance(value, tuple):\n+            if len(value) == 3:\n+                filename, data, content_type = value\n+            else:\n+                filename, data = value\n+                content_type = guess_content_type(filename)\n+        else:\n+            filename = None\n+            content_type = None\n+            data = value\n+\n+        request_param = cls(fieldname, data, filename=filename)\n+        request_param.make_multipart(content_type=content_type)\n+\n+        return request_param\n+\n+    def _render_part(self, name, value):\n+        \"\"\"\n+        Overridable helper function to format a single header parameter.\n+\n+        :param name:\n+            The name of the parameter, a string expected to be ASCII only.\n+        :param value:\n+            The value of the parameter, provided as a unicode string.\n+        \"\"\"\n+        return format_header_param(name, value)\n+\n+    def _render_parts(self, header_parts):\n+        \"\"\"\n+        Helper function to format and quote a single header.\n+\n+        Useful for single headers that are composed of multiple items. E.g.,\n+        'Content-Disposition' fields.\n+\n+        :param header_parts:\n+            A sequence of (k, v) typles or a :class:`dict` of (k, v) to format as\n+            `k1=\"v1\"; k2=\"v2\"; ...`.\n+        \"\"\"\n+        parts = []\n+        iterable = header_parts\n+        if isinstance(header_parts, dict):\n+            iterable = header_parts.items()\n+\n+        for name, value in iterable:\n+            if value:\n+                parts.append(self._render_part(name, value))\n+\n+        return '; '.join(parts)\n+\n+    def render_headers(self):\n+        \"\"\"\n+        Renders the headers for this request field.\n+        \"\"\"\n+        lines = []\n+\n+        sort_keys = ['Content-Disposition', 'Content-Type', 'Content-Location']\n+        for sort_key in sort_keys:\n+            if self.headers.get(sort_key, False):\n+                lines.append('%s: %s' % (sort_key, self.headers[sort_key]))\n+\n+        for header_name, header_value in self.headers.items():\n+            if header_name not in sort_keys:\n+                if header_value:\n+                    lines.append('%s: %s' % (header_name, header_value))\n+\n+        lines.append('\\r\\n')\n+        return '\\r\\n'.join(lines)\n+\n+    def make_multipart(self, content_disposition=None, content_type=None, content_location=None):\n+        \"\"\"\n+        Makes this request field into a multipart request field.\n+\n+        This method overrides \"Content-Disposition\", \"Content-Type\" and\n+        \"Content-Location\" headers to the request parameter.\n+\n+        :param content_type:\n+            The 'Content-Type' of the request body.\n+        :param content_location:\n+            The 'Content-Location' of the request body.\n+\n+        \"\"\"\n+        self.headers['Content-Disposition'] = content_disposition or 'form-data'\n+        self.headers['Content-Disposition'] += '; '.join(['', self._render_parts((('name', self._name), ('filename', self._filename)))])\n+        self.headers['Content-Type'] = content_type\n+        self.headers['Content-Location'] = content_location\n\n@@ -12,6 +12,7 @@ from io import BytesIO\n \n from .packages import six\n from .packages.six import b\n+from .fields import RequestField\n \n writer = codecs.lookup('utf-8')[3]\n \n@@ -23,15 +24,38 @@ def choose_boundary():\n     return uuid4().hex\n \n \n-def get_content_type(filename):\n-    return mimetypes.guess_type(filename)[0] or 'application/octet-stream'\n+def iter_field_objects(fields):\n+    \"\"\"\n+    Iterate over fields.\n+\n+    Supports list of (k, v) tuples and dicts, and lists of\n+    :class:`~urllib3.fields.RequestField`.\n+\n+    \"\"\"\n+    if isinstance(fields, dict):\n+        i = six.iteritems(fields)\n+    else:\n+        i = iter(fields)\n+\n+    for field in i:\n+      if isinstance(field, RequestField):\n+        yield field\n+      else:\n+        yield RequestField.from_tuples(*field)\n \n \n def iter_fields(fields):\n     \"\"\"\n     Iterate over fields.\n \n+    .. deprecated ::\n+\n+      The addition of `~urllib3.fields.RequestField` makes this function\n+      obsolete. Instead, use :func:`iter_field_objects`, which returns\n+      `~urllib3.fields.RequestField` objects, instead.\n+\n     Supports list of (k, v) tuples and dicts.\n+\n     \"\"\"\n     if isinstance(fields, dict):\n         return ((k, v) for k, v in six.iteritems(fields))\n@@ -44,15 +68,7 @@ def encode_multipart_formdata(fields, boundary=None):\n     Encode a dictionary of ``fields`` using the multipart/form-data MIME format.\n \n     :param fields:\n-        Dictionary of fields or list of (key, value) or (key, value, MIME type)\n-        field tuples.  The key is treated as the field name, and the value as\n-        the body of the form-data bytes. If the value is a tuple of two\n-        elements, then the first element is treated as the filename of the\n-        form-data section and a suitable MIME type is guessed based on the\n-        filename. If the value is a tuple of three elements, then the third\n-        element is treated as an explicit MIME type of the form-data section.\n-\n-        Field names and filenames must be unicode.\n+        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).\n \n     :param boundary:\n         If not specified, then a random boundary will be generated using\n@@ -62,24 +78,11 @@ def encode_multipart_formdata(fields, boundary=None):\n     if boundary is None:\n         boundary = choose_boundary()\n \n-    for fieldname, value in iter_fields(fields):\n+    for field in iter_field_objects(fields):\n         body.write(b('--%s\\r\\n' % (boundary)))\n \n-        if isinstance(value, tuple):\n-            if len(value) == 3:\n-                filename, data, content_type = value\n-            else:\n-                filename, data = value\n-                content_type = get_content_type(filename)\n-            writer(body).write('Content-Disposition: form-data; name=\"%s\"; '\n-                               'filename=\"%s\"\\r\\n' % (fieldname, filename))\n-            body.write(b('Content-Type: %s\\r\\n\\r\\n' %\n-                       (content_type,)))\n-        else:\n-            data = value\n-            writer(body).write('Content-Disposition: form-data; name=\"%s\"\\r\\n'\n-                               % (fieldname))\n-            body.write(b'\\r\\n')\n+        writer(body).write(field.render_headers())\n+        data = field.data\n \n         if isinstance(data, int):\n             data = str(data)  # Backwards compatibility\n\n@@ -7,23 +7,60 @@ __version__ = '3.2.2'\n class CertificateError(ValueError):\n     pass\n \n-def _dnsname_to_pat(dn):\n+def _dnsname_match(dn, hostname, max_wildcards=1):\n+    \"\"\"Matching according to RFC 6125, section 6.4.3\n+\n+    http://tools.ietf.org/html/rfc6125#section-6.4.3\n+    \"\"\"\n     pats = []\n-    for frag in dn.split(r'.'):\n-        if frag == '*':\n+    if not dn:\n+        return False\n+\n+    parts = dn.split(r'.')\n+    leftmost = parts[0]\n+\n+    wildcards = leftmost.count('*')\n+    if wildcards > max_wildcards:\n+        # Issue #17980: avoid denials of service by refusing more\n+        # than one wildcard per fragment.  A survery of established\n+        # policy among SSL implementations showed it to be a\n+        # reasonable choice.\n+        raise CertificateError(\n+            \"too many wildcards in certificate DNS name: \" + repr(dn))\n+\n+    # speed up common case w/o wildcards\n+    if not wildcards:\n+        return dn.lower() == hostname.lower()\n+\n+    # RFC 6125, section 6.4.3, subitem 1.\n+    # The client SHOULD NOT attempt to match a presented identifier in which\n+    # the wildcard character comprises a label other than the left-most label.\n+    if leftmost == '*':\n         # When '*' is a fragment by itself, it matches a non-empty dotless\n         # fragment.\n         pats.append('[^.]+')\n+    elif leftmost.startswith('xn--') or hostname.startswith('xn--'):\n+        # RFC 6125, section 6.4.3, subitem 3.\n+        # The client SHOULD NOT attempt to match a presented identifier\n+        # where the wildcard character is embedded within an A-label or\n+        # U-label of an internationalized domain name.\n+        pats.append(re.escape(leftmost))\n     else:\n-            # Otherwise, '*' matches any dotless fragment.\n-            frag = re.escape(frag)\n-            pats.append(frag.replace(r'\\*', '[^.]*'))\n-    return re.compile(r'\\A' + r'\\.'.join(pats) + r'\\Z', re.IGNORECASE)\n+        # Otherwise, '*' matches any dotless string, e.g. www*\n+        pats.append(re.escape(leftmost).replace(r'\\*', '[^.]*'))\n+\n+    # add the remaining fragments, ignore any wildcards\n+    for frag in parts[1:]:\n+        pats.append(re.escape(frag))\n+\n+    pat = re.compile(r'\\A' + r'\\.'.join(pats) + r'\\Z', re.IGNORECASE)\n+    return pat.match(hostname)\n+\n \n def match_hostname(cert, hostname):\n     \"\"\"Verify that *cert* (in decoded format as returned by\n-    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 rules\n-    are mostly followed, but IP addresses are not accepted for *hostname*.\n+    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125\n+    rules are followed, but IP addresses are not accepted for *hostname*.\n \n     CertificateError is raised on failure. On success, the function\n     returns nothing.\n@@ -34,7 +71,7 @@ def match_hostname(cert, hostname):\n     san = cert.get('subjectAltName', ())\n     for key, value in san:\n         if key == 'DNS':\n-            if _dnsname_to_pat(value).match(hostname):\n+            if _dnsname_match(value, hostname):\n                 return\n             dnsnames.append(value)\n     if not dnsnames:\n@@ -45,7 +82,7 @@ def match_hostname(cert, hostname):\n                 # XXX according to RFC 2818, the most specific Common Name\n                 # must be used.\n                 if key == 'commonName':\n-                    if _dnsname_to_pat(value).match(hostname):\n+                    if _dnsname_match(value, hostname):\n                         return\n                     dnsnames.append(value)\n     if len(dnsnames) > 1:\n\n@@ -74,6 +74,7 @@ class HTTPResponse(io.IOBase):\n     \"\"\"\n \n     CONTENT_DECODERS = ['gzip', 'deflate']\n+    REDIRECT_STATUSES = [301, 302, 303, 307, 308]\n \n     def __init__(self, body='', headers=None, status=0, version=0, reason=None,\n                  strict=0, preload_content=True, decode_content=True,\n@@ -107,7 +108,7 @@ class HTTPResponse(io.IOBase):\n             code and valid location. ``None`` if redirect status and no\n             location. ``False`` if not a redirect status code.\n         \"\"\"\n-        if self.status in [301, 302, 303, 307]:\n+        if self.status in self.REDIRECT_STATUSES:\n             return self.headers.get('location')\n \n         return False\n\n@@ -6,10 +6,11 @@\n \n \n from base64 import b64encode\n-from collections import namedtuple\n-from socket import error as SocketError\n-from hashlib import md5, sha1\n from binascii import hexlify, unhexlify\n+from collections import namedtuple\n+from hashlib import md5, sha1\n+from socket import error as SocketError, _GLOBAL_DEFAULT_TIMEOUT\n+import time\n \n try:\n     from select import poll, POLLIN\n@@ -32,7 +33,233 @@ except ImportError:\n     pass\n \n from .packages import six\n-from .exceptions import LocationParseError, SSLError\n+from .exceptions import LocationParseError, SSLError, TimeoutStateError\n+\n+\n+_Default = object()\n+# The default timeout to use for socket connections. This is the attribute used\n+# by httplib to define the default timeout\n+\n+\n+def current_time():\n+    \"\"\"\n+    Retrieve the current time, this function is mocked out in unit testing.\n+    \"\"\"\n+    return time.time()\n+\n+\n+class Timeout(object):\n+    \"\"\"\n+    Utility object for storing timeout values.\n+\n+    Example usage:\n+\n+    .. code-block:: python\n+\n+        timeout = urllib3.util.Timeout(connect=2.0, read=7.0)\n+        pool = HTTPConnectionPool('www.google.com', 80, timeout=timeout)\n+        pool.request(...) # Etc, etc\n+\n+    :param connect:\n+        The maximum amount of time to wait for a connection attempt to a server\n+        to succeed. Omitting the parameter will default the connect timeout to\n+        the system default, probably `the global default timeout in socket.py\n+        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n+        None will set an infinite timeout for connection attempts.\n+\n+    :type connect: integer, float, or None\n+\n+    :param read:\n+        The maximum amount of time to wait between consecutive\n+        read operations for a response from the server. Omitting\n+        the parameter will default the read timeout to the system\n+        default, probably `the global default timeout in socket.py\n+        <http://hg.python.org/cpython/file/603b4d593758/Lib/socket.py#l535>`_.\n+        None will set an infinite timeout.\n+\n+    :type read: integer, float, or None\n+\n+    :param total:\n+        The maximum amount of time to wait for an HTTP request to connect and\n+        return. This combines the connect and read timeouts into one. In the\n+        event that both a connect timeout and a total are specified, or a read\n+        timeout and a total are specified, the shorter timeout will be applied.\n+\n+        Defaults to None.\n+\n+\n+    :type total: integer, float, or None\n+\n+    .. note::\n+\n+        Many factors can affect the total amount of time for urllib3 to return\n+        an HTTP response. Specifically, Python's DNS resolver does not obey the\n+        timeout specified on the socket. Other factors that can affect total\n+        request time include high CPU load, high swap, the program running at a\n+        low priority level, or other behaviors. The observed running time for\n+        urllib3 to return a response may be greater than the value passed to\n+        `total`.\n+\n+        In addition, the read and total timeouts only measure the time between\n+        read operations on the socket connecting the client and the server, not\n+        the total amount of time for the request to return a complete response.\n+        As an example, you may want a request to return within 7 seconds or\n+        fail, so you set the ``total`` timeout to 7 seconds. If the server\n+        sends one byte to you every 5 seconds, the request will **not** trigger\n+        time out. This case is admittedly rare.\n+    \"\"\"\n+\n+    #: A sentinel object representing the default timeout value\n+    DEFAULT_TIMEOUT = _GLOBAL_DEFAULT_TIMEOUT\n+\n+    def __init__(self, connect=_Default, read=_Default, total=None):\n+        self._connect = self._validate_timeout(connect, 'connect')\n+        self._read = self._validate_timeout(read, 'read')\n+        self.total = self._validate_timeout(total, 'total')\n+        self._start_connect = None\n+\n+    def __str__(self):\n+        return '%s(connect=%r, read=%r, total=%r)' % (\n+            type(self).__name__, self._connect, self._read, self.total)\n+\n+\n+    @classmethod\n+    def _validate_timeout(cls, value, name):\n+        \"\"\" Check that a timeout attribute is valid\n+\n+        :param value: The timeout value to validate\n+        :param name: The name of the timeout attribute to validate. This is used\n+            for clear error messages\n+        :return: the value\n+        :raises ValueError: if the type is not an integer or a float, or if it\n+            is a numeric value less than zero\n+        \"\"\"\n+        if value is _Default:\n+            return cls.DEFAULT_TIMEOUT\n+\n+        if value is None or value is cls.DEFAULT_TIMEOUT:\n+            return value\n+\n+        try:\n+            float(value)\n+        except (TypeError, ValueError):\n+            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n+                             \"int or float.\" % (name, value))\n+\n+        try:\n+            if value < 0:\n+                raise ValueError(\"Attempted to set %s timeout to %s, but the \"\n+                                 \"timeout cannot be set to a value less \"\n+                                 \"than 0.\" % (name, value))\n+        except TypeError: # Python 3\n+            raise ValueError(\"Timeout value %s was %s, but it must be an \"\n+                             \"int or float.\" % (name, value))\n+\n+        return value\n+\n+    @classmethod\n+    def from_float(cls, timeout):\n+        \"\"\" Create a new Timeout from a legacy timeout value.\n+\n+        The timeout value used by httplib.py sets the same timeout on the\n+        connect(), and recv() socket requests. This creates a :class:`Timeout`\n+        object that sets the individual timeouts to the ``timeout`` value passed\n+        to this function.\n+\n+        :param timeout: The legacy timeout value\n+        :type timeout: integer, float, sentinel default object, or None\n+        :return: a Timeout object\n+        :rtype: :class:`Timeout`\n+        \"\"\"\n+        return Timeout(read=timeout, connect=timeout)\n+\n+    def clone(self):\n+        \"\"\" Create a copy of the timeout object\n+\n+        Timeout properties are stored per-pool but each request needs a fresh\n+        Timeout object to ensure each one has its own start/stop configured.\n+\n+        :return: a copy of the timeout object\n+        :rtype: :class:`Timeout`\n+        \"\"\"\n+        # We can't use copy.deepcopy because that will also create a new object\n+        # for _GLOBAL_DEFAULT_TIMEOUT, which socket.py uses as a sentinel to\n+        # detect the user default.\n+        return Timeout(connect=self._connect, read=self._read,\n+                       total=self.total)\n+\n+    def start_connect(self):\n+        \"\"\" Start the timeout clock, used during a connect() attempt\n+\n+        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n+            to start a timer that has been started already.\n+        \"\"\"\n+        if self._start_connect is not None:\n+            raise TimeoutStateError(\"Timeout timer has already been started.\")\n+        self._start_connect = current_time()\n+        return self._start_connect\n+\n+    def get_connect_duration(self):\n+        \"\"\" Gets the time elapsed since the call to :meth:`start_connect`.\n+\n+        :return: the elapsed time\n+        :rtype: float\n+        :raises urllib3.exceptions.TimeoutStateError: if you attempt\n+            to get duration for a timer that hasn't been started.\n+        \"\"\"\n+        if self._start_connect is None:\n+            raise TimeoutStateError(\"Can't get connect duration for timer \"\n+                                    \"that has not started.\")\n+        return current_time() - self._start_connect\n+\n+    @property\n+    def connect_timeout(self):\n+        \"\"\" Get the value to use when setting a connection timeout.\n+\n+        This will be a positive float or integer, the value None\n+        (never timeout), or the default system timeout.\n+\n+        :return: the connect timeout\n+        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n+        \"\"\"\n+        if self.total is None:\n+            return self._connect\n+\n+        if self._connect is None or self._connect is self.DEFAULT_TIMEOUT:\n+            return self.total\n+\n+        return min(self._connect, self.total)\n+\n+    @property\n+    def read_timeout(self):\n+        \"\"\" Get the value for the read timeout.\n+\n+        This assumes some time has elapsed in the connection timeout and\n+        computes the read timeout appropriately.\n+\n+        If self.total is set, the read timeout is dependent on the amount of\n+        time taken by the connect timeout. If the connection time has not been\n+        established, a :exc:`~urllib3.exceptions.TimeoutStateError` will be\n+        raised.\n+\n+        :return: the value to use for the read timeout\n+        :rtype: int, float, :attr:`Timeout.DEFAULT_TIMEOUT` or None\n+        :raises urllib3.exceptions.TimeoutStateError: If :meth:`start_connect`\n+            has not yet been called on this object.\n+        \"\"\"\n+        if (self.total is not None and\n+            self.total is not self.DEFAULT_TIMEOUT and\n+            self._read is not None and\n+            self._read is not self.DEFAULT_TIMEOUT):\n+            # in case the connect timeout has not yet been established.\n+            if self._start_connect is None:\n+                return self._read\n+            return max(0, min(self.total - self.get_connect_duration(),\n+                              self._read))\n+        elif self.total is not None and self.total is not self.DEFAULT_TIMEOUT:\n+            return max(0, self.total - self.get_connect_duration())\n+        else:\n+            return self._read\n \n \n class Url(namedtuple('Url', ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment'])):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
