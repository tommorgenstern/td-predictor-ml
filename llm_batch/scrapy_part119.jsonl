{"custom_id": "scrapy#3d8b368fc642274db6c60db295da93e2b78510fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 75 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,6 +5,7 @@ from ConfigParser import NoSectionError\n \n from scrapy.spiderqueue import SqliteSpiderQueue\n from scrapy.utils.python import stringify_dict, unicode_to_str\n+from scrapyd.config import Config\n \n def get_spider_queues(config):\n     \"\"\"Return a dict of Spider Quees keyed by project name\"\"\"\n@@ -44,8 +45,10 @@ def get_crawl_args(message):\n         args += ['%s=%s' % (k, v)]\n     return args\n \n-def get_spider_list(project, runner='scrapyd.runner'):\n+def get_spider_list(project, runner=None):\n     \"\"\"Return the spider list from the given project, using the given runner\"\"\"\n+    if runner is None:\n+        runner = Config().get('runner')\n     env = os.environ.copy()\n     env['SCRAPY_PROJECT'] = project\n     pargs = [sys.executable, '-m', runner, 'list']\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#aebe5d5073bb02c02acc62148a2538ee51e203da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 10 | Churn Cumulative: 66 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,5 @@\n from os.path import join, dirname, abspath, isabs, exists\n-from os import makedirs\n+from os import makedirs, environ\n import warnings\n \n from scrapy.utils.conf import closest_scrapy_cfg, get_config\n@@ -8,6 +8,14 @@ from scrapy.utils.python import is_writable\n DATADIR_CFG_SECTION = 'datadir'\n \n def inside_project():\n+    scrapy_module = environ.get('SCRAPY_SETTINGS_MODULE')\n+    if scrapy_module is not None:\n+        try:\n+            __import__(scrapy_module)\n+        except ImportError:\n+            warnings.warn(\"Cannot import scrapy settings module %s\" % scrapy_module)\n+        else:\n+            return True\n     return bool(closest_scrapy_cfg())\n \n def project_data_dir(project='default'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fe218abbfdf34e10596d3883c4967faa32bf7713", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 38 | Churn Cumulative: 72 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,6 @@\n import os\n+import sys\n+import struct\n \n _vmvalue_scale = {'kB': 1024, 'mB': 1024*1024, 'KB': 1024, 'MB': 1024*1024}\n \n@@ -13,6 +15,9 @@ def get_vmvalue_from_procfs(vmkey='VmSize', pid=None):\n         t = open('/proc/%d/status' % pid)\n     except IOError:\n         raise RuntimeError(\"/proc filesystem not supported\")\n+    if sys.platform == \"sunos5\":\n+        return _vmvalue_solaris(vmkey, pid)\n+    else:\n         v = t.read()\n         t.close()\n         # get vmkey line e.g. 'VmRSS:  9999  kB\\n ...'\n@@ -30,3 +35,36 @@ def procfs_supported():\n         return False\n     else:\n         return True\n+\n+def _vmvalue_solaris(vmkey, pid):\n+\n+     # Memory layout for struct psinfo.\n+     # http://docs.sun.com/app/docs/doc/816-5174/proc-4?l=en&a=view\n+    _psinfo_struct_format = (\n+        \"10i\"   # pr_flag [0] through pr_egid [9]\n+        \"5L\"    # pr_addr [10] through pr_ttyydev [14]\n+        \"2H\"    # pr_pctcpu [15] and pr_pctmem [16]\n+        \"6l\"    # pr_start [17-18] through pr_ctime [21-22]\n+        \"16s\"   # pr_fname [23]\n+        \"80s\"   # pr_psargs [24]\n+        \"2i\"    # pr_wstat[25] and pr_argc [26]\n+        \"2L\"    # pr_argv [27] and pr_envp [28]\n+        \"b3x\"   # pr_dmodel[29] and pr_pad2\n+        \"7i\"    # pr_taskid [30] through pr_filler\n+        \"20i6l\" # pr_lwp\n+        )\n+    psinfo_file = os.path.join(\"/proc\", str(pid), \"psinfo\")\n+    with open(psinfo_file) as f:\n+        parts = struct.unpack(_psinfo_struct_format, f.read())\n+\n+    vmkey_index = {\n+        'VmSize' : 11, # pr_size\n+        'VmRSS'  : 12, # pr_rssize\n+    }\n+\n+    vm_in_kB = parts[vmkey_index[vmkey]]\n+\n+    def kB_to_Bytes(kB):\n+        return kB * 1024\n+\n+    return vm_in_kB * 1024\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5879389ad03059792128507c378c71d07967a089", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 130 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -2,8 +2,8 @@\n Scrapy - a screen scraping framework written in Python\n \"\"\"\n \n-version_info = (0, 11, 0)\n-__version__ = \"0.11.0\"\n+version_info = (0, 12, 0)\n+__version__ = \"0.12.0\"\n \n import sys, os, warnings\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#cd42bd7d0c8c8d9d5a4a3f38e442b5020a68116b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 134 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -2,8 +2,8 @@\n Scrapy - a screen scraping framework written in Python\n \"\"\"\n \n-version_info = (0, 12, 0)\n-__version__ = \"0.12.0\"\n+version_info = (0, 13, 0)\n+__version__ = \"0.13.0\"\n \n import sys, os, warnings\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0ba9999cca6526bd1aea84eb5ce808fc840639b7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 21 | Churn Cumulative: 819 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -81,7 +81,7 @@ class HtmlTag(HtmlDataFragment):\n         return str(self)\n \n _ATTR = \"((?:[^=/>\\s]|/(?!>))+)(?:\\s*=(?:\\s*\\\"(.*?)\\\"|\\s*'(.*?)'|([^>\\s]+))?)?\"\n-_TAG = \"<(\\/?)(\\w+(?::\\w+)?)((?:\\s+\" + _ATTR + \")+\\s*|\\s*)(\\/?)>\"\n+_TAG = \"<(\\/?)(\\w+(?::\\w+)?)((?:\\s+\" + _ATTR + \")+\\s*|\\s*)(\\/?)>?\"\n _DOCTYPE = r\"<!DOCTYPE.*?>\"\n _SCRIPT = \"(<script.*?>)(.*?)(</script.*?>)\"\n _COMMENT = \"(<!--.*?-->)\"\n\n@@ -137,3 +137,13 @@ class TestParseHtml(TestCase):\n         parsed = list(parse_html(\"<IMG SRC='http://images.play.com/banners/SAM550a.jpg' align='left' / hspace=5>\"))\n         self.assertEqual(parsed[0].attributes, {'src': 'http://images.play.com/banners/SAM550a.jpg', \\\n                                                 'align': 'left', 'hspace': '5', '/': None})\n+\n+    def test_no_ending_body(self):\n+        \"\"\"Test case when no ending body nor html elements are present\"\"\"\n+        parsed = [_decode_element(d) for d in PARSED7]\n+        self._test_sample(PAGE7, parsed)\n+\n+    def test_malformed(self):\n+        \"\"\"Test parsing of some malformed cases\"\"\"\n+        parsed = [_decode_element(d) for d in PARSED8]\n+        self._test_sample(PAGE8, parsed)\n\n@@ -246,3 +246,12 @@ PARSED7 = [\n     {'end': 99, 'start': 85},\n ]\n \n+PAGE8 = u\"\"\"<a href=\"/overview.asp?id=277\"><img border=\"0\" src=\"/img/5200814311.jpg\" title=\\'Vinyl Cornice\\'</a></td><table width=\\'5\\'>\"\"\"\n+\n+PARSED8 = [\n+   {'attributes' : {u'href' : u\"/overview.asp?id=277\"}, 'end': 31, 'start': 0, 'tag': u'a', 'tag_type': 1},\n+   {'attributes' : {u'src' : u\"/img/5200814311.jpg\", u'border' : u\"0\", u'title': u'Vinyl Cornice'}, 'end': 94, 'start': 31, 'tag': u'img', 'tag_type': 1},\n+   {'attributes' : {}, 'end': 98, 'start': 94, 'tag': u'a', 'tag_type': 2},\n+   {'attributes' : {}, 'end': 103, 'start': 98, 'tag': u'td', 'tag_type': 2},\n+   {'attributes' : {u'width': u'5'}, 'end': 120, 'start': 103, 'tag': u'table', 'tag_type': 1}\n+]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ebf5ad933e718198cfa557272693fe0aa57a775f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 77 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+from __future__ import with_statement\n+\n import os\n import sys\n import struct\n@@ -64,7 +66,4 @@ def _vmvalue_solaris(vmkey, pid):\n \n     vm_in_kB = parts[vmkey_index[vmkey]]\n \n-    def kB_to_Bytes(kB):\n-        return kB * 1024\n-\n     return vm_in_kB * 1024\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#48b30ba93940a6f29e45a3e40ca3beda69a14470", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 82 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,3 +1,5 @@\n+from __future__ import with_statement\n+\n import os\n import sys\n import struct\n@@ -64,7 +66,4 @@ def _vmvalue_solaris(vmkey, pid):\n \n     vm_in_kB = parts[vmkey_index[vmkey]]\n \n-    def kB_to_Bytes(kB):\n-        return kB * 1024\n-\n     return vm_in_kB * 1024\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#048044c1f8536b1e4d04712bba179053855294a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 51 | Lines Deleted: 19 | Files Changed: 9 | Hunks: 20 | Methods Changed: 12 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 70 | Churn Cumulative: 2261 | Contributors (this commit): 5 | Commits (past 90d): 17 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -13,6 +13,7 @@ from scrapy.conf import settings\n from scrapy.command import ScrapyCommand\n from scrapy.exceptions import UsageError\n from scrapy.utils.misc import walk_modules\n+from scrapy.utils.project import inside_project\n \n def _iter_command_classes(module_name):\n     # TODO: add `name` attribute to commands and and merge this function with\n@@ -106,7 +107,7 @@ def execute(argv=None):\n         argv = sys.argv\n     crawler = CrawlerProcess(settings)\n     crawler.install()\n-    inproject = bool(settings.settings_module)\n+    inproject = inside_project()\n     _check_deprecated_scrapy_ctl(argv, inproject) # TODO: remove for Scrapy 0.11\n     cmds = _get_commands_dict(inproject)\n     cmdname = _pop_command_name(argv)\n\n@@ -1,4 +1,8 @@\n+import os\n+\n from scrapy.command import ScrapyCommand\n+from scrapy.utils.misc import load_object\n+from scrapy.conf import settings\n \n class Command(ScrapyCommand):\n \n@@ -9,4 +13,6 @@ class Command(ScrapyCommand):\n         return \"List available spiders\"\n \n     def run(self, args, opts):\n-        print \"\\n\".join(self.crawler.spiders.list())\n+        spman_cls = load_object(settings['SPIDER_MANAGER_CLASS'])\n+        spiders = spman_cls.from_settings(settings)\n+        print os.linesep.join(spiders.list())\n\n@@ -166,13 +166,11 @@ class ExecutionEngine(object):\n             exc = _failure.value\n             if isinstance(exc, IgnoreRequest):\n                 errmsg = _failure.getErrorMessage()\n-                level = exc.level\n             else:\n                 errmsg = str(_failure)\n-                level = log.ERROR\n             if errmsg:\n                 log.msg(\"Error downloading <%s>: %s\" % (request.url, errmsg), \\\n-                    level=level, spider=spider)\n+                    level=log.ERROR, spider=spider)\n             return Failure(IgnoreRequest(str(exc)))\n \n         def _on_complete(_):\n\n@@ -5,8 +5,6 @@ These exceptions are documented in docs/topics/exceptions.rst. Please don't add\n new exceptions here without documenting them there.\n \"\"\"\n \n-from scrapy import log\n-\n # Internal\n \n class NotConfigured(Exception):\n@@ -18,13 +16,6 @@ class NotConfigured(Exception):\n class IgnoreRequest(Exception):\n     \"\"\"Indicates a decision was made not to process a request\"\"\"\n \n-    def __init__(self, msg='', level=log.ERROR):\n-        self.msg = msg\n-        self.level = level\n-\n-    def __str__(self):\n-        return self.msg\n-\n class DontCloseSpider(Exception):\n     \"\"\"Request the spider not to be closed yet\"\"\"\n     pass\n\n@@ -34,7 +34,8 @@ class MiddlewareManager(object):\n                 middlewares.append(mw)\n             except NotConfigured, e:\n                 if e.args:\n-                    log.msg(e)\n+                    clsname = clspath.split('.')[-1]\n+                    log.msg(\"Disabled %s: %s\" % (clsname, e.args[0]), log.WARNING)\n         enabled = [x.__class__.__name__ for x in middlewares]\n         log.msg(\"Enabled %ss: %s\" % (cls.component_name, \", \".join(enabled)), \\\n             level=log.DEBUG)\n\n@@ -4,6 +4,7 @@ import warnings\n \n from scrapy.utils.conf import closest_scrapy_cfg, get_config\n from scrapy.utils.python import is_writable\n+from scrapy.exceptions import NotConfigured\n \n DATADIR_CFG_SECTION = 'datadir'\n \n@@ -20,12 +21,16 @@ def inside_project():\n \n def project_data_dir(project='default'):\n     \"\"\"Return the current project data dir, creating it if it doesn't exist\"\"\"\n-    assert inside_project(), \"Not inside project\"\n-    scrapy_cfg = closest_scrapy_cfg()\n-    d = abspath(join(dirname(scrapy_cfg), '.scrapy'))\n+    if not inside_project():\n+        raise NotConfigured(\"Not inside a project\")\n     cfg = get_config()\n     if cfg.has_option(DATADIR_CFG_SECTION, project):\n         d = cfg.get(DATADIR_CFG_SECTION, project)\n+    else:\n+        scrapy_cfg = closest_scrapy_cfg()\n+        if not scrapy_cfg:\n+            raise NotConfigured(\"Unable to find scrapy.cfg file to infer project data dir\")\n+        d = abspath(join(dirname(scrapy_cfg), '.scrapy'))\n     if not exists(d):\n         makedirs(d)\n     return d\n@@ -47,7 +52,11 @@ def sqlite_db(path, nonwritable_fallback=True):\n     if not inside_project() or path == ':memory:':\n         db = ':memory:'\n     else:\n+        try:\n             db = data_path(path)\n+        except NotConfigured:\n+            db = ':memory:'\n+        else:\n             if not is_writable(db) and nonwritable_fallback:\n                 warnings.warn(\"%r is not writable - using in-memory SQLite instead\" % db)\n                 db = ':memory:'\n\n@@ -1,3 +1,6 @@\n+from __future__ import with_statement\n+\n+import sys\n import os\n import shutil\n import tempfile\n@@ -22,6 +25,7 @@ def project_environment(project):\n     else:\n         eggpath = None\n     try:\n+        assert 'scrapy.conf' not in sys.modules, \"Scrapy settings already loaded\"\n         yield\n     finally:\n         if eggpath:\n\n@@ -0,0 +1,22 @@\n+import sys\n+import unittest\n+\n+class SettingsSafeModulesTest(unittest.TestCase):\n+\n+    # these modules must not load scrapy.conf\n+    SETTINGS_SAFE_MODULES = [\n+        'scrapy.utils.project',\n+        'scrapy.utils.conf',\n+        'scrapyd.interfaces',\n+        'scrapyd.eggutils',\n+    ]\n+\n+    def test_modules_that_shouldnt_load_settings(self):\n+        sys.modules.pop('scrapy.conf', None)\n+        for m in self.SETTINGS_SAFE_MODULES:\n+            __import__(m)\n+            assert 'scrapy.conf' not in sys.modules, \\\n+                \"Module %r must not cause the scrapy.conf module to be loaded\" % m\n+\n+if __name__ == \"__main__\":\n+    unittest.main()\n\n@@ -25,7 +25,7 @@ class UtilsTest(unittest.TestCase):\n class GetSpiderListTest(unittest.TestCase):\n \n     def test_get_spider_list(self):\n-        path = self.mktemp()\n+        path = os.path.abspath(self.mktemp())\n         j = os.path.join\n         eggs_dir = j(path, 'eggs')\n         os.makedirs(eggs_dir)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#0aac226b42d49a6e6158fddb3c116941be994eae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 18 | Churn Cumulative: 517 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,6 +30,7 @@ class Shell(object):\n         self.item_class = load_object(crawler.settings['DEFAULT_ITEM_CLASS'])\n         self.inthread = inthread\n         self.code = code\n+        self.vars = {}\n \n     def start(self, *a, **kw):\n         # disable accidental Ctrl-C key press from shutting down the engine\n@@ -77,18 +78,15 @@ class Shell(object):\n         self.populate_vars(url, response, request, spider)\n \n     def populate_vars(self, url=None, response=None, request=None, spider=None):\n-        item = self.item_class()\n-        self.vars = {}\n-        self.vars['item'] = item\n+        self.vars['item'] = self.item_class()\n         self.vars['settings'] = self.crawler.settings\n-        if url:\n-            if isinstance(response, XmlResponse):\n-                self.vars['xxs'] = XmlXPathSelector(response)\n-            if isinstance(response, HtmlResponse):\n-                self.vars['hxs'] = HtmlXPathSelector(response)\n-            self.vars['response'] = response\n-            self.vars['request'] = request\n         self.vars['spider'] = spider\n+        self.vars['request'] = request\n+        self.vars['response'] = response\n+        self.vars['xxs'] = XmlXPathSelector(response) \\\n+            if isinstance(response, XmlResponse) else None\n+        self.vars['hxs'] = HtmlXPathSelector(response) \\\n+            if isinstance(response, HtmlResponse) else None\n         if self.inthread:\n             self.vars['fetch'] = self.fetch\n         self.vars['view'] = open_in_browser\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#09f084c220a4a624ac26e968bbdcca326f59099b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 523 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -47,7 +47,7 @@ class Shell(object):\n             self.fetch(request, spider)\n         elif response:\n             request = response.request\n-            self.populate_vars(request.url, response, request, spider)\n+            self.populate_vars(response, request, spider)\n         else:\n             self.populate_vars()\n         if self.code:\n@@ -75,9 +75,9 @@ class Shell(object):\n         response = None\n         response, spider = threads.blockingCallFromThread(reactor, \\\n             self._schedule, request, spider)\n-        self.populate_vars(url, response, request, spider)\n+        self.populate_vars(response, request, spider)\n \n-    def populate_vars(self, url=None, response=None, request=None, spider=None):\n+    def populate_vars(self, response=None, request=None, spider=None):\n         self.vars['item'] = self.item_class()\n         self.vars['settings'] = self.crawler.settings\n         self.vars['spider'] = spider\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#32adbea545e4c4780f7c3545c093a7fb93433a3b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 30 | Churn Cumulative: 849 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -80,8 +80,8 @@ class HtmlTag(HtmlDataFragment):\n     def __repr__(self):\n         return str(self)\n \n-_ATTR = \"((?:[^=/>\\s]|/(?!>))+)(?:\\s*=(?:\\s*\\\"(.*?)\\\"|\\s*'(.*?)'|([^>\\s]+))?)?\"\n-_TAG = \"<(\\/?)(\\w+(?::\\w+)?)((?:\\s+\" + _ATTR + \")+\\s*|\\s*)(\\/?)>?\"\n+_ATTR = \"((?:[^=/<>\\s]|/(?!>))+)(?:\\s*=(?:\\s*\\\"(.*?)\\\"|\\s*'(.*?)'|([^>\\s]+))?)?\"\n+_TAG = \"<(\\/?)(\\w+(?::\\w+)?)((?:\\s*\" + _ATTR + \")+\\s*|\\s*)(\\/?)>?\"\n _DOCTYPE = r\"<!DOCTYPE.*?>\"\n _SCRIPT = \"(<script.*?>)(.*?)(</script.*?>)\"\n _COMMENT = \"(<!--.*?-->)\"\n\n@@ -147,3 +147,9 @@ class TestParseHtml(TestCase):\n         \"\"\"Test parsing of some malformed cases\"\"\"\n         parsed = [_decode_element(d) for d in PARSED8]\n         self._test_sample(PAGE8, parsed)\n+\n+    def test_malformed2(self):\n+        \"\"\"Test case when attributes are not separated by space (still recognizable because of quotes)\"\"\"\n+        parsed = [_decode_element(d) for d in PARSED9]\n+        self._test_sample(PAGE9, parsed)\n+\n\n@@ -255,3 +255,23 @@ PARSED8 = [\n    {'attributes' : {}, 'end': 103, 'start': 98, 'tag': u'td', 'tag_type': 2},\n    {'attributes' : {u'width': u'5'}, 'end': 120, 'start': 103, 'tag': u'table', 'tag_type': 1}\n ]\n+\n+PAGE9 = u\"\"\"\\\n+<html>\\\n+<body>\\\n+<img width='230' height='150'src='/images/9589.jpg' >\\\n+<a href=\"/product/9589\">Click here</a>\\\n+</body>\\\n+</html>\\\n+\"\"\"\n+\n+PARSED9 = [\n+    {'attributes' : {}, 'end': 6, 'start': 0, 'tag': 'html', 'tag_type': 1},\n+    {'attributes' : {}, 'end': 12, 'start': 6, 'tag': 'body', 'tag_type': 1},\n+    {'attributes' : {'width': '230', 'height': '150', 'src': '/images/9589.jpg'}, 'end': 65, 'start': 12, 'tag': 'img', 'tag_type': 1},\n+    {'attributes' : {'href': '/product/9589'}, 'end': 89, 'start': 65, 'tag': 'a', 'tag_type': 1},\n+    {'end': 99, 'start': 89},\n+    {'attributes' : {}, 'end': 103, 'start': 99, 'tag': 'a', 'tag_type': 2},\n+    {'attributes' : {}, 'end': 110, 'start': 103, 'tag': 'body', 'tag_type': 2},\n+    {'attributes' : {}, 'end': 117, 'start': 110, 'tag': 'html', 'tag_type': 2},\n+]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#c5351d2f4882e423828e747b528179d5b1486f7e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 3 | Churn Cumulative: 7 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -19,6 +19,9 @@ class Link(object):\n     def __eq__(self, other):\n         return self.url == other.url and self.text == other.text\n     \n+    def __hash__(self):\n+        return hash(self.url) ^ hash(self.text)\n+\n     def __repr__(self):\n         return '<Link url=%r text=%r >' % (self.url, self.text)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#632bc27deb6e2425f25a3c909a2d80ea4c5df0c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 28 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -30/0 | Churn Δ: 28 | Churn Cumulative: 41 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,28 @@\n+import unittest\n+\n+from scrapy.link import Link\n+\n+class LinkTest(unittest.TestCase):\n+\n+    def test_eq_and_hash(self):\n+        l1 = Link(\"http://www.example.com\")\n+        l2 = Link(\"http://www.example.com/other\")\n+        l3 = Link(\"http://www.example.com\")\n+\n+        self.assertEqual(l1, l1)\n+        self.assertEqual(hash(l1), hash(l1))\n+        self.assertNotEqual(l1, l2)\n+        self.assertNotEqual(hash(l1), hash(l2))\n+        self.assertEqual(l1, l3)\n+        self.assertEqual(hash(l1), hash(l3))\n+\n+        l4 = Link(\"http://www.example.com\", text=\"test\")\n+        l5 = Link(\"http://www.example.com\", text=\"test2\")\n+        l6 = Link(\"http://www.example.com\", text=\"test\")\n+\n+        self.assertEqual(l4, l4)\n+        self.assertEqual(hash(l4), hash(l4))\n+        self.assertNotEqual(l4, l5)\n+        self.assertNotEqual(hash(l4), hash(l5))\n+        self.assertEqual(l4, l6)\n+        self.assertEqual(hash(l4), hash(l6))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#65fc2fbd1f0c84ee56c53c0862ea2af625f7b3e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 109 | Contributors (this commit): 1 | Commits (past 90d): 12 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,6 +30,7 @@ class Environment(object):\n         dbpath = os.path.join(self.dbs_dir, '%s.db' % project)\n         env['SCRAPY_SQLITE_DB'] = dbpath\n         env['SCRAPY_LOG_FILE'] = self._get_log_file(message)\n+        env['SCRAPY_CONCURRENT_SPIDERS'] = '1' # scrapyd runs one spider per process\n         return env\n \n     def _get_log_file(self, message):\n\n@@ -29,6 +29,7 @@ class EnvironmentTest(unittest.TestCase):\n         self.assertEqual(env['SCRAPY_SLOT'], '3')\n         self.assertEqual(env['SCRAPY_SPIDER'], 'myspider')\n         self.assertEqual(env['SCRAPY_JOB'], 'ID')\n+        self.assertEqual(env['SCRAPY_CONCURRENT_SPIDERS'], '1')\n         self.assert_(env['SCRAPY_SQLITE_DB'].endswith('mybot.db'))\n         self.assert_(env['SCRAPY_LOG_FILE'].endswith('/mybot/myspider/ID.log'))\n         self.failIf('SCRAPY_SETTINGS_MODULE' in env)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#bfc6c3809b538ac72b5b677234ebcaacfd1190db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 37 | Churn Cumulative: 211 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,14 +2,19 @@ from scrapy.http import Response\n from scrapy.selector import XmlXPathSelector\n \n \n-def xmliter_lxml(obj, nodename):\n+def xmliter_lxml(obj, nodename, namespace=None):\n     from lxml import etree\n     reader = _StreamReader(obj)\n-    iterable = etree.iterparse(reader, tag=nodename, encoding=reader.encoding)\n+    tag = '{%s}%s' % (namespace, nodename) if namespace else nodename\n+    iterable = etree.iterparse(reader, tag=tag, encoding=reader.encoding)\n     for _, node in iterable:\n         nodetext = etree.tostring(node)\n         node.clear()\n-        yield XmlXPathSelector(text=nodetext).select('//' + nodename)[0]\n+        xs = XmlXPathSelector(text=nodetext)\n+        if namespace:\n+            xs.register_namespace('x', namespace)\n+            nodename = 'x:%s' % nodename\n+        yield xs.select('//' + nodename)[0]\n \n \n class _StreamReader(object):\n\n@@ -97,6 +97,32 @@ class LxmlXmliterTestCase(XmliterTestCase):\n     except ImportError:\n         skip = \"lxml not available\"\n \n+    def test_xmliter_iterate_namespace(self):\n+        body = \"\"\"\\\n+            <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+            <rss version=\"2.0\" xmlns=\"http://base.google.com/ns/1.0\">\n+                <channel>\n+                <title>My Dummy Company</title>\n+                <link>http://www.mydummycompany.com</link>\n+                <description>This is a dummy company. We do nothing.</description>\n+                <item>\n+                    <title>Item 1</title>\n+                    <description>This is item 1</description>\n+                    <link>http://www.mydummycompany.com/items/1</link>\n+                    <image_link>http://www.mydummycompany.com/images/item1.jpg</image_link>\n+                </item>\n+                </channel>\n+            </rss>\n+        \"\"\"\n+        response = XmlResponse(url='http://mydummycompany.com', body=body)\n+\n+        no_namespace_iter = self.xmliter(response, 'image_link')\n+        self.assertEqual(len(list(no_namespace_iter)), 0)\n+\n+        namespace_iter = self.xmliter(response, 'image_link', 'http://base.google.com/ns/1.0')\n+        node = namespace_iter.next()\n+        self.assertEqual(node.select('text()').extract(), ['http://www.mydummycompany.com/images/item1.jpg'])\n+\n \n class UtilsCsvTestCase(unittest.TestCase):\n     sample_feeds_dir = os.path.join(os.path.abspath(os.path.dirname(__file__)), 'sample_data', 'feeds')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#ce8137b7382df81d92b08823a6dfdb6442af2f59", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 6 | Files Changed: 5 | Hunks: 9 | Methods Changed: 9 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 724 | Contributors (this commit): 5 | Commits (past 90d): 7 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -33,7 +33,7 @@ class LxmlLinkExtractor(object):\n         for link in links:\n             link.url = urljoin_rfc(base_url, link.url, response_encoding)\n             link.url = safe_url_string(link.url, response_encoding)\n-            link.text = str_to_unicode(link.text, response_encoding)\n+            link.text = str_to_unicode(link.text, response_encoding, errors='replace')\n             ret.append(link)\n \n         return ret\n\n@@ -33,7 +33,7 @@ class BaseSgmlLinkExtractor(FixedSGMLParser):\n         for link in self.links:\n             link.url = urljoin_rfc(base_url, link.url, response_encoding)\n             link.url = safe_url_string(link.url, response_encoding)\n-            link.text = str_to_unicode(link.text, response_encoding)\n+            link.text = str_to_unicode(link.text, response_encoding, errors='replace')\n             ret.append(link)\n \n         return ret\n\n@@ -51,6 +51,13 @@ class LinkExtractorTestCase(unittest.TestCase):\n         self.assertEqual(lx.extract_links(response),\n                          [Link(url='https://noschemedomain.com/path/to/item/12.html', text='Item 12')])\n \n+    def test_link_text_wrong_encoding(self):\n+        html = \"\"\"<body><p><a href=\"item/12.html\">Wrong: \\xed</a></p></body></html>\"\"\"\n+        response = HtmlResponse(\"http://www.example.com\", body=html, encoding='utf-8')\n+        lx = BaseSgmlLinkExtractor()\n+        self.assertEqual(lx.extract_links(response),\n+             [Link(url='http://www.example.com/item/12.html', text=u'Wrong: \\ufffd')])\n+\n     def test_extraction_encoding(self):\n         body = get_testdata('link_extractor', 'linkextractor_noenc.html')\n         response_utf8 = HtmlResponse(url='http://example.com/utf8', body=body, headers={'Content-Type': ['text/html; charset=utf-8']})\n\n@@ -22,6 +22,9 @@ class UtilsPythonTestCase(unittest.TestCase):\n         # converting a strange object should raise TypeError\n         self.assertRaises(TypeError, str_to_unicode, 423)\n \n+        # check errors argument works\n+        self.assertEqual(str_to_unicode('a\\xedb', 'utf-8', errors='replace'), u'a\\ufffdb')\n+\n     def test_unicode_to_str(self):\n         # converting a unicode object to an utf-8 encoded string\n         self.assertEqual(unicode_to_str(u'\\xa3 49'), '\\xc2\\xa3 49')\n@@ -35,6 +38,9 @@ class UtilsPythonTestCase(unittest.TestCase):\n         # converting a strange object should raise TypeError\n         self.assertRaises(TypeError, unicode_to_str, unittest)\n \n+        # check errors argument works\n+        (str_to_unicode('a\\xedb', 'latin-', errors='replace'), u'a?b')\n+\n     def test_memoizemethod_noargs(self):\n         class A(object):\n \n\n@@ -63,7 +63,7 @@ def unique(list_, key=lambda x: x):\n     return result\n \n \n-def str_to_unicode(text, encoding=None):\n+def str_to_unicode(text, encoding=None, errors='strict'):\n     \"\"\"Return the unicode representation of text in the given encoding. Unlike\n     .encode(encoding) this function can be applied directly to a unicode\n     object without the risk of double-decoding problems (which can happen if\n@@ -73,13 +73,13 @@ def str_to_unicode(text, encoding=None):\n     if encoding is None:\n         encoding = 'utf-8'\n     if isinstance(text, str):\n-        return text.decode(encoding)\n+        return text.decode(encoding, errors)\n     elif isinstance(text, unicode):\n         return text\n     else:\n         raise TypeError('str_to_unicode must receive a str or unicode object, got %s' % type(text).__name__)\n \n-def unicode_to_str(text, encoding=None):\n+def unicode_to_str(text, encoding=None, errors='strict'):\n     \"\"\"Return the str representation of text in the given encoding. Unlike\n     .encode(encoding) this function can be applied directly to a str\n     object without the risk of double-decoding problems (which can happen if\n@@ -89,7 +89,7 @@ def unicode_to_str(text, encoding=None):\n     if encoding is None:\n         encoding = 'utf-8'\n     if isinstance(text, unicode):\n-        return text.encode(encoding)\n+        return text.encode(encoding, errors)\n     elif isinstance(text, str):\n         return text\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#3dc677725e7672a4e069111c19df4b3acdcd1f52", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 127 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -23,7 +23,7 @@ class UtilsPythonTestCase(unittest.TestCase):\n         self.assertRaises(TypeError, str_to_unicode, 423)\n \n         # check errors argument works\n-        self.assertEqual(str_to_unicode('a\\xedb', 'utf-8', errors='replace'), u'a\\ufffdb')\n+        assert u'\\ufffd' in str_to_unicode('a\\xedb', 'utf-8', errors='replace')\n \n     def test_unicode_to_str(self):\n         # converting a unicode object to an utf-8 encoded string\n@@ -39,7 +39,7 @@ class UtilsPythonTestCase(unittest.TestCase):\n         self.assertRaises(TypeError, unicode_to_str, unittest)\n \n         # check errors argument works\n-        (str_to_unicode('a\\xedb', 'latin-', errors='replace'), u'a?b')\n+        assert '?' in unicode_to_str(u'a\\ufffdb', 'latin-1', errors='replace')\n \n     def test_memoizemethod_noargs(self):\n         class A(object):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#9b07b0ab0a218998191ec9b8537cdf0aea0455a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 218 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,14 +7,14 @@ def xmliter_lxml(obj, nodename, namespace=None):\n     reader = _StreamReader(obj)\n     tag = '{%s}%s' % (namespace, nodename) if namespace else nodename\n     iterable = etree.iterparse(reader, tag=tag, encoding=reader.encoding)\n+    selxpath = '//' + ('x:%s' % nodename if namespace else nodename)\n     for _, node in iterable:\n         nodetext = etree.tostring(node)\n         node.clear()\n         xs = XmlXPathSelector(text=nodetext)\n         if namespace:\n             xs.register_namespace('x', namespace)\n-            nodename = 'x:%s' % nodename\n-        yield xs.select('//' + nodename)[0]\n+        yield xs.select(selxpath)[0]\n \n \n class _StreamReader(object):\n\n@@ -110,6 +110,7 @@ class LxmlXmliterTestCase(XmliterTestCase):\n                     <description>This is item 1</description>\n                     <link>http://www.mydummycompany.com/items/1</link>\n                     <image_link>http://www.mydummycompany.com/images/item1.jpg</image_link>\n+                    <image_link>http://www.mydummycompany.com/images/item2.jpg</image_link>\n                 </item>\n                 </channel>\n             </rss>\n@@ -122,6 +123,8 @@ class LxmlXmliterTestCase(XmliterTestCase):\n         namespace_iter = self.xmliter(response, 'image_link', 'http://base.google.com/ns/1.0')\n         node = namespace_iter.next()\n         self.assertEqual(node.select('text()').extract(), ['http://www.mydummycompany.com/images/item1.jpg'])\n+        node = namespace_iter.next()\n+        self.assertEqual(node.select('text()').extract(), ['http://www.mydummycompany.com/images/item2.jpg'])\n \n \n class UtilsCsvTestCase(unittest.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a1c3fa5dd827e1f842e4270cadeec35539f09e38", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 162 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -132,6 +132,10 @@ def image_url(txt):\n         ['http://s7d5.scene7.com/is/image/wasserstrom/165133?wid=227&hei=227&defaultImage=noimage_wasserstrom']\n \n     \"\"\"\n+    imgurl = extract_image_url(txt)\n+    return [safe_url_string(remove_entities(url(imgurl)))] if imgurl else None\n+\n+def extract_image_url(txt):\n     txt = url(txt)\n     imgurl = None\n     if txt:\n@@ -153,4 +157,4 @@ def image_url(txt):\n             imgurl = urlparse.urlunparse(parsed)\n         if not imgurl:\n             imgurl = txt\n-    return [safe_url_string(remove_entities(url(imgurl)))] if imgurl else None\n+    return imgurl\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#74413ff989036edc5e4b1dd1b68182345ddd8e69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1519 | Contributors (this commit): 5 | Commits (past 90d): 2 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -130,10 +130,10 @@ class ExecutionEngine(object):\n         return len(self.downloader.sites) < self.downloader.concurrent_spiders\n \n     def crawl(self, request, spider):\n-        assert spider in self.open_spiders, \\\n-            \"Spider %r not opened when crawling: %s\" % (spider.name, request)\n         if spider in self.closing: # ignore requests for spiders being closed\n             return\n+        assert spider in self.open_spiders, \\\n+            \"Spider %r not opened when crawling: %s\" % (spider.name, request)\n         schd = mustbe_deferred(self.schedule, request, spider)\n         # FIXME: we can't log errors because we would be preventing them from\n         # propagating to the request errback. This should be fixed after the\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#fe9febe2b10d787e00c7e48c0966f27082e82d6d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 12 | Churn Cumulative: 309 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -57,6 +57,8 @@ class Command(ScrapyCommand):\n             help=\"list available projects on TARGET\")\n         parser.add_option(\"--egg\", metavar=\"FILE\",\n             help=\"use the given egg, instead of building it\")\n+        parser.add_option(\"--build-egg\", metavar=\"FILE\",\n+            help=\"only build the egg, don't deploy it\")\n \n     def run(self, args, opts):\n         try:\n@@ -75,11 +77,18 @@ class Command(ScrapyCommand):\n             projects = json.loads(f.read())['projects']\n             print os.linesep.join(projects)\n             return\n+\n+        tmpdir = None\n+\n+        if opts.build_egg: # build egg only\n+            egg, tmpdir = _build_egg()\n+            _log(\"Writing egg to %s\" % opts.build_egg)\n+            shutil.copyfile(egg, opts.build_egg)\n+        else: # buld egg and deploy\n             target_name = _get_target_name(args)\n             target = _get_target(target_name)\n             project = _get_project(target, opts)\n             version = _get_version(target, opts)\n-        tmpdir = None\n             if opts.egg:\n                 _log(\"Using egg: %s\" % opts.egg)\n                 egg = opts.egg\n@@ -87,6 +96,7 @@ class Command(ScrapyCommand):\n                 _log(\"Building egg of %s-%s\" % (project, version))\n                 egg, tmpdir = _build_egg()\n             _upload_egg(target, egg, project, version)\n+\n         if tmpdir:\n             shutil.rmtree(tmpdir)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#32fa2add753306fd20da483c01532ac080488f14", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 697 | Contributors (this commit): 3 | Commits (past 90d): 2 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -75,7 +75,7 @@ class BasicTypeExtractor(object):\n         u'<div data-scrapy-annotate=\"{&quot;annotations&quot;: {&quot;content&quot;: &quot;name&quot;}}\">x<b> xx</b></div>',\\\n         u'<div>a name<b> id-9</b></div>')\n     >>> ex = BasicTypeExtractor(template.annotations[0])\n-    >>> ex.extract(page, 0, 3, [LabelledRegion(*(1,2))])\n+    >>> ex.extract(page, 0, 3, [LabelledRegion(1, 2)])\n     [(u'name', u'a name')]\n     \"\"\"\n \n@@ -395,7 +395,7 @@ class RecordExtractor(object):\n                     s, p, e = similar_region(page.page_tokens, self.template_tokens, \\\n                               i, start, sindex)\n                     if s > 0:\n-                        similar_ignored_regions.append(LabelledRegion(*(p, e)))\n+                        similar_ignored_regions.append(LabelledRegion(p, e))\n                         start = e or start\n                 extracted_data = first_region.extract(page, pindex, sindex, similar_ignored_regions)\n                 if extracted_data:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5cae22b665c250935d7a0c3fdd0e583beff08500", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 18 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,18 +10,19 @@ class Link(object):\n     At the moment, it contains just the url and link text.\n     \"\"\"\n \n-    __slots__ = ['url', 'text']\n+    __slots__ = ['url', 'text', 'nofollow']\n \n-    def __init__(self, url, text=''):\n+    def __init__(self, url, text='', nofollow=False):\n         self.url = url\n         self.text = text\n+        self.nofollow = nofollow\n \n     def __eq__(self, other):\n-        return self.url == other.url and self.text == other.text\n+        return self.url == other.url and self.text == other.text and self.nofollow == other.nofollow\n    \n     def __hash__(self):\n-        return hash(self.url) ^ hash(self.text)\n+        return hash(self.url) ^ hash(self.text) ^ hash(self.nofollow)\n \n     def __repr__(self):\n-        return '<Link url=%r text=%r >' % (self.url, self.text)\n+        return 'Link(url=%r, text=%r, nofollow=%r)' % (self.url, self.text, self.nofollow)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#36431a14390a8e3b4d96a41904f2670c01afa359", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 181 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -11,7 +11,8 @@ class SqliteDict(DictMixin):\n     def __init__(self, database=None, table=\"dict\"):\n         self.database = database or ':memory:'\n         self.table = table\n-        self.conn = sqlite3.connect(self.database)\n+        # about check_same_thread: http://twistedmatrix.com/trac/ticket/4040\n+        self.conn = sqlite3.connect(self.database, check_same_thread=False)\n         q = \"create table if not exists %s (key text primary key, value blob)\" \\\n             % table\n         self.conn.execute(q)\n@@ -91,7 +92,8 @@ class SqlitePriorityQueue(object):\n     def __init__(self, database=None, table=\"queue\"):\n         self.database = database or ':memory:'\n         self.table = table\n-        self.conn = sqlite3.connect(self.database)\n+        # about check_same_thread: http://twistedmatrix.com/trac/ticket/4040\n+        self.conn = sqlite3.connect(self.database, check_same_thread=False)\n         q = \"create table if not exists %s (id integer primary key, \" \\\n             \"priority real key, message blob)\" % table\n         self.conn.execute(q)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#47a7f154abf66c6e51cc3517c6a95aac004af5a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 10 | Churn Cumulative: 310 | Contributors (this commit): 2 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -87,3 +87,12 @@ class DeleteVersion(DeleteProject):\n         self._delete_version(project, version)\n         return {\"status\": \"ok\"}\n \n+class ListJobs(WsResource):\n+    def render_POST(self, txrequest):\n+        project = txrequest.args['project'][0]\n+        spiders = self.root.launcher.processes.values()\n+        jlist = list()\n+        for s in spiders:\n+            if project == s.project:\n+                jlist.append({\"job\": {\"id\":s.job, \"spider\": s.spider}})\n+        return {\"status\":\"ok\", \"jobs\": jlist}\n\n@@ -22,6 +22,7 @@ class Root(resource.Resource):\n         self.putChild('listspiders.json', webservice.ListSpiders(self))\n         self.putChild('delproject.json', webservice.DeleteProject(self))\n         self.putChild('delversion.json', webservice.DeleteVersion(self))\n+        self.putChild('listjobs.json', webservice.ListJobs(self))\n         self.putChild('logs', static.File(logsdir, 'text/plain'))\n         self.putChild('procmon', ProcessMonitor(self))\n         self.update_projects()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
