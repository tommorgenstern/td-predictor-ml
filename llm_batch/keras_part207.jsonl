{"custom_id": "keras#b36c982934334f3bde7187d3a3a25aafa8f60ece", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 9545 | Contributors (this commit): 77 | Commits (past 90d): 9 | Contributors (cumulative): 77 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1037,6 +1037,7 @@ class Sequential(Model):\n                       max_queue_size=10,\n                       workers=1,\n                       use_multiprocessing=False,\n+                      shuffle=False,\n                       initial_epoch=0):\n         \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n \n@@ -1086,6 +1087,9 @@ class Sequential(Model):\n                 non picklable arguments to the generator\n                 as they can't be passed\n                 easily to children processes.\n+            shuffle: Whether to shuffle the data at the beginning of each\n+                epoch. Only used with instances of `Sequence` (\n+                keras.utils.Sequence).\n             initial_epoch: Epoch at which to start training\n                 (useful for resuming a previous training run).\n \n@@ -1126,6 +1130,7 @@ class Sequential(Model):\n                                         max_queue_size=max_queue_size,\n                                         workers=workers,\n                                         use_multiprocessing=use_multiprocessing,\n+                                        shuffle=shuffle,\n                                         initial_epoch=initial_epoch)\n \n     @interfaces.legacy_generator_methods_support\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#130809e645e56d551250aef95c74f6f0f9463381", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 33 | Churn Cumulative: 255 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -129,8 +129,12 @@ encoder_states = [state_h, state_c]\n \n # Set up the decoder, using `encoder_states` as initial state.\n decoder_inputs = Input(shape=(None, num_decoder_tokens))\n-decoder_lstm = LSTM(latent_dim, return_sequences=True)\n-decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n+# We set up our decoder to return full output sequences,\n+# and to return internal states as well. We don't use the\n+# return states in the training model, but we will use them in inference.\n+decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n+decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n+                                     initial_state=encoder_states)\n decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n decoder_outputs = decoder_dense(decoder_outputs)\n \n@@ -153,20 +157,21 @@ model.save('s2s.h5')\n # 2) run one step of decoder with this initial state\n # and a \"start of sequence\" token as target.\n # Output will be the next target token\n-# 3) Append the target token and repeat\n+# 3) Repeat with the current target token and current states\n \n # Define sampling models\n encoder_model = Model(encoder_inputs, encoder_states)\n \n decoder_state_input_h = Input(shape=(latent_dim,))\n decoder_state_input_c = Input(shape=(latent_dim,))\n-decoder_states = [decoder_state_input_h, decoder_state_input_c]\n-decoder_outputs = decoder_lstm(decoder_inputs,\n-                               initial_state=decoder_states)\n+decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n+decoder_outputs, state_h, state_c = decoder_lstm(\n+    decoder_inputs, initial_state=decoder_states_inputs)\n+decoder_states = [state_h, state_c]\n decoder_outputs = decoder_dense(decoder_outputs)\n decoder_model = Model(\n-    [decoder_inputs] + decoder_states,\n-    decoder_outputs)\n+    [decoder_inputs] + decoder_states_inputs,\n+    [decoder_outputs] + decoder_states)\n \n # Reverse-lookup token index to decode sequences back to\n # something readable.\n@@ -190,7 +195,8 @@ def decode_sequence(input_seq):\n     stop_condition = False\n     decoded_sentence = ''\n     while not stop_condition:\n-        output_tokens = decoder_model.predict([target_seq] + states_value)\n+        output_tokens, h, c = decoder_model.predict(\n+            [target_seq] + states_value)\n \n         # Sample a token\n         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n@@ -203,11 +209,12 @@ def decode_sequence(input_seq):\n            len(decoded_sentence) > max_decoder_seq_length):\n             stop_condition = True\n \n-        # Add the sampled character to the sequence\n-        char_vector = np.zeros((1, 1, num_decoder_tokens))\n-        char_vector[0, 0, sampled_token_index] = 1.\n+        # Update the target sequence (of length 1).\n+        target_seq = np.zeros((1, 1, num_decoder_tokens))\n+        target_seq[0, 0, sampled_token_index] = 1.\n \n-        target_seq = np.concatenate([target_seq, char_vector], axis=1)\n+        # Update states\n+        states_value = [h, c]\n \n     return decoded_sentence\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#081d218311cf6c61792159f523ad2dfc2bdb8df9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1149 | Contributors (this commit): 17 | Commits (past 90d): 1 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -234,6 +234,7 @@ PAGES = [\n         'page': 'layers/merge.md',\n         'classes': [\n             layers.Add,\n+            layers.Subtract,\n             layers.Multiply,\n             layers.Average,\n             layers.Maximum,\n@@ -242,6 +243,7 @@ PAGES = [\n         ],\n         'functions': [\n             layers.add,\n+            layers.subtract,\n             layers.multiply,\n             layers.average,\n             layers.maximum,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#213ec198dc7fae17b86d3d4e37dee3559761abd0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 18 | Churn Cumulative: 1053 | Contributors (this commit): 21 | Commits (past 90d): 2 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -24,12 +24,28 @@ def print_summary(model, line_length=None, positions=None, print_fn=print):\n         sequential_like = True\n     else:\n         sequential_like = True\n-        for v in model.nodes_by_depth.values():\n+        nodes_by_depth = model.nodes_by_depth.values()\n+        nodes = []\n+        for v in nodes_by_depth:\n             if (len(v) > 1) or (len(v) == 1 and len(v[0].inbound_layers) > 1):\n                 # if the model has multiple nodes or if the nodes have multiple inbound_layers\n                 # the model is no longer sequential\n                 sequential_like = False\n                 break\n+            nodes += v\n+        if sequential_like:\n+            # search for shared layers\n+            for layer in model.layers:\n+                flag = False\n+                for node in layer.inbound_nodes:\n+                    if node in nodes:\n+                        if flag:\n+                            sequential_like = False\n+                            break\n+                        else:\n+                            flag = True\n+                if not sequential_like:\n+                    break\n \n     if sequential_like:\n         line_length = line_length or 65\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a9f551a7a532c744dcb0fa90699ca3262d10bc0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 286 | Contributors (this commit): 9 | Commits (past 90d): 3 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -76,8 +76,13 @@ def compute_accuracy(predictions, labels):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n     preds = predictions.ravel() < 0.5\n-    return ((preds & labels).sum() +\n-            (np.logical_not(preds) & np.logical_not(labels)).sum()) / float(labels.size)\n+    return np.mean(preds == labels)\n+\n+\n+def accuracy(y_true, y_pred):\n+    '''Compute classification accuracy with a fixed threshold on distances.\n+    '''\n+    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n \n \n # the data, shuffled and split between train and test sets\n@@ -117,7 +122,7 @@ model = Model([input_a, input_b], distance)\n \n # train\n rms = RMSprop()\n-model.compile(loss=contrastive_loss, optimizer=rms)\n+model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n           batch_size=128,\n           epochs=epochs,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ab5700962a74500aef0c6838580d285dbbb359c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 108 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 14 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 114 | Churn Cumulative: 9697 | Contributors (this commit): 58 | Commits (past 90d): 8 | Contributors (cumulative): 62 | DMM Complexity: 0.0\n\nDIFF:\n@@ -204,10 +204,15 @@ PAGES = [\n     {\n         'page': 'layers/recurrent.md',\n         'classes': [\n-            recurrent.Recurrent,\n+            recurrent.RNN,\n             recurrent.SimpleRNN,\n             recurrent.GRU,\n             recurrent.LSTM,\n+            layers.ConvLSTM2D,\n+            recurrent.SimpleRNNCell,\n+            recurrent.GRUCell,\n+            recurrent.LSTMCell,\n+            recurrent.StackedRNNCells,\n         ],\n     },\n     {\n\n@@ -21,8 +21,23 @@ from ..legacy import interfaces\n class StackedRNNCells(Layer):\n     \"\"\"Wrapper allowing a stack of RNN cells to behave as a single cell.\n \n-    # Arguments:\n+    Used to implement efficient stacked RNNs.\n+\n+    # Arguments\n         cells: List of RNN cell instances.\n+\n+    # Examples\n+\n+    ```python\n+        cells = [\n+            keras.layers.LSTMCell(output_dim),\n+            keras.layers.LSTMCell(output_dim),\n+            keras.layers.LSTMCell(output_dim),\n+        ]\n+\n+        inputs = keras.Input((timesteps, input_dim))\n+        x = keras.layers.RNN(cells)(inputs)\n+    ```\n     \"\"\"\n \n     def __init__(self, cells, **kwargs):\n@@ -214,7 +229,8 @@ class RNN(Layer):\n             although it tends to be more memory-intensive.\n             Unrolling is only suitable for short sequences.\n         input_dim: dimensionality of the input (integer).\n-            This argument (or alternatively, the keyword argument `input_shape`)\n+            This argument (or alternatively,\n+            the keyword argument `input_shape`)\n             is required when using this layer as the first layer in a model.\n         input_length: Length of input sequences, to be specified\n             when it is constant.\n@@ -844,6 +860,22 @@ class SimpleRNN(RNN):\n         recurrent_dropout: Float between 0 and 1.\n             Fraction of the units to drop for\n             the linear transformation of the recurrent state.\n+        return_sequences: Boolean. Whether to return the last output.\n+            in the output sequence, or the full sequence.\n+        return_state: Boolean. Whether to return the last state\n+            in addition to the output.\n+        go_backwards: Boolean (default False).\n+            If True, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If True, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If True, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n     \"\"\"\n \n     @interfaces.legacy_recurrent_support\n@@ -862,6 +894,11 @@ class SimpleRNN(RNN):\n                  bias_constraint=None,\n                  dropout=0.,\n                  recurrent_dropout=0.,\n+                 return_sequences=False,\n+                 return_state=False,\n+                 go_backwards=False,\n+                 stateful=False,\n+                 unroll=False,\n                  **kwargs):\n         if 'implementation' in kwargs:\n             kwargs.pop('implementation')\n@@ -893,7 +930,13 @@ class SimpleRNN(RNN):\n                              bias_constraint=bias_constraint,\n                              dropout=dropout,\n                              recurrent_dropout=recurrent_dropout)\n-        super(SimpleRNN, self).__init__(cell, **kwargs)\n+        super(SimpleRNN, self).__init__(cell,\n+                                        return_sequences=return_sequences,\n+                                        return_state=return_state,\n+                                        go_backwards=go_backwards,\n+                                        stateful=stateful,\n+                                        unroll=unroll,\n+                                        **kwargs)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n@@ -1270,6 +1313,22 @@ class GRU(RNN):\n             Fraction of the units to drop for\n             the linear transformation of the recurrent state.\n         implementation: Implementation mode, either 1 or 2.\n+        return_sequences: Boolean. Whether to return the last output.\n+            in the output sequence, or the full sequence.\n+        return_state: Boolean. Whether to return the last state\n+            in addition to the output.\n+        go_backwards: Boolean (default False).\n+            If True, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If True, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If True, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n \n     # References\n         - [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)\n@@ -1295,6 +1354,11 @@ class GRU(RNN):\n                  dropout=0.,\n                  recurrent_dropout=0.,\n                  implementation=1,\n+                 return_sequences=False,\n+                 return_state=False,\n+                 go_backwards=False,\n+                 stateful=False,\n+                 unroll=False,\n                  **kwargs):\n         if implementation == 0:\n             warnings.warn('`implementation=0` has been deprecated, '\n@@ -1327,7 +1391,13 @@ class GRU(RNN):\n                        dropout=dropout,\n                        recurrent_dropout=recurrent_dropout,\n                        implementation=implementation)\n-        super(GRU, self).__init__(cell, **kwargs)\n+        super(GRU, self).__init__(cell,\n+                                  return_sequences=return_sequences,\n+                                  return_state=return_state,\n+                                  go_backwards=go_backwards,\n+                                  stateful=stateful,\n+                                  unroll=unroll,\n+                                  **kwargs)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n@@ -1736,6 +1806,22 @@ class LSTM(RNN):\n             Fraction of the units to drop for\n             the linear transformation of the recurrent state.\n         implementation: Implementation mode, either 1 or 2.\n+        return_sequences: Boolean. Whether to return the last output.\n+            in the output sequence, or the full sequence.\n+        return_state: Boolean. Whether to return the last state\n+            in addition to the output.\n+        go_backwards: Boolean (default False).\n+            If True, process the input sequence backwards and return the\n+            reversed sequence.\n+        stateful: Boolean (default False). If True, the last state\n+            for each sample at index i in a batch will be used as initial\n+            state for the sample of index i in the following batch.\n+        unroll: Boolean (default False).\n+            If True, the network will be unrolled,\n+            else a symbolic loop will be used.\n+            Unrolling can speed-up a RNN,\n+            although it tends to be more memory-intensive.\n+            Unrolling is only suitable for short sequences.\n \n     # References\n         - [Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf) (original 1997 paper)\n@@ -1763,6 +1849,11 @@ class LSTM(RNN):\n                  dropout=0.,\n                  recurrent_dropout=0.,\n                  implementation=1,\n+                 return_sequences=False,\n+                 return_state=False,\n+                 go_backwards=False,\n+                 stateful=False,\n+                 unroll=False,\n                  **kwargs):\n         if implementation == 0:\n             warnings.warn('`implementation=0` has been deprecated, '\n@@ -1796,7 +1887,13 @@ class LSTM(RNN):\n                         dropout=dropout,\n                         recurrent_dropout=recurrent_dropout,\n                         implementation=implementation)\n-        super(LSTM, self).__init__(cell, **kwargs)\n+        super(LSTM, self).__init__(cell,\n+                                   return_sequences=return_sequences,\n+                                   return_state=return_state,\n+                                   go_backwards=go_backwards,\n+                                   stateful=stateful,\n+                                   unroll=unroll,\n+                                   **kwargs)\n         self.activity_regularizer = regularizers.get(activity_regularizer)\n \n     def call(self, inputs, mask=None, training=None, initial_state=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#19e1be2cf2592dcdb1650afc00bad9e08fa07954", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 44 | Lines Deleted: 12 | Files Changed: 2 | Hunks: 15 | Methods Changed: 11 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 56 | Churn Cumulative: 1273 | Contributors (this commit): 10 | Commits (past 90d): 9 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -364,18 +364,35 @@ class Sequence(object):\n         \"\"\"\n         pass\n \n+# Global variables to be shared across processes\n+_SHARED_SEQUENCE = None\n+_MANAGER = multiprocessing.Manager()\n+_SHARED_DICT = _MANAGER.dict()\n \n-def get_index(ds, i):\n-    \"\"\"Quick fix for Python2, otherwise, it cannot be pickled.\n+\n+def get_index(i):\n+    \"\"\"Get the value from the Sequence at index `i`.\n \n     # Arguments\n-        ds: a Sequence object\n         i: index\n \n     # Returns\n         The value at index `i`.\n     \"\"\"\n-    return ds[i]\n+    global _SHARED_SEQUENCE\n+    return _SHARED_SEQUENCE[i]\n+\n+\n+def _update_sequence(seq):\n+    \"\"\"Update current process with a new Sequence.\n+\n+    # Arguments\n+        seq: Sequence object\n+    \"\"\"\n+    global _SHARED_SEQUENCE, _SHARED_DICT\n+    if not multiprocessing.current_process().pid in _SHARED_DICT:\n+        _SHARED_SEQUENCE = seq\n+        _SHARED_DICT[multiprocessing.current_process().pid] = 0\n \n \n class SequenceEnqueuer(object):\n@@ -477,6 +494,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n             self.executor = multiprocessing.Pool(workers)\n         else:\n             self.executor = ThreadPool(workers)\n+        self.workers = workers\n         self.queue = queue.Queue(max_queue_size)\n         self.stop_signal = threading.Event()\n         self.run_thread = threading.Thread(target=self._run)\n@@ -486,6 +504,7 @@ class OrderedEnqueuer(SequenceEnqueuer):\n     def _run(self):\n         \"\"\"Function to submit request to the executor and queue the `Future` objects.\"\"\"\n         sequence = list(range(len(self.sequence)))\n+        self._send_sequence()  # Share the initial sequence\n         while True:\n             if self.shuffle:\n                 random.shuffle(sequence)\n@@ -493,10 +512,10 @@ class OrderedEnqueuer(SequenceEnqueuer):\n                 if self.stop_signal.is_set():\n                     return\n                 self.queue.put(\n-                    self.executor.apply_async(get_index,\n-                                              (self.sequence, i)), block=True)\n+                    self.executor.apply_async(get_index, (i,)), block=True)\n             # Call the internal on epoch end.\n             self.sequence.on_epoch_end()\n+            self._send_sequence()  # Update the pool\n \n     def get(self):\n         \"\"\"Creates a generator to extract data from the queue.\n@@ -516,6 +535,19 @@ class OrderedEnqueuer(SequenceEnqueuer):\n             self.stop()\n             raise StopIteration(e)\n \n+    def _send_sequence(self):\n+        \"\"\"Send current Sequence to all workers.\"\"\"\n+        global _SHARED_SEQUENCE\n+        _SHARED_SEQUENCE = self.sequence  # For new processes that may spawn\n+        if not self.use_multiprocessing:\n+            # Threads are from the same process so they already share the sequence.\n+            return\n+        _SHARED_DICT.clear()\n+        while len(_SHARED_DICT) < self.workers and not self.stop_signal.is_set():\n+            # Ask the pool to update till everyone is updated.\n+            self.executor.apply(_update_sequence, args=(self.sequence,))\n+        # We're done with the update\n+\n     def stop(self, timeout=None):\n         \"\"\"Stops running threads and wait for them to exit, if necessary.\n \n\n@@ -111,7 +111,7 @@ def threadsafe_generator(f):\n     return g\n \n \n-class TestSequence(Sequence):\n+class DummySequence(Sequence):\n     def __init__(self, shape):\n         self.shape = shape\n \n@@ -149,7 +149,7 @@ def create_generator_from_sequence_pcs(ds):\n \n def test_generator_enqueuer_threads():\n     enqueuer = GeneratorEnqueuer(create_generator_from_sequence_threads(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=False)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -166,7 +166,7 @@ def test_generator_enqueuer_threads():\n \n def test_generator_enqueuer_processes():\n     enqueuer = GeneratorEnqueuer(create_generator_from_sequence_pcs(\n-        TestSequence([3, 200, 200, 3])), use_multiprocessing=True)\n+        DummySequence([3, 200, 200, 3])), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -195,7 +195,7 @@ def test_generator_enqueuer_fail_processes():\n \n \n def test_ordered_enqueuer_threads():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=False)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=False)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n@@ -206,7 +206,7 @@ def test_ordered_enqueuer_threads():\n \n \n def test_ordered_enqueuer_threads_not_ordered():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]),\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]),\n                                use_multiprocessing=False,\n                                shuffle=True)\n     enqueuer.start(3, 10)\n@@ -219,7 +219,7 @@ def test_ordered_enqueuer_threads_not_ordered():\n \n \n def test_ordered_enqueuer_processes():\n-    enqueuer = OrderedEnqueuer(TestSequence([3, 200, 200, 3]), use_multiprocessing=True)\n+    enqueuer = OrderedEnqueuer(DummySequence([3, 200, 200, 3]), use_multiprocessing=True)\n     enqueuer.start(3, 10)\n     gen_output = enqueuer.get()\n     acc = []\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#40fd9ca3c877d2e29a2cf077902d61f38aa161f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 22 | Files Changed: 5 | Hunks: 21 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 46 | Churn Cumulative: 1404 | Contributors (this commit): 17 | Commits (past 90d): 12 | Contributors (cumulative): 31 | DMM Complexity: None\n\nDIFF:\n@@ -88,7 +88,7 @@ model.add(layers.Dropout(0.1))\n model.add(layers.Dense(256))\n model.add(Antirectifier())\n model.add(layers.Dropout(0.1))\n-model.add(layers.Dense(10))\n+model.add(layers.Dense(num_classes))\n model.add(layers.Activation('softmax'))\n \n # compile the model\n\n@@ -46,6 +46,8 @@ np.random.seed(1337)\n \n K.set_image_data_format('channels_first')\n \n+num_classes = 10\n+\n \n def build_generator(latent_size):\n     # we will map a pair of (z, L), where z is a latent vector and L is a\n@@ -79,8 +81,7 @@ def build_generator(latent_size):\n     # this will be our label\n     image_class = Input(shape=(1,), dtype='int32')\n \n-    # 10 classes in MNIST\n-    cls = Flatten()(Embedding(10, latent_size,\n+    cls = Flatten()(Embedding(num_classes, latent_size,\n                               embeddings_initializer='glorot_normal')(image_class))\n \n     # hadamard product between z-space and a class conditional embedding\n@@ -124,7 +125,7 @@ def build_discriminator():\n     # (name=auxiliary) is the class that the discriminator thinks the image\n     # belongs to.\n     fake = Dense(1, activation='sigmoid', name='generation')(features)\n-    aux = Dense(10, activation='softmax', name='auxiliary')(features)\n+    aux = Dense(num_classes, activation='softmax', name='auxiliary')(features)\n \n     return Model(image, [fake, aux])\n \n@@ -200,7 +201,7 @@ if __name__ == '__main__':\n             label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n \n             # sample some labels from p_c\n-            sampled_labels = np.random.randint(0, 10, batch_size)\n+            sampled_labels = np.random.randint(0, num_classes, batch_size)\n \n             # generate a batch of fake images, using the generated labels as a\n             # conditioner. We reshape the sampled labels to be\n@@ -220,7 +221,7 @@ if __name__ == '__main__':\n             # the generator optimize over an identical number of images as the\n             # discriminator\n             noise = np.random.uniform(-1, 1, (2 * batch_size, latent_size))\n-            sampled_labels = np.random.randint(0, 10, 2 * batch_size)\n+            sampled_labels = np.random.randint(0, num_classes, 2 * batch_size)\n \n             # we want to train the generator to trick the discriminator\n             # For the generator, we want all the {fake, not-fake} labels to say\n@@ -239,7 +240,7 @@ if __name__ == '__main__':\n         noise = np.random.uniform(-1, 1, (num_test, latent_size))\n \n         # sample some labels from p_c and generate images from them\n-        sampled_labels = np.random.randint(0, 10, num_test)\n+        sampled_labels = np.random.randint(0, num_classes, num_test)\n         generated_images = generator.predict(\n             [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n \n@@ -255,7 +256,7 @@ if __name__ == '__main__':\n \n         # make new noise\n         noise = np.random.uniform(-1, 1, (2 * num_test, latent_size))\n-        sampled_labels = np.random.randint(0, 10, 2 * num_test)\n+        sampled_labels = np.random.randint(0, num_classes, 2 * num_test)\n \n         trick = np.ones(2 * num_test)\n \n@@ -296,7 +297,7 @@ if __name__ == '__main__':\n         noise = np.random.uniform(-1, 1, (100, latent_size))\n \n         sampled_labels = np.array([\n-            [i] * 10 for i in range(10)\n+            [i] * num_classes for i in range(num_classes)\n         ]).reshape(-1, 1)\n \n         # get a batch to display\n@@ -305,7 +306,7 @@ if __name__ == '__main__':\n \n         # arrange them into a grid\n         img = (np.concatenate([r.reshape(-1, 28)\n-                               for r in np.split(generated_images, 10)\n+                               for r in np.split(generated_images, num_classes)\n                                ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n \n         Image.fromarray(img).save(\n\n@@ -13,7 +13,6 @@ from keras.models import Sequential\n from keras.layers import Dense, Dropout\n from keras.optimizers import RMSprop\n \n-\n batch_size = 128\n num_classes = 10\n epochs = 20\n@@ -39,7 +38,7 @@ model.add(Dense(512, activation='relu', input_shape=(784,)))\n model.add(Dropout(0.2))\n model.add(Dense(512, activation='relu'))\n model.add(Dropout(0.2))\n-model.add(Dense(10, activation='softmax'))\n+model.add(Dense(num_classes, activation='softmax'))\n \n model.summary()\n \n\n@@ -21,6 +21,8 @@ from keras.layers import Dense, Dropout, Input, Lambda\n from keras.optimizers import RMSprop\n from keras import backend as K\n \n+num_classes = 10\n+\n \n def euclidean_distance(vects):\n     x, y = vects\n@@ -47,13 +49,13 @@ def create_pairs(x, digit_indices):\n     '''\n     pairs = []\n     labels = []\n-    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n-    for d in range(10):\n+    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n+    for d in range(num_classes):\n         for i in range(n):\n             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n             pairs += [[x[z1], x[z2]]]\n-            inc = random.randrange(1, 10)\n-            dn = (d + inc) % 10\n+            inc = random.randrange(1, num_classes)\n+            dn = (d + inc) % num_classes\n             z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n             pairs += [[x[z1], x[z2]]]\n             labels += [1, 0]\n@@ -97,10 +99,10 @@ input_dim = 784\n epochs = 20\n \n # create training+test positive and negative pairs\n-digit_indices = [np.where(y_train == i)[0] for i in range(10)]\n+digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n \n-digit_indices = [np.where(y_test == i)[0] for i in range(10)]\n+digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n te_pairs, te_y = create_pairs(x_test, digit_indices)\n \n # network definition\n\n@@ -61,7 +61,7 @@ def cnn_layers(x_train_input):\n     x = layers.Flatten()(x)\n     x = layers.Dense(512, activation='relu')(x)\n     x = layers.Dropout(0.5)(x)\n-    x_train_out = layers.Dense(classes,\n+    x_train_out = layers.Dense(num_classes,\n                                activation='softmax',\n                                name='x_train_out')(x)\n     return x_train_out\n@@ -72,7 +72,7 @@ batch_size = 128\n batch_shape = (batch_size, 28, 28, 1)\n steps_per_epoch = 469\n epochs = 5\n-classes = 10\n+num_classes = 10\n \n # The capacity variable controls the maximum queue size\n # allowed when prefetching data for training.\n@@ -106,7 +106,7 @@ x_train_batch = tf.cast(x_train_batch, tf.float32)\n x_train_batch = tf.reshape(x_train_batch, shape=batch_shape)\n \n y_train_batch = tf.cast(y_train_batch, tf.int32)\n-y_train_batch = tf.one_hot(y_train_batch, classes)\n+y_train_batch = tf.one_hot(y_train_batch, num_classes)\n \n x_batch_shape = x_train_batch.get_shape().as_list()\n y_batch_shape = y_train_batch.get_shape().as_list()\n@@ -153,5 +153,5 @@ test_model.summary()\n \n loss, acc = test_model.evaluate(x_test,\n                                 keras.utils.to_categorical(y_test),\n-                                classes)\n+                                num_classes)\n print('\\nTest accuracy: {0}'.format(acc))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfd800ad38132b924af2421008acda970823bb8a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 314 | Contributors (this commit): 9 | Commits (past 90d): 5 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -74,11 +74,11 @@ def create_base_network(input_dim):\n     return seq\n \n \n-def compute_accuracy(predictions, labels):\n+def compute_accuracy(y_true, y_pred):\n     '''Compute classification accuracy with a fixed threshold on distances.\n     '''\n-    preds = predictions.ravel() < 0.5\n-    return np.mean(preds == labels)\n+    pred = y_pred.ravel() < 0.5\n+    return np.mean(pred == y_true)\n \n \n def accuracy(y_true, y_pred):\n@@ -131,10 +131,10 @@ model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n \n # compute final accuracy on training and test sets\n-pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n-tr_acc = compute_accuracy(pred, tr_y)\n-pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n-te_acc = compute_accuracy(pred, te_y)\n+y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n+tr_acc = compute_accuracy(tr_y, y_pred)\n+y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n+te_acc = compute_accuracy(te_y, y_pred)\n \n print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#80dcdcd88d9ca6f93695de0d16e4ce3ff2c094a7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 11/11 | Churn Δ: 99 | Churn Cumulative: 8677 | Contributors (this commit): 91 | Commits (past 90d): 26 | Contributors (cumulative): 91 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,4 +1,5 @@\n import tensorflow as tf\n+from tensorflow.python.client import device_lib\n from tensorflow.python.training import moving_averages\n from tensorflow.python.ops import tensor_array_ops\n from tensorflow.python.ops import control_flow_ops\n@@ -44,6 +45,13 @@ _GRAPH_UID_DICTS = {}\n # Change its value via `manual_variable_initialization(value)`.\n _MANUAL_VAR_INIT = False\n \n+# This map is for converting the keras data format string to that of TF.\n+_DATA_FORMAT_MAP = {'channels_first': 'NCHW', 'channels_last': 'NHWC'}\n+\n+# This list queries the devices.\n+# We assume our devices don't change during our lifetime.\n+_LOCAL_DEVICES = device_lib.list_local_devices()\n+\n \n def get_uid(prefix=''):\n     \"\"\"Get the uid for the default graph.\n@@ -193,6 +201,75 @@ def set_session(session):\n     _SESSION = session\n \n \n+# DEVICE MANIPULATION AND PROBING\n+\n+class _TfDeviceCaptureOp(object):\n+    \"\"\"Class for capturing the TF device scope.\"\"\"\n+\n+    def __init__(self):\n+        self.device = None\n+\n+    def _set_device(self, device):\n+        \"\"\"This method captures TF's explicit device scope setting.\"\"\"\n+        self.device = device\n+\n+\n+def _get_current_tf_device():\n+    \"\"\"Return explicit device of current context, otherwise returns `None`.\n+\n+    # Returns\n+        If the current device scope is explicitly set, it returns a string with\n+        the device (`CPU` or `GPU`). If the scope is not explicitly set, it will\n+        return `None`.\n+    \"\"\"\n+    g = tf.get_default_graph()\n+    op = _TfDeviceCaptureOp()\n+    g._apply_device_functions(op)\n+    return op.device\n+\n+\n+def _is_current_explicit_device(device_type):\n+    \"\"\"Check if the current device is explicitly set on the device type specified.\n+\n+    # Arguments\n+        device_type: A string containing `GPU` or `CPU` (case-insensitive).\n+\n+    # Returns\n+        A boolean indicating if the current device scope is explicitly set on the device type.\n+\n+    # Raises\n+        ValueError: If the `device_type` string indicates an unsupported device.\n+    \"\"\"\n+    device_type = device_type.upper()\n+    if device_type not in ['CPU', 'GPU']:\n+        raise ValueError('device_type should be either \"CPU\" or \"GPU\".')\n+    device = _get_current_tf_device()\n+    return (device is not None and device.device_type == device_type.upper())\n+\n+\n+def _get_available_gpus():\n+    \"\"\"Get a list of available gpu devices (formatted as strings).\n+\n+    # Returns\n+        A list of available GPU devices.\n+    \"\"\"\n+    return [x.name for x in _LOCAL_DEVICES if x.device_type == 'GPU']\n+\n+\n+def _has_nchw_support():\n+    \"\"\"Check whether the current scope supports NCHW ops.\n+\n+    Tensorflow does not support NCHW on CPU. Therefore we check if we are not explicitly put on\n+    CPU, and have GPUs available. In this case there will be soft-placing on the GPU device.\n+\n+    # Returns\n+        bool: if the current scope device placement would support nchw\n+    \"\"\"\n+    explicitly_on_cpu = _is_current_explicit_device('CPU')\n+    gpus_available = len(_get_available_gpus()) > 0\n+    return (not explicitly_on_cpu and gpus_available)\n+\n+\n # VARIABLE MANIPULATION\n \n def _to_tensor(x, dtype):\n@@ -3174,13 +3251,17 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n-    if data_format not in {'channels_first', 'channels_last'}:\n+    if data_format not in _DATA_FORMAT_MAP:\n         raise ValueError('Unknown data_format ' + str(data_format))\n \n-    # With 4d inputs, tf.nn.convolution only supports\n-    # data_format NHWC, so we transpose the inputs\n-    # in case we are in data_format channels_first.\n-    x = _preprocess_conv2d_input(x, data_format)\n+    tf_data_format = _DATA_FORMAT_MAP[data_format]\n+\n+    nhwc_roundtrip = not _has_nchw_support() and tf_data_format == 'NCHW'\n+\n+    if nhwc_roundtrip:\n+        tf_data_format = 'NHWC'\n+        x = tf.transpose(x, (0, 2, 3, 1))  # NCHW -> NHWC\n+\n     padding = _preprocess_padding(padding)\n     x = tf.nn.convolution(\n         input=x,\n@@ -3188,8 +3269,12 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n         dilation_rate=dilation_rate,\n         strides=strides,\n         padding=padding,\n-        data_format='NHWC')\n-    return _postprocess_conv2d_output(x, data_format)\n+        data_format=tf_data_format)\n+\n+    if nhwc_roundtrip:\n+        x = tf.transpose(x, (0, 3, 1, 2))  # NCHW -> NHWC\n+\n+    return x\n \n \n def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4743df7f8051d63a65fb98804966cc47834e1440", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 5413 | Contributors (this commit): 63 | Commits (past 90d): 16 | Contributors (cumulative): 63 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1249,7 +1249,7 @@ class Model(Container):\n                 for i, batch_out in enumerate(batch_outs):\n                     unconcatenated_outs[i].append(batch_out)\n                 if verbose == 1:\n-                    progbar.update(step)\n+                    progbar.update(step + 1)\n             if len(unconcatenated_outs) == 1:\n                 return np.concatenate(unconcatenated_outs[0], axis=0)\n             return [np.concatenate(unconcatenated_outs[i], axis=0)\n@@ -1304,9 +1304,12 @@ class Model(Container):\n                                               steps,\n                                               'steps')\n         outs = []\n-        if steps is not None:\n         if verbose == 1:\n+            if steps is not None:\n                 progbar = Progbar(target=steps)\n+            else:\n+                progbar = Progbar(target=num_samples)\n+        if steps is not None:\n             for step in range(steps):\n                 batch_outs = f(ins)\n                 if isinstance(batch_outs, list):\n@@ -1320,12 +1323,10 @@ class Model(Container):\n                         outs.append(0.)\n                     outs[0] += batch_outs\n                 if verbose == 1:\n-                    progbar.update(step)\n+                    progbar.update(step + 1)\n             for i in range(len(outs)):\n                 outs[i] /= steps\n         else:\n-            if verbose == 1:\n-                progbar = Progbar(target=num_samples)\n             batches = _make_batches(num_samples, batch_size)\n             index_array = np.arange(num_samples)\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fb6cb8c7baf29ed83d2e5522ca1881096446aae3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9547 | Contributors (this commit): 78 | Commits (past 90d): 9 | Contributors (cumulative): 78 | DMM Complexity: None\n\nDIFF:\n@@ -1037,7 +1037,7 @@ class Sequential(Model):\n                       max_queue_size=10,\n                       workers=1,\n                       use_multiprocessing=False,\n-                      shuffle=False,\n+                      shuffle=True,\n                       initial_epoch=0):\n         \"\"\"Fits the model on data generated batch-by-batch by a Python generator.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#306689c52a9674637f30b2319f90c6c0cbe770ff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 31 | Files Changed: 1 | Hunks: 25 | Methods Changed: 12 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 71 | Churn Cumulative: 879 | Contributors (this commit): 11 | Commits (past 90d): 4 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,3 +1,4 @@\n+# -*- coding: utf-8 -*-\n '''This example uses a convolutional stack followed by a recurrent stack\n and a CTC logloss function to perform optical character recognition\n of generated text images. I have no evidence of whether it actually\n@@ -33,6 +34,7 @@ https://github.com/mbhenry/\n '''\n import os\n import itertools\n+import codecs\n import re\n import datetime\n import cairocffi as cairo\n@@ -55,6 +57,10 @@ import keras.callbacks\n \n OUTPUT_DIR = 'image_ocr'\n \n+# character classes and matching regex filter\n+regex = r'^[a-z ]+$'\n+alphabet = u'abcdefghijklmnopqrstuvwxyz '\n+\n np.random.seed(55)\n \n \n@@ -76,7 +82,7 @@ def speckle(img):\n # and a random amount of speckle noise\n \n def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n-    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, width=w, height=h)\n+    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n     with cairo.Context(surface) as context:\n         context.set_source_rgb(1, 1, 1)  # White\n         context.paint()\n@@ -141,22 +147,31 @@ def shuffle_mats_or_lists(matrix_list, stop_ind=None):\n     return ret\n \n \n-def text_to_labels(text, num_classes):\n+# Translation of characters to unique integer values\n+def text_to_labels(text):\n     ret = []\n     for char in text:\n-        if char >= 'a' and char <= 'z':\n-            ret.append(ord(char) - ord('a'))\n-        elif char == ' ':\n-            ret.append(26)\n+        ret.append(alphabet.find(char))\n     return ret\n \n \n+# Reverse translation of numerical classes back to characters\n+def labels_to_text(labels):\n+    ret = []\n+    for c in labels:\n+        if c == len(alphabet):  # CTC Blank\n+            ret.append(\"\")\n+        else:\n+            ret.append(alphabet[c])\n+    return \"\".join(ret)\n+\n+\n # only a-z and space..probably not to difficult\n # to expand to uppercase and symbols\n \n def is_valid_str(in_str):\n-    search = re.compile(r'[^a-z\\ ]').search\n-    return not bool(search(in_str))\n+    search = re.compile(regex, re.UNICODE).search\n+    return bool(search(in_str))\n \n \n # Uses generator functions to supply train/test with\n@@ -180,7 +195,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n         self.absolute_max_string_len = absolute_max_string_len\n \n     def get_output_size(self):\n-        return 28\n+        return len(alphabet) + 1\n \n     # num_words can be independent of the epoch size due to the use of generators\n     # as max_string_len grows, num_words can grow\n@@ -197,7 +212,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n         self.Y_len = [0] * self.num_words\n \n         # monogram file is sorted by frequency in english speech\n-        with open(self.monogram_file, 'rt') as f:\n+        with codecs.open(self.monogram_file, mode='rt', encoding='utf-8') as f:\n             for line in f:\n                 if len(tmp_string_list) == int(self.num_words * mono_fraction):\n                     break\n@@ -206,7 +221,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n                     tmp_string_list.append(word)\n \n         # bigram file contains common word pairings in english speech\n-        with open(self.bigram_file, 'rt') as f:\n+        with codecs.open(self.bigram_file, mode='rt', encoding='utf-8') as f:\n             lines = f.readlines()\n             for line in lines:\n                 if len(tmp_string_list) == self.num_words:\n@@ -224,7 +239,7 @@ class TextImageGenerator(keras.callbacks.Callback):\n \n         for i, word in enumerate(self.string_list):\n             self.Y_len[i] = len(word)\n-            self.Y_data[i, 0:len(word)] = text_to_labels(word, self.get_output_size())\n+            self.Y_data[i, 0:len(word)] = text_to_labels(word)\n             self.X_text.append(word)\n         self.Y_len = np.expand_dims(np.array(self.Y_len), 1)\n \n@@ -237,9 +252,9 @@ class TextImageGenerator(keras.callbacks.Callback):\n         # width and height are backwards from typical Keras convention\n         # because width is the time dimension when it gets fed into the RNN\n         if K.image_data_format() == 'channels_first':\n-            X_data = np.ones([size, 1, self.img_h, self.img_w])\n+            X_data = np.ones([size, 1, self.img_w, self.img_h])\n         else:\n-            X_data = np.ones([size, self.img_h, self.img_w, 1])\n+            X_data = np.ones([size, self.img_w, self.img_h, 1])\n \n         labels = np.ones([size, self.absolute_max_string_len])\n         input_length = np.zeros([size, 1])\n@@ -250,18 +265,18 @@ class TextImageGenerator(keras.callbacks.Callback):\n             # achieving translational invariance\n             if train and i > size - 4:\n                 if K.image_data_format() == 'channels_first':\n-                    X_data[i, 0, 0:self.img_h, :] = self.paint_func('')[0, :, :]\n+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func('')[0, :, :].T\n                 else:\n-                    X_data[i, 0:self.img_h, :, 0] = self.paint_func('',)[0, :, :]\n+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func('',)[0, :, :].T\n                 labels[i, 0] = self.blank_label\n                 input_length[i] = self.img_w // self.downsample_factor - 2\n                 label_length[i] = 1\n                 source_str.append('')\n             else:\n                 if K.image_data_format() == 'channels_first':\n-                    X_data[i, 0, 0:self.img_h, :] = self.paint_func(self.X_text[index + i])[0, :, :]\n+                    X_data[i, 0, 0:self.img_w, :] = self.paint_func(self.X_text[index + i])[0, :, :].T\n                 else:\n-                    X_data[i, 0:self.img_h, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :]\n+                    X_data[i, 0:self.img_w, :, 0] = self.paint_func(self.X_text[index + i])[0, :, :].T\n                 labels[i, :] = self.Y_data[index + i]\n                 input_length[i] = self.img_w // self.downsample_factor - 2\n                 label_length[i] = self.Y_len[index + i]\n@@ -300,10 +315,10 @@ class TextImageGenerator(keras.callbacks.Callback):\n \n     def on_epoch_begin(self, epoch, logs={}):\n         # rebind the paint function to implement curriculum learning\n-        if epoch >= 3 and epoch < 6:\n+        if 3 <= epoch < 6:\n             self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n                                                       rotate=False, ud=True, multi_fonts=False)\n-        elif epoch >= 6 and epoch < 9:\n+        elif 6 <= epoch < 9:\n             self.paint_func = lambda text: paint_text(text, self.img_w, self.img_h,\n                                                       rotate=False, ud=True, multi_fonts=True)\n         elif epoch >= 9:\n@@ -333,13 +348,7 @@ def decode_batch(test_func, word_batch):\n     for j in range(out.shape[0]):\n         out_best = list(np.argmax(out[j, 2:], 1))\n         out_best = [k for k, g in itertools.groupby(out_best)]\n-        # 26 is space, 27 is CTC blank char\n-        outstr = ''\n-        for c in out_best:\n-            if c >= 0 and c < 26:\n-                outstr += chr(c + ord('a'))\n-            elif c == 26:\n-                outstr += ' '\n+        outstr = labels_to_text(out_best)\n         ret.append(outstr)\n     return ret\n \n@@ -388,7 +397,7 @@ class VizCallback(keras.callbacks.Callback):\n                 the_input = word_batch['the_input'][i, 0, :, :]\n             else:\n                 the_input = word_batch['the_input'][i, :, :, 0]\n-            pylab.imshow(the_input, cmap='Greys_r')\n+            pylab.imshow(the_input.T, cmap='Greys_r')\n             pylab.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n         fig = pylab.gcf()\n         fig.set_size_inches(10, 13)\n@@ -412,9 +421,9 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n     minibatch_size = 32\n \n     if K.image_data_format() == 'channels_first':\n-        input_shape = (1, img_h, img_w)\n+        input_shape = (1, img_w, img_h)\n     else:\n-        input_shape = (img_h, img_w, 1)\n+        input_shape = (img_w, img_h, 1)\n \n     fdir = os.path.dirname(get_file('wordlists.tgz',\n                                     origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n@@ -438,7 +447,7 @@ def train(run_name, start_epoch, stop_epoch, img_w):\n                    name='conv2')(inner)\n     inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n \n-    conv_to_rnn_dims = ((img_h // (pool_size ** 2)) * conv_filters, img_w // (pool_size ** 2))\n+    conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n     inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n \n     # cuts down input size going into RNN:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
