{"custom_id": "keras#705694a8707e22ad68b9a3676d76ebdc62b9c2aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 417 | Contributors (this commit): 5 | Commits (past 90d): 16 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -71,5 +71,5 @@ def activity_l1l2(l1=0.01, l2=0.01):\n identity = Regularizer\n \n from .utils.generic_utils import get_from_module\n-def get(identifier):\n-    return get_from_module(identifier, globals(), 'regularizer', instantiate=True)\n+def get(identifier, kwargs=None):\n+    return get_from_module(identifier, globals(), 'regularizer', instantiate=True, kwargs=kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#200a0062620800d955f89c78ac95c143497bdc09", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 6 | Churn Cumulative: 70 | Contributors (this commit): 6 | Commits (past 90d): 12 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -4,13 +4,15 @@ import time\n import sys\n import six\n \n-def get_from_module(identifier, module_params, module_name, instantiate=False):\n+def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):\n     if isinstance(identifier, six.string_types):\n         res = module_params.get(identifier)\n         if not res:\n             raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))\n-        if instantiate:\n+        if instantiate and not kwargs:\n             return res()\n+        elif instantiate and kwargs:\n+            return res(**kwargs)\n         else:\n             return res\n     return identifier\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#af845d55a4752b9936fc0a5312d049a8cfdc695f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 81 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 19/19 | Churn Δ: 81 | Churn Cumulative: 81 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 0.03333333333333333\n\nDIFF:\n@@ -0,0 +1,81 @@\n+import inspect\n+import numpy as np\n+\n+from ..layers.advanced_activations import LeakyReLU, PReLU\n+from ..layers.core import Dense, Merge, Dropout, Activation, Reshape, Flatten, RepeatVector, Layer\n+from ..layers.core import ActivityRegularization, TimeDistributedDense, AutoEncoder, MaxoutDense\n+from ..layers.embeddings import Embedding, WordContextProduct\n+from ..layers.noise import GaussianNoise, GaussianDropout\n+from ..layers.normalization import BatchNormalization\n+from ..layers.recurrent import SimpleRNN, SimpleDeepRNN, GRU, LSTM, JZS1, JZS2, JZS3\n+from ..layers import containers\n+\n+from .. import regularizers\n+from .. import constraints\n+\n+\n+def from_yaml(layer_dict):\n+    name = layer_dict.get('name')\n+    hasParams = False\n+    if name == 'Merge':\n+        mode = layer_dict.get('mode')\n+        layers = layer_dict.get('layers')\n+        layer_list = []\n+        for layer in layers:\n+            init_layer = from_yaml(layer)\n+            layer_list.append(init_layer)\n+        merge_layer = Merge(layer_list, mode)\n+        return merge_layer\n+    elif name == 'Sequential':\n+        layers = layer_dict.get('layers')\n+        layer_list = []\n+        for layer in layers:\n+            init_layer = from_yaml(layer)\n+            layer_list.append(init_layer)\n+        seq_layer = containers.Sequential(layer_list)\n+        return seq_layer\n+    elif name == 'Graph':\n+        graph_layer = containers.Graph()\n+        inputs = layer_dict.get('inputs')\n+        for input in inputs:\n+            graph_layer.add_input(**input)\n+        nodes = layer_dict.get('nodes')\n+        for node in nodes:\n+            layer_conf = node.get('layer')\n+            layer = from_yaml(layer_conf)\n+            node['layer'] = layer\n+            graph_layer.add_node(**node)\n+        outputs = layer_dict.get('outputs')\n+        for output in outputs:\n+            graph_layer.add_output(**output)\n+        return graph_layer\n+    else: # The case in which layer_dict represents an \"atomic\" layer\n+        layer_dict.pop('name')\n+        if layer_dict.has_key('parameters'):\n+            params = layer_dict.get('parameters')\n+            layer_dict.pop('parameters')\n+            hasParams = True\n+        for k, v in layer_dict.iteritems():\n+        \t# For now, this can only happen for regularizers and constraints\n+            if isinstance(v, dict):\n+                vname = v.get('name')\n+                v.pop('name')\n+                if vname in [x for x,y in inspect.getmembers(constraints, predicate=inspect.isclass)]:\n+                \tlayer_dict[k] = constraints.get(vname, v)\n+                if vname in [x for x,y in inspect.getmembers(regularizers, predicate=inspect.isclass)]:\n+                \tlayer_dict[k] = regularizers.get(vname, v)\n+                #layer_dict[k] = globals()[vname](**v)\n+        base_layer = get_layer(name, layer_dict)\n+        if hasParams:\n+            shaped_params = []\n+            for param in params:\n+                data = np.asarray(param.get('data'))\n+                shape = tuple(param.get('shape'))\n+                shaped_params.append(data.reshape(shape))\n+            base_layer.set_weights(shaped_params)\n+        return base_layer\n+\n+\n+from .generic_utils import get_from_module\n+def get_layer(identifier, kwargs=None):\n+    return get_from_module(identifier, globals(), 'layer', instantiate=True, kwargs=kwargs)\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5998b5dcfff59610d531f1d8f5a0a06f6516370a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 63 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 10 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 73 | Churn Cumulative: 128 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -2,15 +2,16 @@ from __future__ import absolute_import\n from __future__ import print_function\n import numpy as np\n \n+from keras.utils.test_utils import get_test_data\n from keras.preprocessing import sequence\n from keras.optimizers import SGD, RMSprop, Adagrad\n from keras.utils import np_utils\n-from keras.models import Sequential\n-from keras.layers.core import Dense, Dropout, Activation\n+from keras.models import Sequential, Graph\n+from keras.layers.core import Dense, Dropout, Activation, Merge\n from keras.layers.embeddings import Embedding\n from keras.layers.recurrent import LSTM, GRU\n from keras.datasets import imdb\n-from keras.models import sequential_from_yaml\n+from keras.models import model_from_yaml\n \n '''\n This is essentially the IMDB test. Deserialized models should yield \n@@ -30,26 +31,78 @@ model = Sequential()\n model.add(Embedding(max_features, 128))\n model.add(LSTM(128, 128)) \n model.add(Dropout(0.5))\n-model.add(Dense(128, 1))\n+model.add(Dense(128, 1, W_regularizer='identity', b_constraint='maxnorm'))\n model.add(Activation('sigmoid'))\n \n-model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n+#model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n \n model.get_config(verbose=1)\n \n ######################\n # save model to yaml #\n ######################\n-yamlString = model.to_yaml()\n+#yaml_string = model.to_yaml()\n \n-recovered_model = sequential_from_yaml(yamlString)\n-recovered_model.get_config(verbose=1)\n+#recovered_model = model_from_yaml(yaml_string)\n+#recovered_model.get_config(verbose=1)\n \n #####################################\n # save model w/o parameters to yaml #\n #####################################\n \n-yaml_no_params = model.to_yaml(storeParams=False)\n+yaml_no_params = model.to_yaml(store_params=False)\n \n-no_param_model = sequential_from_yaml(yaml_no_params)\n+no_param_model = model_from_yaml(yaml_no_params)\n no_param_model.get_config(verbose=1)\n+\n+######################################\n+# save multi-branch sequential model #\n+######################################\n+\n+seq = Sequential()\n+seq.add(Merge([model, model], mode='sum'))\n+seq.get_config(verbose=1)\n+merge_yaml = seq.to_yaml(store_params=False)\n+merge_model = model_from_yaml(merge_yaml)\n+\n+large_model = Sequential()\n+large_model.add(Merge([seq,model], mode='concat'))\n+large_model.get_config(verbose=1)\n+large_model.to_yaml(store_params=False)\n+\n+####################\n+# save graph model #\n+####################\n+\n+X = np.random.random((100, 32))\n+X2 = np.random.random((100, 32))\n+y = np.random.random((100, 4))\n+y2 = np.random.random((100,))\n+\n+(X_train, y_train), (X_test, y_test) = get_test_data(nb_train=1000, nb_test=200, input_shape=(32,),\n+    classification=False, output_shape=(4,))\n+\n+graph = Graph()\n+\n+graph.add_input(name='input1', ndim=2)\n+\n+graph.add_node(Dense(32, 16), name='dense1', input='input1')\n+graph.add_node(Dense(32, 4), name='dense2', input='input1')\n+graph.add_node(Dense(16, 4), name='dense3', input='dense1')\n+\n+graph.add_output(name='output1', inputs=['dense2', 'dense3'], merge_mode='sum')\n+graph.compile('rmsprop', {'output1':'mse'})\n+\n+graph.get_config(verbose=1)\n+\n+history = graph.fit({'input1':X_train, 'output1':y_train}, nb_epoch=10)\n+original_pred = graph.predict({'input1':X_test})\n+\n+graph_yaml = graph.to_yaml(store_params=True)\n+reloaded_graph = model_from_yaml(graph_yaml)\n+reloaded_graph.get_config(verbose=1)\n+\n+reloaded_graph.compile('rmsprop', {'output1':'mse'})\n+new_pred = reloaded_graph.predict({'input1':X_test})\n+\n+print(new_pred['output1'][3][1] == original_pred['output1'][3][1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7af168d81aa1e935cac1cc30a30b9890fed133e8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 16 | Churn Cumulative: 391 | Contributors (this commit): 6 | Commits (past 90d): 16 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -197,7 +197,23 @@ class ZeroPadding2D(Layer):\n         return {\"name\":self.__class__.__name__,\n                 \"width\":self.width}\n \n+class CropImage(Layer):\n+    # take a 4D tensor with (nb_samples, nb_chanels, height, width) and return a smaller tensor\n+    # that has (nb_samples, nb_chanels, height-2*crop, width-2*crop)\n+    # Cropped images are centered\n+    def __init__(self, crop=1):\n+        super(CropImage, self).__init__()\n+        self.crop = crop\n+        self.input = T.tensor4()\n \n+    def get_output(self, train):\n+        X = self.get_input(train)\n+        crop = self.crop\n+        return X[:,:,crop:-crop,crop:-crop]\n+\n+    def get_config(self):\n+        return {\"name\":self.__class__.__name__,\n+                \"crop\":self.crop}\n         \n # class Convolution3D: TODO\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fd1d5908c6b050a64f0eee3571f73a1983bd26d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 186 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -38,7 +38,7 @@ class TestGraph(unittest.TestCase):\n         loss = graph.train_on_batch({'input1':X_test, 'output1':y_test})\n         loss = graph.evaluate({'input1':X_test, 'output1':y_test})\n         print(loss)\n-        assert(loss < 1.4)\n+        assert(loss < 2.5)\n \n     def test_1o_1i_2(self):\n         print('test a more complex non-sequential graph with 1 input and 1 output')\n@@ -63,7 +63,7 @@ class TestGraph(unittest.TestCase):\n         loss = graph.train_on_batch({'input1':X_test, 'output1':y_test})\n         loss = graph.evaluate({'input1':X_test, 'output1':y_test})\n         print(loss)\n-        assert(loss < 1.4)\n+        assert(loss < 2.5)\n         graph.get_config(verbose=1)\n \n     def test_1o_2i(self):\n@@ -87,7 +87,7 @@ class TestGraph(unittest.TestCase):\n         loss = graph.train_on_batch({'input1':X_test, 'input2':X2_test, 'output1':y_test})\n         loss = graph.evaluate({'input1':X_test, 'input2':X2_test, 'output1':y_test})\n         print(loss)\n-        assert(loss < 1.4)\n+        assert(loss < 3.0)\n         graph.get_config(verbose=1)\n \n     def test_2o_1i_weights(self):\n@@ -111,7 +111,7 @@ class TestGraph(unittest.TestCase):\n         loss = graph.train_on_batch({'input1':X_test, 'output1':y_test, 'output2':y2_test})\n         loss = graph.evaluate({'input1':X_test, 'output1':y_test, 'output2':y2_test})\n         print(loss)\n-        assert(loss < 2.7)\n+        assert(loss < 4.)\n \n         print('test weight saving')\n         graph.save_weights('temp.h5', overwrite=True)\n@@ -148,7 +148,7 @@ class TestGraph(unittest.TestCase):\n         history = seq.fit(X_train, y_train, batch_size=10, nb_epoch=10)\n         loss = seq.evaluate(X_test, y_test)\n         print(loss)\n-        assert(loss < 1.4)\n+        assert(loss < 2.5)\n \n         loss = seq.evaluate(X_test, y_test, show_accuracy=True)\n         pred = seq.predict(X_test)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#37fe48b744b00f9e1d4eb7da481cd6a322743c9b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 2 | Churn Cumulative: 478 | Contributors (this commit): 6 | Commits (past 90d): 17 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -16,7 +16,7 @@ def kl_divergence(p, p_hat):\n \n class Optimizer(object):\n     \n-    def get_updates(self, params, regularizers, constraints,  loss):\n+    def get_updates(self, params, constraints, loss):\n         raise NotImplementedError\n \n     def get_gradients(self, loss, params):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3ebda96c3596e015d0c877cce95f3d14075273b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 1 | Churn Cumulative: 727 | Contributors (this commit): 5 | Commits (past 90d): 22 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -139,6 +139,7 @@ class BaseLogger(Callback):\n                 self.log_values.append((k, self.totals[k] / self.seen))\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n+        if self.verbose:\n             self.progbar.update(self.seen, self.log_values)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6336567c84306c08f6ba433e01b5ca6e1deac0e1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 19 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 30 | Churn Cumulative: 421 | Contributors (this commit): 6 | Commits (past 90d): 17 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -140,9 +140,19 @@ class Convolution2D(Layer):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n+        temp_mode = self.border_mode\n+        if temp_mode == 'same':\n+            temp_mode = 'full'    # just for the conv2d in the line below\n+                                    # output will be bigger but then we crop from it\n         conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,\n-            border_mode=self.border_mode, subsample=self.subsample)\n+            border_mode=temp_mode, subsample=self.subsample)\n         output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n+\n+        if self.border_mode == 'same':\n+            clip_row = (self.nb_row - 1)//2\n+            clip_col = (self.nb_col - 1)//2\n+            output = output[:,:,clip_row:-clip_row,clip_col:-clip_col]\n+\n         return output\n \n     def get_config(self):\n@@ -197,24 +207,6 @@ class ZeroPadding2D(Layer):\n         return {\"name\":self.__class__.__name__,\n                 \"width\":self.width}\n \n-class CropImage(Layer):\n-    # take a 4D tensor with (nb_samples, nb_chanels, height, width) and return a smaller tensor\n-    # that has (nb_samples, nb_chanels, height-2*crop, width-2*crop)\n-    # Cropped images are centered\n-    def __init__(self, crop=1):\n-        super(CropImage, self).__init__()\n-        self.crop = crop\n-        self.input = T.tensor4()\n-\n-    def get_output(self, train):\n-        X = self.get_input(train)\n-        crop = self.crop\n-        return X[:,:,crop:-crop,crop:-crop]\n-\n-    def get_config(self):\n-        return {\"name\":self.__class__.__name__,\n-                \"crop\":self.crop}\n-        \n # class Convolution3D: TODO\n \n # class MaxPooling3D: TODO\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43736166a473cd0eea04e18c85d0501d567bf61e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 22 | Churn Cumulative: 443 | Contributors (this commit): 6 | Commits (past 90d): 18 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -16,8 +16,10 @@ class Convolution1D(Layer):\n         border_mode='valid', subsample_length=1,\n         W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):\n \n-        super(Convolution1D,self).__init__()\n+        if border_mode not in {'valid', 'full'}:\n+            raise Exception('Invalid border mode for Convolution1D:', border_mode)\n \n+        super(Convolution1D,self).__init__()\n         self.nb_filter = nb_filter\n         self.input_dim = input_dim\n         self.filter_length = filter_length\n@@ -104,6 +106,9 @@ class Convolution2D(Layer):\n         border_mode='valid', subsample=(1, 1),\n         W_regularizer=None, b_regularizer=None, activity_regularizer=None, W_constraint=None, b_constraint=None):\n \n+        if border_mode not in {'valid', 'full', 'same'}:\n+            raise Exception('Invalid border mode for Convolution2D:', border_mode)\n+\n         super(Convolution2D,self).__init__()\n         self.init = initializations.get(init)\n         self.activation = activations.get(activation)\n@@ -140,19 +145,18 @@ class Convolution2D(Layer):\n \n     def get_output(self, train):\n         X = self.get_input(train)\n-        temp_mode = self.border_mode\n-        if temp_mode == 'same':\n-            temp_mode = 'full'    # just for the conv2d in the line below\n-                                    # output will be bigger but then we crop from it\n+        border_mode = self.border_mode\n+        if border_mode == 'same':\n+            border_mode = 'full'\n+\n         conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,\n-            border_mode=temp_mode, subsample=self.subsample)\n+            border_mode=border_mode, subsample=self.subsample)\n         output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n \n         if self.border_mode == 'same':\n             clip_row = (self.nb_row - 1) // 2\n             clip_col = (self.nb_col - 1) // 2\n             output = output[:, :, clip_row:-clip_row, clip_col:-clip_col]\n-\n         return output\n \n     def get_config(self):\n@@ -206,7 +210,3 @@ class ZeroPadding2D(Layer):\n     def get_config(self):\n         return {\"name\":self.__class__.__name__,\n                 \"width\":self.width}\n-\n-# class Convolution3D: TODO\n-\n-# class MaxPooling3D: TODO\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43d84368c62aebd3976177de6be486b417e462ad", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 59 | Lines Deleted: 40 | Files Changed: 5 | Hunks: 38 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/3 | Churn Δ: 99 | Churn Cumulative: 4410 | Contributors (this commit): 25 | Commits (past 90d): 175 | Contributors (cumulative): 41 | DMM Complexity: 1.0\n\nDIFF:\n@@ -82,12 +82,12 @@ class Sequential(Layer):\n         return {\"name\":self.__class__.__name__,\n             \"layers\":[layer.get_config() for layer in self.layers]}\n \n-    def layer_to_yaml(self, store_params=True):\n+    def to_yaml(self, store_params=True):\n         seq_config = {}\n         seq_config['name'] = self.__class__.__name__\n         layers = []\n         for layer in self.layers:\n-            layer_conf = layer.layer_to_yaml(store_params)\n+            layer_conf = layer.to_yaml(store_params)\n             layers.append(layer_conf)\n         seq_config['layers'] = layers\n         return seq_config\n@@ -223,7 +223,7 @@ class Graph(Layer):\n             \"node_config\":self.node_config,\n             \"nodes\":[self.nodes[c[\"name\"]].get_config() for c in self.node_config]}\n     \n-    def layer_to_yaml(self, store_params=True):\n+    def to_yaml(self, store_params=True):\n         graph_config = {}\n         graph_config['name'] = self.__class__.__name__\n \n@@ -241,7 +241,7 @@ class Graph(Layer):\n         for node_conf in self.node_config:\n             name = node_conf.get('name')\n             layer = self.nodes[name]\n-            layer_conf = layer.layer_to_yaml(store_params)\n+            layer_conf = layer.to_yaml(store_params)\n             node_conf['layer'] = layer_conf\n             nodes.append(node_conf)\n         graph_config['nodes'] = nodes\n\n@@ -90,7 +90,7 @@ class Layer(object):\n \n         return self.params, regularizers, consts\n \n-    def layer_to_yaml(self, store_params=True):\n+    def to_yaml(self, store_params=True):\n         layer_conf = self.get_config()\n         if store_params:\n             layer_conf['parameters'] = [{'shape':list(param.get_value().shape), 'data':param.get_value().tolist()} for param in self.params]\n@@ -190,13 +190,13 @@ class Merge(object):\n             \"layers\":[l.get_config() for l in self.layers],\n             \"mode\":self.mode}\n \n-    def layer_to_yaml(self, store_params=True):\n+    def to_yaml(self, store_params=True):\n         merge_conf = {}\n         merge_conf['name'] = self.__class__.__name__\n         merge_conf['mode'] = self.mode\n         layers = []\n         for layer in self.layers:\n-            layer_conf = layer.layer_to_yaml(store_params)\n+            layer_conf = layer.to_yaml(store_params)\n             layers.append(layer_conf)\n         merge_conf['layers'] = layers\n         return merge_conf     \n\n@@ -12,7 +12,7 @@ from . import constraints\n from . import callbacks as cbks\n \n import time, copy, pprint\n-from .utils.layer_utils import from_yaml\n+from .utils.layer_utils import container_from_yaml\n from .utils.generic_utils import Progbar, printv\n from .layers import containers\n from six.moves import range\n@@ -78,31 +78,39 @@ def standardize_weights(y, sample_weight=None, class_weight=None):\n     else:\n         return np.ones(y.shape[:-1] + (1,))\n \n+\n def model_from_yaml(yaml_string):\n     '''\n         Returns a model generated from a local yaml file,\n         which is either created by hand or from to_yaml method of Sequential or Graph\n     '''\n-    model_dict = yaml.load(yaml_string)\n-    model_name = model_dict.get('name')\n+    model_params = yaml.load(yaml_string)\n+    model_name = model_params.get('name')\n+    if not model_name in {'Graph', 'Sequential'}:\n+        raise Exception('Unrecognized model:', model_name)\n \n-    # Create a container layer and set class to respective model\n-    model = from_yaml(model_dict)\n+    # Create a container then set class to appropriate model\n+    print(model_params)\n+    model = container_from_yaml(model_params)\n     model.__class__ = get(model_name)\n \n-    if model_dict.has_key('optimizer'): # if it has an optimizer, the model is assumed to be compiled\n-        loss = objectives.get(model_dict.get('loss'))\n-        class_mode = model_dict.get('class_mode')\n-        theano_mode = model_dict.get('theano_mode')\n+    if 'optimizer' in model_params: # if it has an optimizer, the model is assumed to be compiled\n+        loss = objectives.get(model_params.get('loss'))\n+        class_mode = model_params.get('class_mode')\n+        theano_mode = model_params.get('theano_mode')\n \n-        optim = model_dict.get('optimizer')\n-        optim_name = optim.get('name')\n-        optim.pop('name')\n-        optimizer = optimizers.get(optim_name, optim)\n+        optimizer_params = model_params.get('optimizer')\n+        optimizer_name = optimizer_params.pop('name')\n+        optimizer = optimizers.get(optimizer_name, optimizer_params)\n+\n+        if model_name == 'Sequential':\n             model.compile(loss=loss, optimizer=optimizer, class_mode=class_mode, theano_mode=theano_mode)\n+        elif model_name == 'Graph':\n+            model.compile(loss=loss, optimizer=optimizer, theano_mode=theano_mode)\n \n     return model\n \n+\n class Model(object):\n     def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[], \\\n         validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):\n@@ -497,17 +505,17 @@ class Sequential(Model, containers.Sequential):\n             Stores a model to yaml string, optionally with all learnable parameters\n             If the model is compiled, it will also serialize the necessary components\n         '''\n-        model_dict = self.layer_to_yaml(store_params)    \n+        model_params = super(Sequential, self).to_yaml(store_params)\n         if hasattr(self, 'optimizer'):\n-            model_dict['class_mode'] = self.class_mode\n-            model_dict['theano_mode'] = self.theano_mode\n-            model_dict['loss'] = self.unweighted_loss.__name__\n-            model_dict['optimizer'] = self.optimizer.get_config()\n-        return yaml.dump(model_dict)\n+            model_params['class_mode'] = self.class_mode\n+            model_params['theano_mode'] = self.theano_mode\n+            model_params['loss'] = self.unweighted_loss.__name__\n+            model_params['optimizer'] = self.optimizer.get_config()\n+        return yaml.dump(model_params)\n \n \n class Graph(Model, containers.Graph):\n-    def compile(self, optimizer, loss, theano_mode=None, class_mode=None):\n+    def compile(self, optimizer, loss, theano_mode=None):\n         # loss is a dictionary mapping output name to loss functions\n         ys = []\n         ys_train = []\n@@ -640,12 +648,12 @@ class Graph(Model, containers.Graph):\n             Stores a model to yaml string, optionally with all learnable parameters\n             If the model is compiled, it will also serialize the necessary components\n         '''\n-        model_dict = self.layer_to_yaml(store_params)    \n+        model_params = super(Graph, self).to_yaml(store_params)\n         if hasattr(self, 'optimizer'):\n-            model_dict['theano_mode'] = self.theano_mode\n-            model_dict['loss'] = self.loss\n-            model_dict['optimizer'] = self.optimizer.get_config()\n-        return yaml.dump(model_dict)\n+            model_params['theano_mode'] = self.theano_mode\n+            model_params['loss'] = self.loss\n+            model_params['optimizer'] = self.optimizer.get_config()\n+        return yaml.dump(model_params)\n \n from .utils.generic_utils import get_from_module\n def get(identifier):\n\n@@ -14,48 +14,58 @@ from .. import regularizers\n from .. import constraints\n \n \n-def from_yaml(layer_dict):\n+def container_from_yaml(layer_dict):\n     name = layer_dict.get('name')\n     hasParams = False\n+\n     if name == 'Merge':\n         mode = layer_dict.get('mode')\n         layers = layer_dict.get('layers')\n         layer_list = []\n+\n         for layer in layers:\n-            init_layer = from_yaml(layer)\n+            init_layer = container_from_yaml(layer)\n             layer_list.append(init_layer)\n         merge_layer = Merge(layer_list, mode)\n         return merge_layer\n+\n     elif name == 'Sequential':\n         layers = layer_dict.get('layers')\n         layer_list = []\n+\n         for layer in layers:\n-            init_layer = from_yaml(layer)\n+            init_layer = container_from_yaml(layer)\n             layer_list.append(init_layer)\n         seq_layer = containers.Sequential(layer_list)\n         return seq_layer\n+\n     elif name == 'Graph':\n         graph_layer = containers.Graph()\n         inputs = layer_dict.get('inputs')\n+\n         for input in inputs:\n             graph_layer.add_input(**input)\n         nodes = layer_dict.get('nodes')\n+\n         for node in nodes:\n             layer_conf = node.get('layer')\n-            layer = from_yaml(layer_conf)\n+            layer = container_from_yaml(layer_conf)\n             node['layer'] = layer\n             graph_layer.add_node(**node)\n         outputs = layer_dict.get('outputs')\n+\n         for output in outputs:\n             graph_layer.add_output(**output)\n         return graph_layer\n+\n     else: # The case in which layer_dict represents an \"atomic\" layer\n         layer_dict.pop('name')\n-        if layer_dict.has_key('parameters'):\n+        if 'parameters' in layer_dict:\n             params = layer_dict.get('parameters')\n             layer_dict.pop('parameters')\n             hasParams = True\n-        for k, v in layer_dict.iteritems():\n+\n+        for k, v in layer_dict.items():\n         \t# For now, this can only happen for regularizers and constraints\n             if isinstance(v, dict):\n                 vname = v.get('name')\n@@ -64,10 +74,11 @@ def from_yaml(layer_dict):\n                 \tlayer_dict[k] = constraints.get(vname, v)\n                 if vname in [x for x,y in inspect.getmembers(regularizers, predicate=inspect.isclass)]:\n                 \tlayer_dict[k] = regularizers.get(vname, v)\n-                #layer_dict[k] = globals()[vname](**v)\n+                \n         base_layer = get_layer(name, layer_dict)\n         if hasParams:\n             shaped_params = []\n+\n             for param in params:\n                 data = np.asarray(param.get('data'))\n                 shape = tuple(param.get('shape'))\n\n@@ -9,6 +9,6 @@ setup(name = 'Keras',\n       url = 'https://github.com/fchollet/keras',\n       download_url = 'https://github.com/fchollet/keras/tarball/0.1.1',\n       license = 'MIT',\n-      install_requires = ['theano'],\n+      install_requires = ['theano', 'pyyaml'],\n       packages = find_packages(),\n )\n\\ No newline at end of file\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8824f1b469cf48d5d8fa96be5368a4cd82d783ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 35 | Lines Deleted: 101 | Files Changed: 5 | Hunks: 35 | Methods Changed: 10 | Complexity Δ (Sum/Max): -14/0 | Churn Δ: 136 | Churn Cumulative: 4599 | Contributors (this commit): 24 | Commits (past 90d): 176 | Contributors (cumulative): 40 | DMM Complexity: 0.0196078431372549\n\nDIFF:\n@@ -82,15 +82,6 @@ class Sequential(Layer):\n         return {\"name\":self.__class__.__name__,\n             \"layers\":[layer.get_config() for layer in self.layers]}\n \n-    def to_yaml(self, store_params=True):\n-        seq_config = {}\n-        seq_config['name'] = self.__class__.__name__\n-        layers = []\n-        for layer in self.layers:\n-            layer_conf = layer.to_yaml(store_params)\n-            layers.append(layer_conf)\n-        seq_config['layers'] = layers\n-        return seq_config\n \n class Graph(Layer):\n     '''\n@@ -219,31 +210,8 @@ class Graph(Layer):\n     def get_config(self):\n         return {\"name\":self.__class__.__name__,\n             \"input_config\":self.input_config,\n-            \"output_config\":self.output_config,\n             \"node_config\":self.node_config,\n-            \"nodes\":[self.nodes[c[\"name\"]].get_config() for c in self.node_config]}\n-    \n-    def to_yaml(self, store_params=True):\n-        graph_config = {}\n-        graph_config['name'] = self.__class__.__name__\n-\n-        inputs = []\n-        for input_conf in self.input_config:\n-            inputs.append(input_conf)\n-        graph_config['inputs'] = inputs\n-\n-        outputs = []\n-        for output_conf in self.output_config:\n-            outputs.append(output_conf)\n-        graph_config['outputs'] = outputs\n-\n-        nodes = []\n-        for node_conf in self.node_config:\n-            name = node_conf.get('name')\n-            layer = self.nodes[name]\n-            layer_conf = layer.to_yaml(store_params)\n-            node_conf['layer'] = layer_conf\n-            nodes.append(node_conf)\n-        graph_config['nodes'] = nodes\n-\n-        return graph_config\n+            \"output_config\":self.output_config,\n+            \"input_order\":self.input_order,\n+            \"output_order\":self.output_order,\n+            \"nodes\":dict([(c[\"name\"], self.nodes[c[\"name\"]].get_config()) for c in self.node_config])}\n\n@@ -90,11 +90,6 @@ class Layer(object):\n \n         return self.params, regularizers, consts\n \n-    def to_yaml(self, store_params=True):\n-        layer_conf = self.get_config()\n-        if store_params:\n-            layer_conf['parameters'] = [{'shape':list(param.get_value().shape), 'data':param.get_value().tolist()} for param in self.params]\n-        return layer_conf\n \n class MaskedLayer(Layer):\n     '''\n@@ -190,16 +185,6 @@ class Merge(object):\n             \"layers\":[l.get_config() for l in self.layers],\n             \"mode\":self.mode}\n   \n-    def to_yaml(self, store_params=True):\n-        merge_conf = {}\n-        merge_conf['name'] = self.__class__.__name__\n-        merge_conf['mode'] = self.mode\n-        layers = []\n-        for layer in self.layers:\n-            layer_conf = layer.to_yaml(store_params)\n-            layers.append(layer_conf)\n-        merge_conf['layers'] = layers\n-        return merge_conf     \n \n class Dropout(MaskedLayer):\n     '''\n\n@@ -12,7 +12,7 @@ from . import constraints\n from . import callbacks as cbks\n \n import time, copy, pprint\n-from .utils.layer_utils import container_from_yaml\n+from .utils.layer_utils import container_from_config\n from .utils.generic_utils import Progbar, printv\n from .layers import containers\n from six.moves import range\n@@ -85,13 +85,14 @@ def model_from_yaml(yaml_string):\n         which is either created by hand or from to_yaml method of Sequential or Graph\n     '''\n     model_params = yaml.load(yaml_string)\n+    print(model_params)\n+\n     model_name = model_params.get('name')\n     if not model_name in {'Graph', 'Sequential'}:\n         raise Exception('Unrecognized model:', model_name)\n \n     # Create a container then set class to appropriate model\n-    print(model_params)\n-    model = container_from_yaml(model_params)\n+    model = container_from_config(model_params)\n     model.__class__ = get(model_name)\n \n     if 'optimizer' in model_params: # if it has an optimizer, the model is assumed to be compiled\n@@ -253,6 +254,13 @@ class Model(object):\n             outs[i] /= nb_sample\n         return outs\n \n+    def get_config(self, verbose=0):\n+        config = super(Model, self).get_config()\n+        if verbose:\n+            pp = pprint.PrettyPrinter(indent=4)\n+            pp.pprint(config)\n+        return config\n+\n class Sequential(Model, containers.Sequential):\n     '''\n         Inherits from Model the following methods:\n@@ -444,16 +452,6 @@ class Sequential(Model, containers.Sequential):\n             return outs[0]\n \n \n-    def get_config(self, verbose=0):\n-        layers = []\n-        for i, l in enumerate(self.layers):\n-            config = l.get_config()\n-            layers.append(config)\n-        if verbose:\n-            printv(layers)\n-        return layers\n-\n-\n     def save_weights(self, filepath, overwrite=False):\n         # Save weights from all layers to HDF5\n         import h5py\n@@ -500,17 +498,18 @@ class Sequential(Model, containers.Sequential):\n         f.close()\n \n \n-    def to_yaml(self, store_params=True):\n+    def to_yaml(self):\n         '''\n             Stores a model to yaml string, optionally with all learnable parameters\n             If the model is compiled, it will also serialize the necessary components\n         '''\n-        model_params = super(Sequential, self).to_yaml(store_params)\n+        model_params = self.get_config()\n         if hasattr(self, 'optimizer'):\n             model_params['class_mode'] = self.class_mode\n             model_params['theano_mode'] = self.theano_mode\n             model_params['loss'] = self.unweighted_loss.__name__\n             model_params['optimizer'] = self.optimizer.get_config()\n+\n         return yaml.dump(model_params)\n \n \n@@ -636,19 +635,12 @@ class Graph(Model, containers.Graph):\n         self.set_weights(weights)\n         f.close()\n \n-    def get_config(self, verbose=1):\n-        config = super(Graph, self).get_config()\n-        if verbose:\n-            pp = pprint.PrettyPrinter(indent=4)\n-            pp.pprint(config)\n-        return config\n-\n-    def to_yaml(self, store_params=True):\n+    def to_yaml(self):\n         '''\n             Stores a model to yaml string, optionally with all learnable parameters\n             If the model is compiled, it will also serialize the necessary components\n         '''\n-        model_params = super(Graph, self).to_yaml(store_params)\n+        model_params = self.get_config()\n         if hasattr(self, 'optimizer'):\n             model_params['theano_mode'] = self.theano_mode\n             model_params['loss'] = self.loss\n\n@@ -14,7 +14,7 @@ from .. import regularizers\n from .. import constraints\n \n \n-def container_from_yaml(layer_dict):\n+def container_from_config(layer_dict):\n     name = layer_dict.get('name')\n     hasParams = False\n \n@@ -22,9 +22,8 @@ def container_from_yaml(layer_dict):\n         mode = layer_dict.get('mode')\n         layers = layer_dict.get('layers')\n         layer_list = []\n-\n         for layer in layers:\n-            init_layer = container_from_yaml(layer)\n+            init_layer = container_from_config(layer)\n             layer_list.append(init_layer)\n         merge_layer = Merge(layer_list, mode)\n         return merge_layer\n@@ -32,28 +31,26 @@ def container_from_yaml(layer_dict):\n     elif name == 'Sequential':\n         layers = layer_dict.get('layers')\n         layer_list = []\n-\n         for layer in layers:\n-            init_layer = container_from_yaml(layer)\n+            init_layer = container_from_config(layer)\n             layer_list.append(init_layer)\n         seq_layer = containers.Sequential(layer_list)\n         return seq_layer\n \n     elif name == 'Graph':\n         graph_layer = containers.Graph()\n-        inputs = layer_dict.get('inputs')\n+        inputs = layer_dict.get('input_config')\n \n         for input in inputs:\n             graph_layer.add_input(**input)\n-        nodes = layer_dict.get('nodes')\n \n+        nodes = layer_dict.get('node_config')\n         for node in nodes:\n-            layer_conf = node.get('layer')\n-            layer = container_from_yaml(layer_conf)\n+            layer = container_from_config(layer_dict['nodes'].get(node['name']))\n             node['layer'] = layer\n             graph_layer.add_node(**node)\n-        outputs = layer_dict.get('outputs')\n \n+        outputs = layer_dict.get('output_config')\n         for output in outputs:\n             graph_layer.add_output(**output)\n         return graph_layer\n@@ -78,7 +75,6 @@ def container_from_yaml(layer_dict):\n         base_layer = get_layer(name, layer_dict)\n         if hasParams:\n             shaped_params = []\n-\n             for param in params:\n                 data = np.asarray(param.get('data'))\n                 shape = tuple(param.get('shape'))\n\n@@ -34,23 +34,13 @@ model.add(Dropout(0.5))\n model.add(Dense(128, 1, W_regularizer='identity', b_constraint='maxnorm'))\n model.add(Activation('sigmoid'))\n \n-#model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n-\n model.get_config(verbose=1)\n \n-######################\n-# save model to yaml #\n-######################\n-#yaml_string = model.to_yaml()\n-\n-#recovered_model = model_from_yaml(yaml_string)\n-#recovered_model.get_config(verbose=1)\n-\n #####################################\n # save model w/o parameters to yaml #\n #####################################\n \n-yaml_no_params = model.to_yaml(store_params=False)\n+yaml_no_params = model.to_yaml()\n \n no_param_model = model_from_yaml(yaml_no_params)\n no_param_model.get_config(verbose=1)\n@@ -62,13 +52,13 @@ no_param_model.get_config(verbose=1)\n seq = Sequential()\n seq.add(Merge([model, model], mode='sum'))\n seq.get_config(verbose=1)\n-merge_yaml = seq.to_yaml(store_params=False)\n+merge_yaml = seq.to_yaml()\n merge_model = model_from_yaml(merge_yaml)\n \n large_model = Sequential()\n large_model.add(Merge([seq,model], mode='concat'))\n large_model.get_config(verbose=1)\n-large_model.to_yaml(store_params=False)\n+large_model.to_yaml()\n \n ####################\n # save graph model #\n@@ -98,11 +88,14 @@ graph.get_config(verbose=1)\n history = graph.fit({'input1':X_train, 'output1':y_train}, nb_epoch=10)\n original_pred = graph.predict({'input1':X_test})\n \n-graph_yaml = graph.to_yaml(store_params=True)\n+graph_yaml = graph.to_yaml()\n+graph.save_weights('temp.h5', overwrite=True)\n+\n reloaded_graph = model_from_yaml(graph_yaml)\n+reloaded_graph.load_weights('temp.h5')\n reloaded_graph.get_config(verbose=1)\n \n reloaded_graph.compile('rmsprop', {'output1':'mse'})\n new_pred = reloaded_graph.predict({'input1':X_test})\n \n-print(new_pred['output1'][3][1] == original_pred['output1'][3][1])\n+assert(new_pred['output1'][3][1] == original_pred['output1'][3][1])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46e19b95d8346a553183c6a734576bca4b55d950", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2319 | Contributors (this commit): 19 | Commits (past 90d): 89 | Contributors (cumulative): 19 | DMM Complexity: 0.0\n\nDIFF:\n@@ -85,8 +85,6 @@ def model_from_yaml(yaml_string):\n         which is either created by hand or from to_yaml method of Sequential or Graph\n     '''\n     model_params = yaml.load(yaml_string)\n-    print(model_params)\n-\n     model_name = model_params.get('name')\n     if not model_name in {'Graph', 'Sequential'}:\n         raise Exception('Unrecognized model:', model_name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a4aab453f42bda2368e51bc707c22c40c384b34", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 10/10 | Churn Δ: 11 | Churn Cumulative: 454 | Contributors (this commit): 6 | Commits (past 90d): 19 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -171,13 +171,14 @@ class Convolution2D(Layer):\n \n         conv_out = theano.tensor.nnet.conv.conv2d(X, self.W,\n             border_mode=border_mode, subsample=self.subsample)\n-        output = self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n \n         if self.border_mode == 'same':\n-            clip_row = (self.nb_row - 1) // 2\n-            clip_col = (self.nb_col - 1) // 2\n-            output = output[:, :, clip_row:-clip_row, clip_col:-clip_col]\n-        return output\n+            shift_x = (self.nb_row - 1) // 2\n+            shift_y = (self.nb_col - 1) // 2\n+            conv_out = conv_out[:, :, shift_x:X.shape[2] + shift_x, shift_y:X.shape[3] + shift_y]\n+\n+        return self.activation(conv_out + self.b.dimshuffle('x', 0, 'x', 'x'))\n+\n \n     def get_config(self):\n         return {\"name\":self.__class__.__name__,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e6582c18927b7dbc36be288eb09277f4f8496f49", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 7 | Complexity Δ (Sum/Max): 12/12 | Churn Δ: 113 | Churn Cumulative: 113 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,113 @@\n+import unittest\n+import numpy as np\n+from numpy.testing import assert_allclose\n+from theano import tensor as T\n+from keras.layers import normalization\n+\n+class TestBatchNormalization(unittest.TestCase):\n+    def setUp(self):\n+        self.input_1 = np.arange(10)\n+        self.input_2 = np.zeros(10)\n+        self.input_3 = np.ones((10))\n+\n+        self.input_shapes = [np.ones((10,10)), np.ones((10,10,10))]\n+\n+    def test_setup(self):\n+        norm_m0 = normalization.BatchNormalization((10,10))\n+        norm_m1 = normalization.BatchNormalization((10,10), mode=1)\n+\n+        # mode 3 does not exist\n+        self.assertRaises(Exception,normalization.BatchNormalization((10,10),mode=3))\n+\n+    def test_mode_0(self):\n+        \"\"\"\n+        Test the function of mode 0. Need to be somewhat lenient with the\n+        equality assertions because of the epsilon trick used to avoid NaNs.\n+        \"\"\"\n+        norm_m0 = normalization.BatchNormalization((10,), momentum=0.5)\n+\n+        norm_m0.input = self.input_1\n+        out = (norm_m0.get_output(train=True) - norm_m0.beta)/norm_m0.gamma\n+        self.assertAlmostEqual(out.mean().eval(), 0.0)\n+        self.assertAlmostEqual(out.std().eval(), 1.0, places=2)\n+\n+        self.assertAlmostEqual(norm_m0.running_mean, 4.5)\n+        self.assertAlmostEqual(norm_m0.running_std.eval(), np.arange(10).std(), places=2)\n+\n+        norm_m0.input = self.input_2\n+        out = (norm_m0.get_output(train=True) - norm_m0.beta)/norm_m0.gamma\n+        self.assertAlmostEqual(out.mean().eval(), 0.0)\n+        self.assertAlmostEqual(out.std().eval(), 0.0, places=2)\n+\n+        #Values calculated by hand\n+        self.assertAlmostEqual(norm_m0.running_mean, 2.25)\n+        self.assertAlmostEqual(norm_m0.running_std.eval(), 0.5*np.arange(10).std(), places=2)\n+\n+        out_test = (norm_m0.get_output(train=False) - norm_m0.beta)/norm_m0.gamma\n+        self.assertAlmostEqual(out_test.mean().eval(), -2.25 / (0.5*np.arange(10).std()),places=2)\n+        self.assertAlmostEqual(out_test.std().eval(), 0.0, places=2)\n+\n+        norm_m0.input = self.input_3\n+        out = (norm_m0.get_output(train=True) - norm_m0.beta)/norm_m0.gamma\n+        self.assertAlmostEqual(out.mean().eval(), 0.0)\n+        self.assertAlmostEqual(out.std().eval(), 0.0, places=2)\n+\n+    def test_mode_1(self):\n+        norm_m1 = normalization.BatchNormalization((10,), mode=1)\n+\n+        for inp in [self.input_1, self.input_2, self.input_3]:\n+            norm_m1.input = inp\n+            out = (norm_m1.get_output(train=True) - norm_m1.beta)/norm_m1.gamma\n+            self.assertAlmostEqual(out.mean().eval(), 0.0)\n+            if inp.std() > 0.:\n+                self.assertAlmostEqual(out.std().eval(), 1.0, places=2)\n+            else:\n+                self.assertAlmostEqual(out.std().eval(), 0.0, places=2)\n+\n+    def test_shapes(self):\n+        \"\"\"\n+        Test batch normalization with various input shapes\n+        \"\"\"\n+        for inp in self.input_shapes:\n+            norm_m0 = normalization.BatchNormalization(inp.shape, mode=0)\n+            norm_m0.input = inp\n+            out = (norm_m0.get_output(train=True) - norm_m0.beta)/norm_m0.gamma\n+\n+            norm_m1 = normalization.BatchNormalization(inp.shape, mode=1)\n+            norm_m1.input = inp\n+            out = (norm_m1.get_output(train=True) - norm_m1.beta)/norm_m1.gamma\n+\n+    def test_weight_init(self):\n+        \"\"\"\n+        Test weight initialization\n+        \"\"\"\n+\n+        norm_m1 = normalization.BatchNormalization((10,), mode=1, weights=[np.ones(10),np.ones(10)])\n+\n+        for inp in [self.input_1, self.input_2, self.input_3]:\n+            norm_m1.input = inp\n+            out = (norm_m1.get_output(train=True) - np.ones(10))/1.\n+            self.assertAlmostEqual(out.mean().eval(), 0.0)\n+            if inp.std() > 0.:\n+                self.assertAlmostEqual(out.std().eval(), 1.0, places=2)\n+            else:\n+                self.assertAlmostEqual(out.std().eval(), 0.0, places=2)\n+\n+        assert_allclose(norm_m1.gamma.eval(),np.ones(10))\n+        assert_allclose(norm_m1.beta.eval(),np.ones(10))\n+\n+        #Weights must be an iterable of gamma AND beta.\n+        self.assertRaises(Exception,normalization.BatchNormalization(10,), weights = np.ones(10))\n+\n+\n+    def test_config(self):\n+        norm = normalization.BatchNormalization((10,10), mode=1, epsilon=0.1)\n+        conf = norm.get_config()\n+        conf_target = {\"input_shape\": (10,10), \"name\": normalization.BatchNormalization.__name__,\n+                       \"epsilon\":0.1, \"mode\": 1}\n+\n+        self.assertDictEqual(conf, conf_target)\n+\n+\n+if __name__ == '__main__':\n+    unittest.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
