{"custom_id": "keras#19bd6333237026c415a02221eadcbaa17e0947d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 890 | Contributors (this commit): 8 | Commits (past 90d): 44 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -228,16 +228,22 @@ if \"KERAS_BACKEND\" in os.environ:\n         _BACKEND = _backend\n \n \n-@keras_core_export(\"keras_core.backend.backend\")\n+@keras_core_export(\n+    [\n+        \"keras_core.config.backend\",\n+        \"keras_core.backend.backend\",\n+    ]\n+)\n def backend():\n     \"\"\"Publicly accessible method for determining the current backend.\n \n     Returns:\n-        String, the name of the backend Keras is currently using.\n+        String, the name of the backend Keras is currently using. One of\n+            `\"tensorflow\"`, `\"torch\"`, or `\"jax\"`.\n \n     Example:\n \n-    >>> keras.backend.backend()\n+    >>> keras.config.backend()\n     'tensorflow'\n     \"\"\"\n     return _BACKEND\n\n@@ -72,7 +72,7 @@ class Loss:\n \n \n def standardize_reduction(reduction):\n-    allowed = {\"sum_over_batch_size\", \"sum\", None}\n+    allowed = {\"sum_over_batch_size\", \"sum\", None, \"none\"}\n     if reduction not in allowed:\n         raise ValueError(\n             \"Invalid value for argument `reduction`. \"\n@@ -100,6 +100,7 @@ def squeeze_to_same_rank(x1, x2):\n def reduce_values(values, reduction=\"sum_over_batch_size\"):\n     if (\n         reduction is None\n+        or reduction == \"none\"\n         or tuple(values.shape) == ()\n         or tuple(values.shape) == (0,)\n     ):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2969246d114fc82c7a5a5e14d6baf1ea2ba97361", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 26 | Churn Cumulative: 214 | Contributors (this commit): 1 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,7 +1,10 @@\n import numpy as np\n+import pytest\n import tensorflow as tf\n from absl.testing import parameterized\n \n+from keras_core import Sequential\n+from keras_core import backend\n from keras_core import layers\n from keras_core import testing\n \n@@ -150,3 +153,21 @@ class ResizingTest(testing.TestCase, parameterized.TestCase):\n         for output in ds.take(1):\n             output = output.numpy()\n         self.assertEqual(list(output.shape), [2, 8, 9, 3])\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"Sequential + tf.data only works with TF backend\",\n+    )\n+    def test_tf_data_compatibility_sequential(self):\n+        # Test compatibility when wrapping in a Sequential\n+        # https://github.com/keras-team/keras-core/issues/347\n+        layer = layers.Resizing(8, 9)\n+        input_data = np.random.random((2, 10, 12, 3))\n+        ds = (\n+            tf.data.Dataset.from_tensor_slices(input_data)\n+            .batch(2)\n+            .map(Sequential([layer]))\n+        )\n+        for output in ds.take(1):\n+            output = output.numpy()\n+        self.assertEqual(list(output.shape), [2, 8, 9, 3])\n\n@@ -1,3 +1,4 @@\n+from keras_core import backend\n from keras_core.layers.layer import Layer\n from keras_core.utils import backend_utils\n \n@@ -16,7 +17,9 @@ class TFDataLayer(Layer):\n         self._allow_non_tensor_positional_args = True\n \n     def __call__(self, inputs, **kwargs):\n-        if backend_utils.in_tf_graph():\n+        if backend_utils.in_tf_graph() and not isinstance(\n+            inputs, backend.KerasTensor\n+        ):\n             # We're in a TF graph, e.g. a tf.data pipeline.\n             self.backend.set_backend(\"tensorflow\")\n             inputs = self.backend.convert_to_tensor(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f90a500d4a2d631b7a9caef785f514c3dbf74b67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 11 | Churn Cumulative: 711 | Contributors (this commit): 3 | Commits (past 90d): 11 | Contributors (cumulative): 5 | DMM Complexity: 0.9\n\nDIFF:\n@@ -52,6 +52,7 @@ class CenterCrop(TFDataLayer):\n         self.data_format = backend.standardize_data_format(data_format)\n \n     def call(self, inputs):\n+        inputs = self.backend.cast(inputs, self.compute_dtype)\n         if self.data_format == \"channels_first\":\n             init_height = inputs.shape[-2]\n             init_width = inputs.shape[-1]\n\n@@ -102,3 +102,13 @@ class CenterCropTest(testing.TestCase, parameterized.TestCase):\n         for output in ds.take(1):\n             output = output.numpy()\n         self.assertEqual(list(output.shape), [2, 8, 9, 3])\n+\n+    def test_list_compatibility(self):\n+        images = [\n+            np.random.rand(10, 10, 3),\n+            np.random.rand(10, 10, 3),\n+        ]\n+        output = layers.CenterCrop(height=6, width=5)(images)\n+        ref_output = tf.keras.layers.CenterCrop(6, 5)(images)\n+        self.assertListEqual(list(output.shape), [2, 6, 5, 3])\n+        self.assertAllClose(ref_output, output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#26a4a6e73793388ee8860b8101fbabfbd83037a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 8 | Files Changed: 6 | Hunks: 11 | Methods Changed: 9 | Complexity Δ (Sum/Max): 8/6 | Churn Δ: 50 | Churn Cumulative: 2742 | Contributors (this commit): 13 | Commits (past 90d): 134 | Contributors (cumulative): 32 | DMM Complexity: 0.9\n\nDIFF:\n@@ -1021,7 +1021,7 @@ class Layer(BackendLayer, Operation):\n             # Case: all input keyword arguments were plain tensors.\n             input_tensors = {\n                 # We strip the `_shape` suffix to recover kwarg names.\n-                k.removesuffix(\"_shape\"): backend.KerasTensor(shape)\n+                utils.removesuffix(k, \"_shape\"): backend.KerasTensor(shape)\n                 for k, shape in shapes_dict.items()\n             }\n             try:\n@@ -1286,7 +1286,7 @@ def check_shapes_signature(target_fn, call_spec, cls):\n                 f\"Received `{method_name}()` argument \"\n                 f\"`{name}`, which does not end in `_shape`.\"\n             )\n-        expected_call_arg = name.removesuffix(\"_shape\")\n+        expected_call_arg = utils.removesuffix(name, \"_shape\")\n         if expected_call_arg not in call_spec.arguments_dict:\n             raise ValueError(\n                 f\"{error_preamble} For layer '{cls.__name__}', \"\n\n@@ -1,6 +1,7 @@\n import copy\n \n from keras_core import operations as ops\n+from keras_core import utils\n from keras_core.api_export import keras_core_export\n from keras_core.layers.core.wrapper import Wrapper\n from keras_core.layers.layer import Layer\n@@ -109,16 +110,16 @@ class Bidirectional(Wrapper):\n         # Recreate the forward layer from the original layer config, so that it\n         # will not carry over any state from the layer.\n         config = serialization_lib.serialize_keras_object(layer)\n-        config[\"config\"][\"name\"] = \"forward_\" + layer.name.removeprefix(\n-            \"forward_\"\n+        config[\"config\"][\"name\"] = \"forward_\" + utils.removeprefix(\n+            layer.name, \"forward_\"\n         )\n         self.forward_layer = serialization_lib.deserialize_keras_object(config)\n \n         if backward_layer is None:\n             config = serialization_lib.serialize_keras_object(layer)\n             config[\"config\"][\"go_backwards\"] = True\n-            config[\"config\"][\"name\"] = \"backward_\" + layer.name.removeprefix(\n-                \"backward_\"\n+            config[\"config\"][\"name\"] = \"backward_\" + utils.removeprefix(\n+                layer.name, \"backward_\"\n             )\n             self.backward_layer = serialization_lib.deserialize_keras_object(\n                 config\n\n@@ -8,6 +8,7 @@ from tensorflow import nest\n \n from keras_core import backend\n from keras_core import operations as ops\n+from keras_core import utils\n from keras_core.models import Model\n from keras_core.utils import traceback_utils\n \n@@ -336,7 +337,9 @@ def create_keras_tensors(input_shape, dtype):\n         return [keras_tensor.KerasTensor(s, dtype=dtype) for s in input_shape]\n     if isinstance(input_shape, dict):\n         return {\n-            k.removesuffix(\"_shape\"): keras_tensor.KerasTensor(v, dtype=dtype)\n+            utils.removesuffix(k, \"_shape\"): keras_tensor.KerasTensor(\n+                v, dtype=dtype\n+            )\n             for k, v in input_shape.items()\n         }\n \n@@ -370,6 +373,6 @@ def create_eager_tensors(input_shape, dtype):\n         return [create_fn(s, dtype=dtype) for s in input_shape]\n     if isinstance(input_shape, dict):\n         return {\n-            k.removesuffix(\"_shape\"): create_fn(v, dtype=dtype)\n+            utils.removesuffix(k, \"_shape\"): create_fn(v, dtype=dtype)\n             for k, v in input_shape.items()\n         }\n\n@@ -18,5 +18,7 @@ from keras_core.utils.numerical_utils import to_categorical\n from keras_core.utils.progbar import Progbar\n from keras_core.utils.python_utils import default\n from keras_core.utils.python_utils import is_default\n+from keras_core.utils.python_utils import removeprefix\n+from keras_core.utils.python_utils import removesuffix\n from keras_core.utils.rng_utils import set_random_seed\n from keras_core.utils.sequence_utils import pad_sequences\n\n@@ -122,3 +122,21 @@ def remove_long_seq(maxlen, seq, label):\n             new_seq.append(x)\n             new_label.append(y)\n     return new_seq, new_label\n+\n+\n+def removeprefix(x, prefix):\n+    \"\"\"Backport of `removeprefix` from PEP-616 (Python 3.9+)\"\"\"\n+\n+    if len(prefix) > 0 and x.startswith(prefix):\n+        return x[len(prefix) :]\n+    else:\n+        return x\n+\n+\n+def removesuffix(x, suffix):\n+    \"\"\"Backport of `removesuffix` from PEP-616 (Python 3.9+)\"\"\"\n+\n+    if len(suffix) > 0 and x.endswith(suffix):\n+        return x[: -len(suffix)]\n+    else:\n+        return x\n\n@@ -10,3 +10,13 @@ class PythonUtilsTest(testing.TestCase):\n         serialized = python_utils.func_dump(my_function)\n         deserialized = python_utils.func_load(serialized)\n         self.assertEqual(deserialized(2, y=3), 5)\n+\n+    def test_removesuffix(self):\n+        x = \"model.keras\"\n+        self.assertEqual(python_utils.removesuffix(x, \".keras\"), \"model\")\n+        self.assertEqual(python_utils.removesuffix(x, \"model\"), x)\n+\n+    def test_removeprefix(self):\n+        x = \"model.keras\"\n+        self.assertEqual(python_utils.removeprefix(x, \"model\"), \".keras\")\n+        self.assertEqual(python_utils.removeprefix(x, \".keras\"), x)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e01d24e0c0f191dd4bbebc9a801fcae610b7d471", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 73 | Lines Deleted: 58 | Files Changed: 4 | Hunks: 5 | Methods Changed: 7 | Complexity Δ (Sum/Max): 2/9 | Churn Δ: 131 | Churn Cumulative: 2866 | Contributors (this commit): 8 | Commits (past 90d): 99 | Contributors (cumulative): 18 | DMM Complexity: 0.8125\n\nDIFF:\n@@ -368,55 +368,6 @@ class Functional(Function, Model):\n         config[\"output_layers\"] = map_tensors(self._outputs_struct)\n         return copy.deepcopy(config)\n \n-    @classmethod\n-    def from_config(cls, config, custom_objects=None):\n-        functional_config_keys = [\n-            \"name\",\n-            \"layers\",\n-            \"input_layers\",\n-            \"output_layers\",\n-        ]\n-        is_functional_config = all(\n-            key in config for key in functional_config_keys\n-        )\n-        argspec = inspect.getfullargspec(cls.__init__)\n-        functional_init_args = inspect.getfullargspec(Functional.__init__).args[\n-            1:\n-        ]\n-        revivable_as_functional = (\n-            cls in {Functional, Model}\n-            or argspec.args[1:] == functional_init_args\n-            or (argspec.varargs == \"args\" and argspec.varkw == \"kwargs\")\n-        )\n-        if is_functional_config and revivable_as_functional:\n-            # Revive Functional model\n-            # (but not Functional subclasses with a custom __init__)\n-            return cls._from_config(config, custom_objects=custom_objects)\n-\n-        # Either the model has a custom __init__, or the config\n-        # does not contain all the information necessary to\n-        # revive a Functional model. This happens when the user creates\n-        # subclassed models where `get_config()` is returning\n-        # insufficient information to be considered a Functional model.\n-        # In this case, we fall back to provide all config into the\n-        # constructor of the class.\n-        try:\n-            return cls(**config)\n-        except TypeError as e:\n-            raise TypeError(\n-                \"Unable to revive model from config. When overriding \"\n-                \"the `get_config()` method, make sure that the \"\n-                \"returned config contains all items used as arguments \"\n-                f\"in the  constructor to {cls}, \"\n-                \"which is the default behavior. \"\n-                \"You can override this default behavior by defining a \"\n-                \"`from_config(cls, config)` class method to specify \"\n-                \"how to create an \"\n-                f\"instance of {cls.__name__} from its config.\\n\\n\"\n-                f\"Received config={config}\\n\\n\"\n-                f\"Error encountered during deserialization: {e}\"\n-            )\n-\n     @classmethod\n     def _from_config(cls, config, custom_objects=None):\n         \"\"\"Instantiates a Model from its config (output of `get_config()`).\"\"\"\n\n@@ -1,3 +1,4 @@\n+import inspect\n import json\n import os\n import warnings\n@@ -380,6 +381,59 @@ class Model(Trainer, Layer):\n             \"TensorFlow SavedModel for your Keras Core model.\"\n         )\n \n+    @classmethod\n+    def from_config(cls, config, custom_objects=None):\n+        from keras_core.models.functional import Functional\n+\n+        functional_config_keys = [\n+            \"name\",\n+            \"layers\",\n+            \"input_layers\",\n+            \"output_layers\",\n+        ]\n+        is_functional_config = all(\n+            key in config for key in functional_config_keys\n+        )\n+        argspec = inspect.getfullargspec(cls.__init__)\n+        functional_init_args = inspect.getfullargspec(Functional.__init__).args[\n+            1:\n+        ]\n+        revivable_as_functional = (\n+            cls in {Functional, Model}\n+            or argspec.args[1:] == functional_init_args\n+            or (argspec.varargs == \"args\" and argspec.varkw == \"kwargs\")\n+        )\n+        if is_functional_config and revivable_as_functional:\n+            # Revive Functional model\n+            # (but not Functional subclasses with a custom __init__)\n+            if cls == Model:\n+                cls = Functional\n+            return cls._from_config(config, custom_objects=custom_objects)\n+\n+        # Either the model has a custom __init__, or the config\n+        # does not contain all the information necessary to\n+        # revive a Functional model. This happens when the user creates\n+        # subclassed models where `get_config()` is returning\n+        # insufficient information to be considered a Functional model.\n+        # In this case, we fall back to provide all config into the\n+        # constructor of the class.\n+        try:\n+            return cls(**config)\n+        except TypeError as e:\n+            raise TypeError(\n+                \"Unable to revive model from config. When overriding \"\n+                \"the `get_config()` method, make sure that the \"\n+                \"returned config contains all items used as arguments \"\n+                f\"in the  constructor to {cls}, \"\n+                \"which is the default behavior. \"\n+                \"You can override this default behavior by defining a \"\n+                \"`from_config(cls, config)` class method to specify \"\n+                \"how to create an \"\n+                f\"instance of {cls.__name__} from its config.\\n\\n\"\n+                f\"Received config={config}\\n\\n\"\n+                f\"Error encountered during deserialization: {e}\"\n+            )\n+\n \n @keras_core_export(\"keras_core.models.model_from_json\")\n def model_from_json(json_string, custom_objects=None):\n\n@@ -46,3 +46,22 @@ class ModelTest(testing.TestCase):\n         x2 = np.random.rand(3, 2)\n         out = model((x1, x2))\n         self.assertEqual(out.shape, (3, 6))\n+\n+    def test_reviving_functional_from_config_custom_layer(self):\n+        class CustomDense(layers.Layer):\n+            def __init__(self, units, **kwargs):\n+                super().__init__(**kwargs)\n+                self.dense = layers.Dense(units)\n+\n+            def call(self, x):\n+                return self.dense(x)\n+\n+        inputs = layers.Input((4,))\n+        outputs = CustomDense(10)(inputs)\n+        model = Model(inputs, outputs)\n+        config = model.get_config()\n+\n+        new_model = Model.from_config(\n+            config, custom_objects={\"CustomDense\": CustomDense}\n+        )\n+        self.assertTrue(isinstance(new_model, Functional))\n\n@@ -136,15 +136,6 @@ class Function(Operation):\n \n         return nest.pack_sequence_as(self._outputs_struct, output_tensors)\n \n-    def get_config(self):\n-        # TODO(fchollet)\n-        raise NotImplementedError\n-\n-    @classmethod\n-    def from_config(self, config):\n-        # TODO(fchollet)\n-        raise NotImplementedError\n-\n     def _assert_input_compatibility(self, inputs):\n         try:\n             nest.assert_same_structure(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b23c06656c9a053e944b78c290acb62f7fc8987c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/4 | Churn Δ: 27 | Churn Cumulative: 808 | Contributors (this commit): 4 | Commits (past 90d): 33 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -229,6 +229,22 @@ class Sequential(Model):\n             f\"Sequential model '{self.name}' has no defined output shape yet.\"\n         )\n \n+    @property\n+    def inputs(self):\n+        if self._functional:\n+            return self._functional.inputs\n+        raise ValueError(\n+            f\"Sequential model '{self.name}' has no defined inputs yet.\"\n+        )\n+\n+    @property\n+    def outputs(self):\n+        if self._functional:\n+            return self._functional.outputs\n+        raise ValueError(\n+            f\"Sequential model '{self.name}' has no defined outputs yet.\"\n+        )\n+\n     def _is_layer_name_unique(self, layer):\n         for ref_layer in self._layers:\n             if layer.name == ref_layer.name and ref_layer is not layer:\n\n@@ -232,3 +232,14 @@ class SequentialTest(testing.TestCase):\n             model, custom_objects={\"DictLayer\": DictLayer}\n         )\n         self.assertLen(revived.layers, 1)\n+\n+    def test_functional_properties(self):\n+        model = Sequential(name=\"seq\")\n+        inputs = Input(shape=(2,))\n+        model.add(inputs)\n+        model.add(layers.Dense(4))\n+\n+        self.assertEqual(model.inputs, [inputs])\n+        self.assertEqual(model.outputs, [model.layers[-1].output])\n+        self.assertEqual(model.input_shape, (None, 2))\n+        self.assertEqual(model.output_shape, (None, 4))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f60334d6b6854fff19f58f1c42c86f354a257d47", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 12 | Methods Changed: 10 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 34 | Churn Cumulative: 1687 | Contributors (this commit): 6 | Commits (past 90d): 45 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -38,7 +38,7 @@ model.predict_on_batch(x)\n inputs = keras_core.Input(shape=(32, 32, 3))\n outputs = layers.Conv2D(filters=10, kernel_size=3)(inputs)\n outputs = layers.GlobalAveragePooling2D()(outputs)\n-outputs = layers.Dense(1)(outputs)\n+outputs = layers.Dense(1, activation=\"sigmoid\")(outputs)\n model = keras_core.Model(inputs, outputs)\n model.compile(\n     loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\", \"accuracy\"]\n\n@@ -58,7 +58,7 @@ def to_torch_dtype(dtype):\n class Variable(KerasVariable):\n     def _initialize(self, value):\n         self._value = torch.nn.Parameter(\n-            convert_to_tensor(value, dtype=self._dtype),\n+            convert_to_tensor(value, dtype=self._dtype).to(get_device()),\n             requires_grad=self.trainable,\n         ).to(get_device())\n \n@@ -84,16 +84,14 @@ class Variable(KerasVariable):\n         return func(*args, **kwargs)\n \n     def __array__(self, dtype=None):\n-        if self.value.requires_grad:\n-            return self.value.detach().__array__(dtype)\n-        return super().__array__(dtype)\n+        return _prepare_for_numpy(self.value).__array__(dtype)\n \n     @property\n     def value(self):\n         value = super().value\n         # Create and use a symbolic tensor stub in symbolic calls.\n         if get_device() == \"meta\" and value.device != \"meta\":\n-            return torch.randn(\n+            return torch.empty(\n                 size=value.shape,\n                 dtype=value.dtype,\n                 device=\"meta\",\n@@ -105,6 +103,7 @@ def convert_to_tensor(x, dtype=None):\n     dtype = to_torch_dtype(dtype or getattr(x, \"dtype\", None))\n     if isinstance(x, Variable):\n         x = x.value\n+        return x\n     if is_tensor(x):\n         if dtype and dtype != x.dtype:\n             x = x.to(dtype)\n@@ -120,15 +119,18 @@ def convert_to_tensor(x, dtype=None):\n     return torch.as_tensor(x, dtype=dtype, device=get_device())\n \n \n-def convert_to_numpy(x):\n-    if isinstance(x, KerasVariable):\n-        x = x.value\n-    if is_tensor(x) and x.is_cuda:\n+def _prepare_for_numpy(x):\n+    if is_tensor(x):\n+        if x.requires_grad:\n+            x = x.detach()\n         # Tensor has to be moved to CPU before converting to numpy.\n+        if x.is_cuda:\n             x = x.cpu()\n-    if is_tensor(x) and x.requires_grad:\n-        return x.detach().numpy()\n-    return np.array(x)\n+    return x\n+\n+\n+def convert_to_numpy(x):\n+    return np.array(_prepare_for_numpy(x))\n \n \n def is_tensor(x):\n@@ -170,7 +172,7 @@ def compute_output_spec(fn, *args, **kwargs):\n                     for i, e in enumerate(shape):\n                         if e is None:\n                             shape[i] = fill_value\n-                return torch.randn(\n+                return torch.empty(\n                     size=shape,\n                     dtype=TORCH_DTYPES[x.dtype],\n                     device=get_device(),\n\n@@ -4,6 +4,7 @@ import numpy as np\n import tensorflow as tf\n import torch\n \n+from keras_core import backend\n from keras_core import callbacks as callbacks_module\n from keras_core import optimizers as optimizers_module\n from keras_core.trainers import trainer as base_trainer\n@@ -386,6 +387,7 @@ class TorchTrainer(base_trainer.Trainer):\n             outputs = append_to_outputs(batch_outputs, outputs)\n             callbacks.on_predict_batch_end(step, {\"outputs\": batch_outputs})\n         callbacks.on_predict_end()\n+        outputs = tf.nest.map_structure(backend.convert_to_numpy, outputs)\n         return tf.__internal__.nest.map_structure_up_to(\n             batch_outputs, np.concatenate, outputs\n         )\n@@ -441,6 +443,6 @@ class TorchTrainer(base_trainer.Trainer):\n         self.make_predict_function()\n         batch_outputs = self.predict_function((x,))\n         batch_outputs = tf.nest.map_structure(\n-            lambda x: np.array(x), batch_outputs\n+            backend.convert_to_numpy, batch_outputs\n         )\n         return batch_outputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed9c20adb55e5facbd8850b55ca7aa638cf8f5da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 127 | Lines Deleted: 30 | Files Changed: 5 | Hunks: 19 | Methods Changed: 21 | Complexity Δ (Sum/Max): 11/4 | Churn Δ: 157 | Churn Cumulative: 2426 | Contributors (this commit): 9 | Commits (past 90d): 98 | Contributors (cumulative): 37 | DMM Complexity: 1.0\n\nDIFF:\n@@ -202,14 +202,12 @@ def scatter_update(inputs, indices, updates):\n     return inputs\n \n \n-def block_update(inputs, start_indices, updates):\n-    update_shape = updates.shape\n-    slices = [\n-        slice(start_index, start_index + update_length)\n-        for start_index, update_length in zip(start_indices, update_shape)\n-    ]\n-    inputs[tuple(slices)] = updates\n-    return inputs\n+def slice(inputs, start_indices, shape):\n+    return jax.lax.dynamic_slice(inputs, start_indices, shape)\n+\n+\n+def slice_update(inputs, start_indices, updates):\n+    return jax.lax.dynamic_update_slice(inputs, updates, start_indices)\n \n \n def while_loop(\n\n@@ -141,7 +141,11 @@ def scatter_update(inputs, indices, updates):\n     return tf.tensor_scatter_nd_update(inputs, indices, updates)\n \n \n-def block_update(inputs, start_indices, updates):\n+def slice(inputs, start_indices, shape):\n+    return tf.slice(inputs, start_indices, shape)\n+\n+\n+def slice_update(inputs, start_indices, updates):\n     return dynamic_update_slice(inputs, updates, start_indices)\n \n \n\n@@ -253,15 +253,30 @@ def scatter_update(inputs, indices, updates):\n     return inputs\n \n \n-def block_update(inputs, start_indices, updates):\n+def slice(inputs, start_indices, shape):\n+    shape_dtype = to_torch_dtype(\"int64\")\n     inputs = convert_to_tensor(inputs)\n-    start_indices = convert_to_tensor(start_indices, dtype=\"int64\")\n+    start_indices = convert_to_tensor(start_indices).to(shape_dtype)\n+    shape = convert_to_tensor(shape).to(shape_dtype)\n+\n+    python_slice = __builtins__[\"slice\"]\n+    slices = [\n+        python_slice(start_index, start_index + length)\n+        for start_index, length in zip(start_indices, shape)\n+    ]\n+    return inputs[slices]\n+\n+\n+def slice_update(inputs, start_indices, updates):\n+    shape_dtype = to_torch_dtype(\"int64\")\n+    inputs = convert_to_tensor(inputs)\n+    start_indices = convert_to_tensor(start_indices).to(shape_dtype)\n     updates = convert_to_tensor(updates)\n \n-    update_shape = updates.shape\n+    python_slice = __builtins__[\"slice\"]\n     slices = [\n-        slice(start_index, start_index + update_length)\n-        for start_index, update_length in zip(start_indices, update_shape)\n+        python_slice(start_index, start_index + update_length)\n+        for start_index, update_length in zip(start_indices, updates.shape)\n     ]\n     inputs[slices] = updates\n     return inputs\n\n@@ -1,7 +1,8 @@\n \"\"\"\n scatter\n scatter_update\n-block_update\n+slice\n+slice_update\n while_loop\n \"\"\"\n \n@@ -87,17 +88,56 @@ def scatter_update(inputs, indices, updates):\n     return backend.core.scatter_update(inputs, indices, updates)\n \n \n-class BlockUpdate(Operation):\n+class Slice(Operation):\n+    def call(self, inputs, start_indices, shape):\n+        return backend.core.slice(inputs, start_indices, shape)\n+\n+    def compute_output_spec(self, inputs, start_indices, shape):\n+        return KerasTensor(shape, dtype=inputs.dtype)\n+\n+\n+@keras_core_export(\"keras_core.operations.slice\")\n+def slice(inputs, start_indices, shape):\n+    \"\"\"Return a slice of an input tensor.\n+\n+    At a high level, this operation is an explicit replacement for array slicing\n+    e.g. `inputs[start_indices: start_indices + shape]`.\n+    Unlike slicing via brackets, this operation will accept tensor start\n+    indices on all backends, which is useful when indices dynamically computed\n+    via other tensor operations.\n+\n+    ```python\n+    inputs = np.zeros((5, 5))\n+    start_indices = np.array([3, 3])\n+    shape = np.array([2, 2])\n+    inputs = keras_core.operations.slice(inputs, start_indices, updates)\n+    ```\n+\n+    Args:\n+        inputs: A tensor, the tensor to be updated.\n+        start_indices: A list/tuple of shape `(inputs.ndim,)`, specifying\n+            the starting indices for updating.\n+        shape: The full shape of the returned slice.\n+\n+    Returns:\n+        A tensor, has the same shape and dtype as `inputs`.\n+    \"\"\"\n+    if any_symbolic_tensors((inputs, start_indices, shape)):\n+        return Slice().symbolic_call(inputs, start_indices, shape)\n+    return backend.core.slice(inputs, start_indices, shape)\n+\n+\n+class SliceUpdate(Operation):\n     def call(self, inputs, start_indices, updates):\n-        return backend.core.block_update(inputs, start_indices, updates)\n+        return backend.core.slice_update(inputs, start_indices, updates)\n \n     def compute_output_spec(self, inputs, start_indices, updates):\n         return KerasTensor(inputs.shape, dtype=inputs.dtype)\n \n \n-@keras_core_export(\"keras_core.operations.block_update\")\n-def block_update(inputs, start_indices, updates):\n-    \"\"\"Update inputs block.\n+@keras_core_export(\"keras_core.operations.slice_update\")\n+def slice_update(inputs, start_indices, updates):\n+    \"\"\"Update an input by slicing in a tensor of updated values.\n \n     At a high level, this operation does\n     `inputs[start_indices: start_indices + updates.shape] = updates`.\n@@ -113,7 +153,7 @@ def block_update(inputs, start_indices, updates):\n     inputs = np.zeros((5, 5))\n     start_indices = [3, 3]\n     updates = np.ones((2, 2))\n-    inputs = keras_core.operations.block_update(inputs, start_indices, updates)\n+    inputs = keras_core.operations.slice_update(inputs, start_indices, updates)\n     ```\n \n     Args:\n@@ -127,8 +167,8 @@ def block_update(inputs, start_indices, updates):\n         A tensor, has the same shape and dtype as `inputs`.\n     \"\"\"\n     if any_symbolic_tensors((inputs, start_indices, updates)):\n-        return BlockUpdate().symbolic_call(inputs, start_indices, updates)\n-    return backend.core.block_update(inputs, start_indices, updates)\n+        return SliceUpdate().symbolic_call(inputs, start_indices, updates)\n+    return backend.core.slice_update(inputs, start_indices, updates)\n \n \n class WhileLoop(Operation):\n\n@@ -32,19 +32,19 @@ class CoreOpsStaticShapeTest(testing.TestCase):\n             core.scatter_update(inputs, indices, updates).shape, (4, 4, 4)\n         )\n \n-    def test_block_update(self):\n+    def test_slice_update(self):\n         inputs = KerasTensor((4, 4))\n         start_indices = KerasTensor((2,))\n         updates = KerasTensor((2, 2))\n         self.assertEqual(\n-            core.block_update(inputs, start_indices, updates).shape, (4, 4)\n+            core.slice_update(inputs, start_indices, updates).shape, (4, 4)\n         )\n \n         inputs = KerasTensor((4, 4, 4))\n         start_indices = KerasTensor((3,))\n         updates = KerasTensor((2, 2, 2))\n         self.assertEqual(\n-            core.block_update(inputs, start_indices, updates).shape, (4, 4, 4)\n+            core.slice_update(inputs, start_indices, updates).shape, (4, 4, 4)\n         )\n \n \n@@ -119,13 +119,53 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         self.assertAllClose(outputs[1, 1, :], [0, 1, 2, 3])\n         self.assertAllClose(outputs[2, 2, :], [3, 2, 1, 0])\n \n-    def test_block_update(self):\n+    def test_slice(self):\n+        # Test 1D.\n+        inputs = np.arange(10)\n+        start_indices = np.array([1])\n+        shape = np.array([4])\n+        self.assertAllClose(\n+            core.slice(inputs, start_indices, shape),\n+            [1, 2, 3, 4],\n+        )\n+\n+        # Test 2D.\n+        inputs = np.broadcast_to(np.arange(10), (4, 10))\n+        start_indices = np.array([1, 1])\n+        shape = np.array([2, 4])\n+        self.assertAllClose(\n+            core.slice(inputs, start_indices, shape),\n+            [[1, 2, 3, 4], [1, 2, 3, 4]],\n+        )\n+\n+        # Test N-D.\n+        inputs = np.broadcast_to(np.arange(10), (4, 4, 4, 10))\n+        start_indices = np.array([1, 1, 1, 1])\n+        shape = np.array([1, 2, 3, 4])\n+        outputs = core.slice(inputs, start_indices, shape)\n+        expected = np.broadcast_to(np.arange(1, 5), (1, 2, 3, 4))\n+        self.assertAllClose(outputs, expected)\n+\n+    def test_dynamic_slice(self):\n+        def cond(index, inputs, sum):\n+            return index < 10\n+\n+        def body(index, inputs, sum):\n+            sum = sum + core.slice(inputs, [index], [1])\n+            index = index + 1\n+            return index, inputs, sum\n+\n+        index, inputs, sum = 0, np.arange(10), np.array([0])\n+        index, inputs, sum = core.while_loop(cond, body, (index, inputs, sum))\n+        self.assertAllClose(sum, [45])\n+\n+    def test_slice_update(self):\n         # Test 1D.\n         inputs = np.array([0, 0, 0, 0, 0, 0, 0, 0])\n         start_indices = [1]\n         updates = np.array([9, 10, 11, 12])\n         self.assertAllClose(\n-            core.block_update(inputs, start_indices, updates),\n+            core.slice_update(inputs, start_indices, updates),\n             [0, 9, 10, 11, 12, 0, 0, 0],\n         )\n \n@@ -134,7 +174,7 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         start_indices = [1, 0]\n         updates = np.array([[2, 2], [2, 2]])\n         self.assertAllClose(\n-            core.block_update(inputs, start_indices, updates),\n+            core.slice_update(inputs, start_indices, updates),\n             [[1, 1], [2, 2], [2, 2]],\n         )\n \n@@ -142,7 +182,7 @@ class CoreOpsCorrectnessTest(testing.TestCase):\n         inputs = np.ones([4, 4, 4, 4])\n         start_indices = [1, 1, 2, 2]\n         updates = np.zeros([2, 2, 2, 2])\n-        outputs = core.block_update(inputs, start_indices, updates)\n+        outputs = core.slice_update(inputs, start_indices, updates)\n         self.assertAllClose(outputs[1:3, 1:3, 2:4, 2:4], np.zeros([2, 2, 2, 2]))\n \n     def test_while_loop(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90388fc609e61013c6bf372a482e87981f97c3b0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 106 | Lines Deleted: 215 | Files Changed: 9 | Hunks: 22 | Methods Changed: 16 | Complexity Δ (Sum/Max): 13/5 | Churn Δ: 321 | Churn Cumulative: 2794 | Contributors (this commit): 10 | Commits (past 90d): 135 | Contributors (cumulative): 43 | DMM Complexity: 1.0\n\nDIFF:\n@@ -15,6 +15,7 @@ from keras_core.backend.common.stateless_scope import in_stateless_scope\n from keras_core.backend.common.variables import AutocastScope\n from keras_core.backend.common.variables import get_autocast_scope\n from keras_core.backend.common.variables import is_float_dtype\n+from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.backend.config import epsilon\n\n@@ -3,6 +3,7 @@ from keras_core.backend.common.variables import AutocastScope\n from keras_core.backend.common.variables import KerasVariable\n from keras_core.backend.common.variables import get_autocast_scope\n from keras_core.backend.common.variables import is_float_dtype\n+from keras_core.backend.common.variables import is_int_dtype\n from keras_core.backend.common.variables import standardize_dtype\n from keras_core.backend.common.variables import standardize_shape\n from keras_core.random import random\n\n@@ -460,6 +460,11 @@ def is_float_dtype(dtype):\n     return dtype.startswith(\"float\") or dtype.startswith(\"bfloat\")\n \n \n+def is_int_dtype(dtype):\n+    dtype = standardize_dtype(dtype)\n+    return dtype.startswith(\"int\") or dtype.startswith(\"uint\")\n+\n+\n def get_autocast_scope():\n     return global_state.get_global_attribute(\"autocast_scope\")\n \n\n@@ -7,26 +7,6 @@ from keras_core.random.seed_generator import make_default_seed\n \n \n def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Draw random samples from a normal (Gaussian) distribution.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`).\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = draw_seed(seed)\n     sample = jax.random.normal(seed, shape=shape, dtype=dtype)\n@@ -34,34 +14,6 @@ def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n \n def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n-    \"\"\"Draw samples from a uniform distribution.\n-\n-    The generated values follow a uniform distribution in the range\n-    `[minval, maxval)`. The lower bound `minval` is included in the range,\n-    while the upper bound `maxval` is excluded.\n-\n-    For floats, the default range is `[0, 1)`.  For ints, at least `maxval`\n-    must be specified explicitly.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        minval: Floats, defaults to 0. Lower bound of the range of\n-            random values to generate (inclusive).\n-        maxval: Floats, defaults to 1. Upper bound of the range of\n-            random values to generate (exclusive).\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = draw_seed(seed)\n     return jax.random.uniform(\n@@ -69,31 +21,14 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n     )\n \n \n+def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n+    seed = draw_seed(seed)\n+    return jax.random.randint(\n+        seed, shape=shape, dtype=dtype, minval=minval, maxval=maxval\n+    )\n+\n+\n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Draw samples from a truncated normal distribution.\n-\n-    The values are drawn from a normal distribution with specified mean and\n-    standard deviation, discarding and re-drawing any samples that are more\n-    than two standard deviations from the mean.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = draw_seed(seed)\n     sample = jax.random.truncated_normal(\n\n@@ -1,5 +1,6 @@\n import tensorflow as tf\n \n+from keras_core.backend.common import standardize_dtype\n from keras_core.backend.config import floatx\n from keras_core.random.seed_generator import SeedGenerator\n from keras_core.random.seed_generator import draw_seed\n@@ -12,26 +13,6 @@ def tf_draw_seed(seed):\n \n \n def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Draw random samples from a normal (Gaussian) distribution.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`).\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = tf_draw_seed(seed)\n     return tf.random.stateless_normal(\n@@ -40,34 +21,6 @@ def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n \n def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n-    \"\"\"Draw samples from a uniform distribution.\n-\n-    The generated values follow a uniform distribution in the range\n-    `[minval, maxval)`. The lower bound `minval` is included in the range,\n-    while the upper bound `maxval` is excluded.\n-\n-    For floats, the default range is `[0, 1)`.  For ints, at least `maxval`\n-    must be specified explicitly.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        minval: Floats, defaults to 0. Lower bound of the range of\n-            random values to generate (inclusive).\n-        maxval: Floats, defaults to 1. Upper bound of the range of\n-            random values to generate (exclusive).\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = tf_draw_seed(seed)\n     return tf.random.stateless_uniform(\n@@ -79,31 +32,22 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n     )\n \n \n+def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n+    intemediate_dtype = dtype\n+    if standardize_dtype(dtype) not in [\"int32\", \"int64\"]:\n+        intemediate_dtype = \"int64\"\n+    seed = tf_draw_seed(seed)\n+    output = tf.random.stateless_uniform(\n+        shape=shape,\n+        minval=minval,\n+        maxval=maxval,\n+        dtype=intemediate_dtype,\n+        seed=seed,\n+    )\n+    return tf.cast(output, dtype)\n+\n+\n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Draw samples from a truncated normal distribution.\n-\n-    The values are drawn from a normal distribution with specified mean and\n-    standard deviation, discarding and re-drawing any samples that are more\n-    than two standard deviations from the mean.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     seed = tf_draw_seed(seed)\n     return tf.random.stateless_truncated_normal(\n\n@@ -18,6 +18,7 @@ TORCH_DTYPES = {\n     \"float32\": torch.float32,\n     \"float64\": torch.float64,\n     \"uint8\": torch.uint8,\n+    \"uint16\": torch.int32,  # TODO: Torch doesn't have `uint16` dtype.\n     \"uint32\": torch.int64,  # TODO: Torch doesn't have `uint32` dtype.\n     \"int8\": torch.int8,\n     \"int16\": torch.int16,\n\n@@ -16,26 +16,6 @@ def torch_seed_generator(seed):\n \n \n def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Produce random number based on the normal distribution.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`).\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     dtype = to_torch_dtype(dtype)\n     generator = torch_seed_generator(seed)\n@@ -45,31 +25,6 @@ def normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n \n \n def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n-    \"\"\"Produce random number based on the uniform distribution.\n-\n-    The generated values follow a uniform distribution in the range\n-    `[minval, maxval)`. The lower bound `minval` is included in the range,\n-    while the upper bound `maxval` is excluded.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        minval: Floats, defaults to 0. Lower bound of the range of\n-            random values to generate (inclusive).\n-        maxval: Floats, defaults to 1. Upper bound of the range of\n-            random values to generate (exclusive).\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     dtype = dtype or floatx()\n     dtype = to_torch_dtype(dtype)\n     generator = torch_seed_generator(seed)\n@@ -78,31 +33,15 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n     ) + minval\n \n \n+def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n+    dtype = to_torch_dtype(dtype)\n+    generator = torch_seed_generator(seed)\n+    return torch.randint(\n+        low=minval, high=maxval, size=shape, generator=generator, dtype=dtype\n+    )\n+\n+\n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n-    \"\"\"Produce random number based on the truncated normal distribution.\n-\n-    The values are drawn from a normal distribution with specified mean and\n-    standard deviation, discarding and re-drawing any samples that are more\n-    than two standard deviations from the mean.\n-\n-    Args:\n-        shape: The shape of the random values to generate.\n-        mean: Floats, defaults to 0. Mean of the random values to generate.\n-        stddev: Floats, defaults to 1. Standard deviation of the random values\n-            to generate.\n-        dtype: Optional dtype of the tensor. Only floating point types are\n-            supported. If not specified, `keras.backend.floatx()` is used,\n-            which defaults to `float32` unless you configured it otherwise (via\n-            `keras.backend.set_floatx(float_dtype)`)\n-        seed: A Python integer or instance of\n-            `keras_core.backend.SeedGenerator`.\n-            Used to make the behavior of the initializer\n-            deterministic. Note that an initializer seeded with an integer\n-            or None (unseeded) will produce the same random values\n-            across multiple calls. To get different random values\n-            across multiple calls, use as seed an instance\n-            of `keras_core.backend.SeedGenerator`.\n-    \"\"\"\n     # Take a larger standard normal dist, discard values outside 2 * stddev\n     # Offset by mean and stddev\n     x = normal(shape + (4,), mean=0, stddev=1, dtype=dtype, seed=seed)\n\n@@ -37,8 +37,7 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n     `[minval, maxval)`. The lower bound `minval` is included in the range,\n     while the upper bound `maxval` is excluded.\n \n-    For floats, the default range is `[0, 1)`.  For ints, at least `maxval`\n-    must be specified explicitly.\n+    `dtype` must be a floating point type, the default range is `[0, 1)`.\n \n     Args:\n         shape: The shape of the random values to generate.\n@@ -59,11 +58,55 @@ def uniform(shape, minval=0.0, maxval=1.0, dtype=None, seed=None):\n             across multiple calls, use as seed an instance\n             of `keras_core.random.SeedGenerator`.\n     \"\"\"\n+    if dtype and not backend.is_float_dtype(dtype):\n+        raise ValueError(\n+            \"`keras_core.random.uniform` requires a floating point `dtype`. \"\n+            f\"Received: dtype={dtype} \"\n+        )\n     return backend.random.uniform(\n         shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed\n     )\n \n \n+@keras_core_export(\"keras_core.random.randint\")\n+def randint(shape, minval, maxval, dtype=\"int32\", seed=None):\n+    \"\"\"Draw random integers from a uniform distribution.\n+\n+    The generated values follow a uniform distribution in the range\n+    `[minval, maxval)`. The lower bound `minval` is included in the range,\n+    while the upper bound `maxval` is excluded.\n+\n+    `dtype` must be an integer type.\n+\n+    Args:\n+        shape: The shape of the random values to generate.\n+        minval: Floats, defaults to 0. Lower bound of the range of\n+            random values to generate (inclusive).\n+        maxval: Floats, defaults to 1. Upper bound of the range of\n+            random values to generate (exclusive).\n+        dtype: Optional dtype of the tensor. Only integer types are\n+            supported. If not specified, `keras_core.config.floatx()` is used,\n+            which defaults to `float32` unless you configured it otherwise (via\n+            `keras_core.config.set_floatx(float_dtype)`)\n+        seed: A Python integer or instance of\n+            `keras_core.random.SeedGenerator`.\n+            Used to make the behavior of the initializer\n+            deterministic. Note that an initializer seeded with an integer\n+            or None (unseeded) will produce the same random values\n+            across multiple calls. To get different random values\n+            across multiple calls, use as seed an instance\n+            of `keras_core.random.SeedGenerator`.\n+    \"\"\"\n+    if dtype and not backend.is_int_dtype(dtype):\n+        raise ValueError(\n+            \"`keras_core.random.randint` requires an integer `dtype`. \"\n+            f\"Received: dtype={dtype} \"\n+        )\n+    return backend.random.randint(\n+        shape, minval=minval, maxval=maxval, dtype=dtype, seed=seed\n+    )\n+\n+\n @keras_core_export(\"keras_core.random.truncated_normal\")\n def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     \"\"\"Draw samples from a truncated normal distribution.\n\n@@ -3,6 +3,7 @@ import pytest\n from absl.testing import parameterized\n \n import keras_core\n+from keras_core import backend\n from keras_core import testing\n from keras_core.operations import numpy as knp\n from keras_core.random import random\n@@ -39,6 +40,27 @@ class RandomTest(testing.TestCase, parameterized.TestCase):\n         self.assertLessEqual(knp.max(res), maxval)\n         self.assertGreaterEqual(knp.max(res), minval)\n \n+    @parameterized.parameters(\n+        {\"seed\": 10, \"shape\": (5,), \"min\": 0, \"max\": 10, \"dtype\": \"uint16\"},\n+        {\"seed\": 10, \"shape\": (2, 3), \"min\": 0, \"max\": 10, \"dtype\": \"uint32\"},\n+        {\"seed\": 10, \"shape\": (2, 3, 4), \"min\": 0, \"max\": 2, \"dtype\": \"int8\"},\n+        {\"seed\": 10, \"shape\": (2, 3), \"min\": -1, \"max\": 1, \"dtype\": \"int16\"},\n+        {\"seed\": 10, \"shape\": (2, 3), \"min\": 1, \"max\": 3, \"dtype\": \"int32\"},\n+    )\n+    def test_randint(self, seed, shape, min, max, dtype):\n+        np.random.seed(seed)\n+        np_res = np.random.randint(low=min, high=max, size=shape)\n+        res = random.randint(\n+            shape, minval=min, maxval=max, seed=seed, dtype=dtype\n+        )\n+        self.assertEqual(res.shape, shape)\n+        self.assertEqual(res.shape, np_res.shape)\n+        self.assertLessEqual(knp.max(res), max)\n+        self.assertGreaterEqual(knp.max(res), min)\n+        # Torch has incomplete dtype support for uints; will remap some dtypes.\n+        if keras_core.backend.backend() != \"torch\":\n+            self.assertEqual(backend.standardize_dtype(res.dtype), dtype)\n+\n     @parameterized.parameters(\n         {\"seed\": 10, \"shape\": (5,), \"mean\": 0, \"stddev\": 1},\n         {\"seed\": 10, \"shape\": (2, 3), \"mean\": 0, \"stddev\": 1},\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
