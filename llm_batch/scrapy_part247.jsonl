{"custom_id": "scrapy#e65f7e0c91ccb16525bb318cb50339979387fdbf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 25 | Churn Cumulative: 129 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -22,6 +22,7 @@ from scrapy import signals\n from scrapy.utils.trackref import print_live_refs\n from scrapy.utils.engine import print_engine_status\n from scrapy.utils.reactor import listen_tcp\n+from scrapy.utils.decorators import defers\n \n try:\n     import guppy\n@@ -49,6 +50,8 @@ class TelnetConsole(protocol.ServerFactory):\n         self.noisy = False\n         self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n         self.host = crawler.settings['TELNETCONSOLE_HOST']\n+        self.username = crawler.settings.get('TELNETCONSOLE_USERNAME', 'scrapy')\n+        self.password = crawler.settings.get('TELNETCONSOLE_PASSWORD', 'scrapy')\n         self.crawler.signals.connect(self.start_listening, signals.engine_started)\n         self.crawler.signals.connect(self.stop_listening, signals.engine_stopped)\n \n@@ -67,9 +70,25 @@ class TelnetConsole(protocol.ServerFactory):\n         self.port.stopListening()\n \n     def protocol(self):\n-        telnet_vars = self._get_telnet_vars()\n-        return telnet.TelnetTransport(telnet.TelnetBootstrapProtocol,\n-            insults.ServerProtocol, manhole.Manhole, telnet_vars)\n+        class Portal:\n+            \"\"\"An implementation of IPortal\"\"\"\n+            @defers\n+            def login(self_, credentials, mind, *interfaces):\n+                if not (credentials.username == self.username\n+                        and credentials.checkPassword(self.password)):\n+                    raise ValueError(\"Invalid credentials\")\n+\n+                protocol = telnet.TelnetBootstrapProtocol(\n+                    insults.ServerProtocol,\n+                    manhole.Manhole,\n+                    self._get_telnet_vars()\n+                )\n+                return (interfaces[0], protocol, lambda: None)\n+\n+        return telnet.TelnetTransport(\n+            telnet.AuthenticatingTelnetProtocol,\n+            Portal()\n+        )\n \n     def _get_telnet_vars(self):\n         # Note: if you add entries here also update topics/telnetconsole.rst\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#eb64214c8a0053627e625debdb55373c8e17ef1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 665 | Contributors (this commit): 40 | Commits (past 90d): 5 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -50,8 +50,8 @@ class TelnetConsole(protocol.ServerFactory):\n         self.noisy = False\n         self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n         self.host = crawler.settings['TELNETCONSOLE_HOST']\n-        self.username = crawler.settings.get('TELNETCONSOLE_USERNAME', 'scrapy')\n-        self.password = crawler.settings.get('TELNETCONSOLE_PASSWORD', 'scrapy')\n+        self.username = crawler.settings['TELNETCONSOLE_USERNAME']\n+        self.password = crawler.settings['TELNETCONSOLE_PASSWORD']\n         self.crawler.signals.connect(self.start_listening, signals.engine_started)\n         self.crawler.signals.connect(self.stop_listening, signals.engine_stopped)\n \n\n@@ -277,6 +277,8 @@ USER_AGENT = 'Scrapy/%s (+https://scrapy.org)' % import_module('scrapy').__versi\n TELNETCONSOLE_ENABLED = 1\n TELNETCONSOLE_PORT = [6023, 6073]\n TELNETCONSOLE_HOST = '127.0.0.1'\n+TELNETCONSOLE_USERNAME = 'scrapy'\n+TELNETCONSOLE_PASSWORD = 'scrapy'\n \n SPIDER_CONTRACTS = {}\n SPIDER_CONTRACTS_BASE = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#25ac4691b414e7c18a4e9dec3bb6a85563d2488d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 460 | Contributors (this commit): 16 | Commits (past 90d): 1 | Contributors (cumulative): 16 | DMM Complexity: None\n\nDIFF:\n@@ -71,7 +71,7 @@ setup(\n         'pyOpenSSL',\n         'cssselect>=0.9',\n         'six>=1.5.2',\n-        'parsel>=1.4',\n+        'parsel>=1.5',\n         'PyDispatcher>=2.0.5',\n         'service_identity',\n     ],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#53da56c8dcd6edba12284ed5d125ddd1dcf6f99c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 63 | Files Changed: 7 | Hunks: 37 | Methods Changed: 21 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 129 | Churn Cumulative: 2794 | Contributors (this commit): 24 | Commits (past 90d): 7 | Contributors (cumulative): 50 | DMM Complexity: 1.0\n\nDIFF:\n@@ -35,7 +35,7 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_response_selector_html(self):\n-        xpath = 'response.xpath(\"//p[@class=\\'one\\']/text()\").extract()[0]'\n+        xpath = 'response.xpath(\"//p[@class=\\'one\\']/text()\").get()'\n         _, out, _ = yield self.execute([self.url('/html'), '-c', xpath])\n         self.assertEqual(out.strip(), b'Works')\n \n\n@@ -336,11 +336,11 @@ class TextResponseTest(BaseResponseTest):\n         self.assertIs(response.selector.response, response)\n \n         self.assertEqual(\n-            response.selector.xpath(\"//title/text()\").extract(),\n+            response.selector.xpath(\"//title/text()\").getall(),\n             [u'Some page']\n         )\n         self.assertEqual(\n-            response.selector.css(\"title::text\").extract(),\n+            response.selector.css(\"title::text\").getall(),\n             [u'Some page']\n         )\n         self.assertEqual(\n@@ -353,12 +353,12 @@ class TextResponseTest(BaseResponseTest):\n         response = self.response_class(\"http://www.example.com\", body=body)\n \n         self.assertEqual(\n-            response.xpath(\"//title/text()\").extract(),\n-            response.selector.xpath(\"//title/text()\").extract(),\n+            response.xpath(\"//title/text()\").getall(),\n+            response.selector.xpath(\"//title/text()\").getall(),\n         )\n         self.assertEqual(\n-            response.css(\"title::text\").extract(),\n-            response.selector.css(\"title::text\").extract(),\n+            response.css(\"title::text\").getall(),\n+            response.selector.css(\"title::text\").getall(),\n         )\n \n     def test_selector_shortcuts_kwargs(self):\n@@ -366,13 +366,13 @@ class TextResponseTest(BaseResponseTest):\n         response = self.response_class(\"http://www.example.com\", body=body)\n \n         self.assertEqual(\n-            response.xpath(\"normalize-space(//p[@class=$pclass])\", pclass=\"content\").extract(),\n-            response.xpath(\"normalize-space(//p[@class=\\\"content\\\"])\").extract(),\n+            response.xpath(\"normalize-space(//p[@class=$pclass])\", pclass=\"content\").getall(),\n+            response.xpath(\"normalize-space(//p[@class=\\\"content\\\"])\").getall(),\n         )\n         self.assertEqual(\n             response.xpath(\"//title[count(following::p[@class=$pclass])=$pcount]/text()\",\n-                pclass=\"content\", pcount=1).extract(),\n-            response.xpath(\"//title[count(following::p[@class=\\\"content\\\"])=1]/text()\").extract(),\n+                pclass=\"content\", pcount=1).getall(),\n+            response.xpath(\"//title[count(following::p[@class=\\\"content\\\"])=1]/text()\").getall(),\n         )\n \n     def test_urljoin_with_base_url(self):\n@@ -562,7 +562,7 @@ class XmlResponseTest(TextResponseTest):\n         self.assertIs(response.selector.response, response)\n \n         self.assertEqual(\n-            response.selector.xpath(\"//elem/text()\").extract(),\n+            response.selector.xpath(\"//elem/text()\").getall(),\n             [u'value']\n         )\n \n@@ -571,8 +571,8 @@ class XmlResponseTest(TextResponseTest):\n         response = self.response_class(\"http://www.example.com\", body=body)\n \n         self.assertEqual(\n-            response.xpath(\"//elem/text()\").extract(),\n-            response.selector.xpath(\"//elem/text()\").extract(),\n+            response.xpath(\"//elem/text()\").getall(),\n+            response.selector.xpath(\"//elem/text()\").getall(),\n         )\n \n     def test_selector_shortcuts_kwargs(self):\n@@ -583,12 +583,12 @@ class XmlResponseTest(TextResponseTest):\n         response = self.response_class(\"http://www.example.com\", body=body)\n \n         self.assertEqual(\n-            response.xpath(\"//s:elem/text()\", namespaces={'s': 'http://scrapy.org'}).extract(),\n-            response.selector.xpath(\"//s:elem/text()\", namespaces={'s': 'http://scrapy.org'}).extract(),\n+            response.xpath(\"//s:elem/text()\", namespaces={'s': 'http://scrapy.org'}).getall(),\n+            response.selector.xpath(\"//s:elem/text()\", namespaces={'s': 'http://scrapy.org'}).getall(),\n         )\n \n         response.selector.register_namespace('s2', 'http://scrapy.org')\n         self.assertEqual(\n-            response.xpath(\"//s1:elem/text()\", namespaces={'s1': 'http://scrapy.org'}).extract(),\n-            response.selector.xpath(\"//s2:elem/text()\").extract(),\n+            response.xpath(\"//s1:elem/text()\", namespaces={'s1': 'http://scrapy.org'}).getall(),\n+            response.selector.xpath(\"//s2:elem/text()\").getall(),\n         )\n\n@@ -634,7 +634,7 @@ class SubselectorLoaderTest(unittest.TestCase):\n         nl = l.nested_xpath(\"//header\")\n         nl.add_xpath('name', 'div/text()')\n         nl.add_css('name_div', '#id')\n-        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n+        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').getall())\n \n         self.assertEqual(l.get_output_value('name'), [u'marta'])\n         self.assertEqual(l.get_output_value('name_div'), [u'<div id=\"id\">marta</div>'])\n@@ -649,7 +649,7 @@ class SubselectorLoaderTest(unittest.TestCase):\n         nl = l.nested_css(\"header\")\n         nl.add_xpath('name', 'div/text()')\n         nl.add_css('name_div', '#id')\n-        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').extract())\n+        nl.add_value('name_value', nl.selector.xpath('div[@id = \"id\"]/text()').getall())\n \n         self.assertEqual(l.get_output_value('name'), [u'marta'])\n         self.assertEqual(l.get_output_value('name_div'), [u'<div id=\"id\">marta</div>'])\n\n@@ -29,7 +29,7 @@ class MediaDownloadSpider(SimpleSpider):\n                     for href in response.xpath('''\n                         //table[thead/tr/th=\"Filename\"]\n                             /tbody//a/@href\n-                        ''').extract()],\n+                        ''').getall()],\n         }\n         yield item\n \n\n@@ -20,17 +20,17 @@ class SelectorTestCase(unittest.TestCase):\n         for x in xl:\n             assert isinstance(x, Selector)\n \n-        self.assertEqual(sel.xpath('//input').extract(),\n-                         [x.extract() for x in sel.xpath('//input')])\n+        self.assertEqual(sel.xpath('//input').getall(),\n+                         [x.get() for x in sel.xpath('//input')])\n \n-        self.assertEqual([x.extract() for x in sel.xpath(\"//input[@name='a']/@name\")],\n+        self.assertEqual([x.get() for x in sel.xpath(\"//input[@name='a']/@name\")],\n                          [u'a'])\n-        self.assertEqual([x.extract() for x in sel.xpath(\"number(concat(//input[@name='a']/@value, //input[@name='b']/@value))\")],\n+        self.assertEqual([x.get() for x in sel.xpath(\"number(concat(//input[@name='a']/@value, //input[@name='b']/@value))\")],\n                          [u'12.0'])\n \n-        self.assertEqual(sel.xpath(\"concat('xpath', 'rules')\").extract(),\n+        self.assertEqual(sel.xpath(\"concat('xpath', 'rules')\").getall(),\n                          [u'xpathrules'])\n-        self.assertEqual([x.extract() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n+        self.assertEqual([x.get() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n                          [u'12'])\n \n     def test_root_base_url(self):\n@@ -60,12 +60,12 @@ class SelectorTestCase(unittest.TestCase):\n         text = b'<div><img src=\"a.jpg\"><p>Hello</div>'\n         sel = Selector(XmlResponse('http://example.com', body=text, encoding='utf-8'))\n         self.assertEqual(sel.type, 'xml')\n-        self.assertEqual(sel.xpath(\"//div\").extract(),\n+        self.assertEqual(sel.xpath(\"//div\").getall(),\n                          [u'<div><img src=\"a.jpg\"><p>Hello</p></img></div>'])\n \n         sel = Selector(HtmlResponse('http://example.com', body=text, encoding='utf-8'))\n         self.assertEqual(sel.type, 'html')\n-        self.assertEqual(sel.xpath(\"//div\").extract(),\n+        self.assertEqual(sel.xpath(\"//div\").getall(),\n                          [u'<div><img src=\"a.jpg\"><p>Hello</p></div>'])\n \n     def test_http_header_encoding_precedence(self):\n@@ -84,15 +84,15 @@ class SelectorTestCase(unittest.TestCase):\n         headers = {'Content-Type': ['text/html; charset=utf-8']}\n         response = HtmlResponse(url=\"http://example.com\", headers=headers, body=html_utf8)\n         x = Selector(response)\n-        self.assertEqual(x.xpath(\"//span[@id='blank']/text()\").extract(),\n+        self.assertEqual(x.xpath(\"//span[@id='blank']/text()\").getall(),\n                           [u'\\xa3'])\n \n     def test_badly_encoded_body(self):\n         # \\xe9 alone isn't valid utf8 sequence\n-        r1 = TextResponse('http://www.example.com', \\\n-                          body=b'<html><p>an Jos\\xe9 de</p><html>', \\\n+        r1 = TextResponse('http://www.example.com',\n+                          body=b'<html><p>an Jos\\xe9 de</p><html>',\n                           encoding='utf-8')\n-        Selector(r1).xpath('//text()').extract()\n+        Selector(r1).xpath('//text()').getall()\n \n     def test_weakref_slots(self):\n         \"\"\"Check that classes are using slots and are weak-referenceable\"\"\"\n\n@@ -147,10 +147,10 @@ class XMLFeedSpiderTest(SpiderTest):\n \n             def parse_node(self, response, selector):\n                 yield {\n-                    'loc': selector.xpath('a:loc/text()').extract(),\n-                    'updated': selector.xpath('b:updated/text()').extract(),\n-                    'other': selector.xpath('other/@value').extract(),\n-                    'custom': selector.xpath('other/@b:custom').extract(),\n+                    'loc': selector.xpath('a:loc/text()').getall(),\n+                    'updated': selector.xpath('b:updated/text()').getall(),\n+                    'other': selector.xpath('other/@value').getall(),\n+                    'custom': selector.xpath('other/@b:custom').getall(),\n                 }\n \n         for iterator in ('iternodes', 'xml'):\n\n@@ -30,10 +30,13 @@ class XmliterTestCase(unittest.TestCase):\n         response = XmlResponse(url=\"http://example.com\", body=body)\n         attrs = []\n         for x in self.xmliter(response, 'product'):\n-            attrs.append((x.xpath(\"@id\").extract(), x.xpath(\"name/text()\").extract(), x.xpath(\"./type/text()\").extract()))\n+            attrs.append((\n+                x.attrib['id'],\n+                x.xpath(\"name/text()\").extract(),\n+                x.xpath(\"./type/text()\").extract()))\n \n         self.assertEqual(attrs,\n-                         [(['001'], ['Name 1'], ['Type 1']), (['002'], ['Name 2'], ['Type 2'])])\n+                         [('001', ['Name 1'], ['Type 1']), ('002', ['Name 2'], ['Type 2'])])\n \n     def test_xmliter_unusual_node(self):\n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n@@ -43,7 +46,7 @@ class XmliterTestCase(unittest.TestCase):\n             </root>\n         \"\"\"\n         response = XmlResponse(url=\"http://example.com\", body=body)\n-        nodenames = [e.xpath('name()').extract()\n+        nodenames = [e.xpath('name()').getall()\n                  for e in self.xmliter(response, 'matchme...')]\n         self.assertEqual(nodenames, [['matchme...']])\n \n@@ -93,19 +96,19 @@ class XmliterTestCase(unittest.TestCase):\n \n             attrs = []\n             for x in self.xmliter(r, u'þingflokkur'):\n-                attrs.append((x.xpath('@id').extract(),\n-                              x.xpath(u'./skammstafanir/stuttskammstöfun/text()').extract(),\n-                              x.xpath(u'./tímabil/fyrstaþing/text()').extract()))\n+                attrs.append((x.attrib['id'],\n+                              x.xpath(u'./skammstafanir/stuttskammstöfun/text()').getall(),\n+                              x.xpath(u'./tímabil/fyrstaþing/text()').getall()))\n \n             self.assertEqual(attrs,\n-                             [([u'26'], [u'-'], [u'80']),\n-                              ([u'21'], [u'Ab'], [u'76']),\n-                              ([u'27'], [u'A'], [u'27'])])\n+                             [(u'26', [u'-'], [u'80']),\n+                              (u'21', [u'Ab'], [u'76']),\n+                              (u'27', [u'A'], [u'27'])])\n \n     def test_xmliter_text(self):\n         body = u\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><products><product>one</product><product>two</product></products>\"\"\"\n \n-        self.assertEqual([x.xpath(\"text()\").extract() for x in self.xmliter(body, 'product')],\n+        self.assertEqual([x.xpath(\"text()\").getall() for x in self.xmliter(body, 'product')],\n                          [[u'one'], [u'two']])\n \n     def test_xmliter_namespaces(self):\n@@ -132,15 +135,15 @@ class XmliterTestCase(unittest.TestCase):\n \n         node = next(my_iter)\n         node.register_namespace('g', 'http://base.google.com/ns/1.0')\n-        self.assertEqual(node.xpath('title/text()').extract(), ['Item 1'])\n-        self.assertEqual(node.xpath('description/text()').extract(), ['This is item 1'])\n-        self.assertEqual(node.xpath('link/text()').extract(), ['http://www.mydummycompany.com/items/1'])\n-        self.assertEqual(node.xpath('g:image_link/text()').extract(), ['http://www.mydummycompany.com/images/item1.jpg'])\n-        self.assertEqual(node.xpath('g:id/text()').extract(), ['ITEM_1'])\n-        self.assertEqual(node.xpath('g:price/text()').extract(), ['400'])\n-        self.assertEqual(node.xpath('image_link/text()').extract(), [])\n-        self.assertEqual(node.xpath('id/text()').extract(), [])\n-        self.assertEqual(node.xpath('price/text()').extract(), [])\n+        self.assertEqual(node.xpath('title/text()').getall(), ['Item 1'])\n+        self.assertEqual(node.xpath('description/text()').getall(), ['This is item 1'])\n+        self.assertEqual(node.xpath('link/text()').getall(), ['http://www.mydummycompany.com/items/1'])\n+        self.assertEqual(node.xpath('g:image_link/text()').getall(), ['http://www.mydummycompany.com/images/item1.jpg'])\n+        self.assertEqual(node.xpath('g:id/text()').getall(), ['ITEM_1'])\n+        self.assertEqual(node.xpath('g:price/text()').getall(), ['400'])\n+        self.assertEqual(node.xpath('image_link/text()').getall(), [])\n+        self.assertEqual(node.xpath('id/text()').getall(), [])\n+        self.assertEqual(node.xpath('price/text()').getall(), [])\n \n     def test_xmliter_exception(self):\n         body = u\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><products><product>one</product><product>two</product></products>\"\"\"\n@@ -159,7 +162,7 @@ class XmliterTestCase(unittest.TestCase):\n         body = b'<?xml version=\"1.0\" encoding=\"ISO-8859-9\"?>\\n<xml>\\n    <item>Some Turkish Characters \\xd6\\xc7\\xde\\xdd\\xd0\\xdc \\xfc\\xf0\\xfd\\xfe\\xe7\\xf6</item>\\n</xml>\\n\\n'\n         response = XmlResponse('http://www.example.com', body=body)\n         self.assertEqual(\n-            next(self.xmliter(response, 'item')).extract(),\n+            next(self.xmliter(response, 'item')).get(),\n             u'<item>Some Turkish Characters \\xd6\\xc7\\u015e\\u0130\\u011e\\xdc \\xfc\\u011f\\u0131\\u015f\\xe7\\xf6</item>'\n         )\n \n@@ -192,9 +195,9 @@ class LxmlXmliterTestCase(XmliterTestCase):\n \n         namespace_iter = self.xmliter(response, 'image_link', 'http://base.google.com/ns/1.0')\n         node = next(namespace_iter)\n-        self.assertEqual(node.xpath('text()').extract(), ['http://www.mydummycompany.com/images/item1.jpg'])\n+        self.assertEqual(node.xpath('text()').getall(), ['http://www.mydummycompany.com/images/item1.jpg'])\n         node = next(namespace_iter)\n-        self.assertEqual(node.xpath('text()').extract(), ['http://www.mydummycompany.com/images/item2.jpg'])\n+        self.assertEqual(node.xpath('text()').getall(), ['http://www.mydummycompany.com/images/item2.jpg'])\n \n     def test_xmliter_namespaces_prefix(self):\n         body = b\"\"\"\\\n@@ -219,14 +222,14 @@ class LxmlXmliterTestCase(XmliterTestCase):\n         my_iter = self.xmliter(response, 'table', 'http://www.w3.org/TR/html4/', 'h')\n \n         node = next(my_iter)\n-        self.assertEqual(len(node.xpath('h:tr/h:td').extract()), 2)\n-        self.assertEqual(node.xpath('h:tr/h:td[1]/text()').extract(), ['Apples'])\n-        self.assertEqual(node.xpath('h:tr/h:td[2]/text()').extract(), ['Bananas'])\n+        self.assertEqual(len(node.xpath('h:tr/h:td').getall()), 2)\n+        self.assertEqual(node.xpath('h:tr/h:td[1]/text()').getall(), ['Apples'])\n+        self.assertEqual(node.xpath('h:tr/h:td[2]/text()').getall(), ['Bananas'])\n \n         my_iter = self.xmliter(response, 'table', 'http://www.w3schools.com/furniture', 'f')\n \n         node = next(my_iter)\n-        self.assertEqual(node.xpath('f:name/text()').extract(), ['African Coffee Table'])\n+        self.assertEqual(node.xpath('f:name/text()').getall(), ['African Coffee Table'])\n \n     def test_xmliter_objtype_exception(self):\n         i = self.xmliter(42, 'product')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#460f0f045141f73dcc6d7a2309b7e2f0c2a492b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 4 | Churn Cumulative: 79 | Contributors (this commit): 5 | Commits (past 90d): 1 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -181,7 +181,7 @@ class ItemLoader(object):\n     def _get_xpathvalues(self, xpaths, **kw):\n         self._check_selector_method()\n         xpaths = arg_to_iter(xpaths)\n-        return flatten(self.selector.xpath(xpath).extract() for xpath in xpaths)\n+        return flatten(self.selector.xpath(xpath).getall() for xpath in xpaths)\n \n     def add_css(self, field_name, css, *processors, **kw):\n         values = self._get_cssvalues(css, **kw)\n@@ -198,6 +198,6 @@ class ItemLoader(object):\n     def _get_cssvalues(self, csss, **kw):\n         self._check_selector_method()\n         csss = arg_to_iter(csss)\n-        return flatten(self.selector.css(css).extract() for css in csss)\n+        return flatten(self.selector.css(css).getall() for css in csss)\n \n XPathItemLoader = create_deprecated_class('XPathItemLoader', ItemLoader)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#12e42bbe06bea5a0f86e95630b184e86b41c95c7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 75 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -141,7 +141,7 @@ class SgmlLinkExtractor(FilteringLinkExtractor):\n             base_url = get_base_url(response)\n             body = u''.join(f\n                             for x in self.restrict_xpaths\n-                            for f in response.xpath(x).extract()\n+                            for f in response.xpath(x).getall()\n                             ).encode(response.encoding, errors='xmlcharrefreplace')\n         else:\n             body = response.body\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#dc95ecbe25a5921f902fbccc93d50f7682cefda2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 33 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 33 | Churn Cumulative: 621 | Contributors (this commit): 9 | Commits (past 90d): 1 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -27,6 +27,10 @@ def _response_from_text(text, st):\n \n \n class SelectorList(_ParselSelector.selectorlist_cls, object_ref):\n+    \"\"\"\n+    The :class:`SelectorList` class is a subclass of the builtin ``list``\n+    class, which provides a few additional methods.\n+    \"\"\"\n     @deprecated(use_instead='.extract()')\n     def extract_unquoted(self):\n         return [x.extract_unquoted() for x in self]\n@@ -41,6 +45,35 @@ class SelectorList(_ParselSelector.selectorlist_cls, object_ref):\n \n \n class Selector(_ParselSelector, object_ref):\n+    \"\"\"\n+    An instance of :class:`Selector` is a wrapper over response to select\n+    certain parts of its content.\n+\n+    ``response`` is an :class:`~scrapy.http.HtmlResponse` or an\n+    :class:`~scrapy.http.XmlResponse` object that will be used for selecting\n+    and extracting data.\n+\n+    ``text`` is a unicode string or utf-8 encoded text for cases when a\n+    ``response`` isn't available. Using ``text`` and ``response`` together is\n+    undefined behavior.\n+\n+    ``type`` defines the selector type, it can be ``\"html\"``, ``\"xml\"``\n+    or ``None`` (default).\n+\n+    If ``type`` is ``None``, the selector automatically chooses the best type\n+    based on ``response`` type (see below), or defaults to ``\"html\"`` in case it\n+    is used together with ``text``.\n+\n+    If ``type`` is ``None`` and a ``response`` is passed, the selector type is\n+    inferred from the response type as follows:\n+\n+    * ``\"html\"`` for :class:`~scrapy.http.HtmlResponse` type\n+    * ``\"xml\"`` for :class:`~scrapy.http.XmlResponse` type\n+    * ``\"html\"`` for anything else\n+\n+    Otherwise, if ``type`` is set, the selector type will be forced and no\n+    detection will occur.\n+    \"\"\"\n \n     __slots__ = ['response']\n     selectorlist_cls = SelectorList\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#2c3b2158c99953823500f275ccc5206c11c9a811", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 277 | Contributors (this commit): 10 | Commits (past 90d): 2 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -32,8 +32,8 @@ class XmliterTestCase(unittest.TestCase):\n         for x in self.xmliter(response, 'product'):\n             attrs.append((\n                 x.attrib['id'],\n-                x.xpath(\"name/text()\").extract(),\n-                x.xpath(\"./type/text()\").extract()))\n+                x.xpath(\"name/text()\").getall(),\n+                x.xpath(\"./type/text()\").getall()))\n \n         self.assertEqual(attrs,\n                          [('001', ['Name 1'], ['Type 1']), ('002', ['Name 2'], ['Type 2'])])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#37cfb49805c86168af7a831fc33ec4aeb83e53da", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 79 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 9 | Complexity Δ (Sum/Max): 7/5 | Churn Δ: 86 | Churn Cumulative: 751 | Contributors (this commit): 41 | Commits (past 90d): 8 | Contributors (cumulative): 48 | DMM Complexity: 0.4444444444444444\n\nDIFF:\n@@ -7,6 +7,8 @@ See documentation in docs/topics/telnetconsole.rst\n import pprint\n import logging\n import traceback\n+import binascii\n+import os\n \n from twisted.internet import protocol\n try:\n@@ -50,8 +52,21 @@ class TelnetConsole(protocol.ServerFactory):\n         self.noisy = False\n         self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n         self.host = crawler.settings['TELNETCONSOLE_HOST']\n-        self.username = crawler.settings['TELNETCONSOLE_USERNAME']\n-        self.password = crawler.settings['TELNETCONSOLE_PASSWORD']\n+\n+        username = crawler.settings.get('TELNETCONSOLE_USERNAME', None)\n+        if username:\n+            self.username = username.encode('utf8')\n+        else:\n+            self.username = binascii.hexlify(os.urandom(8))\n+\n+        password = crawler.settings.get('TELNETCONSOLE_PASSWORD', None)\n+        if password:\n+            self.password = password.encode('utf8')\n+        else:\n+            self.password = binascii.hexlify(os.urandom(8))\n+\n+        logger.info('Telnet Username: %s' % self.username)\n+        logger.info('Telnet Password: %s' % self.password)\n         self.crawler.signals.connect(self.start_listening, signals.engine_started)\n         self.crawler.signals.connect(self.stop_listening, signals.engine_stopped)\n \n@@ -74,8 +89,8 @@ class TelnetConsole(protocol.ServerFactory):\n             \"\"\"An implementation of IPortal\"\"\"\n             @defers\n             def login(self_, credentials, mind, *interfaces):\n-                if not (credentials.username == self.username\n-                        and credentials.checkPassword(self.password)):\n+                if not (credentials.username == self.username and\n+                        credentials.checkPassword(self.password)):\n                     raise ValueError(\"Invalid credentials\")\n \n                 protocol = telnet.TelnetBootstrapProtocol(\n@@ -104,7 +119,7 @@ class TelnetConsole(protocol.ServerFactory):\n             'p': pprint.pprint,\n             'prefs': print_live_refs,\n             'hpy': hpy,\n-            'help': \"This is Scrapy telnet console. For more info see: \" \\\n+            'help': \"This is Scrapy telnet console. For more info see: \"\n                 \"https://doc.scrapy.org/en/latest/topics/telnetconsole.html\",\n         }\n         self.crawler.signals.send_catch_log(update_telnet_vars, telnet_vars=telnet_vars)\n\n@@ -277,8 +277,6 @@ USER_AGENT = 'Scrapy/%s (+https://scrapy.org)' % import_module('scrapy').__versi\n TELNETCONSOLE_ENABLED = 1\n TELNETCONSOLE_PORT = [6023, 6073]\n TELNETCONSOLE_HOST = '127.0.0.1'\n-TELNETCONSOLE_USERNAME = 'scrapy'\n-TELNETCONSOLE_PASSWORD = 'scrapy'\n \n SPIDER_CONTRACTS = {}\n SPIDER_CONTRACTS_BASE = {\n\n@@ -0,0 +1,59 @@\n+try:\n+    import unittest.mock as mock\n+except ImportError:\n+    import mock\n+\n+from twisted.trial import unittest\n+from twisted.conch.telnet import ITelnetProtocol\n+from twisted.cred import credentials\n+from twisted.internet import defer\n+\n+from scrapy.extensions.telnet import TelnetConsole, logger\n+from scrapy.utils.test import get_crawler\n+\n+\n+class TelnetExtensionTest(unittest.TestCase):    \n+    def _get_console_and_portal(self, settings=None):\n+        crawler = get_crawler(settings_dict=settings)\n+        console = TelnetConsole(crawler)\n+        username = console.username\n+        password = console.password\n+\n+        def _get_telnet_vars():\n+            # This function has some side effects we don't need for this test\n+            return {}\n+        console._get_telnet_vars = _get_telnet_vars\n+\n+        console.start_listening()\n+        protocol = console.protocol()\n+        portal = protocol.protocolArgs[0]\n+\n+        return console, portal\n+\n+    @defer.inlineCallbacks\n+    def test_bad_credentials(self):\n+        console, portal = self._get_console_and_portal()\n+        creds = credentials.UsernamePassword(b'username', b'password')\n+        d = portal.login(creds, None, ITelnetProtocol)\n+        yield self.assertFailure(d, ValueError)\n+        console.stop_listening()\n+\n+    @defer.inlineCallbacks\n+    def test_good_credentials(self):\n+        console, portal = self._get_console_and_portal()\n+        creds = credentials.UsernamePassword(console.username, console.password)\n+        d = portal.login(creds, None, ITelnetProtocol)\n+        yield d\n+        console.stop_listening()\n+\n+    @defer.inlineCallbacks\n+    def test_custom_credentials(self):\n+        settings = {\n+            'TELNETCONSOLE_USERNAME': 'user',\n+            'TELNETCONSOLE_PASSWORD': 'pass',\n+        }\n+        console, portal = self._get_console_and_portal(settings=settings)\n+        creds = credentials.UsernamePassword(b'user', b'pass')\n+        d = portal.login(creds, None, ITelnetProtocol)\n+        yield d\n+        console.stop_listening()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e57a629efc0846ed396247baf22d7846689b82e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 29 | Churn Cumulative: 780 | Contributors (this commit): 41 | Commits (past 90d): 11 | Contributors (cumulative): 48 | DMM Complexity: 1.0\n\nDIFF:\n@@ -53,20 +53,14 @@ class TelnetConsole(protocol.ServerFactory):\n         self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n         self.host = crawler.settings['TELNETCONSOLE_HOST']\n \n-        username = crawler.settings.get('TELNETCONSOLE_USERNAME', None)\n-        if username:\n-            self.username = username.encode('utf8')\n-        else:\n-            self.username = binascii.hexlify(os.urandom(8))\n+        self.username = crawler.settings['TELNETCONSOLE_USERNAME']\n+        self.password = crawler.settings['TELNETCONSOLE_PASSWORD']\n \n-        password = crawler.settings.get('TELNETCONSOLE_PASSWORD', None)\n-        if password:\n-            self.password = password.encode('utf8')\n-        else:\n-            self.password = binascii.hexlify(os.urandom(8))\n+        if not self.password:\n+            self.password = binascii.hexlify(os.urandom(8)).decode('utf8')\n+            logger.info('Telnet Username: %s', self.username)\n+            logger.info('Telnet Password: %s', self.password)\n \n-        logger.info('Telnet Username: %s' % self.username)\n-        logger.info('Telnet Password: %s' % self.password)\n         self.crawler.signals.connect(self.start_listening, signals.engine_started)\n         self.crawler.signals.connect(self.stop_listening, signals.engine_stopped)\n \n@@ -89,8 +83,8 @@ class TelnetConsole(protocol.ServerFactory):\n             \"\"\"An implementation of IPortal\"\"\"\n             @defers\n             def login(self_, credentials, mind, *interfaces):\n-                if not (credentials.username == self.username and\n-                        credentials.checkPassword(self.password)):\n+                if not (credentials.username == self.username.encode('utf8') and\n+                        credentials.checkPassword(self.password.encode('utf8'))):\n                     raise ValueError(\"Invalid credentials\")\n \n                 protocol = telnet.TelnetBootstrapProtocol(\n\n@@ -277,6 +277,8 @@ USER_AGENT = 'Scrapy/%s (+https://scrapy.org)' % import_module('scrapy').__versi\n TELNETCONSOLE_ENABLED = 1\n TELNETCONSOLE_PORT = [6023, 6073]\n TELNETCONSOLE_HOST = '127.0.0.1'\n+TELNETCONSOLE_USERNAME = 'scrapy'\n+TELNETCONSOLE_PASSWORD = None\n \n SPIDER_CONTRACTS = {}\n SPIDER_CONTRACTS_BASE = {\n\n@@ -41,7 +41,10 @@ class TelnetExtensionTest(unittest.TestCase):\n     @defer.inlineCallbacks\n     def test_good_credentials(self):\n         console, portal = self._get_console_and_portal()\n-        creds = credentials.UsernamePassword(console.username, console.password)\n+        creds = credentials.UsernamePassword(\n+            console.username.encode('utf8'),\n+            console.password.encode('utf8')\n+        )\n         d = portal.login(creds, None, ITelnetProtocol)\n         yield d\n         console.stop_listening()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#5f9931d2ada7a2a05df77b1c061eeb482fcda347", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 181 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -58,7 +58,6 @@ class TelnetConsole(protocol.ServerFactory):\n \n         if not self.password:\n             self.password = binascii.hexlify(os.urandom(8)).decode('utf8')\n-            logger.info('Telnet Username: %s', self.username)\n             logger.info('Telnet Password: %s', self.password)\n \n         self.crawler.signals.connect(self.start_listening, signals.engine_started)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#441e1e750fe7ad970adafc4c1f42834f7db86d1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 5 | Churn Cumulative: 250 | Contributors (this commit): 6 | Commits (past 90d): 11 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -52,7 +52,6 @@ class TelnetConsole(protocol.ServerFactory):\n         self.noisy = False\n         self.portrange = [int(x) for x in crawler.settings.getlist('TELNETCONSOLE_PORT')]\n         self.host = crawler.settings['TELNETCONSOLE_HOST']\n-\n         self.username = crawler.settings['TELNETCONSOLE_USERNAME']\n         self.password = crawler.settings['TELNETCONSOLE_PASSWORD']\n \n\n@@ -19,10 +19,8 @@ class TelnetExtensionTest(unittest.TestCase):\n         username = console.username\n         password = console.password\n \n-        def _get_telnet_vars():\n         # This function has some side effects we don't need for this test\n-            return {}\n-        console._get_telnet_vars = _get_telnet_vars\n+        console._get_telnet_vars = lambda: {}\n \n         console.start_listening()\n         protocol = console.protocol()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#58f5565357ed532970772cd55c2d17d1e00198a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 22 | Lines Deleted: 20 | Files Changed: 2 | Hunks: 4 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/5 | Churn Δ: 42 | Churn Cumulative: 1035 | Contributors (this commit): 16 | Commits (past 90d): 10 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -11,32 +11,13 @@ from scrapy.exceptions import _InvalidOutput\n from scrapy.middleware import MiddlewareManager\n from scrapy.utils.defer import mustbe_deferred\n from scrapy.utils.conf import build_component_list\n+from scrapy.utils.python import MutableChain\n \n \n def _isiterable(possible_iterator):\n     return hasattr(possible_iterator, '__iter__')\n \n \n-class MutableChain:\n-    \"\"\"\n-    Thin wrapper around itertools.chain, allowing to add iterables \"in-place\"\n-    \"\"\"\n-    def __init__(self, *args):\n-        self.data = chain(*args)\n-\n-    def extend(self, *iterables):\n-        self.data = chain(self.data, *iterables)\n-\n-    def __iter__(self):\n-        return self.data.__iter__()\n-\n-    def __next__(self):  # py3\n-        return self.data.__next__()\n-\n-    def next(self):  # py2\n-        return self.data.next()\n-\n-\n class SpiderMiddlewareManager(MiddlewareManager):\n \n     component_name = 'spider middleware'\n\n@@ -9,6 +9,7 @@ import weakref\n import errno\n import six\n from functools import partial, wraps\n+from itertools import chain\n import sys\n \n from scrapy.utils.decorators import deprecated\n@@ -387,3 +388,23 @@ if hasattr(sys, \"pypy_version_info\"):\n else:\n     def garbage_collect():\n         gc.collect()\n+\n+\n+class MutableChain(object):\n+    \"\"\"\n+    Thin wrapper around itertools.chain, allowing to add iterables \"in-place\"\n+    \"\"\"\n+    def __init__(self, *args):\n+        self.data = chain(*args)\n+\n+    def extend(self, *iterables):\n+        self.data = chain(self.data, *iterables)\n+\n+    def __iter__(self):\n+        return self.data.__iter__()\n+\n+    def __next__(self):  # py3\n+        return self.data.__next__()\n+\n+    def next(self):  # py2\n+        return self.data.next()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#a05eaeed73a469493e78b5a1c5f0b4de2adf41c2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 7 | Churn Cumulative: 653 | Contributors (this commit): 16 | Commits (past 90d): 2 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -403,8 +403,7 @@ class MutableChain(object):\n     def __iter__(self):\n         return self.data.__iter__()\n \n-    def __next__(self):  # py3\n-        return self.data.__next__()\n+    def __next__(self):\n+        return next(self.data)\n \n-    def next(self):  # py2\n-        return self.data.next()\n+    next = __next__\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#15f0a890ee9f059111333fdeb6c6c3b5a8dadc07", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 395 | Contributors (this commit): 4 | Commits (past 90d): 10 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -58,7 +58,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n             # don't handle _InvalidOutput exception\n             if isinstance(exception, _InvalidOutput):\n                 return _failure\n-            for method_index, method in enumerate(self.methods['process_spider_exception'][start_index:], start=start_index):\n+            method_list = self.methods['process_spider_exception'][start_index:]\n+            for method_index, method in enumerate(method_list, start=start_index):\n                 if method is None:\n                     continue\n                 result = method(response=response, exception=exception, spider=spider)\n@@ -88,7 +89,8 @@ class SpiderMiddlewareManager(MiddlewareManager):\n                         raise\n                     recovered.extend(exception_result)\n \n-            for method_index, method in enumerate(self.methods['process_spider_output'][start_index:], start=start_index):\n+            method_list = self.methods['process_spider_output'][start_index:]\n+            for method_index, method in enumerate(method_list, start=start_index):\n                 if method is None:\n                     continue\n                 # the following might fail directly if the output value is not a generator\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#e0360e5223b618934ee006b4c9ed63012e7e621f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 14 | Churn Cumulative: 251 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -9,11 +9,23 @@ import six\n from scrapy.utils.python import (\n     memoizemethod_noargs, binary_is_text, equal_attributes,\n     WeakKeyCache, stringify_dict, get_func_args, to_bytes, to_unicode,\n-    without_none_values)\n+    without_none_values, MutableChain)\n \n __doctests__ = ['scrapy.utils.python']\n \n \n+class MutableChainTest(unittest.TestCase):\n+    def test_mutablechain(self):\n+        m = MutableChain(range(2), [2, 3], (4, 5))\n+        m.extend(range(6, 7))\n+        m.extend([7, 8])\n+        m.extend([9, 10], (11, 12))\n+        self.assertEqual(next(m), 0)\n+        self.assertEqual(m.next(), 1)\n+        self.assertEqual(m.__next__(), 2)\n+        self.assertEqual(list(m), list(range(3, 13)))\n+\n+\n class ToUnicodeTest(unittest.TestCase):\n     def test_converting_an_utf8_encoded_string_to_unicode(self):\n         self.assertEqual(to_unicode(b'lel\\xc3\\xb1e'), u'lel\\xf1e')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f97e3e90f25c5077b47d9ec11a4cf84ea777227e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 4 | Hunks: 9 | Methods Changed: 5 | Complexity Δ (Sum/Max): -15/0 | Churn Δ: 22 | Churn Cumulative: 774 | Contributors (this commit): 13 | Commits (past 90d): 7 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -26,9 +26,9 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n         if hasattr(mw, 'process_request'):\n             self.methods['process_request'].append(mw.process_request)\n         if hasattr(mw, 'process_response'):\n-            self.methods['process_response'].insert(0, mw.process_response)\n+            self.methods['process_response'].appendleft(mw.process_response)\n         if hasattr(mw, 'process_exception'):\n-            self.methods['process_exception'].insert(0, mw.process_exception)\n+            self.methods['process_exception'].appendleft(mw.process_exception)\n \n     def download(self, download_func, request, spider):\n         @defer.inlineCallbacks\n\n@@ -25,11 +25,11 @@ class SpiderMiddlewareManager(MiddlewareManager):\n         if hasattr(mw, 'process_spider_input'):\n             self.methods['process_spider_input'].append(mw.process_spider_input)\n         if hasattr(mw, 'process_spider_output'):\n-            self.methods['process_spider_output'].insert(0, mw.process_spider_output)\n+            self.methods['process_spider_output'].appendleft(mw.process_spider_output)\n         if hasattr(mw, 'process_spider_exception'):\n-            self.methods['process_spider_exception'].insert(0, mw.process_spider_exception)\n+            self.methods['process_spider_exception'].appendleft(mw.process_spider_exception)\n         if hasattr(mw, 'process_start_requests'):\n-            self.methods['process_start_requests'].insert(0, mw.process_start_requests)\n+            self.methods['process_start_requests'].appendleft(mw.process_start_requests)\n \n     def scrape_response(self, scrape_func, response, request, spider):\n         fname = lambda f:'%s.%s' % (\n\n@@ -1,4 +1,4 @@\n-from collections import defaultdict\n+from collections import defaultdict, deque\n import logging\n import pprint\n \n@@ -16,7 +16,7 @@ class MiddlewareManager(object):\n \n     def __init__(self, *middlewares):\n         self.middlewares = middlewares\n-        self.methods = defaultdict(list)\n+        self.methods = defaultdict(deque)\n         for mw in middlewares:\n             self._add_middleware(mw)\n \n@@ -56,7 +56,7 @@ class MiddlewareManager(object):\n         if hasattr(mw, 'open_spider'):\n             self.methods['open_spider'].append(mw.open_spider)\n         if hasattr(mw, 'close_spider'):\n-            self.methods['close_spider'].insert(0, mw.close_spider)\n+            self.methods['close_spider'].appendleft(mw.close_spider)\n \n     def _process_parallel(self, methodname, obj, *args):\n         return process_parallel(self.methods[methodname], obj, *args)\n\n@@ -60,9 +60,9 @@ class MiddlewareManagerTest(unittest.TestCase):\n     def test_init(self):\n         m1, m2, m3 = M1(), M2(), M3()\n         mwman = TestMiddlewareManager(m1, m2, m3)\n-        self.assertEqual(mwman.methods['open_spider'], [m1.open_spider, m2.open_spider])\n-        self.assertEqual(mwman.methods['close_spider'], [m2.close_spider, m1.close_spider])\n-        self.assertEqual(mwman.methods['process'], [m1.process, m3.process])\n+        self.assertEqual(list(mwman.methods['open_spider']), [m1.open_spider, m2.open_spider])\n+        self.assertEqual(list(mwman.methods['close_spider']), [m2.close_spider, m1.close_spider])\n+        self.assertEqual(list(mwman.methods['process']), [m1.process, m3.process])\n \n     def test_methods(self):\n         mwman = TestMiddlewareManager(M1(), M2(), M3())\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
