{"custom_id": "keras#df939b646bdda15673d290f69265bdf4f812dbba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 7 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 49 | Churn Cumulative: 3214 | Contributors (this commit): 7 | Commits (past 90d): 38 | Contributors (cumulative): 11 | DMM Complexity: 0.42857142857142855\n\nDIFF:\n@@ -750,7 +750,14 @@ def take(x, indices, axis=None):\n         # This case is equivalent to embedding lookup.\n         return torch.nn.functional.embedding(indices, x)\n     if axis is not None:\n-        return torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n+        # make sure axis is non-negative\n+        axis = len(x.shape) + axis if axis < 0 else axis\n+        shape = x.shape[:axis] + indices.shape + x.shape[axis + 1 :]\n+        # ravel the `indices` since `index_select` expects `indices`\n+        # to be a vector (1-D tensor).\n+        indices = indices.ravel()\n+        out = torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n+        return out.reshape(shape)\n     return torch.take(x, index=indices)\n \n \n\n@@ -2814,16 +2814,16 @@ class Take(Operation):\n \n     def compute_output_spec(self, x, indices):\n         x_shape = list(x.shape)\n+        if isinstance(indices, KerasTensor):\n+            indices_shape = list(indices.shape)\n+        else:\n             indices_shape = list(getattr(np.array(indices), \"shape\", []))\n         if self.axis is None:\n             return KerasTensor(indices_shape, dtype=x.dtype)\n \n-        if self.axis == -1:\n-            output_shape = x_shape[:-1] + indices_shape\n-        else:\n-            output_shape = (\n-                x_shape[: self.axis] + indices_shape + x_shape[self.axis + 1 :]\n-            )\n+        # make sure axis is non-negative\n+        axis = len(x_shape) + self.axis if self.axis < 0 else self.axis\n+        output_shape = x_shape[:axis] + indices_shape + x_shape[axis + 1 :]\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n\n@@ -203,6 +203,14 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n             knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (None, 2, 2, 3)\n         )\n \n+        # test with negative axis\n+        self.assertEqual(knp.take(x, 1, axis=-2).shape, (None, 3))\n+\n+        # test with multi-dimensional indices\n+        x = KerasTensor([None, 3, None, 5])\n+        indices = KerasTensor([6, 7])\n+        self.assertEqual(knp.take(x, indices, axis=2).shape, (None, 3, 6, 7, 5))\n+\n     def test_take_along_axis(self):\n         x = KerasTensor([None, 3])\n         indices = KerasTensor([1, 3])\n@@ -586,6 +594,11 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (2, 2, 2))\n \n+        # test with multi-dimensional indices\n+        x = KerasTensor([2, 3, 4, 5])\n+        indices = KerasTensor([6, 7])\n+        self.assertEqual(knp.take(x, indices, axis=2).shape, (2, 3, 6, 7, 5))\n+\n     def test_take_along_axis(self):\n         x = KerasTensor([2, 3])\n         indices = KerasTensor([1, 3])\n@@ -1980,6 +1993,21 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(knp.Take()(x, 0), np.take(x, 0))\n         self.assertAllClose(knp.Take(axis=1)(x, 0), np.take(x, 0, axis=1))\n \n+        # test with multi-dimensional indices\n+        rng = np.random.default_rng(0)\n+        x = rng.standard_normal((2, 3, 4, 5))\n+        indices = rng.integers(0, 4, (6, 7))\n+        self.assertAllClose(\n+            knp.take(x, indices, axis=2),\n+            np.take(x, indices, axis=2),\n+        )\n+\n+        # test with negative axis\n+        self.assertAllClose(\n+            knp.take(x, indices, axis=-2),\n+            np.take(x, indices, axis=-2),\n+        )\n+\n     def test_take_along_axis(self):\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         indices = np.ones([1, 4, 1, 1], dtype=np.int32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df99beea515a1d059f664ea60c6f33d643856baa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 223 | Lines Deleted: 139 | Files Changed: 22 | Hunks: 81 | Methods Changed: 32 | Complexity Δ (Sum/Max): -2/1 | Churn Δ: 362 | Churn Cumulative: 13646 | Contributors (this commit): 11 | Commits (past 90d): 236 | Contributors (cumulative): 77 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,7 +2,6 @@ import numpy as np\n \n import keras_core\n from keras_core import Model\n-from keras_core import backend\n from keras_core import initializers\n from keras_core import layers\n from keras_core import losses\n@@ -11,6 +10,9 @@ from keras_core import ops\n from keras_core import optimizers\n \n \n+keras_core.config.disable_traceback_filtering()\n+\n+\n class MyDense(layers.Layer):\n     def __init__(self, units, name=None):\n         super().__init__(name=name)\n\n@@ -98,6 +98,7 @@ train(model, train_loader, num_epochs, optimizer, loss_fn)\n ######## Using a Keras model or layer in a torch Module ########\n ################################################################\n \n+\n class MyModel(nn.Module):\n     def __init__(self):\n         super().__init__()\n\n@@ -157,7 +157,12 @@ devices = mesh_utils.create_device_mesh((8,))\n # data will be split along the batch axis\n data_mesh = Mesh(devices, axis_names=(\"batch\",))  # naming axes of the mesh\n # naming axes of the sharded partition\n-data_sharding = NamedSharding(data_mesh,P(\"batch\",),)\n+data_sharding = NamedSharding(\n+    data_mesh,\n+    P(\n+        \"batch\",\n+    ),\n+)\n \n # all variables will be replicated on all devices\n var_mesh = Mesh(devices, axis_names=(\"_\"))\n\n@@ -40,6 +40,7 @@ from zipfile import ZipFile\n import keras_core as keras\n from keras_core import layers\n from keras_core import ops\n+\n \"\"\"\n ## First, load the data and apply preprocessing\n \"\"\"\n@@ -97,7 +98,11 @@ print(\n df = df.sample(frac=1, random_state=42)\n x = df[[\"user\", \"movie\"]].values\n # Normalize the targets between 0 and 1. Makes it easy to train.\n-y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n+y = (\n+    df[\"rating\"]\n+    .apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n+    .values\n+)\n # Assuming training on 90% of the data and validating on 10%.\n train_indices = int(0.9 * df.shape[0])\n x_train, x_val, y_train, y_val = (\n@@ -204,7 +209,8 @@ user_movie_array = np.hstack(\n ratings = model.predict(user_movie_array).flatten()\n top_ratings_indices = ratings.argsort()[-10:][::-1]\n recommended_movie_ids = [\n-    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n+    movie_encoded2movie.get(movies_not_watched[x][0])\n+    for x in top_ratings_indices\n ]\n \n print(\"Showing recommendations for user: {}\".format(user_id))\n\n@@ -178,7 +178,9 @@ splitting scheme (split on whitespace).\n \n def custom_standardization(input_string):\n     lowercase = tf.strings.lower(input_string)\n-    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n+    return tf.strings.regex_replace(\n+        lowercase, \"[%s]\" % re.escape(strip_chars), \"\"\n+    )\n \n \n strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n@@ -263,7 +265,9 @@ def get_cnn_model():\n     # We freeze our feature extractor\n     base_model.trainable = False\n     base_model_out = base_model.output\n-    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out)\n+    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(\n+        base_model_out\n+    )\n     cnn_model = keras.models.Model(base_model.input, base_model_out)\n     return cnn_model\n \n@@ -342,7 +346,9 @@ class TransformerDecoderBlock(layers.Layer):\n         self.layernorm_3 = layers.LayerNormalization()\n \n         self.embedding = PositionalEmbedding(\n-            embed_dim=EMBED_DIM, sequence_length=SEQ_LENGTH, vocab_size=VOCAB_SIZE\n+            embed_dim=EMBED_DIM,\n+            sequence_length=SEQ_LENGTH,\n+            vocab_size=VOCAB_SIZE,\n         )\n         self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n \n@@ -394,7 +400,10 @@ class TransformerDecoderBlock(layers.Layer):\n         mask = tf.cast(i >= j, dtype=\"int32\")\n         mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n         mult = tf.concat(\n-            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n+            [\n+                tf.expand_dims(batch_size, -1),\n+                tf.constant([1, 1], dtype=tf.int32),\n+            ],\n             axis=0,\n         )\n         return tf.tile(mask, mult)\n@@ -431,7 +440,9 @@ class ImageCaptioningModel(keras.Model):\n         mask = tf.cast(mask, dtype=tf.float32)\n         return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n \n-    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n+    def _compute_caption_loss_and_acc(\n+        self, img_embed, batch_seq, training=True\n+    ):\n         encoder_out = self.encoder(img_embed, training=training)\n         batch_seq_inp = batch_seq[:, :-1]\n         batch_seq_true = batch_seq[:, 1:]\n@@ -469,7 +480,8 @@ class ImageCaptioningModel(keras.Model):\n \n             # 4. Get the list of all the trainable weights\n             train_vars = (\n-                self.encoder.trainable_variables + self.decoder.trainable_variables\n+                self.encoder.trainable_variables\n+                + self.decoder.trainable_variables\n             )\n \n             # 5. Get the gradients\n@@ -484,7 +496,10 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 8. Return the loss and accuracy values\n-        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"acc\": self.acc_tracker.result(),\n+        }\n \n     def test_step(self, batch_data):\n         batch_img, batch_seq = batch_data\n@@ -513,7 +528,10 @@ class ImageCaptioningModel(keras.Model):\n         self.acc_tracker.update_state(batch_acc)\n \n         # 5. Return the loss and accuracy values\n-        return {\"loss\": self.loss_tracker.result(), \"acc\": self.acc_tracker.result()}\n+        return {\n+            \"loss\": self.loss_tracker.result(),\n+            \"acc\": self.acc_tracker.result(),\n+        }\n \n     @property\n     def metrics(self):\n@@ -523,8 +541,12 @@ class ImageCaptioningModel(keras.Model):\n \n \n cnn_model = get_cnn_model()\n-encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n-decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2)\n+encoder = TransformerEncoderBlock(\n+    embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1\n+)\n+decoder = TransformerDecoderBlock(\n+    embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2\n+)\n caption_model = ImageCaptioningModel(\n     cnn_model=cnn_model,\n     encoder=encoder,\n@@ -539,15 +561,20 @@ caption_model = ImageCaptioningModel(\n \n # Define the loss function\n cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n-    from_logits=False, reduction=None,\n+    from_logits=False,\n+    reduction=None,\n )\n \n # EarlyStopping criteria\n-early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n+early_stopping = keras.callbacks.EarlyStopping(\n+    patience=3, restore_best_weights=True\n+)\n \n \n # Learning Rate Scheduler for the optimizer\n-class LRSchedule(keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule):\n+class LRSchedule(\n+    keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule\n+):\n     def __init__(self, post_warmup_learning_rate, warmup_steps):\n         super().__init__()\n         self.post_warmup_learning_rate = post_warmup_learning_rate\n@@ -568,10 +595,14 @@ class LRSchedule(keras.optimizers.schedules.learning_rate_schedule.LearningRateS\n # Create a learning rate schedule\n num_train_steps = len(train_dataset) * EPOCHS\n num_warmup_steps = num_train_steps // 15\n-lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)\n+lr_schedule = LRSchedule(\n+    post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps\n+)\n \n # Compile the model\n-caption_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy)\n+caption_model.compile(\n+    optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy\n+)\n \n # Fit the model\n caption_model.fit(\n\n@@ -58,7 +58,10 @@ transformer_units = [\n     projection_dim,\n ]  # Size of the transformer layers\n transformer_layers = 8\n-mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n+mlp_head_units = [\n+    2048,\n+    1024,\n+]  # Size of the dense layers of the final classifier\n \n \n \"\"\"\n@@ -218,7 +221,9 @@ def create_vit_classifier():\n     representation = layers.Flatten()(representation)\n     representation = layers.Dropout(0.5)(representation)\n     # Add MLP.\n-    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n+    features = mlp(\n+        representation, hidden_units=mlp_head_units, dropout_rate=0.5\n+    )\n     # Classify outputs.\n     logits = layers.Dense(num_classes)(features)\n     # Create the Keras model.\n@@ -241,7 +246,9 @@ def run_experiment(model):\n         loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n         metrics=[\n             keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n-            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n+            keras.metrics.SparseTopKCategoricalAccuracy(\n+                5, name=\"top-5-accuracy\"\n+            ),\n         ],\n     )\n \n\n@@ -123,7 +123,9 @@ class Involution(keras.layers.Layer):\n                 keras.layers.BatchNormalization(),\n                 keras.layers.ReLU(),\n                 keras.layers.Conv2D(\n-                    filters=self.kernel_size * self.kernel_size * self.group_number,\n+                    filters=self.kernel_size\n+                    * self.kernel_size\n+                    * self.group_number,\n                     kernel_size=1,\n                 ),\n             ]\n@@ -198,22 +200,39 @@ input_tensor = tf.random.normal((32, 256, 256, 3))\n \n # Compute involution with stride 1.\n output_tensor, _ = Involution(\n-    channel=3, group_number=1, kernel_size=5, stride=1, reduction_ratio=1, name=\"inv_1\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=1,\n+    reduction_ratio=1,\n+    name=\"inv_1\",\n )(input_tensor)\n print(f\"with stride 1 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 2.\n output_tensor, _ = Involution(\n-    channel=3, group_number=1, kernel_size=5, stride=2, reduction_ratio=1, name=\"inv_2\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=2,\n+    reduction_ratio=1,\n+    name=\"inv_2\",\n )(input_tensor)\n print(f\"with stride 2 ouput shape: {output_tensor.shape}\")\n \n # Compute involution with stride 1, channel 16 and reduction ratio 2.\n output_tensor, _ = Involution(\n-    channel=16, group_number=1, kernel_size=5, stride=1, reduction_ratio=2, name=\"inv_3\"\n+    channel=16,\n+    group_number=1,\n+    kernel_size=5,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_3\",\n )(input_tensor)\n print(\n-    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(output_tensor.shape)\n+    \"with channel 16 and reduction ratio 2 ouput shape: {}\".format(\n+        output_tensor.shape\n+    )\n )\n \n \"\"\"\n@@ -250,7 +269,9 @@ train_ds = (\n     .shuffle(256)\n     .batch(256)\n )\n-test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(256)\n+test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(\n+    256\n+)\n \n \"\"\"\n ## Visualise the data\n@@ -287,7 +308,9 @@ plt.show()\n print(\"building the convolution model...\")\n conv_model = keras.Sequential(\n     [\n-        keras.layers.Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"),\n+        keras.layers.Conv2D(\n+            32, (3, 3), input_shape=(32, 32, 3), padding=\"same\"\n+        ),\n         keras.layers.ReLU(name=\"relu1\"),\n         keras.layers.MaxPooling2D((2, 2)),\n         keras.layers.Conv2D(64, (3, 3), padding=\"same\"),\n@@ -323,17 +346,32 @@ print(\"building the involution model...\")\n \n inputs = keras.Input(shape=(32, 32, 3))\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_1\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_1\",\n )(inputs)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_2\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_2\",\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.MaxPooling2D((2, 2))(x)\n x, _ = Involution(\n-    channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_3\"\n+    channel=3,\n+    group_number=1,\n+    kernel_size=3,\n+    stride=1,\n+    reduction_ratio=2,\n+    name=\"inv_3\",\n )(x)\n x = keras.layers.ReLU()(x)\n x = keras.layers.Flatten()(x)\n\n@@ -140,7 +140,8 @@ certain cases, it may not help improve the performance as well.\n \n # First create the new dataset using our `mix_up` utility\n train_ds_mu = train_ds.map(\n-    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2), num_parallel_calls=AUTO\n+    lambda ds_one, ds_two: mix_up(ds_one, ds_two, alpha=0.2),\n+    num_parallel_calls=AUTO,\n )\n \n # Let's preview 9 samples from the dataset\n@@ -160,7 +161,9 @@ for i, (image, label) in enumerate(zip(sample_images[:9], sample_labels[:9])):\n def get_training_model():\n     model = keras.Sequential(\n         [\n-            layers.Conv2D(16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)),\n+            layers.Conv2D(\n+                16, (5, 5), activation=\"relu\", input_shape=(28, 28, 1)\n+            ),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n             layers.Conv2D(32, (5, 5), activation=\"relu\"),\n             layers.MaxPooling2D(pool_size=(2, 2)),\n@@ -187,7 +190,9 @@ initial_model.save_weights(\"initial_weights.weights.h5\")\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n model.fit(train_ds_mu, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n@@ -198,7 +203,9 @@ print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n \n model = get_training_model()\n model.load_weights(\"initial_weights.weights.h5\")\n-model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n+model.compile(\n+    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n+)\n # Notice that we are NOT using the mixed up dataset here\n model.fit(train_ds_one, validation_data=val_ds, epochs=EPOCHS)\n _, test_acc = model.evaluate(test_ds)\n\n@@ -183,7 +183,9 @@ class Patches(layers.Layer):\n             padding=\"VALID\",\n         )\n         patch_dims = patches.shape[-1]\n-        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n+        patches = tf.reshape(\n+            patches, [batch_size, self.num_patches, patch_dims]\n+        )\n         return patches\n \n \n@@ -207,7 +209,9 @@ instead of batch normalization.\n \n \n class MLPMixerLayer(layers.Layer):\n-    def __init__(self, num_patches, hidden_units, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, hidden_units, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.mlp1 = keras.Sequential(\n@@ -257,7 +261,10 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n mlpmixer_blocks = keras.Sequential(\n-    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        MLPMixerLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.005\n mlpmixer_classifier = build_classifier(mlpmixer_blocks)\n@@ -292,7 +299,9 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n \n class FNetLayer(layers.Layer):\n-    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.ffn = keras.Sequential(\n@@ -332,7 +341,10 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n fnet_blocks = keras.Sequential(\n-    [FNetLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        FNetLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.001\n fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n@@ -363,7 +375,9 @@ The SGU enables cross-patch interactions across the spatial (channel) dimension,\n \n \n class gMLPLayer(layers.Layer):\n-    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n+    def __init__(\n+        self, num_patches, embedding_dim, dropout_rate, *args, **kwargs\n+    ):\n         super().__init__(*args, **kwargs)\n \n         self.channel_projection1 = keras.Sequential(\n@@ -416,7 +430,10 @@ takes around 9 seconds per epoch.\n \"\"\"\n \n gmlp_blocks = keras.Sequential(\n-    [gMLPLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)]\n+    [\n+        gMLPLayer(num_patches, embedding_dim, dropout_rate)\n+        for _ in range(num_blocks)\n+    ]\n )\n learning_rate = 0.003\n gmlp_classifier = build_classifier(gmlp_blocks)\n\n@@ -71,14 +71,18 @@ image_size = 64  # We'll resize input images to this size.\n patch_size = 2  # Size of the patches to be extract from the input images.\n num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n latent_dim = 256  # Size of the latent array.\n-projection_dim = 256  # Embedding size of each element in the data and latent arrays.\n+projection_dim = (\n+    256  # Embedding size of each element in the data and latent arrays.\n+)\n num_heads = 8  # Number of Transformer heads.\n ffn_units = [\n     projection_dim,\n     projection_dim,\n ]  # Size of the Transformer Feedforward network.\n num_transformer_blocks = 4\n-num_iterations = 2  # Repetitions of the cross-attention and Transformer modules.\n+num_iterations = (\n+    2  # Repetitions of the cross-attention and Transformer modules.\n+)\n classifier_units = [\n     projection_dim,\n     num_classes,\n@@ -205,13 +209,19 @@ def create_cross_attention_module(\n ):\n     inputs = {\n         # Recieve the latent array as an input of shape [1, latent_dim, projection_dim].\n-        \"latent_array\": layers.Input(shape=(latent_dim, projection_dim), name=\"latent_array\"),\n+        \"latent_array\": layers.Input(\n+            shape=(latent_dim, projection_dim), name=\"latent_array\"\n+        ),\n         # Recieve the data_array (encoded image) as an input of shape [batch_size, data_dim, projection_dim].\n-        \"data_array\": layers.Input(shape=(data_dim, projection_dim), name=\"data_array\"),\n+        \"data_array\": layers.Input(\n+            shape=(data_dim, projection_dim), name=\"data_array\"\n+        ),\n     }\n \n     # Apply layer norm to the inputs\n-    latent_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"latent_array\"])\n+    latent_array = layers.LayerNormalization(epsilon=1e-6)(\n+        inputs[\"latent_array\"]\n+    )\n     data_array = layers.LayerNormalization(epsilon=1e-6)(inputs[\"data_array\"])\n \n     # Create query tensor: [1, latent_dim, projection_dim].\n\n@@ -148,7 +148,9 @@ model.compile(\n )\n model.summary()\n \n-callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n+callbacks = [\n+    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n+]\n \n model.fit(\n     x_train,\n\n@@ -96,7 +96,9 @@ positive class label is randomly placed among the instances in the positive bag.\n \"\"\"\n \n \n-def create_bags(input_data, input_labels, positive_class, bag_count, instance_count):\n+def create_bags(\n+    input_data, input_labels, positive_class, bag_count, instance_count\n+):\n     # Set up bags.\n     bags = []\n     bag_labels = []\n@@ -109,7 +111,9 @@ def create_bags(input_data, input_labels, positive_class, bag_count, instance_co\n \n     for _ in range(bag_count):\n         # Pick a fixed size random subset of samples.\n-        index = np.random.choice(input_data.shape[0], instance_count, replace=False)\n+        index = np.random.choice(\n+            input_data.shape[0], instance_count, replace=False\n+        )\n         instances_data = input_data[index]\n         instances_labels = input_labels[index]\n \n@@ -241,7 +245,9 @@ class MILAttentionLayer(layers.Layer):\n \n     def call(self, inputs):\n         # Assigning variables from the number of inputs.\n-        instances = [self.compute_attention_scores(instance) for instance in inputs]\n+        instances = [\n+            self.compute_attention_scores(instance) for instance in inputs\n+        ]\n \n         # Stack instances into a single tensor.\n         instances = ops.stack(instances)\n@@ -257,7 +263,9 @@ class MILAttentionLayer(layers.Layer):\n         original_instance = instance\n \n         # tanh(v*h_k^T)\n-        instance = ops.tanh(ops.tensordot(instance, self.v_weight_params, axes=1))\n+        instance = ops.tanh(\n+            ops.tensordot(instance, self.v_weight_params, axes=1)\n+        )\n \n         # for learning non-linear relations efficiently.\n         if self.use_gated:\n@@ -499,12 +507,16 @@ def predict(data, labels, trained_models):\n         models_predictions.append(predictions)\n \n         # Create intermediate model to get MIL attention layer weights.\n-        intermediate_model = keras.Model(model.input, model.get_layer(\"alpha\").output)\n+        intermediate_model = keras.Model(\n+            model.input, model.get_layer(\"alpha\").output\n+        )\n \n         # Predict MIL attention layer weights.\n         intermediate_predictions = intermediate_model.predict(data)\n \n-        attention_weights = np.squeeze(np.swapaxes(intermediate_predictions, 1, 0))\n+        attention_weights = np.squeeze(\n+            np.swapaxes(intermediate_predictions, 1, 0)\n+        )\n         models_attention_weights.append(attention_weights)\n \n         loss, accuracy = model.evaluate(data, labels, verbose=0)\n@@ -523,7 +535,9 @@ def predict(data, labels, trained_models):\n \n \n # Evaluate and predict classes and attention scores on validation data.\n-class_predictions, attention_params = predict(val_data, val_labels, trained_models)\n+class_predictions, attention_params = predict(\n+    val_data, val_labels, trained_models\n+)\n \n # Plot some results from our validation data.\n plot(\n\n@@ -96,9 +96,7 @@ def append(\n \n \n def arange(start, stop=None, step=1, dtype=None):\n-    # tfnp.arange has trouble with dynamic Tensors in compiled function.\n-    # tf.range does not.\n-    return tf.range(start, stop, delta=step, dtype=dtype)\n+    return tfnp.arange(start, stop, step=step, dtype=dtype)\n \n \n def arccos(x):\n@@ -446,9 +444,7 @@ def reciprocal(x):\n \n \n def repeat(x, repeats, axis=None):\n-    # tfnp.repeat has trouble with dynamic Tensors in compiled function.\n-    # tf.repeat does not.\n-    return tf.repeat(x, repeats, axis=axis)\n+    return tfnp.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n\n@@ -39,10 +39,14 @@ def device_scope(device):\n         global_state.set_global_attribute(\"torch_device\", previous_device)\n \n \n+def get_default_device():\n+    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n+\n+\n def get_device():\n     device = global_state.get_global_attribute(\"torch_device\", None)\n     if device is None:\n-        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n+        get_default_device()\n     return device\n \n \n@@ -216,6 +220,7 @@ def compute_output_spec(fn, *args, **kwargs):\n                 )\n                 return fn(*args, **kwargs)\n         except:\n+            with device_scope(get_default_device()):\n                 # If the `\"meta\"` device placement fails, fall back to tracing\n                 # eagerly with tensors on the default device. This will be\n                 # more robust, but more expensive.\n\n@@ -750,14 +750,7 @@ def take(x, indices, axis=None):\n         # This case is equivalent to embedding lookup.\n         return torch.nn.functional.embedding(indices, x)\n     if axis is not None:\n-        # make sure axis is non-negative\n-        axis = len(x.shape) + axis if axis < 0 else axis\n-        shape = x.shape[:axis] + indices.shape + x.shape[axis + 1 :]\n-        # ravel the `indices` since `index_select` expects `indices`\n-        # to be a vector (1-D tensor).\n-        indices = indices.ravel()\n-        out = torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n-        return out.reshape(shape)\n+        return torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n     return torch.take(x, index=indices)\n \n \n\n@@ -12,6 +12,10 @@ from keras_core.random.seed_generator import make_default_seed\n \n def torch_seed_generator(seed):\n     seed_val, _ = draw_seed(seed)\n+    device = get_device()\n+    if device == \"meta\":\n+        # Generator is not support by the meta device.\n+        return None\n     generator = torch.Generator(device=get_device())\n     generator.manual_seed(int(seed_val))\n     return generator\n\n@@ -3,7 +3,6 @@ from keras_core import initializers\n from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n-from keras_core.backend import standardize_dtype\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -189,12 +188,6 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n-        input_dtype = standardize_dtype(inputs.dtype)\n-        if input_dtype in (\"float16\", \"bfloat16\"):\n-            # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n-            # out BN for mixed precision.\n-            inputs = ops.cast(inputs, \"float32\")\n-\n         broadcast_shape = [1] * len(inputs.shape)\n         broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n@@ -205,20 +198,12 @@ class BatchNormalization(Layer):\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n             mean = ops.squeeze(mean, self._reduction_axes)\n             variance = ops.squeeze(variance, self._reduction_axes)\n-            moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n-            moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n-                ops.cast(\n-                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n-                    inputs.dtype,\n-                )\n+                self.moving_mean * self.momentum + mean * (1.0 - self.momentum)\n             )\n             self.moving_variance.assign(\n-                ops.cast(\n-                    moving_variance * self.momentum\n-                    + variance * (1.0 - self.momentum),\n-                    inputs.dtype,\n-                )\n+                self.moving_variance * self.momentum\n+                + variance * (1.0 - self.momentum)\n             )\n         else:\n             moving_mean = ops.reshape(self.moving_mean, broadcast_shape)\n@@ -228,11 +213,9 @@ class BatchNormalization(Layer):\n             )\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n-            gamma = ops.cast(gamma, outputs.dtype)\n             outputs = outputs * gamma\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n-            beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n         return outputs\n \n\n@@ -205,12 +205,9 @@ class LayerNormalization(Layer):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n-            scale = ops.cast(scale, inputs.dtype)\n             inv = inv * scale\n-        x = -mean * inv\n-        if offset is not None:\n-            offset = ops.cast(offset, inputs.dtype)\n-            x = offset + x\n+\n+        x = offset - mean * inv if offset is not None else -mean * inv\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n             x, inputs.dtype\n         )\n\n@@ -93,12 +93,7 @@ class DTypePolicy:\n         return cls(**config)\n \n \n-@keras_core_export(\n-    [\n-        \"keras_core.mixed_precision.set_dtype_policy\",\n-        \"keras_core.mixed_precision.set_global_policy\",\n-    ]\n-)\n+@keras_core_export(\"keras_core.mixed_precision.set_dtype_policy\")\n def set_dtype_policy(policy):\n     if not isinstance(policy, DTypePolicy):\n         if isinstance(policy, str):\n\n@@ -2814,16 +2814,16 @@ class Take(Operation):\n \n     def compute_output_spec(self, x, indices):\n         x_shape = list(x.shape)\n-        if isinstance(indices, KerasTensor):\n-            indices_shape = list(indices.shape)\n-        else:\n         indices_shape = list(getattr(np.array(indices), \"shape\", []))\n         if self.axis is None:\n             return KerasTensor(indices_shape, dtype=x.dtype)\n \n-        # make sure axis is non-negative\n-        axis = len(x_shape) + self.axis if self.axis < 0 else self.axis\n-        output_shape = x_shape[:axis] + indices_shape + x_shape[axis + 1 :]\n+        if self.axis == -1:\n+            output_shape = x_shape[:-1] + indices_shape\n+        else:\n+            output_shape = (\n+                x_shape[: self.axis] + indices_shape + x_shape[self.axis + 1 :]\n+            )\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n\n@@ -203,14 +203,6 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n             knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (None, 2, 2, 3)\n         )\n \n-        # test with negative axis\n-        self.assertEqual(knp.take(x, 1, axis=-2).shape, (None, 3))\n-\n-        # test with multi-dimensional indices\n-        x = KerasTensor([None, 3, None, 5])\n-        indices = KerasTensor([6, 7])\n-        self.assertEqual(knp.take(x, indices, axis=2).shape, (None, 3, 6, 7, 5))\n-\n     def test_take_along_axis(self):\n         x = KerasTensor([None, 3])\n         indices = KerasTensor([1, 3])\n@@ -594,11 +586,6 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (2, 2, 2))\n \n-        # test with multi-dimensional indices\n-        x = KerasTensor([2, 3, 4, 5])\n-        indices = KerasTensor([6, 7])\n-        self.assertEqual(knp.take(x, indices, axis=2).shape, (2, 3, 6, 7, 5))\n-\n     def test_take_along_axis(self):\n         x = KerasTensor([2, 3])\n         indices = KerasTensor([1, 3])\n@@ -1993,21 +1980,6 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(knp.Take()(x, 0), np.take(x, 0))\n         self.assertAllClose(knp.Take(axis=1)(x, 0), np.take(x, 0, axis=1))\n \n-        # test with multi-dimensional indices\n-        rng = np.random.default_rng(0)\n-        x = rng.standard_normal((2, 3, 4, 5))\n-        indices = rng.integers(0, 4, (6, 7))\n-        self.assertAllClose(\n-            knp.take(x, indices, axis=2),\n-            np.take(x, indices, axis=2),\n-        )\n-\n-        # test with negative axis\n-        self.assertAllClose(\n-            knp.take(x, indices, axis=-2),\n-            np.take(x, indices, axis=-2),\n-        )\n-\n     def test_take_along_axis(self):\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         indices = np.ones([1, 4, 1, 1], dtype=np.int32)\n\n@@ -44,9 +44,8 @@ def draw_seed(seed):\n         seed_state = seed.state\n         # Use * 1 to create a copy\n         new_seed_value = seed_state.value * 1\n-        seed.state.assign(seed_state + np.array([0, 1], dtype=\"uint32\"))\n-        if backend.backend() == \"torch\":\n-            return backend.convert_to_numpy(new_seed_value)\n+        increment = backend.convert_to_tensor(np.array([0, 1]), dtype=\"uint32\")\n+        seed.state.assign(seed_state + increment)\n         return new_seed_value\n     elif isinstance(seed, int):\n         return convert_to_tensor([seed, 0], dtype=\"uint32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba1442a22fb6a6b74dce313e4b092657a6832288", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 79 | Lines Deleted: 15 | Files Changed: 7 | Hunks: 18 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/1 | Churn Δ: 94 | Churn Cumulative: 5405 | Contributors (this commit): 8 | Commits (past 90d): 99 | Contributors (cumulative): 27 | DMM Complexity: 0.0\n\nDIFF:\n@@ -96,7 +96,9 @@ def append(\n \n \n def arange(start, stop=None, step=1, dtype=None):\n-    return tfnp.arange(start, stop, step=step, dtype=dtype)\n+    # tfnp.arange has trouble with dynamic Tensors in compiled function.\n+    # tf.range does not.\n+    return tf.range(start, stop, delta=step, dtype=dtype)\n \n \n def arccos(x):\n@@ -444,7 +446,9 @@ def reciprocal(x):\n \n \n def repeat(x, repeats, axis=None):\n-    return tfnp.repeat(x, repeats, axis=axis)\n+    # tfnp.repeat has trouble with dynamic Tensors in compiled function.\n+    # tf.repeat does not.\n+    return tf.repeat(x, repeats, axis=axis)\n \n \n def reshape(x, new_shape):\n\n@@ -750,7 +750,14 @@ def take(x, indices, axis=None):\n         # This case is equivalent to embedding lookup.\n         return torch.nn.functional.embedding(indices, x)\n     if axis is not None:\n-        return torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n+        # make sure axis is non-negative\n+        axis = len(x.shape) + axis if axis < 0 else axis\n+        shape = x.shape[:axis] + indices.shape + x.shape[axis + 1 :]\n+        # ravel the `indices` since `index_select` expects `indices`\n+        # to be a vector (1-D tensor).\n+        indices = indices.ravel()\n+        out = torch.index_select(x, dim=axis, index=indices).squeeze(axis)\n+        return out.reshape(shape)\n     return torch.take(x, index=indices)\n \n \n\n@@ -3,6 +3,7 @@ from keras_core import initializers\n from keras_core import ops\n from keras_core import regularizers\n from keras_core.api_export import keras_core_export\n+from keras_core.backend import standardize_dtype\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n@@ -188,6 +189,12 @@ class BatchNormalization(Layer):\n         return input_shape\n \n     def call(self, inputs, training=None, mask=None):\n+        input_dtype = standardize_dtype(inputs.dtype)\n+        if input_dtype in (\"float16\", \"bfloat16\"):\n+            # BN is prone to overflowing for float16/bfloat16 inputs, so we opt\n+            # out BN for mixed precision.\n+            inputs = ops.cast(inputs, \"float32\")\n+\n         broadcast_shape = [1] * len(inputs.shape)\n         broadcast_shape[self.axis] = inputs.shape[self.axis]\n         if training and self.trainable:\n@@ -198,12 +205,20 @@ class BatchNormalization(Layer):\n             outputs = (inputs - mean) / ops.sqrt(variance + self.epsilon)\n             mean = ops.squeeze(mean, self._reduction_axes)\n             variance = ops.squeeze(variance, self._reduction_axes)\n+            moving_mean = ops.cast(self.moving_mean, inputs.dtype)\n+            moving_variance = ops.cast(self.moving_variance, inputs.dtype)\n             self.moving_mean.assign(\n-                self.moving_mean * self.momentum + mean * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_mean * self.momentum + mean * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n             self.moving_variance.assign(\n-                self.moving_variance * self.momentum\n-                + variance * (1.0 - self.momentum)\n+                ops.cast(\n+                    moving_variance * self.momentum\n+                    + variance * (1.0 - self.momentum),\n+                    inputs.dtype,\n+                )\n             )\n         else:\n             moving_mean = ops.reshape(self.moving_mean, broadcast_shape)\n@@ -213,9 +228,11 @@ class BatchNormalization(Layer):\n             )\n         if self.scale:\n             gamma = ops.reshape(self.gamma, broadcast_shape)\n+            gamma = ops.cast(gamma, outputs.dtype)\n             outputs = outputs * gamma\n         if self.center:\n             beta = ops.reshape(self.beta, broadcast_shape)\n+            beta = ops.cast(beta, outputs.dtype)\n             outputs = outputs + beta\n         return outputs\n \n\n@@ -205,9 +205,12 @@ class LayerNormalization(Layer):\n         # Compute the batch normalization.\n         inv = 1 / ops.sqrt(variance + self.epsilon)\n         if scale is not None:\n+            scale = ops.cast(scale, inputs.dtype)\n             inv = inv * scale\n-\n-        x = offset - mean * inv if offset is not None else -mean * inv\n+        x = -mean * inv\n+        if offset is not None:\n+            offset = ops.cast(offset, inputs.dtype)\n+            x = offset + x\n         outputs = inputs * ops.cast(inv, inputs.dtype) + ops.cast(\n             x, inputs.dtype\n         )\n\n@@ -93,7 +93,12 @@ class DTypePolicy:\n         return cls(**config)\n \n \n-@keras_core_export(\"keras_core.mixed_precision.set_dtype_policy\")\n+@keras_core_export(\n+    [\n+        \"keras_core.mixed_precision.set_dtype_policy\",\n+        \"keras_core.mixed_precision.set_global_policy\",\n+    ]\n+)\n def set_dtype_policy(policy):\n     if not isinstance(policy, DTypePolicy):\n         if isinstance(policy, str):\n\n@@ -2814,16 +2814,16 @@ class Take(Operation):\n \n     def compute_output_spec(self, x, indices):\n         x_shape = list(x.shape)\n+        if isinstance(indices, KerasTensor):\n+            indices_shape = list(indices.shape)\n+        else:\n             indices_shape = list(getattr(np.array(indices), \"shape\", []))\n         if self.axis is None:\n             return KerasTensor(indices_shape, dtype=x.dtype)\n \n-        if self.axis == -1:\n-            output_shape = x_shape[:-1] + indices_shape\n-        else:\n-            output_shape = (\n-                x_shape[: self.axis] + indices_shape + x_shape[self.axis + 1 :]\n-            )\n+        # make sure axis is non-negative\n+        axis = len(x_shape) + self.axis if self.axis < 0 else self.axis\n+        output_shape = x_shape[:axis] + indices_shape + x_shape[axis + 1 :]\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n\n@@ -203,6 +203,14 @@ class NumpyTwoInputOpsDynamicShapeTest(testing.TestCase):\n             knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (None, 2, 2, 3)\n         )\n \n+        # test with negative axis\n+        self.assertEqual(knp.take(x, 1, axis=-2).shape, (None, 3))\n+\n+        # test with multi-dimensional indices\n+        x = KerasTensor([None, 3, None, 5])\n+        indices = KerasTensor([6, 7])\n+        self.assertEqual(knp.take(x, indices, axis=2).shape, (None, 3, 6, 7, 5))\n+\n     def test_take_along_axis(self):\n         x = KerasTensor([None, 3])\n         indices = KerasTensor([1, 3])\n@@ -586,6 +594,11 @@ class NumpyTwoInputOpsStaticShapeTest(testing.TestCase):\n         self.assertEqual(knp.take(x, [1, 2]).shape, (2,))\n         self.assertEqual(knp.take(x, [[1, 2], [1, 2]], axis=1).shape, (2, 2, 2))\n \n+        # test with multi-dimensional indices\n+        x = KerasTensor([2, 3, 4, 5])\n+        indices = KerasTensor([6, 7])\n+        self.assertEqual(knp.take(x, indices, axis=2).shape, (2, 3, 6, 7, 5))\n+\n     def test_take_along_axis(self):\n         x = KerasTensor([2, 3])\n         indices = KerasTensor([1, 3])\n@@ -1980,6 +1993,21 @@ class NumpyTwoInputOpsCorretnessTest(testing.TestCase):\n         self.assertAllClose(knp.Take()(x, 0), np.take(x, 0))\n         self.assertAllClose(knp.Take(axis=1)(x, 0), np.take(x, 0, axis=1))\n \n+        # test with multi-dimensional indices\n+        rng = np.random.default_rng(0)\n+        x = rng.standard_normal((2, 3, 4, 5))\n+        indices = rng.integers(0, 4, (6, 7))\n+        self.assertAllClose(\n+            knp.take(x, indices, axis=2),\n+            np.take(x, indices, axis=2),\n+        )\n+\n+        # test with negative axis\n+        self.assertAllClose(\n+            knp.take(x, indices, axis=-2),\n+            np.take(x, indices, axis=-2),\n+        )\n+\n     def test_take_along_axis(self):\n         x = np.arange(24).reshape([1, 2, 3, 4])\n         indices = np.ones([1, 4, 1, 1], dtype=np.int32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f37477770626ebb8b603f773c453a0ad16d4930", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 851 | Contributors (this commit): 6 | Commits (past 90d): 31 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -10,9 +10,6 @@ from keras_core import ops\n from keras_core import optimizers\n \n \n-keras_core.config.disable_traceback_filtering()\n-\n-\n class MyDense(layers.Layer):\n     def __init__(self, units, name=None):\n         super().__init__(name=name)\n\n@@ -14,7 +14,7 @@ def torch_seed_generator(seed):\n     seed_val, _ = draw_seed(seed)\n     device = get_device()\n     if device == \"meta\":\n-        # Generator is not support by the meta device.\n+        # Generator is not supported by the meta device.\n         return None\n     generator = torch.Generator(device=get_device())\n     generator.manual_seed(int(seed_val))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c99663133cd5cf69b09bf8611bd467b7430056c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 5 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/6 | Churn Δ: 64 | Churn Cumulative: 794 | Contributors (this commit): 8 | Commits (past 90d): 45 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,56 @@\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import testing\n+\n+\n+def example_fn(x):\n+    x = (x + 2) * backend.numpy.ones(x.shape)\n+    x = backend.numpy.stack([x, x], axis=-1)\n+    return x\n+\n+\n+class ComputeOutputSpecTest(testing.TestCase):\n+    def test_basics(self):\n+        out = backend.compute_output_spec(\n+            example_fn, backend.KerasTensor((2, 3))\n+        )\n+        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertEqual(out.shape, (2, 3, 2))\n+\n+        out = backend.compute_output_spec(\n+            example_fn, backend.KerasTensor((None, 3))\n+        )\n+        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertEqual(out.shape, (None, 3, 2))\n+\n+        out = backend.compute_output_spec(\n+            example_fn, backend.KerasTensor((2, None))\n+        )\n+        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertEqual(out.shape, (2, None, 2))\n+\n+    @pytest.mark.skipif(\n+        backend.backend() != \"torch\", reason=\"Only applicable for torch\"\n+    )\n+    def test_torch_meta_device_incompatible_ops(self):\n+        class Container:\n+            def __init__(self):\n+                self.canary = False\n+\n+            def example_meta_fn(self, x):\n+                y = backend.numpy.ones(x.shape)\n+                if str(y.device) == \"meta\":\n+                    self.canary = True\n+                    raise ValueError(\"Erroring out on meta device\")\n+                x = (x + 2) * y\n+                x = backend.numpy.stack([x, x], axis=-1)\n+                return x\n+\n+        instance = Container()\n+        out = backend.compute_output_spec(\n+            instance.example_meta_fn, backend.KerasTensor((2, 3))\n+        )\n+        self.assertTrue(isinstance(out, backend.KerasTensor))\n+        self.assertTrue(instance.canary)\n+        self.assertEqual(out.shape, (2, 3, 2))\n\n@@ -214,21 +214,21 @@ def compute_output_spec(fn, *args, **kwargs):\n             # which  should give a \"zero flop\" way to trace shape, but does\n             # not have universal support with torch operations.\n             with device_scope(\"meta\"):\n-                args, kwargs = nest.map_structure(\n+                meta_args, meta_kwargs = nest.map_structure(\n                     lambda x: convert_keras_tensor_to_torch(x, fill_value),\n                     (args, kwargs),\n                 )\n-                return fn(*args, **kwargs)\n+                return fn(*meta_args, **meta_kwargs)\n         except:\n             with device_scope(get_default_device()):\n                 # If the `\"meta\"` device placement fails, fall back to tracing\n                 # eagerly with tensors on the default device. This will be\n                 # more robust, but more expensive.\n-                args, kwargs = nest.map_structure(\n+                eager_args, eager_kwargs = nest.map_structure(\n                     lambda x: convert_keras_tensor_to_torch(x, fill_value),\n                     (args, kwargs),\n                 )\n-                return fn(*args, **kwargs)\n+                return fn(*eager_args, **eager_kwargs)\n \n     with StatelessScope():\n         outputs = symbolic_call(fn, args, kwargs, fill_value=83)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
