{"custom_id": "keras#9e18fc5b99a4ecb7ec28b2a0d19d458ac0f4d364", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 17 | Files Changed: 3 | Hunks: 16 | Methods Changed: 5 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 54 | Churn Cumulative: 21718 | Contributors (this commit): 143 | Commits (past 90d): 32 | Contributors (cumulative): 177 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3413,7 +3413,8 @@ def conv1d(x, kernel, strides=1, padding='valid',\n         A tensor, result of 1D convolution.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3422,15 +3423,16 @@ def conv1d(x, kernel, strides=1, padding='valid',\n \n     kernel_shape = kernel.get_shape().as_list()\n     if padding == 'causal':\n+        if data_format != 'channels_last':\n+            raise ValueError('When using causal padding in `conv1d`, '\n+                             '`data_format` must be \"channels_last\" '\n+                             '(temporal data).')\n         # causal (dilated) convolution:\n         left_pad = dilation_rate * (kernel_shape[0] - 1)\n         x = temporal_padding(x, (left_pad, 0))\n         padding = 'valid'\n     padding = _preprocess_padding(padding)\n-    if data_format == 'channels_last':\n-        tf_data_format = 'NWC'\n-    else:\n-        tf_data_format = 'NCW'\n+    x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n     x = tf.nn.convolution(\n         input=x,\n         filter=kernel,\n@@ -3438,6 +3440,9 @@ def conv1d(x, kernel, strides=1, padding='valid',\n         strides=(strides,),\n         padding=padding,\n         data_format=tf_data_format)\n+\n+    if data_format == 'channels_first' and tf_data_format in {'NWC', 'NHWC'}:\n+        x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n     return x\n \n \n@@ -3459,7 +3464,8 @@ def conv2d(x, kernel, strides=(1, 1), padding='valid',\n         A tensor, result of 2D convolution.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3500,7 +3506,8 @@ def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n         A tensor, result of transposed 2D convolution.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3551,7 +3558,8 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n         Output tensor.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3607,7 +3615,8 @@ def separable_conv2d(x, depthwise_kernel, pointwise_kernel, strides=(1, 1),\n         Output tensor.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3648,7 +3657,8 @@ def depthwise_conv2d(x, depthwise_kernel, strides=(1, 1), padding='valid',\n         Output tensor.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3690,7 +3700,8 @@ def conv3d(x, kernel, strides=(1, 1, 1), padding='valid',\n         A tensor, result of 3D convolution.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -3729,7 +3740,8 @@ def conv3d_transpose(x, kernel, output_shape, strides=(1, 1, 1),\n         A tensor, result of transposed 3D convolution.\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n@@ -4210,7 +4222,8 @@ def local_conv1d(inputs, kernel, kernel_size, strides, data_format=None):\n         the tensor after 1d conv with un-shared weights, with shape (batch_size, output_length, filters)\n \n     # Raises\n-        ValueError: if `data_format` is neither `channels_last` or `channels_first`.\n+        ValueError: If `data_format` is neither\n+            `\"channels_last\"` nor `\"channels_first\"`.\n     \"\"\"\n     if data_format is None:\n         data_format = image_data_format()\n\n@@ -271,8 +271,10 @@ class Conv1D(_Conv):\n             one of `\"channels_last\"` (default) or `\"channels_first\"`.\n             The ordering of the dimensions in the inputs.\n             `\"channels_last\"` corresponds to inputs with shape\n-            `(batch, length, channels)` while `\"channels_first\"`\n-            corresponds to inputs with shape `(batch, channels, length)`.\n+            `(batch, length, channels)`\n+            (default format for temporal data in Keras)\n+            while `\"channels_first\"` corresponds to inputs\n+            with shape `(batch, channels, length)`.\n         dilation_rate: an integer or tuple/list of a single integer, specifying\n             the dilation rate to use for dilated convolution.\n             Currently, specifying any `dilation_rate` value != 1 is\n@@ -324,6 +326,11 @@ class Conv1D(_Conv):\n                  kernel_constraint=None,\n                  bias_constraint=None,\n                  **kwargs):\n+        if padding == 'causal':\n+            if data_format != 'channels_last':\n+                raise ValueError('When using causal padding in `Conv1D`, '\n+                                 '`data_format` must be \"channels_last\" '\n+                                 '(temporal data).')\n         super(Conv1D, self).__init__(\n             rank=1,\n             filters=filters,\n\n@@ -103,11 +103,11 @@ def test_conv_1d():\n                        'dilation_rate': 2},\n                input_shape=(batch_size, steps, input_dim))\n \n-    # Test channels_last\n+    # Test channels_first\n     layer_test(convolutional.Conv1D,\n                kwargs={'filters': filters,\n                        'kernel_size': kernel_size,\n-                       'data_format': 'channels_last'},\n+                       'data_format': 'channels_first'},\n                input_shape=(batch_size, input_dim, steps))\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#895dba6c92ad4fd9bc98975b0ae23ee6230a8b38", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 28 | Files Changed: 4 | Hunks: 13 | Methods Changed: 10 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 77 | Churn Cumulative: 10710 | Contributors (this commit): 94 | Commits (past 90d): 35 | Contributors (cumulative): 117 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2460,9 +2460,14 @@ def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=None, seed=None):\n     if seed is None:\n         seed = np.random.randint(1, 10e6)\n     rng = RandomStreams(seed=seed)\n-    normal_tensor = rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n+\n+    try:\n+        return rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype,\n+                          truncate=True)\n+    except TypeError:\n+        normal_t = rng.normal(size=shape, avg=mean, std=stddev, dtype=dtype)\n         # Poor man's truncated normal: we literally clip the tensor\n-    return T.clip(normal_tensor, mean - 2 * stddev, mean + 2 * stddev)\n+        return T.clip(normal_t, mean - 2 * stddev, mean + 2 * stddev)\n \n \n # Theano implementation of CTC\n\n@@ -208,7 +208,8 @@ class VarianceScaling(Initializer):\n         else:\n             scale /= max(1., float(fan_in + fan_out) / 2)\n         if self.distribution == 'normal':\n-            stddev = np.sqrt(scale)\n+            # 0.879... = scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)\n+            stddev = np.sqrt(scale) / .87962566103423978\n             return K.truncated_normal(shape, 0., stddev,\n                                       dtype=dtype, seed=self.seed)\n         else:\n\n@@ -1179,6 +1179,21 @@ class TestBackend(object):\n             assert np.max(rand) == 1\n             assert np.min(rand) == 0\n \n+    def test_truncated_normal(self):\n+        mean = 0.\n+        std = 1.\n+        min_val = -2.\n+        max_val = 2.\n+        for k in BACKENDS:\n+            rand = k.eval(k.truncated_normal((300, 200), mean=mean, stddev=std, seed=1337))\n+            assert rand.shape == (300, 200)\n+            assert np.abs(np.mean(rand) - mean) < 0.015\n+            assert np.max(rand) <= max_val\n+            assert np.min(rand) >= min_val\n+\n+            # assumption in initializers.VarianceScaling\n+            assert np.abs(np.std(rand) - std * 0.87962) < 0.015\n+\n     def test_conv_invalid_use(self):\n         with pytest.raises(ValueError):\n             K.conv1d(K.variable(np.ones((4, 8, 2))),\n\n@@ -41,7 +41,7 @@ def test_normal(tensor_shape):\n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n def test_truncated_normal(tensor_shape):\n     _runner(initializers.TruncatedNormal(mean=0, stddev=1), tensor_shape,\n-            target_mean=0., target_std=None, target_max=2)\n+            target_mean=0., target_max=2, target_min=-2)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n@@ -53,49 +53,49 @@ def test_constant(tensor_shape):\n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n def test_lecun_uniform(tensor_shape):\n     fan_in, _ = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(3. / fan_in)\n+    std = np.sqrt(1. / fan_in)\n     _runner(initializers.lecun_uniform(), tensor_shape,\n-            target_mean=0., target_max=scale, target_min=-scale)\n+            target_mean=0., target_std=std)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n def test_glorot_uniform(tensor_shape):\n     fan_in, fan_out = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(6. / (fan_in + fan_out))\n+    std = np.sqrt(2. / (fan_in + fan_out))\n     _runner(initializers.glorot_uniform(), tensor_shape,\n-            target_mean=0., target_max=scale, target_min=-scale)\n+            target_mean=0., target_std=std)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n def test_he_uniform(tensor_shape):\n     fan_in, _ = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(6. / fan_in)\n+    std = np.sqrt(2. / fan_in)\n     _runner(initializers.he_uniform(), tensor_shape,\n-            target_mean=0., target_max=scale, target_min=-scale)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_glorot_normal(tensor_shape):\n-    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(2. / (fan_in + fan_out))\n-    _runner(initializers.glorot_normal(), tensor_shape,\n-            target_mean=0., target_std=None, target_max=2 * scale)\n-\n-\n-@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n-def test_he_normal(tensor_shape):\n-    fan_in, _ = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(2. / fan_in)\n-    _runner(initializers.he_normal(), tensor_shape,\n-            target_mean=0., target_std=None, target_max=2 * scale)\n+            target_mean=0., target_std=std)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n def test_lecun_normal(tensor_shape):\n     fan_in, _ = initializers._compute_fans(tensor_shape)\n-    scale = np.sqrt(1. / fan_in)\n+    std = np.sqrt(1. / fan_in)\n     _runner(initializers.lecun_normal(), tensor_shape,\n-            target_mean=0., target_std=scale)\n+            target_mean=0., target_std=std)\n+\n+\n+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n+def test_glorot_normal(tensor_shape):\n+    fan_in, fan_out = initializers._compute_fans(tensor_shape)\n+    std = np.sqrt(2. / (fan_in + fan_out))\n+    _runner(initializers.glorot_normal(), tensor_shape,\n+            target_mean=0., target_std=std)\n+\n+\n+@pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n+def test_he_normal(tensor_shape):\n+    fan_in, _ = initializers._compute_fans(tensor_shape)\n+    std = np.sqrt(2. / fan_in)\n+    _runner(initializers.he_normal(), tensor_shape,\n+            target_mean=0., target_std=std)\n \n \n @pytest.mark.parametrize('tensor_shape', [FC_SHAPE, CONV_SHAPE], ids=['FC', 'CONV'])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9c689775a22f9e8647207eeae012978048d44bed", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 10 | Churn Cumulative: 9653 | Contributors (this commit): 111 | Commits (past 90d): 18 | Contributors (cumulative): 111 | DMM Complexity: 0.0\n\nDIFF:\n@@ -3325,12 +3325,12 @@ def _preprocess_conv1d_input(x, data_format):\n     \"\"\"\n     if dtype(x) == 'float64':\n         x = tf.cast(x, 'float32')\n-    tf_data_format = 'NHWC'  # to pass TF Conv2dNative operations\n+    tf_data_format = 'NWC'  # to pass TF Conv2dNative operations\n     if data_format == 'channels_first':\n         if not _has_nchw_support():\n             x = tf.transpose(x, (0, 2, 1))  # NCW -> NWC\n         else:\n-            tf_data_format = 'NCHW'\n+            tf_data_format = 'NCW'\n     return x, tf_data_format\n \n \n@@ -3441,7 +3441,7 @@ def conv1d(x, kernel, strides=1, padding='valid',\n         padding=padding,\n         data_format=tf_data_format)\n \n-    if data_format == 'channels_first' and tf_data_format in {'NWC', 'NHWC'}:\n+    if data_format == 'channels_first' and tf_data_format == 'NWC':\n         x = tf.transpose(x, (0, 2, 1))  # NWC -> NCW\n     return x\n \n@@ -3571,6 +3571,10 @@ def separable_conv1d(x, depthwise_kernel, pointwise_kernel, strides=1,\n         dilation_rate = (dilation_rate,)\n \n     x, tf_data_format = _preprocess_conv1d_input(x, data_format)\n+    if tf_data_format == 'NWC':\n+        tf_data_format = 'NHWC'\n+    else:\n+        tf_data_format = 'NCHW'\n     padding = _preprocess_padding(padding)\n     if tf_data_format == 'NHWC':\n         spatial_start_dim = 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83651e616f79b0f2c45eb634b92c2932fd53835c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 1079 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -251,6 +251,7 @@ def load_model(filepath, custom_objects=None, compile=True):\n     else:\n         f = filepath\n \n+    model = None\n     try:\n         # instantiate model\n         model_config = f.attrs.get('model_config')\n@@ -262,15 +263,13 @@ def load_model(filepath, custom_objects=None, compile=True):\n         # set weights\n         load_weights_from_hdf5_group(f['model_weights'], model.layers)\n \n-        # Early return if compilation is not required.\n-        if not compile:\n-            return model\n-\n+        if compile:\n             # instantiate optimizer\n             training_config = f.attrs.get('training_config')\n             if training_config is None:\n                 warnings.warn('No training configuration found in save file: '\n-                          'the model was *not* compiled. Compile it manually.')\n+                              'the model was *not* compiled. '\n+                              'Compile it manually.')\n                 return model\n             training_config = json.loads(training_config.decode('utf-8'))\n             optimizer_config = training_config['optimizer_config']\n@@ -310,10 +309,10 @@ def load_model(filepath, custom_objects=None, compile=True):\n                                   'state. As a result, your model is '\n                                   'starting with a freshly initialized '\n                                   'optimizer.')\n-        return model\n     finally:\n         if opened_new_file:\n             f.close()\n+    return model\n \n \n def model_from_config(config, custom_objects=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e4ddf0f39cdb5f3ac599a687557e734cf5f28a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 31 | Files Changed: 4 | Hunks: 14 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 55 | Churn Cumulative: 13738 | Contributors (this commit): 81 | Commits (past 90d): 11 | Contributors (cumulative): 99 | DMM Complexity: 1.0\n\nDIFF:\n@@ -259,25 +259,23 @@ def ResNet50(include_top=True, weights='imagenet',\n     # load weights\n     if weights == 'imagenet':\n         if include_top:\n-            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n+            weights_path = get_file(\n+                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n                 WEIGHTS_PATH,\n                 cache_subdir='models',\n                 md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n         else:\n-            weights_path = get_file('resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+            weights_path = get_file(\n+                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                 WEIGHTS_PATH_NO_TOP,\n                 cache_subdir='models',\n                 md5_hash='a268eb855778b3df3c7506639542a6af')\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n-            if include_top:\n-                maxpool = model.get_layer(name='avg_pool')\n-                shape = maxpool.output_shape[1:]\n-                dense = model.get_layer(name='fc1000')\n-                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n \n-        if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n+        if (K.image_data_format() == 'channels_first' and\n+                K.backend() == 'tensorflow'):\n             warnings.warn('You are using the TensorFlow backend, yet you '\n                           'are using the Theano '\n                           'image data format convention '\n@@ -285,7 +283,7 @@ def ResNet50(include_top=True, weights='imagenet',\n                           'For best performance, set '\n                           '`image_data_format=\"channels_last\"` in '\n                           'your Keras config '\n-                          'at ~/.keras/keras.json.')\n+                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -164,12 +164,14 @@ def VGG16(include_top=True, weights='imagenet',\n     # load weights\n     if weights == 'imagenet':\n         if include_top:\n-            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n+            weights_path = get_file(\n+                'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n                 WEIGHTS_PATH,\n                 cache_subdir='models',\n                 file_hash='64373286793e3c8b2b4e3219cbf3544b')\n         else:\n-            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+            weights_path = get_file(\n+                'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                 WEIGHTS_PATH_NO_TOP,\n                 cache_subdir='models',\n                 file_hash='6d6bbae143d832006294945121d1f1fc')\n@@ -177,14 +179,8 @@ def VGG16(include_top=True, weights='imagenet',\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n \n-        if K.image_data_format() == 'channels_first':\n-            if include_top:\n-                maxpool = model.get_layer(name='block5_pool')\n-                shape = maxpool.output_shape[1:]\n-                dense = model.get_layer(name='fc1')\n-                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n-\n-            if K.backend() == 'tensorflow':\n+        if (K.image_data_format() == 'channels_first' and\n+                K.backend() == 'tensorflow'):\n             warnings.warn('You are using the TensorFlow backend, yet you '\n                           'are using the Theano '\n                           'image data format convention '\n@@ -192,7 +188,7 @@ def VGG16(include_top=True, weights='imagenet',\n                           'For best performance, set '\n                           '`image_data_format=\"channels_last\"` in '\n                           'your Keras config '\n-                              'at ~/.keras/keras.json.')\n+                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -167,12 +167,14 @@ def VGG19(include_top=True, weights='imagenet',\n     # load weights\n     if weights == 'imagenet':\n         if include_top:\n-            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n+            weights_path = get_file(\n+                'vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n                 WEIGHTS_PATH,\n                 cache_subdir='models',\n                 file_hash='cbe5617147190e668d6c5d5026f83318')\n         else:\n-            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n+            weights_path = get_file(\n+                'vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                 WEIGHTS_PATH_NO_TOP,\n                 cache_subdir='models',\n                 file_hash='253f8cb515780f3b799900260a226db6')\n@@ -180,14 +182,8 @@ def VGG19(include_top=True, weights='imagenet',\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n \n-        if K.image_data_format() == 'channels_first':\n-            if include_top:\n-                maxpool = model.get_layer(name='block5_pool')\n-                shape = maxpool.output_shape[1:]\n-                dense = model.get_layer(name='fc1')\n-                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n-\n-            if K.backend() == 'tensorflow':\n+        if (K.image_data_format() == 'channels_first' and\n+                K.backend() == 'tensorflow'):\n             warnings.warn('You are using the TensorFlow backend, yet you '\n                           'are using the Theano '\n                           'image data format convention '\n@@ -195,7 +191,7 @@ def VGG19(include_top=True, weights='imagenet',\n                           'For best performance, set '\n                           '`image_data_format=\"channels_last\"` in '\n                           'your Keras config '\n-                              'at ~/.keras/keras.json.')\n+                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -470,6 +470,9 @@ class Flatten(Layer):\n         data_format: A string,\n             one of `channels_last` (default) or `channels_first`.\n             The ordering of the dimensions in the inputs.\n+            The purpose of this argument is to preserve weight\n+            ordering when switching a model from one data format\n+            to another.\n             `channels_last` corresponds to inputs with shape\n             `(batch, ..., channels)` while `channels_first` corresponds to\n             inputs with shape `(batch, channels, ...)`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b0f1bb9c7c68e24137a9dc284dc210eb0050a6b4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 53 | Files Changed: 5 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): -10/0 | Churn Δ: 53 | Churn Cumulative: 2658 | Contributors (this commit): 13 | Commits (past 90d): 14 | Contributors (cumulative): 38 | DMM Complexity: 1.0\n\nDIFF:\n@@ -352,16 +352,6 @@ def InceptionResNetV2(include_top=True,\n \n     # Load weights\n     if weights == 'imagenet':\n-        if K.image_data_format() == 'channels_first':\n-            if K.backend() == 'tensorflow':\n-                warnings.warn('You are using the TensorFlow backend, yet you '\n-                              'are using the Theano '\n-                              'image data format convention '\n-                              '(`image_data_format=\"channels_first\"`). '\n-                              'For best performance, set '\n-                              '`image_data_format=\"channels_last\"` in '\n-                              'your Keras config '\n-                              'at ~/.keras/keras.json.')\n         if include_top:\n             fname = 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'\n             weights_path = get_file(fname,\n\n@@ -366,16 +366,6 @@ def InceptionV3(include_top=True,\n \n     # load weights\n     if weights == 'imagenet':\n-        if K.image_data_format() == 'channels_first':\n-            if K.backend() == 'tensorflow':\n-                warnings.warn('You are using the TensorFlow backend, yet you '\n-                              'are using the Theano '\n-                              'image data format convention '\n-                              '(`image_data_format=\"channels_first\"`). '\n-                              'For best performance, set '\n-                              '`image_data_format=\"channels_last\"` in '\n-                              'your Keras config '\n-                              'at ~/.keras/keras.json.')\n         if include_top:\n             weights_path = get_file(\n                 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n\n@@ -273,17 +273,6 @@ def ResNet50(include_top=True, weights='imagenet',\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n-\n-        if (K.image_data_format() == 'channels_first' and\n-                K.backend() == 'tensorflow'):\n-            warnings.warn('You are using the TensorFlow backend, yet you '\n-                          'are using the Theano '\n-                          'image data format convention '\n-                          '(`image_data_format=\"channels_first\"`). '\n-                          'For best performance, set '\n-                          '`image_data_format=\"channels_last\"` in '\n-                          'your Keras config '\n-                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -178,17 +178,6 @@ def VGG16(include_top=True, weights='imagenet',\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n-\n-        if (K.image_data_format() == 'channels_first' and\n-                K.backend() == 'tensorflow'):\n-            warnings.warn('You are using the TensorFlow backend, yet you '\n-                          'are using the Theano '\n-                          'image data format convention '\n-                          '(`image_data_format=\"channels_first\"`). '\n-                          'For best performance, set '\n-                          '`image_data_format=\"channels_last\"` in '\n-                          'your Keras config '\n-                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n@@ -181,17 +181,6 @@ def VGG19(include_top=True, weights='imagenet',\n         model.load_weights(weights_path)\n         if K.backend() == 'theano':\n             layer_utils.convert_all_kernels_in_model(model)\n-\n-        if (K.image_data_format() == 'channels_first' and\n-                K.backend() == 'tensorflow'):\n-            warnings.warn('You are using the TensorFlow backend, yet you '\n-                          'are using the Theano '\n-                          'image data format convention '\n-                          '(`image_data_format=\"channels_first\"`). '\n-                          'For best performance, set '\n-                          '`image_data_format=\"channels_last\"` in '\n-                          'your Keras config '\n-                          'at `~/.keras/keras.json`.')\n     elif weights is not None:\n         model.load_weights(weights)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c405b38f1e26317e5dfdc6edead7e37c86759e8e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 664 | Contributors (this commit): 12 | Commits (past 90d): 4 | Contributors (cumulative): 12 | DMM Complexity: None\n\nDIFF:\n@@ -234,8 +234,8 @@ def test_Bidirectional():\n @keras_test\n @pytest.mark.skipif((K.backend() == 'cntk'),\n                     reason='Unknown timestamps not supported in CNTK.')\n-def test_Bidirectional_unkown_timespamps():\n-    # test with functional API with unknown length\n+def test_Bidirectional_dynamic_timesteps():\n+    # test with functional API with dynamic length\n     rnn = layers.SimpleRNN\n     samples = 2\n     dim = 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ba6f4945858bdf02bf10fc833430fb77894693db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 3 | Churn Cumulative: 2967 | Contributors (this commit): 70 | Commits (past 90d): 8 | Contributors (cumulative): 70 | DMM Complexity: 0.0\n\nDIFF:\n@@ -249,9 +249,6 @@ class TerminateOnNaN(Callback):\n     \"\"\"Callback that terminates training when a NaN loss is encountered.\n     \"\"\"\n \n-    def __init__(self):\n-        super(TerminateOnNaN, self).__init__()\n-\n     def on_batch_end(self, batch, logs=None):\n         logs = logs or {}\n         loss = logs.get('loss')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bfc6a25a6e7ade316922fc8bf83748553fbb39c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 417 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -157,7 +157,6 @@ def fit_loop(model, f, ins,\n \n             if do_validation:\n                 val_outs = test_loop(model, val_f, val_ins,\n-                                     batch_size=batch_size,\n                                      steps=validation_steps,\n                                      verbose=0)\n                 if not isinstance(val_outs, list):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a80ecd78daf7d464a6ff915111f62b8cd21c8b6b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 5 | Churn Cumulative: 422 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: 0.0\n\nDIFF:\n@@ -76,6 +76,11 @@ def fit_loop(model, f, ins,\n                              'when doing step-wise '\n                              'training, i.e. `steps_per_epoch` '\n                              'must be set.')\n+    elif do_validation:\n+        if steps_per_epoch:\n+            raise ValueError('Must specify `validation_steps` '\n+                             'to perform validation '\n+                             'when doing step-wise training.')\n \n     num_train_samples = check_num_samples(ins,\n                                           batch_size=batch_size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4a075dab06daf893be3c197914eff395d37769c6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 15 | Churn Cumulative: 2228 | Contributors (this commit): 13 | Commits (past 90d): 4 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -622,15 +622,20 @@ class ConvLSTM2DCell(Layer):\n             regularizer=self.recurrent_regularizer,\n             constraint=self.recurrent_constraint)\n         if self.use_bias:\n+            if self.unit_forget_bias:\n+                def bias_initializer(_, *args, **kwargs):\n+                    return K.concatenate([\n+                        self.bias_initializer((self.filters,), *args, **kwargs),\n+                        initializers.Ones()((self.filters,), *args, **kwargs),\n+                        self.bias_initializer((self.filters * 2,), *args, **kwargs),\n+                    ])\n+            else:\n+                bias_initializer = self.bias_initializer\n             self.bias = self.add_weight(shape=(self.filters * 4,),\n-                                        initializer=self.bias_initializer,\n                                         name='bias',\n+                                        initializer=bias_initializer,\n                                         regularizer=self.bias_regularizer,\n                                         constraint=self.bias_constraint)\n-            if self.unit_forget_bias:\n-                bias_value = np.zeros((self.filters * 4,))\n-                bias_value[self.filters: self.filters * 2] = 1.\n-                K.set_value(self.bias, bias_value)\n         else:\n             self.bias = None\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#528542176f70f9a889e84e4494032f42a53bec67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 2232 | Contributors (this commit): 30 | Commits (past 90d): 2 | Contributors (cumulative): 30 | DMM Complexity: None\n\nDIFF:\n@@ -175,7 +175,7 @@ class SGD(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n         # momentum\n         shapes = [K.int_shape(p) for p in params]\n@@ -248,7 +248,7 @@ class RMSprop(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n \n         for p, g, a in zip(params, grads, accumulators):\n@@ -309,7 +309,7 @@ class Adagrad(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n \n         for p, g, a in zip(params, grads, accumulators):\n@@ -373,7 +373,7 @@ class Adadelta(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n \n         for p, g, a, d_a in zip(params, grads, accumulators, delta_accumulators):\n@@ -447,7 +447,7 @@ class Adam(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n \n         t = K.cast(self.iterations, K.floatx()) + 1\n@@ -531,7 +531,7 @@ class Adamax(Optimizer):\n \n         lr = self.lr\n         if self.initial_decay > 0:\n-            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n+            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n                                                       K.dtype(self.decay))))\n \n         t = K.cast(self.iterations, K.floatx()) + 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#978efb61b9cea47ddc2b5226cefee2a890693557", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 22 | Churn Cumulative: 804 | Contributors (this commit): 13 | Commits (past 90d): 5 | Contributors (cumulative): 16 | DMM Complexity: 0.9285714285714286\n\nDIFF:\n@@ -38,7 +38,8 @@ def _preprocess_numpy_input(x, data_format, mode):\n     # Returns\n         Preprocessed Numpy array.\n     \"\"\"\n-    x = x.astype(K.floatx())\n+    if not issubclass(x.dtype.type, np.floating):\n+        x = x.astype(K.floatx(), copy=False)\n \n     if mode == 'tf':\n         x /= 127.5\n@@ -153,6 +154,9 @@ def preprocess_input(x, data_format=None, mode='caffe'):\n \n     # Arguments\n         x: Input Numpy or symbolic tensor, 3D or 4D.\n+            The preprocessed data is written over the input data\n+            if the data types are compatible. To avoid this\n+            behaviour, `numpy.copy(x)` can be used.\n         data_format: Data format of the image tensor/array.\n         mode: One of \"caffe\", \"tf\" or \"torch\".\n             - caffe: will convert the images from RGB to BGR,\n\n@@ -38,6 +38,22 @@ def test_preprocess_input():\n     assert_allclose(out1, out2.transpose(1, 2, 0))\n     assert_allclose(out1int, out2int.transpose(1, 2, 0))\n \n+    # Test that writing over the input data works predictably\n+    for mode in ['torch', 'tf']:\n+        x = np.random.uniform(0, 255, (2, 10, 10, 3))\n+        xint = x.astype('int')\n+        x2 = utils.preprocess_input(x, mode=mode)\n+        xint2 = utils.preprocess_input(xint)\n+        assert_allclose(x, x2)\n+        assert xint.astype('float').max() != xint2.max()\n+    # Caffe mode works differently from the others\n+    x = np.random.uniform(0, 255, (2, 10, 10, 3))\n+    xint = x.astype('int')\n+    x2 = utils.preprocess_input(x, data_format='channels_last', mode='caffe')\n+    xint2 = utils.preprocess_input(xint)\n+    assert_allclose(x, x2[..., ::-1])\n+    assert xint.astype('float').max() != xint2.max()\n+\n \n def test_preprocess_input_symbolic():\n     # Test image batch\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ba6d95e768eb7a0d74a6fda3ea893e7fb2d7a67", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 371 | Lines Deleted: 230 | Files Changed: 2 | Hunks: 43 | Methods Changed: 4 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 601 | Churn Cumulative: 1377 | Contributors (this commit): 14 | Commits (past 90d): 2 | Contributors (cumulative): 22 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,111 +1,207 @@\n-'''This script demonstrates how to build a variational autoencoder with Keras.\n+'''Example of VAE on MNIST dataset using MLP\n+\n+The VAE has a modular design. The encoder, decoder and VAE\n+are 3 models that share weights. After training the VAE model,\n+the encoder can be used to  generate latent vectors.\n+The decoder can be used to generate MNIST digits by sampling the\n+latent vector from a Gaussian distribution with mean=0 and std=1.\n \n # Reference\n \n- - Auto-Encoding Variational Bayes\n+[1] Kingma, Diederik P., and Max Welling.\n+\"Auto-encoding variational bayes.\"\n https://arxiv.org/abs/1312.6114\n '''\n+\n+from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n+from keras.layers import Lambda, Input, Dense\n+from keras.models import Model\n+from keras.datasets import mnist\n+from keras.losses import mse, binary_crossentropy\n+from keras.utils import plot_model\n+from keras import backend as K\n+\n import numpy as np\n import matplotlib.pyplot as plt\n-from scipy.stats import norm\n-\n-from keras.layers import Input, Dense, Lambda\n-from keras.models import Model\n-from keras import backend as K\n-from keras import metrics\n-from keras.datasets import mnist\n-\n-batch_size = 100\n-original_dim = 784\n-latent_dim = 2\n-intermediate_dim = 256\n-epochs = 50\n-epsilon_std = 1.0\n-\n-\n-x = Input(shape=(original_dim,))\n-h = Dense(intermediate_dim, activation='relu')(x)\n-z_mean = Dense(latent_dim)(h)\n-z_log_var = Dense(latent_dim)(h)\n+import argparse\n+import os\n \n \n+# reparameterization trick\n+# instead of sampling from Q(z|X), sample eps = N(0,I)\n+# z = z_mean + sqrt(var)*eps\n def sampling(args):\n+    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n+\n+    # Arguments:\n+        args (tensor): mean and log of variance of Q(z|X)\n+\n+    # Returns:\n+        z (tensor): sampled latent vector\n+    \"\"\"\n+\n     z_mean, z_log_var = args\n-    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n-                              stddev=epsilon_std)\n-    return z_mean + K.exp(z_log_var / 2) * epsilon\n-\n-# note that \"output_shape\" isn't necessary with the TensorFlow backend\n-z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n-\n-# we instantiate these layers separately so as to reuse them later\n-decoder_h = Dense(intermediate_dim, activation='relu')\n-decoder_mean = Dense(original_dim, activation='sigmoid')\n-h_decoded = decoder_h(z)\n-x_decoded_mean = decoder_mean(h_decoded)\n-\n-# instantiate VAE model\n-vae = Model(x, x_decoded_mean)\n-\n-# Compute VAE loss\n-xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n-kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n-vae_loss = K.mean(xent_loss + kl_loss)\n-\n-vae.add_loss(vae_loss)\n-vae.compile(optimizer='rmsprop')\n-vae.summary()\n+    batch = K.shape(z_mean)[0]\n+    dim = K.int_shape(z_mean)[1]\n+    # by default, random_normal has mean=0 and std=1.0\n+    epsilon = K.random_normal(shape=(batch, dim))\n+    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n \n \n-# train the VAE on MNIST digits\n-(x_train, y_train), (x_test, y_test) = mnist.load_data()\n+def plot_results(models,\n+                 data,\n+                 batch_size=128,\n+                 model_name=\"vae_mnist\"):\n+    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n \n-x_train = x_train.astype('float32') / 255.\n-x_test = x_test.astype('float32') / 255.\n-x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n-x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n+    # Arguments:\n+        models (tuple): encoder and decoder models\n+        data (tuple): test data and label\n+        batch_size (int): prediction batch size\n+        model_name (string): which model is using this function\n+    \"\"\"\n \n-vae.fit(x_train,\n-        shuffle=True,\n-        epochs=epochs,\n-        batch_size=batch_size,\n-        validation_data=(x_test, None))\n-\n-# build a model to project inputs on the latent space\n-encoder = Model(x, z_mean)\n+    encoder, decoder = models\n+    x_test, y_test = data\n+    os.makedirs(model_name, exist_ok=True)\n \n+    filename = os.path.join(model_name, \"vae_mean.png\")\n     # display a 2D plot of the digit classes in the latent space\n-x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n-plt.figure(figsize=(6, 6))\n-plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n+    z_mean, _, _ = encoder.predict(x_test,\n+                                   batch_size=batch_size)\n+    plt.figure(figsize=(12, 10))\n+    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n     plt.colorbar()\n+    plt.xlabel(\"z[0]\")\n+    plt.ylabel(\"z[1]\")\n+    plt.savefig(filename)\n     plt.show()\n \n-# build a digit generator that can sample from the learned distribution\n-decoder_input = Input(shape=(latent_dim,))\n-_h_decoded = decoder_h(decoder_input)\n-_x_decoded_mean = decoder_mean(_h_decoded)\n-generator = Model(decoder_input, _x_decoded_mean)\n-\n-# display a 2D manifold of the digits\n-n = 15  # figure with 15x15 digits\n+    filename = os.path.join(model_name, \"digits_over_latent.png\")\n+    # display a 30x30 2D manifold of digits\n+    n = 30\n     digit_size = 28\n     figure = np.zeros((digit_size * n, digit_size * n))\n-# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n-# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n-grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n-grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n+    # linearly spaced coordinates corresponding to the 2D plot\n+    # of digit classes in the latent space\n+    grid_x = np.linspace(-4, 4, n)\n+    grid_y = np.linspace(-4, 4, n)[::-1]\n \n-for i, yi in enumerate(grid_x):\n-    for j, xi in enumerate(grid_y):\n+    for i, yi in enumerate(grid_y):\n+        for j, xi in enumerate(grid_x):\n             z_sample = np.array([[xi, yi]])\n-        x_decoded = generator.predict(z_sample)\n+            x_decoded = decoder.predict(z_sample)\n             digit = x_decoded[0].reshape(digit_size, digit_size)\n             figure[i * digit_size: (i + 1) * digit_size,\n                    j * digit_size: (j + 1) * digit_size] = digit\n \n     plt.figure(figsize=(10, 10))\n+    start_range = digit_size // 2\n+    end_range = n * digit_size + start_range + 1\n+    pixel_range = np.arange(start_range, end_range, digit_size)\n+    sample_range_x = np.round(grid_x, 1)\n+    sample_range_y = np.round(grid_y, 1)\n+    plt.xticks(pixel_range, sample_range_x)\n+    plt.yticks(pixel_range, sample_range_y)\n+    plt.xlabel(\"z[0]\")\n+    plt.ylabel(\"z[1]\")\n     plt.imshow(figure, cmap='Greys_r')\n+    plt.savefig(filename)\n     plt.show()\n+\n+\n+# MNIST dataset\n+(x_train, y_train), (x_test, y_test) = mnist.load_data()\n+\n+image_size = x_train.shape[1]\n+original_dim = image_size * image_size\n+x_train = np.reshape(x_train, [-1, original_dim])\n+x_test = np.reshape(x_test, [-1, original_dim])\n+x_train = x_train.astype('float32') / 255\n+x_test = x_test.astype('float32') / 255\n+\n+# network parameters\n+input_shape = (original_dim, )\n+intermediate_dim = 512\n+batch_size = 128\n+latent_dim = 2\n+epochs = 50\n+\n+# VAE model = encoder + decoder\n+# build encoder model\n+inputs = Input(shape=input_shape, name='encoder_input')\n+x = Dense(intermediate_dim, activation='relu')(inputs)\n+z_mean = Dense(latent_dim, name='z_mean')(x)\n+z_log_var = Dense(latent_dim, name='z_log_var')(x)\n+\n+# use reparameterization trick to push the sampling out as input\n+# note that \"output_shape\" isn't necessary with the TensorFlow backend\n+z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n+\n+# instantiate encoder model\n+encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n+encoder.summary()\n+plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n+\n+# build decoder model\n+latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n+x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n+outputs = Dense(original_dim, activation='sigmoid')(x)\n+\n+# instantiate decoder model\n+decoder = Model(latent_inputs, outputs, name='decoder')\n+decoder.summary()\n+plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n+\n+# instantiate VAE model\n+outputs = decoder(encoder(inputs)[2])\n+vae = Model(inputs, outputs, name='vae_mlp')\n+\n+if __name__ == '__main__':\n+    parser = argparse.ArgumentParser()\n+    help_ = \"Load h5 model trained weights\"\n+    parser.add_argument(\"-w\", \"--weights\", help=help_)\n+    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n+    parser.add_argument(\"-m\",\n+                        \"--mse\",\n+                        help=help_, action='store_true')\n+    args = parser.parse_args()\n+    models = (encoder, decoder)\n+    data = (x_test, y_test)\n+\n+    # VAE loss = mse_loss or xent_loss + kl_loss\n+    if args.mse:\n+        reconstruction_loss = mse(inputs, outputs)\n+    else:\n+        reconstruction_loss = binary_crossentropy(inputs,\n+                                                  outputs)\n+\n+    reconstruction_loss *= original_dim\n+    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n+    kl_loss = K.sum(kl_loss, axis=-1)\n+    kl_loss *= -0.5\n+    vae_loss = K.mean(reconstruction_loss + kl_loss)\n+    vae.add_loss(vae_loss)\n+    vae.compile(optimizer='adam')\n+    vae.summary()\n+    plot_model(vae,\n+               to_file='vae_mlp.png',\n+               show_shapes=True)\n+\n+    if args.weights:\n+        vae = vae.load_weights(args.weights)\n+    else:\n+        # train the autoencoder\n+        vae.fit(x_train,\n+                epochs=epochs,\n+                batch_size=batch_size,\n+                validation_data=(x_test, None))\n+        vae.save_weights('vae_mlp_mnist.h5')\n+\n+    plot_results(models,\n+                 data,\n+                 batch_size=batch_size,\n+                 model_name=\"vae_mlp\")\n\n@@ -1,185 +1,230 @@\n-'''This script demonstrates how to build a variational autoencoder\n-with Keras and deconvolution layers.\n+'''Example of VAE on MNIST dataset using CNN\n+\n+The VAE has a modular design. The encoder, decoder and VAE\n+are 3 models that share weights. After training the VAE model,\n+the encoder can be used to  generate latent vectors.\n+The decoder can be used to generate MNIST digits by sampling the\n+latent vector from a Gaussian distribution with mean=0 and std=1.\n \n # Reference\n \n-- Auto-Encoding Variational Bayes\n+[1] Kingma, Diederik P., and Max Welling.\n+\"Auto-encoding variational bayes.\"\n https://arxiv.org/abs/1312.6114\n '''\n+\n+from __future__ import absolute_import\n+from __future__ import division\n from __future__ import print_function\n \n+from keras.layers import Dense, Input\n+from keras.layers import Conv2D, Flatten, Lambda\n+from keras.layers import Reshape, Conv2DTranspose\n+from keras.models import Model\n+from keras.datasets import mnist\n+from keras.losses import mse, binary_crossentropy\n+from keras.utils import plot_model\n+from keras import backend as K\n+\n import numpy as np\n import matplotlib.pyplot as plt\n-from scipy.stats import norm\n-\n-from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n-from keras.layers import Conv2D, Conv2DTranspose\n-from keras.models import Model\n-from keras import backend as K\n-from keras import metrics\n-from keras.datasets import mnist\n-\n-# input image dimensions\n-img_rows, img_cols, img_chns = 28, 28, 1\n-# number of convolutional filters to use\n-filters = 64\n-# convolution kernel size\n-num_conv = 3\n-\n-batch_size = 100\n-if K.image_data_format() == 'channels_first':\n-    original_img_size = (img_chns, img_rows, img_cols)\n-else:\n-    original_img_size = (img_rows, img_cols, img_chns)\n-latent_dim = 2\n-intermediate_dim = 128\n-epsilon_std = 1.0\n-epochs = 5\n-\n-x = Input(shape=original_img_size)\n-conv_1 = Conv2D(img_chns,\n-                kernel_size=(2, 2),\n-                padding='same', activation='relu')(x)\n-conv_2 = Conv2D(filters,\n-                kernel_size=(2, 2),\n-                padding='same', activation='relu',\n-                strides=(2, 2))(conv_1)\n-conv_3 = Conv2D(filters,\n-                kernel_size=num_conv,\n-                padding='same', activation='relu',\n-                strides=1)(conv_2)\n-conv_4 = Conv2D(filters,\n-                kernel_size=num_conv,\n-                padding='same', activation='relu',\n-                strides=1)(conv_3)\n-flat = Flatten()(conv_4)\n-hidden = Dense(intermediate_dim, activation='relu')(flat)\n-\n-z_mean = Dense(latent_dim)(hidden)\n-z_log_var = Dense(latent_dim)(hidden)\n+import argparse\n+import os\n \n \n+# reparameterization trick\n+# instead of sampling from Q(z|X), sample eps = N(0,I)\n+# then z = z_mean + sqrt(var)*eps\n def sampling(args):\n+    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n+\n+    # Arguments:\n+        args (tensor): mean and log of variance of Q(z|X)\n+\n+    # Returns:\n+        z (tensor): sampled latent vector\n+    \"\"\"\n+\n     z_mean, z_log_var = args\n-    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n-                              mean=0., stddev=epsilon_std)\n-    return z_mean + K.exp(z_log_var) * epsilon\n+    batch = K.shape(z_mean)[0]\n+    dim = K.int_shape(z_mean)[1]\n+    # by default, random_normal has mean=0 and std=1.0\n+    epsilon = K.random_normal(shape=(batch, dim))\n+    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n \n-# note that \"output_shape\" isn't necessary with the TensorFlow backend\n-# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n-z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n \n-# we instantiate these layers separately so as to reuse them later\n-decoder_hid = Dense(intermediate_dim, activation='relu')\n-decoder_upsample = Dense(filters * 14 * 14, activation='relu')\n+def plot_results(models,\n+                 data,\n+                 batch_size=128,\n+                 model_name=\"vae_mnist\"):\n+    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n \n-if K.image_data_format() == 'channels_first':\n-    output_shape = (batch_size, filters, 14, 14)\n-else:\n-    output_shape = (batch_size, 14, 14, filters)\n+    # Arguments:\n+        models (tuple): encoder and decoder models\n+        data (tuple): test data and label\n+        batch_size (int): prediction batch size\n+        model_name (string): which model is using this function\n+    \"\"\"\n \n-decoder_reshape = Reshape(output_shape[1:])\n-decoder_deconv_1 = Conv2DTranspose(filters,\n-                                   kernel_size=num_conv,\n-                                   padding='same',\n-                                   strides=1,\n-                                   activation='relu')\n-decoder_deconv_2 = Conv2DTranspose(filters,\n-                                   kernel_size=num_conv,\n-                                   padding='same',\n-                                   strides=1,\n-                                   activation='relu')\n-if K.image_data_format() == 'channels_first':\n-    output_shape = (batch_size, filters, 29, 29)\n-else:\n-    output_shape = (batch_size, 29, 29, filters)\n-decoder_deconv_3_upsamp = Conv2DTranspose(filters,\n-                                          kernel_size=(3, 3),\n-                                          strides=(2, 2),\n-                                          padding='valid',\n-                                          activation='relu')\n-decoder_mean_squash = Conv2D(img_chns,\n-                             kernel_size=2,\n-                             padding='valid',\n-                             activation='sigmoid')\n-\n-hid_decoded = decoder_hid(z)\n-up_decoded = decoder_upsample(hid_decoded)\n-reshape_decoded = decoder_reshape(up_decoded)\n-deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n-deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n-x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n-x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n-\n-# instantiate VAE model\n-vae = Model(x, x_decoded_mean_squash)\n-\n-# Compute VAE loss\n-xent_loss = img_rows * img_cols * metrics.binary_crossentropy(\n-    K.flatten(x),\n-    K.flatten(x_decoded_mean_squash))\n-kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n-vae_loss = K.mean(xent_loss + kl_loss)\n-vae.add_loss(vae_loss)\n-\n-vae.compile(optimizer='rmsprop')\n-vae.summary()\n-\n-# train the VAE on MNIST digits\n-(x_train, _), (x_test, y_test) = mnist.load_data()\n-\n-x_train = x_train.astype('float32') / 255.\n-x_train = x_train.reshape((x_train.shape[0],) + original_img_size)\n-x_test = x_test.astype('float32') / 255.\n-x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n-\n-print('x_train.shape:', x_train.shape)\n-\n-vae.fit(x_train,\n-        shuffle=True,\n-        epochs=epochs,\n-        batch_size=batch_size,\n-        validation_data=(x_test, None))\n-\n-# build a model to project inputs on the latent space\n-encoder = Model(x, z_mean)\n+    encoder, decoder = models\n+    x_test, y_test = data\n+    os.makedirs(model_name, exist_ok=True)\n \n+    filename = os.path.join(model_name, \"vae_mean.png\")\n     # display a 2D plot of the digit classes in the latent space\n-x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n-plt.figure(figsize=(6, 6))\n-plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n+    z_mean, _, _ = encoder.predict(x_test,\n+                                   batch_size=batch_size)\n+    plt.figure(figsize=(12, 10))\n+    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n     plt.colorbar()\n+    plt.xlabel(\"z[0]\")\n+    plt.ylabel(\"z[1]\")\n+    plt.savefig(filename)\n     plt.show()\n \n-# build a digit generator that can sample from the learned distribution\n-decoder_input = Input(shape=(latent_dim,))\n-_hid_decoded = decoder_hid(decoder_input)\n-_up_decoded = decoder_upsample(_hid_decoded)\n-_reshape_decoded = decoder_reshape(_up_decoded)\n-_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n-_deconv_2_decoded = decoder_deconv_2(_deconv_1_decoded)\n-_x_decoded_relu = decoder_deconv_3_upsamp(_deconv_2_decoded)\n-_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n-generator = Model(decoder_input, _x_decoded_mean_squash)\n-\n-# display a 2D manifold of the digits\n-n = 15  # figure with 15x15 digits\n+    filename = os.path.join(model_name, \"digits_over_latent.png\")\n+    # display a 30x30 2D manifold of digits\n+    n = 30\n     digit_size = 28\n     figure = np.zeros((digit_size * n, digit_size * n))\n-# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n-# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n-grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n-grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n+    # linearly spaced coordinates corresponding to the 2D plot\n+    # of digit classes in the latent space\n+    grid_x = np.linspace(-4, 4, n)\n+    grid_y = np.linspace(-4, 4, n)[::-1]\n \n-for i, yi in enumerate(grid_x):\n-    for j, xi in enumerate(grid_y):\n+    for i, yi in enumerate(grid_y):\n+        for j, xi in enumerate(grid_x):\n             z_sample = np.array([[xi, yi]])\n-        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n-        x_decoded = generator.predict(z_sample, batch_size=batch_size)\n+            x_decoded = decoder.predict(z_sample)\n             digit = x_decoded[0].reshape(digit_size, digit_size)\n             figure[i * digit_size: (i + 1) * digit_size,\n                    j * digit_size: (j + 1) * digit_size] = digit\n \n     plt.figure(figsize=(10, 10))\n+    start_range = digit_size // 2\n+    end_range = n * digit_size + start_range + 1\n+    pixel_range = np.arange(start_range, end_range, digit_size)\n+    sample_range_x = np.round(grid_x, 1)\n+    sample_range_y = np.round(grid_y, 1)\n+    plt.xticks(pixel_range, sample_range_x)\n+    plt.yticks(pixel_range, sample_range_y)\n+    plt.xlabel(\"z[0]\")\n+    plt.ylabel(\"z[1]\")\n     plt.imshow(figure, cmap='Greys_r')\n+    plt.savefig(filename)\n     plt.show()\n+\n+\n+# MNIST dataset\n+(x_train, y_train), (x_test, y_test) = mnist.load_data()\n+\n+image_size = x_train.shape[1]\n+x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n+x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n+x_train = x_train.astype('float32') / 255\n+x_test = x_test.astype('float32') / 255\n+\n+# network parameters\n+input_shape = (image_size, image_size, 1)\n+batch_size = 128\n+kernel_size = 3\n+filters = 16\n+latent_dim = 2\n+epochs = 30\n+\n+# VAE model = encoder + decoder\n+# build encoder model\n+inputs = Input(shape=input_shape, name='encoder_input')\n+x = inputs\n+for i in range(2):\n+    filters *= 2\n+    x = Conv2D(filters=filters,\n+               kernel_size=kernel_size,\n+               activation='relu',\n+               strides=2,\n+               padding='same')(x)\n+\n+# shape info needed to build decoder model\n+shape = K.int_shape(x)\n+\n+# generate latent vector Q(z|X)\n+x = Flatten()(x)\n+x = Dense(16, activation='relu')(x)\n+z_mean = Dense(latent_dim, name='z_mean')(x)\n+z_log_var = Dense(latent_dim, name='z_log_var')(x)\n+\n+# use reparameterization trick to push the sampling out as input\n+# note that \"output_shape\" isn't necessary with the TensorFlow backend\n+z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n+\n+# instantiate encoder model\n+encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n+encoder.summary()\n+plot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n+\n+# build decoder model\n+latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n+x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n+x = Reshape((shape[1], shape[2], shape[3]))(x)\n+\n+for i in range(2):\n+    x = Conv2DTranspose(filters=filters,\n+                        kernel_size=kernel_size,\n+                        activation='relu',\n+                        strides=2,\n+                        padding='same')(x)\n+    filters //= 2\n+\n+outputs = Conv2DTranspose(filters=1,\n+                          kernel_size=kernel_size,\n+                          activation='sigmoid',\n+                          padding='same',\n+                          name='decoder_output')(x)\n+\n+# instantiate decoder model\n+decoder = Model(latent_inputs, outputs, name='decoder')\n+decoder.summary()\n+plot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n+\n+# instantiate VAE model\n+outputs = decoder(encoder(inputs)[2])\n+vae = Model(inputs, outputs, name='vae')\n+\n+if __name__ == '__main__':\n+    parser = argparse.ArgumentParser()\n+    help_ = \"Load h5 model trained weights\"\n+    parser.add_argument(\"-w\", \"--weights\", help=help_)\n+    help_ = \"Use mse loss instead of binary cross entropy (default)\"\n+    parser.add_argument(\"-m\", \"--mse\", help=help_, action='store_true')\n+    args = parser.parse_args()\n+    models = (encoder, decoder)\n+    data = (x_test, y_test)\n+\n+    # VAE loss = mse_loss or xent_loss + kl_loss\n+    if args.mse:\n+        reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n+    else:\n+        reconstruction_loss = binary_crossentropy(K.flatten(inputs),\n+                                                  K.flatten(outputs))\n+\n+    reconstruction_loss *= image_size * image_size\n+    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n+    kl_loss = K.sum(kl_loss, axis=-1)\n+    kl_loss *= -0.5\n+    vae_loss = K.mean(reconstruction_loss + kl_loss)\n+    vae.add_loss(vae_loss)\n+    vae.compile(optimizer='rmsprop')\n+    vae.summary()\n+    plot_model(vae, to_file='vae_cnn.png', show_shapes=True)\n+\n+    if args.weights:\n+        vae = vae.load_weights(args.weights)\n+    else:\n+        # train the autoencoder\n+        vae.fit(x_train,\n+                epochs=epochs,\n+                batch_size=batch_size,\n+                validation_data=(x_test, None))\n+        vae.save_weights('vae_cnn_mnist.h5')\n+\n+    plot_results(models, data, batch_size=batch_size, model_name=\"vae_cnn\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
