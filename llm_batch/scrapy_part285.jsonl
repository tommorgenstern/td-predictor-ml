{"custom_id": "scrapy#533131a30fa944688dc54dd82a581739d1ed247c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 190 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -26,11 +26,6 @@ from scrapy.utils.engine import print_engine_status\n from scrapy.utils.reactor import listen_tcp\n from scrapy.utils.decorators import defers\n \n-try:\n-    import guppy\n-    hpy = guppy.hpy()\n-except ImportError:\n-    hpy = None\n \n logger = logging.getLogger(__name__)\n \n@@ -110,7 +105,6 @@ class TelnetConsole(protocol.ServerFactory):\n             'est': lambda: print_engine_status(self.crawler.engine),\n             'p': pprint.pprint,\n             'prefs': print_live_refs,\n-            'hpy': hpy,\n             'help': \"This is Scrapy telnet console. For more info see: \"\n                     \"https://docs.scrapy.org/en/latest/topics/telnetconsole.html\",\n         }\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#f37b1bdc5616f67460c645e26c49f9d5b34e3631", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 314 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -121,9 +121,7 @@ class DictItem(MutableMapping, BaseItem):\n         return self.__class__(self)\n \n     def deepcopy(self):\n-        \"\"\"Return a `deep copy`_ of this item.\n-\n-        .. _deep copy: https://docs.python.org/library/copy.html#copy.deepcopy\n+        \"\"\"Return a :func:`~copy.deepcopy` of this item.\n         \"\"\"\n         return deepcopy(self)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#532cd1d93ed58f038346ca6b753462563c85b489", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 1777 | Contributors (this commit): 24 | Commits (past 90d): 10 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,7 +4,15 @@ import signal\n import warnings\n \n from twisted.internet import defer\n-from zope.interface.verify import DoesNotImplement, verifyClass\n+from zope.interface.exceptions import DoesNotImplement\n+\n+try:\n+    # zope >= 5.0 only supports MultipleInvalid\n+    from zope.interface.exceptions import MultipleInvalid\n+except ImportError:\n+    MultipleInvalid = None\n+\n+from zope.interface.verify import verifyClass\n \n from scrapy import signals, Spider\n from scrapy.core.engine import ExecutionEngine\n@@ -124,9 +132,10 @@ class CrawlerRunner:\n         \"\"\" Get SpiderLoader instance from settings \"\"\"\n         cls_path = settings.get('SPIDER_LOADER_CLASS')\n         loader_cls = load_object(cls_path)\n+        excs = (DoesNotImplement, MultipleInvalid) if MultipleInvalid else DoesNotImplement\n         try:\n             verifyClass(ISpiderLoader, loader_cls)\n-        except DoesNotImplement:\n+        except excs:\n             warnings.warn(\n                 'SPIDER_LOADER_CLASS (previously named SPIDER_MANAGER_CLASS) does '\n                 'not fully implement scrapy.interfaces.ISpiderLoader interface. '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#36a3913a41a033e57c6119edd8bbf967044c927f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 13 | Files Changed: 4 | Hunks: 7 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 39 | Churn Cumulative: 1354 | Contributors (this commit): 23 | Commits (past 90d): 6 | Contributors (cumulative): 35 | DMM Complexity: 1.0\n\nDIFF:\n@@ -165,6 +165,7 @@ if __name__ == '__main__':\n     try:\n         execute()\n     finally:\n-        # Twisted prints errors in DebugInfo.__del__, but PyPy does not run gc.collect()\n-        # on exit: http://doc.pypy.org/en/latest/cpython_differences.html?highlight=gc.collect#differences-related-to-garbage-collection-strategies\n+        # Twisted prints errors in DebugInfo.__del__, but PyPy does not run gc.collect() on exit:\n+        # http://doc.pypy.org/en/latest/cpython_differences.html\n+        # ?highlight=gc.collect#differences-related-to-garbage-collection-strategies\n         garbage_collect()\n\n@@ -35,8 +35,10 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             for method in self.methods['process_request']:\n                 response = yield deferred_from_coro(method(request=request, spider=spider))\n                 if response is not None and not isinstance(response, (Response, Request)):\n-                    raise _InvalidOutput('Middleware %s.process_request must return None, Response or Request, got %s' % \\\n-                                         (method.__self__.__class__.__name__, response.__class__.__name__))\n+                    raise _InvalidOutput(\n+                        \"Middleware %s.process_request must return None, Response or Request, got %s\"\n+                        % (method.__self__.__class__.__name__, response.__class__.__name__)\n+                    )\n                 if response:\n                     defer.returnValue(response)\n             defer.returnValue((yield download_func(request=request, spider=spider)))\n@@ -50,8 +52,10 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             for method in self.methods['process_response']:\n                 response = yield deferred_from_coro(method(request=request, response=response, spider=spider))\n                 if not isinstance(response, (Response, Request)):\n-                    raise _InvalidOutput('Middleware %s.process_response must return Response or Request, got %s' % \\\n-                                         (method.__self__.__class__.__name__, type(response)))\n+                    raise _InvalidOutput(\n+                        \"Middleware %s.process_response must return Response or Request, got %s\"\n+                        % (method.__self__.__class__.__name__, type(response))\n+                    )\n                 if isinstance(response, Request):\n                     defer.returnValue(response)\n             defer.returnValue(response)\n@@ -62,8 +66,10 @@ class DownloaderMiddlewareManager(MiddlewareManager):\n             for method in self.methods['process_exception']:\n                 response = yield deferred_from_coro(method(request=request, exception=exception, spider=spider))\n                 if response is not None and not isinstance(response, (Response, Request)):\n-                    raise _InvalidOutput('Middleware %s.process_exception must return None, Response or Request, got %s' % \\\n-                                         (method.__self__.__class__.__name__, type(response)))\n+                    raise _InvalidOutput(\n+                        \"Middleware %s.process_exception must return None, Response or Request, got %s\"\n+                        % (method.__self__.__class__.__name__, type(response))\n+                    )\n                 if response:\n                     defer.returnValue(response)\n             defer.returnValue(_failure)\n\n@@ -17,10 +17,12 @@ def decode_robotstxt(robotstxt_body, spider, to_native_str_type=False):\n     except UnicodeDecodeError:\n         # If we found garbage or robots.txt in an encoding other than UTF-8, disregard it.\n         # Switch to 'allow all' state.\n-        logger.warning(\"Failure while parsing robots.txt. \"\n-                       \"File either contains garbage or is in an encoding other than UTF-8, treating it as an empty file.\",\n+        logger.warning(\n+            \"Failure while parsing robots.txt. File either contains garbage or \"\n+            \"is in an encoding other than UTF-8, treating it as an empty file.\",\n             exc_info=sys.exc_info(),\n-                       extra={'spider': spider})\n+            extra={'spider': spider},\n+        )\n         robotstxt_body = ''\n     return robotstxt_body\n \n\n@@ -54,8 +54,12 @@ class Rule:\n         self.process_request = _get_method(self.process_request, spider)\n         self.process_request_argcount = len(get_func_args(self.process_request))\n         if self.process_request_argcount == 1:\n-            msg = 'Rule.process_request should accept two arguments (request, response), accepting only one is deprecated'\n-            warnings.warn(msg, category=ScrapyDeprecationWarning, stacklevel=2)\n+            warnings.warn(\n+                \"Rule.process_request should accept two arguments\"\n+                \" (request, response), accepting only one is deprecated\",\n+                category=ScrapyDeprecationWarning,\n+                stacklevel=2,\n+            )\n \n     def _process_request(self, request, response):\n         \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "scrapy#182394bcecf556854291f1a0d2e0d2c406bc7b48", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 319 | Lines Deleted: 118 | Files Changed: 22 | Hunks: 83 | Methods Changed: 44 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 437 | Churn Cumulative: 13880 | Contributors (this commit): 72 | Commits (past 90d): 57 | Contributors (cumulative): 241 | DMM Complexity: 0.937888198757764\n\nDIFF:\n@@ -56,7 +56,9 @@ class ShellTest(ProcessTest, SiteTest, unittest.TestCase):\n \n     @defer.inlineCallbacks\n     def test_redirect_not_follow_302(self):\n-        _, out, _ = yield self.execute(['--no-redirect', self.url('/redirect-no-meta-refresh'), '-c', 'response.status'])\n+        _, out, _ = yield self.execute(\n+            ['--no-redirect', self.url('/redirect-no-meta-refresh'), '-c', 'response.status']\n+        )\n         assert out.strip().endswith(b'302')\n \n     @defer.inlineCallbacks\n\n@@ -303,8 +303,10 @@ class CrawlerProcessSubprocess(unittest.TestCase):\n     def test_ipv6_default_name_resolver(self):\n         log = self.run_script('default_name_resolver.py')\n         self.assertIn('Spider closed (finished)', log)\n-        self.assertIn(\"twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ::1.\", log)\n         self.assertIn(\"'downloader/exception_type_count/twisted.internet.error.DNSLookupError': 1,\", log)\n+        self.assertIn(\n+            \"twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ::1.\",\n+            log)\n \n     def test_ipv6_alternative_name_resolver(self):\n         log = self.run_script('alternative_name_resolver.py')\n\n@@ -493,7 +493,10 @@ class Http11TestCase(HttpTestCase):\n class Https11TestCase(Http11TestCase):\n     scheme = 'https'\n \n-    tls_log_message = 'SSL connection certificate: issuer \"/C=IE/O=Scrapy/CN=localhost\", subject \"/C=IE/O=Scrapy/CN=localhost\"'\n+    tls_log_message = (\n+        'SSL connection certificate: issuer \"/C=IE/O=Scrapy/CN=localhost\", '\n+        'subject \"/C=IE/O=Scrapy/CN=localhost\"'\n+    )\n \n     @defer.inlineCallbacks\n     def test_tls_logging(self):\n@@ -542,7 +545,10 @@ class Https11InvalidDNSPattern(Https11TestCase):\n             from service_identity.exceptions import CertificateError  # noqa: F401\n         except ImportError:\n             raise unittest.SkipTest(\"cryptography lib is too old\")\n-        self.tls_log_message = 'SSL connection certificate: issuer \"/C=IE/O=Scrapy/CN=127.0.0.1\", subject \"/C=IE/O=Scrapy/CN=127.0.0.1\"'\n+        self.tls_log_message = (\n+            'SSL connection certificate: issuer \"/C=IE/O=Scrapy/CN=127.0.0.1\", '\n+            'subject \"/C=IE/O=Scrapy/CN=127.0.0.1\"'\n+        )\n         super(Https11InvalidDNSPattern, self).setUp()\n \n \n\n@@ -124,7 +124,8 @@ class HttpCompressionTest(TestCase):\n             'Content-Encoding': 'gzip',\n         }\n         f = BytesIO()\n-        plainbody = b\"\"\"<html><head><title>Some page</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">\"\"\"\n+        plainbody = (b'<html><head><title>Some page</title>'\n+                     b'<meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">')\n         zf = GzipFile(fileobj=f, mode='wb')\n         zf.write(plainbody)\n         zf.close()\n@@ -142,7 +143,8 @@ class HttpCompressionTest(TestCase):\n             'Content-Encoding': 'gzip',\n         }\n         f = BytesIO()\n-        plainbody = b\"\"\"<html><head><title>Some page</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">\"\"\"\n+        plainbody = (b'<html><head><title>Some page</title>'\n+                     b'<meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">')\n         zf = GzipFile(fileobj=f, mode='wb')\n         zf.write(plainbody)\n         zf.close()\n@@ -158,7 +160,8 @@ class HttpCompressionTest(TestCase):\n         headers = {\n             'Content-Encoding': 'identity',\n         }\n-        plainbody = b\"\"\"<html><head><title>Some page</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">\"\"\"\n+        plainbody = (b'<html><head><title>Some page</title>'\n+                     b'<meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\">')\n         respcls = responsetypes.from_args(url=\"http://www.example.com/index\", headers=headers, body=plainbody)\n         response = respcls(\"http://www.example.com/index\", headers=headers, body=plainbody)\n         request = Request(\"http://www.example.com/index\")\n\n@@ -151,7 +151,10 @@ class RedirectMiddlewareTest(unittest.TestCase):\n         self.assertEqual(req2.url, 'http://scrapytest.org/redirected')\n         self.assertEqual(req2.meta['redirect_urls'], ['http://scrapytest.org/first'])\n         self.assertEqual(req3.url, 'http://scrapytest.org/redirected2')\n-        self.assertEqual(req3.meta['redirect_urls'], ['http://scrapytest.org/first', 'http://scrapytest.org/redirected'])\n+        self.assertEqual(\n+            req3.meta['redirect_urls'],\n+            ['http://scrapytest.org/first', 'http://scrapytest.org/redirected']\n+        )\n \n     def test_redirect_reasons(self):\n         req1 = Request('http://scrapytest.org/first')\n@@ -282,7 +285,10 @@ class MetaRefreshMiddlewareTest(unittest.TestCase):\n         self.assertEqual(req2.url, 'http://scrapytest.org/redirected')\n         self.assertEqual(req2.meta['redirect_urls'], ['http://scrapytest.org/first'])\n         self.assertEqual(req3.url, 'http://scrapytest.org/redirected2')\n-        self.assertEqual(req3.meta['redirect_urls'], ['http://scrapytest.org/first', 'http://scrapytest.org/redirected'])\n+        self.assertEqual(\n+            req3.meta['redirect_urls'],\n+            ['http://scrapytest.org/first', 'http://scrapytest.org/redirected']\n+        )\n \n     def test_redirect_reasons(self):\n         req1 = Request('http://scrapytest.org/first')\n\n@@ -111,7 +111,10 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n         self.assertEqual(type(exported), dict)\n-        self.assertEqual(exported, {'age': {'age': {'age': '22', 'name': u'Joseph'}, 'name': u'Maria'}, 'name': 'Jesus'})\n+        self.assertEqual(\n+            exported,\n+            {'age': {'age': {'age': '22', 'name': u'Joseph'}, 'name': u'Maria'}, 'name': 'Jesus'}\n+        )\n         self.assertEqual(type(exported['age']), dict)\n         self.assertEqual(type(exported['age']['age']), dict)\n \n@@ -121,7 +124,10 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         i3 = TestItem(name=u'Jesus', age=[i2])\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n-        self.assertEqual(exported, {'age': [{'age': [{'age': '22', 'name': u'Joseph'}], 'name': u'Maria'}], 'name': 'Jesus'})\n+        self.assertEqual(\n+            exported,\n+            {'age': [{'age': [{'age': '22', 'name': u'Joseph'}], 'name': u'Maria'}], 'name': 'Jesus'}\n+        )\n         self.assertEqual(type(exported['age'][0]), dict)\n         self.assertEqual(type(exported['age'][0]['age'][0]), dict)\n \n@@ -131,7 +137,10 @@ class PythonItemExporterTest(BaseItemExporterTest):\n         i3 = TestItem(name=u'Jesus', age=[i2])\n         ie = self._get_exporter()\n         exported = ie.export_item(i3)\n-        self.assertEqual(exported, {'age': [{'age': [{'age': '22', 'name': u'Joseph'}], 'name': u'Maria'}], 'name': 'Jesus'})\n+        self.assertEqual(\n+            exported,\n+            {'age': [{'age': [{'age': '22', 'name': u'Joseph'}], 'name': u'Maria'}], 'name': 'Jesus'}\n+        )\n         self.assertEqual(type(exported['age'][0]), dict)\n         self.assertEqual(type(exported['age'][0]['age'][0]), dict)\n \n@@ -327,13 +336,19 @@ class XmlItemExporterTest(BaseItemExporterTest):\n         self.assertXmlEquivalent(fp.getvalue(), expected_value)\n \n     def _check_output(self):\n-        expected_value = b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<items><item><age>22</age><name>John\\xc2\\xa3</name></item></items>'\n+        expected_value = (\n+            b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n'\n+            b'<items><item><age>22</age><name>John\\xc2\\xa3</name></item></items>'\n+        )\n         self.assertXmlEquivalent(self.output.getvalue(), expected_value)\n \n     def test_multivalued_fields(self):\n         self.assertExportResult(\n             TestItem(name=[u'John\\xa3', u'Doe']),\n-            b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<items><item><name><value>John\\xc2\\xa3</value><value>Doe</value></name></item></items>'\n+            (\n+                b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n'\n+                b'<items><item><name><value>John\\xc2\\xa3</value><value>Doe</value></name></item></items>'\n+            )\n         )\n \n     def test_nested_item(self):\n\n@@ -718,10 +718,13 @@ class FeedExportTest(unittest.TestCase):\n         header = ['foo']\n \n         formats = {\n-            'json': u'[{\"foo\": \"Test\\\\u00d6\"}]'.encode('utf-8'),\n-            'jsonlines': u'{\"foo\": \"Test\\\\u00d6\"}\\n'.encode('utf-8'),\n-            'xml': u'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<items><item><foo>Test\\xd6</foo></item></items>'.encode('utf-8'),\n-            'csv': u'foo\\r\\nTest\\xd6\\r\\n'.encode('utf-8'),\n+            'json': '[{\"foo\": \"Test\\\\u00d6\"}]'.encode('utf-8'),\n+            'jsonlines': '{\"foo\": \"Test\\\\u00d6\"}\\n'.encode('utf-8'),\n+            'xml': (\n+                '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n'\n+                '<items><item><foo>Test\\xd6</foo></item></items>'\n+            ).encode('utf-8'),\n+            'csv': 'foo\\r\\nTest\\xd6\\r\\n'.encode('utf-8'),\n         }\n \n         for fmt, expected in formats.items():\n@@ -735,10 +738,13 @@ class FeedExportTest(unittest.TestCase):\n             self.assertEqual(expected, data[fmt])\n \n         formats = {\n-            'json': u'[{\"foo\": \"Test\\xd6\"}]'.encode('latin-1'),\n-            'jsonlines': u'{\"foo\": \"Test\\xd6\"}\\n'.encode('latin-1'),\n-            'xml': u'<?xml version=\"1.0\" encoding=\"latin-1\"?>\\n<items><item><foo>Test\\xd6</foo></item></items>'.encode('latin-1'),\n-            'csv': u'foo\\r\\nTest\\xd6\\r\\n'.encode('latin-1'),\n+            'json': '[{\"foo\": \"Test\\xd6\"}]'.encode('latin-1'),\n+            'jsonlines': '{\"foo\": \"Test\\xd6\"}\\n'.encode('latin-1'),\n+            'xml': (\n+                '<?xml version=\"1.0\" encoding=\"latin-1\"?>\\n'\n+                '<items><item><foo>Test\\xd6</foo></item></items>'\n+            ).encode('latin-1'),\n+            'csv': 'foo\\r\\nTest\\xd6\\r\\n'.encode('latin-1'),\n         }\n \n         for fmt, expected in formats.items():\n@@ -757,9 +763,12 @@ class FeedExportTest(unittest.TestCase):\n         items = [dict({'foo': u'FOO', 'bar': u'BAR'})]\n \n         formats = {\n-            'json': u'[\\n{\"bar\": \"BAR\"}\\n]'.encode('utf-8'),\n-            'xml': u'<?xml version=\"1.0\" encoding=\"latin-1\"?>\\n<items>\\n  <item>\\n    <foo>FOO</foo>\\n  </item>\\n</items>'.encode('latin-1'),\n-            'csv': u'bar,foo\\r\\nBAR,FOO\\r\\n'.encode('utf-8'),\n+            'json': '[\\n{\"bar\": \"BAR\"}\\n]'.encode('utf-8'),\n+            'xml': (\n+                '<?xml version=\"1.0\" encoding=\"latin-1\"?>\\n'\n+                '<items>\\n  <item>\\n    <foo>FOO</foo>\\n  </item>\\n</items>'\n+            ).encode('latin-1'),\n+            'csv': 'bar,foo\\r\\nBAR,FOO\\r\\n'.encode('utf-8'),\n         }\n \n         settings = {\n\n@@ -1262,7 +1262,10 @@ class XmlRpcRequestTest(RequestTest):\n class JsonRequestTest(RequestTest):\n     request_class = JsonRequest\n     default_method = 'GET'\n-    default_headers = {b'Content-Type': [b'application/json'], b'Accept': [b'application/json, text/javascript, */*; q=0.01']}\n+    default_headers = {\n+        b'Content-Type': [b'application/json'],\n+        b'Accept': [b'application/json, text/javascript, */*; q=0.01'],\n+    }\n \n     def setUp(self):\n         warnings.simplefilter(\"always\")\n\n@@ -25,7 +25,11 @@ class BaseResponseTest(unittest.TestCase):\n         self.assertTrue(isinstance(self.response_class('http://example.com/', body=b''), self.response_class))\n         self.assertTrue(isinstance(self.response_class('http://example.com/', body=b'body'), self.response_class))\n         # test presence of all optional parameters\n-        self.assertTrue(isinstance(self.response_class('http://example.com/', body=b'', headers={}, status=200), self.response_class))\n+        self.assertTrue(\n+            isinstance(\n+                self.response_class('http://example.com/', body=b'', headers={}, status=200), self.response_class\n+            )\n+        )\n \n         r = self.response_class(\"http://www.example.com\")\n         assert isinstance(r.url, str)\n@@ -323,13 +327,16 @@ class TextResponseTest(BaseResponseTest):\n         self.assertEqual(resp.url, to_unicode(b'http://www.example.com/price/\\xc2\\xa3'))\n         resp = self.response_class(url=u\"http://www.example.com/price/\\xa3\", encoding='latin-1')\n         self.assertEqual(resp.url, 'http://www.example.com/price/\\xa3')\n-        resp = self.response_class(u\"http://www.example.com/price/\\xa3\", headers={\"Content-type\": [\"text/html; charset=utf-8\"]})\n+        resp = self.response_class(u\"http://www.example.com/price/\\xa3\",\n+                                   headers={\"Content-type\": [\"text/html; charset=utf-8\"]})\n         self.assertEqual(resp.url, to_unicode(b'http://www.example.com/price/\\xc2\\xa3'))\n-        resp = self.response_class(u\"http://www.example.com/price/\\xa3\", headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]})\n+        resp = self.response_class(u\"http://www.example.com/price/\\xa3\",\n+                                   headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]})\n         self.assertEqual(resp.url, 'http://www.example.com/price/\\xa3')\n \n     def test_unicode_body(self):\n-        unicode_string = u'\\u043a\\u0438\\u0440\\u0438\\u043b\\u043b\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 \\u0442\\u0435\\u043a\\u0441\\u0442'\n+        unicode_string = ('\\u043a\\u0438\\u0440\\u0438\\u043b\\u043b\\u0438\\u0447\\u0435\\u0441\\u043a\\u0438\\u0439 '\n+                          '\\u0442\\u0435\\u043a\\u0441\\u0442')\n         self.assertRaises(TypeError, self.response_class, 'http://www.example.com', body=u'unicode body')\n \n         original_string = unicode_string.encode('cp1251')\n@@ -344,13 +351,18 @@ class TextResponseTest(BaseResponseTest):\n         self.assertEqual(r1.text, unicode_string)\n \n     def test_encoding(self):\n-        r1 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=utf-8\"]}, body=b\"\\xc2\\xa3\")\n+        r1 = self.response_class(\"http://www.example.com\", body=b\"\\xc2\\xa3\",\n+                                 headers={\"Content-type\": [\"text/html; charset=utf-8\"]})\n         r2 = self.response_class(\"http://www.example.com\", encoding='utf-8', body=u\"\\xa3\")\n-        r3 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]}, body=b\"\\xa3\")\n+        r3 = self.response_class(\"http://www.example.com\", body=b\"\\xa3\",\n+                                 headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]})\n         r4 = self.response_class(\"http://www.example.com\", body=b\"\\xa2\\xa3\")\n-        r5 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=None\"]}, body=b\"\\xc2\\xa3\")\n-        r6 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=gb2312\"]}, body=b\"\\xa8D\")\n-        r7 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=gbk\"]}, body=b\"\\xa8D\")\n+        r5 = self.response_class(\"http://www.example.com\", body=b\"\\xc2\\xa3\",\n+                                 headers={\"Content-type\": [\"text/html; charset=None\"]})\n+        r6 = self.response_class(\"http://www.example.com\", body=b\"\\xa8D\",\n+                                 headers={\"Content-type\": [\"text/html; charset=gb2312\"]})\n+        r7 = self.response_class(\"http://www.example.com\", body=b\"\\xa8D\",\n+                                 headers={\"Content-type\": [\"text/html; charset=gbk\"]})\n \n         self.assertEqual(r1._headers_encoding(), \"utf-8\")\n         self.assertEqual(r2._headers_encoding(), None)\n@@ -685,7 +697,8 @@ class HtmlResponseTest(TextResponseTest):\n         body = b\"\"\"<html><head><title>Some page</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n         </head><body>Price: \\xa3100</body></html>'\n         \"\"\"\n-        r3 = self.response_class(\"http://www.example.com\", headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]}, body=body)\n+        r3 = self.response_class(\"http://www.example.com\", body=body,\n+                                 headers={\"Content-type\": [\"text/html; charset=iso-8859-1\"]})\n         self._assert_response_values(r3, 'iso-8859-1', body)\n \n         # make sure replace() preserves the encoding of the original response\n\n@@ -279,7 +279,7 @@ class Base:\n         def test_process_value(self):\n             \"\"\"Test restrict_xpaths with encodings\"\"\"\n             html = b\"\"\"\n-            <a href=\"javascript:goToPage('../other/page.html','photo','width=600,height=540,scrollbars'); return false\">Link text</a>\n+<a href=\"javascript:goToPage('../other/page.html','photo','width=600,height=540,scrollbars'); return false\">Text</a>\n <a href=\"/about.html\">About us</a>\n             \"\"\"\n             response = HtmlResponse(\"http://example.org/somepage/index.html\", body=html, encoding='windows-1252')\n@@ -291,7 +291,7 @@ class Base:\n \n             lx = self.extractor_cls(process_value=process_value)\n             self.assertEqual(lx.extract_links(response),\n-                             [Link(url='http://example.org/other/page.html', text='Link text')])\n+                             [Link(url='http://example.org/other/page.html', text='Text')])\n \n         def test_base_url_with_restrict_xpaths(self):\n             html = b\"\"\"<html><head><title>Page title<title><base href=\"http://otherdomain.com/base/\" />\n@@ -332,7 +332,10 @@ class Base:\n             self.assertEqual(lx.extract_links(self.response), [])\n \n         def test_tags(self):\n-            html = b\"\"\"<html><area href=\"sample1.html\"></area><a href=\"sample2.html\">sample 2</a><img src=\"sample2.jpg\"/></html>\"\"\"\n+            html = (\n+                b'<html><area href=\"sample1.html\"></area>'\n+                b'<a href=\"sample2.html\">sample 2</a><img src=\"sample2.jpg\"/></html>'\n+            )\n             response = HtmlResponse(\"http://example.com/index.html\", body=html)\n \n             lx = self.extractor_cls(tags=None)\n@@ -413,23 +416,33 @@ class Base:\n             response = HtmlResponse(\"http://example.com/index.xhtml\", body=xhtml)\n \n             lx = self.extractor_cls()\n-            self.assertEqual(lx.extract_links(response),\n-                             [Link(url='http://example.com/about.html', text=u'About us', fragment='', nofollow=False),\n+            self.assertEqual(\n+                lx.extract_links(response),\n+                [\n+                    Link(url='http://example.com/about.html', text=u'About us', fragment='', nofollow=False),\n                     Link(url='http://example.com/follow.html', text=u'Follow this link', fragment='', nofollow=False),\n-                              Link(url='http://example.com/nofollow.html', text=u'Dont follow this one', fragment='', nofollow=True),\n-                              Link(url='http://example.com/nofollow2.html', text=u'Choose to follow or not', fragment='', nofollow=False),\n-                              Link(url='http://google.com/something', text=u'External link not to follow', nofollow=True)]\n+                    Link(url='http://example.com/nofollow.html', text=u'Dont follow this one', fragment='',\n+                         nofollow=True),\n+                    Link(url='http://example.com/nofollow2.html', text=u'Choose to follow or not', fragment='',\n+                         nofollow=False),\n+                    Link(url='http://google.com/something', text=u'External link not to follow', nofollow=True),\n+                ]\n             )\n \n             response = XmlResponse(\"http://example.com/index.xhtml\", body=xhtml)\n \n             lx = self.extractor_cls()\n-            self.assertEqual(lx.extract_links(response),\n-                             [Link(url='http://example.com/about.html', text=u'About us', fragment='', nofollow=False),\n+            self.assertEqual(\n+                lx.extract_links(response),\n+                [\n+                    Link(url='http://example.com/about.html', text=u'About us', fragment='', nofollow=False),\n                     Link(url='http://example.com/follow.html', text=u'Follow this link', fragment='', nofollow=False),\n-                              Link(url='http://example.com/nofollow.html', text=u'Dont follow this one', fragment='', nofollow=True),\n-                              Link(url='http://example.com/nofollow2.html', text=u'Choose to follow or not', fragment='', nofollow=False),\n-                              Link(url='http://google.com/something', text=u'External link not to follow', nofollow=True)]\n+                    Link(url='http://example.com/nofollow.html', text=u'Dont follow this one', fragment='',\n+                         nofollow=True),\n+                    Link(url='http://example.com/nofollow2.html', text=u'Choose to follow or not', fragment='',\n+                         nofollow=False),\n+                    Link(url='http://google.com/something', text=u'External link not to follow', nofollow=True),\n+                ]\n             )\n \n         def test_link_wrong_href(self):\n\n@@ -38,25 +38,34 @@ class FilesPipelineTestCase(unittest.TestCase):\n \n     def test_file_path(self):\n         file_path = self.pipeline.file_path\n-        self.assertEqual(file_path(Request(\"https://dev.mydeco.com/mydeco.pdf\")),\n+        self.assertEqual(\n+            file_path(Request(\"https://dev.mydeco.com/mydeco.pdf\")),\n             'full/c9b564df929f4bc635bdd19fde4f3d4847c757c5.pdf')\n-        self.assertEqual(file_path(Request(\"http://www.maddiebrown.co.uk///catalogue-items//image_54642_12175_95307.txt\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.maddiebrown.co.uk///catalogue-items//image_54642_12175_95307.txt\")),\n             'full/4ce274dd83db0368bafd7e406f382ae088e39219.txt')\n-        self.assertEqual(file_path(Request(\"https://dev.mydeco.com/two/dirs/with%20spaces%2Bsigns.doc\")),\n+        self.assertEqual(\n+            file_path(Request(\"https://dev.mydeco.com/two/dirs/with%20spaces%2Bsigns.doc\")),\n             'full/94ccc495a17b9ac5d40e3eabf3afcb8c2c9b9e1a.doc')\n-        self.assertEqual(file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg\")),\n             'full/4507be485f38b0da8a0be9eb2e1dfab8a19223f2.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532/\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532/\")),\n             'full/97ee6f8a46cbbb418ea91502fd24176865cf39b2')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\")),\n             'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\"),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                       response=Response(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                       info=object()),\n             'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1')\n-        self.assertEqual(file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg.bohaha\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg.bohaha\")),\n             'full/76c00cef2ef669ae65052661f68d451162829507')\n-        self.assertEqual(file_path(Request(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAR0AAACxCAMAAADOHZloAAACClBMVEX/\\\n+        self.assertEqual(\n+            file_path(Request(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAR0AAACxCAMAAADOHZloAAACClBMVEX/\\\n                                     //+F0tzCwMK76ZKQ21AMqr7oAAC96JvD5aWM2kvZ78J0N7fmAAC46Y4Ap7y\")),\n             'full/178059cbeba2e34120a67f2dc1afc3ecc09b61cb.png')\n \n\n@@ -41,19 +41,26 @@ class ImagesPipelineTestCase(unittest.TestCase):\n \n     def test_file_path(self):\n         file_path = self.pipeline.file_path\n-        self.assertEqual(file_path(Request(\"https://dev.mydeco.com/mydeco.gif\")),\n+        self.assertEqual(\n+            file_path(Request(\"https://dev.mydeco.com/mydeco.gif\")),\n             'full/3fd165099d8e71b8a48b2683946e64dbfad8b52d.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.maddiebrown.co.uk///catalogue-items//image_54642_12175_95307.jpg\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.maddiebrown.co.uk///catalogue-items//image_54642_12175_95307.jpg\")),\n             'full/0ffcd85d563bca45e2f90becd0ca737bc58a00b2.jpg')\n-        self.assertEqual(file_path(Request(\"https://dev.mydeco.com/two/dirs/with%20spaces%2Bsigns.gif\")),\n+        self.assertEqual(\n+            file_path(Request(\"https://dev.mydeco.com/two/dirs/with%20spaces%2Bsigns.gif\")),\n             'full/b250e3a74fff2e4703e310048a5b13eba79379d2.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dfsonline.co.uk/get_prod_image.php?img=status_0907_mdm.jpg\")),\n             'full/4507be485f38b0da8a0be9eb2e1dfab8a19223f2.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532/\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532/\")),\n             'full/97ee6f8a46cbbb418ea91502fd24176865cf39b2.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\")),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\")),\n             'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1.jpg')\n-        self.assertEqual(file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\"),\n+        self.assertEqual(\n+            file_path(Request(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                       response=Response(\"http://www.dorma.co.uk/images/product_details/2532\"),\n                       info=object()),\n             'full/244e0dd7d96a3b7b01f54eded250c9e272577aa1.jpg')\n\n@@ -158,6 +158,12 @@ class CallbackKeywordArgumentsTestCase(TestCase):\n                 if key in line.getMessage():\n                     exceptions[key] = line\n         self.assertEqual(exceptions['takes_less'].exc_info[0], TypeError)\n-        self.assertEqual(str(exceptions['takes_less'].exc_info[1]), \"parse_takes_less() got an unexpected keyword argument 'number'\")\n+        self.assertEqual(\n+            str(exceptions['takes_less'].exc_info[1]),\n+            \"parse_takes_less() got an unexpected keyword argument 'number'\"\n+        )\n         self.assertEqual(exceptions['takes_more'].exc_info[0], TypeError)\n-        self.assertEqual(str(exceptions['takes_more'].exc_info[1]), \"parse_takes_more() missing 1 required positional argument: 'other'\")\n+        self.assertEqual(\n+            str(exceptions['takes_more'].exc_info[1]),\n+            \"parse_takes_more() missing 1 required positional argument: 'other'\"\n+        )\n\n@@ -64,8 +64,9 @@ class ResponseTypesTest(unittest.TestCase):\n     def test_from_headers(self):\n         mappings = [\n             ({'Content-Type': ['text/html; charset=utf-8']}, HtmlResponse),\n-            ({'Content-Type': ['application/octet-stream'], 'Content-Disposition': ['attachment; filename=data.txt']}, TextResponse),\n             ({'Content-Type': ['text/html; charset=utf-8'], 'Content-Encoding': ['gzip']}, Response),\n+            ({'Content-Type': ['application/octet-stream'],\n+              'Content-Disposition': ['attachment; filename=data.txt']}, TextResponse),\n         ]\n         for source, cls in mappings:\n             source = Headers(source)\n@@ -77,8 +78,10 @@ class ResponseTypesTest(unittest.TestCase):\n         mappings = [\n             ({'url': 'http://www.example.com/data.csv'}, TextResponse),\n             # headers takes precedence over url\n-            ({'headers': Headers({'Content-Type': ['text/html; charset=utf-8']}), 'url': 'http://www.example.com/item/'}, HtmlResponse),\n-            ({'headers': Headers({'Content-Disposition': ['attachment; filename=\"data.xml.gz\"']}), 'url': 'http://www.example.com/page/'}, Response),\n+            ({'headers': Headers({'Content-Type': ['text/html; charset=utf-8']}),\n+              'url': 'http://www.example.com/item/'}, HtmlResponse),\n+            ({'headers': Headers({'Content-Disposition': ['attachment; filename=\"data.xml.gz\"']}),\n+              'url': 'http://www.example.com/page/'}, Response),\n \n \n         ]\n\n@@ -19,18 +19,26 @@ class SelectorTestCase(unittest.TestCase):\n         for x in xl:\n             assert isinstance(x, Selector)\n \n-        self.assertEqual(sel.xpath('//input').getall(),\n-                         [x.get() for x in sel.xpath('//input')])\n-\n-        self.assertEqual([x.get() for x in sel.xpath(\"//input[@name='a']/@name\")],\n-                         [u'a'])\n-        self.assertEqual([x.get() for x in sel.xpath(\"number(concat(//input[@name='a']/@value, //input[@name='b']/@value))\")],\n-                         [u'12.0'])\n-\n-        self.assertEqual(sel.xpath(\"concat('xpath', 'rules')\").getall(),\n-                         [u'xpathrules'])\n-        self.assertEqual([x.get() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n-                         [u'12'])\n+        self.assertEqual(\n+            sel.xpath('//input').getall(),\n+            [x.get() for x in sel.xpath('//input')]\n+        )\n+        self.assertEqual(\n+            [x.get() for x in sel.xpath(\"//input[@name='a']/@name\")],\n+            [u'a']\n+        )\n+        self.assertEqual(\n+            [x.get() for x in sel.xpath(\"number(concat(//input[@name='a']/@value, //input[@name='b']/@value))\")],\n+            [u'12.0']\n+        )\n+        self.assertEqual(\n+            sel.xpath(\"concat('xpath', 'rules')\").getall(),\n+            [u'xpathrules']\n+        )\n+        self.assertEqual(\n+            [x.get() for x in sel.xpath(\"concat(//input[@name='a']/@value, //input[@name='b']/@value)\")],\n+            [u'12']\n+        )\n \n     def test_root_base_url(self):\n         body = b'<html><form action=\"/path\"><input name=\"a\" /></form></html>'\n\n@@ -120,7 +120,9 @@ class XMLFeedSpiderTest(SpiderTest):\n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n         <urlset xmlns:x=\"http://www.google.com/schemas/sitemap/0.84\"\n                 xmlns:y=\"http://www.example.com/schemas/extras/1.0\">\n-        <url><x:loc>http://www.example.com/Special-Offers.html</loc><y:updated>2009-08-16</updated><other value=\"bar\" y:custom=\"fuu\"/></url>\n+        <url><x:loc>http://www.example.com/Special-Offers.html</loc><y:updated>2009-08-16</updated>\n+            <other value=\"bar\" y:custom=\"fuu\"/>\n+        </url>\n         <url><loc>http://www.example.com/</loc><y:updated>2009-08-16</updated><other value=\"foo\"/></url>\n         </urlset>\"\"\"\n         response = XmlResponse(url='http://example.com/sitemap.xml', body=body)\n\n@@ -385,9 +385,15 @@ class TestSpiderMiddleware(TestCase):\n         log4 = yield self.crawl_log(GeneratorOutputChainSpider)\n         self.assertIn(\"'item_scraped_count': 2\", str(log4))\n         self.assertIn(\"GeneratorRecoverMiddleware.process_spider_exception: LookupError caught\", str(log4))\n-        self.assertIn(\"GeneratorDoNothingAfterFailureMiddleware.process_spider_exception: LookupError caught\", str(log4))\n-        self.assertNotIn(\"GeneratorFailMiddleware.process_spider_exception: LookupError caught\", str(log4))\n-        self.assertNotIn(\"GeneratorDoNothingAfterRecoveryMiddleware.process_spider_exception: LookupError caught\", str(log4))\n+        self.assertIn(\n+            \"GeneratorDoNothingAfterFailureMiddleware.process_spider_exception: LookupError caught\",\n+            str(log4))\n+        self.assertNotIn(\n+            \"GeneratorFailMiddleware.process_spider_exception: LookupError caught\",\n+            str(log4))\n+        self.assertNotIn(\n+            \"GeneratorDoNothingAfterRecoveryMiddleware.process_spider_exception: LookupError caught\",\n+            str(log4))\n         item_from_callback = {'processed': [\n             'parse-first-item',\n             'GeneratorFailMiddleware.process_spider_output',\n@@ -414,9 +420,13 @@ class TestSpiderMiddleware(TestCase):\n         log5 = yield self.crawl_log(NotGeneratorOutputChainSpider)\n         self.assertIn(\"'item_scraped_count': 1\", str(log5))\n         self.assertIn(\"GeneratorRecoverMiddleware.process_spider_exception: ReferenceError caught\", str(log5))\n-        self.assertIn(\"GeneratorDoNothingAfterFailureMiddleware.process_spider_exception: ReferenceError caught\", str(log5))\n+        self.assertIn(\n+            \"GeneratorDoNothingAfterFailureMiddleware.process_spider_exception: ReferenceError caught\",\n+            str(log5))\n         self.assertNotIn(\"GeneratorFailMiddleware.process_spider_exception: ReferenceError caught\", str(log5))\n-        self.assertNotIn(\"GeneratorDoNothingAfterRecoveryMiddleware.process_spider_exception: ReferenceError caught\", str(log5))\n+        self.assertNotIn(\n+            \"GeneratorDoNothingAfterRecoveryMiddleware.process_spider_exception: ReferenceError caught\",\n+            str(log5))\n         item_recovered = {'processed': [\n             'NotGeneratorRecoverMiddleware.process_spider_exception',\n             'NotGeneratorDoNothingAfterRecoveryMiddleware.process_spider_output']}\n\n@@ -119,7 +119,11 @@ class MixinSameOrigin:\n         ('https://example.com:443/page.html', 'https://example.com/not-page.html', b'https://example.com/page.html'),\n         ('http://example.com:80/page.html', 'http://example.com/not-page.html', b'http://example.com/page.html'),\n         ('http://example.com/page.html', 'http://example.com:80/not-page.html', b'http://example.com/page.html'),\n-        ('http://example.com:8888/page.html',   'http://example.com:8888/not-page.html',    b'http://example.com:8888/page.html'),\n+        (\n+            'http://example.com:8888/page.html',\n+            'http://example.com:8888/not-page.html',\n+            b'http://example.com:8888/page.html',\n+        ),\n \n         # Different host: do NOT send referrer\n         ('https://example.com/page.html',       'https://not.example.com/otherpage.html',   None),\n@@ -139,8 +143,12 @@ class MixinSameOrigin:\n         ('ftps://example.com/urls.zip',     'https://example.com/not-page.html',    None),\n \n         # test for user/password stripping\n-        ('https://user:password@example.com/page.html', 'https://example.com/not-page.html',    b'https://example.com/page.html'),\n         ('https://user:password@example.com/page.html', 'http://example.com/not-page.html', None),\n+        (\n+            'https://user:password@example.com/page.html',\n+            'https://example.com/not-page.html',\n+            b'https://example.com/page.html',\n+        ),\n     ]\n \n \n@@ -184,7 +192,11 @@ class MixinOriginWhenCrossOrigin:\n         ('https://example.com:443/page.html', 'https://example.com/not-page.html', b'https://example.com/page.html'),\n         ('http://example.com:80/page.html', 'http://example.com/not-page.html', b'http://example.com/page.html'),\n         ('http://example.com/page.html', 'http://example.com:80/not-page.html', b'http://example.com/page.html'),\n-        ('http://example.com:8888/page.html',   'http://example.com:8888/not-page.html',    b'http://example.com:8888/page.html'),\n+        (\n+            'http://example.com:8888/page.html',\n+            'http://example.com:8888/not-page.html',\n+            b'http://example.com:8888/page.html',\n+        ),\n \n         # Different host: send origin as referrer\n         ('https://example2.com/page.html',  'https://scrapy.org/otherpage.html',        b'https://example2.com/'),\n@@ -205,9 +217,17 @@ class MixinOriginWhenCrossOrigin:\n         ('ftps://example4.com/urls.zip',    'https://example4.com/not-page.html',   b'ftps://example4.com/'),\n \n         # test for user/password stripping\n-        ('https://user:password@example5.com/page.html', 'https://example5.com/not-page.html',  b'https://example5.com/page.html'),\n+        (\n+            'https://user:password@example5.com/page.html',\n+            'https://example5.com/not-page.html',\n+            b'https://example5.com/page.html',\n+        ),\n         # TLS to non-TLS downgrade: send origin\n-        ('https://user:password@example5.com/page.html', 'http://example5.com/not-page.html',   b'https://example5.com/'),\n+        (\n+            'https://user:password@example5.com/page.html',\n+            'http://example5.com/not-page.html',\n+            b'https://example5.com/',\n+        ),\n     ]\n \n \n@@ -219,7 +239,11 @@ class MixinStrictOriginWhenCrossOrigin:\n         ('https://example.com:443/page.html', 'https://example.com/not-page.html', b'https://example.com/page.html'),\n         ('http://example.com:80/page.html', 'http://example.com/not-page.html', b'http://example.com/page.html'),\n         ('http://example.com/page.html', 'http://example.com:80/not-page.html', b'http://example.com/page.html'),\n-        ('http://example.com:8888/page.html',   'http://example.com:8888/not-page.html',    b'http://example.com:8888/page.html'),\n+        (\n+            'http://example.com:8888/page.html',\n+            'http://example.com:8888/not-page.html',\n+            b'http://example.com:8888/page.html',\n+        ),\n \n         # Different host: send origin as referrer\n         ('https://example2.com/page.html',  'https://scrapy.org/otherpage.html',        b'https://example2.com/'),\n@@ -248,7 +272,11 @@ class MixinStrictOriginWhenCrossOrigin:\n         ('ftps://example4.com/urls.zip',    'https://example4.com/not-page.html',   b'ftps://example4.com/'),\n \n         # test for user/password stripping\n-        ('https://user:password@example5.com/page.html', 'https://example5.com/not-page.html',  b'https://example5.com/page.html'),\n+        (\n+            'https://user:password@example5.com/page.html',\n+            'https://example5.com/not-page.html',\n+            b'https://example5.com/page.html',\n+        ),\n \n         # TLS to non-TLS downgrade: send nothing\n         ('https://user:password@example5.com/page.html', 'http://example5.com/not-page.html',   None),\n@@ -281,8 +309,16 @@ class MixinUnsafeUrl:\n         ('ftp://example3.com/urls.zip',         'https://scrapy.org/',          b'ftp://example3.com/urls.zip'),\n \n         # test for user/password stripping\n-        ('http://user:password@example4.com/page.html',     'https://not.example4.com/',    b'http://example4.com/page.html'),\n-        ('https://user:password@example4.com/page.html',    'http://scrapy.org/',           b'https://example4.com/page.html'),\n+        (\n+            'http://user:password@example4.com/page.html',\n+            'https://not.example4.com/',\n+            b'http://example4.com/page.html',\n+        ),\n+        (\n+            'https://user:password@example4.com/page.html',\n+            'http://scrapy.org/',\n+            b'https://example4.com/page.html',\n+        ),\n     ]\n \n \n\n@@ -17,7 +17,8 @@ class XmliterTestCase(unittest.TestCase):\n \n     def test_xmliter(self):\n         body = b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\\n-            <products xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"someschmea.xsd\">\\\n+            <products xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+                      xsi:noNamespaceSchemaLocation=\"someschmea.xsd\">\\\n               <product id=\"001\">\\\n                 <type>Type 1</type>\\\n                 <name>Name 1</name>\\\n@@ -107,7 +108,10 @@ class XmliterTestCase(unittest.TestCase):\n                               (u'27', [u'A'], [u'27'])])\n \n     def test_xmliter_text(self):\n-        body = u\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><products><product>one</product><product>two</product></products>\"\"\"\n+        body = (\n+            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n+            '<products><product>one</product><product>two</product></products>'\n+        )\n \n         self.assertEqual([x.xpath(\"text()\").getall() for x in self.xmliter(body, 'product')],\n                          [[u'one'], [u'two']])\n@@ -139,7 +143,10 @@ class XmliterTestCase(unittest.TestCase):\n         self.assertEqual(node.xpath('title/text()').getall(), ['Item 1'])\n         self.assertEqual(node.xpath('description/text()').getall(), ['This is item 1'])\n         self.assertEqual(node.xpath('link/text()').getall(), ['http://www.mydummycompany.com/items/1'])\n-        self.assertEqual(node.xpath('g:image_link/text()').getall(), ['http://www.mydummycompany.com/images/item1.jpg'])\n+        self.assertEqual(\n+            node.xpath('g:image_link/text()').getall(),\n+            ['http://www.mydummycompany.com/images/item1.jpg']\n+        )\n         self.assertEqual(node.xpath('g:id/text()').getall(), ['ITEM_1'])\n         self.assertEqual(node.xpath('g:price/text()').getall(), ['400'])\n         self.assertEqual(node.xpath('image_link/text()').getall(), [])\n@@ -147,7 +154,10 @@ class XmliterTestCase(unittest.TestCase):\n         self.assertEqual(node.xpath('price/text()').getall(), [])\n \n     def test_xmliter_exception(self):\n-        body = u\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?><products><product>one</product><product>two</product></products>\"\"\"\n+        body = (\n+            '<?xml version=\"1.0\" encoding=\"UTF-8\"?>'\n+            '<products><product>one</product><product>two</product></products>'\n+        )\n \n         iter = self.xmliter(body, 'product')\n         next(iter)\n@@ -160,7 +170,12 @@ class XmliterTestCase(unittest.TestCase):\n         self.assertRaises(AssertionError, next, i)\n \n     def test_xmliter_encoding(self):\n-        body = b'<?xml version=\"1.0\" encoding=\"ISO-8859-9\"?>\\n<xml>\\n    <item>Some Turkish Characters \\xd6\\xc7\\xde\\xdd\\xd0\\xdc \\xfc\\xf0\\xfd\\xfe\\xe7\\xf6</item>\\n</xml>\\n\\n'\n+        body = (\n+            b'<?xml version=\"1.0\" encoding=\"ISO-8859-9\"?>\\n'\n+            b'<xml>\\n'\n+            b'    <item>Some Turkish Characters \\xd6\\xc7\\xde\\xdd\\xd0\\xdc \\xfc\\xf0\\xfd\\xfe\\xe7\\xf6</item>\\n'\n+            b'</xml>\\n\\n'\n+        )\n         response = XmlResponse('http://www.example.com', body=body)\n         self.assertEqual(\n             next(self.xmliter(response, 'item')).get(),\n\n@@ -75,8 +75,12 @@ class UtilsRequestTest(unittest.TestCase):\n         r1 = Request(\"http://www.example.com/some/page.html?arg=1\")\n         self.assertEqual(request_httprepr(r1), b'GET /some/page.html?arg=1 HTTP/1.1\\r\\nHost: www.example.com\\r\\n\\r\\n')\n \n-        r1 = Request(\"http://www.example.com\", method='POST', headers={\"Content-type\": b\"text/html\"}, body=b\"Some body\")\n-        self.assertEqual(request_httprepr(r1), b'POST / HTTP/1.1\\r\\nHost: www.example.com\\r\\nContent-Type: text/html\\r\\n\\r\\nSome body')\n+        r1 = Request(\"http://www.example.com\", method='POST',\n+                     headers={\"Content-type\": b\"text/html\"}, body=b\"Some body\")\n+        self.assertEqual(\n+            request_httprepr(r1),\n+            b'POST / HTTP/1.1\\r\\nHost: www.example.com\\r\\nContent-Type: text/html\\r\\n\\r\\nSome body'\n+        )\n \n     def test_request_httprepr_for_non_http_request(self):\n         # the representation is not important but it must not fail.\n\n@@ -22,8 +22,14 @@ class SitemapTest(unittest.TestCase):\n   </url>\n </urlset>\"\"\")\n         assert s.type == 'urlset'\n-        self.assertEqual(list(s),\n-            [{'priority': '1', 'loc': 'http://www.example.com/', 'lastmod': '2009-08-16', 'changefreq': 'daily'}, {'priority': '0.8', 'loc': 'http://www.example.com/Special-Offers.html', 'lastmod': '2009-08-16', 'changefreq': 'weekly'}])\n+        self.assertEqual(\n+            list(s),\n+            [\n+                {'priority': '1', 'loc': 'http://www.example.com/', 'lastmod': '2009-08-16', 'changefreq': 'daily'},\n+                {'priority': '0.8', 'loc': 'http://www.example.com/Special-Offers.html',\n+                 'lastmod': '2009-08-16', 'changefreq': 'weekly'},\n+            ]\n+        )\n \n     def test_sitemap_index(self):\n         s = Sitemap(b\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n@@ -38,7 +44,13 @@ class SitemapTest(unittest.TestCase):\n    </sitemap>\n </sitemapindex>\"\"\")\n         assert s.type == 'sitemapindex'\n-        self.assertEqual(list(s), [{'loc': 'http://www.example.com/sitemap1.xml.gz', 'lastmod': '2004-10-01T18:23:17+00:00'}, {'loc': 'http://www.example.com/sitemap2.xml.gz', 'lastmod': '2005-01-01'}])\n+        self.assertEqual(\n+            list(s),\n+            [\n+                {'loc': 'http://www.example.com/sitemap1.xml.gz', 'lastmod': '2004-10-01T18:23:17+00:00'},\n+                {'loc': 'http://www.example.com/sitemap2.xml.gz', 'lastmod': '2005-01-01'},\n+            ]\n+        )\n \n     def test_sitemap_strip(self):\n         \"\"\"Assert we can deal with trailing spaces inside <loc> tags - we've\n@@ -195,11 +207,19 @@ Disallow: /forum/active/\n         </url>\n     </urlset>\"\"\")\n \n-        self.assertEqual(list(s), [\n-            {'loc': 'http://www.example.com/english/',\n-             'alternate': ['http://www.example.com/deutsch/', 'http://www.example.com/schweiz-deutsch/', 'http://www.example.com/english/']\n+        self.assertEqual(\n+            list(s),\n+            [\n+                {\n+                    'loc': 'http://www.example.com/english/',\n+                    'alternate': [\n+                        'http://www.example.com/deutsch/',\n+                        'http://www.example.com/schweiz-deutsch/',\n+                        'http://www.example.com/english/',\n+                    ],\n                 }\n-        ])\n+            ]\n+        )\n \n     def test_xml_entity_expansion(self):\n         s = Sitemap(b\"\"\"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n\n@@ -28,7 +28,10 @@ class UrlUtilsTest(unittest.TestCase):\n         self.assertTrue(url_is_from_any_domain(url, ['192.169.0.15:8080']))\n         self.assertFalse(url_is_from_any_domain(url, ['192.169.0.15']))\n \n-        url = 'javascript:%20document.orderform_2581_1190810811.mode.value=%27add%27;%20javascript:%20document.orderform_2581_1190810811.submit%28%29'\n+        url = (\n+            'javascript:%20document.orderform_2581_1190810811.mode.value=%27add%27;%20'\n+            'javascript:%20document.orderform_2581_1190810811.submit%28%29'\n+        )\n         self.assertFalse(url_is_from_any_domain(url, ['testdomain.com']))\n         self.assertFalse(url_is_from_any_domain(url + '.testdomain.com', ['testdomain.com']))\n \n@@ -105,8 +108,10 @@ class AddHttpIfNoScheme(unittest.TestCase):\n                                                'http://username:password@www.example.com')\n \n     def test_complete_url(self):\n-        self.assertEqual(add_http_if_no_scheme('username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n-                                               'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag')\n+        self.assertEqual(\n+            add_http_if_no_scheme('username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n+            'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'\n+        )\n \n     def test_preserve_http(self):\n         self.assertEqual(add_http_if_no_scheme('http://www.example.com'),\n@@ -137,8 +142,10 @@ class AddHttpIfNoScheme(unittest.TestCase):\n                                                'http://username:password@www.example.com')\n \n     def test_preserve_http_complete_url(self):\n-        self.assertEqual(add_http_if_no_scheme('http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n-                                               'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag')\n+        self.assertEqual(\n+            add_http_if_no_scheme('http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n+            'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'\n+        )\n \n     def test_protocol_relative(self):\n         self.assertEqual(add_http_if_no_scheme('//www.example.com'),\n@@ -169,8 +176,10 @@ class AddHttpIfNoScheme(unittest.TestCase):\n                                                'http://username:password@www.example.com')\n \n     def test_protocol_relative_complete_url(self):\n-        self.assertEqual(add_http_if_no_scheme('//username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n-                                               'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag')\n+        self.assertEqual(\n+            add_http_if_no_scheme('//username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'),\n+            'http://username:password@www.example.com:80/some/page/do?a=1&b=2&c=3#frag'\n+        )\n \n     def test_preserve_https(self):\n         self.assertEqual(add_http_if_no_scheme('https://www.example.com'),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
