{"custom_id": "keras#6bb3fb7c9d853dec1c4dc8564debeb426b13cd30", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 3264 | Contributors (this commit): 15 | Commits (past 90d): 16 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -12,6 +12,7 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow as tf\n+import warnings\n \n \n class TensorBoard(tf.keras.callbacks.TensorBoard):\n\n@@ -1089,6 +1089,7 @@ class Layer(object):\n     def weights(self):\n         return self.trainable_weights + self.non_trainable_weights\n \n+    @K.eager\n     def set_weights(self, weights):\n         \"\"\"Sets the weights of the layer, from Numpy arrays.\n \n@@ -1126,6 +1127,7 @@ class Layer(object):\n             weight_value_tuples.append((p, w))\n         K.batch_set_value(weight_value_tuples)\n \n+    @K.eager\n     def get_weights(self):\n         \"\"\"Returns the current weights of the layer.\n \n\n@@ -1025,7 +1025,7 @@ def call_metric_function(metric_fn,\n             weights = mask\n         else:\n             # Update dimensions of weights to match with mask.\n-            mask, _, weights = tf_losses_utils.squeeze_or_expand_dimensions(\n+            mask, _, weights = losses_utils.squeeze_or_expand_dimensions(\n                 mask, sample_weight=weights)\n             weights *= mask\n \n\n@@ -71,7 +71,9 @@ def squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n     y_pred_rank = K.ndim(y_pred)\n     weights_rank = K.ndim(sample_weight)\n     if weights_rank != 0:\n-        if weights_rank - y_pred_rank == 1:\n+        if y_pred_rank == 0 and weights_rank == 1:\n+            y_pred = K.expand_dims(y_pred, -1)\n+        elif weights_rank - y_pred_rank == 1:\n             sample_weight = K.squeeze(sample_weight, -1)\n         elif y_pred_rank - weights_rank == 1:\n             sample_weight = K.expand_dims(sample_weight, -1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#763f69fb526dc20deaa77d0f3440d7d0cd0e80be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 18 | Files Changed: 5 | Hunks: 15 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 45 | Churn Cumulative: 17369 | Contributors (this commit): 148 | Commits (past 90d): 18 | Contributors (cumulative): 172 | DMM Complexity: 1.0\n\nDIFF:\n@@ -26,7 +26,14 @@ Epoch |   TF   |   TH\n     20|  0.043 | 0.045\n     25|  0.014 | 0.019\n \n+# Additional dependencies\n+\n This requires ```cairo``` and ```editdistance``` packages:\n+\n+First, install the Cairo library: https://cairographics.org/\n+\n+Then install Python dependencies:\n+\n ```python\n pip install cairocffi\n pip install editdistance\n\n@@ -94,13 +94,6 @@ def getwhere(x):\n     y_prepool, y_postpool = x\r\n     return K.gradients(K.sum(y_postpool), y_prepool)\r\n \r\n-if K.backend() == 'tensorflow':\r\n-    raise RuntimeError('This example can only run with the '\r\n-                       'Theano backend for the time being, '\r\n-                       'because it requires taking the gradient '\r\n-                       'of a gradient, which isn\\'t '\r\n-                       'supported for all TensorFlow ops.')\r\n-\r\n # This example assume 'channels_first' data format.\r\n K.set_image_data_format('channels_first')\r\n \r\n\n@@ -90,6 +90,8 @@ num_colors = 3  # RGB\n ref_img = img_to_array(load_img(target_mask_path))\r\n img_nrows, img_ncols = ref_img.shape[:2]\r\n \r\n+num_iterations = 50\r\n+\r\n total_variation_weight = 50.\r\n style_weight = 1.\r\n content_weight = 0.1 if use_content_img else 0\r\n@@ -267,8 +269,10 @@ def style_loss(style_image, target_image, style_masks, target_masks):\n         else:\r\n             style_mask = style_masks[:, :, i]\r\n             target_mask = target_masks[:, :, i]\r\n-        loss += region_style_loss(style_image,\r\n-                                  target_image, style_mask, target_mask)\r\n+        loss = loss + region_style_loss(style_image,\r\n+                                        target_image,\r\n+                                        style_mask,\r\n+                                        target_mask)\r\n     return loss\r\n \r\n \r\n@@ -297,7 +301,7 @@ loss = K.variable(0)\n for layer in content_feature_layers:\r\n     content_feat = image_features[layer][CONTENT, :, :, :]\r\n     target_feat = image_features[layer][TARGET, :, :, :]\r\n-    loss += content_weight * content_loss(content_feat, target_feat)\r\n+    loss = loss + content_weight * content_loss(content_feat, target_feat)\r\n \r\n for layer in style_feature_layers:\r\n     style_feat = image_features[layer][STYLE, :, :, :]\r\n@@ -305,9 +309,9 @@ for layer in style_feature_layers:\n     style_masks = mask_features[layer][STYLE, :, :, :]\r\n     target_masks = mask_features[layer][TARGET, :, :, :]\r\n     sl = style_loss(style_feat, target_feat, style_masks, target_masks)\r\n-    loss += (style_weight / len(style_feature_layers)) * sl\r\n+    loss = loss + (style_weight / len(style_feature_layers)) * sl\r\n \r\n-loss += total_variation_weight * total_variation_loss(target_image)\r\n+loss = loss + total_variation_weight * total_variation_loss(target_image)\r\n loss_grads = K.gradients(loss, target_image)\r\n \r\n # Evaluator class for computing efficiency\r\n@@ -354,6 +358,7 @@ class Evaluator(object):\n         self.grad_values = None\r\n         return grad_values\r\n \r\n+\r\n evaluator = Evaluator()\r\n \r\n # Generate images by iterative optimization\r\n@@ -362,8 +367,8 @@ if K.image_data_format() == 'channels_first':\n else:\r\n     x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\r\n \r\n-for i in range(50):\r\n-    print('Start of iteration', i)\r\n+for i in range(num_iterations):\r\n+    print('Start of iteration', i, '/', num_iterations)\r\n     start_time = time.time()\r\n     x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\r\n                                      fprime=evaluator.grads, maxfun=20)\r\n\n@@ -203,12 +203,13 @@ def total_variation_loss(x):\n             x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n     return K.sum(K.pow(a + b, 1.25))\n \n+\n # combine these loss functions into a single scalar\n loss = K.variable(0.0)\n layer_features = outputs_dict['block5_conv2']\n base_image_features = layer_features[0, :, :, :]\n combination_features = layer_features[2, :, :, :]\n-loss += content_weight * content_loss(base_image_features,\n+loss = loss + content_weight * content_loss(base_image_features,\n                                             combination_features)\n \n feature_layers = ['block1_conv1', 'block2_conv1',\n@@ -219,8 +220,8 @@ for layer_name in feature_layers:\n     style_reference_features = layer_features[1, :, :, :]\n     combination_features = layer_features[2, :, :, :]\n     sl = style_loss(style_reference_features, combination_features)\n-    loss += (style_weight / len(feature_layers)) * sl\n-loss += total_variation_weight * total_variation_loss(combination_image)\n+    loss = loss + (style_weight / len(feature_layers)) * sl\n+loss = loss + total_variation_weight * total_variation_loss(combination_image)\n \n # get the gradients of the generated image wrt the loss\n grads = K.gradients(loss, combination_image)\n@@ -275,6 +276,7 @@ class Evaluator(object):\n         self.grad_values = None\n         return grad_values\n \n+\n evaluator = Evaluator()\n \n # run scipy-based optimization (L-BFGS) over the pixels of the generated image\n\n@@ -2687,7 +2687,9 @@ def batch_flatten(x):\n     # Returns\n         A tensor.\n     \"\"\"\n-    x = tf.reshape(x, tf.stack([-1, prod(shape(x)[1:])]))\n+    x = tf.reshape(\n+        x, tf.stack([-1, prod(shape(x)[1:])],\n+                    name='stack_' + str(np.random.randint(1e4))))\n     return x\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69fcefd826d2c41c79322dd213fe54817eacd83a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 127 | Lines Deleted: 35 | Files Changed: 5 | Hunks: 17 | Methods Changed: 8 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 162 | Churn Cumulative: 18770 | Contributors (this commit): 145 | Commits (past 90d): 56 | Contributors (cumulative): 168 | DMM Complexity: 1.0\n\nDIFF:\n@@ -160,7 +160,5 @@ elif backend() == 'tensorflow':\n     from .load_backend import manual_variable_initialization\r\n     from .load_backend import get_session\r\n     from .load_backend import set_session\r\n-    from .load_backend import top_k\r\n-    from .load_backend import MeanIoU\r\n elif backend() == 'cntk':\r\n     from .load_backend import clear_session\r\n\n@@ -28,8 +28,6 @@ py_any = any\n py_sum = sum\n py_slice = slice\n \n-MeanIoU = tf.keras.metrics.MeanIoU\n-\n # INTERNAL UTILS\n \n # This list holds the available devices.\n@@ -3503,24 +3501,6 @@ def in_top_k(predictions, targets, k):\n                           k=k)\n \n \n-def top_k(input, k=1, sorted=True, name=None):\n-    \"\"\"Finds values and indices of the k largest entries for the last dimension.\n-\n-    # Arguments\n-        input: 1-D or higher Tensor with last dimension at least k.\n-        k: 0-D int32 Tensor. Number of top elements to look for along the last\n-            dimension (along each row for matrices).\n-        sorted: If true the resulting k elements will be sorted by the values\n-            in descending order.\n-        name: Optional name for the operation.\n-\n-    # Returns\n-        values: The k largest elements along each last dimensional slice.\n-        indices: The indices of values within the last dimension of input.\n-    \"\"\"\n-    return tf.math.top_k(input, k=k, sorted=sorted, name=name)\n-\n-\n # CONVOLUTIONS\n \n \n\n@@ -5,6 +5,7 @@ from __future__ import division\n from __future__ import print_function\n \n import abc\n+import numpy as np\n import six\n import types\n \n@@ -984,9 +985,9 @@ class _ConfusionMatrixConditionCount(Metric):\n         return self.accumulator\n \n     def reset_states(self):\n-        num_thresholds = len(to_list(self.thresholds))\n+        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n         K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.variables])\n+            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n \n     def get_config(self):\n         config = {'thresholds': self.init_thresholds}\n@@ -1203,7 +1204,7 @@ class SensitivitySpecificityBase(Metric):\n     def reset_states(self):\n         num_thresholds = len(self.thresholds)\n         K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.variables])\n+            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n \n \n class SensitivityAtSpecificity(SensitivitySpecificityBase):\n@@ -1409,8 +1410,8 @@ class Precision(Metric):\n         self.init_thresholds = thresholds\n         if top_k is not None and K.backend() != 'tensorflow':\n             raise RuntimeError(\n-                '`top_k` argument for `Precision` metric is currently supported only '\n-                'with TensorFlow backend.')\n+                '`top_k` argument for `Precision` metric is currently supported '\n+                'only with TensorFlow backend.')\n \n         self.top_k = top_k\n         self.class_id = class_id\n@@ -1450,9 +1451,9 @@ class Precision(Metric):\n         return result[0] if len(self.thresholds) == 1 else result\n \n     def reset_states(self):\n-        num_thresholds = len(to_list(self.thresholds))\n+        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n         K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.variables])\n+            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n \n     def get_config(self):\n         config = {\n@@ -1559,9 +1560,9 @@ class Recall(Metric):\n         return result[0] if len(self.thresholds) == 1 else result\n \n     def reset_states(self):\n-        num_thresholds = len(to_list(self.thresholds))\n+        num_thresholds = len(metrics_utils.to_list(self.thresholds))\n         K.batch_set_value(\n-            [(v, np.zeros((num_thresholds,))) for v in self.variables])\n+            [(v, np.zeros((num_thresholds,))) for v in self.weights])\n \n     def get_config(self):\n         config = {\n@@ -1826,7 +1827,7 @@ class AUC(Metric):\n \n     def reset_states(self):\n         K.batch_set_value(\n-            [(v, np.zeros((self.num_thresholds,))) for v in self.variables])\n+            [(v, np.zeros((self.num_thresholds,))) for v in self.weights])\n \n     def get_config(self):\n         config = {\n@@ -1842,6 +1843,51 @@ class AUC(Metric):\n         return dict(list(base_config.items()) + list(config.items()))\n \n \n+BaseMeanIoU = object\n+if K.backend() == 'tensorflow':\n+    import tensorflow as tf\n+    if tf.__version__ >= '2.0.0':\n+        BaseMeanIoU = tf.keras.metrics.MeanIoU\n+\n+\n+class MeanIoU(BaseMeanIoU):\n+    \"\"\"Computes the mean Intersection-Over-Union metric.\n+\n+    Mean Intersection-Over-Union is a common evaluation metric for semantic image\n+    segmentation, which first computes the IOU for each semantic class and then\n+    computes the average over classes. IOU is defined as follows:\n+    IOU = true_positive / (true_positive + false_positive + false_negative).\n+    The predictions are accumulated in a confusion matrix, weighted by\n+    `sample_weight` and the metric is then calculated from it.\n+\n+    If `sample_weight` is `None`, weights default to 1.\n+    Use `sample_weight` of 0 to mask values.\n+\n+    Usage with the compile API:\n+\n+    ```python\n+    model = keras.Model(inputs, outputs)\n+    model.compile(\n+        'sgd',\n+        loss='mse',\n+        metrics=[keras.metrics.MeanIoU(num_classes=2)])\n+    ```\n+\n+    # Arguments\n+        num_classes: The possible number of labels the prediction task can have.\n+            This value must be provided, since a confusion matrix of dimension =\n+            [num_classes, num_classes] will be allocated.\n+        name: (Optional) string name of the metric instance.\n+        dtype: (Optional) data type of the metric result.\n+    \"\"\"\n+    def __init__(self, num_classes, name=None, dtype=None):\n+        if K.backend() != 'tensorflow' or BaseMeanIoU is object:\n+            raise RuntimeError(\n+                '`MeanIoU` metric is currently supported only '\n+                'with TensorFlow backend and TF version >= 2.0.0.')\n+        super(MeanIoU, self).__init__(num_classes, name=name, dtype=dtype)\n+\n+\n def accuracy(y_true, y_pred):\n     if not K.is_tensor(y_pred):\n         y_pred = K.constant(y_pred)\n@@ -1911,8 +1957,6 @@ mae = MAE = mean_absolute_error\n mape = MAPE = mean_absolute_percentage_error\n msle = MSLE = mean_squared_logarithmic_error\n cosine = cosine_similarity = cosine_proximity\n-if K.backend() == 'tensorflow':\n-    MeanIoU = K.MeanIoU\n \n \n def serialize(metric):\n\n@@ -80,7 +80,8 @@ def filter_top_k(x, k):\n     # Returns\n         tensor with same shape and dtype as x.\n     \"\"\"\n-    _, top_k_idx = K.top_k(x, k, sorted=False)\n+    from tensorflow.nn import top_k\n+    _, top_k_idx = top_k(x, k, sorted=False)\n     top_k_mask = K.sum(\n         K.one_hot(top_k_idx, x.shape[-1]), axis=-2)\n     return x * top_k_mask + NEG_INF * (1 - top_k_mask)\n\n@@ -0,0 +1,69 @@\n+\"\"\"Tests for metric objects training and evaluation.\"\"\"\n+import pytest\n+import numpy as np\n+\n+from keras import metrics\n+from keras import backend as K\n+from keras.layers import Dense\n+from keras.models import Sequential\n+\n+\n+class TestMetricsTrainingEvaluation(object):\n+\n+    def test_training_and_eval(self):\n+        model = Sequential([Dense(2, input_shape=(3,))])\n+        metrics_list = [\n+            metrics.Accuracy(),\n+            metrics.MeanSquaredError(),\n+            metrics.Hinge(),\n+            metrics.CategoricalHinge(),\n+            metrics.SquaredHinge(),\n+            metrics.FalsePositives(),\n+            metrics.TruePositives(),\n+            metrics.FalseNegatives(),\n+            metrics.TrueNegatives(),\n+            metrics.BinaryAccuracy(),\n+            metrics.CategoricalAccuracy(),\n+            metrics.TopKCategoricalAccuracy(),\n+            metrics.LogCoshError(),\n+            metrics.Poisson(),\n+            metrics.KLDivergence(),\n+            metrics.CosineSimilarity(),\n+            metrics.MeanAbsoluteError(),\n+            metrics.MeanAbsolutePercentageError(),\n+            metrics.MeanSquaredError(),\n+            metrics.MeanSquaredLogarithmicError(),\n+            metrics.RootMeanSquaredError(),\n+            metrics.BinaryCrossentropy(),\n+            metrics.CategoricalCrossentropy(),\n+            metrics.SensitivityAtSpecificity(0.5),\n+            metrics.SpecificityAtSensitivity(0.5),\n+            metrics.Precision(),\n+            metrics.Recall(),\n+            metrics.AUC()]\n+        model.compile('rmsprop', 'mse', metrics=metrics_list)\n+        x = np.random.random((10, 3))\n+        y = np.random.random((10, 2))\n+        model.fit(x, y)\n+        model.evaluate(x, y)\n+\n+    def test_sparse_metrics(self):\n+        model = Sequential([Dense(1, input_shape=(3,))])\n+        metrics_list = [\n+            metrics.SparseCategoricalAccuracy(),\n+            metrics.SparseTopKCategoricalAccuracy(),\n+            metrics.SparseCategoricalCrossentropy()]\n+        model.compile('rmsprop', 'mse', metrics=metrics_list)\n+        x = np.random.random((10, 3))\n+        y = np.random.random((10,))\n+        model.fit(x, y)\n+        model.evaluate(x, y)\n+\n+    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n+    def test_mean_iou(self):\n+        model = Sequential([Dense(1, input_shape=(3,))])\n+        model.compile('rmsprop', 'mse', metrics=[metrics.MeanIoU(2)])\n+        x = np.random.random((10, 3))\n+        y = np.random.random((10,))\n+        model.fit(x, y)\n+        model.evaluate(x, y)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#388cbf171d79933522560296368ff1b64cf60537", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 73 | Lines Deleted: 57 | Files Changed: 5 | Hunks: 26 | Methods Changed: 10 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 130 | Churn Cumulative: 8804 | Contributors (this commit): 94 | Commits (past 90d): 33 | Contributors (cumulative): 103 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1091,15 +1091,16 @@ def tile(x, n):\n     elif isinstance(n, list):\n         n = tuple(n)\n \n-    y = T.tile(x, n)\n+    y = T.tile(x, n, ndim=x.ndim)\n     shape = int_shape(x)\n     if shape is None:\n         return y\n-    elif len(n) < len(shape):  # Padding the axis\n+    elif isinstance(n, tuple) and len(n) < len(shape):  # Padding the axis\n         n = tuple([1 for _ in range(len(shape) - len(n))]) + n\n-    elif len(n) != len(shape):\n+    elif isinstance(n, tuple) and len(n) != len(shape):\n         raise NotImplementedError\n \n+    if isinstance(n, tuple):\n         y._keras_shape = tuple([None if a is None else a * b\n                                 for (a, b) in zip(shape, n)])\n     return y\n\n@@ -80,8 +80,8 @@ def filter_top_k(x, k):\n     # Returns\n         tensor with same shape and dtype as x.\n     \"\"\"\n-    from tensorflow.nn import top_k\n-    _, top_k_idx = top_k(x, k, sorted=False)\n+    import tensorflow as tf\n+    _, top_k_idx = tf.nn.top_k(x, k, sorted=False)\n     top_k_mask = K.sum(\n         K.one_hot(top_k_idx, x.shape[-1]), axis=-2)\n     return x * top_k_mask + NEG_INF * (1 - top_k_mask)\n@@ -171,7 +171,7 @@ def weighted_assign_add(label, pred, weights, var):\n     label_and_pred = K.cast(label_and_pred, dtype=K.floatx())\n     if weights is not None:\n         label_and_pred *= weights\n-    return var.assign_add(K.sum(label_and_pred, 1))\n+    return K.update_add(var, K.sum(label_and_pred, 1))\n \n \n def update_confusion_matrix_variables(variables_to_update,\n@@ -273,7 +273,11 @@ def update_confusion_matrix_variables(variables_to_update,\n     # Tile the thresholds for every prediction.\n     thresh_tiled = K.tile(\n         K.expand_dims(K.constant(thresholds), 1),\n-        K.stack([1, num_predictions]))\n+        K.cast(\n+            K.stack([1, num_predictions]),\n+            dtype='int32',\n+        )\n+    )\n \n     # Tile the predictions for every threshold.\n     preds_tiled = K.tile(predictions_2d, [num_thresholds, 1])\n\n@@ -72,7 +72,7 @@ def test_image_data_generator_training():\n                                   validation_data=img_gen.flow(x_test, y_test,\n                                                                batch_size=16),\n                                   verbose=0)\n-    assert history.history['val_accuracy'][-1] > 0.75\n+    assert history.history['val_accuracy'][-1] > 0.70\n     model.evaluate_generator(img_gen.flow(x_train, y_train, batch_size=16))\n \n \n\n@@ -10,6 +10,8 @@ if K.backend() != 'tensorflow':\n     # Need TensorFlow to use metric.__call__\n     pytestmark = pytest.mark.skip\n \n+import tensorflow as tf\n+\n \n class TestFalsePositives(object):\n \n@@ -663,7 +665,6 @@ class TestPrecisionTest(object):\n         expected_precision = weighted_tp / weighted_positives\n         assert np.allclose([expected_precision, 0], K.eval(result), 1e-3)\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k(self):\n         p_obj = metrics.Precision(top_k=3)\n         y_pred = K.constant([0.2, 0.1, 0.5, 0, 0.2], shape=(1, 5))\n@@ -671,7 +672,6 @@ class TestPrecisionTest(object):\n         result = p_obj(y_true, y_pred)\n         assert np.isclose(1. / 3, K.eval(result))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_weighted_top_k(self):\n         p_obj = metrics.Precision(top_k=3)\n         y_pred1 = K.constant([0.2, 0.1, 0.4, 0, 0.2], shape=(1, 5))\n@@ -715,7 +715,6 @@ class TestPrecisionTest(object):\n         assert np.isclose(1, K.eval(p_obj.true_positives))\n         assert np.isclose(1, K.eval(p_obj.false_positives))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k_and_class_id(self):\n         p_obj = metrics.Precision(class_id=2, top_k=2)\n \n@@ -733,7 +732,6 @@ class TestPrecisionTest(object):\n         assert np.isclose(1, K.eval(p_obj.true_positives))\n         assert np.isclose(0, K.eval(p_obj.false_positives))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k_and_threshold(self):\n         p_obj = metrics.Precision(thresholds=.7, top_k=2)\n \n@@ -816,7 +814,6 @@ class TestRecall(object):\n         expected_recall = weighted_tp / weighted_positives\n         assert np.allclose([expected_recall, 0], K.eval(result), 1e-3)\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k(self):\n         r_obj = metrics.Recall(top_k=3)\n         y_pred = K.constant([0.2, 0.1, 0.5, 0, 0.2], shape=(1, 5))\n@@ -824,7 +821,6 @@ class TestRecall(object):\n         result = r_obj(y_true, y_pred)\n         assert np.isclose(0.5, K.eval(result))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_weighted_top_k(self):\n         r_obj = metrics.Recall(top_k=3)\n         y_pred1 = K.constant([0.2, 0.1, 0.4, 0, 0.2], shape=(1, 5))\n@@ -868,7 +864,6 @@ class TestRecall(object):\n         assert np.isclose(1, K.eval(r_obj.true_positives))\n         assert np.isclose(1, K.eval(r_obj.false_negatives))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k_and_class_id(self):\n         r_obj = metrics.Recall(class_id=2, top_k=2)\n \n@@ -886,7 +881,6 @@ class TestRecall(object):\n         assert np.isclose(1, K.eval(r_obj.true_positives))\n         assert np.isclose(1, K.eval(r_obj.false_negatives))\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n     def test_unweighted_top_k_and_threshold(self):\n         r_obj = metrics.Recall(thresholds=.7, top_k=2)\n \n@@ -898,7 +892,8 @@ class TestRecall(object):\n         assert np.isclose(3, K.eval(r_obj.false_negatives))\n \n \n-@pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n+@pytest.mark.skipif(not tf.__version__.startswith('2.'),\n+                    reason='Requires TF 2')\n class TestMeanIoU(object):\n \n     def test_config(self):\n\n@@ -7,59 +7,75 @@ from keras import backend as K\n from keras.layers import Dense\n from keras.models import Sequential\n \n+METRICS = [\n+    metrics.Accuracy,\n+    metrics.MeanSquaredError,\n+    metrics.Hinge,\n+    metrics.CategoricalHinge,\n+    metrics.SquaredHinge,\n+    metrics.FalsePositives,\n+    metrics.TruePositives,\n+    metrics.FalseNegatives,\n+    metrics.TrueNegatives,\n+    metrics.BinaryAccuracy,\n+    metrics.CategoricalAccuracy,\n+    metrics.TopKCategoricalAccuracy,\n+    metrics.LogCoshError,\n+    metrics.Poisson,\n+    metrics.KLDivergence,\n+    metrics.CosineSimilarity,\n+    metrics.MeanAbsoluteError,\n+    metrics.MeanAbsolutePercentageError,\n+    metrics.MeanSquaredError,\n+    metrics.MeanSquaredLogarithmicError,\n+    metrics.RootMeanSquaredError,\n+    metrics.BinaryCrossentropy,\n+    metrics.CategoricalCrossentropy,\n+    metrics.Precision,\n+    metrics.Recall,\n+    metrics.AUC,\n+]\n+SPARSE_METRICS = [\n+    metrics.SparseCategoricalAccuracy,\n+    metrics.SparseTopKCategoricalAccuracy,\n+    metrics.SparseCategoricalCrossentropy\n+]\n \n-class TestMetricsTrainingEvaluation(object):\n \n-    def test_training_and_eval(self):\n+@pytest.mark.parametrize('metric_cls', METRICS)\n+def test_training_and_eval(metric_cls):\n     model = Sequential([Dense(2, input_shape=(3,))])\n+    model.compile('rmsprop', 'mse', metrics=[metric_cls()])\n+    x = np.random.random((10, 3))\n+    y = np.random.random((10, 2))\n+    model.fit(x, y)\n+    model.evaluate(x, y)\n+\n+\n+@pytest.mark.parametrize('metric_cls', SPARSE_METRICS)\n+def test_sparse_metrics(metric_cls):\n+    model = Sequential([Dense(1, input_shape=(3,))])\n+    model.compile('rmsprop', 'mse', metrics=[metric_cls()])\n+    x = np.random.random((10, 3))\n+    y = np.random.random((10,))\n+    model.fit(x, y)\n+    model.evaluate(x, y)\n+\n+\n+def test_sensitivity_metrics():\n     metrics_list = [\n-            metrics.Accuracy(),\n-            metrics.MeanSquaredError(),\n-            metrics.Hinge(),\n-            metrics.CategoricalHinge(),\n-            metrics.SquaredHinge(),\n-            metrics.FalsePositives(),\n-            metrics.TruePositives(),\n-            metrics.FalseNegatives(),\n-            metrics.TrueNegatives(),\n-            metrics.BinaryAccuracy(),\n-            metrics.CategoricalAccuracy(),\n-            metrics.TopKCategoricalAccuracy(),\n-            metrics.LogCoshError(),\n-            metrics.Poisson(),\n-            metrics.KLDivergence(),\n-            metrics.CosineSimilarity(),\n-            metrics.MeanAbsoluteError(),\n-            metrics.MeanAbsolutePercentageError(),\n-            metrics.MeanSquaredError(),\n-            metrics.MeanSquaredLogarithmicError(),\n-            metrics.RootMeanSquaredError(),\n-            metrics.BinaryCrossentropy(),\n-            metrics.CategoricalCrossentropy(),\n         metrics.SensitivityAtSpecificity(0.5),\n         metrics.SpecificityAtSensitivity(0.5),\n-            metrics.Precision(),\n-            metrics.Recall(),\n-            metrics.AUC()]\n+    ]\n+    model = Sequential([Dense(2, input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=metrics_list)\n     x = np.random.random((10, 3))\n     y = np.random.random((10, 2))\n     model.fit(x, y)\n     model.evaluate(x, y)\n \n-    def test_sparse_metrics(self):\n-        model = Sequential([Dense(1, input_shape=(3,))])\n-        metrics_list = [\n-            metrics.SparseCategoricalAccuracy(),\n-            metrics.SparseTopKCategoricalAccuracy(),\n-            metrics.SparseCategoricalCrossentropy()]\n-        model.compile('rmsprop', 'mse', metrics=metrics_list)\n-        x = np.random.random((10, 3))\n-        y = np.random.random((10,))\n-        model.fit(x, y)\n-        model.evaluate(x, y)\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow', reason=\"requires tensorflow\")\n+@pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')\n def test_mean_iou(self):\n     model = Sequential([Dense(1, input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metrics.MeanIoU(2)])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a1be7c3ebd16a9a8add07bf144545def932c7e0d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 1 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 24 | Churn Cumulative: 4718 | Contributors (this commit): 17 | Commits (past 90d): 38 | Contributors (cumulative): 21 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1412,6 +1412,12 @@ class Precision(Metric):\n             raise RuntimeError(\n                 '`top_k` argument for `Precision` metric is currently supported '\n                 'only with TensorFlow backend.')\n+            import tensorflow as tf\n+            if not tf.__version__.startswith('2.'):\n+                raise RuntimeError(\n+                    '`top_k` argument for `Precision` metric is currently '\n+                    'supported only with TensorFlow 2.0. Your version '\n+                    'of TensorFlow is ' + str(tf.__version__))\n \n         self.top_k = top_k\n         self.class_id = class_id\n@@ -1522,6 +1528,12 @@ class Recall(Metric):\n             raise RuntimeError(\n                 '`top_k` argument for `Recall` metric is currently supported only '\n                 'with TensorFlow backend.')\n+            import tensorflow as tf\n+            if not tf.__version__.startswith('2.'):\n+                raise RuntimeError(\n+                    '`top_k` argument for `Precision` metric is currently '\n+                    'supported only with TensorFlow 2.0. Your version '\n+                    'of TensorFlow is ' + str(tf.__version__))\n \n         self.top_k = top_k\n         self.class_id = class_id\n@@ -1885,6 +1897,12 @@ class MeanIoU(BaseMeanIoU):\n             raise RuntimeError(\n                 '`MeanIoU` metric is currently supported only '\n                 'with TensorFlow backend and TF version >= 2.0.0.')\n+            import tensorflow as tf\n+            if not tf.__version__.startswith('2.'):\n+                raise RuntimeError(\n+                    '`top_k` argument for `Precision` metric is currently '\n+                    'supported only with TensorFlow 2.0. Your version '\n+                    'of TensorFlow is ' + str(tf.__version__))\n         super(MeanIoU, self).__init__(num_classes, name=name, dtype=dtype)\n \n \n\n@@ -594,6 +594,8 @@ class TestAUC(object):\n             metrics.AUC(summation_method='Invalid')\n \n \n+@pytest.mark.skipif(not tf.__version__.startswith('2.'),\n+                    reason='Requires TF 2')\n class TestPrecisionTest(object):\n \n     def test_config(self):\n@@ -743,6 +745,8 @@ class TestPrecisionTest(object):\n         assert np.isclose(0, K.eval(p_obj.false_positives))\n \n \n+@pytest.mark.skipif(not tf.__version__.startswith('2.'),\n+                    reason='Requires TF 2')\n class TestRecall(object):\n \n     def test_config(self):\n\n@@ -76,7 +76,7 @@ def test_sensitivity_metrics():\n \n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')\n-def test_mean_iou(self):\n+def test_mean_iou():\n     model = Sequential([Dense(1, input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metrics.MeanIoU(2)])\n     x = np.random.random((10, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fe4110f22a26c7c03995429371cecf511f68eb24", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 22 | Files Changed: 3 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/1 | Churn Δ: 26 | Churn Cumulative: 4744 | Contributors (this commit): 17 | Commits (past 90d): 41 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1412,12 +1412,6 @@ class Precision(Metric):\n             raise RuntimeError(\n                 '`top_k` argument for `Precision` metric is currently supported '\n                 'only with TensorFlow backend.')\n-            import tensorflow as tf\n-            if not tf.__version__.startswith('2.'):\n-                raise RuntimeError(\n-                    '`top_k` argument for `Precision` metric is currently '\n-                    'supported only with TensorFlow 2.0. Your version '\n-                    'of TensorFlow is ' + str(tf.__version__))\n \n         self.top_k = top_k\n         self.class_id = class_id\n@@ -1528,12 +1522,6 @@ class Recall(Metric):\n             raise RuntimeError(\n                 '`top_k` argument for `Recall` metric is currently supported only '\n                 'with TensorFlow backend.')\n-            import tensorflow as tf\n-            if not tf.__version__.startswith('2.'):\n-                raise RuntimeError(\n-                    '`top_k` argument for `Precision` metric is currently '\n-                    'supported only with TensorFlow 2.0. Your version '\n-                    'of TensorFlow is ' + str(tf.__version__))\n \n         self.top_k = top_k\n         self.class_id = class_id\n@@ -1897,12 +1885,6 @@ class MeanIoU(BaseMeanIoU):\n             raise RuntimeError(\n                 '`MeanIoU` metric is currently supported only '\n                 'with TensorFlow backend and TF version >= 2.0.0.')\n-            import tensorflow as tf\n-            if not tf.__version__.startswith('2.'):\n-                raise RuntimeError(\n-                    '`top_k` argument for `Precision` metric is currently '\n-                    'supported only with TensorFlow 2.0. Your version '\n-                    'of TensorFlow is ' + str(tf.__version__))\n         super(MeanIoU, self).__init__(num_classes, name=name, dtype=dtype)\n \n \n\n@@ -594,8 +594,6 @@ class TestAUC(object):\n             metrics.AUC(summation_method='Invalid')\n \n \n-@pytest.mark.skipif(not tf.__version__.startswith('2.'),\n-                    reason='Requires TF 2')\n class TestPrecisionTest(object):\n \n     def test_config(self):\n@@ -745,8 +743,6 @@ class TestPrecisionTest(object):\n         assert np.isclose(0, K.eval(p_obj.false_positives))\n \n \n-@pytest.mark.skipif(not tf.__version__.startswith('2.'),\n-                    reason='Requires TF 2')\n class TestRecall(object):\n \n     def test_config(self):\n\n@@ -77,6 +77,10 @@ def test_sensitivity_metrics():\n \n @pytest.mark.skipif(K.backend() != 'tensorflow', reason='requires tensorflow')\n def test_mean_iou():\n+    import tensorflow as tf\n+    if not tf.__version__.startswith('2.'):\n+        return\n+\n     model = Sequential([Dense(1, input_shape=(3,))])\n     model.compile('rmsprop', 'mse', metrics=[metrics.MeanIoU(2)])\n     x = np.random.random((10, 3))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b86a986c0bbc4d6501c0ffa0da9ad47e9050ee8b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1512 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -688,7 +688,7 @@ class TestPrecisionTest(object):\n \n         tp = (2 + 5) + (3 + 3)\n         predicted_positives = (1 + 2 + 5) + (3 + 3 + 3)\n-        expected_precision = tp / predicted_positives\n+        expected_precision = float(tp) / predicted_positives\n         assert np.isclose(expected_precision, K.eval(result))\n \n     def test_unweighted_class_id(self):\n@@ -837,7 +837,7 @@ class TestRecall(object):\n \n         tp = (2 + 5) + (3 + 3)\n         positives = (4 + 2 + 5) + (3 + 3 + 3 + 3)\n-        expected_recall = tp / positives\n+        expected_recall = float(tp) / positives\n         assert np.isclose(expected_recall, K.eval(result))\n \n     def test_unweighted_class_id(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e70caf7c6e03fe7a112d60a2ed920f0deda0b43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 176 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -7,6 +7,11 @@ from keras import backend as K\n from keras.layers import Dense\n from keras.models import Sequential\n \n+\n+if K.backend() == 'cntk':\n+    pytestmark = pytest.mark.skip\n+\n+\n METRICS = [\n     metrics.Accuracy,\n     metrics.MeanSquaredError,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#da289bb337ea2639cb03d162574aaeb94f58e928", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1514 | Contributors (this commit): 2 | Commits (past 90d): 11 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -917,7 +917,7 @@ class TestMeanIoU(object):\n         # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n         # iou = true_positives / (sum_row + sum_col - true_positives))\n         expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n-        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n+        assert np.allclose(K.eval(result), float(expected_result), atol=1e-3)\n \n     def test_weighted(self):\n         y_pred = K.constant([0, 1, 0, 1], dtype='float32')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bbed5cfa6b23a475ecba0d20a9574cbbaad569fa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1520 | Contributors (this commit): 2 | Commits (past 90d): 12 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -916,8 +916,8 @@ class TestMeanIoU(object):\n         #       [1, 1]]\n         # sum_row = [2, 2], sum_col = [2, 2], true_positives = [1, 1]\n         # iou = true_positives / (sum_row + sum_col - true_positives))\n-        expected_result = (1 / (2 + 2 - 1) + 1 / (2 + 2 - 1)) / 2\n-        assert np.allclose(K.eval(result), float(expected_result), atol=1e-3)\n+        expected_result = (1. / (2 + 2 - 1) + 1. / (2 + 2 - 1)) / 2\n+        assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n \n     def test_weighted(self):\n         y_pred = K.constant([0, 1, 0, 1], dtype='float32')\n@@ -964,5 +964,5 @@ class TestMeanIoU(object):\n         #       [0, 1]]\n         # sum_row = [0, 1], sum_col = [0, 1], true_positives = [0, 1]\n         # iou = true_positives / (sum_row + sum_col - true_positives))\n-        expected_result = (0 + 1 / (1 + 1 - 1)) / 1\n+        expected_result = (0. + 1. / (1 + 1 - 1)) / 1\n         assert np.allclose(K.eval(result), expected_result, atol=1e-3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#88ca804d94a0f978d0522d82a2e2bda26362076a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 2 | Churn Cumulative: 127 | Contributors (this commit): 7 | Commits (past 90d): 1 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -13,7 +13,7 @@ from ..utils.generic_utils import to_list\n \n \n def _get_available_devices():\n-    return K.tensorflow_backend._get_available_gpus()\n+    return K.tensorflow_backend._get_available_gpus() + ['/cpu:0']\n \n \n def _normalize_device_name(name):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e8e2733ab281f50d03170c744cc42275f47c4fd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 867 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -134,7 +134,7 @@ class LossFunctionWrapper(Loss):\n     def get_config(self):\n         config = {}\n         for k, v in six.iteritems(self._fn_kwargs):\n-            config[k] = K.eval(v) if is_tensor_or_variable(v) else v\n+            config[k] = K.eval(v) if K.is_tensor(v) or K.is_variable(v) else v\n         base_config = super(LossFunctionWrapper, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8315a0b7b93ae87a94812f5833a6c7befddc4fe6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 308 | Contributors (this commit): 8 | Commits (past 90d): 1 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -114,6 +114,7 @@ decoder_target_data = np.zeros(\n for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n     for t, char in enumerate(input_text):\n         encoder_input_data[i, t, input_token_index[char]] = 1.\n+    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n     for t, char in enumerate(target_text):\n         # decoder_target_data is ahead of decoder_input_data by one timestep\n         decoder_input_data[i, t, target_token_index[char]] = 1.\n@@ -121,7 +122,8 @@ for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n             # decoder_target_data will be ahead by one timestep\n             # and will not include the start character.\n             decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n-\n+    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n+    decoder_target_data[i, t:, target_token_index[' ']] = 1.\n # Define an input sequence and process it.\n encoder_inputs = Input(shape=(None, num_encoder_tokens))\n encoder = LSTM(latent_dim, return_state=True)\n@@ -145,7 +147,8 @@ decoder_outputs = decoder_dense(decoder_outputs)\n model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n \n # Run training\n-model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n+model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n+              metrics=['accuracy'])\n model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n           batch_size=batch_size,\n           epochs=epochs,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66455371551a544ed5127ed0792af1ef62001bb3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 474 | Contributors (this commit): 11 | Commits (past 90d): 1 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -79,7 +79,7 @@ def tokenize(sent):\n     >>> tokenize('Bob dropped the apple. Where is the apple?')\n     ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n     '''\n-    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n+    return [x.strip() for x in re.split(r'(\\W+)', sent) if x.strip()]\n \n \n def parse_stories(lines, only_supporting=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ccecd39dd9281d65bada97f6762f622563227315", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 12136 | Contributors (this commit): 70 | Commits (past 90d): 2 | Contributors (cumulative): 70 | DMM Complexity: None\n\nDIFF:\n@@ -1759,10 +1759,10 @@ class DepthwiseConv2D(Conv2D):\n \n     # Output shape\n         4D tensor with shape:\n-        `(batch, filters, new_rows, new_cols)`\n+        `(batch, channels * depth_multiplier, new_rows, new_cols)`\n         if `data_format` is `\"channels_first\"`\n         or 4D tensor with shape:\n-        `(batch, new_rows, new_cols, filters)`\n+        `(batch, new_rows, new_cols,  channels * depth_multiplier)`\n         if `data_format` is `\"channels_last\"`.\n         `rows` and `cols` values might have changed due to padding.\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1eac861262d00618e490d50a9db9f69572bd3300", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1644 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -618,7 +618,7 @@ class Layer(object):\n                 instead of an integer.\n \n         # Returns\n-            An input shape tuple.\n+            An output shape tuple.\n         \"\"\"\n         return input_shape\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb96315a291a8515544c6dd807500073958f8928", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 4/2 | Churn Δ: 34 | Churn Cumulative: 22082 | Contributors (this commit): 141 | Commits (past 90d): 21 | Contributors (cumulative): 179 | DMM Complexity: 1.0\n\nDIFF:\n@@ -528,6 +528,10 @@ def print_tensor(x, message=''):\n     return x\n \n \n+def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=0.001):\n+    return ((x - mean) / sqrt(var + epsilon)) * gamma + beta\n+\n+\n def dot(x, y):\n     return np.dot(x, y)\n \n\n@@ -2332,6 +2332,8 @@ def batch_normalization(x, mean, var, beta, gamma, axis=-1, epsilon=1e-3):\n \n     # Returns\n         A tensor.\n+\n+    {{np_implementation}}\n     \"\"\"\n     if ndim(x) == 4:\n         # The CPU implementation of FusedBatchNorm only support NHWC\n\n@@ -1641,6 +1641,34 @@ class TestBackend(object):\n         with pytest.raises(ValueError):\n             K.bias_add(x, b, data_format='channels_middle')\n \n+    @pytest.mark.skipif(K.backend() == 'theano',\n+                        reason='Theano behaves differently '\n+                               'because of the broadcast.')\n+    @pytest.mark.parametrize('axis', [1, -1])\n+    @pytest.mark.parametrize('x_shape', [(3, 2, 4, 5), (3, 2, 4)])\n+    def test_batch_normalization(self, axis, x_shape):\n+        other_shape = [1] * len(x_shape)\n+        other_shape[axis] = x_shape[axis]\n+        other_shape = tuple(other_shape)\n+        x_np = np.random.random(x_shape)\n+        mean_np = np.random.random(other_shape)\n+        var_np = np.random.random(other_shape)\n+        beta_np = np.random.random(other_shape)\n+        gamma_np = np.random.random(other_shape)\n+        output_tensors = []\n+        output_arrays = []\n+        for k in WITH_NP:\n+            x = k.variable(x_np)\n+            mean = k.variable(mean_np)\n+            var = k.variable(var_np)\n+            beta = k.variable(beta_np)\n+            gamma = k.variable(gamma_np)\n+            output = k.batch_normalization(x, mean, var, beta, gamma, axis=axis)\n+            output_tensors.append(output)\n+            output_arrays.append(k.eval(output))\n+        assert_list_pairwise(output_arrays)\n+        assert_list_keras_shape(output_tensors, output_arrays)\n+\n     @pytest.mark.skipif(K.backend() != 'theano',\n                         reason='Specific to Theano.')\n     @pytest.mark.parametrize('x_shape', [(1, 4, 2, 3), (1, 2, 3, 4)])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
