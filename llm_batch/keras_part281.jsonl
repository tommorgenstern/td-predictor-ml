{"custom_id": "keras#b0bfd5201da2bfced84028bcc5bda05bdfd75af7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1166 | Contributors (this commit): 25 | Commits (past 90d): 1 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -103,6 +103,7 @@ def print_summary(model, line_length=None, positions=None, print_fn=None):\n             line += ' ' * (positions[i] - len(line))\n         print_fn(line)\n \n+    print_fn('Model: \"{}\"'.format(model.name))\n     print_fn('_' * line_length)\n     print_row(to_display, positions)\n     print_fn('=' * line_length)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4185cbb50bfcae9cc30b0fc7b67e81d67a50a8ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 27 | Churn Cumulative: 2588 | Contributors (this commit): 36 | Commits (past 90d): 3 | Contributors (cumulative): 42 | DMM Complexity: 1.0\n\nDIFF:\n@@ -703,7 +703,7 @@ class TFOptimizer(Optimizer):\n \n     @interfaces.legacy_get_updates_support\n     def get_updates(self, loss, params):\n-        grads = self.optimizer.compute_gradients(loss, params)\n+        grads = self.optimizer.compute_gradients(loss, var_list=params)\n         self.updates = [K.update_add(self.iterations, 1)]\n         opt_update = self.optimizer.apply_gradients(\n             grads, global_step=self.iterations)\n\n@@ -148,5 +148,30 @@ def test_tfoptimizer():\n         optimizer.from_config(None)\n \n \n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n+                    reason='Requires TensorFlow backend')\n+def test_tfoptimizer_pass_correct_named_params_to_native_tensorflow_optimizer():\n+    from keras import constraints\n+    from tensorflow import train\n+\n+    class MyTfOptimizer(train.Optimizer):\n+        wrapping_optimizer = train.AdamOptimizer()\n+\n+        def compute_gradients(self, loss, **kwargs):\n+            return super(MyTfOptimizer, self).compute_gradients(loss, **kwargs)\n+\n+        def apply_gradients(self, grads_and_vars, **kwargs):\n+            return self.wrapping_optimizer.apply_gradients(grads_and_vars,\n+                                                           **kwargs)\n+    my_tf_optimizer = MyTfOptimizer(use_locking=False, name='MyTfOptimizer')\n+    optimizer = optimizers.TFOptimizer(my_tf_optimizer)\n+    model = Sequential()\n+    model.add(Dense(num_classes, input_shape=(3,),\n+                    kernel_constraint=constraints.MaxNorm(1)))\n+    model.compile(loss='mean_squared_error', optimizer=optimizer)\n+    model.fit(np.random.random((5, 3)), np.random.random((5, num_classes)),\n+              epochs=1, batch_size=5, verbose=0)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e4e342f70dec046fdb1a092e5a12c565f37b9ddc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 14 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 144 | Churn Cumulative: 562 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -206,6 +206,7 @@ PAGES = [\n             layers.GRU,\r\n             layers.LSTM,\r\n             layers.ConvLSTM2D,\r\n+            layers.ConvLSTM2DCell,\r\n             layers.SimpleRNNCell,\r\n             layers.GRUCell,\r\n             layers.LSTMCell,\r\n@@ -241,6 +242,7 @@ PAGES = [\n             layers.Multiply,\r\n             layers.Average,\r\n             layers.Maximum,\r\n+            layers.Minimum,\r\n             layers.Concatenate,\r\n             layers.Dot,\r\n         ],\r\n@@ -250,6 +252,7 @@ PAGES = [\n             layers.multiply,\r\n             layers.average,\r\n             layers.maximum,\r\n+            layers.minimum,\r\n             layers.concatenate,\r\n             layers.dot,\r\n         ]\r\n\n@@ -5,20 +5,133 @@ from ..engine.base_layer import Layer\n from ..engine import Input\n from ..engine import InputLayer\n from ..engine.base_layer import InputSpec\n-from .merge import *\n-from .core import *\n-from .convolutional import *\n-from .pooling import *\n-from .local import *\n-from .recurrent import *\n-from .cudnn_recurrent import *\n-from .normalization import *\n-from .embeddings import *\n-from .noise import *\n-from .advanced_activations import *\n-from .wrappers import *\n-from .convolutional_recurrent import *\n-from ..legacy.layers import *\n+\n+from .merge import Add\n+from .merge import Subtract\n+from .merge import Multiply\n+from .merge import Average\n+from .merge import Maximum\n+from .merge import Minimum\n+from .merge import Concatenate\n+from .merge import Dot\n+from .merge import add\n+from .merge import subtract\n+from .merge import multiply\n+from .merge import average\n+from .merge import maximum\n+from .merge import minimum\n+from .merge import concatenate\n+from .merge import dot\n+\n+from .core import Dense\n+from .core import Activation\n+from .core import Dropout\n+from .core import Flatten\n+from .core import Reshape\n+from .core import Permute\n+from .core import RepeatVector\n+from .core import Lambda\n+from .core import ActivityRegularization\n+from .core import Masking\n+from .core import SpatialDropout1D\n+from .core import SpatialDropout2D\n+from .core import SpatialDropout3D\n+\n+from .convolutional import Conv1D\n+from .convolutional import Conv2D\n+from .convolutional import SeparableConv1D\n+from .convolutional import SeparableConv2D\n+from .convolutional import DepthwiseConv2D\n+from .convolutional import Conv2DTranspose\n+from .convolutional import Conv3D\n+from .convolutional import Conv3DTranspose\n+from .convolutional import Cropping1D\n+from .convolutional import Cropping2D\n+from .convolutional import Cropping3D\n+from .convolutional import UpSampling1D\n+from .convolutional import UpSampling2D\n+from .convolutional import UpSampling3D\n+from .convolutional import ZeroPadding1D\n+from .convolutional import ZeroPadding2D\n+from .convolutional import ZeroPadding3D\n+\n+# Aliases (not in the docs)\n+from .convolutional import Convolution1D\n+from .convolutional import Convolution2D\n+from .convolutional import Convolution3D\n+from .convolutional import Deconvolution2D\n+from .convolutional import Deconvolution3D\n+\n+from .pooling import MaxPooling1D\n+from .pooling import MaxPooling2D\n+from .pooling import MaxPooling3D\n+from .pooling import AveragePooling1D\n+from .pooling import AveragePooling2D\n+from .pooling import AveragePooling3D\n+from .pooling import GlobalMaxPooling1D\n+from .pooling import GlobalMaxPooling2D\n+from .pooling import GlobalMaxPooling3D\n+from .pooling import GlobalAveragePooling2D\n+from .pooling import GlobalAveragePooling1D\n+from .pooling import GlobalAveragePooling3D\n+\n+# Aliases (not in the docs)\n+from .pooling import MaxPool1D\n+from .pooling import MaxPool2D\n+from .pooling import MaxPool3D\n+from .pooling import AvgPool1D\n+from .pooling import AvgPool2D\n+from .pooling import AvgPool3D\n+from .pooling import GlobalMaxPool1D\n+from .pooling import GlobalMaxPool2D\n+from .pooling import GlobalMaxPool3D\n+from .pooling import GlobalAvgPool1D\n+from .pooling import GlobalAvgPool2D\n+from .pooling import GlobalAvgPool3D\n+\n+from .local import LocallyConnected1D\n+from .local import LocallyConnected2D\n+\n+from .recurrent import RNN\n+from .recurrent import SimpleRNN\n+from .recurrent import GRU\n+from .recurrent import LSTM\n+from .recurrent import SimpleRNNCell\n+from .recurrent import GRUCell\n+from .recurrent import LSTMCell\n+from .recurrent import StackedRNNCells\n+\n+from .cudnn_recurrent import CuDNNGRU\n+from .cudnn_recurrent import CuDNNLSTM\n+\n+from .normalization import BatchNormalization\n+\n+from .embeddings import Embedding\n+\n+from .noise import GaussianNoise\n+from .noise import GaussianDropout\n+from .noise import AlphaDropout\n+\n+from .advanced_activations import LeakyReLU\n+from .advanced_activations import PReLU\n+from .advanced_activations import ELU\n+from .advanced_activations import ThresholdedReLU\n+from .advanced_activations import Softmax\n+from .advanced_activations import ReLU\n+\n+from .wrappers import Bidirectional\n+from .wrappers import TimeDistributed\n+\n+from .convolutional_recurrent import ConvLSTM2D\n+from .convolutional_recurrent import ConvLSTM2DCell\n+\n+# Legacy imports\n+from ..legacy.layers import MaxoutDense\n+from ..legacy.layers import Highway\n+from ..legacy.layers import AtrousConvolution1D\n+from ..legacy.layers import AtrousConvolution2D\n+from ..legacy.layers import Recurrent\n+from ..legacy.layers import ConvRecurrent2D\n \n \n def serialize(layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#86ce3cdd7d87d84532d08b0d6b65b3918a10ba5e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 347 | Contributors (this commit): 20 | Commits (past 90d): 2 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -58,7 +58,7 @@ def selu(x):\n     \"\"\"Scaled Exponential Linear Unit (SELU).\n \n     SELU is equal to: `scale * elu(x, alpha)`, where alpha and scale\n-    are pre-defined constants. The values of `alpha` and `scale` are\n+    are predefined constants. The values of `alpha` and `scale` are\n     chosen so that the mean and variance of the inputs are preserved\n     between two consecutive layers as long as the weights are initialized\n     correctly (see `lecun_normal` initialization) and the number of inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2dc4049c16ab8cbc215bb0ae80cd94a3d9542f5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 52 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): 9/9 | Churn Δ: 55 | Churn Cumulative: 3308 | Contributors (this commit): 43 | Commits (past 90d): 13 | Contributors (cumulative): 57 | DMM Complexity: 0.2857142857142857\n\nDIFF:\n@@ -312,6 +312,52 @@ def read_page_data(page_data, type):\n     return data\n \n \n+def get_module_docstring(filepath):\n+    \"\"\"Extract the module docstring.\n+\n+    Also finds the line at which the docstring ends.\n+    \"\"\"\n+    co = compile(open(filepath).read(), filepath, 'exec')\n+    if co.co_consts and isinstance(co.co_consts[0], str):\n+        docstring = co.co_consts[0]\n+    else:\n+        print('Could not get the docstring from ' + filepath)\n+        docstring = ''\n+    return docstring, co.co_firstlineno\n+\n+\n+def copy_examples():\n+    \"\"\"Copy the examples directory in the documentation.\n+\n+    Will make the files pretty by extracting the docstrings written in markdown.\n+    \"\"\"\n+    os.makedirs('sources/examples', exist_ok=True)\n+    for file in os.listdir('../examples'):\n+        if not file.endswith('.py'):\n+            continue\n+        docstring, starting_line = get_module_docstring('../examples/' + file)\n+        destination_file = 'sources/examples/' + file[:-2] + 'md'\n+        with open(destination_file, 'w+') as f_out, \\\n+                open('../examples/' + file, 'r+') as f_in:\n+\n+            f_out.write(docstring + '\\n\\n')\n+\n+            # skip docstring\n+            for _ in range(starting_line):\n+                next(f_in)\n+\n+            f_out.write('```python\\n')\n+            # next line might be empty.\n+            line = next(f_in)\n+            if line != '\\n':\n+                f_out.write(line)\n+\n+            # copy the rest of the file.\n+            for line in f_in:\n+                f_out.write(line)\n+            f_out.write('```')\n+\n+\n def generate():\n     if K.backend() != 'tensorflow':\n         raise ModuleNotFoundError('The documentation must be built '\n@@ -404,6 +450,7 @@ def generate():\n             f.write(mkdown)\n \n     shutil.copyfile('../CONTRIBUTING.md', 'sources/contributing.md')\n+    copy_examples()\n \n \n if __name__ == '__main__':\n\n@@ -1,5 +1,6 @@\n # -*- coding: utf-8 -*-\n-'''An implementation of sequence to sequence learning for performing addition\n+'''\n+# An implementation of sequence to sequence learning for performing addition\n \n Input: \"535+61\"\n Output: \"596\"\n\n@@ -1,4 +1,5 @@\n-'''Trains two recurrent neural networks based upon a story and a question.\n+'''\n+# Trains two recurrent neural networks based upon a story and a question.\n \n The resulting merged vector is then queried to answer a range of bAbI tasks.\n \n@@ -32,7 +33,7 @@ QA20 - Agent's Motivations   | 91               | 90.7\n For the resources related to the bAbI project, refer to:\n https://research.facebook.com/researchers/1543934539189348\n \n-# Notes\n+### Notes\n \n - With default word, sentence, and query vector sizes, the GRU model achieves:\n   - 52.1% test accuracy on QA1 in 20 epochs (2 seconds per epoch on CPU)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#328df7303425c2e3bf4274bb1eb0a2040bab5d8c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 23 | Churn Cumulative: 12943 | Contributors (this commit): 84 | Commits (past 90d): 5 | Contributors (cumulative): 93 | DMM Complexity: 0.8888888888888888\n\nDIFF:\n@@ -22,7 +22,6 @@ from ..utils.generic_utils import func_dump\n from ..utils.generic_utils import func_load\n from ..utils.generic_utils import deserialize_keras_object\n from ..utils.generic_utils import has_arg\n-from ..utils import conv_utils\n from ..legacy import interfaces\n \n \n@@ -644,6 +643,7 @@ class Lambda(Layer):\n                  mask=None, arguments=None, **kwargs):\n         super(Lambda, self).__init__(**kwargs)\n         self.function = function\n+        self._input_dtypes = None\n         self.arguments = arguments if arguments else {}\n         if mask is not None:\n             self.supports_masking = True\n@@ -664,10 +664,11 @@ class Lambda(Layer):\n             # With TensorFlow or CNTK, we can infer the output shape directly:\n             if K.backend() in ('tensorflow', 'cntk'):\n                 if isinstance(input_shape, list):\n-                    xs = [K.placeholder(shape=shape) for shape in input_shape]\n+                    xs = [K.placeholder(shape=shape, dtype=dtype)\n+                          for shape, dtype in zip(input_shape, self._input_dtypes)]\n                     x = self.call(xs)\n                 else:\n-                    x = K.placeholder(shape=input_shape)\n+                    x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)\n                     x = self.call(x)\n                 if isinstance(x, list):\n                     return [K.int_shape(x_elem) for x_elem in x]\n@@ -703,6 +704,10 @@ class Lambda(Layer):\n         arguments = self.arguments\n         if has_arg(self.function, 'mask'):\n             arguments['mask'] = mask\n+        if isinstance(inputs, list):\n+            self._input_dtypes = [K.dtype(x) for x in inputs]\n+        else:\n+            self._input_dtypes = K.dtype(inputs)\n         return self.function(inputs, **arguments)\n \n     def compute_mask(self, inputs, mask=None):\n\n@@ -242,6 +242,18 @@ def test_lambda():\n \n     test_multiple_outputs_no_mask()\n \n+    def test_dtypes():\n+        def func(x):\n+            if K.dtype(x) != 'float16':\n+                raise TypeError('x dtype is not float16, it is', K.dtype(x))\n+            return x\n+\n+        i = layers.Input(shape=(3, 2, 1), dtype='float16')\n+        o = layers.Lambda(func)\n+        _ = o(i)\n+        assert o._input_dtypes == 'float16'\n+    test_dtypes()\n+\n     # test serialization with function\n     def f(x):\n         return x + 1\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55e7875354416c04719eb60c7db2bac78f271df4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 10 | Churn Cumulative: 2327 | Contributors (this commit): 32 | Commits (past 90d): 7 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -369,15 +369,7 @@ def generate():\n         shutil.rmtree('sources')\n \n     print('Populating sources directory with templates.')\n-    for subdir, dirs, fnames in os.walk('templates'):\n-        for fname in fnames:\n-            new_subdir = subdir.replace('templates', 'sources')\n-            if not os.path.exists(new_subdir):\n-                os.makedirs(new_subdir)\n-            if fname[-3:] == '.md':\n-                fpath = os.path.join(subdir, fname)\n-                new_fpath = fpath.replace('templates', 'sources')\n-                shutil.copy(fpath, new_fpath)\n+    shutil.copytree('templates', 'sources')\n \n     readme = read_file('../README.md')\n     index = read_file('templates/index.md')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68dc181a5e34d1f20edabe531176b3bfb50001f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 8651 | Contributors (this commit): 95 | Commits (past 90d): 4 | Contributors (cumulative): 95 | DMM Complexity: None\n\nDIFF:\n@@ -1347,8 +1347,7 @@ class Model(Network):\n                 Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n-                be equal to the number of samples of your dataset\n-                divided by the batch size.\n+                be equal to `ceil(num_samples / batch_size)`\n                 Optional for `Sequence`: if unspecified, will use\n                 the `len(generator)` as a number of steps.\n             epochs: Integer. Number of epochs to train the model.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4aba316b7973e246af94ab5ace18fd5d5ffe4f81", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 128 | Files Changed: 3 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/1 | Churn Δ: 258 | Churn Cumulative: 1106 | Contributors (this commit): 25 | Commits (past 90d): 9 | Contributors (cumulative): 27 | DMM Complexity: None\n\nDIFF:\n@@ -1,124 +1 @@\n-from __future__ import absolute_import\n-from __future__ import print_function\n-import os\n-import json\n-import sys\n-import importlib\n-from .common import epsilon\n-from .common import floatx\n-from .common import set_epsilon\n-from .common import set_floatx\n-from .common import cast_to_floatx\n-from .common import image_data_format\n-from .common import set_image_data_format\n-from .common import normalize_data_format\n-\n-# Set Keras base dir path given KERAS_HOME env variable, if applicable.\n-# Otherwise either ~/.keras or /tmp.\n-if 'KERAS_HOME' in os.environ:\n-    _keras_dir = os.environ.get('KERAS_HOME')\n-else:\n-    _keras_base_dir = os.path.expanduser('~')\n-    if not os.access(_keras_base_dir, os.W_OK):\n-        _keras_base_dir = '/tmp'\n-    _keras_dir = os.path.join(_keras_base_dir, '.keras')\n-\n-# Default backend: TensorFlow.\n-_BACKEND = 'tensorflow'\n-\n-# Attempt to read Keras config file.\n-_config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n-if os.path.exists(_config_path):\n-    try:\n-        with open(_config_path) as f:\n-            _config = json.load(f)\n-    except ValueError:\n-        _config = {}\n-    _floatx = _config.get('floatx', floatx())\n-    assert _floatx in {'float16', 'float32', 'float64'}\n-    _epsilon = _config.get('epsilon', epsilon())\n-    assert isinstance(_epsilon, float)\n-    _backend = _config.get('backend', _BACKEND)\n-    _image_data_format = _config.get('image_data_format',\n-                                     image_data_format())\n-    assert _image_data_format in {'channels_last', 'channels_first'}\n-\n-    set_floatx(_floatx)\n-    set_epsilon(_epsilon)\n-    set_image_data_format(_image_data_format)\n-    _BACKEND = _backend\n-\n-# Save config file, if possible.\n-if not os.path.exists(_keras_dir):\n-    try:\n-        os.makedirs(_keras_dir)\n-    except OSError:\n-        # Except permission denied and potential race conditions\n-        # in multi-threaded environments.\n-        pass\n-\n-if not os.path.exists(_config_path):\n-    _config = {\n-        'floatx': floatx(),\n-        'epsilon': epsilon(),\n-        'backend': _BACKEND,\n-        'image_data_format': image_data_format()\n-    }\n-    try:\n-        with open(_config_path, 'w') as f:\n-            f.write(json.dumps(_config, indent=4))\n-    except IOError:\n-        # Except permission denied.\n-        pass\n-\n-# Set backend based on KERAS_BACKEND flag, if applicable.\n-if 'KERAS_BACKEND' in os.environ:\n-    _backend = os.environ['KERAS_BACKEND']\n-    if _backend:\n-        _BACKEND = _backend\n-\n-# Import backend functions.\n-if _BACKEND == 'cntk':\n-    sys.stderr.write('Using CNTK backend\\n')\n-    from .cntk_backend import *\n-elif _BACKEND == 'theano':\n-    sys.stderr.write('Using Theano backend.\\n')\n-    from .theano_backend import *\n-elif _BACKEND == 'tensorflow':\n-    sys.stderr.write('Using TensorFlow backend.\\n')\n-    from .tensorflow_backend import *\n-else:\n-    # Try and load external backend.\n-    try:\n-        backend_module = importlib.import_module(_BACKEND)\n-        entries = backend_module.__dict__\n-        # Check if valid backend.\n-        # Module is a valid backend if it has the required entries.\n-        required_entries = ['placeholder', 'variable', 'function']\n-        for e in required_entries:\n-            if e not in entries:\n-                raise ValueError('Invalid backend. Missing required entry : ' + e)\n-        namespace = globals()\n-        for k, v in entries.items():\n-            # Make sure we don't override any entries from common, such as epsilon.\n-            if k not in namespace:\n-                namespace[k] = v\n-        sys.stderr.write('Using ' + _BACKEND + ' backend.\\n')\n-    except ImportError:\n-        raise ValueError('Unable to import backend : ' + str(_BACKEND))\n-\n-\n-def backend():\n-    \"\"\"Publicly accessible method\n-    for determining the current backend.\n-\n-    # Returns\n-        String, the name of the backend Keras is currently using.\n-\n-    # Example\n-    ```python\n-        >>> keras.backend.backend()\n-        'tensorflow'\n-    ```\n-    \"\"\"\n-    return _BACKEND\n+from .load_backend import *\n\n@@ -0,0 +1,124 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+import os\n+import json\n+import sys\n+import importlib\n+from .common import epsilon\n+from .common import floatx\n+from .common import set_epsilon\n+from .common import set_floatx\n+from .common import cast_to_floatx\n+from .common import image_data_format\n+from .common import set_image_data_format\n+from .common import normalize_data_format\n+\n+# Set Keras base dir path given KERAS_HOME env variable, if applicable.\n+# Otherwise either ~/.keras or /tmp.\n+if 'KERAS_HOME' in os.environ:\n+    _keras_dir = os.environ.get('KERAS_HOME')\n+else:\n+    _keras_base_dir = os.path.expanduser('~')\n+    if not os.access(_keras_base_dir, os.W_OK):\n+        _keras_base_dir = '/tmp'\n+    _keras_dir = os.path.join(_keras_base_dir, '.keras')\n+\n+# Default backend: TensorFlow.\n+_BACKEND = 'tensorflow'\n+\n+# Attempt to read Keras config file.\n+_config_path = os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))\n+if os.path.exists(_config_path):\n+    try:\n+        with open(_config_path) as f:\n+            _config = json.load(f)\n+    except ValueError:\n+        _config = {}\n+    _floatx = _config.get('floatx', floatx())\n+    assert _floatx in {'float16', 'float32', 'float64'}\n+    _epsilon = _config.get('epsilon', epsilon())\n+    assert isinstance(_epsilon, float)\n+    _backend = _config.get('backend', _BACKEND)\n+    _image_data_format = _config.get('image_data_format',\n+                                     image_data_format())\n+    assert _image_data_format in {'channels_last', 'channels_first'}\n+\n+    set_floatx(_floatx)\n+    set_epsilon(_epsilon)\n+    set_image_data_format(_image_data_format)\n+    _BACKEND = _backend\n+\n+# Save config file, if possible.\n+if not os.path.exists(_keras_dir):\n+    try:\n+        os.makedirs(_keras_dir)\n+    except OSError:\n+        # Except permission denied and potential race conditions\n+        # in multi-threaded environments.\n+        pass\n+\n+if not os.path.exists(_config_path):\n+    _config = {\n+        'floatx': floatx(),\n+        'epsilon': epsilon(),\n+        'backend': _BACKEND,\n+        'image_data_format': image_data_format()\n+    }\n+    try:\n+        with open(_config_path, 'w') as f:\n+            f.write(json.dumps(_config, indent=4))\n+    except IOError:\n+        # Except permission denied.\n+        pass\n+\n+# Set backend based on KERAS_BACKEND flag, if applicable.\n+if 'KERAS_BACKEND' in os.environ:\n+    _backend = os.environ['KERAS_BACKEND']\n+    if _backend:\n+        _BACKEND = _backend\n+\n+# Import backend functions.\n+if _BACKEND == 'cntk':\n+    sys.stderr.write('Using CNTK backend\\n')\n+    from .cntk_backend import *\n+elif _BACKEND == 'theano':\n+    sys.stderr.write('Using Theano backend.\\n')\n+    from .theano_backend import *\n+elif _BACKEND == 'tensorflow':\n+    sys.stderr.write('Using TensorFlow backend.\\n')\n+    from .tensorflow_backend import *\n+else:\n+    # Try and load external backend.\n+    try:\n+        backend_module = importlib.import_module(_BACKEND)\n+        entries = backend_module.__dict__\n+        # Check if valid backend.\n+        # Module is a valid backend if it has the required entries.\n+        required_entries = ['placeholder', 'variable', 'function']\n+        for e in required_entries:\n+            if e not in entries:\n+                raise ValueError('Invalid backend. Missing required entry : ' + e)\n+        namespace = globals()\n+        for k, v in entries.items():\n+            # Make sure we don't override any entries from common, such as epsilon.\n+            if k not in namespace:\n+                namespace[k] = v\n+        sys.stderr.write('Using ' + _BACKEND + ' backend.\\n')\n+    except ImportError:\n+        raise ValueError('Unable to import backend : ' + str(_BACKEND))\n+\n+\n+def backend():\n+    \"\"\"Publicly accessible method\n+    for determining the current backend.\n+\n+    # Returns\n+        String, the name of the backend Keras is currently using.\n+\n+    # Example\n+    ```python\n+        >>> keras.backend.backend()\n+        'tensorflow'\n+    ```\n+    \"\"\"\n+    return _BACKEND\n\n@@ -25,6 +25,7 @@ from keras.utils.data_utils import _hash_file\n from keras.utils.data_utils import get_file\n from keras.utils.data_utils import validate_file\n from keras import backend as K\n+from keras.backend import load_backend\n \n pytestmark = pytest.mark.skipif(\n     six.PY2 and 'TRAVIS_PYTHON_VERSION' in os.environ,\n@@ -88,21 +89,21 @@ def test_data_utils(in_tmpdir):\n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n     data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n-    assert data_keras_home == os.path.dirname(K._config_path)\n+    assert data_keras_home == os.path.dirname(load_backend._config_path)\n     os.remove(filepath)\n \n     _keras_home = os.path.join(os.path.abspath('.'), '.keras')\n     if not os.path.exists(_keras_home):\n         os.makedirs(_keras_home)\n     os.environ['KERAS_HOME'] = _keras_home\n-    reload_module(K)\n+    reload_module(load_backend)\n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n     data_keras_home = os.path.dirname(os.path.dirname(os.path.abspath(filepath)))\n-    assert data_keras_home == os.path.dirname(K._config_path)\n+    assert data_keras_home == os.path.dirname(load_backend._config_path)\n     os.environ.pop('KERAS_HOME')\n     shutil.rmtree(_keras_home)\n-    reload_module(K)\n+    reload_module(load_backend)\n \n     path = get_file(dirname, origin, untar=True)\n     filepath = path + '.tar.gz'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d25cdca6348af2627b5026ef29eff8754273bc3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 10837 | Contributors (this commit): 127 | Commits (past 90d): 18 | Contributors (cumulative): 127 | DMM Complexity: 1.0\n\nDIFF:\n@@ -95,7 +95,9 @@ def clear_session():\n     tf.reset_default_graph()\n     reset_uids()\n     _SESSION = None\n-    phase = tf.placeholder_with_default(False,\n+    with tf.name_scope(''):\n+        phase = tf.placeholder_with_default(\n+            False,\n             shape=(),\n             name='keras_learning_phase')\n     _GRAPH_LEARNING_PHASES = {}\n@@ -130,7 +132,9 @@ def learning_phase():\n     \"\"\"\n     graph = tf.get_default_graph()\n     if graph not in _GRAPH_LEARNING_PHASES:\n-        phase = tf.placeholder_with_default(False,\n+        with tf.name_scope(''):\n+            phase = tf.placeholder_with_default(\n+                False,\n                 shape=(),\n                 name='keras_learning_phase')\n         _GRAPH_LEARNING_PHASES[graph] = phase\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3dbc940b9eb690e92fa6d7fe7ebf897a552a1c50", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 15 | Churn Cumulative: 10852 | Contributors (this commit): 127 | Commits (past 90d): 19 | Contributors (cumulative): 127 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -3069,8 +3069,7 @@ def rnn(step_function, inputs, initial_states,\n     if constants is None:\n         constants = []\n \n-    global uses_learning_phase\n-    uses_learning_phase = False\n+    uses_learning_phase = [False]\n \n     if unroll:\n         if not inputs.shape[0]:\n@@ -3092,7 +3091,7 @@ def rnn(step_function, inputs, initial_states,\n             for inp, mask_t in zip(input_list, mask_list):\n                 output, new_states = step_function(inp, states + constants)\n                 if getattr(output, '_uses_learning_phase', False):\n-                    uses_learning_phase = True\n+                    uses_learning_phase[0] = True\n \n                 if not successive_outputs:\n                     prev_output = zeros_like(output)\n@@ -3118,7 +3117,7 @@ def rnn(step_function, inputs, initial_states,\n             for inp in input_list:\n                 output, states = step_function(inp, states + constants)\n                 if getattr(output, '_uses_learning_phase', False):\n-                    uses_learning_phase = True\n+                    uses_learning_phase[0] = True\n                 successive_outputs.append(output)\n                 successive_states.append(states)\n             last_output = successive_outputs[-1]\n@@ -3178,8 +3177,7 @@ def rnn(step_function, inputs, initial_states,\n                                                    tuple(states) +\n                                                    tuple(constants))\n                 if getattr(output, '_uses_learning_phase', False):\n-                    global uses_learning_phase\n-                    uses_learning_phase = True\n+                    uses_learning_phase[0] = True\n                 for state, new_state in zip(states, new_states):\n                     new_state.set_shape(state.shape)\n \n@@ -3215,8 +3213,7 @@ def rnn(step_function, inputs, initial_states,\n                                                    tuple(states) +\n                                                    tuple(constants))\n                 if getattr(output, '_uses_learning_phase', False):\n-                    global uses_learning_phase\n-                    uses_learning_phase = True\n+                    uses_learning_phase[0] = True\n                 for state, new_state in zip(states, new_states):\n                     new_state.set_shape(state.shape)\n                 output_ta_t = output_ta_t.write(time, output)\n@@ -3235,7 +3232,7 @@ def rnn(step_function, inputs, initial_states,\n \n     axes = [1, 0] + list(range(2, len(outputs.shape)))\n     outputs = tf.transpose(outputs, axes)\n-    last_output._uses_learning_phase = uses_learning_phase\n+    last_output._uses_learning_phase = uses_learning_phase[0]\n     return last_output, outputs, new_states\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f42d9e0179f11871179bc9ee4e8c138cd016612b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 232 | Lines Deleted: 12 | Files Changed: 6 | Hunks: 14 | Methods Changed: 14 | Complexity Δ (Sum/Max): 14/12 | Churn Δ: 244 | Churn Cumulative: 19449 | Contributors (this commit): 127 | Commits (past 90d): 34 | Contributors (cumulative): 193 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1 +1,159 @@\n-from .load_backend import *\n+from .load_backend import epsilon\r\n+from .load_backend import set_epsilon\r\n+from .load_backend import floatx\r\n+from .load_backend import set_floatx\r\n+from .load_backend import cast_to_floatx\r\n+from .load_backend import image_data_format\r\n+from .load_backend import set_image_data_format\r\n+from .load_backend import reset_uids\r\n+from .load_backend import get_uid\r\n+from .load_backend import learning_phase\r\n+from .load_backend import set_learning_phase\r\n+from .load_backend import is_sparse\r\n+from .load_backend import to_dense\r\n+from .load_backend import variable\r\n+from .load_backend import constant\r\n+from .load_backend import is_keras_tensor\r\n+from .load_backend import is_tensor\r\n+from .load_backend import placeholder\r\n+from .load_backend import is_placeholder\r\n+from .load_backend import shape\r\n+from .load_backend import int_shape\r\n+from .load_backend import ndim\r\n+from .load_backend import dtype\r\n+from .load_backend import eval\r\n+from .load_backend import zeros\r\n+from .load_backend import ones\r\n+from .load_backend import eye\r\n+from .load_backend import zeros_like\r\n+from .load_backend import ones_like\r\n+from .load_backend import identity\r\n+from .load_backend import random_uniform_variable\r\n+from .load_backend import random_normal_variable\r\n+from .load_backend import count_params\r\n+from .load_backend import cast\r\n+from .load_backend import update\r\n+from .load_backend import update_add\r\n+from .load_backend import update_sub\r\n+from .load_backend import moving_average_update\r\n+from .load_backend import dot\r\n+from .load_backend import batch_dot\r\n+from .load_backend import transpose\r\n+from .load_backend import gather\r\n+from .load_backend import max\r\n+from .load_backend import min\r\n+from .load_backend import sum\r\n+from .load_backend import prod\r\n+from .load_backend import cumsum\r\n+from .load_backend import cumprod\r\n+from .load_backend import var\r\n+from .load_backend import std\r\n+from .load_backend import mean\r\n+from .load_backend import any\r\n+from .load_backend import all\r\n+from .load_backend import argmax\r\n+from .load_backend import argmin\r\n+from .load_backend import square\r\n+from .load_backend import abs\r\n+from .load_backend import sqrt\r\n+from .load_backend import exp\r\n+from .load_backend import log\r\n+from .load_backend import logsumexp\r\n+from .load_backend import round\r\n+from .load_backend import sign\r\n+from .load_backend import pow\r\n+from .load_backend import clip\r\n+from .load_backend import equal\r\n+from .load_backend import not_equal\r\n+from .load_backend import greater\r\n+from .load_backend import greater_equal\r\n+from .load_backend import less\r\n+from .load_backend import less_equal\r\n+from .load_backend import maximum\r\n+from .load_backend import minimum\r\n+from .load_backend import sin\r\n+from .load_backend import cos\r\n+from .load_backend import normalize_batch_in_training\r\n+from .load_backend import batch_normalization\r\n+from .load_backend import concatenate\r\n+from .load_backend import reshape\r\n+from .load_backend import permute_dimensions\r\n+from .load_backend import resize_images\r\n+from .load_backend import resize_volumes\r\n+from .load_backend import repeat_elements\r\n+from .load_backend import repeat\r\n+from .load_backend import arange\r\n+from .load_backend import tile\r\n+from .load_backend import flatten\r\n+from .load_backend import batch_flatten\r\n+from .load_backend import expand_dims\r\n+from .load_backend import squeeze\r\n+from .load_backend import temporal_padding\r\n+from .load_backend import spatial_2d_padding\r\n+from .load_backend import spatial_3d_padding\r\n+from .load_backend import stack\r\n+from .load_backend import one_hot\r\n+from .load_backend import reverse\r\n+from .load_backend import slice\r\n+from .load_backend import get_value\r\n+from .load_backend import batch_get_value\r\n+from .load_backend import set_value\r\n+from .load_backend import batch_set_value\r\n+from .load_backend import print_tensor\r\n+from .load_backend import function\r\n+from .load_backend import gradients\r\n+from .load_backend import stop_gradient\r\n+from .load_backend import rnn\r\n+from .load_backend import switch\r\n+from .load_backend import in_train_phase\r\n+from .load_backend import in_test_phase\r\n+from .load_backend import relu\r\n+from .load_backend import elu\r\n+from .load_backend import softmax\r\n+from .load_backend import softplus\r\n+from .load_backend import softsign\r\n+from .load_backend import categorical_crossentropy\r\n+from .load_backend import sparse_categorical_crossentropy\r\n+from .load_backend import binary_crossentropy\r\n+from .load_backend import sigmoid\r\n+from .load_backend import hard_sigmoid\r\n+from .load_backend import tanh\r\n+from .load_backend import dropout\r\n+from .load_backend import l2_normalize\r\n+from .load_backend import in_top_k\r\n+from .load_backend import conv1d\r\n+from .load_backend import separable_conv1d\r\n+from .load_backend import conv2d\r\n+from .load_backend import separable_conv2d\r\n+from .load_backend import conv2d_transpose\r\n+from .load_backend import depthwise_conv2d\r\n+from .load_backend import conv3d\r\n+from .load_backend import conv3d_transpose\r\n+from .load_backend import pool2d\r\n+from .load_backend import pool3d\r\n+from .load_backend import bias_add\r\n+from .load_backend import random_normal\r\n+from .load_backend import random_uniform\r\n+from .load_backend import random_binomial\r\n+from .load_backend import truncated_normal\r\n+from .load_backend import ctc_label_dense_to_sparse\r\n+from .load_backend import ctc_batch_cost\r\n+from .load_backend import ctc_decode\r\n+from .load_backend import map_fn\r\n+from .load_backend import foldl\r\n+from .load_backend import foldr\r\n+from .load_backend import local_conv1d\r\n+from .load_backend import local_conv2d\r\n+from .load_backend import backend\r\n+from .load_backend import normalize_data_format\r\n+from .load_backend import name_scope\r\n+\r\n+if backend() == 'theano':\r\n+    from .load_backend import pattern_broadcast\r\n+elif backend() == 'tensorflow':\r\n+    from .load_backend import clear_session\r\n+    from .load_backend import manual_variable_initialization\r\n+    from .load_backend import get_session\r\n+    from .load_backend import set_session\r\n+elif backend() == 'cntk':\r\n+    from .load_backend import clear_session\r\n\n@@ -2727,3 +2727,51 @@ class LambdaFunc(C.ops.functions.UserFunction):\n \n     def backward(self, state, root_gradients):\n         return root_gradients\n+\n+\n+def reset_uids():\n+    raise NotImplementedError\n+\n+\n+def to_dense(tensor):\n+    raise NotImplementedError\n+\n+\n+def update_sub(x, decrement):\n+    raise NotImplementedError\n+\n+\n+def cumsum(x, axis=0):\n+    raise NotImplementedError\n+\n+\n+def cumprod(x, axis=0):\n+    raise NotImplementedError\n+\n+\n+def arange(start, stop=None, step=1, dtype='int32'):\n+    raise NotImplementedError\n+\n+\n+def ctc_label_dense_to_sparse(labels, label_lengths):\n+    raise NotImplementedError\n+\n+\n+def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n+    raise NotImplementedError\n+\n+\n+def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n+    raise NotImplementedError\n+\n+\n+def map_fn(fn, elems, name=None, dtype=None):\n+    raise NotImplementedError\n+\n+\n+def foldl(fn, elems, initializer=None, name=None):\n+    raise NotImplementedError\n+\n+\n+def foldr(fn, elems, initializer=None, name=None):\n+    raise NotImplementedError\n\n@@ -6,7 +6,7 @@ from __future__ import print_function\n import numpy as np\n import scipy.signal as signal\n import scipy as sp\n-from keras.backend import floatx\n+from .common import floatx\n from keras.utils.generic_utils import transpose_shape\n from keras.utils import to_categorical\n \n\n@@ -2938,3 +2938,11 @@ def local_conv2d(inputs,\n                          (output_row, output_col, -1, filters))\n         output = permute_dimensions(output, (2, 0, 1, 3))\n     return output\n+\n+\n+def ctc_label_dense_to_sparse(labels, label_lengths):\n+    raise NotImplementedError\n+\n+\n+def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n+    raise NotImplementedError\n\n@@ -35,6 +35,13 @@ elif K.backend() == 'cntk':\n else:\n     WITH_NP = [KTF, KNP]\n \n+if K.backend() == 'cntk':\n+    supports_sparse = False\n+elif K.backend() == 'theano' and not KTH.th_sparse_module:\n+    supports_sparse = False\n+else:\n+    supports_sparse = True\n+\n \n def check_dtype(var, dtype):\n     if K.backend() == 'theano':\n@@ -1184,7 +1191,7 @@ class TestBackend(object):\n             output_shape=output_shape, padding=padding, data_format=data_format,\n             cntk_dynamicity=True)\n \n-    @pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+    @pytest.mark.skipif((K.backend() == 'cntk' and KC.dev.type() == 0),\n                         reason='cntk only supports dilated conv on GPU')\n     @pytest.mark.parametrize(\n         'op,input_shape,kernel_shape,padding,data_format,dilation_rate', [\n@@ -1211,7 +1218,7 @@ class TestBackend(object):\n             padding=padding, data_format=data_format,\n             dilation_rate=dilation_rate, cntk_dynamicity=True)\n \n-    @pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+    @pytest.mark.skipif((K.backend() == 'cntk' and KC.dev.type() == 0),\n                         reason='cntk only supports dilated conv transpose on GPU')\n     @pytest.mark.parametrize(\n         'op,input_shape,kernel_shape,output_shape,padding,data_format,dilation_rate',\n@@ -1822,8 +1829,7 @@ class TestBackend(object):\n         koh = K.eval(K.one_hot(K.variable(indices, dtype='int32'), num_classes))\n         assert np.all(koh == oh)\n \n-    @pytest.mark.skipif((K.backend() == 'cntk'\n-                         or (K.backend() == 'theano' and not K.th_sparse_module)),\n+    @pytest.mark.skipif(not supports_sparse,\n                         reason='Sparse tensors are not supported in cntk '\n                                'and Theano has some dependency issues for sparse.')\n     def test_sparse_dot(self):\n@@ -1842,8 +1848,7 @@ class TestBackend(object):\n         assert k_s.shape == k_d.shape\n         assert_allclose(k_s, k_d, atol=1e-05)\n \n-    @pytest.mark.skipif((K.backend() == 'cntk'\n-                         or (K.backend() == 'theano' and not K.th_sparse_module)),\n+    @pytest.mark.skipif(not supports_sparse,\n                         reason='Sparse tensors are not supported in cntk '\n                                'and Theano has some dependency issues for sparse.')\n     def test_sparse_concat(self):\n\n@@ -6,6 +6,7 @@ from keras.utils.test_utils import layer_test\n from keras import backend as K\n from keras.layers import convolutional\n from keras.models import Sequential\n+from keras.backend import load_backend\n \n \n # TensorFlow does not support full convolution.\n@@ -15,7 +16,7 @@ else:\n     _convolution_paddings = ['valid', 'same']\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n                     reason='cntk only support dilated conv on GPU')\n @pytest.mark.parametrize(\n     'layer_kwargs,input_length,expected_output',\n@@ -75,7 +76,7 @@ def test_conv_1d(padding, strides):\n                input_shape=(batch_size, steps, input_dim))\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n                     reason='cntk only support dilated conv on GPU')\n def test_conv_1d_dilation():\n     batch_size = 2\n@@ -155,7 +156,7 @@ def test_convolution_2d_channels_last():\n                input_shape=(num_samples, num_row, num_col, stack_size))\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n                     reason='cntk only supports dilated conv on GPU')\n def test_convolution_2d_dilation():\n     num_samples = 2\n@@ -212,7 +213,7 @@ def test_conv2d_transpose(padding, out_padding, strides):\n                fixed_batch_size=True)\n \n \n-@pytest.mark.skipif((K.backend() == 'cntk' and K.dev.type() == 0),\n+@pytest.mark.skipif((K.backend() == 'cntk' and load_backend.dev.type() == 0),\n                     reason='cntk only supports dilated conv transpose on GPU')\n def test_conv2d_transpose_dilation():\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#931540d4970f1ccfd4abac70dd61d9e49067b00f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 15 | Files Changed: 1 | Hunks: 12 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 39 | Churn Cumulative: 2366 | Contributors (this commit): 32 | Commits (past 90d): 8 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -7,13 +7,17 @@ import inspect\n import os\n import shutil\n \n+try:\n+    import pathlib\n+except ImportError:\n+    import pathlib2 as pathlib\n+\n import keras\n from keras import backend as K\n from keras.backend import numpy_backend\n \n from docs.structure import EXCLUDE\n from docs.structure import PAGES\n-from docs.structure import ROOT\n from docs.structure import template_np_implementation\n from docs.structure import template_hidden_np_implementation\n \n@@ -117,13 +121,15 @@ def count_leading_spaces(s):\n def process_list_block(docstring, starting_point, section_end,\n                        leading_spaces, marker):\n     ending_point = docstring.find('\\n\\n', starting_point)\n-    block = docstring[starting_point:(ending_point - 1 if ending_point > -1 else\n-                                      section_end)]\n+    block = docstring[starting_point:\n+                      (ending_point - 1 if ending_point > -1\n+                       else section_end)]\n     # Place marker for later reinjection.\n-    docstring_slice = docstring[starting_point:section_end].replace(block, marker)\n-    docstring = (docstring[:starting_point]\n-                 + docstring_slice\n-                 + docstring[section_end:])\n+    docstring_slice = docstring[\n+        starting_point:section_end].replace(block, marker)\n+    docstring = (docstring[:starting_point] +\n+                 docstring_slice +\n+                 docstring[section_end:])\n     lines = block.split('\\n')\n     # Remove the computed number of leading white spaces from each line.\n     lines = [re.sub('^' + ' ' * leading_spaces, '', line) for line in lines]\n@@ -131,7 +137,8 @@ def process_list_block(docstring, starting_point, section_end,\n     # These have to be removed, but first the list roots have to be detected.\n     top_level_regex = r'^    ([^\\s\\\\\\(]+):(.*)'\n     top_level_replacement = r'- __\\1__:\\2'\n-    lines = [re.sub(top_level_regex, top_level_replacement, line) for line in lines]\n+    lines = [re.sub(top_level_regex, top_level_replacement, line)\n+             for line in lines]\n     # All the other lines get simply the 4 leading space (if present) removed\n     lines = [re.sub(r'^    ', '', line) for line in lines]\n     # Fix text lines after lists\n@@ -329,9 +336,9 @@ def get_module_docstring(filepath):\n def copy_examples():\n     \"\"\"Copy the examples directory in the documentation.\n \n-    Will make the files pretty by extracting the docstrings written in markdown.\n+    Prettify files by extracting the docstrings written in Markdown.\n     \"\"\"\n-    os.makedirs('sources/examples', exist_ok=True)\n+    pathlib.Path('sources/examples').mkdir(exist_ok=True)\n     for file in os.listdir('../examples'):\n         if not file.endswith('.py'):\n             continue\n@@ -360,7 +367,7 @@ def copy_examples():\n \n def generate():\n     if K.backend() != 'tensorflow':\n-        raise ModuleNotFoundError('The documentation must be built '\n+        raise RuntimeError('The documentation must be built '\n                            'with the TensorFlow backend because this '\n                            'is the only backend with docstrings.')\n \n@@ -403,7 +410,8 @@ def generate():\n                 subblocks.append('\\n---')\n                 subblocks.append('## ' + cls.__name__ + ' methods\\n')\n                 subblocks.append('\\n---\\n'.join(\n-                    [render_function(method, method=True) for method in methods]))\n+                    [render_function(method, method=True)\n+                     for method in methods]))\n             blocks.append('\\n'.join(subblocks))\n \n         methods = read_page_data(page_data, 'methods')\n@@ -421,14 +429,15 @@ def generate():\n                                page_data['page'])\n \n         mkdown = '\\n----\\n\\n'.join(blocks)\n-        # save module page.\n+        # Save module page.\n         # Either insert content into existing page,\n-        # or create page otherwise\n+        # or create page otherwise.\n         page_name = page_data['page']\n         path = os.path.join('sources', page_name)\n         if os.path.exists(path):\n             template = read_file(path)\n-            assert '{{autogenerated}}' in template, ('Template found for ' + path +\n+            if '{{autogenerated}}' not in template:\n+                raise RuntimeError('Template found for ' + path +\n                                    ' but missing {{autogenerated}}'\n                                    ' tag.')\n             mkdown = template.replace('{{autogenerated}}', mkdown)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
