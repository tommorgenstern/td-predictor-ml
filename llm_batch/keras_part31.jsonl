{"custom_id": "keras#cdbbdce9341b34a1f9b3fbceaf9d76ac11a580f8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 15 | Methods Changed: 9 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 46 | Churn Cumulative: 1402 | Contributors (this commit): 12 | Commits (past 90d): 42 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,11 +1,11 @@\n from __future__ import absolute_import\n from __future__ import print_function\n \n-import theano\n-import theano.tensor as T\n import numpy as np\n \n-import time, json, warnings\n+import time\n+import json\n+import warnings\n from collections import deque\n \n from .utils.generic_utils import Progbar\n@@ -262,3 +262,18 @@ class RemoteMonitor(Callback):\n             r = requests.post(self.root + '/publish/epoch/end/', {'data': json.dumps(send)})\n         except:\n             print('Warning: could not reach RemoteMonitor root server at ' + str(self.root))\n+\n+\n+class LrSetter(Callback):\n+    '''LrSetter\n+    epoch_rl is a dict with epoch x learning_rate pairs\n+    everytime you get to an epoch in that dict, change the learning rate to that\n+    value\n+    '''\n+    def __init__(self, epoch_lr):\n+        super(LrSetter, self).__init__()\n+        self.epoch_lr = epoch_lr\n+\n+    def on_epoch_end(self, epoch, logs={}):\n+        if str(epoch) in self.epoch_lr:\n+            self.model.lr.set_value(self.epoch_lr[str(epoch)])\n\n@@ -1,7 +1,6 @@\n from __future__ import absolute_import\n import theano\n import theano.tensor as T\n-import numpy as np\n \n from .utils.theano_utils import shared_zeros, shared_scalar, floatX\n from six.moves import zip\n@@ -49,10 +48,13 @@ class Optimizer(object):\n \n class SGD(Optimizer):\n \n-    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):\n+    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args,\n+                 **kwargs):\n         super(SGD, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n+        self.lr = shared_scalar(lr)\n+        self.momentum = shared_scalar(momentum)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -84,6 +86,8 @@ class RMSprop(Optimizer):\n     def __init__(self, lr=0.001, rho=0.9, epsilon=1e-6, *args, **kwargs):\n         super(RMSprop, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n+        self.lr = shared_scalar(lr)\n+        self.rho = shared_scalar(rho)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -109,6 +113,7 @@ class Adagrad(Optimizer):\n     def __init__(self, lr=0.01, epsilon=1e-6, *args, **kwargs):\n         super(Adagrad, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n+        self.lr = shared_scalar(lr)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -135,6 +140,7 @@ class Adadelta(Optimizer):\n     def __init__(self, lr=1.0, rho=0.95, epsilon=1e-6, *args, **kwargs):\n         super(Adadelta, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n+        self.lr = shared_scalar(lr)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -142,12 +148,14 @@ class Adadelta(Optimizer):\n         delta_accumulators = [shared_zeros(p.get_value().shape) for p in params]\n         self.updates = []\n \n-        for p, g, a, d_a, c in zip(params, grads, accumulators, delta_accumulators, constraints):\n+        for p, g, a, d_a, c in zip(params, grads, accumulators,\n+                                   delta_accumulators, constraints):\n             new_a = self.rho * a + (1 - self.rho) * g ** 2  # update accumulator\n             self.updates.append((a, new_a))\n \n             # use the new accumulator and the *old* delta_accumulator\n-            update = g * T.sqrt(d_a + self.epsilon) / T.sqrt(new_a + self.epsilon)\n+            update = g * T.sqrt(d_a + self.epsilon) / T.sqrt(new_a +\n+                                                             self.epsilon)\n \n             new_p = p - self.lr * update\n             self.updates.append((p, c(new_p)))  # apply constraints\n@@ -170,10 +178,12 @@ class Adam(Optimizer):\n \n         Default parameters follow those provided in the original paper.\n     '''\n-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):\n+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args,\n+                 **kwargs):\n         super(Adam, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n+        self.lr = shared_scalar(lr)\n \n     def get_updates(self, params, constraints, loss):\n         grads = self.get_gradients(loss, params)\n@@ -210,5 +220,8 @@ adadelta = Adadelta\n adam = Adam\n \n from .utils.generic_utils import get_from_module\n+\n+\n def get(identifier, kwargs=None):\n-    return get_from_module(identifier, globals(), 'optimizer', instantiate=True, kwargs=kwargs)\n+    return get_from_module(identifier, globals(), 'optimizer', instantiate=True,\n+                           kwargs=kwargs)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6a5a317848d73b5cb3aafd17718bf84688538a9e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 777 | Contributors (this commit): 6 | Commits (past 90d): 28 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -274,6 +274,6 @@ class LrSetter(Callback):\n         super(LrSetter, self).__init__()\n         self.epoch_lr = epoch_lr\n \n-    def on_epoch_end(self, epoch, logs={}):\n+    def on_epoch_begin(self, epoch, logs={}):\n         if str(epoch) in self.epoch_lr:\n             self.model.lr.set_value(self.epoch_lr[str(epoch)])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f4a2323d5e917a8353a2a1d61606decc3188b028", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 23 | Churn Cumulative: 800 | Contributors (this commit): 6 | Commits (past 90d): 29 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2,12 +2,9 @@ from __future__ import absolute_import\n from __future__ import print_function\n \n import numpy as np\n+import time, json, warnings\n \n-import time\n-import json\n-import warnings\n from collections import deque\n-\n from .utils.generic_utils import Progbar\n \n \n@@ -264,16 +261,14 @@ class RemoteMonitor(Callback):\n             print('Warning: could not reach RemoteMonitor root server at ' + str(self.root))\n \n \n-class LrSetter(Callback):\n-    '''LrSetter\n-    epoch_rl is a dict with epoch x learning_rate pairs\n-    everytime you get to an epoch in that dict, change the learning rate to that\n-    value\n+class LearningRateScheduler(Callback):\n+    '''LearningRateScheduler\n+    func is a function that gets an epoch number as input and returns a new\n+    learning rate as output.\n     '''\n-    def __init__(self, epoch_lr):\n-        super(LrSetter, self).__init__()\n-        self.epoch_lr = epoch_lr\n+    def __init__(self, func):\n+        super(LearningRateScheduler, self).__init__()\n+        self.func = func\n \n     def on_epoch_begin(self, epoch, logs={}):\n-        if str(epoch) in self.epoch_lr:\n-            self.model.lr.set_value(self.epoch_lr[str(epoch)])\n+        model.lr.set_value(self.func(epoch))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#af84a6879d2496f97244474dfe0284b50f2edf28", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 3 | Churn Cumulative: 694 | Contributors (this commit): 10 | Commits (past 90d): 25 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -203,8 +203,7 @@ class MaxPooling1D(Layer):\n         return {\"name\": self.__class__.__name__,\n                 \"stride\": self.stride,\n                 \"pool_length\": self.pool_length,\n-                \"ignore_border\": self.ignore_border,\n-                \"subsample_length\": self.subsample_length}\n+                \"ignore_border\": self.ignore_border}\n \n \n class MaxPooling2D(Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ff197781b3b4ce80a165b313b9e2daa0e126a7c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 515 | Contributors (this commit): 5 | Commits (past 90d): 22 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -136,20 +136,20 @@ class Graph(Layer):\n                     raise Exception('Invalid connection map.')\n \n     def get_input(self, train=False):\n-        if len(self.inputs) != 1 or len(self.outputs) != 1:\n-            raise Exception('The Graph container can only be used as a layer \\\n-                when it has exactly one input and one output.')\n+        if len(self.inputs) == len(self.outputs) == 1:\n             return self.inputs[self.input_order[0]].get_input(train)\n+        else:\n+            return dict([k, v.get_input(train) for k, v in self.inputs.items()])\n \n     @property\n     def input(self):\n         return self.get_input()\n \n     def get_output(self, train=False):\n-        if len(self.inputs) != 1 or len(self.outputs) != 1:\n-            raise Exception('The Graph container can only be used as a layer \\\n-                when it has exactly one input and one output.')\n+        if len(self.inputs) == len(self.outputs) == 1:\n             return self.outputs[self.output_order[0]].get_output(train)\n+        else:\n+            return dict([k, v.get_output(train) for k, v in self.outputs.items()])\n \n     def add_input(self, name, ndim=2, dtype='float'):\n         if name in self.namespace:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9579e1c08d8d661ba41f31d6daf345e22a5e38a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 8 | Methods Changed: 5 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 1444 | Contributors (this commit): 12 | Commits (past 90d): 46 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -263,12 +263,12 @@ class RemoteMonitor(Callback):\n \n class LearningRateScheduler(Callback):\n     '''LearningRateScheduler\n-    func is a function that gets an epoch number as input and returns a new\n+    schedule is a function that gets an epoch number as input and returns a new\n     learning rate as output.\n     '''\n-    def __init__(self, func):\n+    def __init__(self, schedule):\n         super(LearningRateScheduler, self).__init__()\n-        self.func = func\n+        self.schedule = schedule\n \n     def on_epoch_begin(self, epoch, logs={}):\n-        model.lr.set_value(self.func(epoch))\n+        model.lr.set_value(self.schedule(epoch))\n\n@@ -3,6 +3,7 @@ import theano\n import theano.tensor as T\n \n from .utils.theano_utils import shared_zeros, shared_scalar, floatX\n+from .utils.generic_utils import get_from_module\n from six.moves import zip\n \n \n@@ -48,8 +49,7 @@ class Optimizer(object):\n \n class SGD(Optimizer):\n \n-    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args,\n-                 **kwargs):\n+    def __init__(self, lr=0.01, momentum=0., decay=0., nesterov=False, *args, **kwargs):\n         super(SGD, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n@@ -178,8 +178,7 @@ class Adam(Optimizer):\n \n         Default parameters follow those provided in the original paper.\n     '''\n-    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args,\n-                 **kwargs):\n+    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, *args, **kwargs):\n         super(Adam, self).__init__(**kwargs)\n         self.__dict__.update(locals())\n         self.iterations = shared_scalar(0)\n@@ -219,8 +218,6 @@ adagrad = Adagrad\n adadelta = Adadelta\n adam = Adam\n \n-from .utils.generic_utils import get_from_module\n-\n \n def get(identifier, kwargs=None):\n     return get_from_module(identifier, globals(), 'optimizer', instantiate=True,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#93624e10e87a3ab0c2ce1f84a8d73e8bac140c3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 519 | Contributors (this commit): 5 | Commits (past 90d): 23 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -139,7 +139,7 @@ class Graph(Layer):\n         if len(self.inputs) == len(self.outputs) == 1:\n             return self.inputs[self.input_order[0]].get_input(train)\n         else:\n-            return dict([k, v.get_input(train) for k, v in self.inputs.items()])\n+            return dict([(k, v.get_input(train)) for k, v in self.inputs.items()])\n \n     @property\n     def input(self):\n@@ -149,7 +149,7 @@ class Graph(Layer):\n         if len(self.inputs) == len(self.outputs) == 1:\n             return self.outputs[self.output_order[0]].get_output(train)\n         else:\n-            return dict([k, v.get_output(train) for k, v in self.outputs.items()])\n+            return dict([(k, v.get_output(train)) for k, v in self.outputs.items()])\n \n     def add_input(self, name, ndim=2, dtype='float'):\n         if name in self.namespace:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b498218d0b16ed1ca619b77332b6fccac32fc175", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 151 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -49,7 +49,7 @@ class PReLU(MaskedLayer):\n \n class ParametricSoftplus(MaskedLayer):\n     '''\n-        Parametric Softplus of the form: alpha * (1 + exp(beta * X))\n+        Parametric Softplus of the form: alpha * log(1 + exp(beta * X))\n \n         Reference:\n             Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6cd8d3c37a2fcaf861e49bfebad49f43cfaa7ab3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 7 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 26 | Churn Cumulative: 946 | Contributors (this commit): 9 | Commits (past 90d): 20 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -76,9 +76,9 @@ class SGD(Optimizer):\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"lr\": self.lr,\n-                \"momentum\": self.momentum,\n-                \"decay\": self.decay,\n+                \"lr\": float(self.lr.get_value()),\n+                \"momentum\": float(self.momentum.get_value()),\n+                \"decay\": float(self.decay.get_value()),\n                 \"nesterov\": self.nesterov}\n \n \n@@ -104,8 +104,8 @@ class RMSprop(Optimizer):\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"lr\": self.lr,\n-                \"rho\": self.rho,\n+                \"lr\": float(self.lr.get_value()),\n+                \"rho\": float(self.rho.get_value()),\n                 \"epsilon\": self.epsilon}\n \n \n@@ -129,7 +129,7 @@ class Adagrad(Optimizer):\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"lr\": self.lr,\n+                \"lr\": float(self.lr.get_value()),\n                 \"epsilon\": self.epsilon}\n \n \n@@ -167,7 +167,7 @@ class Adadelta(Optimizer):\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"lr\": self.lr,\n+                \"lr\": float(self.lr.get_value()),\n                 \"rho\": self.rho,\n                 \"epsilon\": self.epsilon}\n \n@@ -206,7 +206,7 @@ class Adam(Optimizer):\n \n     def get_config(self):\n         return {\"name\": self.__class__.__name__,\n-                \"lr\": self.lr,\n+                \"lr\": float(self.lr.get_value()),\n                 \"beta_1\": self.beta_1,\n                 \"beta_2\": self.beta_2,\n                 \"epsilon\": self.epsilon}\n\n@@ -4,7 +4,7 @@ import unittest\n import numpy as np\n np.random.seed(1337)\n \n-from keras.models import Sequential\n+from keras.models import Sequential, model_from_json, model_from_yaml\n from keras.layers.core import Dense, Activation, Merge\n from keras.utils import np_utils\n from keras.utils.test_utils import get_test_data\n@@ -68,6 +68,14 @@ class TestSequential(unittest.TestCase):\n         print(nloss)\n         assert(loss == nloss)\n \n+        # test json serialization\n+        json_data = model.to_json()\n+        model = model_from_json(json_data)\n+\n+        # test yaml serialization\n+        yaml_data = model.to_yaml()\n+        model = model_from_yaml(yaml_data)\n+\n     def test_merge_sum(self):\n         print('Test merge: sum')\n         left = Sequential()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#34999c865896642e25d46d6334200775008e1562", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 236 | Contributors (this commit): 6 | Commits (past 90d): 27 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -51,7 +51,7 @@ def binary_crossentropy(y_true, y_pred):\n \n \n def poisson_loss(y_true, y_pred):\n-    return T.mean(y_pred - y_true * T.log(y_pred), axis=-1)\n+    return T.mean(y_pred - y_true * T.log(y_pred + epsilon), axis=-1)\n \n # aliases\n mse = MSE = mean_squared_error\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#25508e0771ba557d22994cab04c195f1df467379", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 41 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 51 | Churn Cumulative: 2737 | Contributors (this commit): 21 | Commits (past 90d): 89 | Contributors (cumulative): 24 | DMM Complexity: 1.0\n\nDIFF:\n@@ -64,18 +64,28 @@ def slice_X(X, start=None, stop=None):\n \n def weighted_objective(fn):\n     def weighted(y_true, y_pred, weights, mask=None):\n-        # it's important that 0 * Inf == 0, not NaN, so I need to mask first\n-        masked_y_true = y_true[weights.nonzero()[:-1]]\n-        masked_y_pred = y_pred[weights.nonzero()[:-1]]\n-        masked_weights = weights[weights.nonzero()]\n-        obj_output = fn(masked_y_true, masked_y_pred)\n+        '''\n+        y_true dimension:  (sample, timestep, dims)\n+        y_pred dimension:  (sample, timestep, dims)\n+        weights dimension: (sample, timestep, 1)\n+        '''\n+        # it's important that 0 * Inf == 0, not NaN, so I need to filter\n+        # those out first\n+        filtered_y_true = y_true[weights.nonzero()[:-1]]\n+        filtered_y_pred = y_pred[weights.nonzero()[:-1]]\n+        filtered_weights = weights[weights.nonzero()]\n+        obj_output = fn(filtered_y_true, filtered_y_pred)\n         if mask is None:\n-            return (masked_weights.flatten() * obj_output.flatten()).mean()\n+            # Instead of calling mean() here, we divide by the sum of filtered_weights.\n+            return (filtered_weights.flatten() * obj_output.flatten()).sum() / filtered_weights.sum()\n         else:\n             # We assume the time index to be masked is axis=1\n-            wc = masked_weights * obj_output\n-            wc = wc.reshape(mask.shape)\n-            wc = wc.sum(axis=1) / mask.sum(axis=1)\n+            filtered_mask = mask[weights.nonzero()[:-1]]\n+            wc = filtered_weights * obj_output\n+            wc = wc.reshape(filtered_mask.shape)\n+            # Divide by mask.sum() here not filtered_mask.sum() since otherwise interactions\n+            # between sample_weight and masks cause issues.\n+            wc = wc.sum() / mask.sum()\n             return wc.mean()\n     return weighted\n \n\n@@ -1,7 +1,9 @@\n import numpy as np\n import unittest\n-from keras.models import Sequential\n+from keras.models import Sequential, weighted_objective\n from keras.layers.core import TimeDistributedDense, Masking\n+from keras import objectives\n+import theano\n \n \n class TestLossMasking(unittest.TestCase):\n@@ -17,6 +19,25 @@ class TestLossMasking(unittest.TestCase):\n         loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]\n         assert loss == 282.375\n \n+    def test_loss_masking_time(self):\n+        theano.config.mode = 'FAST_COMPILE'\n+        weighted_loss = weighted_objective(objectives.get('categorical_crossentropy'))\n+        shape = (3, 4, 2)\n+        X = np.arange(24).reshape(shape)\n+        Y = 2*X\n+\n+        weights = np.ones((3, 4, 1)) # Normally the trailing 1 is added by standardize_weights\n+        weights[0,0] = 0\n+        mask = np.ones((3, 4))\n+        mask[1,0] = 0\n+\n+        out = weighted_loss(X, Y, weights, mask).eval()\n+        weights[0,0] = 1e-9 # so that nonzero() doesn't remove this weight\n+        out2 = weighted_loss(X, Y, weights, mask).eval()\n+        print(out)\n+        print(out2)\n+        assert abs(out-out2) < 1e-8\n+\n \n if __name__ == '__main__':\n     print('Test loss masking')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1ee8efde5620bd71dde7705a2668eff766e656ee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 2670 | Contributors (this commit): 21 | Commits (past 90d): 85 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -82,7 +82,6 @@ def weighted_objective(fn):\n             # We assume the time index to be masked is axis=1\n             filtered_mask = mask[weights.nonzero()[:-1]]\n             wc = filtered_weights * obj_output\n-            wc = wc.reshape(filtered_mask.shape)\n             # Divide by mask.sum() here not filtered_mask.sum() since otherwise interactions\n             # between sample_weight and masks cause issues.\n             wc = wc.sum() / mask.sum()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc6c42e3dffc228231a650fba75586315cadee10", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 2673 | Contributors (this commit): 21 | Commits (past 90d): 86 | Contributors (cumulative): 21 | DMM Complexity: 0.0\n\nDIFF:\n@@ -84,8 +84,7 @@ def weighted_objective(fn):\n             wc = filtered_weights * obj_output\n             # Divide by mask.sum() here not filtered_mask.sum() since otherwise interactions\n             # between sample_weight and masks cause issues.\n-            wc = wc.sum() / mask.sum()\n-            return wc.mean()\n+            return (wc * filtered_mask).sum() / (filtered_mask * filtered_weights).sum()\n     return weighted\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e001ee70cd274fbea1491658a3d35a8dbc264a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 2682 | Contributors (this commit): 21 | Commits (past 90d): 87 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -75,16 +75,13 @@ def weighted_objective(fn):\n         filtered_y_pred = y_pred[weights.nonzero()[:-1]]\n         filtered_weights = weights[weights.nonzero()]\n         obj_output = fn(filtered_y_true, filtered_y_pred)\n+        weighted = filtered_weights * obj_output\n         if mask is None:\n             # Instead of calling mean() here, we divide by the sum of filtered_weights.\n-            return (filtered_weights.flatten() * obj_output.flatten()).sum() / filtered_weights.sum()\n+            return weighted.sum() / filtered_weights.sum()\n         else:\n-            # We assume the time index to be masked is axis=1\n             filtered_mask = mask[weights.nonzero()[:-1]]\n-            wc = filtered_weights * obj_output\n-            # Divide by mask.sum() here not filtered_mask.sum() since otherwise interactions\n-            # between sample_weight and masks cause issues.\n-            return (wc * filtered_mask).sum() / (filtered_mask * filtered_weights).sum()\n+            return weighted.sum() / (filtered_mask * filtered_weights).sum()\n     return weighted\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#21f0bfa239c2250f3459aa3fc011cc3f4c814e03", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 72 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,4 +1,6 @@\n import numpy as np\n+np.random.seed(1337)\n+\n import unittest\n from keras.models import Sequential, weighted_objective\n from keras.layers.core import TimeDistributedDense, Masking\n@@ -17,7 +19,7 @@ class TestLossMasking(unittest.TestCase):\n         model.compile(loss='mse', optimizer='sgd')\n         y = model.predict(X)\n         loss = model.fit(X, 4*y, nb_epoch=1, batch_size=2, verbose=1).history['loss'][0]\n-        assert loss == 282.375\n+        assert loss == 285.\n \n     def test_loss_masking_time(self):\n         theano.config.mode = 'FAST_COMPILE'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5a3d2fe2049366bcca9225d2a6cc555ca5d73826", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 2 | Churn Cumulative: 696 | Contributors (this commit): 10 | Commits (past 90d): 26 | Contributors (cumulative): 10 | DMM Complexity: 0.0\n\nDIFF:\n@@ -178,7 +178,7 @@ class Convolution2D(Layer):\n     def get_output(self, train):\n         X = self.get_input(train)\n         border_mode = self.border_mode\n-        if dnn.dnn_available():\n+        if dnn.dnn_available() and theano.config.device == 'gpu':\n             if border_mode == 'same':\n                 assert(self.subsample == (1, 1))\n                 pad_x = (self.nb_row - self.subsample[0]) // 2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9773e810a527d88b97239e0117be0967a3b4214f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 24 | Files Changed: 2 | Hunks: 18 | Methods Changed: 7 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 71 | Churn Cumulative: 2994 | Contributors (this commit): 21 | Commits (past 90d): 94 | Contributors (cumulative): 23 | DMM Complexity: 0.15789473684210525\n\nDIFF:\n@@ -160,7 +160,7 @@ def get_function_name(o):\n \n class Model(object):\n     def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n-             validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):\n+             val_f=None, val_ins=None, shuffle=True, metrics=[]):\n         '''\n             Abstract fit function for f(*ins). Assume that f returns a list, labelled by out_labels.\n         '''\n@@ -169,13 +169,6 @@ class Model(object):\n             do_validation = True\n             if verbose:\n                 print(\"Train on %d samples, validate on %d samples\" % (len(ins[0]), len(val_ins[0])))\n-        else:\n-            if 0 < validation_split < 1:\n-                do_validation = True\n-                split_at = int(len(ins[0]) * (1 - validation_split))\n-                (ins, val_ins) = (slice_X(ins, 0, split_at), slice_X(ins, split_at))\n-                if verbose:\n-                    print(\"Train on %d samples, validate on %d samples\" % (len(ins[0]), len(val_ins[0])))\n \n         nb_train_sample = len(ins[0])\n         index_array = np.arange(nb_train_sample)\n@@ -451,7 +444,6 @@ class Sequential(Model, containers.Sequential):\n \n         X = standardize_X(X)\n         y = standardize_y(y)\n-        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)\n \n         val_f = None\n         val_ins = None\n@@ -461,14 +453,27 @@ class Sequential(Model, containers.Sequential):\n             else:\n                 val_f = self._test\n         if validation_data:\n-            try:\n+            if len(validation_data) == 2:\n                 X_val, y_val = validation_data\n-            except:\n-                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val). \\\n+                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))\n+            elif len(validation_data) == 3:\n+                X_val, y_val, sample_weight_val = validation_data\n+            else:\n+                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val) or (X_val, y_val, sample_weight). \\\n                     X_val may be a numpy array or a list of numpy arrays depending on your model input.\")\n             X_val = standardize_X(X_val)\n             y_val = standardize_y(y_val)\n-            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]\n+            val_ins = X_val + [y_val, sample_weight_val]\n+\n+        elif 0 < validation_split < 1:\n+            split_at = int(len(X[0]) * (1 - validation_split))\n+            X, X_val = (slice_X(X, 0, split_at), slice_X(X, split_at))\n+            y, y_val = (slice_X(y, 0, split_at), slice_X(y, split_at))\n+            if sample_weight:\n+                sample_weight, sample_weight_val = (slice_X(sample_weight, 0, split_at), slice_X(sample_weight, split_at))\n+            else:\n+                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))\n+            val_ins = X_val + [y_val, sample_weight_val]\n \n         if show_accuracy:\n             f = self._train_with_acc\n@@ -477,11 +482,12 @@ class Sequential(Model, containers.Sequential):\n             f = self._train\n             out_labels = ['loss']\n \n+        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)\n         ins = X + [y, sample_weight]\n         metrics = ['loss', 'acc', 'val_loss', 'val_acc']\n         return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,\n                          verbose=verbose, callbacks=callbacks,\n-                         validation_split=validation_split, val_f=val_f, val_ins=val_ins,\n+                         val_f=val_f, val_ins=val_ins,\n                          shuffle=shuffle, metrics=metrics)\n \n     def predict(self, X, batch_size=128, verbose=0):\n@@ -624,8 +630,8 @@ class Graph(Model, containers.Graph):\n \n     def test_on_batch(self, data, sample_weight={}):\n         # data is a dictionary mapping input names to arrays\n-        sample_weight = [standardize_weights(data[name]) for name in self.output_order]\n-\n+        sample_weight = [standardize_weights(data[name],\n+                                             sample_weight=sample_weight.get(name)) for name in self.output_order]\n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n         return self._test(*ins)\n \n@@ -636,30 +642,46 @@ class Graph(Model, containers.Graph):\n \n     def fit(self, data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True, class_weight={}, sample_weight={}):\n-        sample_weight = [standardize_weights(data[name],\n-                                             sample_weight=sample_weight.get(name),\n-                                             class_weight=class_weight.get(name)) for name in self.output_order]\n-        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n+        X = [data[name] for name in self.input_order]\n+        y = [standardize_y(data[name]) for name in self.output_order]\n+        sample_weight_list = [standardize_weights(data[name],\n+                                                  sample_weight=sample_weight.get(name)) for name in self.output_order]\n+        class_weight_list = [class_weight.get(name) for name in self.output_order]\n \n         val_f = None\n         val_ins = None\n         if validation_data or validation_split:\n             val_f = self._test\n         if validation_data:\n+            # can't use sample weights with validation data at this point\n             sample_weight = [standardize_weights(validation_data[name]) for name in self.output_order]\n             val_ins = [validation_data[name] for name in self.input_order] + [standardize_y(validation_data[name]) for name in self.output_order] + sample_weight\n \n+        elif 0 < validation_split < 1:\n+            split_at = int(len(X[0]) * (1 - validation_split))\n+            X, X_val = (slice_X(X, 0, split_at), slice_X(X, split_at))\n+            y, y_val = (slice_X(y, 0, split_at), slice_X(y, split_at))\n+            sample_weight_list, sample_weight_list_val = (slice_X(sample_weight_list, 0, split_at), slice_X(sample_weight_list, split_at))\n+            val_ins = X_val + y_val + sample_weight_val\n+\n         f = self._train\n         out_labels = ['loss']\n         metrics = ['loss', 'val_loss']\n+\n+        sample_weight_list = [standardize_weights(y[i],\n+                                                  sample_weight=sample_weight_list[i],\n+                                                  class_weight=class_weight_list[i]) for i in range(len(self.output_order))]\n+        ins = X + y + sample_weight_list\n+\n         history = self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,\n                             verbose=verbose, callbacks=callbacks,\n-                            validation_split=validation_split, val_f=val_f, val_ins=val_ins,\n+                            val_f=val_f, val_ins=val_ins,\n                             shuffle=shuffle, metrics=metrics)\n         return history\n \n     def evaluate(self, data, batch_size=128, verbose=0, sample_weight={}):\n-        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]\n+        sample_weight = [standardize_weights(data[name],\n+                                             sample_weight=sample_weight.get(name)) for name in self.output_order]\n \n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n         outs = self._test_loop(self._test, ins, batch_size, verbose)\n\n@@ -144,6 +144,8 @@ class TestGraph(unittest.TestCase):\n \n         weights1 = np.random.uniform(size=y_train.shape[0])\n         weights2 = np.random.uniform(size=y2_train.shape[0])\n+        weights1_test = np.random.uniform(size=y_test.shape[0])\n+        weights2_test = np.random.uniform(size=y2_test.shape[0])\n \n         graph.compile('rmsprop', {'output1': 'mse', 'output2': 'mse'})\n \n@@ -153,12 +155,11 @@ class TestGraph(unittest.TestCase):\n         assert(type(out == dict))\n         assert(len(out) == 2)\n         loss = graph.test_on_batch({'input1': X_test, 'output1': y_test, 'output2': y2_test},\n-                                   sample_weight={'output1': weights1, 'output2': weights2})\n+                                   sample_weight={'output1': weights1_test, 'output2': weights2_test})\n         loss = graph.train_on_batch({'input1': X_train, 'output1': y_train, 'output2': y2_train},\n                                     sample_weight={'output1': weights1, 'output2': weights2})\n         loss = graph.evaluate({'input1': X_train, 'output1': y_train, 'output2': y2_train},\n                               sample_weight={'output1': weights1, 'output2': weights2})\n-        print(loss)\n \n     def test_recursive(self):\n         print('test layer-like API')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3c4f0ac609b5a7b1f55db0f3dd5d25d366416f70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 24 | Lines Deleted: 47 | Files Changed: 2 | Hunks: 18 | Methods Changed: 7 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 71 | Churn Cumulative: 3065 | Contributors (this commit): 21 | Commits (past 90d): 96 | Contributors (cumulative): 23 | DMM Complexity: 0.8421052631578947\n\nDIFF:\n@@ -160,7 +160,7 @@ def get_function_name(o):\n \n class Model(object):\n     def _fit(self, f, ins, out_labels=[], batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n-             val_f=None, val_ins=None, shuffle=True, metrics=[]):\n+             validation_split=0., val_f=None, val_ins=None, shuffle=True, metrics=[]):\n         '''\n             Abstract fit function for f(*ins). Assume that f returns a list, labelled by out_labels.\n         '''\n@@ -169,6 +169,13 @@ class Model(object):\n             do_validation = True\n             if verbose:\n                 print(\"Train on %d samples, validate on %d samples\" % (len(ins[0]), len(val_ins[0])))\n+        else:\n+            if 0 < validation_split < 1:\n+                do_validation = True\n+                split_at = int(len(ins[0]) * (1 - validation_split))\n+                (ins, val_ins) = (slice_X(ins, 0, split_at), slice_X(ins, split_at))\n+                if verbose:\n+                    print(\"Train on %d samples, validate on %d samples\" % (len(ins[0]), len(val_ins[0])))\n \n         nb_train_sample = len(ins[0])\n         index_array = np.arange(nb_train_sample)\n@@ -444,6 +451,7 @@ class Sequential(Model, containers.Sequential):\n \n         X = standardize_X(X)\n         y = standardize_y(y)\n+        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)\n \n         val_f = None\n         val_ins = None\n@@ -453,27 +461,14 @@ class Sequential(Model, containers.Sequential):\n             else:\n                 val_f = self._test\n         if validation_data:\n-            if len(validation_data) == 2:\n+            try:\n                 X_val, y_val = validation_data\n-                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))\n-            elif len(validation_data) == 3:\n-                X_val, y_val, sample_weight_val = validation_data\n-            else:\n-                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val) or (X_val, y_val, sample_weight). \\\n+            except:\n+                raise Exception(\"Invalid format for validation data; provide a tuple (X_val, y_val). \\\n                     X_val may be a numpy array or a list of numpy arrays depending on your model input.\")\n             X_val = standardize_X(X_val)\n             y_val = standardize_y(y_val)\n-            val_ins = X_val + [y_val, sample_weight_val]\n-\n-        elif 0 < validation_split < 1:\n-            split_at = int(len(X[0]) * (1 - validation_split))\n-            X, X_val = (slice_X(X, 0, split_at), slice_X(X, split_at))\n-            y, y_val = (slice_X(y, 0, split_at), slice_X(y, split_at))\n-            if sample_weight:\n-                sample_weight, sample_weight_val = (slice_X(sample_weight, 0, split_at), slice_X(sample_weight, split_at))\n-            else:\n-                sample_weight_val = np.ones(y_val.shape[:-1] + (1,))\n-            val_ins = X_val + [y_val, sample_weight_val]\n+            val_ins = X_val + [y_val, np.ones(y_val.shape[:-1] + (1,))]\n \n         if show_accuracy:\n             f = self._train_with_acc\n@@ -482,12 +477,11 @@ class Sequential(Model, containers.Sequential):\n             f = self._train\n             out_labels = ['loss']\n \n-        sample_weight = standardize_weights(y, class_weight=class_weight, sample_weight=sample_weight)\n         ins = X + [y, sample_weight]\n         metrics = ['loss', 'acc', 'val_loss', 'val_acc']\n         return self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,\n                          verbose=verbose, callbacks=callbacks,\n-                         val_f=val_f, val_ins=val_ins,\n+                         validation_split=validation_split, val_f=val_f, val_ins=val_ins,\n                          shuffle=shuffle, metrics=metrics)\n \n     def predict(self, X, batch_size=128, verbose=0):\n@@ -630,8 +624,8 @@ class Graph(Model, containers.Graph):\n \n     def test_on_batch(self, data, sample_weight={}):\n         # data is a dictionary mapping input names to arrays\n-        sample_weight = [standardize_weights(data[name],\n-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]\n+        sample_weight = [standardize_weights(data[name]) for name in self.output_order]\n+\n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n         return self._test(*ins)\n \n@@ -642,46 +636,30 @@ class Graph(Model, containers.Graph):\n \n     def fit(self, data, batch_size=128, nb_epoch=100, verbose=1, callbacks=[],\n             validation_split=0., validation_data=None, shuffle=True, class_weight={}, sample_weight={}):\n-        X = [data[name] for name in self.input_order]\n-        y = [standardize_y(data[name]) for name in self.output_order]\n-        sample_weight_list = [standardize_weights(data[name],\n-                                                  sample_weight=sample_weight.get(name)) for name in self.output_order]\n-        class_weight_list = [class_weight.get(name) for name in self.output_order]\n+        sample_weight = [standardize_weights(data[name],\n+                                             sample_weight=sample_weight.get(name),\n+                                             class_weight=class_weight.get(name)) for name in self.output_order]\n+        ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n \n         val_f = None\n         val_ins = None\n         if validation_data or validation_split:\n             val_f = self._test\n         if validation_data:\n-            # can't use sample weights with validation data at this point\n             sample_weight = [standardize_weights(validation_data[name]) for name in self.output_order]\n             val_ins = [validation_data[name] for name in self.input_order] + [standardize_y(validation_data[name]) for name in self.output_order] + sample_weight\n \n-        elif 0 < validation_split < 1:\n-            split_at = int(len(X[0]) * (1 - validation_split))\n-            X, X_val = (slice_X(X, 0, split_at), slice_X(X, split_at))\n-            y, y_val = (slice_X(y, 0, split_at), slice_X(y, split_at))\n-            sample_weight_list, sample_weight_list_val = (slice_X(sample_weight_list, 0, split_at), slice_X(sample_weight_list, split_at))\n-            val_ins = X_val + y_val + sample_weight_val\n-\n         f = self._train\n         out_labels = ['loss']\n         metrics = ['loss', 'val_loss']\n-\n-        sample_weight_list = [standardize_weights(y[i],\n-                                                  sample_weight=sample_weight_list[i],\n-                                                  class_weight=class_weight_list[i]) for i in range(len(self.output_order))]\n-        ins = X + y + sample_weight_list\n-\n         history = self._fit(f, ins, out_labels=out_labels, batch_size=batch_size, nb_epoch=nb_epoch,\n                             verbose=verbose, callbacks=callbacks,\n-                            val_f=val_f, val_ins=val_ins,\n+                            validation_split=validation_split, val_f=val_f, val_ins=val_ins,\n                             shuffle=shuffle, metrics=metrics)\n         return history\n \n     def evaluate(self, data, batch_size=128, verbose=0, sample_weight={}):\n-        sample_weight = [standardize_weights(data[name],\n-                                             sample_weight=sample_weight.get(name)) for name in self.output_order]\n+        sample_weight = [standardize_weights(data[name], sample_weight.get(name)) for name in self.output_order]\n \n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n         outs = self._test_loop(self._test, ins, batch_size, verbose)\n\n@@ -144,8 +144,6 @@ class TestGraph(unittest.TestCase):\n \n         weights1 = np.random.uniform(size=y_train.shape[0])\n         weights2 = np.random.uniform(size=y2_train.shape[0])\n-        weights1_test = np.random.uniform(size=y_test.shape[0])\n-        weights2_test = np.random.uniform(size=y2_test.shape[0])\n \n         graph.compile('rmsprop', {'output1': 'mse', 'output2': 'mse'})\n \n@@ -155,11 +153,12 @@ class TestGraph(unittest.TestCase):\n         assert(type(out == dict))\n         assert(len(out) == 2)\n         loss = graph.test_on_batch({'input1': X_test, 'output1': y_test, 'output2': y2_test},\n-                                   sample_weight={'output1': weights1_test, 'output2': weights2_test})\n+                                   sample_weight={'output1': weights1, 'output2': weights2})\n         loss = graph.train_on_batch({'input1': X_train, 'output1': y_train, 'output2': y2_train},\n                                     sample_weight={'output1': weights1, 'output2': weights2})\n         loss = graph.evaluate({'input1': X_train, 'output1': y_train, 'output2': y2_train},\n                               sample_weight={'output1': weights1, 'output2': weights2})\n+        print(loss)\n \n     def test_recursive(self):\n         print('test layer-like API')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
