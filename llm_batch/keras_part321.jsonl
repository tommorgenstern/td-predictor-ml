{"custom_id": "keras#da39848ecdca190445b6786cb16f93fc921f3be8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 47 | Files Changed: 11 | Hunks: 34 | Methods Changed: 15 | Complexity Δ (Sum/Max): 3/4 | Churn Δ: 100 | Churn Cumulative: 13381 | Contributors (this commit): 12 | Commits (past 90d): 60 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -30,9 +30,9 @@ import random\n import numpy as np\n import six\n from tensorflow.python.eager import context\n-from tensorflow.python.framework import smart_cond\n from keras import backend\n from keras.engine import training_utils\n+from keras.utils import control_flow_util\n from keras.utils import data_utils\n from keras.utils import dataset_creator\n from keras.utils import tf_utils\n@@ -1398,7 +1398,7 @@ def _make_class_weight_map_fn(class_weight):\n       raise ValueError(\"`class_weight` not supported for \"\n                        \"3+ dimensional targets.\")\n \n-    y_classes = smart_cond.smart_cond(\n+    y_classes = control_flow_util.smart_cond(\n         y.shape.rank == 2 and backend.shape(y)[1] > 1,\n         lambda: backend.argmax(y, axis=1),\n         lambda: tf.cast(backend.reshape(y, (-1,)), tf.int64))\n\n@@ -30,11 +30,11 @@ import time\n import numpy as np\n import six\n from six.moves import zip  # pylint: disable=redefined-builtin\n-from tensorflow.python.framework import smart_cond\n from keras import backend as K\n from keras import callbacks as cbks\n from keras import losses\n from keras import metrics as metrics_module\n+from keras.utils import control_flow_util\n from keras.utils import data_utils\n from keras.utils import generic_utils\n from keras.utils import losses_utils\n@@ -1009,7 +1009,7 @@ def standardize_weights(y,\n       weight_vector[:] = np.nan\n       weight_vector[keys] = values\n \n-      y_classes = smart_cond.smart_cond(\n+      y_classes = control_flow_util.smart_cond(\n           len(y.shape.as_list()) == 2 and K.shape(y)[1] > 1,\n           lambda: K.argmax(y, axis=1),\n           lambda: tf.cast(K.reshape(y, (-1,)), tf.int64))\n\n@@ -103,9 +103,9 @@ class TextVectorization(base_preprocessing_layer.CombinerPreprocessingLayer):\n        `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n        see `[\"string to split\", \"another string to split\"]`. The callable should\n        return a Tensor with the first dimension containing the split tokens -\n-       in this example, we should see something like `[[\"string\", \"to\", \"split],\n-       [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable site\n-       natively compatible with `tf.strings.split()`.\n+       in this example, we should see something like `[[\"string\", \"to\",\n+       \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n+       site natively compatible with `tf.strings.split()`.\n \n   Args:\n     max_tokens: The maximum size of the vocabulary for this layer. If None,\n\n@@ -21,7 +21,6 @@ from __future__ import print_function\n import tensorflow.compat.v2 as tf\n \n import uuid\n-from tensorflow.python.eager import function\n from tensorflow.python.eager.context import get_device_name\n from keras import activations\n from keras import backend as K\n@@ -1779,9 +1778,6 @@ def _function_register(func, *args, **kwargs):\n   Raises:\n     ValueError: When the input function is not a defun wrapped python function.\n   \"\"\"\n-  if not isinstance(func, function.Function):\n-    raise ValueError('Only defun function is allowed to be registered. '\n-                     'Got type: %s' % type(func))\n   concrete_func = func.get_concrete_function(*args, **kwargs)\n   concrete_func.add_to_graph()\n   concrete_func.add_gradient_functions_to_graph()\n\n@@ -23,8 +23,8 @@ import abc\n import functools\n \n import six\n-from tensorflow.python.framework import smart_cond\n from keras import backend as K\n+from keras.utils import control_flow_util\n from keras.utils import losses_utils\n from keras.utils import tf_utils\n from keras.utils.generic_utils import deserialize_keras_object\n@@ -1395,8 +1395,8 @@ def _maybe_convert_labels(y_true):\n     # Convert the binary labels to -1 or 1.\n     return 2. * y_true - 1.\n \n-  updated_y_true = smart_cond.smart_cond(is_binary, _convert_binary_labels,\n-                                         lambda: y_true)\n+  updated_y_true = control_flow_util.smart_cond(\n+      is_binary, _convert_binary_labels, lambda: y_true)\n   return updated_y_true\n \n \n@@ -1613,8 +1613,8 @@ def categorical_crossentropy(y_true,\n     num_classes = tf.cast(tf.compat.v1.shape(y_true)[-1], y_pred.dtype)\n     return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)\n \n-  y_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,\n-                                 lambda: y_true)\n+  y_true = control_flow_util.smart_cond(\n+      label_smoothing, _smooth_labels, lambda: y_true)\n   return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n \n \n@@ -1710,8 +1710,8 @@ def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n   def _smooth_labels():\n     return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n \n-  y_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,\n-                                 lambda: y_true)\n+  y_true = control_flow_util.smart_cond(\n+      label_smoothing, _smooth_labels, lambda: y_true)\n   return K.mean(\n       K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n \n\n@@ -19,11 +19,11 @@ from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n from tensorflow.python.framework import ops\n-from tensorflow.python.framework import smart_cond\n from keras import backend\n from keras import optimizers\n from keras.mixed_precision import loss_scale as keras_loss_scale_module\n from keras.optimizer_v2 import optimizer_v2\n+from keras.utils import control_flow_util\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.training.experimental import mixed_precision\n from tensorflow.python.training.tracking import base as trackable\n@@ -727,8 +727,8 @@ class LossScaleOptimizer(_DelegatingTrackableMixin, optimizer_v2.OptimizerV2):\n     # DistributionStrategy does not support having a cond in a replica context\n     # with a branch that calls `merge_call`, and self._optimizer.apply_gradients\n     # calls `merge_call`.\n-    maybe_apply_op = smart_cond.smart_cond(should_apply_grads, apply_fn,\n-                                           do_not_apply_fn)\n+    maybe_apply_op = control_flow_util.smart_cond(\n+        should_apply_grads, apply_fn, do_not_apply_fn)\n     return tf.group(maybe_apply_op, loss_scale_update_op)\n \n   def _apply_gradients(self, grads, wrapped_vars, name,\n\n@@ -42,6 +42,6 @@ class MetricSavedModelSaver(layer_serialization.LayerSavedModelSaver):\n     return metadata\n \n   def _get_serialized_attributes_internal(self, unused_serialization_cache):\n-    return (dict(variables=data_structures.ListWrapper(self.obj.variables)),\n+    return (dict(variables=data_structures.wrap_or_unwrap(self.obj.variables)),\n             dict())  # TODO(b/135550038): save functions to enable saving\n                      # custom metrics.\n\n@@ -111,19 +111,19 @@ def wrap_layer_objects(layer, serialization_cache):\n   wrapped_layer_losses = [keras_loss_cache[fn]\n                           for fn in layer._callable_losses[:]]  # pylint: disable=protected-access\n \n-  layer_metrics = data_structures._DictWrapper(  # pylint: disable=protected-access\n+  layer_metrics = data_structures.wrap_or_unwrap(\n       {m.name: m for m in layer._metrics})  # pylint: disable=protected-access\n   return dict(\n-      variables=data_structures.ListWrapper(layer.variables),\n-      trainable_variables=data_structures.ListWrapper(\n+      variables=data_structures.wrap_or_unwrap(layer.variables),\n+      trainable_variables=data_structures.wrap_or_unwrap(\n           layer.trainable_variables),\n-      non_trainable_variables=data_structures.ListWrapper(\n+      non_trainable_variables=data_structures.wrap_or_unwrap(\n           layer.non_trainable_variables),\n-      layers=data_structures.ListWrapper(utils.list_all_layers(layer)),\n-      metrics=data_structures.ListWrapper(layer.metrics),\n-      regularization_losses=data_structures.ListWrapper(\n+      layers=data_structures.wrap_or_unwrap(utils.list_all_layers(layer)),\n+      metrics=data_structures.wrap_or_unwrap(layer.metrics),\n+      regularization_losses=data_structures.wrap_or_unwrap(\n           wrapped_loss_functions),\n-      layer_regularization_losses=data_structures.ListWrapper(\n+      layer_regularization_losses=data_structures.wrap_or_unwrap(\n           wrapped_layer_losses),\n       layer_metrics=layer_metrics)\n   # pylint: disable=protected-access\n\n@@ -21,7 +21,6 @@ from __future__ import print_function\n import tensorflow.compat.v2 as tf\n \n from tensorflow.python.eager import def_function\n-from tensorflow.python.eager import function as defun\n from keras.saving.saved_model import constants\n from keras.utils.generic_utils import LazyLoader\n from tensorflow.python.training.tracking.tracking import AutoTrackable\n@@ -191,8 +190,7 @@ class SerializedAttributes(object):\n     for key in self.all_functions:\n       if key in function_dict:\n         if (function_dict[key] is not None and  # Not all functions are required\n-            not isinstance(function_dict[key],\n-                           (defun.Function, def_function.Function))):\n+            not isinstance(function_dict[key], def_function.Function)):\n           raise ValueError(\n               'Function dictionary contained a non-function object: {} (for key'\n               ' {})'.format(function_dict[key], key))\n\n@@ -38,7 +38,7 @@ class HasList(training.Model):\n \n   def __init__(self):\n     super(HasList, self).__init__()\n-    self.layer_list = data_structures.List([core.Dense(3)])\n+    self.layer_list = data_structures.wrap_or_unwrap([core.Dense(3)])\n     self.layer_list.append(core.Dense(4))\n     self.layer_list.extend(\n         [core.Dense(5),\n@@ -48,13 +48,13 @@ class HasList(training.Model):\n         core.Dense(8)\n     ]\n     self.layer_list += (\n-        data_structures.List([core.Dense(9)]) + data_structures.List(\n-            [core.Dense(10)]))\n+        data_structures.wrap_or_unwrap([core.Dense(9)]) +\n+        data_structures.wrap_or_unwrap([core.Dense(10)]))\n     self.layer_list.extend(\n-        data_structures.List(\n+        data_structures.wrap_or_unwrap(\n             list([core.Dense(11)]) + [core.Dense(12)]))\n-    self.layers_with_updates = data_structures.List(\n-        (normalization.BatchNormalization(),))\n+    self.layers_with_updates = data_structures.wrap_or_unwrap(\n+        [normalization.BatchNormalization()])\n \n   def call(self, x):\n     aggregation = 0.\n@@ -225,7 +225,7 @@ class ListWrapperTest(tf.test.TestCase):\n \n   def testLayerCollectionWithExternalMutation(self):\n     l = []\n-    l_wrapper = data_structures.ListWrapper(l)\n+    l_wrapper = data_structures.wrap_or_unwrap(l)\n     layer = core.Dense(1)\n     l.append(layer)\n     self.assertEqual([layer], l_wrapper.layers)\n@@ -235,9 +235,9 @@ class HasMapping(training.Model):\n \n   def __init__(self):\n     super(HasMapping, self).__init__()\n-    self.layer_dict = data_structures.Mapping(output=core.Dense(7))\n-    self.layer_dict[\"norm\"] = data_structures.List()\n-    self.layer_dict[\"dense\"] = data_structures.List()\n+    self.layer_dict = data_structures.wrap_or_unwrap(dict(output=core.Dense(7)))\n+    self.layer_dict[\"norm\"] = data_structures.wrap_or_unwrap([])\n+    self.layer_dict[\"dense\"] = data_structures.wrap_or_unwrap([])\n     self.layer_dict[\"dense\"].extend(\n         [core.Dense(5),\n          core.Dense(6, kernel_regularizer=tf.reduce_sum)])\n@@ -293,7 +293,7 @@ class MappingTests(keras_parameterized.TestCase):\n   def testDictWrapperBadKeys(self):\n     a = tf.Module()\n     a.d = {}\n-    a.d[1] = data_structures.List()\n+    a.d[1] = data_structures.wrap_or_unwrap([])\n     model = training.Model()\n     model.sub = a\n     save_path = os.path.join(self.get_temp_dir(), \"ckpt\")\n\n@@ -23,7 +23,6 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import smart_cond as smart_module\n \n \n def InXlaContext(graph):\n@@ -108,8 +107,21 @@ def smart_cond(pred, true_fn=None, false_fn=None, name=None):  # pylint: disable\n   if isinstance(pred, tf.Variable):\n     return tf.compat.v1.cond(\n         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n-  return smart_module.smart_cond(\n-      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n+\n+  if not callable(true_fn):\n+    raise TypeError(\"`true_fn` must be callable.\")\n+  if not callable(false_fn):\n+    raise TypeError(\"`false_fn` must be callable.\")\n+\n+  pred_value = constant_value(pred)\n+  if pred_value is not None:\n+    if pred_value:\n+      return true_fn()\n+    else:\n+      return false_fn()\n+  else:\n+    return tf.compat.v1.cond(pred, true_fn=true_fn, false_fn=false_fn,\n+                                 name=name)\n \n \n def constant_value(pred):  # pylint: disable=invalid-name\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08fb0c6027b43eee9a0367fdc22a4c958ab564c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 248 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -91,7 +91,7 @@ class TpuStrategyTest(tf.test.TestCase):\n     # Only needed for serving.\n     label_inverse_lookup_layer = (\n         tf.keras.layers.experimental.preprocessing.StringLookup(\n-            num_oov_indices=1,\n+            num_oov_indices=0,\n             mask_token=None,\n             vocabulary=LABEL_VOCAB,\n             invert=True))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0b89570b1601f25ebb959638aa7254b9394f7694", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 1208 | Contributors (this commit): 2 | Commits (past 90d): 6 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1183,8 +1183,12 @@ class MetricTest(tf.test.TestCase, parameterized.TestCase):\n     class CustomMetric(keras.metrics.MeanSquaredError):\n       pass\n \n+    with self.cached_session():\n+      metric = CustomMetric()\n       model = testing_utils.get_small_mlp(1, 4, input_dim=3)\n-    model.compile(loss='mse', optimizer='rmsprop', metrics=[CustomMetric()])\n+      model.compile(loss='mse', optimizer='rmsprop', metrics=[metric])\n+      self.evaluate(tf.compat.v1.global_variables_initializer())\n+      self.evaluate([v.initializer for v in metric.variables])\n \n       saved_model_dir = self._save_model_dir()\n       tf.saved_model.save(model, saved_model_dir)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d77bc5f267a49ed890222039f9ee058cca7f22f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 493 | Lines Deleted: 197 | Files Changed: 30 | Hunks: 160 | Methods Changed: 102 | Complexity Δ (Sum/Max): 35/9 | Churn Δ: 690 | Churn Cumulative: 103375 | Contributors (this commit): 292 | Commits (past 90d): 205 | Contributors (cumulative): 474 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3161,8 +3161,11 @@ def resize_images(x, height_factor, width_factor, data_format,\n   else:\n     raise ValueError('Invalid `data_format` argument: %s' % (data_format,))\n \n-  original_shape = int_shape(x)\n-  new_shape = tf.compat.v1.shape(x)[rows:cols + 1]\n+  new_shape = x.shape[rows:cols + 1]\n+  if new_shape.is_fully_defined():\n+    new_shape = tf.constant(new_shape.as_list(), dtype='int32')\n+  else:\n+    new_shape = tf.shape(x)[rows:cols + 1]\n   new_shape *= tf.constant(\n       np.array([height_factor, width_factor], dtype='int32'))\n \n@@ -3180,21 +3183,6 @@ def resize_images(x, height_factor, width_factor, data_format,\n   if data_format == 'channels_first':\n     x = permute_dimensions(x, [0, 3, 1, 2])\n \n-  if original_shape[rows] is None:\n-    new_height = None\n-  else:\n-    new_height = original_shape[rows] * height_factor\n-\n-  if original_shape[cols] is None:\n-    new_width = None\n-  else:\n-    new_width = original_shape[cols] * width_factor\n-\n-  if data_format == 'channels_first':\n-    output_shape = (None, None, new_height, new_width)\n-  else:\n-    output_shape = (None, new_height, new_width, None)\n-  x.set_shape(output_shape)\n   return x\n \n \n\n@@ -600,6 +600,12 @@ class BackendShapeOpsTest(tf.test.TestCase):\n     y = backend.resize_images(x, height_factor, width_factor, data_format)\n     self.assertEqual(y.shape.as_list(), [1, 3, 4, 4])\n \n+    # Use with a dynamic axis:\n+    if not tf.executing_eagerly():\n+      x = backend.placeholder(shape=(1, 3, None, None))\n+      y = backend.resize_images(x, height_factor, width_factor, data_format)\n+      self.assertEqual(y.shape.as_list(), [1, 3, None, None])\n+\n     # Invalid use:\n     with self.assertRaises(ValueError):\n       backend.resize_images(\n\n@@ -35,7 +35,7 @@ def _get_metadata(name):\n \n \n def _get_layer_args(layer_cls, layer_args):\n-  # To make benchmark parameters be compatible with GPU platform.\n+  # To make benchmark parameters compatible with GPU platform.\n   if layer_cls is tf.keras.layers.Bidirectional:\n     return {\"layer\": tf.keras.layers.LSTM(1)}\n   return layer_args\n\n@@ -229,8 +229,8 @@ class CallbackList(object):\n \n     # Performance check: Check batch hooks for slowness compared to batch time.\n     # Only run check for custom callbacks (i.e. not present in this file).\n-    self._check_timing = any([cbk.__class__.__name__ not in globals()\n-                              for cbk in self.callbacks])\n+    self._check_timing = any(\n+        cbk.__class__.__name__ not in globals() for cbk in self.callbacks)\n     self._num_batches_for_timing_check = 5\n     self._hook_times = {}\n     self._batch_start_time = None\n@@ -1089,6 +1089,19 @@ class History(Callback):\n   This callback is automatically applied to\n   every Keras model. The `History` object\n   gets returned by the `fit` method of models.\n+\n+  Example:\n+\n+  >>> model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n+  >>> model.compile(tf.keras.optimizers.SGD(), loss='mse')\n+  >>> history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n+  ...                     epochs=10)\n+  >>> print(history.params)\n+  {'verbose': 1, 'epochs': 10, 'steps': 1}\n+  >>> # check the keys of history object\n+  >>> print(history.history.keys())\n+  dict_keys(['loss'])\n+\n   \"\"\"\n \n   def __init__(self):\n@@ -1189,8 +1202,9 @@ class ModelCheckpoint(Callback):\n         decision to overwrite the current save file is made based on either\n         the maximization or the minimization of the monitored quantity.\n         For `val_acc`, this should be `max`, for `val_loss` this should be\n-        `min`, etc. In `auto` mode, the direction is automatically inferred\n-        from the name of the monitored quantity.\n+        `min`, etc. In `auto` mode, the mode is set to `max` if the quantities\n+        monitored are 'acc' or start with 'fmeasure' and are set to `min` for\n+        the rest of the quantities.\n       save_weights_only: if True, then only the model's weights will be saved\n         (`model.save_weights(filepath)`), else the full model is saved\n         (`model.save(filepath)`).\n@@ -1291,14 +1305,6 @@ class ModelCheckpoint(Callback):\n     # restore checkpoint at on_train_begin().\n     self._chief_worker_only = False\n \n-  def set_model(self, model):\n-    self.model = model\n-    # Use name matching rather than `isinstance` to avoid circular dependencies.\n-    if (not self.save_weights_only and\n-        not model._is_graph_network and  # pylint: disable=protected-access\n-        model.__class__.__name__ != 'Sequential'):\n-      self.save_weights_only = True\n-\n   def on_train_begin(self, logs=None):\n     if self.load_weights_on_restart:\n       filepath_to_load = (\n@@ -2314,10 +2320,14 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n     if self._start_batch < 0 or self._stop_batch < self._start_batch:\n       raise ValueError(profile_batch_error_message)\n \n+    # True when the profiler was successfully started by this callback.\n+    # We track the status here to make sure callbacks do not interfere with\n+    # each other. The callback will only stop the profiler it started.\n+    self._profiler_started = False\n     if self._start_batch > 0:\n       # Warm up and improve the profiling accuracy.\n-      tf.profiler.experimental.start('')\n-      tf.profiler.experimental.stop(save=False)\n+      self._start_profiler(logdir='')\n+      self._stop_profiler(save=False)\n     # True when a trace is running.\n     self._is_tracing = False\n \n@@ -2392,7 +2402,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n \n   def _start_trace(self):\n     tf.summary.trace_on(graph=True, profiler=False)\n-    tf.profiler.experimental.start(logdir=self._train_dir)\n+    self._start_profiler(logdir=self._train_dir)\n     self._is_tracing = True\n \n   def _stop_trace(self, batch=None):\n@@ -2403,7 +2413,7 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n       with tf.summary.record_if(True):\n         # TODO(b/126388999): Remove step info in the summary name.\n         tf.summary.trace_export(name='batch_%d' % batch, step=batch)\n-    tf.profiler.experimental.stop()\n+    self._stop_profiler()\n     self._is_tracing = False\n \n   def _collect_learning_rate(self, logs):\n@@ -2486,6 +2496,37 @@ class TensorBoard(Callback, version_utils.TensorBoardVersionSelector):\n                                    'keras_embedding.ckpt-{}'.format(epoch))\n     self.model.save_weights(embeddings_ckpt)\n \n+  def _start_profiler(self, logdir):\n+    \"\"\"Starts the profiler if currently inactive.\n+\n+    Args:\n+      logdir: Directory where profiler results will be saved.\n+    \"\"\"\n+    if self._profiler_started:\n+      return\n+    try:\n+      tf.profiler.experimental.start(logdir=logdir)\n+      self._profiler_started = True\n+    except tf.errors.AlreadyExistsError as e:\n+      # Profiler errors should not be fatal.\n+      logging.error('Failed to start profiler: %s', e.message)\n+\n+  def _stop_profiler(self, save=True):\n+    \"\"\"Stops the profiler if currently active.\n+\n+    Args:\n+      save: Whether to save the profiler results to TensorBoard.\n+    \"\"\"\n+    if not self._profiler_started:\n+      return\n+    try:\n+      tf.profiler.experimental.stop(save=save)\n+    except tf.errors.UnavailableError as e:\n+      # Profiler errors should not be fatal.\n+      logging.error('Failed to stop profiler: %s', e.message)\n+    finally:\n+      self._profiler_started = False\n+\n \n @keras_export('keras.callbacks.ReduceLROnPlateau')\n class ReduceLROnPlateau(Callback):\n\n@@ -36,6 +36,7 @@ import numpy as np\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n+from keras.callbacks import BackupAndRestore\n from keras.engine import sequential\n from keras.layers import Activation\n from keras.layers import Dense\n@@ -266,6 +267,14 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n       model.fit(dataset, epochs=2, steps_per_epoch=10)\n       self.assertRegex(printed.contents(), expected_log)\n \n+  @keras_parameterized.run_all_keras_modes\n+  def test_trivial_backup_restore(self):\n+    if testing_utils.should_run_eagerly():\n+      model = keras.Sequential([keras.layers.Dense(1)])\n+      model.compile('sgd', 'mse')\n+      cbk = BackupAndRestore(self.get_temp_dir())\n+      model.fit(np.ones((10, 1)), np.ones((10, 1)), epochs=0, callbacks=[cbk])\n+\n   @keras_parameterized.run_all_keras_modes\n   def test_callback_warning(self):\n \n@@ -433,11 +442,15 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     if h5py is None:\n       return  # Skip test if models cannot be saved.\n \n+    model_type = testing_utils.get_model_type()\n+    if model_type == 'subclass':\n+      return  # Skip test since subclassed models cannot be saved in .h5 format.\n+\n     layers = [\n         keras.layers.Dense(NUM_HIDDEN, input_dim=INPUT_DIM, activation='relu'),\n         keras.layers.Dense(NUM_CLASSES, activation='softmax')\n     ]\n-    model = testing_utils.get_model_from_layers(layers, input_shape=(10,))\n+    model = testing_utils.get_model_from_layers(layers, input_shape=(3,))\n     model.compile(\n         loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n \n@@ -452,19 +465,12 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         num_classes=NUM_CLASSES)\n     y_test = np_utils.to_categorical(y_test)\n     y_train = np_utils.to_categorical(y_train)\n-    # case 1\n+\n+    # Case 1\n     monitor = 'val_loss'\n     save_best_only = False\n     mode = 'auto'\n \n-    model = keras.models.Sequential()\n-    model.add(\n-        keras.layers.Dense(\n-            NUM_HIDDEN, input_dim=INPUT_DIM, activation='relu'))\n-    model.add(keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n-    model.compile(\n-        loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n-\n     cbks = [\n         keras.callbacks.ModelCheckpoint(\n             filepath,\n@@ -483,7 +489,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n \n-    # case 2\n+    # Case 2\n     mode = 'min'\n     cbks = [\n         keras.callbacks.ModelCheckpoint(\n@@ -503,7 +509,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n \n-    # case 3\n+    # Case 3\n     mode = 'max'\n     monitor = 'val_acc'\n     cbks = [\n@@ -524,7 +530,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n \n-    # case 4\n+    # Case 4\n     save_best_only = True\n     cbks = [\n         keras.callbacks.ModelCheckpoint(\n@@ -544,7 +550,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     assert os.path.exists(filepath)\n     os.remove(filepath)\n \n-    # Case: metric not available.\n+    # Case 5: metric not available.\n     cbks = [\n         keras.callbacks.ModelCheckpoint(\n             filepath,\n@@ -562,7 +568,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     # File won't be written.\n     assert not os.path.exists(filepath)\n \n-    # case 5\n+    # Case 6\n     save_best_only = False\n     period = 2\n     mode = 'auto'\n@@ -598,7 +604,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         save_best_only=save_best_only,\n         mode='unknown')\n \n-    # Case 6: `ModelCheckpoint` with a combination of `save_freq` and `period`.\n+    # Case 7: `ModelCheckpoint` with a combination of `save_freq` and `period`.\n     # Though `period` is deprecated, we're testing it for\n     # backward-compatibility.\n     filepath = os.path.join(temp_dir, 'checkpoint.epoch{epoch:02d}.h5')\n@@ -626,7 +632,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     os.remove(filepath.format(epoch=5))\n     os.remove(filepath.format(epoch=10))\n \n-    # Case 7: `ModelCheckpoint` with an integer `save_freq`\n+    # Case 8: `ModelCheckpoint` with an integer `save_freq`\n     filepath = os.path.join(temp_dir, 'checkpoint.epoch{epoch:02d}.h5')\n     cbks = [\n         keras.callbacks.ModelCheckpoint(\n@@ -659,7 +665,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n     os.remove(filepath.format(epoch=6))\n     os.remove(filepath.format(epoch=9))\n \n-    # Case 8: `ModelCheckpoint` with valid and invalid save_freq argument.\n+    # Case 9: `ModelCheckpoint` with valid and invalid save_freq argument.\n     with self.assertRaisesRegex(ValueError, 'Unrecognized save_freq'):\n       keras.callbacks.ModelCheckpoint(\n           filepath,\n@@ -681,7 +687,7 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         mode=mode,\n         save_freq=3)\n \n-    # Case 9: `ModelCheckpoint` with valid and invalid `options` argument.\n+    # Case 10: `ModelCheckpoint` with valid and invalid `options` argument.\n     with self.assertRaisesRegex(TypeError, 'tf.train.CheckpointOptions'):\n       keras.callbacks.ModelCheckpoint(\n           filepath,\n@@ -713,6 +719,33 @@ class KerasCallbacksTest(keras_parameterized.TestCase):\n         mode=mode,\n         options=tf.saved_model.SaveOptions())\n \n+  @testing_utils.run_v2_only\n+  def test_ModelCheckpoint_subclass_save_weights_false(self):\n+    model = testing_utils.get_small_subclass_mlp(NUM_HIDDEN, NUM_CLASSES)\n+    model.compile(\n+        loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n+    temp_dir = self.get_temp_dir()\n+    self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n+    filepath = os.path.join(temp_dir, 'checkpoint')\n+    cbks = [keras.callbacks.ModelCheckpoint(\n+        filepath, save_weights_only=False)]\n+\n+    (x_train, y_train), _ = testing_utils.get_test_data(\n+        train_samples=TRAIN_SAMPLES,\n+        test_samples=TEST_SAMPLES,\n+        input_shape=(INPUT_DIM,),\n+        num_classes=NUM_CLASSES)\n+    y_train = np_utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n+\n+    model.fit(\n+        x_train,\n+        y_train,\n+        callbacks=cbks,\n+        epochs=1,\n+        verbose=0)\n+    # Check that the filepath is a SavedModel directory.\n+    self.assertIn('saved_model.pb', os.listdir(filepath))\n+\n   def _get_dummy_resource_for_model_checkpoint_testing(self):\n \n     def get_input_datasets():\n@@ -2414,6 +2447,36 @@ class TestTensorBoardV2NonParameterizedTest(keras_parameterized.TestCase):\n     )\n     self.assertEqual(1, self._count_trace_file(logdir=self.train_dir))\n \n+  def test_TensorBoard_autoTrace_outerProfiler(self):\n+    \"\"\"Runs a profiler session that interferes with the one from the callback.\n+\n+    The callback will not generate a profile but execution will proceed without\n+    crashing due to unhandled exceptions.\n+    \"\"\"\n+    tf.profiler.experimental.start(logdir='')\n+    model = self._get_seq_model()\n+    x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n+    tb_cbk = keras.callbacks.TensorBoard(\n+        self.logdir, histogram_freq=1, profile_batch=1, write_graph=False)\n+\n+    model.fit(\n+        x,\n+        y,\n+        batch_size=2,\n+        epochs=2,\n+        validation_data=(x, y),\n+        callbacks=[tb_cbk])\n+    summary_file = list_summaries(self.logdir)\n+    tf.profiler.experimental.stop(save=False)\n+\n+    self.assertEqual(\n+        summary_file.tensors,\n+        {\n+            _ObservedSummary(logdir=self.train_dir, tag=u'batch_1'),\n+        },\n+    )\n+    self.assertEqual(0, self._count_trace_file(logdir=self.train_dir))\n+\n   def test_TensorBoard_autoTrace_tagNameWithBatchNum(self):\n     model = self._get_seq_model()\n     x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n\n@@ -149,8 +149,10 @@ class TensorBoard(callbacks.TensorBoard):\n     self._samples_seen_at_last_write = 0\n     # TODO(fishx): Add a link to the full profiler tutorial.\n     self._profile_batch = profile_batch\n-    # One profiler session is running if it is True.\n-    self._is_profiling = False\n+    # True when the profiler was successfully started by this callback.\n+    # We track the status here to make sure callbacks do not interfere with\n+    # each other. The callback will only stop the profiler it started.\n+    self._profiler_started = False\n \n     # TensorBoard should only write summaries on the chief when in a\n     # Multi-Worker setting.\n@@ -337,10 +339,8 @@ class TensorBoard(callbacks.TensorBoard):\n     self.writer.flush()\n \n   def on_train_batch_begin(self, batch, logs=None):\n-    if (not self._is_profiling and\n-        self._total_batches_seen == self._profile_batch - 1):\n-      tf.profiler.experimental.start(self.log_dir)\n-      self._is_profiling = True\n+    if self._total_batches_seen == self._profile_batch - 1:\n+      self._start_profiler()\n \n   def on_train_batch_end(self, batch, logs=None):\n     return self.on_batch_end(batch, logs)\n@@ -367,10 +367,7 @@ class TensorBoard(callbacks.TensorBoard):\n       self._write_custom_summaries(self._total_batches_seen, batch_logs)\n       self._samples_seen_at_last_write = self._samples_seen\n     self._total_batches_seen += 1\n-\n-    if self._is_profiling:\n-      tf.profiler.experimental.stop()\n-      self._is_profiling = False\n+    self._stop_profiler()\n \n   def on_train_begin(self, logs=None):\n     pass\n@@ -455,7 +452,28 @@ class TensorBoard(callbacks.TensorBoard):\n           i += self.batch_size\n \n   def on_train_end(self, logs=None):\n-    if self._is_profiling:\n-      tf.profiler.experimental.stop()\n-      self._is_profiling = False\n+    self._stop_profiler()\n     self.writer.close()\n+\n+  def _start_profiler(self):\n+    \"\"\"Starts the profiler if currently inactive.\"\"\"\n+    if self._profiler_started:\n+      return\n+    try:\n+      tf.profiler.experimental.start(logdir=self.log_dir)\n+      self._profiler_started = True\n+    except tf.errors.AlreadyExistsError as e:\n+      # Profiler errors should not be fatal.\n+      logging.error('Failed to start profiler: %s', e.message)\n+\n+  def _stop_profiler(self):\n+    \"\"\"Stops the profiler if currently active.\"\"\"\n+    if not self._profiler_started:\n+      return\n+    try:\n+      tf.profiler.experimental.stop()\n+    except tf.errors.UnavailableError as e:\n+      # Profiler errors should not be fatal.\n+      logging.error('Failed to stop profiler: %s', e.message)\n+    finally:\n+      self._profiler_started = False\n\n@@ -58,10 +58,11 @@ def make_cluster(num_workers, num_ps):\n   return SimpleClusterResolver(ClusterSpec(cluster_def), rpc_layer=\"grpc\")\n \n \n-def make_coordinator(num_workers, num_ps):\n+def make_coordinator(num_workers, num_ps, variable_partitioner=None):\n   return tf.distribute.experimental.coordinator.ClusterCoordinator(\n       tf.distribute.experimental.ParameterServerStrategy(\n-          make_cluster(num_workers, num_ps)))\n+          make_cluster(num_workers, num_ps),\n+          variable_partitioner=variable_partitioner))\n \n \n # TODO(yuefengz): move this to keras/integration_tests.\n@@ -230,7 +231,10 @@ class KPLTest(tf.test.TestCase, parameterized.TestCase):\n \n class ModelFitTest(tf.test.TestCase, parameterized.TestCase):\n \n-  def _model_compile(self, steps_per_execution=1, run_eagerly=False):\n+  def _model_compile(self,\n+                     steps_per_execution=1,\n+                     run_eagerly=False,\n+                     with_normalization_layer=False):\n \n     class ResultAssertingCallback(callbacks_lib.Callback):\n \n@@ -247,9 +251,15 @@ class ModelFitTest(tf.test.TestCase, parameterized.TestCase):\n           raise RuntimeError(\"loss is supposed to be in the logs and float.\")\n \n     strategy = tf.distribute.experimental.ParameterServerStrategy(\n-        make_cluster(3, 2))\n+        make_cluster(3, 2),\n+        variable_partitioner=tf.distribute.experimental.partitioners.FixedShardsPartitioner(2))\n     with strategy.scope():\n       model = sequential.Sequential([core_layers.Dense(10)])\n+      if with_normalization_layer:\n+        norm = keras.layers.BatchNormalization(\n+            axis=-1, input_shape=(4, 4, 3), momentum=0.8)\n+        model.add(norm)\n+\n     model.compile(\n         gradient_descent.SGD(),\n         loss=\"mse\",\n@@ -262,8 +272,10 @@ class ModelFitTest(tf.test.TestCase, parameterized.TestCase):\n                  validation_data=None,\n                  x=None,\n                  steps_per_epoch=10,\n-                 run_eagerly=False):\n-    model, callbacks = self._model_compile(steps_per_execution, run_eagerly)\n+                 run_eagerly=False,\n+                 with_normalization_layer=False):\n+    model, callbacks = self._model_compile(steps_per_execution, run_eagerly,\n+                                           with_normalization_layer)\n \n     def dataset_fn(input_context):\n       del input_context\n@@ -287,6 +299,12 @@ class ModelFitTest(tf.test.TestCase, parameterized.TestCase):\n   def testModelFit(self):\n     model = self._model_fit()\n     self.assertEqual(model.optimizer.iterations, 100)\n+    return model\n+\n+  @tf.__internal__.distribute.combinations.generate(tf.__internal__.test.combinations.combine(mode=[\"eager\"]))\n+  def testModelFitWithNormalizationLayer(self):\n+    model = self._model_fit(with_normalization_layer=True)\n+    self.assertEqual(model.optimizer.iterations, 100)\n \n   @tf.__internal__.distribute.combinations.generate(tf.__internal__.test.combinations.combine(mode=[\"eager\"]))\n   def testModelFitWithStepsPerExecution(self):\n\n@@ -109,7 +109,10 @@ class WorkerTrainingState(object):\n     successfully finishes.\n     \"\"\"\n     if self.write_checkpoint_manager is self.read_checkpoint_manager:\n+      try:\n         tf.io.gfile.rmtree(self.write_checkpoint_manager.directory)\n+      except tf.errors.NotFoundError:\n+        pass\n \n   def maybe_load_initial_epoch_from_ckpt(self, initial_epoch, mode):\n     \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n\n@@ -678,10 +678,11 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     self.assertEqual([None, 3], layer._build_input_shape.as_list())\n \n   @combinations.generate(combinations.combine(mode=['eager']))\n-  def custom_layer_training_arg(self):\n+  def test_custom_layer_training_arg(self):\n     class CustomLayerNoTrainingArg(base_layer.Layer):\n \n       def __init__(self, nested_layer=None):\n+        super(CustomLayerNoTrainingArg, self).__init__()\n         self._nested_layer = nested_layer or tf.identity\n \n       def call(self, inputs):\n@@ -690,6 +691,7 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     class CustomLayerDefaultTrainingMissing(base_layer.Layer):\n \n       def __init__(self, nested_layer=None):\n+        super(CustomLayerDefaultTrainingMissing, self).__init__()\n         self._nested_layer = nested_layer or tf.identity\n \n       def call(self, inputs, training):\n@@ -701,6 +703,7 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     class CustomLayerDefaultTrainingNone(base_layer.Layer):\n \n       def __init__(self, nested_layer=None):\n+        super(CustomLayerDefaultTrainingNone, self).__init__()\n         self._nested_layer = nested_layer or tf.identity\n \n       def call(self, inputs, training=None):\n@@ -712,6 +715,7 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     class CustomLayerDefaultTrainingFalse(base_layer.Layer):\n \n       def __init__(self, nested_layer=None):\n+        super(CustomLayerDefaultTrainingFalse, self).__init__()\n         self._nested_layer = nested_layer or tf.identity\n \n       def call(self, inputs, training=False):\n@@ -723,6 +727,7 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     class CustomLayerDefaultTrainingTrue(base_layer.Layer):\n \n       def __init__(self, nested_layer=None):\n+        super(CustomLayerDefaultTrainingTrue, self).__init__()\n         self._nested_layer = nested_layer or tf.identity\n \n       def call(self, inputs, training=True):\n@@ -761,14 +766,14 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     # nested layers, respecting whatever mode the outer layer was run with.\n     layer = CustomLayerDefaultTrainingTrue(CustomLayerDefaultTrainingFalse())\n     # No outer value passed: use local defaults\n-    self.assertAllEqual(layer(x), x * 0.25)  # Use local default False\n+    self.assertAllEqual(layer(x), x)  # Use outer default True\n     # Outer value passed: override local defaults\n     self.assertAllEqual(layer(x, training=False), x * 0.25)\n     self.assertAllEqual(layer(x, training=True), x)\n \n     layer = CustomLayerDefaultTrainingFalse(CustomLayerDefaultTrainingTrue())\n     # No outer value passed: use local defaults\n-    self.assertAllEqual(layer(x), x)  # Use local default True\n+    self.assertAllEqual(layer(x), x * 0.25)  # Use outer default False\n     # Outer value passed: override local defaults\n     self.assertAllEqual(layer(x, training=False), x * 0.25)\n     self.assertAllEqual(layer(x, training=True), x)\n@@ -783,8 +788,8 @@ class BaseLayerTest(keras_parameterized.TestCase):\n     self.assertAllEqual(layer(x, training=True), x)\n \n     layer = CustomLayerDefaultTrainingNone(CustomLayerDefaultTrainingTrue())\n-    self.assertAllEqual(layer(x), x)  # Use local default True\n-    self.assertAllEqual(layer(x, training=False), x * 0.5)\n+    self.assertAllEqual(layer(x), x * 0.5)  # Nested use local default True\n+    self.assertAllEqual(layer(x, training=False), x * 0.25)\n     self.assertAllEqual(layer(x, training=True), x)\n \n   def test_activity_regularizer_string(self):\n\n@@ -30,9 +30,9 @@ import random\n import numpy as np\n import six\n from tensorflow.python.eager import context\n+from tensorflow.python.framework import smart_cond\n from keras import backend\n from keras.engine import training_utils\n-from keras.utils import control_flow_util\n from keras.utils import data_utils\n from keras.utils import dataset_creator\n from keras.utils import tf_utils\n@@ -1398,7 +1398,7 @@ def _make_class_weight_map_fn(class_weight):\n       raise ValueError(\"`class_weight` not supported for \"\n                        \"3+ dimensional targets.\")\n \n-    y_classes = control_flow_util.smart_cond(\n+    y_classes = smart_cond.smart_cond(\n         y.shape.rank == 2 and backend.shape(y)[1] > 1,\n         lambda: backend.argmax(y, axis=1),\n         lambda: tf.cast(backend.reshape(y, (-1,)), tf.int64))\n\n@@ -1010,8 +1010,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         workers: Integer. Used for generator or `keras.utils.Sequence` input\n             only. Maximum number of processes to spin up\n             when using process-based threading. If unspecified, `workers`\n-            will default to 1. If 0, will execute the generator on the main\n-            thread.\n+            will default to 1.\n         use_multiprocessing: Boolean. Used for generator or\n             `keras.utils.Sequence` input only. If `True`, use process-based\n             threading. If unspecified, `use_multiprocessing` will default to\n@@ -1347,8 +1346,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           `max_queue_size` will default to 10.\n         workers: Integer. Used for generator or `keras.utils.Sequence` input\n           only. Maximum number of processes to spin up when using process-based\n-          threading. If unspecified, `workers` will default to 1. If 0, will\n-          execute the generator on the main thread.\n+          threading. If unspecified, `workers` will default to 1.\n         use_multiprocessing: Boolean. Used for generator or\n           `keras.utils.Sequence` input only. If `True`, use process-based\n           threading. If unspecified, `use_multiprocessing` will default to\n@@ -1589,7 +1587,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         workers: Integer. Used for generator or `keras.utils.Sequence` input\n             only. Maximum number of processes to spin up when using\n             process-based threading. If unspecified, `workers` will default\n-            to 1. If 0, will execute the generator on the main thread.\n+            to 1.\n         use_multiprocessing: Boolean. Used for generator or\n             `keras.utils.Sequence` input only. If `True`, use process-based\n             threading. If unspecified, `use_multiprocessing` will default to\n\n@@ -30,11 +30,11 @@ import time\n import numpy as np\n import six\n from six.moves import zip  # pylint: disable=redefined-builtin\n+from tensorflow.python.framework import smart_cond\n from keras import backend as K\n from keras import callbacks as cbks\n from keras import losses\n from keras import metrics as metrics_module\n-from keras.utils import control_flow_util\n from keras.utils import data_utils\n from keras.utils import generic_utils\n from keras.utils import losses_utils\n@@ -826,6 +826,7 @@ def collect_per_output_metric_info(metrics,\n                                    output_names,\n                                    output_shapes,\n                                    loss_fns,\n+                                   from_serialized=False,\n                                    is_weighted=False):\n   \"\"\"Maps metric names and functions to model outputs.\n \n@@ -834,6 +835,8 @@ def collect_per_output_metric_info(metrics,\n       output_names: a list of the names (strings) of model outputs.\n       output_shapes: a list of the shapes (strings) of model outputs.\n       loss_fns: a list of the loss functions corresponding to the model outputs.\n+      from_serialized: whether the model the metrics are being sourced from is\n+        being initialized from a serialized format.\n       is_weighted: Boolean indicating whether the given metrics are weighted.\n \n   Returns:\n@@ -890,11 +893,16 @@ def collect_per_output_metric_info(metrics,\n       metric_name = get_metric_name(metric, is_weighted)\n       metric_fn = get_metric_function(\n           metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])\n+      metric_fn._from_serialized = from_serialized  # pylint: disable=protected-access\n \n       # If the metric function is not stateful, we create a stateful version.\n       if not isinstance(metric_fn, metrics_module.Metric):\n         metric_fn = metrics_module.MeanMetricWrapper(\n             metric_fn, name=metric_name)\n+        # If the metric is being revived from something stateless, such as a\n+        # string (e.g. \"accuracy\"), we may need to later reapply transformations\n+        # such as renaming.\n+        metric_fn._from_serialized = False  # pylint: disable=protected-access\n       metrics_dict[metric_name] = metric_fn\n     per_output_metrics.append(metrics_dict)\n \n@@ -1009,7 +1017,7 @@ def standardize_weights(y,\n       weight_vector[:] = np.nan\n       weight_vector[keys] = values\n \n-      y_classes = control_flow_util.smart_cond(\n+      y_classes = smart_cond.smart_cond(\n           len(y.shape.as_list()) == 2 and K.shape(y)[1] > 1,\n           lambda: K.argmax(y, axis=1),\n           lambda: tf.cast(K.reshape(y, (-1,)), tf.int64))\n\n@@ -291,7 +291,7 @@ class Model(training_lib.Model):\n \n     # Prepare Session arguments (legacy).\n     kwargs.pop('cloning', None)  # Legacy DistStrat argument, never used.\n-    kwargs.pop('from_serialized', None)  # Not used in v1.\n+    self._from_serialized = kwargs.pop('from_serialized', False)\n     allowed_kwargs = {'feed_dict', 'fetches', 'options', 'run_metadata'}\n     unknown_kwargs = set(kwargs.keys()) - allowed_kwargs\n     if unknown_kwargs:\n@@ -1783,17 +1783,19 @@ class Model(training_lib.Model):\n       else:\n         output_shapes.append(output.shape.as_list())\n     self._per_output_metrics = training_utils_v1.collect_per_output_metric_info(\n-        metrics, self.output_names, output_shapes, self.loss_functions)\n+        metrics, self.output_names, output_shapes, self.loss_functions,\n+        from_serialized=self._from_serialized)\n     self._per_output_weighted_metrics = (\n         training_utils_v1.collect_per_output_metric_info(\n             weighted_metrics,\n             self.output_names,\n             output_shapes,\n             self.loss_functions,\n+            from_serialized=self._from_serialized,\n             is_weighted=True))\n \n-  def _add_unique_metric_name(self, metric_name, output_index):\n-    \"\"\"Makes the metric name unique and adds it to the model's metric name list.\n+  def _add_unique_metric_name(self, metric_name, metric_fn, output_index):\n+    \"\"\"Makes the metric name unique.\n \n       If there are multiple outputs for which the metrics are calculated, the\n       metric names have to be made unique by appending an integer.\n@@ -1801,14 +1803,24 @@ class Model(training_lib.Model):\n     Args:\n       metric_name: Metric name that corresponds to the metric specified by the\n           user. For example: 'acc'.\n+      metric_fn: The Metric object.\n       output_index: The index of the model output for which the metric name is\n         being added.\n \n     Returns:\n       string, name of the model's unique metric name\n     \"\"\"\n+    # For multi-output models, prepend the output names to the metric name.\n     if len(self.output_names) > 1:\n+      # If we're loading from an already-serialized model, we've already\n+      # prepended the output name, and we don't want to do it again.\n+      #\n+      # Alternatively, we may be receiving a stateless metric (e.g. the string\n+      # \"accuracy\") rather than a `Metric` object, in which case we want to\n+      # prepend the output name even if we are loading a serialized model.\n+      if not getattr(metric_fn, '_from_serialized', False):\n         metric_name = '%s_%s' % (self.output_names[output_index], metric_name)\n+\n     j = 1\n     base_metric_name = metric_name\n     while metric_name in self.metrics_names:\n@@ -1836,7 +1848,8 @@ class Model(training_lib.Model):\n     \"\"\"\n     updated_metrics_dict = collections.OrderedDict()\n     for metric_name, metric_fn in metrics_dict.items():\n-      metric_name = self._add_unique_metric_name(metric_name, output_index)\n+      metric_name = self._add_unique_metric_name(\n+          metric_name, metric_fn, output_index)\n \n       # Update the name on the metric class to be the unique generated name.\n       metric_fn._name = metric_name  # pylint: disable=protected-access\n\n@@ -23,6 +23,7 @@ from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n \n+import re\n \n from tensorflow.python.feature_column import feature_column_v2\n from keras.engine.base_layer import Layer\n@@ -75,8 +76,7 @@ class _BaseFeaturesLayer(Layer):\n       with tf.compat.v1.variable_scope(\n           self.name, partitioner=self._partitioner):\n         with tf.compat.v1.variable_scope(\n-            feature_column_v2._sanitize_column_name_for_variable_scope(  # pylint: disable=protected-access\n-                column.name)):\n+            _sanitize_column_name_for_variable_scope(column.name)):\n           column.create_state(self._state_manager)\n     super(_BaseFeaturesLayer, self).build(None)\n \n@@ -142,3 +142,9 @@ class _BaseFeaturesLayer(Layer):\n         config['partitioner'], custom_objects)\n \n     return cls(**config_cp)\n+\n+\n+def _sanitize_column_name_for_variable_scope(name):\n+  \"\"\"Sanitizes user-provided feature names for use as variable scopes.\"\"\"\n+  invalid_char = re.compile('[^A-Za-z0-9_.\\\\-]')\n+  return invalid_char.sub('_', name)\n\n@@ -530,7 +530,8 @@ class Conv2D(Conv):\n   provide the keyword argument `input_shape`\n   (tuple of integers or `None`, does not include the sample axis),\n   e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n-  in `data_format=\"channels_last\"`.\n+  in `data_format=\"channels_last\"`. You can use `None` when\n+  a dimension has variable size.\n \n   Examples:\n \n\n@@ -19,7 +19,6 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import ops\n from tensorflow.python.framework import tensor_shape\n from keras import backend as K\n from keras import constraints\n@@ -510,8 +509,8 @@ class BatchNormalizationBase(Layer):\n     self.built = True\n \n   def _assign_moving_average(self, variable, value, momentum, inputs_size):\n-    with K.name_scope('AssignMovingAvg') as scope:\n-      with ops.colocate_with(variable):\n+\n+    def calculate_update_delta():\n       decay = tf.convert_to_tensor(\n           1.0 - momentum, name='decay')\n       if decay.dtype != variable.dtype.base_dtype:\n@@ -520,11 +519,22 @@ class BatchNormalizationBase(Layer):\n       if inputs_size is not None:\n         update_delta = tf.compat.v1.where(inputs_size > 0, update_delta,\n                                        K.zeros_like(update_delta))\n-        return tf.compat.v1.assign_sub(variable, update_delta, name=scope)\n+      return update_delta\n+\n+    with K.name_scope('AssignMovingAvg') as scope:\n+      if tf.compat.v1.executing_eagerly_outside_functions():\n+        return variable.assign_sub(calculate_update_delta(), name=scope)\n+      else:\n+        with tf.compat.v1.colocate_with(variable):  # pylint: disable=protected-access\n+          return tf.compat.v1.assign_sub(\n+              variable, calculate_update_delta(), name=scope)\n \n   def _assign_new_value(self, variable, value):\n     with K.name_scope('AssignNewValue') as scope:\n-      with ops.colocate_with(variable):\n+      if tf.compat.v1.executing_eagerly_outside_functions():\n+        return variable.assign(value, name=scope)\n+      else:\n+        with tf.compat.v1.colocate_with(variable):  # pylint: disable=protected-access\n           return tf.compat.v1.assign(variable, value, name=scope)\n \n   def _fused_batch_norm(self, inputs, training):\n\n@@ -27,14 +27,10 @@ from keras.utils import layer_utils\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n-TFIDF = \"tf-idf\"\n INT = \"int\"\n BINARY = \"binary\"\n COUNT = \"count\"\n \n-# The inverse-document-frequency weights\n-_IDF_NAME = \"idf\"\n-\n \n @keras_export(\"keras.layers.experimental.preprocessing.CategoryEncoding\")\n class CategoryEncoding(base_preprocessing_layer.PreprocessingLayer):\n@@ -78,10 +74,10 @@ class CategoryEncoding(base_preprocessing_layer.PreprocessingLayer):\n       error will be thrown.\n     output_mode: Specification for the output of the layer.\n       Defaults to \"binary\". Values can\n-      be \"binary\", \"count\" or \"tf-idf\", configuring the layer as follows:\n-        \"binary\": Outputs a single int array per batch, of either vocab_size or\n-          num_tokens size, containing 1s in all elements where the token mapped\n-          to that index exists at least once in the batch item.\n+      be \"binary\" or \"count\", configuring the layer as follows:\n+        \"binary\": Outputs a single int array per batch, of num_tokens size,\n+          containing 1s in all elements where the token mapped to that index\n+          exists at least once in the batch item.\n         \"count\": As \"binary\", but the int array contains a count of the number\n           of times the token at that index appeared in the batch item.\n     sparse: Boolean. If true, returns a `SparseTensor` instead of a dense\n@@ -91,7 +87,7 @@ class CategoryEncoding(base_preprocessing_layer.PreprocessingLayer):\n     inputs: A 2D tensor `(samples, timesteps)`.\n     count_weights: A 2D tensor in the same shape as `inputs` indicating the\n       weight for each sample value when summing up in `count` mode. Not used in\n-      `binary` or `tfidf` mode.\n+      `binary` mode.\n   \"\"\"\n \n   def __init__(self,\n@@ -132,12 +128,11 @@ class CategoryEncoding(base_preprocessing_layer.PreprocessingLayer):\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape.as_list())\n-    output_dtype = K.floatx() if self.output_mode == TFIDF else tf.int64\n     if self.sparse:\n       return tf.SparseTensorSpec(\n-          shape=output_shape, dtype=output_dtype)\n+          shape=output_shape, dtype=tf.int64)\n     else:\n-      return tf.TensorSpec(shape=output_shape, dtype=output_dtype)\n+      return tf.TensorSpec(shape=output_shape, dtype=tf.int64)\n \n   def get_config(self):\n     config = {\n@@ -155,8 +150,8 @@ class CategoryEncoding(base_preprocessing_layer.PreprocessingLayer):\n       inputs = tf.compat.v1.expand_dims(inputs, 1)\n \n     if count_weights is not None and self.output_mode != COUNT:\n-      raise ValueError(\"count_weights is not used in `output_mode='tf-idf'`, \"\n-                       \"or `output_mode='binary'`. Please pass a single input.\")\n+      raise ValueError(\"count_weights is not used in `output_mode='binary'`. \"\n+                       \"Please pass a single input.\")\n \n     out_depth = self.num_tokens\n     binary_output = (self.output_mode == BINARY)\n\n@@ -20,7 +20,6 @@ from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n \n-\n from absl.testing import parameterized\n import numpy as np\n \n@@ -32,10 +31,6 @@ from keras.layers.preprocessing import category_encoding\n from keras.layers.preprocessing import preprocessing_test_utils\n \n \n-def get_layer_class():\n-  return category_encoding.CategoryEncoding\n-\n-\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class CategoryEncodingInputTest(keras_parameterized.TestCase,\n                                 preprocessing_test_utils.PreprocessingLayerTest\n@@ -45,15 +40,14 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     input_array = tf.constant([[1, 2, 3], [3, 3, 0]])\n \n     # The expected output should be (X for missing value):\n-    # [[X, 1, 1, 1]\n-    #  [1, X, X, X]\n-    #  [X, X, X, 2]]\n+    # [[X, 1, 1, 1, X, X]\n+    #  [1, X, X, 2, X, X]]\n     expected_indices = [[0, 1], [0, 2], [0, 3], [1, 0], [1, 3]]\n     expected_values = [1, 1, 1, 1, 2]\n     num_tokens = 6\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT, sparse=True)\n     int_data = layer(input_data)\n \n@@ -63,7 +57,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     self.assertAllEqual(expected_indices, sp_output_dataset.indices)\n \n     # Assert sparse output is same as dense output.\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens,\n         output_mode=category_encoding.COUNT,\n         sparse=False)\n@@ -87,7 +81,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int64, sparse=True)\n \n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.BINARY)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -112,7 +106,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     input_data = keras.Input(shape=(None,), dtype=tf.int64, sparse=True)\n     weight_data = keras.Input(shape=(None,), dtype=tf.float32, sparse=True)\n \n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT)\n     int_data = layer(input_data, count_weights=weight_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -138,7 +132,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     expected_values = [1, 1, 2, 1]\n     num_tokens = 6\n \n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT, sparse=True)\n     int_data = layer(input_data)\n \n@@ -148,7 +142,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     self.assertAllEqual(expected_indices, sp_output_dataset.indices)\n \n     # Assert sparse output is same as dense output.\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens,\n         output_mode=category_encoding.COUNT,\n         sparse=False)\n@@ -177,7 +171,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     expected_values = [.1, .2, .7, .2]\n     num_tokens = 6\n \n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT, sparse=True)\n     int_data = layer(input_data, count_weights=weight_data)\n \n@@ -198,7 +192,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32, ragged=True)\n \n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.BINARY)\n     int_data = layer(input_data)\n \n@@ -219,7 +213,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     num_tokens = 6\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32, ragged=True)\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT, sparse=True)\n     int_data = layer(input_data)\n \n@@ -229,7 +223,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     self.assertAllEqual(expected_indices, sp_output_dataset.indices)\n \n     # Assert sparse output is same as dense output.\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens,\n         output_mode=category_encoding.COUNT,\n         sparse=False)\n@@ -246,7 +240,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     num_tokens = 4\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    encoding_layer = get_layer_class()(\n+    encoding_layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.COUNT, sparse=True)\n     int_data = encoding_layer(input_data)\n     dense_layer = keras.layers.Dense(units=1)\n@@ -259,7 +253,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     input_array = tf.constant([[0, 1, 2], [2, 3, 1]])\n     num_tokens = 3\n     expected_output_shape = [None, num_tokens]\n-    encoder_layer = get_layer_class()(num_tokens)\n+    encoder_layer = category_encoding.CategoryEncoding(num_tokens)\n     input_data = keras.Input(shape=(3,), dtype=tf.int32)\n     int_data = encoder_layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -273,7 +267,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     input_array = tf.constant([[1, 2, 0], [2, 2, -1]])\n     num_tokens = 3\n     expected_output_shape = [None, num_tokens]\n-    encoder_layer = get_layer_class()(num_tokens)\n+    encoder_layer = category_encoding.CategoryEncoding(num_tokens)\n     input_data = keras.Input(shape=(3,), dtype=tf.int32)\n     int_data = encoder_layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -290,7 +284,7 @@ class CategoryEncodingInputTest(keras_parameterized.TestCase,\n     expected_output_shape = [None, num_tokens]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         max_tokens=num_tokens, output_mode=category_encoding.BINARY)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -317,7 +311,7 @@ class CategoryEncodingOutputTest(keras_parameterized.TestCase,\n     expected_output_shape = [None, num_tokens]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    layer = get_layer_class()(\n+    layer = category_encoding.CategoryEncoding(\n         num_tokens=num_tokens, output_mode=category_encoding.BINARY)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n@@ -337,7 +331,8 @@ class CategoryEncodingOutputTest(keras_parameterized.TestCase,\n     expected_output_shape = [None, num_tokens]\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    layer = get_layer_class()(num_tokens=6, output_mode=category_encoding.COUNT)\n+    layer = category_encoding.CategoryEncoding(\n+        num_tokens=6, output_mode=category_encoding.COUNT)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n@@ -364,7 +359,8 @@ class CategoryEncodingModelBuildingTest(\n     input_array = np.array([[1, 2, 3, 1], [0, 3, 1, 0]])\n \n     input_data = keras.Input(shape=(None,), dtype=tf.int32)\n-    layer = get_layer_class()(num_tokens=num_tokens, output_mode=output_mode)\n+    layer = category_encoding.CategoryEncoding(\n+        num_tokens=num_tokens, output_mode=output_mode)\n \n     weights = []\n     if num_tokens is None:\n\n@@ -171,9 +171,8 @@ class FunctionalPreprocessingStage(functional.Functional,\n     \"\"\"\n     if not isinstance(data, tf.data.Dataset):\n       data = self._flatten_to_reference_inputs(data)\n-      if any([\n-          not isinstance(datum, (np.ndarray, tf.__internal__.EagerTensor)) for datum in data\n-      ]):\n+      if any(not isinstance(datum, (np.ndarray, tf.__internal__.EagerTensor))\n+             for datum in data):\n         raise ValueError(\n             '`adapt()` requires a batched Dataset, a list of EagerTensors '\n             'or Numpy arrays as input, got {}'.format(type(data)))\n\n@@ -38,7 +38,6 @@ from keras.utils import generic_utils\n from keras.utils import tf_utils\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.training.tracking import base as trackable\n-from tensorflow.python.training.tracking import data_structures\n from tensorflow.python.util.tf_export import keras_export\n from tensorflow.tools.docs import doc_controls\n \n@@ -2334,13 +2333,7 @@ class LSTMCell(DropoutRNNCellMixin, Layer):\n       self.implementation = 1\n     else:\n       self.implementation = implementation\n-    # tuple(_ListWrapper) was silently dropping list content in at least 2.7.10,\n-    # and fixed after 2.7.16. Converting the state_size to wrapper around\n-    # NoDependency(), so that the base_layer.__setattr__ will not convert it to\n-    # ListWrapper. Down the stream, self.states will be a list since it is\n-    # generated from nest.map_structure with list, and tuple(list) will work\n-    # properly.\n-    self.state_size = data_structures.NoDependency([self.units, self.units])\n+    self.state_size = [self.units, self.units]\n     self.output_size = self.units\n \n   @tf_utils.shape_type_conversion\n\n@@ -23,8 +23,8 @@ import abc\n import functools\n \n import six\n+from tensorflow.python.framework import smart_cond\n from keras import backend as K\n-from keras.utils import control_flow_util\n from keras.utils import losses_utils\n from keras.utils import tf_utils\n from keras.utils.generic_utils import deserialize_keras_object\n@@ -1348,6 +1348,14 @@ def mean_absolute_percentage_error(y_true, y_pred):\n   return 100. * K.mean(diff, axis=-1)\n \n \n+@dispatch.dispatch_for_types(mean_absolute_percentage_error,\n+                             tf.RaggedTensor)\n+def _ragged_tensor_mape(y_true, y_pred):\n+  \"\"\" Support RaggedTensors.\"\"\"\n+  return _ragged_tensor_apply_loss(mean_absolute_percentage_error, y_true,\n+                                   y_pred)\n+\n+\n @keras_export('keras.metrics.mean_squared_logarithmic_error',\n               'keras.metrics.msle', 'keras.metrics.MSLE',\n               'keras.losses.mean_squared_logarithmic_error',\n@@ -1385,6 +1393,14 @@ def mean_squared_logarithmic_error(y_true, y_pred):\n   return K.mean(tf.math.squared_difference(first_log, second_log), axis=-1)\n \n \n+@dispatch.dispatch_for_types(mean_squared_logarithmic_error,\n+                             tf.RaggedTensor)\n+def _ragged_tensor_msle(y_true, y_pred):\n+  \"\"\" Implements support for handling RaggedTensors.\"\"\"\n+  return _ragged_tensor_apply_loss(mean_squared_logarithmic_error, y_true,\n+                                   y_pred)\n+\n+\n def _maybe_convert_labels(y_true):\n   \"\"\"Converts binary labels into -1/1.\"\"\"\n   are_zeros = tf.equal(y_true, 0)\n@@ -1395,8 +1411,8 @@ def _maybe_convert_labels(y_true):\n     # Convert the binary labels to -1 or 1.\n     return 2. * y_true - 1.\n \n-  updated_y_true = control_flow_util.smart_cond(\n-      is_binary, _convert_binary_labels, lambda: y_true)\n+  updated_y_true = smart_cond.smart_cond(is_binary, _convert_binary_labels,\n+                                         lambda: y_true)\n   return updated_y_true\n \n \n@@ -1613,8 +1629,8 @@ def categorical_crossentropy(y_true,\n     num_classes = tf.cast(tf.compat.v1.shape(y_true)[-1], y_pred.dtype)\n     return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)\n \n-  y_true = control_flow_util.smart_cond(\n-      label_smoothing, _smooth_labels, lambda: y_true)\n+  y_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,\n+                                 lambda: y_true)\n   return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n \n \n@@ -1710,8 +1726,8 @@ def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):\n   def _smooth_labels():\n     return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n \n-  y_true = control_flow_util.smart_cond(\n-      label_smoothing, _smooth_labels, lambda: y_true)\n+  y_true = smart_cond.smart_cond(label_smoothing, _smooth_labels,\n+                                 lambda: y_true)\n   return K.mean(\n       K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n \n\n@@ -550,6 +550,15 @@ class MeanAbsolutePercentageErrorTest(tf.test.TestCase):\n     loss = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n     self.assertAlmostEqual(self.evaluate(loss), 422.8888, 3)\n \n+  def test_ragged_tensors(self):\n+    mape_obj = losses.MeanAbsolutePercentageError()\n+    y_true = tf.ragged.constant([[1, 9, 2], [-5, -2]])\n+    y_pred = tf.ragged.constant([[4, 8, 12], [8, 1]],\n+                                         dtype=tf.float32)\n+    sample_weight = tf.constant([1.2, 3.4], shape=(2, 1))\n+    loss = mape_obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAlmostEqual(self.evaluate(loss), 510.7222, 3)\n+\n   def test_timestep_weighted(self):\n     mape_obj = losses.MeanAbsolutePercentageError()\n     y_true = tf.constant([1, 9, 2, -5, -2, 6], shape=(2, 3, 1))\n@@ -637,6 +646,18 @@ class MeanSquaredLogarithmicErrorTest(tf.test.TestCase):\n     loss = msle_obj(y_true, y_pred, sample_weight=0)\n     self.assertAlmostEqual(self.evaluate(loss), 0.0, 3)\n \n+  def test_ragged_tensors(self):\n+    msle_obj = losses.MeanSquaredLogarithmicError()\n+    y_true = tf.ragged.constant([[1, 9, 2], [-5, -2]])\n+    # log(max(y_true, 0) + 1): [[0.69314, 2.3025, 1.0986], [0., 0.]]\n+    y_pred = tf.ragged.constant([[4, 8, 12], [8, 1]],\n+                                         dtype=tf.float32)\n+    # log(max(y_pred, 0) + 1): [[1.6094, 2.1972, 2.5649], [2.1972, 0.6932]]\n+    # per batch loss: [1.0002, 2.6541]\n+    sample_weight = tf.constant([1.2, 3.4], shape=(2, 1))\n+    loss = msle_obj(y_true, y_pred, sample_weight=sample_weight)\n+    self.assertAlmostEqual(self.evaluate(loss), 5.1121, 3)\n+\n \n @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n class CosineSimilarityTest(tf.test.TestCase):\n\n@@ -18,12 +18,11 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n-from tensorflow.python.framework import ops\n+from tensorflow.python.framework import smart_cond\n from keras import backend\n from keras import optimizers\n from keras.mixed_precision import loss_scale as keras_loss_scale_module\n from keras.optimizer_v2 import optimizer_v2\n-from keras.utils import control_flow_util\n from tensorflow.python.platform import tf_logging\n from tensorflow.python.training.experimental import mixed_precision\n from tensorflow.python.training.tracking import base as trackable\n@@ -309,7 +308,7 @@ class _DynamicLossScaleState(tf.__internal__.tracking.Trackable):\n \n   def __call__(self):\n     \"\"\"Returns the current loss scale as a scalar `float32` tensor.\"\"\"\n-    return ops.convert_to_tensor(self._current_loss_scale)\n+    return tf.convert_to_tensor(self._current_loss_scale)\n \n   def update(self, grads):\n     \"\"\"Updates the value of the loss scale.\n@@ -553,9 +552,10 @@ class LossScaleOptimizer(_DelegatingTrackableMixin, optimizer_v2.OptimizerV2):\n   def loss_scale(self):\n     \"\"\"The current loss scale as a float32 scalar tensor.\"\"\"\n     if isinstance(self._loss_scale, _DynamicLossScaleState):\n-      return ops.convert_to_tensor(self._loss_scale.current_loss_scale)\n+      return tf.convert_to_tensor(\n+          self._loss_scale.current_loss_scale)\n     else:\n-      return ops.convert_to_tensor(self._loss_scale)\n+      return tf.convert_to_tensor(self._loss_scale)\n \n   @property\n   def dynamic_counter(self):\n@@ -727,8 +727,8 @@ class LossScaleOptimizer(_DelegatingTrackableMixin, optimizer_v2.OptimizerV2):\n     # DistributionStrategy does not support having a cond in a replica context\n     # with a branch that calls `merge_call`, and self._optimizer.apply_gradients\n     # calls `merge_call`.\n-    maybe_apply_op = control_flow_util.smart_cond(\n-        should_apply_grads, apply_fn, do_not_apply_fn)\n+    maybe_apply_op = smart_cond.smart_cond(should_apply_grads, apply_fn,\n+                                           do_not_apply_fn)\n     return tf.group(maybe_apply_op, loss_scale_update_op)\n \n   def _apply_gradients(self, grads, wrapped_vars, name,\n\n@@ -25,6 +25,7 @@ import os\n import shutil\n import sys\n import tempfile\n+import warnings\n \n from absl.testing import parameterized\n import numpy as np\n@@ -302,17 +303,17 @@ class TestSaveModel(tf.test.TestCase, parameterized.TestCase):\n       shape_from_key = reader.get_variable_to_shape_map()\n       return sorted(shape_from_key.keys())\n \n+    path = os.path.join(self.get_temp_dir(), 'no_optimizer')\n+    x, y = np.ones((10, 10)), np.ones((10, 1))\n+\n     with self.cached_session():\n       model = keras.models.Sequential()\n       model.add(keras.layers.Dense(1))\n       model.compile('adam', loss='mse')\n-      x, y = np.ones((10, 10)), np.ones((10, 1))\n       model.train_on_batch(x, y)\n-\n-      path = os.path.join(self.get_temp_dir(), 'no_optimizer')\n       model.save(path, save_format='tf', include_optimizer=False)\n-      variables = get_variables(path)\n \n+    variables = get_variables(path)\n     for v in variables:\n       self.assertNotIn('optimizer', v)\n \n@@ -994,13 +995,14 @@ class TestWholeModelSaving(keras_parameterized.TestCase):\n     loaded = keras.models.load_model(saved_model_dir)\n     self.assertIs(loaded.layers[1], loaded.layers[2].layer)\n \n-  @combinations.generate(combinations.combine(mode=['eager']))\n+  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n   def test_multi_output_metrics_name_stay_same(self):\n     \"\"\"Tests that metric names don't change with each save/load cycle.\n \n     e.g. \"head_0_accuracy\" should not become \"head_0_head_0_accuracy\" after\n     saving and loading a model.\n     \"\"\"\n+    with self.cached_session():\n       input_ = keras.Input((4,))\n       model = keras.Model(\n           input_,\n@@ -1027,6 +1029,54 @@ class TestWholeModelSaving(keras_parameterized.TestCase):\n     # model.\n     self.assertSequenceEqual(model.metrics_names, loaded.metrics_names)\n \n+  @combinations.generate(combinations.combine(mode=['graph', 'eager']))\n+  def test_warning_when_saving_invalid_custom_mask_layer(self):\n+\n+    class MyMasking(keras.layers.Layer):\n+\n+      def call(self, inputs):\n+        return inputs\n+\n+      def compute_mask(self, inputs, mask=None):\n+        mask = tf.not_equal(inputs, 0)\n+        return mask\n+\n+    class MyLayer(keras.layers.Layer):\n+\n+      def call(self, inputs, mask=None):\n+        return tf.identity(inputs)\n+\n+    samples = np.random.random((2, 2))\n+    model = keras.Sequential([MyMasking(), MyLayer()])\n+    model.predict(samples)\n+    with warnings.catch_warnings(record=True) as w:\n+      model.save(self._save_model_dir(), testing_utils.get_save_format())\n+    self.assertIn(generic_utils.CustomMaskWarning,\n+                  {warning.category for warning in w})\n+\n+    # Test that setting up a custom mask correctly does not issue a warning.\n+    class MyCorrectMasking(keras.layers.Layer):\n+\n+      def call(self, inputs):\n+        return inputs\n+\n+      def compute_mask(self, inputs, mask=None):\n+        mask = tf.not_equal(inputs, 0)\n+        return mask\n+\n+      # This get_config doesn't actually do anything because our mask is\n+      # static and doesn't need any external information to work. We do need a\n+      # dummy get_config method to prevent the warning from appearing, however.\n+      def get_config(self, *args, **kwargs):\n+        return {}\n+\n+    model = keras.Sequential([MyCorrectMasking(), MyLayer()])\n+    model.predict(samples)\n+    with warnings.catch_warnings(record=True) as w:\n+      model.save(self._save_model_dir(), testing_utils.get_save_format())\n+    self.assertNotIn(generic_utils.CustomMaskWarning,\n+                     {warning.category for warning in w})\n+\n \n # Factory functions to create models that will be serialized inside a Network.\n def _make_graph_network(input_size, output_size):\n\n@@ -688,7 +688,7 @@ class KerasObjectLoader(object):\n       model.__init__(inputs, outputs, name=config['name'])\n       functional_lib.connect_ancillary_layers(model, created_layers)\n \n-    # Set model dtype and trainable status.\n+    # Set model dtype.\n     _set_network_attributes_from_metadata(model)\n \n     # Unblock models that are dependent on this model.\n@@ -1153,7 +1153,7 @@ def _set_network_attributes_from_metadata(revived_obj):\n     metadata = revived_obj._serialized_attributes['metadata']\n     if metadata.get('dtype') is not None:\n       revived_obj._set_dtype_policy(metadata['dtype'])\n-    revived_obj.trainable = metadata['trainable']\n+    revived_obj._trainable = metadata['trainable']\n     # pylint:enable=protected-access\n \n \n\n@@ -107,7 +107,7 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     self.addCleanup(shutil.rmtree, temp_dir, ignore_errors=True)\n     return os.path.join(temp_dir, dirname)\n \n-  def _test_save_and_load(self, use_dataset=False):\n+  def _get_model(self):\n     model = testing_utils.get_small_mlp(1, 4, input_dim=3)\n     model.layers[-1].activity_regularizer = regularizers.get('l2')\n     model.activity_regularizer = regularizers.get('l2')\n@@ -117,7 +117,9 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     def callable_loss():\n       return tf.reduce_sum(model.weights[0])\n     model.add_loss(callable_loss)\n+    return model\n \n+  def _train_model(self, model, use_dataset=False):\n     x = np.random.random((1, 3))\n     y = np.random.random((1, 4))\n \n@@ -133,9 +135,14 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     else:\n       model.train_on_batch(x, y)\n \n+  def _save_and_load(self, model):\n     saved_model_dir = self._save_model_dir()\n     tf.saved_model.save(model, saved_model_dir)\n     loaded = keras_load.load(saved_model_dir)\n+    return loaded\n+\n+  def _test_evaluation(self, model, loaded):\n+    # Assert that original and loaded models have the same results when called.\n     self.evaluate(tf.compat.v1.variables_initializer(loaded.variables))\n     self.assertAllClose(self.evaluate(model.weights),\n                         self.evaluate(loaded.weights))\n@@ -158,13 +165,20 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n \n   @keras_parameterized.run_with_all_model_types\n   def test_model_save_and_load(self):\n-    self._test_save_and_load(use_dataset=True)\n+    model = self._get_model()\n+    self._train_model(model, use_dataset=False)\n+    loaded = self._save_and_load(model)\n+    self._test_evaluation(model, loaded)\n \n   @keras_parameterized.run_with_all_model_types\n   def test_model_save_and_load_dataset(self):\n-    self._test_save_and_load(use_dataset=True)\n+    model = self._get_model()\n+    self._train_model(model, use_dataset=True)\n+    loaded = self._save_and_load(model)\n+    self._test_evaluation(model, loaded)\n \n   def test_trainable_weights(self):\n+    \"\"\"Tests that trainable status of individual weights is preserved.\"\"\"\n     layer = keras.layers.Dense(4, name='custom_layer')\n     layer.build([3,])\n     layer.add_weight(\n@@ -191,6 +205,31 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n       self.assertAllClose(self.evaluate(getattr(layer, attr)),\n                           self.evaluate(getattr(loaded, attr)))\n \n+  @keras_parameterized.run_with_all_model_types\n+  def test_trainable_layers(self):\n+    \"\"\"Tests that trainable status of individual layers is preserved.\"\"\"\n+    model = model = self._get_model()\n+    # Set the last layer to *not* be trainable.\n+    model.layers[-1].trainable = False\n+    self._train_model(model, use_dataset=True)\n+    loaded = self._save_and_load(model)\n+\n+    self._test_evaluation(model, loaded)\n+    self.assertFalse(model.layers[-1].trainable)\n+    self.assertFalse(loaded.layers[-1].trainable)\n+\n+  def test_trainable_custom_model_false(self):\n+    \"\"\"Tests that overall False trainable status of Model is preserved.\"\"\"\n+    # Set all layers to *not* be trainable.\n+    model = testing_utils.SmallSubclassMLP(1, 4, trainable=False)\n+    model.compile(loss='mse', optimizer='rmsprop')\n+    self._train_model(model, use_dataset=False)\n+    loaded = self._save_and_load(model)\n+\n+    self._test_evaluation(model, loaded)\n+    self.assertEmpty(model.trainable_variables)\n+    self.assertEmpty(loaded.trainable_variables)\n+\n   def test_maintains_losses(self):\n     \"\"\"Tests that the layer losses do not change before and after export.\"\"\"\n     model = keras.models.Sequential([LayerWithLoss()])\n\n@@ -462,8 +462,13 @@ def get_small_functional_mlp(num_hidden, num_classes, input_dim):\n class SmallSubclassMLP(models.Model):\n   \"\"\"A subclass model based small MLP.\"\"\"\n \n-  def __init__(self, num_hidden, num_classes, use_bn=False, use_dp=False):\n-    super(SmallSubclassMLP, self).__init__(name='test_model')\n+  def __init__(self,\n+               num_hidden,\n+               num_classes,\n+               use_bn=False,\n+               use_dp=False,\n+               **kwargs):\n+    super(SmallSubclassMLP, self).__init__(name='test_model', **kwargs)\n     self.use_bn = use_bn\n     self.use_dp = use_dp\n \n\n@@ -23,6 +23,7 @@ from __future__ import division\n from __future__ import print_function\n \n import tensorflow.compat.v2 as tf\n+from tensorflow.python.framework import smart_cond as smart_module\n \n \n def InXlaContext(graph):\n@@ -107,21 +108,8 @@ def smart_cond(pred, true_fn=None, false_fn=None, name=None):  # pylint: disable\n   if isinstance(pred, tf.Variable):\n     return tf.compat.v1.cond(\n         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n-\n-  if not callable(true_fn):\n-    raise TypeError(\"`true_fn` must be callable.\")\n-  if not callable(false_fn):\n-    raise TypeError(\"`false_fn` must be callable.\")\n-\n-  pred_value = constant_value(pred)\n-  if pred_value is not None:\n-    if pred_value:\n-      return true_fn()\n-    else:\n-      return false_fn()\n-  else:\n-    return tf.compat.v1.cond(pred, true_fn=true_fn, false_fn=false_fn,\n-                                 name=name)\n+  return smart_module.smart_cond(\n+      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n \n \n def constant_value(pred):  # pylint: disable=invalid-name\n\n@@ -694,8 +694,6 @@ class SequenceEnqueuer(object):\n class OrderedEnqueuer(SequenceEnqueuer):\n   \"\"\"Builds a Enqueuer from a Sequence.\n \n-  Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n-\n   Args:\n       sequence: A `tf.keras.utils.data_utils.Sequence` object.\n       use_multiprocessing: use multiprocessing if True, otherwise threading\n@@ -832,20 +830,17 @@ class GeneratorEnqueuer(SequenceEnqueuer):\n   The provided generator can be finite in which case the class will throw\n   a `StopIteration` exception.\n \n-  Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n-\n   Args:\n       generator: a generator function which yields data\n       use_multiprocessing: use multiprocessing if True, otherwise threading\n-      wait_time: time to sleep in-between calls to `put()`\n       random_seed: Initial seed for workers,\n           will be incremented by one for each worker.\n   \"\"\"\n \n-  def __init__(self, sequence,\n+  def __init__(self, generator,\n                use_multiprocessing=False,\n                random_seed=None):\n-    super(GeneratorEnqueuer, self).__init__(sequence, use_multiprocessing)\n+    super(GeneratorEnqueuer, self).__init__(generator, use_multiprocessing)\n     self.random_seed = random_seed\n \n   def _get_executor_init(self, workers):\n\n@@ -29,6 +29,7 @@ import sys\n import threading\n import time\n import types as python_types\n+import warnings\n import weakref\n \n import numpy as np\n@@ -460,6 +461,12 @@ def get_registered_object(name, custom_objects=None, module_objects=None):\n   return None\n \n \n+# pylint: disable=g-bad-exception-name\n+class CustomMaskWarning(Warning):\n+  pass\n+# pylint: enable=g-bad-exception-name\n+\n+\n @keras_export('keras.utils.serialize_keras_object')\n def serialize_keras_object(instance):\n   \"\"\"Serialize a Keras object into a JSON-compatible representation.\n@@ -479,6 +486,20 @@ def serialize_keras_object(instance):\n   if instance is None:\n     return None\n \n+  # pylint: disable=protected-access\n+  #\n+  # For v1 layers, checking supports_masking is not enough. We have to also\n+  # check whether compute_mask has been overridden.\n+  supports_masking = (getattr(instance, 'supports_masking', False)\n+                      or (hasattr(instance, 'compute_mask')\n+                          and not is_default(instance.compute_mask)))\n+  if supports_masking and is_default(instance.get_config):\n+    warnings.warn('Custom mask layers require a config and must override '\n+                  'get_config. When loading, the custom mask layer must be '\n+                  'passed to the custom_objects argument.',\n+                  category=CustomMaskWarning)\n+  # pylint: enable=protected-access\n+\n   if hasattr(instance, 'get_config'):\n     name = get_registered_name(instance.__class__)\n     try:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
