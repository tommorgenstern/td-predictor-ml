{"custom_id": "keras#a99929176052e0c98cf3c7916d12b88633cab535", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 46 | Lines Deleted: 34 | Files Changed: 2 | Hunks: 20 | Methods Changed: 10 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 80 | Churn Cumulative: 1980 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: 0.25\n\nDIFF:\n@@ -119,8 +119,9 @@ def _concat(prefix, suffix, static=False):\n     if p.shape.ndims == 0:\n       p = tf.compat.v1.expand_dims(p, 0)\n     elif p.shape.ndims != 1:\n-      raise ValueError(\"prefix tensor must be either a scalar or vector, \"\n-                       \"but saw tensor: %s\" % p)\n+      raise ValueError(\n+          \"Prefix tensor must be either a scalar or vector, \"\n+          f\"but received tensor: {p}\")\n   else:\n     p = tf.TensorShape(prefix)\n     p_static = p.as_list() if p.ndims is not None else None\n@@ -134,7 +135,7 @@ def _concat(prefix, suffix, static=False):\n       s = tf.compat.v1.expand_dims(s, 0)\n     elif s.shape.ndims != 1:\n       raise ValueError(\"suffix tensor must be either a scalar or vector, \"\n-                       \"but saw tensor: %s\" % s)\n+                       f\"but received tensor: {s}\")\n   else:\n     s = tf.TensorShape(suffix)\n     s_static = s.as_list() if s.ndims is not None else None\n@@ -147,8 +148,9 @@ def _concat(prefix, suffix, static=False):\n     shape = shape.as_list() if shape.ndims is not None else None\n   else:\n     if p is None or s is None:\n-      raise ValueError(\"Provided a prefix or suffix of None: %s and %s\" %\n-                       (prefix, suffix))\n+      raise ValueError(\n+          \"Prefix or suffix can't be None. \"\n+          f\"Received prefix = {prefix} and suffix = {suffix}\")\n     shape = tf.concat((p, s), 0)\n   return shape\n \n@@ -281,21 +283,20 @@ class RNNCell(base_layer.Layer):\n         if inputs.shape.dims[0].value != static_batch_size:\n           raise ValueError(\n               \"batch size from input tensor is different from the \"\n-              \"input param. Input tensor batch: {}, batch_size: {}\".format(\n-                  inputs.shape.dims[0].value, batch_size))\n+              f\"input param. Input tensor batch: {inputs.shape.dims[0].value}, \"\n+              f\"batch_size: {batch_size}\")\n \n       if dtype is not None and inputs.dtype != dtype:\n         raise ValueError(\n             \"dtype from input tensor is different from the \"\n-            \"input param. Input tensor dtype: {}, dtype: {}\".format(\n-                inputs.dtype, dtype))\n+            f\"input param. Input tensor dtype: {inputs.dtype}, dtype: {dtype}\")\n \n       batch_size = inputs.shape.dims[0].value or tf.compat.v1.shape(inputs)[0]\n       dtype = inputs.dtype\n     if batch_size is None or dtype is None:\n       raise ValueError(\n           \"batch_size and dtype cannot be None while constructing initial \"\n-          \"state: batch_size={}, dtype={}\".format(batch_size, dtype))\n+          f\"state: batch_size={batch_size}, dtype={dtype}\")\n     return self.zero_state(batch_size, dtype)\n \n   def zero_state(self, batch_size, dtype):\n@@ -445,8 +446,9 @@ class BasicRNNCell(LayerRNNCell):\n   @tf_utils.shape_type_conversion\n   def build(self, inputs_shape):\n     if inputs_shape[-1] is None:\n-      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n-                       str(inputs_shape))\n+      raise ValueError(\n+          \"Expected inputs.shape[-1] to be known, \"\n+          f\"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n \n     input_depth = inputs_shape[-1]\n@@ -556,8 +558,9 @@ class GRUCell(LayerRNNCell):\n   @tf_utils.shape_type_conversion\n   def build(self, inputs_shape):\n     if inputs_shape[-1] is None:\n-      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n-                       str(inputs_shape))\n+      raise ValueError(\n+          \"Expected inputs.shape[-1] to be known, \"\n+          f\"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n     input_depth = inputs_shape[-1]\n     self._gate_kernel = self.add_variable(\n@@ -635,8 +638,8 @@ class LSTMStateTuple(_LSTMStateTuple):\n   def dtype(self):\n     (c, h) = self\n     if c.dtype != h.dtype:\n-      raise TypeError(\"Inconsistent internal state: %s vs %s\" %\n-                      (str(c.dtype), str(h.dtype)))\n+      raise TypeError(\"Inconsistent dtypes for internal state: \"\n+                      f\"{c.dtype} vs {h.dtype}\")\n     return c.dtype\n \n \n@@ -736,8 +739,9 @@ class BasicLSTMCell(LayerRNNCell):\n   @tf_utils.shape_type_conversion\n   def build(self, inputs_shape):\n     if inputs_shape[-1] is None:\n-      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n-                       str(inputs_shape))\n+      raise ValueError(\n+          \"Expected inputs.shape[-1] to be known, \"\n+          f\"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n     input_depth = inputs_shape[-1]\n     h_depth = self._num_units\n@@ -960,8 +964,9 @@ class LSTMCell(LayerRNNCell):\n   @tf_utils.shape_type_conversion\n   def build(self, inputs_shape):\n     if inputs_shape[-1] is None:\n-      raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n-                       str(inputs_shape))\n+      raise ValueError(\n+          \"Expected inputs.shape[-1] to be known, \"\n+          \"received shape: {inputs_shape}\")\n     _check_supported_dtypes(self.dtype)\n     input_depth = inputs_shape[-1]\n     h_depth = self._num_units if self._num_proj is None else self._num_proj\n@@ -1038,7 +1043,9 @@ class LSTMCell(LayerRNNCell):\n \n     input_size = inputs.get_shape().with_rank(2).dims[1].value\n     if input_size is None:\n-      raise ValueError(\"Could not infer input size from inputs.get_shape()[-1]\")\n+      raise ValueError(\n+          \"Could not infer input size from inputs.get_shape()[-1].\"\n+          f\"Received input shape: {inputs.get_shape()}\")\n \n     # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n     lstm_matrix = tf.matmul(\n@@ -1248,7 +1255,7 @@ class MultiRNNCell(RNNCell):\n     if not cells:\n       raise ValueError(\"Must specify at least one cell for MultiRNNCell.\")\n     if not tf.nest.is_nested(cells):\n-      raise TypeError(\"cells must be a list or tuple, but saw: %s.\" % cells)\n+      raise TypeError(f\"cells must be a list or tuple, but received: {cells}.\")\n \n     if len(set(id(cell) for cell in cells)) < len(cells):\n       logging.log_first_n(\n@@ -1265,9 +1272,10 @@ class MultiRNNCell(RNNCell):\n     self._state_is_tuple = state_is_tuple\n     if not state_is_tuple:\n       if any(tf.nest.is_nested(c.state_size) for c in self._cells):\n-        raise ValueError(\"Some cells return tuples of states, but the flag \"\n-                         \"state_is_tuple is not set.  State sizes are: %s\" %\n-                         str([c.state_size for c in self._cells]))\n+        raise ValueError(\n+            \"Some cells return tuples of states, but the flag \"\n+            \"state_is_tuple is not set. \"\n+            f\"State sizes are: {[c.state_size for c in self._cells]}\")\n \n   @property\n   def state_size(self):\n@@ -1323,8 +1331,8 @@ class MultiRNNCell(RNNCell):\n         if self._state_is_tuple:\n           if not tf.nest.is_nested(state):\n             raise ValueError(\n-                \"Expected state to be a tuple of length %d, but received: %s\" %\n-                (len(self.state_size), state))\n+                f\"Expected state to be a tuple of length {len(self.state_size)}\"\n+                f\", but received: {state}\")\n           cur_state = state[i]\n         else:\n           cur_state = tf.slice(state, [0, cur_state_pos],\n@@ -1365,4 +1373,4 @@ def _check_supported_dtypes(dtype):\n   dtype = tf.as_dtype(dtype)\n   if not (dtype.is_floating or dtype.is_complex):\n     raise ValueError(\"RNN cell only supports floating point inputs, \"\n-                     \"but saw dtype: %s\" % dtype)\n+                     f\"but received dtype: {dtype}\")\n\n@@ -102,7 +102,8 @@ class DropoutWrapperBase:\n \n     if (dropout_state_filter_visitor is not None and\n         not callable(dropout_state_filter_visitor)):\n-      raise TypeError(\"dropout_state_filter_visitor must be callable\")\n+      raise TypeError(\"dropout_state_filter_visitor must be callable. \"\n+                      f\"Received: {dropout_state_filter_visitor}\")\n     self._dropout_state_filter = (\n         dropout_state_filter_visitor or _default_dropout_state_filter_visitor)\n     with tf.name_scope(\"DropoutWrapperInit\"):\n@@ -118,8 +119,9 @@ class DropoutWrapperBase:\n         tensor_prob, const_prob = tensor_and_const_value(prob)\n         if const_prob is not None:\n           if const_prob < 0 or const_prob > 1:\n-            raise ValueError(\"Parameter %s must be between 0 and 1: %d\" %\n-                             (attr, const_prob))\n+            raise ValueError(\n+                f\"Parameter {attr} must be between 0 and 1. \"\n+                \"Received {const_prob}\")\n           setattr(self, \"_%s\" % attr, float(const_prob))\n         else:\n           setattr(self, \"_%s\" % attr, tensor_prob)\n@@ -451,8 +453,8 @@ def _serialize_function_to_config(function):\n     output_type = \"function\"\n     module = function.__module__\n   else:\n-    raise ValueError(\"Unrecognized function type for input: {}\".format(\n-        type(function)))\n+    raise ValueError(\n+        f\"Unrecognized function type for input: {type(function)}\")\n \n   return output, output_type, module\n \n@@ -482,7 +484,9 @@ def _parse_config_to_function(config, custom_objects, func_attr_name,\n     function = generic_utils.func_load(\n         config[func_attr_name], globs=globs)\n   else:\n-    raise TypeError(\"Unknown function type:\", function_type)\n+    raise TypeError(\n+        f\"Unknown function type received: {function_type}. \"\n+        \"Expected types are ['function', 'lambda']\")\n   return function\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a0b123f2dde667c963e3a59bbc60af93372ded3c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 159 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -106,7 +106,8 @@ def inject_argument_info_in_traceback(fn, object_name=None):\n       arguments_context = []\n       for arg in list(signature.parameters.values()):\n         if arg.name in bound_signature.arguments:\n-          value = format_argument_value(bound_signature.arguments[arg.name])\n+          value = tf.nest.map_structure(\n+              format_argument_value, bound_signature.arguments[arg.name])\n         else:\n           value = arg.default\n         arguments_context.append(f'  • {arg.name}={value}')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#03e9bfaf7cf6c133f66dc4a28d68b55b9e9d2753", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 16 | Files Changed: 1 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 39 | Churn Cumulative: 15690 | Contributors (this commit): 108 | Commits (past 90d): 31 | Contributors (cumulative): 108 | DMM Complexity: 0.0\n\nDIFF:\n@@ -2547,12 +2547,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     # TODO(fchollet): We could build a dictionary based on layer names\n     # since they are constant, but we have not done that yet.\n     if index is not None and name is not None:\n-      raise ValueError('Provide only a layer name or a layer index.')\n+      raise ValueError('Provide only a layer name or a layer index. Received: '\n+                       f'index={index}, name={name}.')\n \n     if index is not None:\n       if len(self.layers) <= index:\n-        raise ValueError('Was asked to retrieve layer at index ' + str(index) +\n-                         ' but model only has ' + str(len(self.layers)) +\n+        raise ValueError(f'Was asked to retrieve layer at index {str(index)}'\n+                         f' but model only has {str(len(self.layers))}'\n                          ' layers.')\n       else:\n         return self.layers[index]\n@@ -2561,8 +2562,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       for layer in self.layers:\n         if layer.name == name:\n           return layer\n-      raise ValueError('No such layer: ' + name + '.')\n-    raise ValueError('Provide either a layer name or layer index.')\n+      raise ValueError(f'No such layer: {name}. Existing layers are '\n+                       f'{self.layers}.')\n+    raise ValueError('Provide either a layer name or layer index at '\n+                     '`get_layer`.')\n \n   @tf.__internal__.tracking.no_automatic_dependency_tracking\n   def _set_save_spec(self, inputs, args=None, kwargs=None):\n@@ -2664,10 +2667,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       # For any model that has customized build() method but hasn't\n       # been invoked yet, this will cover both sequential and subclass model.\n       # Also make sure to exclude Model class itself which has build() defined.\n-      raise ValueError('Weights for model %s have not yet been created. '\n+      raise ValueError(f'Weights for model {self.name} have not yet been '\n+                       'created. '\n                        'Weights are created when the Model is first called on '\n-                       'inputs or `build()` is called with an `input_shape`.' %\n-                       self.name)\n+                       'inputs or `build()` is called with an `input_shape`.')\n \n   def _check_call_args(self, method_name):\n     \"\"\"Check that `call()` has only one positional arg.\"\"\"\n@@ -2684,9 +2687,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     if len(positional_args) > 2:\n       extra_args = positional_args[2:]\n       raise ValueError(\n-          'Models passed to `' + method_name + '` can only have `training` '\n+          f'Models passed to `{method_name}` can only have `training` '\n           'and the first argument in `call()` as positional arguments, '\n-          'found: ' + str(extra_args) + '.')\n+          f'found: {str(extra_args)}.')\n \n   def _validate_compile(self, optimizer, metrics, **kwargs):\n     \"\"\"Performs validation checks for the default `compile()`.\"\"\"\n@@ -2694,20 +2697,24 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         isinstance(opt, optimizer_v1.Optimizer)\n         for opt in tf.nest.flatten(optimizer)):\n       raise ValueError(\n-          '`tf.compat.v1.keras` Optimizer (', optimizer, ') is '\n+          f'`tf.compat.v1.keras` Optimizer ({optimizer}) is '\n           'not supported when eager execution is enabled. Use a '\n           '`tf.keras` Optimizer instead, or disable eager '\n           'execution.')\n \n     kwargs.pop('cloning', None)  # Legacy DistStrat argument, never used.\n     kwargs.pop('experimental_run_tf_function', None)  # Always `True`.\n-    if kwargs.pop('distribute', None) is not None:\n+    distribute_arg = kwargs.pop('distribute', None)\n+    if distribute_arg is not None:\n       raise ValueError(\n-          'Distribute argument in compile is not available in TF 2.0 please '\n-          'create the model under the distribution strategy scope.')\n-    if kwargs.pop('target_tensors', None) is not None:\n+          '`distribute` argument in compile is not available in TF 2.0. Please '\n+          'create the model under the `strategy.scope()`. Received: '\n+          f'{distribute_arg}.')\n+    target_tensor_arg = kwargs.pop('target_tensors', None)\n+    if target_tensor_arg is not None:\n       raise ValueError(\n-          'target_tensors argument is not supported when executing eagerly.')\n+          '`target_tensors` argument is not supported when executing eagerly. '\n+          f'Received: {target_tensor_arg}.')\n     invalid_kwargs = set(kwargs) - {'sample_weight_mode'}\n     if invalid_kwargs:\n       raise TypeError('Invalid keyword argument(s) in `compile()`: %s' %\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd01c009ff1c839e71cfff8b6c3546b7597759c1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 29 | Lines Deleted: 19 | Files Changed: 1 | Hunks: 13 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 48 | Churn Cumulative: 1140 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -13,12 +13,11 @@\n # limitations under the License.\n # ==============================================================================\n \"\"\"Keras initializers for TF 2.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n # pylint: disable=g-classes-have-attributes\n \n import math\n from keras import backend\n+import tensorflow.compat.v2 as tf\n from tensorflow.python.ops import stateless_random_ops\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -76,7 +75,8 @@ class Initializer:\n       dtype: Optional dtype of the tensor.\n       **kwargs: Additional keyword arguments.\n     \"\"\"\n-    raise NotImplementedError\n+    raise NotImplementedError('Initializer subclasses must implement the '\n+                              '`__call__()` method.')\n \n   def get_config(self):\n     \"\"\"Returns the configuration of the initializer as a JSON-serializable dict.\n@@ -139,7 +139,7 @@ class Zeros(Initializer):\n     _validate_kwargs(self.__class__.__name__, kwargs)\n     dtype = _get_dtype(dtype)\n     if not dtype.is_numpy_compatible or dtype == tf.string:\n-      raise ValueError('Expected numeric or boolean dtype, got %s.' % dtype)\n+      raise ValueError(f'Expected numeric or boolean dtype, got {dtype}.')\n     if _PARTITION_SHAPE in kwargs:\n       shape = kwargs[_PARTITION_SHAPE]\n     return tf.zeros(shape, dtype)\n@@ -176,7 +176,7 @@ class Ones(Initializer):\n     _validate_kwargs(self.__class__.__name__, kwargs)\n     dtype = _get_dtype(dtype)\n     if not dtype.is_numpy_compatible or dtype == tf.string:\n-      raise ValueError('Expected numeric or boolean dtype, got %s.' % dtype)\n+      raise ValueError(f'Expected numeric or boolean dtype, got {dtype}.')\n     if _PARTITION_SHAPE in kwargs:\n       shape = kwargs[_PARTITION_SHAPE]\n     return tf.ones(shape, dtype)\n@@ -279,7 +279,7 @@ class RandomUniform(Initializer):\n     _validate_kwargs(self.__class__.__name__, kwargs)\n     dtype = _get_dtype(dtype)\n     if not dtype.is_floating and not dtype.is_integer:\n-      raise ValueError('Expected float or integer dtype, got %s.' % dtype)\n+      raise ValueError(f'Expected float or integer dtype, got {dtype}.')\n     if _PARTITION_SHAPE in kwargs:\n       shape = kwargs[_PARTITION_SHAPE]\n     return self._random_generator.random_uniform(shape, self.minval,\n@@ -466,16 +466,22 @@ class VarianceScaling(Initializer):\n                distribution='truncated_normal',\n                seed=None):\n     if scale <= 0.:\n-      raise ValueError('`scale` must be positive float.')\n-    if mode not in {'fan_in', 'fan_out', 'fan_avg'}:\n-      raise ValueError('Invalid `mode` argument:', mode)\n+      raise ValueError('`scale` must be positive float. '\n+                       f'Received: scale={scale}.')\n+    allowed_modes = {'fan_in', 'fan_out', 'fan_avg'}\n+    if mode not in allowed_modes:\n+      raise ValueError(f'Invalid `mode` argument: {mode}. '\n+                       f'Please use one of the {allowed_modes}.')\n     distribution = distribution.lower()\n     # Compatibility with keras-team/keras.\n     if distribution == 'normal':\n       distribution = 'truncated_normal'\n-    if distribution not in {'uniform', 'truncated_normal',\n-                            'untruncated_normal'}:\n-      raise ValueError('Invalid `distribution` argument:', distribution)\n+    allowed_distributions = {\n+        'uniform', 'truncated_normal', 'untruncated_normal'\n+    }\n+    if distribution not in allowed_distributions:\n+      raise ValueError(f'Invalid `distribution` argument: {distribution}.'\n+                       f'Allowed distributions: {allowed_distributions}.')\n     self.scale = scale\n     self.mode = mode\n     self.distribution = distribution\n@@ -585,7 +591,8 @@ class Orthogonal(Initializer):\n     # Check the shape\n     if len(shape) < 2:\n       raise ValueError('The tensor to initialize must be '\n-                       'at least two-dimensional')\n+                       'at least two-dimensional. Received: '\n+                       f'shape={shape} of rank {len(shape)}.')\n     # Flatten the input shape with the last dimension remaining\n     # its original shape so it works for conv2d\n     num_rows = 1\n@@ -651,7 +658,8 @@ class Identity(Initializer):\n     dtype = _assert_float_dtype(_get_dtype(dtype))\n     if len(shape) != 2:\n       raise ValueError(\n-          'Identity matrix initializer can only be used for 2D matrices.')\n+          'Identity matrix initializer can only be used for 2D matrices. '\n+          f'Received: shape={shape} of rank {len(shape)}.')\n     initializer = tf.eye(*shape, dtype=dtype)\n     return self.gain * initializer\n \n@@ -939,7 +947,7 @@ def _assert_float_dtype(dtype):\n   \"\"\"\n   dtype = tf.as_dtype(dtype)\n   if not dtype.is_floating:\n-    raise ValueError('Expected floating point type, got %s.' % dtype)\n+    raise ValueError(f'Expected floating point type, got {dtype}.')\n   return dtype\n \n \n@@ -1011,8 +1019,10 @@ def _compute_fans(shape):\n \n def _validate_kwargs(cls_name, kwargs, support_partition=True):\n   for kwarg in kwargs:\n-    if kwarg not in [_PARTITION_SHAPE, _PARTITION_OFFSET]:\n-      raise TypeError('Unknown keyword arguments: %s' % kwarg)\n+    allowed_kwargs = [_PARTITION_SHAPE, _PARTITION_OFFSET]\n+    if kwarg not in allowed_kwargs:\n+      raise TypeError(f'Unknown keyword arguments: {kwarg}. Allowed keyword '\n+                      f'arguments: {allowed_kwargs}.')\n     elif not support_partition:\n-      raise ValueError('%s initializer doesn\\'t support partition-related '\n-                       'arguments' % cls_name)\n+      raise ValueError(f'{cls_name} initializer doesn\\'t support '\n+                       'partition-related arguments.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#673c95d383eb08892fb109a676e3cd6d241052a6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 202 | Contributors (this commit): 3 | Commits (past 90d): 1 | Contributors (cumulative): 3 | DMM Complexity: 0.0\n\nDIFF:\n@@ -107,7 +107,8 @@ class SGD(optimizer_v2.OptimizerV2):\n     if isinstance(momentum, tf.Tensor) or callable(momentum) or momentum > 0:\n       self._momentum = True\n     if isinstance(momentum, (int, float)) and (momentum < 0 or momentum > 1):\n-      raise ValueError(\"`momentum` must be between [0, 1].\")\n+      raise ValueError(f\"`momentum` must be between [0, 1]. Received: \"\n+                       f\"momentum={momentum} (of type {type(momentum)}).\")\n     self._set_hyper(\"momentum\", momentum)\n \n     self.nesterov = nesterov\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6e84e99c5fa76ecb473ebd1b56d93b5d9ea4b8cb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 24 | Files Changed: 1 | Hunks: 10 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 56 | Churn Cumulative: 15746 | Contributors (this commit): 108 | Commits (past 90d): 32 | Contributors (cumulative): 108 | DMM Complexity: 0.5\n\nDIFF:\n@@ -2717,8 +2717,10 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n           f'Received: {target_tensor_arg}.')\n     invalid_kwargs = set(kwargs) - {'sample_weight_mode'}\n     if invalid_kwargs:\n-      raise TypeError('Invalid keyword argument(s) in `compile()`: %s' %\n-                      (invalid_kwargs,))\n+      raise TypeError('Invalid keyword argument(s) in `compile()`: '\n+                      f'{(invalid_kwargs,)}. Valid keyword arguments include '\n+                      '\"cloning\", \"experimental_run_tf_function\", \"distribute\",'\n+                      ' \"target_tensors\", or \"sample_weight_mode\".')\n \n     # Model must be created and compiled with the same DistStrat.\n     if self.built and tf.distribute.has_strategy():\n@@ -2726,14 +2728,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       for v in self.variables:\n         if not strategy.extended.variable_created_in_scope(v):\n           raise ValueError(\n-              'Variable (%s) was not created in the distribution strategy '\n-              'scope of (%s). It is most likely due to not all layers or '\n-              'the model or optimizer being created outside the distribution '\n-              'strategy scope. Try to make sure your code looks similar '\n-              'to the following.\\n'\n+              f'Variable ({v}) was not created in the distribution strategy '\n+              f'scope of ({strategy}). It is most likely because some '\n+              'layers, model, or optimizer was being created outside the '\n+              'distribution strategy scope. Try to make sure your code looks '\n+              'similar to the following.\\n'\n               'with strategy.scope():\\n'\n               '  model=_create_model()\\n'\n-              '  model.compile(...)' % (v, strategy))\n+              '  model.compile(...)')\n \n     # Model metrics must be created in the same distribution strategy scope\n     # as the model.\n@@ -2742,13 +2744,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       for v in getattr(metric, 'variables', []):\n         if not strategy.extended.variable_created_in_scope(v):\n           raise ValueError(\n-              'Metric (%s) passed to model.compile was created inside of a '\n-              'different distribution strategy scope than the model. All '\n+              f'Metric ({metric}) passed to `model.compile` was created inside '\n+              'a different distribution strategy scope than the model. All '\n               'metrics must be created in the same distribution strategy '\n-              'scope as the model (in this case %s). If you pass in a string '\n-              'identifier for a metric to compile the metric will '\n+              f'scope as the model (in this case {strategy}). If you pass in a '\n+              'string identifier for a metric to compile, the metric will '\n               'automatically be created in the correct distribution '\n-              'strategy scope.' % (metric, strategy)\n+              'strategy scope.'\n           )\n \n     # Model metrics must be created in the same distribution strategy scope\n@@ -2757,13 +2759,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       for v in getattr(opt, '_weights', []):\n         if not strategy.extended.variable_created_in_scope(v):\n           raise ValueError(\n-              'Optimizer (%s) passed to model.compile was created inside of a '\n-              'different distribution strategy scope than the model. All '\n-              'optimizers must be created in the same distribution strategy '\n-              'scope as the model (in this case %s). If you pass in a string '\n-              'identifier for an optimizer to compile the optimizer will '\n-              'automatically be created in the correct distribution '\n-              'strategy scope.' % (opt, strategy))\n+              f'Optimizer ({optimizer}) passed to `model.compile` was created '\n+              'inside a different distribution strategy scope than the model. '\n+              'All optimizers must be created in the same distribution '\n+              f'strategy scope as the model (in this case {strategy}). If you '\n+              'pass in a string identifier for an optimizer to compile, the '\n+              'optimizer will automatically be created in the correct '\n+              'distribution strategy scope.'\n+          )\n \n   def _maybe_load_initial_epoch_from_ckpt(self, initial_epoch):\n     \"\"\"Maybe load initial epoch from ckpt considering possible worker recovery.\n@@ -2827,7 +2830,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     elif isinstance(validation_freq, list):\n       return epoch in validation_freq\n     else:\n-      raise ValueError('Expected `validation_freq` to be a list or int.')\n+      raise ValueError('Expected `validation_freq` to be a list or int. '\n+                       f'Received: validation_freq={validation_freq} of the '\n+                       f'type {type(validation_freq)}.')\n \n   ######################################################################\n   # Functions below exist only as v1 / v2 compatibility shims.\n@@ -2903,7 +2908,8 @@ def reduce_per_replica(values, strategy, reduction='first'):\n       else:\n         return concat(strategy.unwrap(v))\n     else:\n-      raise ValueError('`reduction` must be \"first\" or \"concat\".')\n+      raise ValueError('`reduction` must be \"first\" or \"concat\". Received: '\n+                       f'reduction={reduction}.')\n \n   return tf.nest.map_structure(_reduce, values)\n \n@@ -3075,8 +3081,10 @@ def disable_multi_worker(method):\n \n   def _method_wrapper(self, *args, **kwargs):\n     if self._in_multi_worker_mode():  # pylint: disable=protected-access\n-      raise ValueError('{} is not supported in multi-worker mode.'.format(\n-          method.__name__))\n+      raise ValueError(f'{method.__name__} is not supported in multi-worker '\n+                       'mode. Please use a non-multi-worker '\n+                       '`tf.distribute.Strategy` such as '\n+                       '`tf.distribute.MirroredStrategy`.')\n     return method(self, *args, **kwargs)\n \n   return tf.__internal__.decorator.make_decorator(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f12f4821a5045b7ca503195fe53a11f132062f94", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 6 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 15763 | Contributors (this commit): 108 | Commits (past 90d): 33 | Contributors (cumulative): 108 | DMM Complexity: 0.0\n\nDIFF:\n@@ -191,8 +191,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         # In case there are unused kwargs, we should raise an error to user, in\n         # case they have a typo in the param name.\n         raise TypeError(\n-            'The following keyword arguments aren\\'t supported: {}'.format(\n-                other_kwargs))\n+            'The following keyword arguments passed to `Model` aren\\'t '\n+            'supported: {}.'.format(other_kwargs))\n       return\n \n     base_layer.keras_api_gauge.get_cell('Model subclass').set(True)\n@@ -347,14 +347,14 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n       return\n \n     if input_shape is None:\n-      raise ValueError('Input shape must be defined when calling build on a '\n+      raise ValueError('Input shape must be defined when calling `build` on a '\n                        'model subclass network.')\n     valid_types = (tuple, list, tf.TensorShape, dict)\n     if not isinstance(input_shape, valid_types):\n       raise ValueError('Specified input shape is not one of the valid types. '\n                        'Please specify a batch input shape of type tuple or '\n                        'list of input shapes. User provided '\n-                       'input type: {}'.format(type(input_shape)))\n+                       'input type: {}.'.format(type(input_shape)))\n \n     if input_shape and not self.inputs:\n       # We create placeholders for the `None`s in the shape and build the model\n@@ -401,7 +401,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n                   'inputs to the model, but are required for its '\n                   '`call()` method. Instead, in order to instantiate '\n                   'and build your model, `call()` your model on real '\n-                  'tensor data with all expected call arguments.')\n+                  'tensor data with all expected call arguments. The argument '\n+                  'for `call()` can be a single list/tuple that contains '\n+                  'multiple inputs.')\n         elif len(call_args) < 2:\n           # Signature without `inputs`.\n           raise ValueError(\n@@ -409,12 +411,13 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n               'method accepts an `inputs` argument.')\n         try:\n           self.call(x, **kwargs)\n-        except (tf.errors.InvalidArgumentError, TypeError):\n+        except (tf.errors.InvalidArgumentError, TypeError) as e:\n           raise ValueError('You cannot build your model by calling `build` '\n                            'if your layers do not support float type inputs. '\n                            'Instead, in order to instantiate and build your '\n                            'model, call your model on real tensor data (of '\n-                           'the correct dtype).')\n+                           'the correct dtype).\\n\\nThe actual error from '\n+                           f'`call` is: {e}.')\n     super(Model, self).build(input_shape)\n \n   @doc_controls.doc_in_current_and_subclasses\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0fadd903ecc41214a7fcdc92cd944351e8c2e07d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 588 | Contributors (this commit): 6 | Commits (past 90d): 4 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -185,22 +185,23 @@ class BaseDenseAttention(Layer):\n     class_name = self.__class__.__name__\n     if not isinstance(inputs, list):\n       raise ValueError(\n-          '{} layer must be called on a list of inputs, namely [query, value] '\n-          'or [query, value, key].'.format(class_name))\n+          f'{class_name} layer must be called on a list of inputs, '\n+          'namely [query, value] or [query, value, key]. '\n+          f'Received: {inputs}.')\n     if len(inputs) < 2 or len(inputs) > 3:\n       raise ValueError(\n-          '{} layer accepts inputs list of length 2 or 3, '\n+          f'{class_name} layer accepts inputs list of length 2 or 3, '\n           'namely [query, value] or [query, value, key]. '\n-          'Given length: {}'.format(class_name, len(inputs)))\n+          f'Received length: {len(inputs)}.')\n     if mask:\n       if not isinstance(mask, list):\n         raise ValueError(\n-            '{} layer mask must be a list, '\n-            'namely [query_mask, value_mask].'.format(class_name))\n+            f'{class_name} layer mask must be a list, '\n+            f'namely [query_mask, value_mask]. Received: {mask}.')\n       if len(mask) < 2 or len(mask) > len(inputs):\n         raise ValueError(\n-            '{} layer mask must be a list of length 2, namely [query_mask, '\n-            'value_mask]. Given length: {}'.format(class_name, len(mask)))\n+            f'{class_name} layer mask must be a list of length 2, '\n+            f'namely [query_mask, value_mask]. Received length: {len(mask)}.')\n \n   def get_config(self):\n     config = {\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3e70013536ed9200419d39bdf1e40d50d046906f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1694 | Contributors (this commit): 12 | Commits (past 90d): 1 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -115,11 +115,13 @@ def InceptionV3(\n     raise ValueError('The `weights` argument should be either '\n                      '`None` (random initialization), `imagenet` '\n                      '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+                     'or the path to the weights file to be loaded; '\n+                     f'Received: weights={weights}')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n-                     ' as true, `classes` should be 1000')\n+                     'as true, `classes` should be 1000; '\n+                     f'Received classes={classes}')\n \n   # Determine proper input shape\n   input_shape = imagenet_utils.obtain_input_shape(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e9e82756d881f31709302376ad5a2e6e01fc0e32", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 464 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -22,10 +22,14 @@ from keras.engine import base_layer\n from keras.engine import input_spec\n from keras.engine import training\n from keras.layers import core\n+from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.experimental.LinearModel')\n+@keras_export(\n+    'keras.experimental.LinearModel',\n+    v1=['keras.experimental.LinearModel', 'keras.models.LinearModel'])\n+@deprecation.deprecated_endpoints('keras.experimental.LinearModel')\n class LinearModel(training.Model):\n   r\"\"\"Linear Model for regression and classification problems.\n \n\n@@ -22,10 +22,14 @@ from keras.engine import base_layer\n from keras.engine import data_adapter\n from keras.engine import training as keras_training\n from keras.utils import generic_utils\n+from tensorflow.python.util import deprecation  # pylint: disable=g-direct-tensorflow-import\n from tensorflow.python.util.tf_export import keras_export\n \n \n-@keras_export('keras.experimental.WideDeepModel')\n+@keras_export(\n+    'keras.experimental.WideDeepModel',\n+    v1=['keras.experimental.WideDeepModel', 'keras.models.WideDeepModel'])\n+@deprecation.deprecated_endpoints('keras.experimental.WideDeepModel')\n class WideDeepModel(keras_training.Model):\n   r\"\"\"Wide & Deep Model for regression and classification problems.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7fc16e3cbbb0f424d92a0914b115d47c1124f2bf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 2190 | Contributors (this commit): 14 | Commits (past 90d): 3 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -165,16 +165,18 @@ def MobileNet(input_shape=None,\n   else:\n     layers = VersionAwareLayers()\n   if kwargs:\n-    raise ValueError('Unknown argument(s): %s' % (kwargs,))\n+    raise ValueError(f'Unknown argument(s): {(kwargs,)}')\n   if not (weights in {'imagenet', None} or tf.io.gfile.exists(weights)):\n     raise ValueError('The `weights` argument should be either '\n                      '`None` (random initialization), `imagenet` '\n                      '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+                     'or the path to the weights file to be loaded.  '\n+                     f'Received weights={weights}')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n-                     'as true, `classes` should be 1000')\n+                     'as true, `classes` should be 1000.  '\n+                     f'Received classes={classes}')\n \n   # Determine proper input shape and default size.\n   if input_shape is None:\n@@ -210,12 +212,14 @@ def MobileNet(input_shape=None,\n   if weights == 'imagenet':\n     if depth_multiplier != 1:\n       raise ValueError('If imagenet weights are being loaded, '\n-                       'depth multiplier must be 1')\n+                       'depth multiplier must be 1.  '\n+                       'Received depth_multiplier={depth_multiplier}')\n \n     if alpha not in [0.25, 0.50, 0.75, 1.0]:\n       raise ValueError('If imagenet weights are being loaded, '\n                        'alpha can be one of'\n-                       '`0.25`, `0.50`, `0.75` or `1.0` only.')\n+                       '`0.25`, `0.50`, `0.75` or `1.0` only.  '\n+                       f'Received alpha={alpha}')\n \n     if rows != cols or rows not in [128, 160, 192, 224]:\n       rows = 224\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a3c7e5a7c1ef50e219199b5519aa8eed5743bc51", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 11 | Files Changed: 1 | Hunks: 6 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 30 | Churn Cumulative: 733 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -173,11 +173,13 @@ def MobileNetV3(stack_fn,\n     raise ValueError('The `weights` argument should be either '\n                      '`None` (random initialization), `imagenet` '\n                      '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+                     'or the path to the weights file to be loaded.  '\n+                     f'Received weights={weights}')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n-                     'as true, `classes` should be 1000')\n+                     'as true, `classes` should be 1000.  '\n+                     f'Received classes={classes}')\n \n   # Determine proper input shape and default size.\n   # If both input_shape and input_tensor are used, they should match\n@@ -190,18 +192,24 @@ def MobileNetV3(stack_fn,\n             layer_utils.get_source_inputs(input_tensor))\n       except ValueError:\n         raise ValueError('input_tensor: ', input_tensor,\n-                         'is not type input_tensor')\n+                         'is not type input_tensor.  '\n+                         f'Received type(input_tensor)={type(input_tensor)}')\n     if is_input_t_tensor:\n       if backend.image_data_format() == 'channels_first':\n         if backend.int_shape(input_tensor)[1] != input_shape[1]:\n-          raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n-                           input_tensor,\n-                           'do not meet the same shape requirements')\n+          raise ValueError('When backend.image_data_format()=channels_first, '\n+                           'input_shape[1] must equal '\n+                           'backend.int_shape(input_tensor)[1].  Received '\n+                           f'input_shape={input_shape}, '\n+                           'backend.int_shape(input_tensor)='\n+                           f'{backend.int_shape(input_tensor)}')\n       else:\n         if backend.int_shape(input_tensor)[2] != input_shape[1]:\n-          raise ValueError('input_shape: ', input_shape, 'and input_tensor: ',\n-                           input_tensor,\n-                           'do not meet the same shape requirements')\n+          raise ValueError('input_shape[1] must equal '\n+                           'backend.int_shape(input_tensor)[2].  Received '\n+                           f'input_shape={input_shape}, '\n+                           'backend.int_shape(input_tensor)='\n+                           f'{backend.int_shape(input_tensor)}')\n     else:\n       raise ValueError('input_tensor specified: ', input_tensor,\n                        'is not a keras tensor')\n@@ -235,8 +243,8 @@ def MobileNetV3(stack_fn,\n   rows = input_shape[row_axis]\n   cols = input_shape[col_axis]\n   if rows and cols and (rows < 32 or cols < 32):\n-    raise ValueError('Input size must be at least 32x32; got `input_shape=' +\n-                     str(input_shape) + '`')\n+    raise ValueError('Input size must be at least 32x32; Received `input_shape='\n+                     f'{input_shape}`')\n   if weights == 'imagenet':\n     if (not minimalistic and alpha not in [0.75, 1.0]\n         or minimalistic and alpha != 1.0):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bda914e6e09813970728bf84eec75fc0eab6853", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 929 | Contributors (this commit): 12 | Commits (past 90d): 1 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -113,14 +113,17 @@ def VGG16(\n     A `keras.Model` instance.\n   \"\"\"\n   if not (weights in {'imagenet', None} or tf.io.gfile.exists(weights)):\n-    raise ValueError('The `weights` argument should be either '\n+    raise ValueError(\n+        'The `weights` argument should be either '\n         '`None` (random initialization), `imagenet` '\n         '(pre-training on ImageNet), '\n-                     'or the path to the weights file to be loaded.')\n+        'or the path to the weights file to be loaded.  Received: '\n+        f'weights={weights}')\n \n   if weights == 'imagenet' and include_top and classes != 1000:\n     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n-                     ' as true, `classes` should be 1000')\n+                     'as true, `classes` should be 1000.  '\n+                     f'Received `classes={classes}`')\n   # Determine proper input shape\n   input_shape = imagenet_utils.obtain_input_shape(\n       input_shape,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#18b25a9cf55bad22092c307314c8eeafe827d0b2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 490 | Contributors (this commit): 4 | Commits (past 90d): 2 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -223,9 +223,9 @@ def _get_argspec_for_partial(obj):\n   ]\n \n   if invalid_default_values:\n-    raise ValueError('Some arguments %s do not have default value, but they '\n-                     'are positioned after those with default values. This can '\n-                     'not be expressed with ArgSpec.' % invalid_default_values)\n+    raise ValueError(f'Some arguments {invalid_default_values} do not have '\n+                     'default value, but they are positioned after those with '\n+                     'default values. This can not be expressed with ArgSpec.')\n \n   return ArgSpec(args, varargs, keywords, tuple(all_defaults[first_default:]))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
