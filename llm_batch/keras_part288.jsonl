{"custom_id": "keras#d3ab82cfafb8cd95818375f8cd5fdd7a47833e98", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 6800 | Contributors (this commit): 38 | Commits (past 90d): 20 | Contributors (cumulative): 38 | DMM Complexity: 1.0\n\nDIFF:\n@@ -630,7 +630,7 @@ class TestBackend(object):\n                         reason='cntk doesn\\'t support gradient in this way.')\n     def test_gradient(self):\n         val = np.random.random((4, 2))\n-        x_list = [k.variable(val) for k in [KTH, KTF]]\n+        x_list = [k.placeholder(shape=(4, 2)) for k in [KTH, KTF]]\n         z_list = []\n         zero_list = []\n         for x, k in zip(x_list, [KTH, KTF]):\n@@ -638,9 +638,12 @@ class TestBackend(object):\n             loss = k.sum(exp)\n             zero_loss = k.stop_gradient(loss)\n             grad = k.gradients(loss, [exp])\n+\n             zero_grad = k.gradients(loss + zero_loss, [exp])\n-            z_list.append(k.eval(grad[0]))\n-            zero_list.append(k.eval(zero_grad[0]))\n+            grad_eval_fn = k.function([x], [grad[0]])\n+            zero_grad_eval_fn = k.function([x], [zero_grad[0]])\n+            z_list.append(grad_eval_fn([val])[0])\n+            zero_list.append(zero_grad_eval_fn([val])[0])\n \n         assert_list_pairwise(z_list)\n         assert_list_pairwise(zero_list)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8ec47aa7b76f8817561d087be4141c403951d09", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 23909 | Contributors (this commit): 196 | Commits (past 90d): 36 | Contributors (cumulative): 230 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2937,6 +2937,7 @@ def print_tensor(x, message=''):\n \n # GRAPH MANIPULATION\n \n+\n def function(inputs, outputs, updates=None, **kwargs):\n     if _is_tf_1():\n         v1_variable_initialization()\n\n@@ -1017,7 +1017,7 @@ class Model(Network):\n         elif validation_steps:\n             do_validation = True\n             if self._uses_dynamic_learning_phase():\n-                val_inputs = [0.]\n+                val_inputs = [0]\n \n         # Prepare input arrays and training function.\n         if self._uses_dynamic_learning_phase():\n\n@@ -329,7 +329,6 @@ def predict_loop(model, f, ins,\n \n             batch_logs = {'batch': batch_index, 'size': len(batch_ids)}\n             callbacks._call_batch_hook('predict', 'begin', batch_index, batch_logs)\n-            print('ins_batch', ins_batch)\n             batch_outs = f(ins_batch)\n             batch_outs = to_list(batch_outs)\n             if batch_index == 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0cccb83cdf98832feb647278422a75edb4375c76", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 8 | Churn Cumulative: 14598 | Contributors (this commit): 129 | Commits (past 90d): 26 | Contributors (cumulative): 129 | DMM Complexity: 0.0\n\nDIFF:\n@@ -603,8 +603,6 @@ def variable(value, dtype=None, name=None, constraint=None):\n                [ 3.,  4.]])\n     ```\n     \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n     v = tf_keras_backend.variable(\n         value, dtype=dtype, name=name, constraint=constraint)\n     if hasattr(value, 'tocoo'):\n@@ -629,10 +627,8 @@ def constant(value, dtype=None, shape=None, name=None):\n     # Returns\n         A Constant Tensor.\n     \"\"\"\n-    if dtype is None:\n-        dtype = floatx()\n-    with tf_ops.init_scope():\n-        return tf.constant(value, dtype=dtype, shape=shape, name=name)\n+    return tf_keras_backend.constant(\n+        value, dtype=dtype, shape=shape, name=name)\n \n \n def is_keras_tensor(x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#adaed1f84a0d980a660eb7d5ff271408374e5bef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 11 | Files Changed: 6 | Hunks: 11 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 22 | Churn Cumulative: 4687 | Contributors (this commit): 51 | Commits (past 90d): 14 | Contributors (cumulative): 70 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ def gen_uniform_amp(amp=1, xn=10000):\n     -amp and +amp\n     and of length xn\n \n-    Arguments:\n+    # Arguments\n         amp: maximum/minimum range of uniform data\n         xn: length of series\n     \"\"\"\n\n@@ -175,7 +175,7 @@ def hard_sigmoid(x):\n def exponential(x):\n     \"\"\"Exponential (base e) activation function.\n \n-    # Arguments:\n+    # Arguments\n         x: Input tensor.\n \n     # Returns\n\n@@ -960,7 +960,7 @@ class Network(Layer):\n         def add_unprocessed_node(layer, node_data):\n             \"\"\"Add node to layer list\n \n-            Args:\n+            # Arguments\n                 layer: layer object\n                 node_data: Node data specifying layer call\n             \"\"\"\n@@ -972,11 +972,11 @@ class Network(Layer):\n         def process_node(layer, node_data):\n             \"\"\"Reconstruct node by linking to inbound layers\n \n-            Args:\n+            # Arguments\n                 layer: Layer to process\n                 node_data: List of layer configs\n \n-            Raises:\n+            # Raises\n                 ValueError: For incorrect layer config\n                 LookupError: If layer required is not found\n             \"\"\"\n\n@@ -621,16 +621,16 @@ def is_sequence(seq):\n def should_run_validation(validation_freq, epoch):\n     \"\"\"Checks if validation should be run this epoch.\n \n-    Arguments:\n+    # Arguments\n         validation_freq: Integer or list. If an integer, specifies how many training\n           epochs to run before a new validation run is performed. If a list,\n           specifies the epochs on which to run validation.\n         epoch: Integer, the number of the training epoch just completed.\n \n-    Returns:\n+    # Returns\n         Bool, True if validation should be run.\n \n-    Raises:\n+    # Raises\n         ValueError: if `validation_freq` is an Integer and less than 1, or if\n         it is neither an Integer nor a Sequence.\n     \"\"\"\n\n@@ -153,14 +153,14 @@ class tf_file_io_proxy(object):\n     recommended to use method `get_filepath(filename)` in tests to make them\n     pass with and without a real GCS bucket during testing. See example below.\n \n-    Arguments:\n+    # Arguments\n         file_io_module: String identifier of the file_io module import to patch. E.g\n             'keras.engine.saving.tf_file_io'\n         bucket_name: String identifier of *a real* GCS bucket (with or without the\n             'gs://' prefix). A bucket name provided with argument precedes what is\n             specified using the GCS_TEST_BUCKET environment variable.\n \n-    Example:\n+    # Example\n     ```python\n     model = Sequential()\n     model.add(Dense(2, input_shape=(3,)))\n\n@@ -169,7 +169,7 @@ def plot_model(model,\n         expand_nested: whether to expand nested models into clusters.\n         dpi: dot DPI.\n \n-    # Returns:\n+    # Returns\n         A Jupyter notebook Image object if Jupyter is installed.\n         This enables in-line display of the model plots in notebooks.\n     \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd024a1fc1cd6d88e8bc5da148968ff5e079caeb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 2 | Churn Cumulative: 6802 | Contributors (this commit): 38 | Commits (past 90d): 21 | Contributors (cumulative): 38 | DMM Complexity: None\n\nDIFF:\n@@ -556,8 +556,6 @@ class TestBackend(object):\n         K.reset_uids()\n         assert K.get_uid() == first\n \n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='cntk does not support '\n-                                                      'cumsum and cumprod yet')\n     def test_cumsum(self):\n         check_single_tensor_operation('cumsum', (4, 2), WITH_NP)\n         check_single_tensor_operation('cumsum', (4, 2), WITH_NP, axis=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f6a30b005535fb45a5b4decf084af437ac7fc7f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 18 | Files Changed: 5 | Hunks: 12 | Methods Changed: 10 | Complexity Δ (Sum/Max): 53/59 | Churn Δ: 48 | Churn Cumulative: 32019 | Contributors (this commit): 168 | Commits (past 90d): 73 | Contributors (cumulative): 301 | DMM Complexity: 1.0\n\nDIFF:\n@@ -523,7 +523,11 @@ def ones(shape, dtype=None, name=None):\n def eye(size, dtype=None, name=None):\n     if dtype is None:\n         dtype = floatx()\n-    return variable(np.eye(size), dtype, name)\n+    if isinstance(size, (list, tuple)):\n+        n, m = size\n+    else:\n+        n, m = size, size\n+    return variable(np.eye(n, m), dtype, name)\n \n \n def zeros_like(x, dtype=None, name=None):\n\n@@ -684,7 +684,11 @@ def ones_like(x, dtype=floatx(), name=None):\n \n \n def eye(size, dtype=None, name=None):\n-    return np.eye(size, dtype=dtype)\n+    if isinstance(size, (list, tuple)):\n+        n, m = size\n+    else:\n+        n, m = size, size\n+    return np.eye(n, m, dtype=dtype)\n \n \n def resize_images(x, height_factor, width_factor, data_format):\n\n@@ -761,7 +761,7 @@ def eye(size, dtype=None, name=None):\n     \"\"\"Instantiate an identity matrix and returns it.\n \n     # Arguments\n-        size: Integer, number of rows/columns.\n+        size: Tuple, number of rows and columns. If Integer, number of rows.\n         dtype: String, data type of returned Keras variable.\n         name: String, name of returned Keras variable.\n \n@@ -771,18 +771,24 @@ def eye(size, dtype=None, name=None):\n     # Example\n     ```python\n         >>> from keras import backend as K\n-        >>> kvar = K.eye(3)\n-        >>> K.eval(kvar)\n+        >>> K.eval(K.eye(3))\n         array([[ 1.,  0.,  0.],\n                [ 0.,  1.,  0.],\n                [ 0.,  0.,  1.]], dtype=float32)\n+        >>> K.eval(K.eye((2, 3)))\n+        array([[1., 0., 0.],\n+               [0., 1., 0.]], dtype=float32)\n     ```\n     {{np_implementation}}\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n     tf_dtype = tf.as_dtype(dtype)\n-    return variable(tf.eye(size, dtype=tf_dtype), dtype, name)\n+    if isinstance(size, (list, tuple)):\n+        n, m = size\n+    else:\n+        n, m = size, size\n+    return variable(tf.eye(n, m, dtype=tf_dtype), dtype, name)\n \n \n def zeros_like(x, dtype=None, name=None):\n\n@@ -320,7 +320,11 @@ def eye(size, dtype=None, name=None):\n     \"\"\"\n     if dtype is None:\n         dtype = floatx()\n-    return variable(np.eye(size), dtype, name)\n+    if isinstance(size, (list, tuple)):\n+        n, m = size\n+    else:\n+        n, m = size, size\n+    return variable(np.eye(n, m), dtype, name)\n \n \n def ones_like(x, dtype=None, name=None):\n\n@@ -250,24 +250,18 @@ class TestBackend(object):\n         with pytest.raises(ValueError):\n             K.set_learning_phase(2)\n \n-    def test_eye(self):\n+    def test_creation_operations(self):\n         check_single_tensor_operation('eye', 3, WITH_NP, shape_or_val=False)\n+        check_single_tensor_operation('eye', (3, 2), WITH_NP, shape_or_val=False)\n+        check_single_tensor_operation('eye', (3, 4), WITH_NP, shape_or_val=False)\n \n-    def test_ones(self):\n         check_single_tensor_operation('ones', (3, 5, 10, 8),\n                                       WITH_NP, shape_or_val=False)\n-\n-    def test_zeros(self):\n         check_single_tensor_operation('zeros', (3, 5, 10, 8),\n                                       WITH_NP, shape_or_val=False)\n \n-    def test_ones_like(self):\n-        check_single_tensor_operation('ones_like', (3, 5, 10, 8),\n-                                      WITH_NP, shape_or_val=True)\n-\n-    def test_zeros_like(self):\n-        check_single_tensor_operation('zeros_like', (3, 5, 10, 8),\n-                                      WITH_NP, shape_or_val=True)\n+        check_single_tensor_operation('ones_like', (3, 5, 10, 8), WITH_NP)\n+        check_single_tensor_operation('zeros_like', (3, 5, 10, 8), WITH_NP)\n \n     def test_linear_operations(self):\n         check_two_tensor_operation('dot', (4, 2), (2, 4), WITH_NP)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#618edbe595abcdca96f508b14d9198d68ac767a2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 19 | Churn Cumulative: 10703 | Contributors (this commit): 54 | Commits (past 90d): 36 | Contributors (cumulative): 72 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2746,7 +2746,22 @@ def cumsum(x, axis=0):\n \n \n def cumprod(x, axis=0):\n-    raise NotImplementedError\n+    shape = x.shape\n+    out = x\n+    for rep in range(shape[axis] - 1):\n+        sliced_shape = list(shape)\n+        sliced_shape[axis] = rep + 1\n+        if axis == 0:\n+            _x = x[rep:(rep + 1)]\n+        elif axis == 1:\n+            _x = x[:, rep:(rep + 1)]\n+        elif axis == 2:\n+            _x = x[:, :, rep:(rep + 1)]\n+        y = concatenate([ones(sliced_shape, dtype=x.dtype),\n+                         repeat_elements(_x, rep=shape[axis] - 1 - rep, axis=axis)],\n+                        axis=axis)\n+        out = C.element_times(out, y)\n+    return out\n \n \n def arange(start, stop=None, step=1, dtype='int32'):\n\n@@ -554,8 +554,6 @@ class TestBackend(object):\n         check_single_tensor_operation('cumsum', (4, 2), WITH_NP)\n         check_single_tensor_operation('cumsum', (4, 2), WITH_NP, axis=1)\n \n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='cntk does not support '\n-                                                      'cumprod yet')\n     def test_cumprod(self):\n         check_single_tensor_operation('cumprod', (4, 2), WITH_NP)\n         check_single_tensor_operation('cumprod', (4, 2), WITH_NP, axis=1)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ce67a90decbe2f26f9ac9597d518f07b01d0c293", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 23 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 43 | Churn Cumulative: 6863 | Contributors (this commit): 38 | Commits (past 90d): 24 | Contributors (cumulative): 38 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1108,32 +1108,29 @@ class TestBackend(object):\n         check_single_tensor_operation('softmax', (4, 5, 3), WITH_NP, axis=1)\n         check_single_tensor_operation('softmax', (4, 5, 3, 10), WITH_NP, axis=2)\n \n-        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2),\n-                                   WITH_NP, from_logits=True)\n-        # cross_entropy call require the label is a valid probability distribution,\n-        # otherwise it is garbage in garbage out...\n-        # due to the algo difference, we can't guarantee CNTK has the same result\n-        # on the garbage input.\n-        # so create a separate test case for valid label input\n-        if K.backend() != 'cntk':\n-            check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2),\n-                                       WITH_NP, from_logits=True)\n-        xval = np.asarray([[0.26157712, 0.0432167], [-0.43380741, 0.30559841],\n-                           [0.20225059, -0.38956559], [-0.13805378, 0.08506755]],\n-                          dtype=np.float32)\n-        yval = np.asarray([[0.46221867, 0.53778133], [0.51228984, 0.48771016],\n-                           [0.64916514, 0.35083486], [0.47028078, 0.52971922]],\n-                          dtype=np.float32)\n-        check_two_tensor_operation('categorical_crossentropy', yval, xval, WITH_NP,\n-                                   cntk_two_dynamicity=True, from_logits=True)\n-        check_two_tensor_operation('binary_crossentropy', (4, 2), (4, 2),\n-                                   WITH_NP, from_logits=False)\n-        check_two_tensor_operation('categorical_crossentropy', (4, 2), (4, 2),\n-                                   WITH_NP, from_logits=False)\n-\n         check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=-1)\n         check_single_tensor_operation('l2_normalize', (4, 3), WITH_NP, axis=1)\n \n+    def test_crossentropy(self):\n+        # toy label matrix (4 samples, 2 classes)\n+        label = np.array([[.4, .6], [.3, .7], [.1, .9], [.2, .8]], dtype=np.float32)\n+        check_two_tensor_operation('binary_crossentropy', label, (4, 2), WITH_NP)\n+        check_two_tensor_operation('binary_crossentropy', label, (4, 2),\n+                                   WITH_NP, from_logits=True)\n+        check_two_tensor_operation('categorical_crossentropy', label, (4, 2),\n+                                   WITH_NP, cntk_two_dynamicity=True)\n+        check_two_tensor_operation('categorical_crossentropy', label, (4, 2),\n+                                   WITH_NP, cntk_two_dynamicity=True,\n+                                   from_logits=True)\n+\n+        # toy label matrix (2 samples, 3 classes)\n+        label = np.array([[.4, .1, .5], [.2, .6, .2]], dtype=np.float32)\n+        check_two_tensor_operation('categorical_crossentropy', label, (2, 3),\n+                                   WITH_NP, cntk_two_dynamicity=True)\n+        check_two_tensor_operation('categorical_crossentropy', label, (2, 3),\n+                                   WITH_NP, cntk_two_dynamicity=True,\n+                                   from_logits=True)\n+\n     @pytest.mark.skipif(K.backend() == 'cntk', reason='Bug in CNTK')\n     def test_in_top_k(self):\n         batch_size = 20\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#78e1f57c484da15466a34ed543a1cc4709617a2f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/3 | Churn Δ: 7 | Churn Cumulative: 13460 | Contributors (this commit): 108 | Commits (past 90d): 31 | Contributors (cumulative): 130 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1314,6 +1314,11 @@ def reverse(x, axes):\n     \"\"\"\n     if isinstance(axes, int):\n         axes = [axes]\n+    elif isinstance(axes, tuple):\n+        axes = list(axes)\n+    for i in range(len(axes)):\n+        if axes[i] == -1:\n+            axes[i] = x.ndim - 1\n     slices = []\n     for i in range(x.ndim):\n         if i in axes:\n\n@@ -290,8 +290,8 @@ class TestBackend(object):\n \n         check_single_tensor_operation('transpose', (4, 2), WITH_NP)\n         check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=1)\n-        if K.backend() != 'cntk':\n         check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=(1, 2))\n+        check_single_tensor_operation('reverse', (4, 3, 2), WITH_NP, axes=(0, -1))\n \n     def test_random_variables(self):\n         check_single_tensor_operation('random_uniform_variable', (2, 3), WITH_NP,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5d844095f6df0db8bd596247a98f429c594855f2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 32 | Churn Cumulative: 6897 | Contributors (this commit): 38 | Commits (past 90d): 26 | Contributors (cumulative): 38 | DMM Complexity: 0.0\n\nDIFF:\n@@ -369,9 +369,6 @@ class TestBackend(object):\n             assert_allclose(z, z_np, atol=1e-05)\n \n     def test_shape_operations(self):\n-        check_two_tensor_operation('concatenate', (4, 3), (4, 2), WITH_NP,\n-                                   axis=-1, concat_args=True)\n-\n         check_single_tensor_operation('reshape', (4, 2), WITH_NP, shape=(8, 1))\n         check_single_tensor_operation('permute_dimensions', (4, 2, 3), WITH_NP,\n                                       pattern=(2, 0, 1))\n@@ -1924,21 +1921,20 @@ class TestBackend(object):\n         assert k_s_d.shape == k_d.shape\n         assert_allclose(k_s_d, k_d, atol=1e-05)\n \n-    def test_stack(self):\n-        tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)]\n-        stack_axis = 3\n-        results = []\n-        if WITH_NP[0] == KC:\n-            check_two_tensor_operation('stack', (5, 4, 6, 10),\n-                                       (5, 4, 6, 10), WITH_NP,\n-                                       axis=stack_axis, concat_args=True)\n-        else:\n-            for k in WITH_NP:\n-                tensor_list_var = [k.variable(tensor) for tensor in tensor_list]\n-                out = k.eval(k.stack(tensor_list_var, axis=stack_axis))\n-                results.append(out)\n-\n-            assert_list_pairwise(results)\n+    @pytest.mark.parametrize('shape,shape2,axis', [\n+        ((5, 2), (7, 2), 0),\n+        ((5, 4, 6), (5, 3, 6), 1),\n+        ((5, 4, 6, 10), (5, 4, 6, 2), 3),\n+        ((5, 4, 6, 3), (5, 4, 6, 2), -1),\n+    ])\n+    def test_concat_operations(self, shape, shape2, axis):\n+        # In stack, each array must have the same shape.\n+        check_two_tensor_operation('stack', shape, shape, WITH_NP,\n+                                   axis=axis, concat_args=True)\n+        check_two_tensor_operation('concatenate', shape, shape2, WITH_NP,\n+                                   axis=axis, concat_args=True)\n+        check_two_tensor_operation('concatenate', shape, shape2, WITH_NP,\n+                                   axis=axis, concat_args=True)\n \n     @pytest.mark.skipif(K.backend() == 'cntk', reason='Not supported.')\n     def test_map(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#960e7b5367a072fe10b8c2c50d2ce68607057f5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 1 | Churn Cumulative: 6898 | Contributors (this commit): 38 | Commits (past 90d): 27 | Contributors (cumulative): 38 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1415,7 +1415,6 @@ class TestBackend(object):\n         with pytest.raises(ValueError):\n             K.conv3d(dummy_x_3d, dummy_w_3d, data_format='channels_middle')\n \n-        if K.backend() != 'theano':\n         with pytest.raises(ValueError):\n             K.separable_conv2d(dummy_x_2d, dummy_w_2d, dummy_w1x1_2d,\n                                data_format='channels_middle')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8202e627c7d7897728d824c84a6d479ca84a9098", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 18 | Files Changed: 4 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/2 | Churn Δ: 45 | Churn Cumulative: 32033 | Contributors (this commit): 168 | Commits (past 90d): 77 | Contributors (cumulative): 293 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2577,7 +2577,11 @@ def reverse(x, axes):\n \n \n def slice(x, start, size):\n-    raise NotImplementedError\n+    if not (len(int_shape(x)) == len(start) == len(size)):\n+        raise ValueError('The dimension and the size of indices should match.')\n+    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n+    out._keras_shape = tuple(size)\n+    return out\n \n \n def _reshape_batch(x, shape):\n\n@@ -2624,8 +2624,13 @@ def slice(x, start, size):\n         new_x = x[start[0]: start[0] + size[0], ..., start[-1]: start[-1] + size[-1]]\n         ```\n \n+    # Raises\n+        ValueError: if the dimension and the size of indices mismatches.\n+\n     {{np_implementation}}\n     \"\"\"\n+    if not (len(int_shape(x)) == len(start) == len(size)):\n+        raise ValueError('The dimension and the size of indices should match.')\n     return tf.slice(x, start, size)\n \n \n\n@@ -1329,7 +1329,11 @@ def reverse(x, axes):\n \n \n def slice(x, start, size):\n-    raise NotImplementedError\n+    if not (len(int_shape(x)) == len(start) == len(size)):\n+        raise ValueError('The dimension and the size of indices should match.')\n+    out = x[tuple([py_slice(i, i + j) for (i, j) in zip(start, size)])]\n+    out._keras_shape = tuple(size)\n+    return out\n \n \n def pattern_broadcast(x, broadcastable):\n\n@@ -1745,23 +1745,19 @@ class TestBackend(object):\n         assert np.alltrue(decode_pred_np == decode_pred)\n         assert np.allclose(log_prob_pred_np, log_prob_pred)\n \n-    @pytest.mark.skipif(K.backend() != 'tensorflow',\n-                        reason='tensorflow-way slice is '\n-                        'only supported in tensorflow.')\n-    @pytest.mark.parametrize('x_size', [\n-        [1, 1, 3],\n-        [1, 2, 3],\n-        [2, 1, 3]\n+    @pytest.mark.parametrize('shape,start,size', [\n+        ((2, 5), (0, 1), (2, 3)),\n+        ((2, 5), (1, 0), (1, 4)),\n+        ((3, 2, 3), (1, 1, 0), (1, 1, 3)),\n+        ((3, 2, 3), (1, 0, 0), (1, 2, 3)),\n+        ((3, 2, 3), (1, 0, 0), (2, 1, 3)),\n     ])\n-    def test_slice(self, x_size):\n-        npt = np.array([[[1, 1, 1], [2, 2, 2]],\n-                       [[3, 3, 3], [4, 4, 4]],\n-                       [[5, 5, 5], [6, 6, 6]]])\n-        x_start = [1, 0, 0]\n-        tft = K.constant(npt)\n-        test_input = K.eval(K.slice(tft, x_start, x_size))\n-        expected = KNP.slice(npt, x_start, x_size)\n-        assert np.allclose(test_input, expected)\n+    def test_slice(self, shape, start, size):\n+        check_single_tensor_operation('slice', shape, WITH_NP,\n+                                      start=start, size=size)\n+        with pytest.raises(ValueError):\n+            K.slice(K.variable(np.random.random(shape)),\n+                    start=[1, 0, 0, 0], size=size)\n \n     @pytest.mark.skipif(K.backend() != 'tensorflow',\n                         reason='Beam search is only implemented with '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8ec0e6dc9bc2b069fa9cdb86b8a32ef6a10a6aa", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 17 | Churn Cumulative: 6943 | Contributors (this commit): 38 | Commits (past 90d): 29 | Contributors (cumulative): 38 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2079,14 +2079,17 @@ class TestBackend(object):\n             with pytest.raises(TypeError):\n                 K.variable('', dtype='unsupported')\n \n-    def test_clip_supports_tensor_arguments(self):\n+    @pytest.mark.parametrize('shape', [(4, 2), (2, 3)])\n+    def test_clip_supports_tensor_arguments(self, shape):\n         # GitHub issue: 11435\n-        x = K.variable([-10., -5., 0., 5., 10.])\n-        min_value = K.variable([-5., -4., 0., 3., 5.])\n-        max_value = K.variable([5., 4., 1., 4., 9.])\n-\n-        assert np.allclose(K.eval(K.clip(x, min_value, max_value)),\n-                           np.asarray([-5., -4., 0., 4., 9.], dtype=np.float32))\n+        _, x = parse_shape_or_val(shape)\n+        _, min_val = parse_shape_or_val(shape)\n+        max_val = min_val + 1.\n+        x_k = K.variable(x)\n+        min_val_k = K.variable(min_val)\n+        max_val_k = K.variable(max_val)\n+        assert np.allclose(K.eval(K.clip(x_k, min_val_k, max_val_k)),\n+                           KNP.eval(KNP.clip(x, min_val, max_val)))\n \n     @pytest.mark.skipif(K.backend() != 'tensorflow',\n                         reason='This test is for tensorflow parallelism.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ad578c4c19444af9d1f0e0d51a8283eb0db1a264", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 11 | Churn Cumulative: 10843 | Contributors (this commit): 54 | Commits (past 90d): 45 | Contributors (cumulative): 72 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2363,8 +2363,10 @@ def elu(x, alpha=1.):\n \n def in_top_k(predictions, targets, k):\n     _targets = C.one_hot(targets, predictions.shape[-1])\n-    result = C.classification_error(predictions, _targets, topN=k)\n-    return 1 - C.reshape(result, shape=())\n+    result = [C.classification_error(predictions[i], _targets[i], topN=k)\n+              for i in range(predictions.shape[0])]\n+    result = concatenate(result, axis=-1)\n+    return 1 - C.reshape(result, shape=(-1,))\n \n \n def conv2d_transpose(x, kernel, output_shape, strides=(1, 1),\n\n@@ -1128,7 +1128,6 @@ class TestBackend(object):\n                                    WITH_NP, cntk_two_dynamicity=True,\n                                    from_logits=True)\n \n-    @pytest.mark.skipif(K.backend() == 'cntk', reason='Bug in CNTK')\n     def test_in_top_k(self):\n         batch_size = 20\n         num_classes = 10\n@@ -1139,7 +1138,7 @@ class TestBackend(object):\n \n         # (k == 0 or k > num_classes) does not raise an error\n         # but just return an unmeaningful tensor.\n-        for k in range(1, num_classes + 1):\n+        for k in range(1, 2 if K.backend() == 'cntk' else (num_classes + 1)):\n             z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),\n                                         b.variable(targets, dtype='int32'), k))\n                       for b in WITH_NP]\n@@ -1154,7 +1153,7 @@ class TestBackend(object):\n             predictions[i, idx_identical] = predictions[i, 0]\n         targets = np.zeros(batch_size, dtype='int32')\n \n-        for k in range(1, num_classes + 1):\n+        for k in range(1, 2 if K.backend() == 'cntk' else (num_classes + 1)):\n             z_list = [b.eval(b.in_top_k(b.variable(predictions, dtype='float32'),\n                                         b.variable(targets, dtype='int32'), k))\n                       for b in WITH_NP]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c3eb62763fcc5029c26b025ba1b60d7788d491a1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 278 | Lines Deleted: 73 | Files Changed: 5 | Hunks: 36 | Methods Changed: 32 | Complexity Δ (Sum/Max): 31/14 | Churn Δ: 351 | Churn Cumulative: 6726 | Contributors (this commit): 47 | Commits (past 90d): 13 | Contributors (cumulative): 78 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1105,7 +1105,11 @@ class Network(Layer):\n         was never compiled in the first place).\n \n         # Arguments\n-            filepath: String, path to the file to save the weights to.\n+            filepath: one of the following:\n+                - string, path to the file to save the model to\n+                - h5py.File or h5py.Group object where to save the model\n+                - any file-like object implementing the method `write` that accepts\n+                    `bytes` data (e.g. `io.BytesIO`).\n             overwrite: Whether to silently overwrite any existing file at the\n                 target location, or provide the user with a manual prompt.\n             include_optimizer: If True, save optimizer's state together.\n\n@@ -18,8 +18,10 @@ import numpy as np\n \n from .. import backend as K\n from .. import optimizers\n-from ..utils.io_utils import ask_to_proceed_with_overwrite\n from ..utils.io_utils import H5Dict\n+from ..utils.io_utils import ask_to_proceed_with_overwrite\n+from ..utils.io_utils import save_to_binary_h5py\n+from ..utils.io_utils import load_from_binary_h5py\n from ..utils import conv_utils\n \n try:\n@@ -475,8 +477,10 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     # Arguments\n         model: Keras model instance to be saved.\n         filepath: one of the following:\n-            - string, path where to save the model, or\n+            - string, path to the file to save the model to\n             - h5py.File or h5py.Group object where to save the model\n+            - any file-like object implementing the method `write` that accepts\n+                `bytes` data (e.g. `io.BytesIO`).\n         overwrite: Whether we should overwrite any existing\n             model at the target location, or instead\n             ask the user with a manual prompt.\n@@ -488,22 +492,21 @@ def save_model(model, filepath, overwrite=True, include_optimizer=True):\n     if h5py is None:\n         raise ImportError('`save_model` requires h5py.')\n \n-    if not isinstance(filepath, h5py.Group):\n-        # If file exists and should not be overwritten.\n-        if not overwrite and os.path.isfile(filepath):\n+    if H5Dict.is_supported_type(filepath):\n+        opens_file = not isinstance(filepath, (dict, h5py.Group))\n+        if opens_file and os.path.isfile(filepath) and not overwrite:\n             proceed = ask_to_proceed_with_overwrite(filepath)\n             if not proceed:\n                 return\n-        opened_new_file = True\n-    else:\n-        opened_new_file = False\n-\n-    h5dict = H5Dict(filepath, mode='w')\n-    try:\n+        with H5Dict(filepath, mode='w') as h5dict:\n             _serialize_model(model, h5dict, include_optimizer)\n-    finally:\n-        if opened_new_file:\n-            h5dict.close()\n+    elif hasattr(filepath, 'write') and callable(filepath.write):\n+        # write as binary stream\n+        def save_function(h5file):\n+            _serialize_model(model, H5Dict(h5file), include_optimizer)\n+        save_to_binary_h5py(save_function, filepath)\n+    else:\n+        raise ValueError('unexpected type {} for `filepath`'.format(type(filepath)))\n \n \n @allow_read_from_gcs\n@@ -512,8 +515,10 @@ def load_model(filepath, custom_objects=None, compile=True):\n \n     # Arguments\n         filepath: one of the following:\n-            - string, path to the saved model, or\n+            - string, path to the saved model\n             - h5py.File or h5py.Group object from which to load the model\n+            - any file-like object implementing the method `read` that returns\n+            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n         custom_objects: Optional dictionary mapping names\n             (strings) to custom classes or functions to be\n             considered during deserialization.\n@@ -534,14 +539,17 @@ def load_model(filepath, custom_objects=None, compile=True):\n     \"\"\"\n     if h5py is None:\n         raise ImportError('`load_model` requires h5py.')\n-    model = None\n-    opened_new_file = not isinstance(filepath, h5py.Group)\n-    h5dict = H5Dict(filepath, 'r')\n-    try:\n+\n+    if H5Dict.is_supported_type(filepath):\n+        with H5Dict(filepath, mode='r') as h5dict:\n             model = _deserialize_model(h5dict, custom_objects, compile)\n-    finally:\n-        if opened_new_file:\n-            h5dict.close()\n+    elif hasattr(filepath, 'write') and callable(filepath.write):\n+        def load_function(h5file):\n+            return _deserialize_model(H5Dict(h5file), custom_objects, compile)\n+        model = load_from_binary_h5py(load_function, filepath)\n+    else:\n+        raise ValueError('unexpected type {} for `filepath`'.format(type(filepath)))\n+\n     return model\n \n \n\n@@ -6,6 +6,7 @@ from __future__ import print_function\n import numpy as np\n from collections import defaultdict\n import sys\n+import contextlib\n \n \n import six\n@@ -183,16 +184,10 @@ class H5Dict(object):\n     \"\"\"\n \n     def __init__(self, path, mode='a'):\n-        def is_path_instance(path):\n-            # We can't use isinstance here because it would require\n-            # us to add pathlib2 to the Python 2 dependencies.\n-            class_name = type(path).__name__\n-            return class_name == 'PosixPath' or class_name == 'WindowsPath'\n-\n         if isinstance(path, h5py.Group):\n             self.data = path\n             self._is_file = False\n-        elif isinstance(path, six.string_types) or is_path_instance(path):\n+        elif isinstance(path, six.string_types) or _is_path_instance(path):\n             self.data = h5py.File(path, mode=mode)\n             self._is_file = True\n         elif isinstance(path, dict):\n@@ -207,6 +202,16 @@ class H5Dict(object):\n                             'Received: {}.'.format(type(path)))\n         self.read_only = mode == 'r'\n \n+    @staticmethod\n+    def is_supported_type(path):\n+        \"\"\"Check if `path` is of supported type for instantiating a `H5Dict`\"\"\"\n+        return (\n+            isinstance(path, h5py.Group) or\n+            isinstance(path, dict) or\n+            isinstance(path, six.string_types) or\n+            _is_path_instance(path)\n+        )\n+\n     def __setitem__(self, attr, val):\n         if self.read_only:\n             raise ValueError('Cannot set item in read-only mode.')\n@@ -358,5 +363,68 @@ class H5Dict(object):\n             return self[key]\n         return default\n \n+    def __enter__(self):\n+        return self\n+\n+    def __exit__(self, exc_type, exc_val, exc_tb):\n+        self.close()\n+\n \n h5dict = H5Dict\n+\n+\n+def load_from_binary_h5py(load_function, stream):\n+    \"\"\"Calls `load_function` on a `h5py.File` read from the binary `stream`.\n+\n+    # Arguments\n+        load_function: A function that takes a `h5py.File`, reads from it, and\n+            returns any object.\n+        stream: Any file-like object implementing the method `read` that returns\n+            `bytes` data (e.g. `io.BytesIO`) that represents a valid h5py file image.\n+\n+    # Returns\n+        The object returned by `load_function`.\n+    \"\"\"\n+    # Implementation based on suggestion solution here:\n+    #   https://github.com/keras-team/keras/issues/9343#issuecomment-440903847\n+    binary_data = stream.read()\n+    file_access_property_list = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\n+    file_access_property_list.set_fapl_core(backing_store=False)\n+    file_access_property_list.set_file_image(binary_data)\n+    file_id_args = {'fapl': file_access_property_list,\n+                    'flags': h5py.h5f.ACC_RDONLY,\n+                    'name': b'in-memory-h5py'}  # name does not matter\n+    h5_file_args = {'backing_store': False,\n+                    'driver': 'core',\n+                    'mode': 'r'}\n+    with contextlib.closing(h5py.h5f.open(**file_id_args)) as file_id:\n+        with h5py.File(file_id, **h5_file_args) as h5_file:\n+            return load_function(h5_file)\n+\n+\n+def save_to_binary_h5py(save_function, stream):\n+    \"\"\"Calls `save_function` on an in memory `h5py.File`.\n+\n+    The file is subsequently written to the binary `stream`.\n+\n+     # Arguments\n+        save_function: A function that takes a `h5py.File`, writes to it and\n+            (optionally) returns any object.\n+        stream: Any file-like object implementing the method `write` that accepts\n+            `bytes` data (e.g. `io.BytesIO`).\n+     \"\"\"\n+    with h5py.File('in-memory-h5py', driver='core', backing_store=False) as h5file:\n+        # note that filename does not matter here.\n+        return_value = save_function(h5file)\n+        h5file.flush()\n+        binary_data = h5file.fid.get_file_image()\n+    stream.write(binary_data)\n+\n+    return return_value\n+\n+\n+def _is_path_instance(path):\n+    # We can't use isinstance here because it would require\n+    # us to add pathlib2 to the Python 2 dependencies.\n+    class_name = type(path).__name__\n+    return class_name == 'PosixPath' or class_name == 'WindowsPath'\n\n@@ -1,13 +1,20 @@\n '''Tests for functions in io_utils.py.\n '''\n import os\n+import io\n import pytest\n+\n+from contextlib import contextmanager\n+\n from keras.models import Sequential\n from keras.layers import Dense\n from keras.utils.io_utils import HDF5Matrix\n from keras.utils.io_utils import H5Dict\n from keras.utils.io_utils import ask_to_proceed_with_overwrite\n+from keras.utils.io_utils import save_to_binary_h5py\n+from keras.utils.io_utils import load_from_binary_h5py\n from numpy.testing import assert_allclose\n+from numpy.testing import assert_array_equal\n import numpy as np\n import six\n import h5py\n@@ -232,5 +239,115 @@ def test_H5Dict_accepts_pathlib_Path():\n     os.remove(h5_path)\n \n \n+@contextmanager\n+def temp_filename(suffix):\n+    \"\"\"Context that returns a temporary filename and deletes the file on exit if\n+    it still exists (so that this is not forgotten).\n+    \"\"\"\n+    _, temp_fname = tempfile.mkstemp(suffix=suffix)\n+    yield temp_fname\n+    if os.path.exists(temp_fname):\n+        os.remove(temp_fname)\n+\n+\n+def test_save_to_binary_h5py_direct_to_file():\n+    data = np.random.random((3, 5))\n+\n+    def save_function(h5file_):\n+        h5file_['data'] = data\n+\n+    with temp_filename('.h5') as fname:\n+        with open(fname, 'wb') as f:\n+            save_to_binary_h5py(save_function, f)\n+\n+        with h5py.File(fname) as h5file:\n+            data_rec = h5file['data'][:]\n+\n+    assert_array_equal(data_rec, data)\n+\n+\n+def test_save_to_binary_h5py_to_bytes_io():\n+    data = np.random.random((3, 5))\n+\n+    def save_function(h5file_):\n+        h5file_['data'] = data\n+\n+    file_like = io.BytesIO()\n+    save_to_binary_h5py(save_function, file_like)\n+\n+    file_like.seek(0)\n+\n+    with temp_filename('.h5') as fname:\n+        with open(fname, 'wb') as f:\n+            f.write(file_like.read())\n+\n+        with h5py.File(fname) as h5file:\n+            data_rec = h5file['data'][:]\n+\n+    assert_array_equal(data_rec, data)\n+\n+\n+def test_load_from_binary_h5py_direct_from_file():\n+    data = np.random.random((3, 5))\n+\n+    def load_function(h5file_):\n+        return h5file_['data'][:]\n+\n+    with temp_filename('.h5') as fname:\n+        with h5py.File(fname, 'w') as h5file:\n+            h5file['data'] = data\n+\n+        with open(fname, 'rb') as f:\n+            data_rec = load_from_binary_h5py(load_function, f)\n+\n+    assert_array_equal(data_rec, data)\n+\n+\n+def test_load_from_binary_h5py_from_bytes_io():\n+    data = np.random.random((3, 5))\n+\n+    def load_function(h5file_):\n+        return h5file_['data'][:]\n+\n+    with temp_filename('.h5') as fname:\n+        with h5py.File(fname, 'w') as h5file:\n+            h5file['data'] = data\n+\n+        file_like = io.BytesIO()\n+        with open(fname, 'rb') as f:\n+            file_like.write(f.read())\n+\n+    file_like.seek(0)\n+    data_rec = load_from_binary_h5py(load_function, file_like)\n+\n+    assert_array_equal(data_rec, data)\n+\n+\n+def test_save_load_binary_h5py():\n+\n+    data1 = np.random.random((3, 5))\n+    data2 = np.random.random((2, 3, 5))\n+    attr = 1\n+    datas = [data1, data2, attr]\n+\n+    def save_function(h5file_):\n+        h5file_['data1'] = data1\n+        h5file_['subgroup/data2'] = data2\n+        h5file_['data1'].attrs['attr'] = attr\n+\n+    def load_function(h5file_):\n+        d1 = h5file_['data1'][:]\n+        d2 = h5file_['subgroup/data2'][:]\n+        a = h5file_['data1'].attrs['attr']\n+        return d1, d2, a\n+\n+    file_like = io.BytesIO()\n+    save_to_binary_h5py(save_function, file_like)\n+    file_like.seek(0)\n+    datas_rec = load_from_binary_h5py(load_function, file_like)\n+    for d_rec, d in zip(datas_rec, datas):\n+        assert_array_equal(d_rec, d)\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n@@ -1,8 +1,9 @@\n-\n+import io\n import pytest\n import os\n import h5py\n import tempfile\n+from contextlib import contextmanager\n import numpy as np\n from numpy.testing import assert_allclose\n from numpy.testing import assert_raises\n@@ -106,7 +107,7 @@ def test_sequential_model_saving_2():\n         assert_allclose(out, new_out, atol=1e-05)\n \n \n-def test_functional_model_saving():\n+def _get_sample_model_and_input():\n     inputs = Input(shape=(3,))\n     x = Dense(2)(inputs)\n     outputs = Dense(3)(x)\n@@ -118,8 +119,13 @@ def test_functional_model_saving():\n     x = np.random.random((1, 3))\n     y = np.random.random((1, 3))\n     model.train_on_batch(x, y)\n-    out = model.predict(x)\n \n+    return model, x\n+\n+\n+def test_functional_model_saving():\n+    model, x = _get_sample_model_and_input()\n+    out = model.predict(x)\n     _, fname = tempfile.mkstemp('.h5')\n     save_model(model, fname)\n     new_model_disk = load_model(fname)\n@@ -138,17 +144,7 @@ def test_functional_model_saving():\n \n \n def test_model_saving_to_pre_created_h5py_file():\n-    inputs = Input(shape=(3,))\n-    x = Dense(2)(inputs)\n-    outputs = Dense(3)(x)\n-\n-    model = Model(inputs, outputs)\n-    model.compile(loss=losses.MSE,\n-                  optimizer=optimizers.Adam(),\n-                  metrics=[metrics.categorical_accuracy])\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n+    model, x = _get_sample_model_and_input()\n \n     out = model.predict(x)\n     _, fname = tempfile.mkstemp('.h5')\n@@ -174,44 +170,56 @@ def test_model_saving_to_pre_created_h5py_file():\n     assert_allclose(out, out2, atol=1e-05)\n \n \n+@contextmanager\n+def temp_filename(filename):\n+    \"\"\"Context that returns a temporary filename and deletes the file on exit if\n+    it still exists (so that this is not forgotten).\n+    \"\"\"\n+    _, temp_fname = tempfile.mkstemp(filename)\n+    yield temp_fname\n+    if os.path.exists(temp_fname):\n+        os.remove(temp_fname)\n+\n+\n def test_model_saving_to_binary_stream():\n-    inputs = Input(shape=(3,))\n-    x = Dense(2)(inputs)\n-    outputs = Dense(3)(x)\n-\n-    model = Model(inputs, outputs)\n-    model.compile(loss=losses.MSE,\n-                  optimizer=optimizers.Adam(),\n-                  metrics=[metrics.categorical_accuracy])\n-    x = np.random.random((1, 3))\n-    y = np.random.random((1, 3))\n-    model.train_on_batch(x, y)\n-\n+    model, x = _get_sample_model_and_input()\n     out = model.predict(x)\n-    _, fname = tempfile.mkstemp('.h5')\n-    with h5py.File(fname, mode='r+') as h5file:\n-        save_model(model, h5file)\n+\n+    with temp_filename('h5') as fname:\n+        # save directly to binary file\n+        with open(fname, 'wb') as raw_file:\n+            save_model(model, raw_file)\n+        # Load the data the usual way, and make sure the model is intact.\n+        with h5py.File(fname, mode='r') as h5file:\n             loaded_model = load_model(h5file)\n     out2 = loaded_model.predict(x)\n     assert_allclose(out, out2, atol=1e-05)\n \n-    # Save the model to an in-memory-only h5 file.\n-    with h5py.File('does not matter', driver='core',\n-                   backing_store=False) as h5file:\n+\n+def test_model_loading_from_binary_stream():\n+    model, x = _get_sample_model_and_input()\n+    out = model.predict(x)\n+\n+    with temp_filename('h5') as fname:\n+        # save the model the usual way\n+        with h5py.File(fname, mode='w') as h5file:\n             save_model(model, h5file)\n-        h5file.flush()  # Very important! Otherwise you get all zeroes below.\n-        binary_data = h5file.fid.get_file_image()\n-\n-        # Make sure the binary data is correct by saving it to a file manually\n-        # and then loading it the usual way.\n-        with open(fname, 'wb') as raw_file:\n-            raw_file.write(binary_data)\n-\n-    # Load the manually-saved binary data, and make sure the model is intact.\n-    with h5py.File(fname, mode='r') as h5file:\n-        loaded_model = load_model(h5file)\n+        # Load the data binary, and make sure the model is intact.\n+        with open(fname, 'rb') as raw_file:\n+            loaded_model = load_model(raw_file)\n     out2 = loaded_model.predict(x)\n+    assert_allclose(out, out2, atol=1e-05)\n \n+\n+def test_model_save_load_binary_in_memory():\n+    model, x = _get_sample_model_and_input()\n+    out = model.predict(x)\n+\n+    stream = io.BytesIO()\n+    save_model(model, stream)\n+    stream.seek(0)\n+    loaded_model = load_model(stream)\n+    out2 = loaded_model.predict(x)\n     assert_allclose(out, out2, atol=1e-05)\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
