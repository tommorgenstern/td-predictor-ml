{"custom_id": "keras#9854e7b534ad6c05f2fe949b7f7969a4a12eac64", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 39 | Lines Deleted: 42 | Files Changed: 2 | Hunks: 9 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 81 | Churn Cumulative: 6804 | Contributors (this commit): 6 | Commits (past 90d): 34 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -741,9 +741,9 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       return tf.lookup.StaticHashTable(initializer, self._default_value)\n \n   def _standardize_inputs(self, inputs, dtype):\n-    if isinstance(inputs, (list, tuple, np.ndarray)):\n-      inputs = tf.convert_to_tensor(inputs)\n-    if inputs.dtype != dtype:\n+    if not isinstance(inputs, (tf.Tensor, tf.RaggedTensor, tf.SparseTensor)):\n+      inputs = tf.convert_to_tensor(inputs, dtype)\n+    elif inputs.dtype != dtype:\n       inputs = tf.cast(inputs, dtype)\n     return inputs\n \n\n@@ -677,6 +677,15 @@ class CategoricalEncodingAdaptTest(\n     layer.adapt(batched_ds)\n \n \n+class ArrayLike:\n+\n+  def __init__(self, values):\n+    self.values = values\n+\n+  def __array__(self):\n+    return np.array(self.values)\n+\n+\n @keras_parameterized.run_all_keras_modes(always_skip_v1=True)\n class IndexLookupOutputTest(keras_parameterized.TestCase,\n                             preprocessing_test_utils.PreprocessingLayerTest):\n@@ -690,13 +699,31 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n       writer.close()\n     return vocab_path\n \n-  def test_int_output(self):\n+  @parameterized.named_parameters(\n+      (\"array_2d\", [None],\n+       np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n+                 [\"fire\", \"and\", \"earth\", \"michigan\"]]),\n+       [[2, 3, 4, 5],\n+        [5, 4, 2, 1]]),\n+      (\"array_1d\", [],\n+       np.array([\"earth\", \"wind\", \"and\", \"fire\"]),\n+       [2, 3, 4, 5]),\n+      (\"array_0\", [],\n+       tf.constant(\"earth\"),\n+       2),\n+      (\"str\", [],\n+       \"earth\",\n+       2),\n+      (\"list\", [None],\n+       [\"earth\", \"wind\", \"and\", \"fire\"],\n+       [2, 3, 4, 5]),\n+      (\"array_like\", [None],\n+       ArrayLike([\"earth\", \"wind\", \"and\", \"fire\"]),\n+       [2, 3, 4, 5]),\n+  )  # pyformat: disable\n+  def test_int_output(self, shape, input_array, expected_output):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n-                            [\"fire\", \"and\", \"earth\", \"michigan\"]])\n-    expected_output = [[2, 3, 4, 5], [5, 4, 2, 1]]\n \n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n     layer = index_lookup.IndexLookup(\n         max_tokens=None,\n         num_oov_indices=1,\n@@ -704,45 +731,15 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n         oov_token=\"[OOV]\",\n         dtype=tf.string)\n     layer.set_vocabulary(vocab_data)\n-    int_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=int_data)\n-    output_dataset = model.predict(input_array)\n+    output_dataset = layer(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_int_output_rank_one(self):\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_data = np.array([\"earth\", \"wind\", \"and\", \"fire\"])\n-    expected_output = [2, 3, 4, 5]\n-\n-    inputs = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=None,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n+    # Again in a keras.Model\n+    inputs = keras.Input(shape=shape, dtype=tf.string)\n     outputs = layer(inputs)\n     model = keras.Model(inputs=inputs, outputs=outputs)\n-    output_dataset = model(input_data)\n-    self.assertAllEqual(expected_output, output_dataset)\n+    output_dataset = model(tf.constant(input_array))\n \n-  def test_int_output_rank_zero(self):\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_data = tf.constant(\"earth\")\n-    expected_output = 2\n-\n-    inputs = keras.Input(shape=(), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=None,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n-    outputs = layer(inputs)\n-    model = keras.Model(inputs=inputs, outputs=outputs)\n-    output_dataset = model(input_data)\n     self.assertAllEqual(expected_output, output_dataset)\n \n   def test_int_output_shape(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2f6e348a82cafe4a9566191ff5eb09d1d26ad93", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 21 | Files Changed: 5 | Hunks: 20 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 42 | Churn Cumulative: 1719 | Contributors (this commit): 8 | Commits (past 90d): 12 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -22,7 +22,7 @@ import numpy as np\n import keras\n from keras import keras_parameterized\n from keras.applications import imagenet_utils as utils\n-from keras.mixed_precision.policy import set_policy\n+from keras.mixed_precision.policy import set_global_policy\n \n \n class TestImageNetUtils(keras_parameterized.TestCase):\n@@ -160,7 +160,7 @@ class TestImageNetUtils(keras_parameterized.TestCase):\n       },\n   ])\n   def test_preprocess_input_symbolic_mixed_precision(self, mode):\n-    set_policy('mixed_float16')\n+    set_global_policy('mixed_float16')\n     shape = (20, 20, 3)\n     inputs = keras.layers.Input(shape=shape)\n     try:\n@@ -168,7 +168,7 @@ class TestImageNetUtils(keras_parameterized.TestCase):\n           lambda x: utils.preprocess_input(x, mode=mode), output_shape=shape)(\n               inputs)\n     finally:\n-      set_policy('float32')\n+      set_global_policy('float32')\n \n   @parameterized.named_parameters([\n       {'testcase_name': 'channels_last_format',\n\n@@ -84,7 +84,7 @@ def set_floatx(value):\n   Note: It is not recommended to set this to float16 for training, as this will\n   likely cause numeric stability issues. Instead, mixed precision, which is\n   using a mix of float16 and float32, can be used by calling\n-  `tf.keras.mixed_precision.experimental.set_policy('mixed_float16')`. See the\n+  `tf.keras.mixed_precision.set_global_policy('mixed_float16')`. See the\n   [mixed precision guide](\n     https://www.tensorflow.org/guide/keras/mixed_precision) for details.\n \n\n@@ -125,13 +125,13 @@ class EmbeddingTest(keras_parameterized.TestCase):\n   @testing_utils.enable_v2_dtype_behavior\n   def test_mixed_precision_embedding(self):\n     try:\n-      policy.set_policy('mixed_float16')\n+      policy.set_global_policy('mixed_float16')\n       layer = keras.layers.Embedding(input_dim=5, output_dim=2)\n       self.assertEqual(layer._dtype_policy.name, 'mixed_float16')\n       outputs = layer(np.array([0, 1, 2]))\n       self.assertEqual(outputs.dtype, 'float16')\n     finally:\n-      policy.set_policy('float32')\n+      policy.set_global_policy('float32')\n \n \n if __name__ == '__main__':\n\n@@ -450,7 +450,7 @@ def _check_if_mixed_precision_graph_rewrite_is_enabled(policy):\n         'At most, one of the following can be called:\\n\\n'\n         '  1. tf.compat.v1.train.enable_mixed_precision_graph_rewrite() '\n         '(You called this first)\\n'\n-        '  2. tf.keras.mixed_precision.experimental.set_policy() with a mixed '\n+        '  2. tf.keras.mixed_precision.set_global_policy() with a mixed '\n         'precision policy (You called this second)\\n\\n'\n         'You called both functions, which is an error, because both functions '\n         'enable you to use mixed precision. If in doubt which function to use, '\n@@ -460,7 +460,7 @@ def _check_if_mixed_precision_graph_rewrite_is_enabled(policy):\n \n @keras_export('keras.mixed_precision.set_global_policy',\n               'keras.mixed_precision.experimental.set_policy', v1=[])\n-def set_policy(policy):\n+def set_global_policy(policy):\n   \"\"\"Sets the global dtype policy.\n \n   The global policy is the default `tf.keras.mixed_precision.Policy` used for\n@@ -509,8 +509,8 @@ def set_policy(policy):\n     _check_if_mixed_precision_graph_rewrite_is_enabled(policy)\n   if (policy is not None and policy.compute_dtype is not None and\n       not tf.as_dtype(policy.compute_dtype).is_floating):\n-    raise ValueError('set_policy can only be used to set the global policy to '\n-                     'floating-point policies, such as \"float32\" and '\n+    raise ValueError('set_global_policy can only be used to set the global '\n+                     'policy to floating-point policies, such as \"float32\" and '\n                      '\"mixed_float16\", but got policy: %s'\n                      % (policy.name,))\n   _global_policy = policy\n@@ -530,10 +530,10 @@ def policy_scope(policy):\n   \"\"\"\n   old_policy = _global_policy\n   try:\n-    set_policy(policy)\n+    set_global_policy(policy)\n     yield\n   finally:\n-    set_policy(old_policy)\n+    set_global_policy(old_policy)\n \n \n def _is_convertible_to_dtype(dtype):\n\n@@ -141,32 +141,32 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n       default_policy = '_infer'\n     self.assertEqual(mp_policy.global_policy().name, default_policy)\n     try:\n-      mp_policy.set_policy('mixed_float16')\n+      mp_policy.set_global_policy('mixed_float16')\n       self.assertEqual(mp_policy.global_policy().name, 'mixed_float16')\n       with tf.Graph().as_default():  # Policies are not associated with a graph\n         self.assertEqual(mp_policy.global_policy().name, 'mixed_float16')\n-      mp_policy.set_policy('_infer')\n+      mp_policy.set_global_policy('_infer')\n       self.assertEqual(mp_policy.global_policy().name, '_infer')\n       policy = mp_policy.Policy('mixed_bfloat16')\n-      mp_policy.set_policy(policy)\n+      mp_policy.set_global_policy(policy)\n       self.assertIs(mp_policy.global_policy(), policy)\n     finally:\n-      mp_policy.set_policy(None)\n+      mp_policy.set_global_policy(None)\n \n   @testing_utils.enable_v2_dtype_behavior\n   def test_global_policy_dtype_error(self):\n     with self.assertRaisesRegex(\n         ValueError,\n-        'set_policy can only be used to set the global policy to '\n+        'set_global_policy can only be used to set the global policy to '\n         'floating-point policies, such as \"float32\" and \"mixed_float16\", but '\n         'got policy: int32'):\n-      mp_policy.set_policy('int32')\n+      mp_policy.set_global_policy('int32')\n     with self.assertRaisesRegex(\n         ValueError,\n-        'set_policy can only be used to set the global policy to '\n+        'set_global_policy can only be used to set the global policy to '\n         'floating-point policies, such as \"float32\" and \"mixed_float16\", but '\n         'got policy: complex64'):\n-      mp_policy.set_policy(mp_policy.Policy('complex64'))\n+      mp_policy.set_global_policy(mp_policy.Policy('complex64'))\n \n   @testing_utils.enable_v2_dtype_behavior\n   def test_loss_scale_warning(self):\n@@ -301,7 +301,7 @@ class PolicyTest(tf.test.TestCase, parameterized.TestCase):\n       with self.assertRaisesRegex(\n           ValueError, 'cannot be set to \"mixed_float16\", .* the mixed '\n           'precision graph rewrite has already been enabled'):\n-        mp_policy.set_policy('mixed_float16')\n+        mp_policy.set_global_policy('mixed_float16')\n       with mp_policy.policy_scope('float64'):\n         pass  # Non-mixed policies are allowed\n     finally:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7df001e1f57c6b9e3465a990a5949b6b1db05d73", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 167 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ class BenchmarkLayer(tf.test.Benchmark):\n       ds = ds.prefetch(batch_size)\n       img_augmentation = functools.partial(\n           image_augmentation, batch_size=batch_size)\n-      ds = ds.map(img_augmentation,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n+      ds = ds.map(img_augmentation,num_parallel_calls=8)\n       starts.append(time.time())\n       count = 0\n       # Benchmarked code begins here.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#81b6a9b369234aff58a975c5a9c5e0101b6f93a9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 4 | Methods Changed: 0 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 8 | Churn Cumulative: 19167 | Contributors (this commit): 80 | Commits (past 90d): 20 | Contributors (cumulative): 80 | DMM Complexity: None\n\nDIFF:\n@@ -1942,8 +1942,6 @@ class SeparableConv1D(SeparableConv):\n       inputs with shape `(batch_size, channels, length)`.\n     dilation_rate: A single integer, specifying\n       the dilation rate to use for dilated convolution.\n-      Currently, specifying any `dilation_rate` value != 1 is\n-      incompatible with specifying any stride value != 1.\n     depth_multiplier: The number of depthwise convolution output channels for\n       each input channel. The total number of depthwise convolution output\n       channels will be equal to `num_filters_in * depth_multiplier`.\n@@ -1999,9 +1997,6 @@ class SeparableConv1D(SeparableConv):\n   Returns:\n     A tensor of rank 3 representing\n     `activation(separableconv1d(inputs, kernel) + bias)`.\n-\n-  Raises:\n-    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n   \"\"\"\n \n   def __init__(self,\n@@ -2137,8 +2132,6 @@ class SeparableConv2D(SeparableConv):\n       If you never set it, then it will be \"channels_last\".\n     dilation_rate: An integer or tuple/list of 2 integers, specifying\n       the dilation rate to use for dilated convolution.\n-      Currently, specifying any `dilation_rate` value != 1 is\n-      incompatible with specifying any `strides` value != 1.\n     depth_multiplier: The number of depthwise convolution output channels\n       for each input channel.\n       The total number of depthwise convolution output\n@@ -2192,7 +2185,6 @@ class SeparableConv2D(SeparableConv):\n \n   Raises:\n     ValueError: if `padding` is \"causal\".\n-    ValueError: when both `strides` > 1 and `dilation_rate` > 1.\n   \"\"\"\n \n   def __init__(self,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4bc0b6d9dcc325e2f85b931f1c593e6f92ab198f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1297 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -997,8 +997,8 @@ def _compute_fans(shape):\n \n \n def _validate_kwargs(cls_name, kwargs, support_partition=True):\n-  for kwarg in kwargs:\n   allowed_kwargs = [_PARTITION_SHAPE, _PARTITION_OFFSET]\n+  for kwarg in kwargs:\n     if kwarg not in allowed_kwargs:\n       raise TypeError(f'Unknown keyword arguments: {kwarg}. Allowed keyword '\n                       f'arguments: {allowed_kwargs}.')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#634203bbdc1d9a2cf6fbdfdec6c78dbfcddd6b76", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 1167 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -662,7 +662,7 @@ class CosineDecayRestarts(LearningRateSchedule):\n   The learning rate multiplier first decays\n   from 1 to `alpha` for `first_decay_steps` steps. Then, a warm\n   restart is performed. Each new warm restart runs for `t_mul` times more\n-  steps and with `m_mul` times smaller initial learning rate.\n+  steps and with `m_mul` times larger initial learning rate.\n \n   Example usage:\n   ```python\n@@ -700,9 +700,9 @@ class CosineDecayRestarts(LearningRateSchedule):\n       first_decay_steps: A scalar `int32` or `int64` `Tensor` or a Python\n         number. Number of steps to decay over.\n       t_mul: A scalar `float32` or `float64` `Tensor` or a Python number.\n-        Used to derive the number of iterations in the i-th period\n+        Used to derive the number of iterations in the i-th period.\n       m_mul: A scalar `float32` or `float64` `Tensor` or a Python number.\n-        Used to derive the initial learning rate of the i-th period:\n+        Used to derive the initial learning rate of the i-th period.\n       alpha: A scalar `float32` or `float64` Tensor or a Python number.\n         Minimum learning rate value as a fraction of the initial_learning_rate.\n       name: String. Optional name of the operation.  Defaults to 'SGDRDecay'.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa706f99a44f4c7436410e68ccc82ceb8c7a9955", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 3 | Churn Cumulative: 7225 | Contributors (this commit): 95 | Commits (past 90d): 15 | Contributors (cumulative): 95 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1782,7 +1782,8 @@ class EarlyStopping(Callback):\n     elif mode == 'max':\n       self.monitor_op = np.greater\n     else:\n-      if 'acc' in self.monitor:\n+      if (self.monitor.endswith('acc') or self.monitor.endswith('accuracy') or\n+          self.monitor.endswith('auc')):\n         self.monitor_op = np.greater\n       else:\n         self.monitor_op = np.less\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#03fa776d3472f4938954f21862bd3426e524605e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 53 | Lines Deleted: 52 | Files Changed: 51 | Hunks: 52 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 105 | Churn Cumulative: 6672 | Contributors (this commit): 5 | Commits (past 90d): 61 | Contributors (cumulative): 93 | DMM Complexity: None\n\nDIFF:\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Common utils for benchmarks.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import timeit\n import numpy as np\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Tests for benchmark utitilies.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -18,7 +18,7 @@ Mostly from\n https://github.com/tensorflow/models/blob/master/official/utils/misc/distribution_utils.py.\n \"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import json\n import os\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Microbenchmarks for Keras components in eager mode.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n@@ -201,5 +201,6 @@ class KerasLayerCallOverheadBenchmarks(  # pylint: disable=undefined-variable\n \n \n if __name__ == \"__main__\":\n-  assert tf.executing_eagerly()\n+  if tf.compat.v1.executing_eagerly():\n+    # Only run test when eager is enabled (skip test in v1).\n     tf.test.main()\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark tests for CPU performance of Keras models.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import timeit\n import numpy as np\n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n \n\n@@ -17,7 +17,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import numpy as np\n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark tests for Keras metrics memory consumption.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n r\"\"\"Benchmarks on Keras components with different Keras model types.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n\n@@ -20,7 +20,7 @@ To add a new model for memory profile:\n 3. Add the model function to the dict `models`.\n \"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from absl import app\n from absl import flags\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark tests for Keras optimizers.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n from keras.benchmarks import benchmark_util\n from keras.optimizer_v2 import adam\n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import tempfile\n import time\n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -18,7 +18,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n from keras.benchmarks.saved_model_benchmarks import saved_model_benchmark_util\n \n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of bucketized columns with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import numpy as np\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of categorical cross hash columns with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras categorical_encoding preprocessing layer.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import time\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras category_encoding preprocessing layer.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of categorical hash columns with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of categorical hash columns with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns from files with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns from files with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns from lists with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns + indicator from lists with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns + indicator from lists with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of vocabulary columns from lists with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras discretization preprocessing layer's adapt method.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of embedding column with dense inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of embedding column with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark suite for KPL and feature column implementations.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n import itertools\n import math\n import random\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras hashing preprocessing layer.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import itertools\n import random\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras image preprocessing layer.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import functools\n import time\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras text vectorization preprocessing layer's adapt method.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import collections\n import itertools\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras text vectorization preprocessing layer's adapt method.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import os\n import random\n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for Keras text vectorization preprocessing layer's adapt method.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import time\n \n\n@@ -14,7 +14,7 @@\n # ==============================================================================\n \"\"\"Benchmark for KPL implementation of weighted embedding column with varying-length inputs.\"\"\"\n \n-import tensorflow as tf\n+import tensorflow.compat.v2 as tf\n \n import keras\n from tensorflow.python.eager.def_function import function as tf_function\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1618b36aec855f1132b2beee59540074a18057ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 120 | Files Changed: 1 | Hunks: 3 | Methods Changed: 26 | Complexity Δ (Sum/Max): -25/0 | Churn Δ: 124 | Churn Cumulative: 1539 | Contributors (this commit): 5 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -45,124 +45,6 @@ class _UnwrapPreventer:\n     self.value = value\n \n \n-class _DelegatingTrackableMixin:\n-  \"\"\"A mixin that delegates all Trackable methods to another trackable object.\n-\n-  This class must be used with multiple inheritance. A class that subclasses\n-  Trackable can also subclass this class, which causes all Trackable methods to\n-  be delegated to the trackable object passed in the constructor.\n-\n-  A subclass can use this mixin to appear as if it were the trackable passed to\n-  the constructor, from a Checkpoint's perspective. LossScaleOptimizer uses this\n-  mixin, so that the checkpoint format for a LossScaleOptimizer is identical to\n-  the checkpoint format for a normal optimizer. This allows a model to be saved\n-  with a normal Optimizer and restored with a LossScaleOptimizer, or vice versa.\n-  The only difference in checkpoint format is that the loss scale is also saved\n-  with a LossScaleOptimizer.\n-  \"\"\"\n-\n-  def __init__(self, trackable_obj):\n-    self._trackable = trackable_obj\n-\n-  # pylint: disable=protected-access\n-  @property\n-  def _setattr_tracking(self):\n-    return self._trackable._setattr_tracking\n-\n-  @_setattr_tracking.setter\n-  def _setattr_tracking(self, value):\n-    self._trackable._setattr_tracking = value\n-\n-  @property\n-  def _update_uid(self):\n-    return self._trackable._update_uid\n-\n-  @_update_uid.setter\n-  def _update_uid(self, value):\n-    self._trackable._update_uid = value\n-\n-  @property\n-  def _unconditional_checkpoint_dependencies(self):\n-    return self._trackable._unconditional_checkpoint_dependencies\n-\n-  @property\n-  def _unconditional_dependency_names(self):\n-    return self._trackable._unconditional_dependency_names\n-\n-  @property\n-  def _name_based_restores(self):\n-    return self._trackable._name_based_restores\n-\n-  def _maybe_initialize_trackable(self):\n-    return self._trackable._maybe_initialize_trackable()\n-\n-  @property\n-  def _object_identifier(self):\n-    return self._trackable._object_identifier\n-\n-  @property\n-  def _tracking_metadata(self):\n-    return self._trackable._tracking_metadata\n-\n-  def _no_dependency(self, value):\n-    return self._trackable._no_dependency(value)\n-\n-  def _name_based_attribute_restore(self, checkpoint):\n-    return self._trackable._name_based_attribute_restore(checkpoint)\n-\n-  @property\n-  def _checkpoint_dependencies(self):\n-    return self._trackable._checkpoint_dependencies\n-\n-  @property\n-  def _deferred_dependencies(self):\n-    return self._trackable._deferred_dependencies\n-\n-  def _lookup_dependency(self, name):\n-    self._trackable._lookup_dependency(name)\n-\n-  def _add_variable_with_custom_getter(self,\n-                                       name,\n-                                       shape=None,\n-                                       dtype=tf.float32,\n-                                       initializer=None,\n-                                       getter=None,\n-                                       overwrite=False,\n-                                       **kwargs_for_getter):\n-    return self._trackable._add_variable_with_custom_getter(\n-        name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\n-\n-  def _preload_simple_restoration(self, name):\n-    return self._trackable._preload_simple_restoration(name)\n-\n-  def _track_trackable(self, trackable, name, overwrite=False):  # pylint: disable=redefined-outer-name\n-    return self._trackable._track_trackable(trackable, name, overwrite)\n-\n-  def _handle_deferred_dependencies(self, name, trackable):  # pylint: disable=redefined-outer-name\n-    return self._trackable._handle_deferred_dependencies(name, trackable)\n-\n-  def _restore_from_checkpoint_position(self, checkpoint_position):\n-    return self._trackable._restore_from_checkpoint_position(\n-        checkpoint_position)\n-\n-  def _single_restoration_from_checkpoint_position(self, checkpoint_position,\n-                                                   visit_queue):\n-    return self._trackable._single_restoration_from_checkpoint_position(\n-        checkpoint_position, visit_queue)\n-\n-  def _gather_saveables_for_checkpoint(self):\n-    return self._trackable._gather_saveables_for_checkpoint()\n-\n-  def _list_extra_dependencies_for_serialization(self, serialization_cache):\n-    return self._trackable._list_extra_dependencies_for_serialization(\n-        serialization_cache)\n-\n-  def _list_functions_for_serialization(self, serialization_cache):\n-    return self._trackable._list_functions_for_serialization(\n-        serialization_cache)\n-  # pylint: enable=protected-access\n-\n-\n def _is_all_finite(grads):\n   \"\"\"Returns a scalar boolean tensor indicating if all gradients are finite.\"\"\"\n   is_finite_per_grad = [\n@@ -372,7 +254,8 @@ _DEFAULT_GROWTH_STEPS = 2000\n \n # pylint: disable=g-classes-have-attributes\n @keras_export('keras.mixed_precision.LossScaleOptimizer')\n-class LossScaleOptimizer(_DelegatingTrackableMixin, optimizer_v2.OptimizerV2):\n+class LossScaleOptimizer(tf.__internal__.tracking.DelegatingTrackableMixin,\n+                         optimizer_v2.OptimizerV2):\n   \"\"\"An optimizer that applies loss scaling to prevent numeric underflow.\n \n   Loss scaling is a technique to prevent numeric underflow in intermediate\n@@ -530,7 +413,8 @@ class LossScaleOptimizer(_DelegatingTrackableMixin, optimizer_v2.OptimizerV2):\n \n     # We don't call super().__init__, since we do not want to call OptimizerV2's\n     # constructor.\n-    _DelegatingTrackableMixin.__init__(self, self._optimizer)\n+    tf.__internal__.tracking.DelegatingTrackableMixin.__init__(self,\n+                                                               self._optimizer)\n \n     if dynamic:\n       if initial_scale is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b99e9fcb746b141472050eafc5b45761674c12a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 93 | Files Changed: 2 | Hunks: 19 | Methods Changed: 16 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 123 | Churn Cumulative: 4795 | Contributors (this commit): 40 | Commits (past 90d): 13 | Contributors (cumulative): 44 | DMM Complexity: 0.0\n\nDIFF:\n@@ -35,6 +35,9 @@ from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n from tensorflow.python.util.tf_export import keras_export\n \n+_GLOBAL_CUSTOM_OBJECTS = {}\n+_GLOBAL_CUSTOM_NAMES = {}\n+\n # Flag that determines whether to skip the NotImplementedError when calling\n # get_config in custom models and layers. This is only enabled when saving to\n # SavedModel, when the config isn't required.\n@@ -44,17 +47,6 @@ _SKIP_FAILED_SERIALIZATION = False\n _LAYER_UNDEFINED_CONFIG_KEY = 'layer was saved without config'\n \n \n-class CustomObjectsContext(threading.local):\n-\n-  def __init__(self):\n-    super(CustomObjectsContext, self).__init__()\n-    self.objects = {}\n-    self.names = {}\n-\n-\n-GLOBAL_CUSTOM_OBJECTS = CustomObjectsContext()\n-\n-\n @keras_export('keras.utils.custom_object_scope',  # pylint: disable=g-classes-have-attributes\n               'keras.utils.CustomObjectScope')\n class CustomObjectScope:\n@@ -87,14 +79,14 @@ class CustomObjectScope:\n     self.backup = None\n \n   def __enter__(self):\n-    self.backup = GLOBAL_CUSTOM_OBJECTS.objects.copy()\n+    self.backup = _GLOBAL_CUSTOM_OBJECTS.copy()\n     for objects in self.custom_objects:\n-      GLOBAL_CUSTOM_OBJECTS.objects.update(objects)\n+      _GLOBAL_CUSTOM_OBJECTS.update(objects)\n     return self\n \n   def __exit__(self, *args, **kwargs):\n-    GLOBAL_CUSTOM_OBJECTS.objects.clear()\n-    GLOBAL_CUSTOM_OBJECTS.objects.update(self.backup)\n+    _GLOBAL_CUSTOM_OBJECTS.clear()\n+    _GLOBAL_CUSTOM_OBJECTS.update(self.backup)\n \n \n @keras_export('keras.utils.get_custom_objects')\n@@ -113,9 +105,9 @@ def get_custom_objects():\n   ```\n \n   Returns:\n-      Global dictionary of names to classes (`GLOBAL_CUSTOM_OBJECTS.objects`).\n+      Global dictionary of names to classes (`_GLOBAL_CUSTOM_OBJECTS`).\n   \"\"\"\n-  return GLOBAL_CUSTOM_OBJECTS.objects\n+  return _GLOBAL_CUSTOM_OBJECTS\n \n \n # Store a unique, per-object ID for shared objects.\n@@ -382,16 +374,16 @@ def register_keras_serializable(package='Custom', name=None):\n       raise ValueError(\n           'Cannot register a class that does not have a get_config() method.')\n \n-    if registered_name in GLOBAL_CUSTOM_OBJECTS.objects:\n-      raise ValueError(f'{registered_name} has already been registered to '\n-                       f'{GLOBAL_CUSTOM_OBJECTS.objects[registered_name]}')\n-\n-    if arg in GLOBAL_CUSTOM_OBJECTS.names:\n+    if registered_name in _GLOBAL_CUSTOM_OBJECTS:\n       raise ValueError(\n-          f'{arg} has already been registered to {GLOBAL_CUSTOM_OBJECTS.names[arg]}'\n-      )\n-    GLOBAL_CUSTOM_OBJECTS.objects[registered_name] = arg\n-    GLOBAL_CUSTOM_OBJECTS.names[arg] = registered_name\n+          f'{registered_name} has already been registered to '\n+          f'{_GLOBAL_CUSTOM_OBJECTS[registered_name]}')\n+\n+    if arg in _GLOBAL_CUSTOM_NAMES:\n+      raise ValueError(\n+          f'{arg} has already been registered to {_GLOBAL_CUSTOM_NAMES[arg]}')\n+    _GLOBAL_CUSTOM_OBJECTS[registered_name] = arg\n+    _GLOBAL_CUSTOM_NAMES[arg] = registered_name\n \n     return arg\n \n@@ -413,8 +405,8 @@ def get_registered_name(obj):\n     The name associated with the object, or the default Python name if the\n       object is not registered.\n   \"\"\"\n-  if obj in GLOBAL_CUSTOM_OBJECTS.names:\n-    return GLOBAL_CUSTOM_OBJECTS.names[obj]\n+  if obj in _GLOBAL_CUSTOM_NAMES:\n+    return _GLOBAL_CUSTOM_NAMES[obj]\n   else:\n     return obj.__name__\n \n@@ -457,8 +449,8 @@ def get_registered_object(name, custom_objects=None, module_objects=None):\n     An instantiable class associated with 'name', or None if no such class\n       exists.\n   \"\"\"\n-  if name in GLOBAL_CUSTOM_OBJECTS.objects:\n-    return GLOBAL_CUSTOM_OBJECTS.objects[name]\n+  if name in _GLOBAL_CUSTOM_OBJECTS:\n+    return _GLOBAL_CUSTOM_OBJECTS[name]\n   elif custom_objects and name in custom_objects:\n     return custom_objects[name]\n   elif module_objects and name in module_objects:\n@@ -543,8 +535,8 @@ def serialize_keras_object(instance):\n \n def get_custom_objects_by_name(item, custom_objects=None):\n   \"\"\"Returns the item if it is in either local or global custom objects.\"\"\"\n-  if item in GLOBAL_CUSTOM_OBJECTS.objects:\n-    return GLOBAL_CUSTOM_OBJECTS.objects[item]\n+  if item in _GLOBAL_CUSTOM_OBJECTS:\n+    return _GLOBAL_CUSTOM_OBJECTS[item]\n   elif custom_objects and item in custom_objects:\n     return custom_objects[item]\n   return None\n@@ -686,7 +678,7 @@ def deserialize_keras_object(identifier,\n         deserialized_obj = cls.from_config(\n             cls_config,\n             custom_objects=dict(\n-                list(GLOBAL_CUSTOM_OBJECTS.objects.items()) +\n+                list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n                 list(custom_objects.items())))\n       else:\n         with CustomObjectScope(custom_objects):\n@@ -708,8 +700,8 @@ def deserialize_keras_object(identifier,\n     object_name = identifier\n     if custom_objects and object_name in custom_objects:\n       obj = custom_objects.get(object_name)\n-    elif object_name in GLOBAL_CUSTOM_OBJECTS.objects:\n-      obj = GLOBAL_CUSTOM_OBJECTS.objects[object_name]\n+    elif object_name in _GLOBAL_CUSTOM_OBJECTS:\n+      obj = _GLOBAL_CUSTOM_OBJECTS[object_name]\n     else:\n       obj = module_objects.get(object_name)\n       if obj is None:\n\n@@ -17,7 +17,6 @@\n import tensorflow.compat.v2 as tf\n \n from functools import partial\n-import threading\n \n import numpy as np\n \n@@ -88,58 +87,6 @@ class TestCustomObjectScope(tf.test.TestCase):\n       cl = keras.regularizers.get('CustomClass')\n       self.assertEqual(cl.__class__, CustomClass)\n \n-  def test_custom_object_scope_thread_safety(self):\n-\n-    class CustomClass:\n-      pass\n-\n-    def custom_object_scope_in_thread(event_start, event_entered, event_finish,\n-                                      event_exited):\n-\n-      def fn():\n-        event_start.wait()\n-        with keras.utils.generic_utils.custom_object_scope(\n-            {'CustomClass': CustomClass}):\n-          event_entered.set()\n-          event_finish.wait()\n-        event_exited.set()\n-\n-      return fn\n-\n-    event_start_1 = threading.Event()\n-    event_entered_1 = threading.Event()\n-    event_finish_1 = threading.Event()\n-    event_exited_1 = threading.Event()\n-    thread_1 = threading.Thread(\n-        target=custom_object_scope_in_thread(event_start_1, event_entered_1,\n-                                             event_finish_1, event_exited_1))\n-\n-    event_start_2 = threading.Event()\n-    event_entered_2 = threading.Event()\n-    event_finish_2 = threading.Event()\n-    event_exited_2 = threading.Event()\n-    thread_2 = threading.Thread(\n-        target=custom_object_scope_in_thread(event_start_2, event_entered_2,\n-                                             event_finish_2, event_exited_2))\n-\n-    keras.utils.generic_utils.get_custom_objects().clear()\n-    thread_1.start()\n-    thread_2.start()\n-\n-    event_start_1.set()\n-    event_entered_1.wait()\n-    event_start_2.set()\n-    event_entered_2.wait()\n-\n-    event_finish_1.set()\n-    event_exited_1.wait()\n-    event_finish_2.set()\n-    event_exited_2.wait()\n-\n-    thread_1.join()\n-    thread_2.join()\n-    self.assertEqual(keras.utils.generic_utils.get_custom_objects(), {})\n-\n \n class SerializeKerasObjectTest(tf.test.TestCase):\n \n@@ -163,8 +110,7 @@ class SerializeKerasObjectTest(tf.test.TestCase):\n \n     serialized_name = 'Custom>TestClass'\n     inst = TestClass(value=10)\n-    class_name = keras.utils.generic_utils.GLOBAL_CUSTOM_OBJECTS.names[\n-        TestClass]\n+    class_name = keras.utils.generic_utils._GLOBAL_CUSTOM_NAMES[TestClass]\n     self.assertEqual(serialized_name, class_name)\n     config = keras.utils.generic_utils.serialize_keras_object(inst)\n     self.assertEqual(class_name, config['class_name'])\n@@ -198,8 +144,7 @@ class SerializeKerasObjectTest(tf.test.TestCase):\n \n     serialized_name = 'TestPackage>CustomName'\n     inst = OtherTestClass(val=5)\n-    class_name = keras.utils.generic_utils.GLOBAL_CUSTOM_OBJECTS.names[\n-        OtherTestClass]\n+    class_name = keras.utils.generic_utils._GLOBAL_CUSTOM_NAMES[OtherTestClass]\n     self.assertEqual(serialized_name, class_name)\n     fn_class_name = keras.utils.generic_utils.get_registered_name(\n         OtherTestClass)\n@@ -222,7 +167,7 @@ class SerializeKerasObjectTest(tf.test.TestCase):\n       return 42\n \n     serialized_name = 'Custom>my_fn'\n-    class_name = keras.utils.generic_utils.GLOBAL_CUSTOM_OBJECTS.names[my_fn]\n+    class_name = keras.utils.generic_utils._GLOBAL_CUSTOM_NAMES[my_fn]\n     self.assertEqual(serialized_name, class_name)\n     fn_class_name = keras.utils.generic_utils.get_registered_name(my_fn)\n     self.assertEqual(fn_class_name, class_name)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
