{"custom_id": "keras#9290fc954aa762d5532afe6704ebe5f59db8090f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 23 | Files Changed: 4 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 71 | Churn Cumulative: 2769 | Contributors (this commit): 10 | Commits (past 90d): 62 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -4,6 +4,7 @@ from keras_core.backend.tensorflow import math\n from keras_core.backend.tensorflow import nn\n from keras_core.backend.tensorflow import numpy\n from keras_core.backend.tensorflow import random\n+from keras_core.backend.tensorflow import tensorboard\n from keras_core.backend.tensorflow.core import DYNAMIC_SHAPES_OK\n from keras_core.backend.tensorflow.core import Variable\n from keras_core.backend.tensorflow.core import cast\n\n@@ -0,0 +1,9 @@\n+import tensorflow as tf\n+\n+\n+def start_trace(logdir):\n+    tf.profiler.experimental.start(logdir=logdir)\n+\n+\n+def stop_trace(save):\n+    tf.profiler.experimental.stop(save=save)\n\n@@ -183,7 +183,9 @@ class TensorBoard(Callback):\n         self.update_freq = 1 if update_freq == \"batch\" else update_freq\n         self.embeddings_freq = embeddings_freq\n         self.embeddings_metadata = embeddings_metadata\n-        self._init_profile_batch(0)  # TODO: profiling not available in JAX\n+        self._init_profile_batch(\n+            profile_batch\n+        )  # TODO: profiling not available in JAX\n         self._global_train_batch = 0\n         self._previous_epoch_iterations = 0\n         self._train_accumulated_time = 0\n\n@@ -3,11 +3,13 @@ import os\n import random\n \n import numpy as np\n+import pytest\n import tensorflow.summary as summary\n from tensorflow.compat.v1 import SummaryMetadata\n from tensorflow.core.util import event_pb2\n from tensorflow.python.lib.io import tf_record\n \n+from keras_core import backend\n from keras_core import callbacks\n from keras_core import layers\n from keras_core import losses\n@@ -704,32 +706,43 @@ class TestTensorBoardV2(testing.TestCase):\n         # self.fitModelAndAssertKerasModelWritten(model)\n         pass\n \n+    @pytest.mark.skipif(\n+        backend.backend() != \"tensorflow\",\n+        reason=\"The profiling test can only run with TF backend.\",\n+    )\n     def test_TensorBoard_auto_trace(self):\n         # TODO: Waiting for implementation for torch/jax for profiling ops\n         # if backend.backend() == \"jax\":\n         #       return\n         # TODO: Debug profiling for JAX\n-        # model = self._get_seq_model()\n-        # x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n-        # tb_cbk = callbacks.TensorBoard(\n-        #     logdir, histogram_freq=1, profile_batch=1, write_graph=False\n-        # )\n+        logdir, train_dir, validation_dir = self._get_log_dirs()\n+        model = models.Sequential(\n+            [\n+                layers.Input((10, 10, 1)),\n+                layers.Flatten(),\n+                layers.Dense(1),\n+            ]\n+        )\n+        x, y = np.ones((10, 10, 10, 1)), np.ones((10, 1))\n+        tb_cbk = callbacks.TensorBoard(\n+            logdir, histogram_freq=1, profile_batch=1, write_graph=False\n+        )\n+        model.compile(\"sgd\", \"mse\")\n+        model.fit(\n+            x,\n+            y,\n+            batch_size=2,\n+            epochs=2,\n+            validation_data=(x, y),\n+            callbacks=[tb_cbk],\n+        )\n+        summary_file = list_summaries(logdir)\n \n-        # model.fit(\n-        #     x,\n-        #     y,\n-        #     batch_size=2,\n-        #     epochs=2,\n-        #     validation_data=(x, y),\n-        #     callbacks=[tb_cbk],\n-        # )\n-        # summary_file = list_summaries(logdir)\n-\n-        # self.assertEqual(\n-        #     summary_file.tensors,\n-        #     {\n-        #         _ObservedSummary(logdir=train_dir, tag=\"batch_1\"),\n-        #     },\n-        # )\n-        # self.assertEqual(1, self._count_xplane_file(logdir=logdir))\n+        self.assertEqual(\n+            summary_file.tensors,\n+            {\n+                _ObservedSummary(logdir=train_dir, tag=\"batch_1\"),\n+            },\n+        )\n+        self.assertEqual(1, self._count_xplane_file(logdir=logdir))\n         pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2923ef03f87fe2851fb6efa535df08ed14b3c09c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 383 | Contributors (this commit): 5 | Commits (past 90d): 10 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -42,7 +42,7 @@ def set_floatx(value):\n     as this will likely cause numeric stability issues.\n     Instead, mixed precision, which leverages\n     a mix of `float16` and `float32`. It can be configured by calling\n-    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n+    `keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#942d5958d4b8f696a5154032bf859b7db47db511", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 575 | Contributors (this commit): 5 | Commits (past 90d): 19 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -30,7 +30,7 @@ epochs = 3\n \n model = keras_core.Sequential(\n     [\n-        layers.Input(shape=input_shape, batch_size=batch_size),\n+        layers.Input(shape=input_shape),\n         layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n         layers.MaxPooling2D(pool_size=(2, 2)),\n         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n\n@@ -42,7 +42,7 @@ def set_floatx(value):\n     as this will likely cause numeric stability issues.\n     Instead, mixed precision, which leverages\n     a mix of `float16` and `float32`. It can be configured by calling\n-    `keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.\n+    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`.\n\n@@ -100,7 +100,7 @@ class HashedCrossing(Layer):\n \n     def call(self, inputs):\n         outputs = self.layer.call(inputs)\n-        if backend.backend() != \"tensorflow\":\n+        if backend.backend() != \"tensorflow\" and tf.executing_eagerly():\n             outputs = backend.convert_to_tensor(outputs)\n         return outputs\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bf9af2d6af2446e29c26a9113adf7508ae5b1ace", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 387 | Contributors (this commit): 5 | Commits (past 90d): 12 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -42,7 +42,7 @@ def set_floatx(value):\n     as this will likely cause numeric stability issues.\n     Instead, mixed precision, which leverages\n     a mix of `float16` and `float32`. It can be configured by calling\n-    `keras_core.mixed_precision.set_global_policy('mixed_float16')`.\n+    `keras_core.mixed_precision.set_dtype_policy('mixed_float16')`.\n \n     Args:\n         value: String; `'float16'`, `'float32'`, or `'float64'`.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e2da5ee703fd26be38841ac74e7a24fa368e47f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 10 | Files Changed: 2 | Hunks: 10 | Methods Changed: 4 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 50 | Churn Cumulative: 2554 | Contributors (this commit): 4 | Commits (past 90d): 26 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -26,7 +26,7 @@ class RNN(Layer):\n             section \"Note on passing external constants\" below.\n             - A `state_size` attribute. This can be a single integer\n             (single state) in which case it is the size of the recurrent\n-            state. This can also be a list of integers\n+            state. This can also be a list/tuple of integers\n             (one size per state).\n             - A `output_size` attribute, a single integer.\n             - A `get_initial_state(batch_size=None)`\n@@ -227,16 +227,16 @@ class RNN(Layer):\n             raise ValueError(\n                 \"state_size must be specified as property on the RNN cell.\"\n             )\n-        if not isinstance(state_size, (list, int)):\n+        if not isinstance(state_size, (list, tuple, int)):\n             raise ValueError(\n-                \"state_size must be an integer, or a list of integers \"\n+                \"state_size must be an integer, or a list/tuple of integers \"\n                 \"(one for each state tensor).\"\n             )\n         if isinstance(state_size, int):\n             self.state_size = [state_size]\n             self.single_state = True\n         else:\n-            self.state_size = state_size\n+            self.state_size = list(state_size)\n             self.single_state = False\n \n     def compute_output_shape(self, sequences_shape, initial_state_shape=None):\n\n@@ -8,10 +8,10 @@ from keras_core import testing\n \n \n class OneStateRNNCell(layers.Layer):\n-    def __init__(self, units, **kwargs):\n+    def __init__(self, units, state_size=None, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = units\n+        self.state_size = state_size if state_size else units\n \n     def build(self, input_shape):\n         self.kernel = self.add_weight(\n@@ -34,10 +34,10 @@ class OneStateRNNCell(layers.Layer):\n \n \n class TwoStatesRNNCell(layers.Layer):\n-    def __init__(self, units, **kwargs):\n+    def __init__(self, units, state_size=None, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = [units, units]\n+        self.state_size = state_size if state_size else [units, units]\n         self.output_size = units\n \n     def build(self, input_shape):\n@@ -72,7 +72,27 @@ class RNNTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": OneStateRNNCell(5)},\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=5)},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=[5])},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=(5,))},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=2,\n@@ -106,7 +126,17 @@ class RNNTest(testing.TestCase):\n         )\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": TwoStatesRNNCell(5)},\n+            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=[5, 5])},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=(5, 5))},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=3,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#43bded597d95dcda4835b530552390edf9f175e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 130 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,12 +67,20 @@ class InputLayer(Layer):\n \n \n @keras_core_export([\"keras_core.layers.Input\", \"keras_core.Input\"])\n-def Input(shape=None, batch_size=None, dtype=None, batch_shape=None, name=None):\n+def Input(\n+    shape=None,\n+    batch_size=None,\n+    dtype=None,\n+    batch_shape=None,\n+    name=None,\n+    tensor=None,\n+):\n     layer = InputLayer(\n         shape=shape,\n         batch_size=batch_size,\n         dtype=dtype,\n         batch_shape=batch_shape,\n         name=name,\n+        input_tensor=tensor,\n     )\n     return layer.output\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2338b8a6c466cde16d37fcf5247935a4fc7cedba", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 54 | Files Changed: 5 | Hunks: 18 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/2 | Churn Δ: 74 | Churn Cumulative: 4034 | Contributors (this commit): 9 | Commits (past 90d): 56 | Contributors (cumulative): 17 | DMM Complexity: 0.0\n\nDIFF:\n@@ -67,20 +67,12 @@ class InputLayer(Layer):\n \n \n @keras_core_export([\"keras_core.layers.Input\", \"keras_core.Input\"])\n-def Input(\n-    shape=None,\n-    batch_size=None,\n-    dtype=None,\n-    batch_shape=None,\n-    name=None,\n-    tensor=None,\n-):\n+def Input(shape=None, batch_size=None, dtype=None, batch_shape=None, name=None):\n     layer = InputLayer(\n         shape=shape,\n         batch_size=batch_size,\n         dtype=dtype,\n         batch_shape=batch_shape,\n         name=name,\n-        input_tensor=tensor,\n     )\n     return layer.output\n\n@@ -26,7 +26,7 @@ class RNN(Layer):\n             section \"Note on passing external constants\" below.\n             - A `state_size` attribute. This can be a single integer\n             (single state) in which case it is the size of the recurrent\n-            state. This can also be a list/tuple of integers\n+            state. This can also be a list of integers\n             (one size per state).\n             - A `output_size` attribute, a single integer.\n             - A `get_initial_state(batch_size=None)`\n@@ -227,16 +227,16 @@ class RNN(Layer):\n             raise ValueError(\n                 \"state_size must be specified as property on the RNN cell.\"\n             )\n-        if not isinstance(state_size, (list, tuple, int)):\n+        if not isinstance(state_size, (list, int)):\n             raise ValueError(\n-                \"state_size must be an integer, or a list/tuple of integers \"\n+                \"state_size must be an integer, or a list of integers \"\n                 \"(one for each state tensor).\"\n             )\n         if isinstance(state_size, int):\n             self.state_size = [state_size]\n             self.single_state = True\n         else:\n-            self.state_size = list(state_size)\n+            self.state_size = state_size\n             self.single_state = False\n \n     def compute_output_shape(self, sequences_shape, initial_state_shape=None):\n\n@@ -8,10 +8,10 @@ from keras_core import testing\n \n \n class OneStateRNNCell(layers.Layer):\n-    def __init__(self, units, state_size=None, **kwargs):\n+    def __init__(self, units, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = state_size if state_size else units\n+        self.state_size = units\n \n     def build(self, input_shape):\n         self.kernel = self.add_weight(\n@@ -34,10 +34,10 @@ class OneStateRNNCell(layers.Layer):\n \n \n class TwoStatesRNNCell(layers.Layer):\n-    def __init__(self, units, state_size=None, **kwargs):\n+    def __init__(self, units, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = state_size if state_size else [units, units]\n+        self.state_size = [units, units]\n         self.output_size = units\n \n     def build(self, input_shape):\n@@ -72,27 +72,7 @@ class RNNTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=5)},\n-            input_shape=(3, 2, 4),\n-            expected_output_shape=(3, 5),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=[5])},\n-            input_shape=(3, 2, 4),\n-            expected_output_shape=(3, 5),\n-            expected_num_trainable_weights=2,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=(5,))},\n+            init_kwargs={\"cell\": OneStateRNNCell(5)},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=2,\n@@ -126,17 +106,7 @@ class RNNTest(testing.TestCase):\n         )\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=[5, 5])},\n-            input_shape=(3, 2, 4),\n-            expected_output_shape=(3, 5),\n-            expected_num_trainable_weights=3,\n-            expected_num_non_trainable_weights=0,\n-            expected_num_seed_generators=0,\n-            supports_masking=True,\n-        )\n-        self.run_layer_test(\n-            layers.RNN,\n-            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=(5, 5))},\n+            init_kwargs={\"cell\": TwoStatesRNNCell(5)},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=3,\n\n@@ -2,13 +2,17 @@ from keras_core import backend\n from keras_core import operations as ops\n \n \n-def float_dtype_size(dtype):\n+def dtype_size(dtype):\n     if dtype in (\"bfloat16\", \"float16\"):\n         return 16\n-    if dtype == \"float32\":\n+    if dtype in (\"float32\", \"int32\"):\n         return 32\n-    if dtype == \"float64\":\n+    if dtype in (\"float64\", \"int64\"):\n         return 64\n+    if dtype == \"uint8\":\n+        return 8\n+    if dtype == \"bool\":\n+        return 1\n     raise ValueError(f\"Invalid dtype: {dtype}\")\n \n \n@@ -32,7 +36,7 @@ def cast_to_common_dtype(tensors):\n     for x in tensors:\n         dtype = backend.standardize_dtype(x.dtype)\n         if is_float(dtype):\n-            if highest_float is None or float_dtype_size(dtype) > highest_float:\n+            if highest_float is None or dtype_size(dtype) > highest_float:\n                 highest_float = dtype\n             elif dtype == \"float16\" and highest_float == \"bfloat16\":\n                 highest_float = \"float32\"\n\n@@ -30,7 +30,7 @@ def weight_memory_size(weights):\n     for w in unique_weights:\n         weight_shape = math.prod(w.shape)\n         dtype = backend.standardize_dtype(w.dtype)\n-        per_param_size = dtype_utils.float_dtype_size(dtype)\n+        per_param_size = dtype_utils.dtype_size(dtype)\n         total_memory_size += weight_shape * per_param_size\n     return total_memory_size\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9fb21bbafc52565675ebc728b5b1bc0b6f301f72", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 49 | Lines Deleted: 11 | Files Changed: 3 | Hunks: 12 | Methods Changed: 6 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 60 | Churn Cumulative: 2804 | Contributors (this commit): 6 | Commits (past 90d): 40 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -67,12 +67,20 @@ class InputLayer(Layer):\n \n \n @keras_core_export([\"keras_core.layers.Input\", \"keras_core.Input\"])\n-def Input(shape=None, batch_size=None, dtype=None, batch_shape=None, name=None):\n+def Input(\n+    shape=None,\n+    batch_size=None,\n+    dtype=None,\n+    batch_shape=None,\n+    name=None,\n+    tensor=None,\n+):\n     layer = InputLayer(\n         shape=shape,\n         batch_size=batch_size,\n         dtype=dtype,\n         batch_shape=batch_shape,\n         name=name,\n+        input_tensor=tensor,\n     )\n     return layer.output\n\n@@ -26,7 +26,7 @@ class RNN(Layer):\n             section \"Note on passing external constants\" below.\n             - A `state_size` attribute. This can be a single integer\n             (single state) in which case it is the size of the recurrent\n-            state. This can also be a list of integers\n+            state. This can also be a list/tuple of integers\n             (one size per state).\n             - A `output_size` attribute, a single integer.\n             - A `get_initial_state(batch_size=None)`\n@@ -227,16 +227,16 @@ class RNN(Layer):\n             raise ValueError(\n                 \"state_size must be specified as property on the RNN cell.\"\n             )\n-        if not isinstance(state_size, (list, int)):\n+        if not isinstance(state_size, (list, tuple, int)):\n             raise ValueError(\n-                \"state_size must be an integer, or a list of integers \"\n+                \"state_size must be an integer, or a list/tuple of integers \"\n                 \"(one for each state tensor).\"\n             )\n         if isinstance(state_size, int):\n             self.state_size = [state_size]\n             self.single_state = True\n         else:\n-            self.state_size = state_size\n+            self.state_size = list(state_size)\n             self.single_state = False\n \n     def compute_output_shape(self, sequences_shape, initial_state_shape=None):\n\n@@ -8,10 +8,10 @@ from keras_core import testing\n \n \n class OneStateRNNCell(layers.Layer):\n-    def __init__(self, units, **kwargs):\n+    def __init__(self, units, state_size=None, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = units\n+        self.state_size = state_size if state_size else units\n \n     def build(self, input_shape):\n         self.kernel = self.add_weight(\n@@ -34,10 +34,10 @@ class OneStateRNNCell(layers.Layer):\n \n \n class TwoStatesRNNCell(layers.Layer):\n-    def __init__(self, units, **kwargs):\n+    def __init__(self, units, state_size=None, **kwargs):\n         super().__init__(**kwargs)\n         self.units = units\n-        self.state_size = [units, units]\n+        self.state_size = state_size if state_size else [units, units]\n         self.output_size = units\n \n     def build(self, input_shape):\n@@ -72,7 +72,27 @@ class RNNTest(testing.TestCase):\n     def test_basics(self):\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": OneStateRNNCell(5)},\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=5)},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=[5])},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=2,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": OneStateRNNCell(5, state_size=(5,))},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=2,\n@@ -106,7 +126,17 @@ class RNNTest(testing.TestCase):\n         )\n         self.run_layer_test(\n             layers.RNN,\n-            init_kwargs={\"cell\": TwoStatesRNNCell(5)},\n+            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=[5, 5])},\n+            input_shape=(3, 2, 4),\n+            expected_output_shape=(3, 5),\n+            expected_num_trainable_weights=3,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            supports_masking=True,\n+        )\n+        self.run_layer_test(\n+            layers.RNN,\n+            init_kwargs={\"cell\": TwoStatesRNNCell(5, state_size=(5, 5))},\n             input_shape=(3, 2, 4),\n             expected_output_shape=(3, 5),\n             expected_num_trainable_weights=3,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ea23c1829bc1c9f976e3eb382d78bc3c2d392904", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 163 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 16 | Methods Changed: 12 | Complexity Δ (Sum/Max): 24/21 | Churn Δ: 171 | Churn Cumulative: 479 | Contributors (this commit): 4 | Commits (past 90d): 26 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -2,22 +2,88 @@ import numpy as np\n \n import keras_core\n from keras_core import layers\n+from keras_core import operations as ops\n \n+keras_core.utils.set_random_seed(1337)\n+x = np.random.rand(100, 32, 32, 3)\n+y = np.random.randint(0, 2, size=(100, 1))\n+\n+# Test sequential model.\n model = keras_core.Sequential(\n     [\n+        layers.Conv2D(filters=10, kernel_size=3),\n+        layers.GlobalAveragePooling2D(),\n         layers.Dense(1, activation=\"sigmoid\"),\n     ]\n )\n model.compile(\n     loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\", \"accuracy\"]\n )\n-x = np.random.rand(100, 10)\n-y = np.random.randint(0, 2, size=(100, 1))\n history = model.fit(\n     x=x,\n     y=y,\n     epochs=10,\n-    shuffle=False,\n     validation_data=(x, y),\n+    verbose=0,\n )\n-model.predict(x)\n+model.evaluate(x, y, verbose=0)\n+model.predict(x, verbose=0)\n+\n+# Test functional model.\n+inputs = keras_core.Input(shape=(32, 32, 3))\n+outputs = layers.Conv2D(filters=10, kernel_size=3)(inputs)\n+outputs = layers.GlobalAveragePooling2D()(outputs)\n+outputs = layers.Dense(1)(outputs)\n+model = keras_core.Model(inputs, outputs)\n+model.compile(\n+    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\", \"accuracy\"]\n+)\n+history = model.fit(\n+    x=x,\n+    y=y,\n+    epochs=10,\n+    validation_data=(x, y),\n+    verbose=0,\n+)\n+model.evaluate(x, y, verbose=0)\n+model.predict(x, verbose=0)\n+\n+\n+# Test custom layer\n+class Linear(layers.Layer):\n+    def __init__(self, units=32):\n+        super().__init__()\n+        self.units = units\n+\n+    def build(self, input_shape):\n+        self.w = self.add_weight(\n+            shape=(input_shape[-1], self.units),\n+            initializer=\"random_normal\",\n+            trainable=True,\n+        )\n+        self.b = self.add_weight(\n+            shape=(self.units,), initializer=\"random_normal\", trainable=True\n+        )\n+\n+    def call(self, inputs):\n+        return ops.matmul(inputs, self.w) + self.b\n+\n+\n+inputs = keras_core.Input(shape=(32, 32, 3))\n+outputs = layers.Conv2D(filters=10, kernel_size=3)(inputs)\n+outputs = layers.GlobalAveragePooling2D()(outputs)\n+outputs = Linear(1)(outputs)\n+outputs = layers.Activation(\"sigmoid\")(outputs)\n+model = keras_core.Model(inputs, outputs)\n+model.compile(\n+    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"mae\", \"accuracy\"]\n+)\n+history = model.fit(\n+    x=x,\n+    y=y,\n+    epochs=10,\n+    validation_data=(x, y),\n+    verbose=0,\n+)\n+model.evaluate(x, y, verbose=0)\n+model.predict(x, verbose=0)\n\n@@ -2,9 +2,13 @@ import contextlib\n \n import numpy as np\n import torch\n+from tensorflow import nest\n \n from keras_core.backend.common import KerasVariable\n+from keras_core.backend.common import global_state\n from keras_core.backend.common import standardize_dtype\n+from keras_core.backend.common.keras_tensor import KerasTensor\n+from keras_core.backend.common.stateless_scope import StatelessScope\n \n DYNAMIC_SHAPES_OK = True\n \n@@ -24,6 +28,23 @@ TORCH_DTYPES = {\n }\n \n \n+@contextlib.contextmanager\n+def device_scope(device):\n+    previous_device = global_state.get_global_attribute(\"torch_device\", None)\n+    global_state.set_global_attribute(\"torch_device\", device)\n+    try:\n+        yield\n+    finally:\n+        global_state.set_global_attribute(\"torch_device\", previous_device)\n+\n+\n+def get_device():\n+    device = global_state.get_global_attribute(\"torch_device\", None)\n+    if device is None:\n+        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n+    return device\n+\n+\n def to_torch_dtype(dtype):\n     if isinstance(dtype, torch.dtype):\n         return dtype\n@@ -43,7 +64,7 @@ class Variable(KerasVariable):\n \n     def _direct_assign(self, value):\n         with torch.no_grad():\n-            self._value.copy_(value)\n+            self.value.copy_(value)\n \n     def _convert_to_tensor(self, value, dtype=None):\n         return convert_to_tensor(value, dtype=dtype)\n@@ -67,6 +88,18 @@ class Variable(KerasVariable):\n             return self.value.detach().__array__(dtype)\n         return super().__array__(dtype)\n \n+    @property\n+    def value(self):\n+        value = super().value\n+        # Create and use a symbolic tensor stub in symbolic calls.\n+        if get_device() == \"meta\" and value.device != \"meta\":\n+            return torch.randn(\n+                size=value.shape,\n+                dtype=value.dtype,\n+                device=\"meta\",\n+            )\n+        return value\n+\n \n def convert_to_tensor(x, dtype=None):\n     # TODO: Need to address device placement arg of `as_tensor`\n@@ -80,7 +113,7 @@ def convert_to_tensor(x, dtype=None):\n \n     # Convert to np first in case of any non-numpy, numpy-compatible array.\n     x = np.array(x)\n-    return torch.as_tensor(x, dtype=dtype)\n+    return torch.as_tensor(x, dtype=dtype, device=get_device())\n \n \n def convert_to_numpy(x):\n@@ -112,9 +145,65 @@ def name_scope(name):\n \n # Shape / dtype inference util\n def compute_output_spec(fn, *args, **kwargs):\n-    raise NotImplementedError(\n-        \"`compute_output_spec` not implemented for PyTorch backend\"\n+    with StatelessScope():\n+\n+        def has_none_shape(x):\n+            if isinstance(x, KerasTensor):\n+                return None in x.shape\n+            return False\n+\n+        none_in_shape = any(map(has_none_shape, nest.flatten((args, kwargs))))\n+\n+        def convert_keras_tensor_to_torch(x, fill_value=None):\n+            if isinstance(x, KerasTensor):\n+                shape = list(x.shape)\n+                if fill_value:\n+                    for i, e in enumerate(shape):\n+                        if e is None:\n+                            shape[i] = fill_value\n+                return torch.randn(\n+                    size=shape,\n+                    dtype=TORCH_DTYPES[x.dtype],\n+                    device=get_device(),\n                 )\n+            return x\n+\n+        with device_scope(\"meta\"):\n+            args_1, kwargs_1 = nest.map_structure(\n+                lambda x: convert_keras_tensor_to_torch(x, fill_value=83),\n+                (args, kwargs),\n+            )\n+            outputs_1 = fn(*args_1, **kwargs_1)\n+\n+        outputs = outputs_1\n+\n+        if none_in_shape:\n+            with device_scope(\"meta\"):\n+                args_2, kwargs_2 = nest.map_structure(\n+                    lambda x: convert_keras_tensor_to_torch(x, fill_value=89),\n+                    (args, kwargs),\n+                )\n+                outputs_2 = fn(*args_2, **kwargs_2)\n+\n+            flat_out_1 = nest.flatten(outputs_1)\n+            flat_out_2 = nest.flatten(outputs_2)\n+\n+            flat_out = []\n+            for x1, x2 in zip(flat_out_1, flat_out_2):\n+                shape = list(x1.shape)\n+                for i, e in enumerate(x2.shape):\n+                    if e != shape[i]:\n+                        shape[i] = None\n+                flat_out.append(KerasTensor(shape, standardize_dtype(x1.dtype)))\n+            outputs = nest.pack_sequence_as(outputs_1, flat_out)\n+\n+        def convert_torch_to_keras_tensor(x):\n+            if is_tensor(x):\n+                return KerasTensor(x.shape, standardize_dtype(x.dtype))\n+            return x\n+\n+        output_spec = nest.map_structure(convert_torch_to_keras_tensor, outputs)\n+    return output_spec\n \n \n def cond(pred, true_fn, false_fn):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c2d7c51aba89f4c69ece3036d9643b5f61f35183", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 82 | Lines Deleted: 35 | Files Changed: 11 | Hunks: 31 | Methods Changed: 23 | Complexity Δ (Sum/Max): 12/3 | Churn Δ: 117 | Churn Cumulative: 6905 | Contributors (this commit): 11 | Commits (past 90d): 205 | Contributors (cumulative): 39 | DMM Complexity: 1.0\n\nDIFF:\n@@ -108,8 +108,6 @@ class MyModel(nn.Module):\n                 layers.Dense(num_classes),\n             ]\n         )\n-        # TODO: automate this\n-        self.model.parameters()\n \n     def forward(self, x):\n         return self.model(x)\n\n@@ -1,2 +1,4 @@\n class JaxLayer:\n+    def _post_build(self):\n+        \"\"\"Can be overriden to perform post-build actions.\"\"\"\n         pass\n\n@@ -2,6 +2,10 @@ import tensorflow as tf\n \n \n class TFLayer(tf.__internal__.tracking.AutoTrackable):\n+    def _post_build(self):\n+        \"\"\"Can be overriden to perform post-build actions.\"\"\"\n+        pass\n+\n     @property\n     def _default_save_signature(self):\n         \"\"\"For SavedModel support: returns the default serving signature.\"\"\"\n\n@@ -4,11 +4,17 @@ from keras_core.operations.operation import Operation\n \n \n class TorchLayer(torch.nn.Module):\n-    def parameters(self, recurse=True):\n-        if not hasattr(self, \"torch_params\"):\n+    def _post_build(self):\n+        self._track_variables()\n+\n+    def _track_variables(self):\n         self.torch_params = torch.nn.ParameterList(\n             [variable.value for variable in self.variables]\n         )\n+\n+    def parameters(self, recurse=True):\n+        if not hasattr(self, \"torch_params\"):\n+            self._track_variables()\n         return torch.nn.Module.parameters(self, recurse=recurse)\n \n     def forward(self, *args, **kwargs):\n\n@@ -245,12 +245,8 @@ class Layer(BackendLayer, Operation):\n         self.supports_jit = True\n \n         self._trainable = trainable\n-        self._layers = []\n-        self._metrics = []\n-        self._seed_generators = []\n         self._losses = []\n-        self._trainable_variables = []\n-        self._non_trainable_variables = []\n+\n         self._supports_masking = not utils.is_default(self.compute_mask)\n         # Whether to automatically convert (+ auto-cast) inputs to `call()`.\n         self._convert_input_args = True\n@@ -261,7 +257,17 @@ class Layer(BackendLayer, Operation):\n         self._call_signature_parameters = [\n             p.name for p in inspect.signature(self.call).parameters.values()\n         ]\n+        self._configure_tracker()\n \n+    def _configure_tracker(self):\n+        if hasattr(self, \"_tracker\"):\n+            return\n+\n+        self._trainable_variables = []\n+        self._non_trainable_variables = []\n+        self._layers = []\n+        self._metrics = []\n+        self._seed_generators = []\n         self._tracker = Tracker(\n             {\n                 \"trainable_variables\": (\n@@ -889,15 +895,9 @@ class Layer(BackendLayer, Operation):\n \n     def _track_variable(self, variable):\n         if variable.trainable:\n-            self._trainable_variables.append(variable)\n-            # Prevent double-tracking\n-            self._tracker.stored_ids[\"trainable_variables\"].add(id(variable))\n+            self._tracker.add_to_store(\"trainable_variables\", variable)\n         else:\n-            self._non_trainable_variables.append(variable)\n-            # Prevent double-tracking\n-            self._tracker.stored_ids[\"non_trainable_variables\"].add(\n-                id(variable)\n-            )\n+            self._tracker.add_to_store(\"non_trainable_variables\", variable)\n \n     def add_metric(self):\n         # Permanently disabled\n@@ -966,6 +966,19 @@ class Layer(BackendLayer, Operation):\n             # Check input spec again (after build, since self.input_spec\n             # may have been updated\n             self._assert_input_compatibility(call_spec.first_arg)\n+            # Hook used to do post-build actions\n+            self._post_build()\n+        if not self._tracker.locked:\n+            # No state updates past this point.\n+            self._tracker.lock(\n+                msg=(\n+                    \"You cannot add new elements of state \"\n+                    \"(variables or sub-layers) \"\n+                    \"to a layer that is already built. All state \"\n+                    \"must be created in the `__init__()` method or \"\n+                    \"in the`build()` method.\"\n+                )\n+            )\n \n     def _build_by_run_for_single_pos_arg(self, input_shape):\n         # Case: all inputs are in the first arg (possibly nested).\n\n@@ -626,3 +626,16 @@ class LayerTest(testing.TestCase):\n             NonMatchingArgument()(foo, bar)\n \n         MatchingArguments()(foo, bar)\n+\n+    def test_tracker_locking(self):\n+        class BadLayer(layers.Layer):\n+            def call(self, x):\n+                self.w = self.add_weight(initializer=\"zeros\", shape=())\n+                return x\n+\n+        layer = BadLayer()\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"cannot add new elements of state\",\n+        ):\n+            layer(np.random.random((3, 2)))\n\n@@ -131,9 +131,8 @@ class Metric:\n             trainable=False,\n             name=name,\n         )\n-        self._variables.append(variable)\n         # Prevent double-tracking\n-        self._tracker.stored_ids[\"variables\"].add(id(variable))\n+        self._tracker.add_to_store(\"variables\", variable)\n         return variable\n \n     def add_weight(self, *args, **kwargs):\n\n@@ -152,6 +152,7 @@ class Functional(Function, Model):\n \n         self._layers = self.layers\n         self.built = True\n+        self._post_build()\n \n     @property\n     def layers(self):\n\n@@ -103,24 +103,25 @@ class Sequential(Model):\n             self._maybe_rebuild()\n         else:\n             self.built = False\n+            self._tracker.locked = False\n             self._functional = None\n \n     def pop(self, rebuild=True):\n         layer = self._layers.pop()\n+        self.built = False\n+        self._tracker.locked = False\n+        self._functional = None\n         if rebuild:\n             self._maybe_rebuild()\n-        else:\n-            self.built = False\n-            self._functional = None\n         return layer\n \n     def _maybe_rebuild(self):\n+        self.built = False\n+        self._functional = None\n+        self._tracker.locked = False\n         if isinstance(self._layers[0], InputLayer) and len(self._layers) > 1:\n             input_shape = self._layers[0].batch_shape\n             self.build(input_shape)\n-        else:\n-            self.built = False\n-            self._functional = None\n \n     def build(self, input_shape=None):\n         if not isinstance(input_shape, (tuple, list)):\n@@ -162,6 +163,7 @@ class Sequential(Model):\n         outputs = x\n         self._functional = Functional(inputs=inputs, outputs=outputs)\n         self.built = True\n+        self._post_build()\n \n     def call(self, inputs, training=None, mask=None):\n         if self._functional:\n\n@@ -109,9 +109,7 @@ class BaseOptimizer:\n             self._learning_rate = learning_rate\n \n     def _track_variable(self, variable):\n-        self._variables.append(variable)\n-        # Prevent double-tracking\n-        self._tracker.stored_ids[\"variables\"].add(id(variable))\n+        self._tracker.add_to_store(\"variables\", variable)\n \n     @tracking.no_automatic_dependency_tracking\n     def build(self, variables):\n\n@@ -58,16 +58,17 @@ class Tracker:\n     def __init__(self, config):\n         self.config = config\n         self.stored_ids = {name: set() for name in self.config.keys()}\n+        self.locked = False\n+        self._lock_violation_msg = None\n \n     def track(self, attr):\n         if not is_tracking_enabled():\n             return attr\n \n-        for name, (is_attr_type, store) in self.config.items():\n+        for name, (is_attr_type, _) in self.config.items():\n             if is_attr_type(attr):\n                 if id(attr) not in self.stored_ids[name]:\n-                    store.append(attr)\n-                    self.stored_ids[name].add(id(attr))\n+                    self.add_to_store(name, attr)\n                 return attr\n         if isinstance(attr, tuple):\n             wrapped_attr = []\n@@ -78,15 +79,25 @@ class Tracker:\n         elif isinstance(attr, list):\n             return TrackedList(attr, self)\n         elif isinstance(attr, dict):\n-            # TODO: OrderedDict\n+            # TODO: OrderedDict?\n             return TrackedDict(attr, self)\n         elif isinstance(attr, set):\n             return TrackedSet(attr, self)\n         return attr\n \n+    def lock(self, msg):\n+        self.locked = True\n+        self._lock_violation_msg = msg\n+\n+    def add_to_store(self, store_name, value):\n+        if self.locked:\n+            raise ValueError(self._lock_violation_msg)\n+        self.config[store_name][1].append(value)\n+        self.stored_ids[store_name].add(id(value))\n+\n \n class TrackedList(list):\n-    # TODO(fchollet): override item removal methods?\n+    # TODO: override item removal methods?\n     def __init__(self, values, tracker):\n         self.tracker = tracker\n         values = [tracker.track(v) for v in values]\n@@ -106,7 +117,7 @@ class TrackedList(list):\n \n \n class TrackedDict(dict):\n-    # TODO(fchollet): override item removal methods?\n+    # TODO: override item removal methods?\n     def __init__(self, values, tracker):\n         self.tracker = tracker\n         values = {k: tracker.track(v) for k, v in values.items()}\n@@ -122,7 +133,7 @@ class TrackedDict(dict):\n \n \n class TrackedSet(set):\n-    # TODO(fchollet): override item removal methods?\n+    # TODO: override item removal methods?\n     def __init__(self, values, tracker):\n         self.tracker = tracker\n         values = {tracker.track(v) for v in values}\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b6312810118e7a310fb357a24dc1cdafa56b6fff", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 41 | Churn Cumulative: 120 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -38,7 +38,7 @@ class Rescaling(Layer):\n         dtype = self.compute_dtype\n         scale = ops.cast(self.scale, dtype)\n         offset = ops.cast(self.offset, dtype)\n-        return inputs * scale + offset\n+        return ops.cast(inputs, dtype) * scale + offset\n \n     def compute_output_shape(self, input_shape):\n         return input_shape\n\n@@ -18,6 +18,45 @@ class RescalingTest(testing.TestCase):\n             supports_masking=True,\n         )\n \n+    def test_rescaling_dtypes(self):\n+        # int scale\n+        self.run_layer_test(\n+            layers.Rescaling,\n+            init_kwargs={\"scale\": 2, \"offset\": 0.5},\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+        # int offset\n+        self.run_layer_test(\n+            layers.Rescaling,\n+            init_kwargs={\"scale\": 1.0, \"offset\": 2},\n+            input_shape=(2, 3),\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+        # int inputs\n+        self.run_layer_test(\n+            layers.Rescaling,\n+            init_kwargs={\"scale\": 1.0 / 255, \"offset\": 0.5},\n+            input_shape=(2, 3),\n+            input_dtype=\"int16\",\n+            expected_output_shape=(2, 3),\n+            expected_num_trainable_weights=0,\n+            expected_num_non_trainable_weights=0,\n+            expected_num_seed_generators=0,\n+            expected_num_losses=0,\n+            supports_masking=True,\n+        )\n+\n     def test_rescaling_correctness(self):\n         layer = layers.Rescaling(scale=1.0 / 255, offset=0.5)\n         x = np.random.random((3, 10, 10, 3)) * 255\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#289dc028a9b5f69d219950d3f53386258667602c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 128 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 4 | Methods Changed: 8 | Complexity Δ (Sum/Max): 10/9 | Churn Δ: 136 | Churn Cumulative: 1076 | Contributors (this commit): 8 | Commits (past 90d): 40 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -30,9 +30,7 @@ def benchmark_dense(\n     benchmark = LayerBenchmark(\n         layer_name,\n         init_args,\n-        input_shape=[\n-            256,\n-        ],\n+        input_shape=[256, 256],\n         jit_compile=jit_compile,\n     )\n \n\n@@ -111,12 +111,129 @@ class ArrayDataAdapter(DataAdapter):\n             yield tf.nest.map_structure(lambda x: x[start:stop], inputs)\n \n     def get_tf_dataset(self):\n-        ds = tf.data.Dataset.from_tensor_slices(self._inputs)\n+        inputs = self._inputs\n+        shuffle = self._shuffle\n+        batch_size = self._batch_size\n+        num_samples = self._num_samples\n+        num_full_batches = int(self._num_samples // batch_size)\n+\n+        # Vectorized version of shuffle.\n+        # This is a performance improvement over using `from_tensor_slices`.\n+        # The indices of the data are shuffled and batched, and these indices\n+        # are then zipped with the data and used to extract a batch of the data\n+        # at each step. The performance improvements here come from:\n+        # 1. vectorized batch using gather\n+        # 2. parallelized map\n+        # 3. pipelined permutation generation\n+        # 4. optimized permutation batching\n+        # 5. disabled static optimizations\n+\n+        indices_dataset = tf.data.Dataset.range(1)\n+\n+        def permutation(_):\n+            # It turns out to be more performant to make a new set of indices\n+            # rather than reusing the same range Tensor. (presumably because of\n+            # buffer forwarding.)\n+            indices = tf.range(num_samples, dtype=tf.int64)\n+            if shuffle and shuffle != \"batch\":\n+                indices = tf.random.shuffle(indices)\n+            return indices\n+\n+        # We prefetch a single element. Computing large permutations can take\n+        # quite a while so we don't want to wait for prefetching over an epoch\n+        # boundary to trigger the next permutation. On the other hand, too many\n+        # simultaneous shuffles can contend on a hardware level and degrade all\n+        # performance.\n+        indices_dataset = indices_dataset.map(permutation).prefetch(1)\n+\n+        def slice_batch_indices(indices):\n+            \"\"\"Convert a Tensor of indices into a dataset of batched indices.\n+\n+            This step can be accomplished in several ways. The most natural is\n+            to slice the Tensor in a Dataset map. (With a condition on the upper\n+            index to handle the partial batch.) However it turns out that\n+            coercing the Tensor into a shape which is divisible by the batch\n+            size (and handling the last partial batch separately) allows for a\n+            much more favorable memory access pattern and improved performance.\n+\n+            Args:\n+                indices: Tensor which determines the data order for an entire\n+                    epoch.\n+\n+            Returns:\n+                A Dataset of batched indices.\n+            \"\"\"\n+            num_in_full_batch = num_full_batches * batch_size\n+            first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n+            first_k_indices = tf.reshape(\n+                first_k_indices, [num_full_batches, batch_size]\n+            )\n+\n+            flat_dataset = tf.data.Dataset.from_tensor_slices(first_k_indices)\n+            if self._partial_batch_size:\n+                index_remainder = tf.data.Dataset.from_tensors(\n+                    tf.slice(\n+                        indices, [num_in_full_batch], [self._partial_batch_size]\n+                    )\n+                )\n+                flat_dataset = flat_dataset.concatenate(index_remainder)\n+\n+            return flat_dataset\n+\n+        indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n+\n+        dataset = self.slice_inputs(indices_dataset, inputs)\n+\n+        if shuffle == \"batch\":\n+\n+            def shuffle_batch(*batch):\n+                return tf.nest.map_structure(tf.random.shuffle, batch)\n+\n+            dataset = dataset.map(shuffle_batch)\n+\n+        options = tf.data.Options()\n+        options.experimental_distribute.auto_shard_policy = (\n+            tf.data.experimental.AutoShardPolicy.DATA\n+        )\n+        dataset = dataset.with_options(options)\n+        return dataset.prefetch(tf.data.AUTOTUNE)\n+\n+    def slice_inputs(self, indices_dataset, inputs):\n+        \"\"\"Slice inputs into a Dataset of batches.\n+\n+        Given a Dataset of batch indices and the unsliced inputs,\n+        this step slices the inputs in a parallelized fashion\n+        and produces a dataset of input batches.\n+\n+        Args:\n+            indices_dataset: A Dataset of batched indices.\n+            inputs: A python data structure that contains the inputs, targets,\n+                and possibly sample weights.\n+\n+        Returns:\n+            A Dataset of input batches matching the batch indices.\n+        \"\"\"\n+        dataset = tf.data.Dataset.zip(\n+            (indices_dataset, tf.data.Dataset.from_tensors(inputs).repeat())\n+        )\n+\n+        def grab_batch(i, data):\n+            return tf.nest.map_structure(\n+                lambda d: tf.gather(d, i, axis=0), data\n+            )\n+\n+        dataset = dataset.map(grab_batch, num_parallel_calls=tf.data.AUTOTUNE)\n+\n+        # Default optimizations are disabled to avoid the overhead of\n+        # (unnecessary) input pipeline graph serialization and deserialization\n+        options = tf.data.Options()\n+        options.experimental_optimization.apply_default_optimizations = False\n         if self._shuffle:\n-            ds = ds.shuffle(self._batch_size * 8)\n-        ds = ds.batch(self._batch_size)\n-        ds = ds.prefetch(tf.data.AUTOTUNE)\n-        return ds\n+            options.experimental_external_state_policy = (\n+                tf.data.experimental.ExternalStatePolicy.IGNORE\n+            )\n+        dataset = dataset.with_options(options)\n+        return dataset\n \n     @property\n     def num_batches(self):\n\n@@ -154,6 +154,11 @@ class TestTrainer(testing.TestCase):\n         )\n \n     def test_fit_steps_per_epoch_flow_graph_fn(self):\n+        if backend.backend() == \"tensorflow\":\n+            self.skipTest(\n+                \"TODO: Graph mode without XLA in TF backend leads to \"\n+                \"unexpected logs, need further checks.\"\n+            )\n         self._test_fit_flow(\n             run_eagerly=False, jit_compile=False, use_steps_per_epoch=True\n         )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
