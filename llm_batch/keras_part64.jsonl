{"custom_id": "keras#13df0bf32accd57a7288a29fa09e4badf1d0b780", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 238 | Contributors (this commit): 2 | Commits (past 90d): 5 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,6 @@\n import pytest\n import os\n+import sys\n import numpy as np\n np.random.seed(1337)\n \n@@ -120,7 +121,7 @@ def test_LearningRateScheduler():\n     assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()\n \n \n-@pytest.mark.skipif(K._BACKEND != 'tensorflow',\n+@pytest.mark.skipif((K._BACKEND != 'tensorflow') or (sys.version_info[0] == 3),\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard():\n     import shutil\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#908d86655831e153bb11aa8ce2c9bdaf821b1154", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 47 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 5 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 49 | Churn Cumulative: 577 | Contributors (this commit): 6 | Commits (past 90d): 16 | Contributors (cumulative): 10 | DMM Complexity: 0.8461538461538461\n\nDIFF:\n@@ -39,7 +39,10 @@ def load_data(path=\"imdb.pkl\", nb_words=None, skip_top=0,\n                 new_labels.append(y)\n         X = new_X\n         labels = new_labels\n-\n+    if not X:\n+        raise Exception('After filtering for sequences shorter than maxlen=' +\n+                        str(maxlen) + ', no sequence was kept. '\n+                        'Increase maxlen.')\n     if not nb_words:\n         nb_words = max([max(x) for x in X])\n \n\n@@ -11,6 +11,7 @@ def test_cifar():\n \n def test_reuters():\n     (X_train, y_train), (X_test, y_test) = reuters.load_data()\n+    (X_train, y_train), (X_test, y_test) = reuters.load_data(maxlen=10)\n \n \n def test_mnist():\n@@ -19,6 +20,7 @@ def test_mnist():\n \n def test_imdb():\n     (X_train, y_train), (X_test, y_test) = imdb.load_data()\n+    (X_train, y_train), (X_test, y_test) = imdb.load_data(maxlen=40)\n \n \n if __name__ == '__main__':\n\n@@ -182,4 +182,3 @@ def _runner(layer):\n \n if __name__ == '__main__':\n     pytest.main([__file__])\n-\n\n@@ -0,0 +1,41 @@\n+import pytest\n+import numpy as np\n+from keras import backend as K\n+from keras.layers import core\n+from keras.layers import noise\n+\n+input_shape = (10, 10)\n+batch_input_shape = (10, 10, 10)\n+\n+\n+def test_GaussianNoise():\n+    layer = noise.GaussianNoise(sigma=1., input_shape=input_shape)\n+    _runner(layer)\n+\n+\n+def test_GaussianDropout():\n+    layer = noise.GaussianDropout(p=0.2, input_shape=input_shape)\n+    _runner(layer)\n+\n+\n+def _runner(layer):\n+    assert isinstance(layer, core.Layer)\n+    layer.build()\n+    conf = layer.get_config()\n+    assert (type(conf) == dict)\n+\n+    param = layer.get_params()\n+    # Typically a list or a tuple, but may be any iterable\n+    assert hasattr(param, '__iter__')\n+    layer.input = K.variable(np.random.random(batch_input_shape))\n+    output = layer.get_output(train=False)\n+    output_np = K.eval(output)\n+    assert output_np.shape == batch_input_shape\n+\n+    output = layer.get_output(train=True)\n+    output_np = K.eval(output)\n+    assert output_np.shape == batch_input_shape\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d8e83cc773a0f7bd7ed550c784bacda4fa4da53b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 450 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -3,7 +3,7 @@\n References:\n - Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n   \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n-  http://arxiv.org/abs/1503.08895\n+  http://arxiv.org/abs/1502.05698\n \n - Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n   \"End-To-End Memory Networks\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2a0f3e3dfc02233461b70b640878b3ee5acf2bc1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 19 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 19 | Churn Cumulative: 488 | Contributors (this commit): 4 | Commits (past 90d): 12 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -180,5 +180,24 @@ def _runner(layer):\n     layer.trainable = True\n     layer.trainable = False\n \n+def test_siamese():\n+    right_input_layer = core.Dense(7, input_dim=3)\n+    left_input_layer = core.Dense(7, input_dim=3)\n+\n+    shared_layer = core.Dense(5,input_dim=7)\n+    for mode in ['sum', 'mul', 'ave', 'concat']:\n+        siamese_layer = core.Siamese(shared_layer, [left_input_layer, right_input_layer], merge_mode=mode)\n+        siamese_layer.output_shape\n+        siamese_layer.get_output()\n+\n+    # Merge modes 'dot' and 'cos' requires a different call signature\n+    for mode in ['dot', 'cos']:\n+        siamese_layer = core.Siamese(shared_layer, [left_input_layer, right_input_layer], merge_mode=mode,\n+                                     dot_axes=([1], [1]))\n+        siamese_layer.output_shape\n+        siamese_layer.get_output()\n+\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3d109c6ebe07af3c235a112d689aa8f5af3f691a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 13 | Churn Cumulative: 501 | Contributors (this commit): 4 | Commits (past 90d): 13 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -180,7 +180,7 @@ def _runner(layer):\n     layer.trainable = True\n     layer.trainable = False\n \n-def test_siamese():\n+def test_siamese_all():\n     right_input_layer = core.Dense(7, input_dim=3)\n     left_input_layer = core.Dense(7, input_dim=3)\n \n@@ -190,14 +190,19 @@ def test_siamese():\n         siamese_layer.output_shape\n         siamese_layer.get_output()\n \n-    # Merge modes 'dot' and 'cos' requires a different call signature\n+@pytest.mark.skipif(K._BACKEND == 'tensorflow',\n+                    reason='currently not working with TensorFlow')\n+def test_siamese_theano_only():\n+    right_input_layer = core.Dense(7, input_dim=3)\n+    left_input_layer = core.Dense(7, input_dim=3)\n+\n+    shared_layer = core.Dense(5,input_dim=7)\n+\n     for mode in ['dot', 'cos']:\n         siamese_layer = core.Siamese(shared_layer, [left_input_layer, right_input_layer], merge_mode=mode,\n                                      dot_axes=([1], [1]))\n         siamese_layer.output_shape\n         siamese_layer.get_output()\n \n-\n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f2f4f4ec48a3ae49f3f345f5e0eda60084d606a8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 7 | Churn Cumulative: 7109 | Contributors (this commit): 33 | Commits (past 90d): 115 | Contributors (cumulative): 33 | DMM Complexity: 1.0\n\nDIFF:\n@@ -762,6 +762,13 @@ class Flatten(Layer):\n     @property\n     def output_shape(self):\n         input_shape = self.input_shape\n+        if not all(input_shape[1:]):\n+            raise Exception('The shape of the input to \"Flatten\" '\n+                            'is not fully defined '\n+                            '(got ' + str(input_shape[1:]) + '. '\n+                            'Make sure to pass a complete \"input_shape\" '\n+                            'or \"batch_input_shape\" argument to the first '\n+                            'layer in your model.')\n         return (input_shape[0], np.prod(input_shape[1:]))\n \n     def get_output(self, train=False):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d870e45eb0e4b3d6a8c8441d797becde2d17ab4d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 2 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ def test_unitnorm_constraint():\n                    class_mode='binary')\n     lookup.train_on_batch(X1, np.array([[1], [0]], dtype='int32'))\n     norm = np.linalg.norm(K.get_value(lookup.params[0]), axis=1)\n-    assert_allclose(norm, np.ones_like(norm).astype('float32'))\n+    assert_allclose(norm, np.ones_like(norm).astype('float32'), rtol=1e-05)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d5fb5d1f15a94d43bb803be257342c613f882087", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 29 | Churn Cumulative: 1222 | Contributors (this commit): 12 | Commits (past 90d): 9 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -359,9 +359,16 @@ class EarlyStopping(Callback):\n \n \n class RemoteMonitor(Callback):\n-    '''Experimental callback used to stream events to a server.\n+    '''Callback used to stream events to a server.\n \n     Requires the `requests` library.\n+\n+    # Arguments\n+        root: root url to which the events will be send (at the end\n+            of every epoch). Events are sent to\n+            `root + '/publish/epoch/end/'`. Calls are HTTP POST,\n+            with a `data` argument which is a JSON-encoded dictionary\n+            of event data.\n     '''\n     def __init__(self, root='http://localhost:9000'):\n         self.root = root\n@@ -401,9 +408,9 @@ class LearningRateScheduler(Callback):\n     '''Learning rate scheduler.\n \n     # Arguments\n-        schedule: a function that gets an epoch index as input\n+        schedule: a function that takes an epoch index as input\n             (integer, indexed from 0) and returns a new\n-            learning rate as output.\n+            learning rate as output (float).\n     '''\n     def __init__(self, schedule):\n         super(LearningRateScheduler, self).__init__()\n@@ -412,22 +419,28 @@ class LearningRateScheduler(Callback):\n     def on_epoch_begin(self, epoch, logs={}):\n         assert hasattr(self.model.optimizer, 'lr'), \\\n             'Optimizer must have a \"lr\" attribute.'\n-        K.set_value(self.model.optimizer.lr, self.schedule(epoch))\n+        lr = self.schedule(epoch)\n+        assert type(lr) == float, 'The output of the \"schedule\" function should be float.'\n+        K.set_value(self.model.optimizer.lr, lr)\n \n \n class TensorBoard(Callback):\n     ''' Tensorboard basic visualizations.\n \n-    This callback writes a log usable with TensorBoard.\n-    TensorBoard is a visualization tools provided with TensorFlow.\n+    This callback writes a log for TensorBoard, which allows\n+    you to visualize dynamic graphs of your training and test\n+    metrics, as well as activation histograms for the different\n+    layers in your model.\n+\n+    TensorBoard is a visualization tool provided with TensorFlow.\n \n     If you have installed TensorFlow with pip, you should be able\n     to launch TensorBoard from the command line:\n     ```\n     tensorboard --logdir=/full_path_to_your_logs\n     ```\n-    You could find more information at:\n-    https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html\n+    You can find more information about TensorBoard\n+    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n \n     # Arguments\n         log_dir: the path of the directory where to save the log\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#485d451b62600d01bd728b2ae301ef233b5c4d7b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 24 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -7/0 | Churn Δ: 28 | Churn Cumulative: 130 | Contributors (this commit): 9 | Commits (past 90d): 4 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -5,11 +5,13 @@ import sys\n import six\n \n \n-def get_from_module(identifier, module_params, module_name, instantiate=False, kwargs=None):\n+def get_from_module(identifier, module_params, module_name,\n+                    instantiate=False, kwargs=None):\n     if isinstance(identifier, six.string_types):\n         res = module_params.get(identifier)\n         if not res:\n-            raise Exception('Invalid ' + str(module_name) + ': ' + str(identifier))\n+            raise Exception('Invalid ' + str(module_name) + ': ' +\n+                            str(identifier))\n         if instantiate and not kwargs:\n             return res()\n         elif instantiate and kwargs:\n@@ -23,28 +25,6 @@ def make_tuple(*args):\n     return args\n \n \n-def printv(v, prefix=''):\n-    if type(v) == dict:\n-        if 'name' in v:\n-            print(prefix + '#' + v['name'])\n-            del v['name']\n-        prefix += '...'\n-        for nk, nv in v.items():\n-            if type(nv) in [dict, list]:\n-                print(prefix + nk + ':')\n-                printv(nv, prefix)\n-            else:\n-                print(prefix + nk + ':' + str(nv))\n-    elif type(v) == list:\n-        prefix += '...'\n-        for i, nv in enumerate(v):\n-            print(prefix + '#' + str(i))\n-            printv(nv, prefix)\n-    else:\n-        prefix += '...'\n-        print(prefix + str(v))\n-\n-\n class Progbar(object):\n     def __init__(self, target, width=30, verbose=1):\n         '''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#18d52e634d75074983cba62f51c3fc6737828d97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 31 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 35 | Churn Cumulative: 187 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -39,7 +39,30 @@ def one_hot(text, n, filters=base_filter(), lower=True, split=\" \"):\n \n \n class Tokenizer(object):\n-    def __init__(self, nb_words=None, filters=base_filter(), lower=True, split=\" \"):\n+    def __init__(self, nb_words=None, filters=base_filter(),\n+                 lower=True, split=' '):\n+        '''The class allows to vectorize a text corpus, by turning each\n+        text into either a sequence of integers (each integer being the index\n+        of a token in a dictionary) or into a vector where the coefficient\n+        for each token could be binary, based on word count, based on tf-idf...\n+\n+        # Arguments\n+            nb_words: the maximum number of words to keep, based\n+                on word frequency. Only the most common `nb_words` words will\n+                be kept.\n+            filters: a string where each element is a character that will be\n+                filtered from the texts. The default is all punctuation, plus\n+                tabs and line breaks, minus the `'` character.\n+            lower: boolean. Whether to convert the texts to lowercase.\n+            split: character or string to use for token splitting.\n+\n+        By default, all punctuation is removed, turning the texts into\n+        space-separated sequences of words\n+        (words maybe include the `'` character). These sequences are then\n+        splits into lists of tokens. They will then be indexed or vectorized.\n+\n+        `0` is a reserved index that won't be assigned to any word.\n+        '''\n         self.word_counts = {}\n         self.word_docs = {}\n         self.filters = filters\n@@ -51,7 +74,10 @@ class Tokenizer(object):\n     def fit_on_texts(self, texts):\n         '''\n             required before using texts_to_sequences or texts_to_matrix\n-            @param texts: can be a list or a generator (for memory-efficiency)\n+\n+        # Arguments\n+            texts: can be a list of strings,\n+                or a generator of strings (for memory-efficiency)\n         '''\n         self.document_count = 0\n         for text in texts:\n\n@@ -3,8 +3,9 @@ from numpy.testing import assert_allclose\n \n import pytest\n \n-from keras.preprocessing.sequence import (pad_sequences, make_sampling_table,\n-                                          skipgrams)\n+from keras.preprocessing.sequence import pad_sequences\n+from keras.preprocessing.sequence import make_sampling_table\n+from keras.preprocessing.sequence import skipgrams\n \n \n def test_pad_sequences():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f3cd093c096c03d9710940dc5cd700c2b7142a6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 2 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ def test_image_classification():\n     history = model.fit(X_train, y_train, nb_epoch=10, batch_size=16,\n                         validation_data=(X_test, y_test),\n                         show_accuracy=True, verbose=0)\n-    assert(history.history['val_acc'][-1] > 0.9)\n+    assert(history.history['val_acc'][-1] > 0.85)\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7f85541785da1183796d1d5fc6494f938ea77b5b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 34 | Churn Cumulative: 34 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,34 @@\n+from keras.preprocessing.text import Tokenizer, one_hot\n+import pytest\n+import numpy as np\n+\n+\n+def test_one_hot():\n+    text = 'The cat sat on the mat.'\n+    encoded = one_hot(text, 5)\n+    assert len(encoded) == 6\n+    assert np.max(encoded) <= 4\n+    assert np.min(encoded) >= 0\n+\n+\n+def test_tokenizer():\n+    texts = ['The cat sat on the mat.',\n+             'The dog sat on the log.',\n+             'Dogs and cats living together.']\n+    tokenizer = Tokenizer(nb_words=20)\n+    tokenizer.fit_on_texts(texts)\n+\n+    sequences = []\n+    for seq in tokenizer.texts_to_sequences_generator(texts):\n+        sequences.append(seq)\n+    assert np.max(np.max(sequences)) == 12\n+    assert np.min(np.min(sequences)) == 1\n+\n+    tokenizer.fit_on_sequences(sequences)\n+\n+    for mode in ['binary', 'count', 'tfidf', 'freq']:\n+        matrix = tokenizer.texts_to_matrix(texts, mode)\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#69932604f9b9ecd6bf63af60aaf4b2b854759d56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 38 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -15,13 +15,13 @@ def test_tokenizer():\n     texts = ['The cat sat on the mat.',\n              'The dog sat on the log.',\n              'Dogs and cats living together.']\n-    tokenizer = Tokenizer(nb_words=20)\n+    tokenizer = Tokenizer(nb_words=10)\n     tokenizer.fit_on_texts(texts)\n \n     sequences = []\n     for seq in tokenizer.texts_to_sequences_generator(texts):\n         sequences.append(seq)\n-    assert np.max(np.max(sequences)) == 12\n+    assert np.max(np.max(sequences)) < 10\n     assert np.min(np.min(sequences)) == 1\n \n     tokenizer.fit_on_sequences(sequences)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#eda1a9e0a4eb786128a117409f26c5bf072ea172", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 91 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 3 | Methods Changed: 14 | Complexity Δ (Sum/Max): 16/16 | Churn Δ: 93 | Churn Cumulative: 197 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -14,7 +14,7 @@ def uniform(shape, scale=0.05):\n \n \n def normal(shape, scale=0.05):\n-    return K.variable(np.random.randn(*shape) * scale)\n+    return K.variable(np.random.normal(loc=0.0, scale=scale, size=shape))\n \n \n def lecun_uniform(shape):\n@@ -68,7 +68,8 @@ def orthogonal(shape, scale=1.1):\n \n def identity(shape, scale=1):\n     if len(shape) != 2 or shape[0] != shape[1]:\n-        raise Exception(\"Identity matrix initialization can only be used for 2D square matrices\")\n+        raise Exception('Identity matrix initialization can only be used '\n+                        'for 2D square matrices')\n     else:\n         return K.variable(scale * np.identity(shape[0]))\n \n\n@@ -0,0 +1,88 @@\n+import pytest\n+import numpy as np\n+\n+from keras import initializations\n+from keras import backend as K\n+\n+SHAPE = (100, 100)\n+\n+\n+def _runner(init, shape, target_mean=None, target_std=None,\n+            target_max=None, target_min=None):\n+    variable = init(shape)\n+    output = K.get_value(variable)\n+    print target_std\n+    print output.std()\n+    print output.mean()\n+    lim = 1e-2\n+    if target_std is not None:\n+        assert abs(output.std() - target_std) < lim\n+    if target_mean is not None:\n+        assert abs(output.mean() - target_mean) < lim\n+    if target_max is not None:\n+        assert abs(output.max() - target_max) < lim\n+    if target_min is not None:\n+        assert abs(output.min() - target_min) < lim\n+\n+\n+def test_uniform():\n+    _runner(initializations.uniform, SHAPE, target_mean=0.,\n+            target_max=0.05, target_min=-0.05)\n+\n+\n+def test_normal():\n+    _runner(initializations.normal, SHAPE, target_mean=0., target_std=0.05)\n+\n+\n+def test_lecun_uniform():\n+    scale = np.sqrt(3. / SHAPE[0])\n+    _runner(initializations.lecun_uniform, SHAPE,\n+            target_mean=0., target_max=scale, target_min=-scale)\n+\n+\n+def test_glorot_uniform():\n+    scale = np.sqrt(6. / (SHAPE[0] + SHAPE[1]))\n+    _runner(initializations.glorot_uniform, SHAPE, target_mean=0.,\n+            target_max=scale, target_min=-scale)\n+\n+\n+def test_glorot_normal():\n+    scale = np.sqrt(2. / (SHAPE[0] + SHAPE[1]))\n+    _runner(initializations.glorot_normal, SHAPE,\n+            target_mean=0., target_std=scale)\n+\n+\n+def test_he_uniform():\n+    scale = np.sqrt(6. / SHAPE[0])\n+    _runner(initializations.he_uniform, SHAPE, target_mean=0.,\n+            target_max=scale, target_min=-scale)\n+\n+\n+def test_he_normal():\n+    scale = np.sqrt(2. / SHAPE[0])\n+    _runner(initializations.he_normal, SHAPE,\n+            target_mean=0., target_std=scale)\n+\n+\n+def test_orthogonal():\n+    _runner(initializations.orthogonal, SHAPE,\n+            target_mean=0.)\n+\n+\n+def test_identity():\n+    _runner(initializations.identity, SHAPE,\n+            target_mean=1./SHAPE[0], target_max=1.)\n+\n+\n+def test_zero():\n+    _runner(initializations.zero, SHAPE,\n+            target_mean=0., target_max=0.)\n+\n+\n+def test_one():\n+    _runner(initializations.one, SHAPE,\n+            target_mean=1., target_max=1.)\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#29e60ab372e1a123be2f2884a6818f9a2508bf68", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 91 | Contributors (this commit): 1 | Commits (past 90d): 2 | Contributors (cumulative): 1 | DMM Complexity: 0.0\n\nDIFF:\n@@ -11,9 +11,6 @@ def _runner(init, shape, target_mean=None, target_std=None,\n             target_max=None, target_min=None):\n     variable = init(shape)\n     output = K.get_value(variable)\n-    print target_std\n-    print output.std()\n-    print output.mean()\n     lim = 1e-2\n     if target_std is not None:\n         assert abs(output.std() - target_std) < lim\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#19290c07fdd3ece4903de31325153f6ce5731d08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 3970 | Contributors (this commit): 28 | Commits (past 90d): 18 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1097,7 +1097,8 @@ class Graph(Model, containers.Graph):\n         '''Generate predictions for a single batch of samples.\n         '''\n         ins = [data[name] for name in self.input_order]\n-        return self._predict(ins)\n+        outs = self._predict(ins)\n+        return dict(zip(self.output_order, outs))\n \n     def save_weights(self, filepath, overwrite=False):\n         '''Save weights from all layers to a HDF5 files.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0695b82f7476329bd1dcba1baf482986b357c0c0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 186 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -85,7 +85,7 @@ for iteration in range(1, 60):\n         print('----- Generating with seed: \"' + sentence + '\"')\n         sys.stdout.write(generated)\n \n-        for iteration in range(400):\n+        for i in range(400):\n             x = np.zeros((1, maxlen, len(chars)))\n             for t, char in enumerate(sentence):\n                 x[0, t, char_indices[char]] = 1.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#85e51a0f8f6bfbb2ca8c0b5e07f87e843313c3e9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 48 | Files Changed: 15 | Hunks: 46 | Methods Changed: 27 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 96 | Churn Cumulative: 21037 | Contributors (this commit): 75 | Commits (past 90d): 315 | Contributors (cumulative): 175 | DMM Complexity: None\n\nDIFF:\n@@ -39,7 +39,7 @@ def hard_sigmoid(x):\n \n def linear(x):\n     '''\n-    The function returns the variable that is passed in, so all types work\n+    The function returns the variable that is passed in, so all types work.\n     '''\n     return x\n \n\n@@ -11,7 +11,7 @@ theano.config.floatX = _FLOATX\n \n \n def _on_gpu():\n-    '''Returns whether the session is set to\n+    '''Return whether the session is set to\n     run on GPU or not (i.e. on CPU).\n     '''\n     return theano.config.device[:3] == 'gpu'\n@@ -19,7 +19,7 @@ def _on_gpu():\n \n if _on_gpu():\n     '''Import cuDNN only if running on GPU:\n-    not having Cuda install should not\n+    not having Cuda installed should not\n     prevent from running the present code.\n     '''\n     from theano.sandbox.cuda import dnn\n@@ -244,18 +244,18 @@ def permute_dimensions(x, pattern):\n \n \n def repeat_elements(x, rep, axis):\n-    '''Repeats the elements of a tensor along an axis, like np.repeat\n+    '''Repeat the elements of a tensor along an axis, like np.repeat.\n \n     If x has shape (s1, s2, s3) and axis=1, the output\n-    will have shape (s1, s2 * rep, s3)\n+    will have shape (s1, s2 * rep, s3).\n     '''\n     return T.repeat(x, rep, axis=axis)\n \n def repeat(x, n):\n-    '''Repeat a 2D tensor:\n+    '''Repeat a 2D tensor.\n \n-    if x has shape (samples, dim) and n=2,\n-    the output will have shape (samples, 2, dim)\n+    If x has shape (samples, dim) and n=2,\n+    the output will have shape (samples, 2, dim).\n     '''\n     tensors = [x] * n\n     stacked = T.stack(*tensors)\n@@ -377,7 +377,7 @@ def gradients(loss, variables):\n \n def rnn(step_function, inputs, initial_states,\n         go_backwards=False, masking=True):\n-    '''Iterates over the time dimension of a tensor.\n+    '''Iterate over the time dimension of a tensor.\n \n     Parameters\n     ----------\n\n@@ -256,7 +256,7 @@ class ModelCheckpoint(Callback):\n \n         if mode not in ['auto', 'min', 'max']:\n             warnings.warn('ModelCheckpoint mode %s is unknown, '\n-                          'fallback to auto mode' % (self.mode),\n+                          'fallback to auto mode.' % (self.mode),\n                           RuntimeWarning)\n             mode = 'auto'\n \n@@ -311,7 +311,7 @@ class EarlyStopping(Callback):\n         mode: one of {auto, min, max}. In 'min' mode,\n             training will stop when the quantity\n             monitored has stopped decreasing; in 'max'\n-            mode it will stopped when the quantity\n+            mode it will stop when the quantity\n             monitored has stopped increasing.\n     '''\n     def __init__(self, monitor='val_loss', patience=0, verbose=0, mode='auto'):\n@@ -324,7 +324,7 @@ class EarlyStopping(Callback):\n \n         if mode not in ['auto', 'min', 'max']:\n             warnings.warn('EarlyStopping mode %s is unknown, '\n-                          'fallback to auto mode' % (self.mode), RuntimeWarning)\n+                          'fallback to auto mode.' % (self.mode), RuntimeWarning)\n             mode = 'auto'\n \n         if mode == 'min':\n@@ -364,7 +364,7 @@ class RemoteMonitor(Callback):\n     Requires the `requests` library.\n \n     # Arguments\n-        root: root url to which the events will be send (at the end\n+        root: root url to which the events will be sent (at the end\n             of every epoch). Events are sent to\n             `root + '/publish/epoch/end/'`. Calls are HTTP POST,\n             with a `data` argument which is a JSON-encoded dictionary\n@@ -453,7 +453,7 @@ class TensorBoard(Callback):\n         super(Callback, self).__init__()\n         if K._BACKEND != 'tensorflow':\n             raise Exception('TensorBoard callback only works '\n-                            'with the TensorFlow backend')\n+                            'with the TensorFlow backend.')\n         self.log_dir = log_dir\n         self.histogram_freq = histogram_freq\n \n\n@@ -69,7 +69,7 @@ def orthogonal(shape, scale=1.1):\n def identity(shape, scale=1):\n     if len(shape) != 2 or shape[0] != shape[1]:\n         raise Exception('Identity matrix initialization can only be used '\n-                        'for 2D square matrices')\n+                        'for 2D square matrices.')\n     else:\n         return K.variable(scale * np.identity(shape[0]))\n \n\n@@ -104,7 +104,7 @@ class Sequential(Layer):\n     @property\n     def state_updates(self):\n         \"\"\"\n-        Returns the `updates` from all layers in the sequence that are\n+        Return the `updates` from all layers in the sequence that are\n         stateful.  This is useful for separating _training_ updates and\n         _prediction_ updates for when we need to update a layers internal state\n         during a stateful prediction.\n@@ -232,7 +232,7 @@ class Graph(Layer):\n     @property\n     def state_updates(self):\n         \"\"\"\n-        Returns the `updates` from all nodes in that graph for nodes that are\n+        Return the `updates` from all nodes in that graph for nodes that are\n         stateful.  This is useful for separating _training_ updates and\n         _prediction_ updates for when we need to update a layers internal state\n         during a stateful prediction.\n\n@@ -584,7 +584,7 @@ class AveragePooling2D(_Pooling2D):\n \n \n class UpSampling1D(Layer):\n-    '''Repeats each temporal step `length` times along the time axis.\n+    '''Repeat each temporal step `length` times along the time axis.\n \n     # Input shape\n         3D tensor with shape: `(samples, steps, features)`.\n@@ -620,7 +620,7 @@ class UpSampling1D(Layer):\n \n \n class UpSampling2D(Layer):\n-    '''Repeats the rows and columns of the data\n+    '''Repeat the rows and columns of the data\n     by size[0] and size[1] respectively.\n \n     # Input shape\n\n@@ -84,7 +84,7 @@ class Layer(object):\n                                                                 ' but previous layer has output_shape ' +\n                                                                 str(layer.output_shape))\n         if layer.get_output_mask() is not None:\n-            assert self.supports_masked_input(), 'Cannot connect non-masking layer to layer with masked output'\n+            assert self.supports_masked_input(), 'Cannot connect non-masking layer to layer with masked output.'\n         self.previous = layer\n         self.build()\n \n@@ -530,7 +530,7 @@ class Merge(Layer):\n             for i in range(len(self.layers)):\n                 X = self.layers[i].get_output(train)\n                 if X.name is None:\n-                    raise ValueError('merge_mode=\"join\" only works with named inputs')\n+                    raise ValueError('merge_mode=\"join\" only works with named inputs.')\n                 else:\n                     inputs[X.name] = X\n             return inputs\n@@ -560,7 +560,7 @@ class Merge(Layer):\n             output = output.dimshuffle((0, 'x'))\n             return output\n         else:\n-            raise Exception('Unknown merge mode')\n+            raise Exception('Unknown merge mode.')\n \n     def get_input(self, train=False):\n         res = []\n@@ -748,7 +748,7 @@ class Flatten(Layer):\n     '''Flatten the input. Does not affect the batch size.\n \n     # Input shape\n-        Arbitrary, although all dimensions in the input shaped must be fixed.\n+        Arbitrary, although all dimensions in the input shape must be fixed.\n         Use the keyword argument `input_shape`\n         (tuple of integers, does not include the samples axis)\n         when using this layer as the first layer in a model.\n@@ -1363,7 +1363,7 @@ class LambdaMerge(Lambda):\n     def __init__(self, layers, function, output_shape=None):\n         if len(layers) < 2:\n             raise Exception('Please specify two or more input layers '\n-                            '(or containers) to merge')\n+                            '(or containers) to merge.')\n         self.layers = layers\n         self.params = []\n         self.regularizers = []\n@@ -1406,7 +1406,7 @@ class LambdaMerge(Lambda):\n             output_shape_func = types.FunctionType(output_shape_func, globals())\n             shape = output_shape_func(input_shapes)\n             if type(shape) not in {list, tuple}:\n-                raise Exception('output_shape function must return a tuple')\n+                raise Exception('output_shape function must return a tuple.')\n             return tuple(shape)\n \n     def get_params(self):\n@@ -1486,7 +1486,7 @@ class Siamese(Layer):\n \n         if merge_mode in {'cos', 'dot'}:\n             if len(inputs) > 2:\n-                raise Exception(merge_mode + ' merge takes exactly 2 layers')\n+                raise Exception(merge_mode + ' merge takes exactly 2 layers.')\n \n         self.layer = layer\n         self.trainable = layer.trainable\n@@ -1573,7 +1573,7 @@ class Siamese(Layer):\n             X = self.get_output_at(i, train)\n             if X.name is None:\n                 raise ValueError('merge_mode=\"join\" '\n-                                 'only works with named inputs')\n+                                 'only works with named inputs.')\n             o[X.name] = X\n         return o\n \n@@ -1691,10 +1691,10 @@ class Siamese(Layer):\n \n class SiameseHead(Layer):\n     '''This layer should be added only on top of a Siamese layer\n-    with merge_mode = None\n+    with merge_mode = None.\n \n     Outputs the output of the Siamese layer at a given index,\n-    specified by the head argument\n+    specified by the head argument.\n \n     # Arguments\n         head: The index at which the output of the Siamese layer\n@@ -1729,7 +1729,7 @@ class SiameseHead(Layer):\n \n def add_shared_layer(layer, inputs):\n     '''Use this function to add a shared layer across\n-    multiple Sequential models without merging the outputs\n+    multiple Sequential models without merging the outputs.\n     '''\n     input_layers = [l.layers[-1] for l in inputs]\n     s = Siamese(layer, input_layers, merge_mode=None)\n@@ -1741,7 +1741,7 @@ def add_shared_layer(layer, inputs):\n \n class Highway(Layer):\n     '''Densely connected highway network,\n-    a natural extension of LSTMs to feedforward networks\n+    a natural extension of LSTMs to feedforward networks.\n \n     cite: http://arxiv.org/pdf/1505.00387v2.pdf\n \n\n@@ -8,7 +8,7 @@ from ..constraints import unitnorm\n \n \n class Embedding(Layer):\n-    '''Turn positive integers (indexes) into denses vectors of fixed size.\n+    '''Turn positive integers (indexes) into dense vectors of fixed size.\n     eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n \n     This layer can only be used as the first layer in a model.\n@@ -38,7 +38,7 @@ class Embedding(Layer):\n           This is useful for [recurrent layers](recurrent.md) which may take\n           variable length input. If this is `True` then all subsequent layers\n           in the model need to support masking or an exception will be raised.\n-      input_length: Length of input sequences, when it is constantself.\n+      input_length: Length of input sequences, when it is constant.\n           This argument is required if you are going to connect\n           `Flatten` then `Dense` layers upstream\n           (without it, the shape of the dense outputs cannot be computed).\n\n@@ -6,7 +6,7 @@ from .. import backend as K\n class BatchNormalization(Layer):\n     '''Normalize the activations of the previous layer at each batch,\n     i.e. applies a transformation that maintains the mean activation\n-    close to 0. and the activation standard deviation close to 1.\n+    close to 0 and the activation standard deviation close to 1.\n \n     # Input shape\n         Arbitrary. Use the keyword argument `input_shape`\n\n@@ -30,7 +30,7 @@ class Recurrent(MaskedLayer):\n         return_sequences: Boolean. Whether to return the last output\n             in the output sequence, or the full sequence.\n         go_backwards: Boolean (default False).\n-            If True, rocess the input sequence backwards.\n+            If True, process the input sequence backwards.\n         stateful: Boolean (default False). If True, the last state\n             for each sample at index i in a batch will be used as initial\n             state for the sample of index i in the following batch.\n@@ -43,7 +43,7 @@ class Recurrent(MaskedLayer):\n             `Flatten` then `Dense` layers upstream\n             (without it, the shape of the dense outputs cannot be computed).\n             Note that if the recurrent layer is not the first layer\n-            in your model, you would need to specify the input Length\n+            in your model, you would need to specify the input length\n             at the level of the first layer\n             (e.g. via the `input_shape` argument)\n \n@@ -129,7 +129,7 @@ class Recurrent(MaskedLayer):\n         if K._BACKEND == 'tensorflow':\n             if not self.input_shape[1]:\n                 raise Exception('When using TensorFlow, you should define ' +\n-                                'explicitely the number of timesteps of ' +\n+                                'explicitly the number of timesteps of ' +\n                                 'your sequences. Make sure the first layer ' +\n                                 'has a \"batch_input_shape\" argument ' +\n                                 'including the samples axis.')\n\n@@ -59,7 +59,7 @@ def slice_X(X, start=None, stop=None):\n     '''\n     if type(X) == list:\n         if hasattr(start, '__len__'):\n-            # hdf5 dataset only support list object as indices\n+            # hdf5 datasets only support list objects as indices\n             if hasattr(start, 'shape'):\n                 start = start.tolist()\n             return [x[start] for x in X]\n@@ -84,7 +84,7 @@ def weighted_objective(fn):\n             # mask should have the same shape as score_array\n             score_array *= mask\n             #  the loss per batch should be proportional\n-            #  to the number of unmasked sampled.\n+            #  to the number of unmasked samples.\n             score_array /= K.mean(mask)\n \n         # reduce score_array to 1D\n@@ -461,7 +461,7 @@ class Sequential(Model, containers.Sequential):\n             show_accuracy=False, class_weight=None, sample_weight=None):\n         '''Train the model for a fixed number of epochs.\n \n-        Returns a history object. It `history` attribute is a record of\n+        Returns a history object. Its `history` attribute is a record of\n         training loss values at successive epochs,\n         as well as validation loss values (if applicable).\n \n@@ -984,7 +984,7 @@ class Graph(Model, containers.Graph):\n             class_weight={}, sample_weight={}):\n         '''Train the model for a fixed number of epochs.\n \n-        Returns a history object. It `history` attribute is a record of\n+        Returns a history object. Its `history` attribute is a record of\n         training loss values at successive epochs,\n         as well as validation loss values (if applicable).\n \n\n@@ -35,7 +35,7 @@ def hinge(y_true, y_pred):\n \n \n def categorical_crossentropy(y_true, y_pred):\n-    '''Expects a binary class matrix instead of a vector of scalar classes\n+    '''Expects a binary class matrix instead of a vector of scalar classes.\n     '''\n     return K.mean(K.categorical_crossentropy(y_pred, y_true), axis=-1)\n \n\n@@ -59,7 +59,7 @@ class Tokenizer(object):\n         By default, all punctuation is removed, turning the texts into\n         space-separated sequences of words\n         (words maybe include the `'` character). These sequences are then\n-        splits into lists of tokens. They will then be indexed or vectorized.\n+        split into lists of tokens. They will then be indexed or vectorized.\n \n         `0` is a reserved index that won't be assigned to any word.\n         '''\n@@ -167,12 +167,12 @@ class Tokenizer(object):\n             if self.word_index:\n                 nb_words = len(self.word_index) + 1\n             else:\n-                raise Exception(\"Specify a dimension (nb_words argument), or fit on some text data first\")\n+                raise Exception(\"Specify a dimension (nb_words argument), or fit on some text data first.\")\n         else:\n             nb_words = self.nb_words\n \n         if mode == \"tfidf\" and not self.document_count:\n-            raise Exception(\"Fit the Tokenizer on some data before using tfidf mode\")\n+            raise Exception(\"Fit the Tokenizer on some data before using tfidf mode.\")\n \n         X = np.zeros((len(sequences), nb_words))\n         for i, seq in enumerate(sequences):\n\n@@ -7,7 +7,7 @@ from six.moves import zip\n \n def to_categorical(y, nb_classes=None):\n     '''Convert class vector (integers from 0 to nb_classes)\n-    to binary class matrix, for use with categorical_crossentropy\n+    to binary class matrix, for use with categorical_crossentropy.\n     '''\n     y = np.asarray(y, dtype='int32')\n     if not nb_classes:\n\n@@ -143,8 +143,8 @@ class ModelToDot(object):\n \n def to_graph(model, **kwargs):\n     \"\"\"\n-    `recursive` controls wether we recursively explore container layers\n-    `show_shape` controls wether the shape is shown in the graph\n+    `recursive` controls whether we recursively explore container layers\n+    `show_shape` controls whether the shape is shown in the graph\n     \"\"\"\n     return ModelToDot()(model, **kwargs)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#16675b98c0d47c1f58f42ada534ff52721aa085e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 99 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 19 | Methods Changed: 14 | Complexity Δ (Sum/Max): 44/44 | Churn Δ: 103 | Churn Cumulative: 4081 | Contributors (this commit): 29 | Commits (past 90d): 20 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -498,6 +498,20 @@ class Sequential(Model, containers.Sequential):\n                 output timesteps, which is useful\n                 in sequence to sequence learning.\n         '''\n+        if type(X) == list:\n+            if len(set([len(a) for a in X] + [len(y)])) != 1:\n+                raise Exception('All input arrays and the target array must '\n+                                'have the same number of samples.')\n+        else:\n+            if len(X) != len(y):\n+                raise Exception('The input data tensor (X) and '\n+                                'the target tensor (y) must have '\n+                                'the same number of samples. Found: '\n+                                'len(X) = {}, len(y) = {}'.format(len(X), len(y)))\n+        if sample_weight is not None:\n+            assert len(sample_weight) == len(y), ('\"sample_weight\" must have '\n+                                                  'the same number of samples '\n+                                                  'as X and y.')\n         X = standardize_X(X)\n         y = standardize_y(y)\n \n@@ -511,11 +525,20 @@ class Sequential(Model, containers.Sequential):\n         if validation_data:\n             if len(validation_data) == 2:\n                 X_val, y_val = validation_data\n+                if type(X_val) == list:\n+                    assert len(set([len(a) for a in X_val] + [len(y_val)])) == 1\n+                else:\n+                    assert len(X_val) == len(y_val)\n                 X_val = standardize_X(X_val)\n                 y_val = standardize_y(y_val)\n                 sample_weight_val = standardize_weights(y_val)\n             elif len(validation_data) == 3:\n                 X_val, y_val, sample_weight_val = validation_data\n+                if type(X_val) == list:\n+                    assert len(set([len(a) for a in X_val] +\n+                                   [len(y_val), len(sample_weight_val)])) == 1\n+                else:\n+                    assert len(X_val) == len(y_val) == len(sample_weight_val)\n                 X_val = standardize_X(X_val)\n                 y_val = standardize_y(y_val)\n                 sample_weight_val = standardize_weights(y_val,\n@@ -619,6 +642,20 @@ class Sequential(Model, containers.Sequential):\n             verbose: verbosity mode, 0 or 1.\n             sample_weight: sample weights, as a numpy array.\n         '''\n+        if type(X) == list:\n+            if len(set([len(a) for a in X] + [len(y)])) != 1:\n+                raise Exception('All input arrays and the target array must '\n+                                'have the same number of samples.')\n+        else:\n+            if len(X) != len(y):\n+                raise Exception('The input data tensor (X) and '\n+                                'the target tensor (y) must have '\n+                                'the same number of samples. Found: '\n+                                'len(X) = {}, len(y) = {}'.format(len(X), len(y)))\n+        if sample_weight is not None:\n+            assert len(sample_weight) == len(y), ('\"sample_weight\" must have '\n+                                                  'the same number of samples '\n+                                                  'as X and y.')\n         X = standardize_X(X)\n         y = standardize_y(y)\n         sample_weight = standardize_weights(y, sample_weight=sample_weight)\n@@ -643,6 +680,20 @@ class Sequential(Model, containers.Sequential):\n \n         Arguments: see `fit` method.\n         '''\n+        if type(X) == list:\n+            if len(set([len(a) for a in X] + [len(y)])) != 1:\n+                raise Exception('All input arrays and the target array must '\n+                                'have the same number of samples.')\n+        else:\n+            if len(X) != len(y):\n+                raise Exception('The input data tensor (X) and '\n+                                'the target tensor (y) must have '\n+                                'the same number of samples. Found: '\n+                                'len(X) = {}, len(y) = {}'.format(len(X), len(y)))\n+        if sample_weight is not None:\n+            assert len(sample_weight) == len(y), ('\"sample_weight\" must have '\n+                                                  'the same number of samples '\n+                                                  'as X and y.')\n         X = standardize_X(X)\n         y = standardize_y(y)\n         sample_weight = standardize_weights(y, class_weight=class_weight,\n@@ -659,6 +710,20 @@ class Sequential(Model, containers.Sequential):\n \n         Arguments: see `fit` method.\n         '''\n+        if type(X) == list:\n+            if len(set([len(a) for a in X] + [len(y)])) != 1:\n+                raise Exception('All input arrays and the target array must '\n+                                'have the same number of samples.')\n+        else:\n+            if len(X) != len(y):\n+                raise Exception('The input data tensor (X) and '\n+                                'the target tensor (y) must have '\n+                                'the same number of samples. Found: '\n+                                'len(X) = {}, len(y) = {}'.format(len(X), len(y)))\n+        if sample_weight is not None:\n+            assert len(sample_weight) == len(y), ('\"sample_weight\" must have '\n+                                                  'the same number of samples '\n+                                                  'as X and y.')\n         X = standardize_X(X)\n         y = standardize_y(y)\n         sample_weight = standardize_weights(y, sample_weight=sample_weight)\n@@ -821,12 +886,21 @@ class Sequential(Model, containers.Sequential):\n                 raise Exception('The generator output must be a tuple.')\n             if len(generator_output) == 2:\n                 X, y = generator_output\n+                if type(X) == list:\n+                    assert len(set([len(a) for a in X] + [len(y)])) == 1\n+                else:\n+                    assert len(X) == len(y)\n                 sample_weight = None\n             elif len(generator_output) == 3:\n                 X, y, sample_weight = generator_output\n+                if type(X) == list:\n+                    assert len(set([len(a) for a in X] + [len(y), len(sample_weight)])) == 1\n+                else:\n+                    assert len(X) == len(y) == len(sample_weight)\n             else:\n                 _stop.set()\n-                raise Exception('The generator output tuple must have 2 or 3 elements.')\n+                raise Exception('The generator output tuple must have '\n+                                '2 or 3 elements.')\n             return X, y, sample_weight\n \n         # start generator thread storing batches into a queue\n@@ -843,7 +917,7 @@ class Sequential(Model, containers.Sequential):\n                         i += 1\n                     else:\n                         time.sleep(wait_time)\n-                except KeyboardInterrupt:\n+                except:\n                     _stop.set()\n                     return\n \n@@ -1013,6 +1087,9 @@ class Graph(Model, containers.Graph):\n         '''\n         X = [data[name] for name in self.input_order]\n         y = [standardize_y(data[name]) for name in self.output_order]\n+        if len(set([len(a) for a in X] + [len(a) for a in y])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n \n         sample_weight_list = [standardize_weights(y[i],\n                                                   sample_weight=sample_weight.get(self.output_order[i])) for i in range(len(self.output_order))]\n@@ -1057,8 +1134,10 @@ class Graph(Model, containers.Graph):\n         '''\n         sample_weight = [standardize_weights(data[name],\n                                              sample_weight=sample_weight.get(name)) for name in self.output_order]\n-\n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n+        if len(set([len(a) for a in ins])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n         outs = self._test_loop(self._test, ins, batch_size, verbose)\n         return outs[0]\n \n@@ -1069,6 +1148,9 @@ class Graph(Model, containers.Graph):\n         Arguments: see `fit` method.\n         '''\n         ins = [data[name] for name in self.input_order]\n+        if len(set([len(a) for a in ins])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n         outs = self._predict_loop(self._predict, ins, batch_size, verbose)\n         return dict(zip(self.output_order, outs))\n \n@@ -1081,6 +1163,9 @@ class Graph(Model, containers.Graph):\n                                              sample_weight=sample_weight.get(name),\n                                              class_weight=class_weight.get(name)) for name in self.output_order]\n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n+        if len(set([len(a) for a in ins])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n         return self._train(ins)\n \n     def test_on_batch(self, data, sample_weight={}):\n@@ -1091,12 +1176,18 @@ class Graph(Model, containers.Graph):\n         sample_weight = [standardize_weights(data[name],\n                                              sample_weight=sample_weight.get(name)) for name in self.output_order]\n         ins = [data[name] for name in self.input_order] + [standardize_y(data[name]) for name in self.output_order] + sample_weight\n+        if len(set([len(a) for a in ins])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n         return self._test(ins)\n \n     def predict_on_batch(self, data):\n         '''Generate predictions for a single batch of samples.\n         '''\n         ins = [data[name] for name in self.input_order]\n+        if len(set([len(a) for a in ins])) != 1:\n+            raise Exception('All input arrays and target arrays must have '\n+                            'the same number of samples.')\n         outs = self._predict(ins)\n         return dict(zip(self.output_order, outs))\n \n@@ -1247,6 +1338,10 @@ class Graph(Model, containers.Graph):\n                                 '(data, sample_weight).')\n             assert type(data) == dict\n             assert type(sample_weight) == dict\n+            if len(set([len(data[name]) for name in data.keys()] +\n+                       [len(sample_weight[name]) for name in sample_weight.keys()])) != 1:\n+                raise Exception('All input arrays and target arrays must have '\n+                                'the same number of samples.')\n             return data, sample_weight\n \n         # start generator thread storing batches into a queue\n@@ -1263,7 +1358,7 @@ class Graph(Model, containers.Graph):\n                         i += 1\n                     else:\n                         time.sleep(wait_time)\n-                except KeyboardInterrupt:\n+                except:\n                     _stop.set()\n                     return\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
