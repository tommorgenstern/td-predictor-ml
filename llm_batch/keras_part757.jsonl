{"custom_id": "keras#75784fad8e3bc268108eae3550decc6b13a2f329", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 89 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 9 | Complexity Î” (Sum/Max): 9/9 | Churn Î”: 89 | Churn Cumulative: 95 | Contributors (this commit): 2 | Commits (past 90d): 2 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -3,6 +3,7 @@ import numpy as np\n from keras import backend\n from keras import regularizers\n from keras import testing\n+from keras.regularizers.regularizers import validate_float_arg\n \n \n # TODO: serialization tests\n@@ -51,3 +52,91 @@ class RegularizersTest(testing.TestCase):\n \n         with self.assertRaises(ValueError):\n             regularizers.get(\"typo\")\n+\n+    def test_l1l2_get_config(self):\n+        l1 = 0.01\n+        l2 = 0.02\n+        reg = regularizers.L1L2(l1=l1, l2=l2)\n+        config = reg.get_config()\n+\n+        self.assertEqual(config, {\"l1\": l1, \"l2\": l2})\n+\n+        reg_from_config = regularizers.L1L2.from_config(config)\n+        config_from_config = reg_from_config.get_config()\n+\n+        self.assertDictEqual(config, config_from_config)\n+        self.assertEqual(reg_from_config.l1, l1)\n+        self.assertEqual(reg_from_config.l2, l2)\n+\n+    def test_orthogonal_regularizer_mode_validation(self):\n+        with self.assertRaises(ValueError) as context:\n+            regularizers.OrthogonalRegularizer(factor=0.01, mode=\"invalid_mode\")\n+\n+        expected_message = (\n+            'Invalid value for argument `mode`. Expected one of {\"rows\", '\n+            '\"columns\"}. Received: mode=invalid_mode'\n+        )\n+        self.assertEqual(str(context.exception), expected_message)\n+\n+    def test_orthogonal_regularizer_input_rank_validation(self):\n+        with self.assertRaises(ValueError) as context:\n+            value = np.random.random((4, 4, 4))\n+            x = backend.Variable(value)\n+            regularizers.OrthogonalRegularizer(factor=0.1)(x)\n+\n+        expected_message = (\n+            \"Inputs to OrthogonalRegularizer must have rank 2. \"\n+            f\"Received: inputs.shape={(4, 4, 4)}\"\n+        )\n+        self.assertEqual(str(context.exception), expected_message)\n+\n+    def test_orthogonal_regularizer_get_config(self):\n+        factor = 0.01\n+        mode = \"columns\"\n+        regularizer = regularizers.OrthogonalRegularizer(\n+            factor=factor, mode=mode\n+        )\n+        config = regularizer.get_config()\n+\n+        self.assertAlmostEqual(config[\"factor\"], factor, 7)\n+        self.assertEqual(config[\"mode\"], mode)\n+\n+        reg_from_config = regularizers.OrthogonalRegularizer.from_config(config)\n+        config_from_config = reg_from_config.get_config()\n+\n+        self.assertAlmostEqual(config_from_config[\"factor\"], factor, 7)\n+        self.assertEqual(config_from_config[\"mode\"], mode)\n+\n+\n+class ValidateFloatArgTest(testing.TestCase):\n+    def test_validate_float_with_valid_args(self):\n+        self.assertEqual(validate_float_arg(1, \"test\"), 1.0)\n+        self.assertEqual(validate_float_arg(1.0, \"test\"), 1.0)\n+\n+    def test_validate_float_with_invalid_types(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"expected a non-negative float\"\n+        ):\n+            validate_float_arg(\"not_a_number\", \"test\")\n+\n+    def test_validate_float_with_nan(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"expected a non-negative float\"\n+        ):\n+            validate_float_arg(float(\"nan\"), \"test\")\n+\n+    def test_validate_float_with_inf(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"expected a non-negative float\"\n+        ):\n+            validate_float_arg(float(\"inf\"), \"test\")\n+        with self.assertRaisesRegex(\n+            ValueError, \"expected a non-negative float\"\n+        ):\n+            validate_float_arg(-float(\"inf\"), \"test\")\n+\n+    def test_validate_float_with_negative_number(self):\n+        with self.assertRaisesRegex(\n+            ValueError, \"expected a non-negative float\"\n+        ):\n+            validate_float_arg(-1, \"test\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73e110bf69b30ed134f987988f2264d7a0c36124", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 1 | Churn Cumulative: 1307 | Contributors (this commit): 10 | Commits (past 90d): 3 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -293,6 +293,7 @@ def load_img(\n     return img\n \n \n+@keras_export(\"keras.preprocessing.image.smart_resize\")\n def smart_resize(\n     x,\n     size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#60b2d33b1dbbd50de5b8bb27f4221fd53d90fa26", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 8 | Files Changed: 3 | Hunks: 3 | Methods Changed: 2 | Complexity Î” (Sum/Max): 1/1 | Churn Î”: 12 | Churn Cumulative: 3800 | Contributors (this commit): 25 | Commits (past 90d): 9 | Contributors (cumulative): 28 | DMM Complexity: 1.0\n\nDIFF:\n@@ -281,7 +281,7 @@ class TextGenerator(keras.callbacks.Callback):\n             else:\n                 x = start_tokens\n             x = np.array([x])\n-            y, _ = self.model.predict(x)\n+            y, _ = self.model.predict(x, verbose=0)\n             sample_token = self.sample_from(y[0][sample_index])\n             tokens_generated.append(sample_token)\n             start_tokens.append(sample_token)\n\n@@ -575,11 +575,4 @@ the regularization techniques are necessary.\n bag sizes are fixed here.\n - In order not to rely on the random initial weights of a single model, averaging ensemble\n methods should be considered.\n-\n-Example available on HuggingFace.\n-\n-| Trained Model | Demo |\n-| :--: | :--: |\n-| [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Model-Attention%20MIL-black.svg)](https://huggingface.co/keras-io/attention_mil) | [![Generic badge](https://img.shields.io/badge/ðŸ¤—%20Spaces-Attention%20MIL-black.svg)](https://huggingface.co/spaces/keras-io/Attention_based_Deep_Multiple_Instance_Learning) |\n-\n \"\"\"\n\n@@ -370,6 +370,9 @@ class TextVectorization(Layer):\n     def variable_dtype(self):\n         return \"string\"\n     \n+    def build(self, input_shape=None):\n+        pass\n+\n     def compute_output_shape(self, input_shape):\n         if self._output_mode == \"int\":\n             return (input_shape[0], self._output_sequence_length)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d0121437f94d39f3f6d2ca01fe0b2a5744eca2c5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 3 | Churn Cumulative: 130 | Contributors (this commit): 4 | Commits (past 90d): 5 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -30,11 +30,8 @@ If you are unfamiliar with the concept of self-attention or Transformers, you ca\n from  FranÃ§ois Chollet's book *Deep Learning with Python*. This example uses\n code snippets from another example,\n [Image classification with Vision Transformer](https://keras.io/examples/vision/image_classification_with_vision_transformer/).\n-\n-\n \"\"\"\n \n-\n \"\"\"\n ## Imports\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ed7706906196c2ac4a7fbb1cd8379224480dc53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 132 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: Compact Convolutional Transformers\n Author: [Sayak Paul](https://twitter.com/RisingSayak)\n-Converted to Keras 3 by: [Muhammad Anas Raza](https://anasrz.com), [Guillaume Baquiast](https://www.linkedin.com/in/guillaume-baquiast-478965ba/)\n Date created: 2021/06/30\n Last modified: 2023/08/07\n Description: Compact Convolutional Transformers for efficient image classification.\n Accelerator: GPU\n+Converted to Keras 3 by: [Muhammad Anas Raza](https://anasrz.com), [Guillaume Baquiast](https://www.linkedin.com/in/guillaume-baquiast-478965ba/)\n \"\"\"\n \"\"\"\n As discussed in the [Vision Transformers (ViT)](https://arxiv.org/abs/2010.11929) paper,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a6f4ac2ccc6f873a116df4632449fe188bd092f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 5 | Churn Cumulative: 137 | Contributors (this commit): 4 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -248,12 +248,15 @@ class StochasticDepth(layers.Layer):\n     def __init__(self, drop_prop, **kwargs):\n         super().__init__(**kwargs)\n         self.drop_prob = drop_prop\n+        self.seed_generator = keras.random.SeedGenerator(1337)\n \n     def call(self, x, training=None):\n         if training:\n             keep_prob = 1 - self.drop_prob\n             shape = (keras.ops.shape(x)[0],) + (1,) * (len(x.shape) - 1)\n-            random_tensor = keep_prob + keras.random.uniform(shape, 0, 1)\n+            random_tensor = keep_prob + keras.random.uniform(\n+                shape, 0, 1, seed=self.seed_generator\n+            )\n             random_tensor = keras.ops.floor(random_tensor)\n             return (x / keep_prob) * random_tensor\n         return x\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a43944251e54c36c3193b11c23848c067f354116", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 4 | Churn Cumulative: 462 | Contributors (this commit): 2 | Commits (past 90d): 8 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -37,10 +37,6 @@ the CIFAR-10 dataset.\n ## Imports\n \"\"\"\n \n-import os\n-\n-os.environ[\"KERAS_BACKEND\"] = \"jax\"\n-\n import keras\n from keras import layers\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9e5df4991180329b91e02e4aae9b6e2f86a45139", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 464 | Contributors (this commit): 2 | Commits (past 90d): 9 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -1,10 +1,10 @@\n \"\"\"\n Title: Image classification with ConvMixer\n Author: [Sayak Paul](https://twitter.com/RisingSayak)\n-Converted to Keras 3 by: [Md Awsafur Rahman](https://awsaf49.github.io)\n Date created: 2021/10/12\n Last modified: 2021/10/12\n Description: An all-convolutional network applied to patches of images.\n+Converted to Keras 3 by: [Md Awsafur Rahman](https://awsaf49.github.io)\n \"\"\"\n \"\"\"\n ## Introduction\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#abe4e4bd5260d9e95733f1853b6fa5de64f88617", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 1 | Churn Cumulative: 465 | Contributors (this commit): 2 | Commits (past 90d): 10 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -4,6 +4,7 @@ Author: [Sayak Paul](https://twitter.com/RisingSayak)\n Date created: 2021/10/12\n Last modified: 2021/10/12\n Description: An all-convolutional network applied to patches of images.\n+Accelerator: GPU\n Converted to Keras 3 by: [Md Awsafur Rahman](https://awsaf49.github.io)\n \"\"\"\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1ae3fe4775e9c5a996e86eeb531501c273fe437e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 71 | Lines Deleted: 37 | Files Changed: 7 | Hunks: 39 | Methods Changed: 10 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 108 | Churn Cumulative: 3994 | Contributors (this commit): 8 | Commits (past 90d): 31 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -89,7 +89,7 @@ auto = tf.data.AUTOTUNE\n \n augmentation_layers = [\n     keras.layers.RandomCrop(image_size, image_size),\n-    keras.layers.RandomFlip(\"horizontal\")\n+    keras.layers.RandomFlip(\"horizontal\"),\n ]\n \n \n@@ -159,7 +159,12 @@ def conv_mixer_block(x, filters: int, kernel_size: int):\n \n \n def get_conv_mixer_256_8(\n-    image_size=32, filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=10\n+    image_size=32,\n+    filters=256,\n+    depth=8,\n+    kernel_size=5,\n+    patch_size=2,\n+    num_classes=10,\n ):\n     \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n     The hyperparameter values are taken from the paper.\n\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: Multiclass semantic segmentation using DeepLabV3+\n Author: [Soumik Rakshit](http://github.com/soumik12345)\n-Converted to Keras 3: [Muhammad Anas Raza](https://anasrz.com)\n Date created: 2021/08/31\n Last modified: 2023/07/19\n Description: Implement DeepLabV3+ architecture for Multi-class Semantic Segmentation.\n Accelerator: GPU\n+Converted to Keras 3: [Muhammad Anas Raza](https://anasrz.com)\n \"\"\"\n \"\"\"\n ## Introduction\n@@ -36,11 +36,13 @@ import keras\n from keras import layers\n from keras import ops\n \n-import cv2\n import numpy as np\n from glob import glob\n+import cv2\n from scipy.io import loadmat\n import matplotlib.pyplot as plt\n+\n+# For data preprocessing\n from tensorflow import image as tf_image\n from tensorflow import data as tf_data\n from tensorflow import io as tf_io\n@@ -330,6 +332,7 @@ plot_predictions(train_images[:4], colormap, model=model)\n \n \"\"\"\n ### Inference on Validation Images\n+\n You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/deeplabv3p-resnet50)\n and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/Human-Part-Segmentation).\n \"\"\"\n\n@@ -148,13 +148,9 @@ AUTOTUNE = tf_data.AUTOTUNE\n tfds.disable_progress_bar()\n \n data, dataset_info = tfds.load(\n-    \"cats_vs_dogs\",\n-    with_info=True,\n-    as_supervised=True\n-)\n-train_steps_per_epoch = (\n-    dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n+    \"cats_vs_dogs\", with_info=True, as_supervised=True\n )\n+train_steps_per_epoch = dataset_info.splits[\"train\"].num_examples // BATCH_SIZE\n train_dataset = data[\"train\"]\n \n num_classes = dataset_info.features[\"label\"].num_classes\n@@ -521,6 +517,7 @@ keras_cv.visualization.plot_image_gallery(\n `model.fit()`, which accepts a tuple of `(images, labels)`.\n \"\"\"\n \n+\n def unpackage_dict(inputs):\n     return inputs[\"images\"], inputs[\"labels\"]\n \n@@ -540,6 +537,7 @@ Cosine decay with warmup schedule used here, [you can read more about it\n here](https://scorrea92.medium.com/cosine-learning-rate-decay-e8b50aa455b).\n \"\"\"\n \n+\n def lr_warmup_cosine_decay(\n     global_step,\n     warmup_steps,\n@@ -566,7 +564,7 @@ def lr_warmup_cosine_decay(\n         )\n     )\n \n-    warmup_lr = (target_lr * (global_step / warmup_steps))\n+    warmup_lr = target_lr * (global_step / warmup_steps)\n \n     if hold > 0:\n         learning_rate = ops.where(\n@@ -579,9 +577,7 @@ def lr_warmup_cosine_decay(\n     return learning_rate\n \n \n-class WarmUpCosineDecay(\n-    schedules.LearningRateSchedule\n-):\n+class WarmUpCosineDecay(schedules.LearningRateSchedule):\n     def __init__(\n         self, warmup_steps, total_steps, hold, start_lr=0.0, target_lr=1e-2\n     ):\n@@ -604,6 +600,7 @@ class WarmUpCosineDecay(\n \n         return ops.where(step > self.total_steps, 0.0, lr)\n \n+\n \"\"\"![WarmUpCosineDecay schedule](https://i.imgur.com/YCr5pII.png)\n \n The schedule looks a as we expect.\n\n@@ -99,7 +99,9 @@ interpolation_steps = 5\n encoding_1 = ops.squeeze(model.encode_text(prompt_1))\n encoding_2 = ops.squeeze(model.encode_text(prompt_2))\n \n-interpolated_encodings = ops.linspace(encoding_1, encoding_2, interpolation_steps)\n+interpolated_encodings = ops.linspace(\n+    encoding_1, encoding_2, interpolation_steps\n+)\n \n # Show the size of the latent manifold\n print(f\"Encoding shape: {encoding_1.shape}\")\n@@ -174,7 +176,9 @@ interpolation_steps = 150\n batch_size = 3\n batches = interpolation_steps // batch_size\n \n-interpolated_encodings = ops.linspace(encoding_1, encoding_2, interpolation_steps)\n+interpolated_encodings = ops.linspace(\n+    encoding_1, encoding_2, interpolation_steps\n+)\n batched_encodings = ops.split(interpolated_encodings, batches)\n \n images = []\n@@ -274,7 +278,9 @@ the `diffusion_noise` parameter:\n \n images = []\n for batch in range(batches):\n-    images.append(model.generate_image(batched_encodings[batch], batch_size=batch_size))\n+    images.append(\n+        model.generate_image(batched_encodings[batch], batch_size=batch_size)\n+    )\n \n images = np.concatenate(images)\n plot_grid(images, \"4-way-interpolation-varying-noise.jpg\", interpolation_steps)\n\n@@ -175,10 +175,12 @@ class Patches(layers.Layer):\n         out = keras.ops.reshape(patches, (batch_size, num_patches, patch_dim))\n         return out\n \n+\n \"\"\"\n ## Implement position embedding as a layer\n \"\"\"\n \n+\n class PositionEmbedding(keras.layers.Layer):\n     def __init__(\n         self,\n@@ -221,7 +223,9 @@ class PositionEmbedding(keras.layers.Layer):\n         sequence_length = shape[-2]\n         # trim to match the length of the input sequence, which might be less\n         # than the sequence_length of the layer.\n-        position_embeddings = keras.ops.convert_to_tensor(self.position_embeddings)\n+        position_embeddings = keras.ops.convert_to_tensor(\n+            self.position_embeddings\n+        )\n         position_embeddings = keras.ops.slice(\n             position_embeddings,\n             (start_index, 0),\n@@ -232,6 +236,7 @@ class PositionEmbedding(keras.layers.Layer):\n     def compute_output_shape(self, input_shape):\n         return input_shape\n \n+\n \"\"\"\n ## The MLP-Mixer model\n \n@@ -342,9 +347,7 @@ in the Transformer block with a parameter-free 2D Fourier transformation layer:\n \n \n class FNetLayer(layers.Layer):\n-    def __init__(\n-        self, embedding_dim, dropout_rate, *args, **kwargs\n-    ):\n+    def __init__(self, embedding_dim, dropout_rate, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n \n         self.ffn = keras.Sequential(\n@@ -383,10 +386,7 @@ takes around 8 seconds per epoch.\n \"\"\"\n \n fnet_blocks = keras.Sequential(\n-    [\n-        FNetLayer(embedding_dim, dropout_rate)\n-        for _ in range(num_blocks)\n-    ]\n+    [FNetLayer(embedding_dim, dropout_rate) for _ in range(num_blocks)]\n )\n learning_rate = 0.001\n fnet_classifier = build_classifier(fnet_blocks, positional_encoding=True)\n\n@@ -77,10 +77,14 @@ shutil.unpack_archive(\"/datasets/caltech-101/Annotations.tar\", \"/\")\n \n # list of paths to images and annotations\n image_paths = [\n-    f for f in os.listdir(path_images) if os.path.isfile(os.path.join(path_images, f))\n+    f\n+    for f in os.listdir(path_images)\n+    if os.path.isfile(os.path.join(path_images, f))\n ]\n annot_paths = [\n-    f for f in os.listdir(path_annot) if os.path.isfile(os.path.join(path_annot, f))\n+    f\n+    for f in os.listdir(path_annot)\n+    if os.path.isfile(os.path.join(path_annot, f))\n ]\n \n image_paths.sort()\n@@ -195,7 +199,9 @@ plt.axis(\"off\")\n patches = Patches(patch_size)(np.expand_dims(x_train[0], axis=0))\n print(f\"Image size: {image_size} X {image_size}\")\n print(f\"Patch size: {patch_size} X {patch_size}\")\n-print(f\"{patches.shape[1]} patches per image \\n{patches.shape[-1]} elements per patch\")\n+print(\n+    f\"{patches.shape[1]} patches per image \\n{patches.shape[-1]} elements per patch\"\n+)\n \n \n n = int(np.sqrt(patches.shape[1]))\n@@ -301,7 +307,9 @@ def create_vit_object_detector(\n     representation = layers.Flatten()(representation)\n     representation = layers.Dropout(0.3)(representation)\n     # Add MLP.\n-    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.3)\n+    features = mlp(\n+        representation, hidden_units=mlp_head_units, dropout_rate=0.3\n+    )\n \n     bounding_box = layers.Dense(4)(\n         features\n@@ -317,7 +325,6 @@ def create_vit_object_detector(\n \n \n def run_experiment(model, learning_rate, weight_decay, batch_size, num_epochs):\n-\n     optimizer = keras.optimizers.AdamW(\n         learning_rate=learning_rate, weight_decay=weight_decay\n     )\n@@ -408,6 +415,7 @@ import matplotlib.patches as patches\n # Saves the model in current path\n vit_object_detector.save(\"vit_object_detector.keras\")\n \n+\n # To calculate IoU (intersection over union, given two bounding boxes)\n def bounding_box_intersection_over_union(box_predicted, box_truth):\n     # get (x, y) coordinates of intersection of bounding boxes\n@@ -487,7 +495,9 @@ for input_image in x_test[:10]:\n \n     top_left_x, top_left_y = int(y_test[i][0] * w), int(y_test[i][1] * h)\n \n-    bottom_right_x, bottom_right_y = int(y_test[i][2] * w), int(y_test[i][3] * h)\n+    bottom_right_x, bottom_right_y = int(y_test[i][2] * w), int(\n+        y_test[i][3] * h\n+    )\n \n     box_truth = top_left_x, top_left_y, bottom_right_x, bottom_right_y\n \n\n@@ -29,6 +29,7 @@ import keras\n from keras import ops\n from keras import layers\n from keras.applications.resnet_v2 import ResNet50V2\n+\n \"\"\"\n ## Prepare the data\n \"\"\"\n@@ -109,7 +110,9 @@ def create_classifier(encoder, trainable=True):\n     features = layers.Dropout(dropout_rate)(features)\n     outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n \n-    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n+    model = keras.Model(\n+        inputs=inputs, outputs=outputs, name=\"cifar10-classifier\"\n+    )\n     model.compile(\n         optimizer=keras.optimizers.Adam(learning_rate),\n         loss=keras.losses.SparseCategoricalCrossentropy(),\n@@ -122,6 +125,7 @@ def create_classifier(encoder, trainable=True):\n ## Define npairs loss function\n \"\"\"\n \n+\n def npairs_loss(y_true, y_pred):\n     \"\"\"Computes the npairs loss between `y_true` and `y_pred`.\n \n@@ -164,7 +168,9 @@ encoder = create_encoder()\n classifier = create_classifier(encoder)\n classifier.summary()\n \n-history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n+history = classifier.fit(\n+    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n+)\n \n accuracy = classifier.evaluate(x_test, y_test)[1]\n print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n@@ -192,11 +198,14 @@ class SupervisedContrastiveLoss(keras.losses.Loss):\n \n     def __call__(self, labels, feature_vectors, sample_weight=None):\n         # Normalize feature vectors\n-        feature_vectors_normalized = keras.utils.normalize(feature_vectors, axis=1, order=2)\n+        feature_vectors_normalized = keras.utils.normalize(\n+            feature_vectors, axis=1, order=2\n+        )\n         # Compute logits\n         logits = ops.divide(\n             ops.matmul(\n-                feature_vectors_normalized, ops.transpose(feature_vectors_normalized)\n+                feature_vectors_normalized,\n+                ops.transpose(feature_vectors_normalized),\n             ),\n             self.temperature,\n         )\n@@ -208,7 +217,9 @@ def add_projection_head(encoder):\n     features = encoder(inputs)\n     outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n     model = keras.Model(\n-        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n+        inputs=inputs,\n+        outputs=outputs,\n+        name=\"cifar-encoder_with_projection-head\",\n     )\n     return model\n \n@@ -237,7 +248,9 @@ history = encoder_with_projection_head.fit(\n \n classifier = create_classifier(encoder, trainable=False)\n \n-history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n+history = classifier.fit(\n+    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n+)\n \n accuracy = classifier.evaluate(x_test, y_test)[1]\n print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2af542dbfa501b0cc87e77bc191f67ecf382b37e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 366 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,7 @@ architecture that performs well on semantic segmentation benchmarks.\n \n ### References:\n \n-- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1802.02611.pdf)\n+- [Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1802.02611)\n - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587)\n - [DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](https://arxiv.org/abs/1606.00915)\n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3028ab52cf2640fea98b4935b8b614540f1587d8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 1 | Churn Cumulative: 367 | Contributors (this commit): 3 | Commits (past 90d): 5 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -36,6 +36,7 @@ import keras\n from keras import layers\n from keras import ops\n \n+import os\n import numpy as np\n from glob import glob\n import cv2\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0ef8a0f6719418c885b329d9ed129d06bda45c97", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 97 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -276,7 +276,7 @@ def run_experiment(model):\n         ],\n     )\n \n-    checkpoint_filepath = \"/tmp/checkpoint\"\n+    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n     checkpoint_callback = keras.callbacks.ModelCheckpoint(\n         checkpoint_filepath,\n         monitor=\"val_accuracy\",\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#127a11dfc5cd5c4da8712c863464d1a17ab01e5a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 99 | Contributors (this commit): 4 | Commits (past 90d): 4 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -112,7 +112,7 @@ class Patches(layers.Layer):\n         self.patch_size = patch_size\n \n     def call(self, images):\n-        input_shape = ops.backend.shape(images)\n+        input_shape = ops.shape(images)\n         batch_size = input_shape[0]\n         height = input_shape[1]\n         width = input_shape[2]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8f73dd04c8df8b9b5a51917129dc9d17b6465828", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Î” (Sum/Max): 3/3 | Churn Î”: 16 | Churn Cumulative: 32 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -10,6 +10,7 @@ from keras.backend.common import standardize_dtype\n from keras.backend.common.keras_tensor import KerasTensor\n from keras.backend.common.name_scope import name_scope as base_name_scope\n from keras.backend.common.stateless_scope import StatelessScope\n+from keras.backend.common.stateless_scope import in_stateless_scope\n from keras.utils.naming import auto_name\n \n SUPPORTS_SPARSE_TENSORS = True\n@@ -31,6 +32,21 @@ class Variable(\n             value, dtype=self._dtype, trainable=self.trainable, name=self.name\n         )\n \n+    def _deferred_initialize(self):\n+        if self._value is not None:\n+            raise ValueError(f\"Variable {self.path} is already initialized.\")\n+\n+        if in_stateless_scope():\n+            raise ValueError(\n+                \"You are attempting to initialize a variable \"\n+                \"while in a stateless scope. This is disallowed. \"\n+                \"Make sure that all variables are initialized \"\n+                \"before you start using your layer/model objects.\"\n+            )\n+        with tf.init_scope():\n+            value = self._initializer(self._shape, dtype=self._dtype)\n+            self._initialize(value)\n+\n     def _direct_assign(self, value):\n         self._value.assign(tf.cast(value, self._value.dtype))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7cc0d7cff0241acc2e19a5c5d5b95d1eae6479e3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 4 | Churn Cumulative: 942 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -162,7 +162,7 @@ def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n         )\n \n         # Copy from remote to temporary local directory\n-        file_utils.copy(filepath, local_path, overwrite=True)\n+        file_utils.copy(filepath, local_path)\n \n         # Switch filepath to local zipfile for loading model\n         if zipfile.is_zipfile(local_path):\n\n@@ -470,7 +470,7 @@ def listdir(path):\n def copy(src, dst):\n     if is_remote_path(src) or is_remote_path(dst):\n         if gfile.available:\n-            return gfile.copy(src, dst)\n+            return gfile.copy(src, dst, overwrite=True)\n         else:\n             _raise_if_no_gfile(f\"src={src} dst={dst}\")\n     return shutil.copy(src, dst)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4fabf63d164931471b89f56f3f2d31b097a2a677", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 103 | Lines Deleted: 0 | Files Changed: 6 | Hunks: 9 | Methods Changed: 9 | Complexity Î” (Sum/Max): 12/5 | Churn Î”: 103 | Churn Cumulative: 6543 | Contributors (this commit): 6 | Commits (past 90d): 77 | Contributors (cumulative): 26 | DMM Complexity: 1.0\n\nDIFF:\n@@ -302,6 +302,10 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n     )\n \n \n+def diff(a, n=1, axis=-1):\n+    return jnp.diff(a, n=n, axis=axis)\n+\n+\n def digitize(x, bins):\n     x = convert_to_tensor(x)\n     bins = convert_to_tensor(bins)\n\n@@ -336,6 +336,10 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n     )\n \n \n+def diff(a, n=1, axis=-1):\n+    return np.diff(a, n=n, axis=axis)\n+\n+\n def digitize(x, bins):\n     return np.digitize(x, bins).astype(np.int32)\n \n\n@@ -562,6 +562,10 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n     )\n \n \n+def diff(a, n=1, axis=-1):\n+    return tfnp.diff(a, n=n, axis=axis)\n+\n+\n def digitize(x, bins):\n     bins = list(bins)\n     if isinstance(x, tf.RaggedTensor):\n\n@@ -480,6 +480,11 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n     )\n \n \n+def diff(a, n=1, axis=-1):\n+    a = convert_to_tensor(a)\n+    return torch.diff(a, n=n, dim=axis)\n+\n+\n def digitize(x, bins):\n     x = convert_to_tensor(x)\n     bins = convert_to_tensor(bins)\n\n@@ -140,6 +140,7 @@ zeros_like\n \n \n \"\"\"\n+import builtins\n import re\n \n import numpy as np\n@@ -2019,6 +2020,58 @@ def diagonal(x, offset=0, axis1=0, axis2=1):\n     )\n \n \n+class Diff(Operation):\n+    def __init__(self, n=1, axis=-1):\n+        super().__init__()\n+        self.n = n\n+        self.axis = axis\n+\n+    def call(self, a):\n+        return backend.numpy.diff(a, n=self.n, axis=self.axis)\n+\n+    def compute_output_spec(self, a):\n+        shape = list(a.shape)\n+        size = shape[self.axis]\n+        if size is not None:\n+            shape[self.axis] = builtins.max(size - self.n, 0)\n+        return KerasTensor(shape, dtype=a.dtype)\n+\n+\n+@keras_export([\"keras.ops.diff\", \"keras.ops.numpy.diff\"])\n+def diff(a, n=1, axis=-1):\n+    \"\"\"Calculate the n-th discrete difference along the given axis.\n+\n+    The first difference is given by `out[i] = a[i+1] - a[i]` along\n+    the given axis, higher differences are calculated by using `diff`\n+    recursively.\n+\n+    Args:\n+        a: Input tensor.\n+        n: The number of times values are differenced. Defaults to `1`.\n+        axis: Axis to compute discrete difference(s) along.\n+            Defaults to `-1`.(last axis).\n+\n+    Returns:\n+        Tensor of diagonals.\n+\n+    Examples:\n+    >>> from keras import ops\n+    >>> x = ops.convert_to_tensor([1, 2, 4, 7, 0])\n+    >>> ops.diff(x)\n+    array([ 1,  2,  3, -7])\n+    >>> ops.diff(x, n=2)\n+    array([  1,   1, -10])\n+\n+    >>> x = ops.convert_to_tensor([[1, 3, 6, 10], [0, 5, 6, 8]])\n+    >>> ops.diff(x)\n+    array([[2, 3, 4],\n+           [5, 1, 2]])\n+    >>> ops.diff(x, axis=0)\n+    array([[-1,  2,  0, -2]])\n+    \"\"\"\n+    return Diff(n=n, axis=axis)(a)\n+\n+\n class Digitize(Operation):\n     def call(self, x, bins):\n         return backend.numpy.digitize(x, bins)\n\n@@ -1092,6 +1092,16 @@ class NumpyOneInputOpsDynamicShapeTest(testing.TestCase):\n         x = KerasTensor((None, 3, 3))\n         self.assertEqual(knp.diagonal(x).shape, (3, None))\n \n+    def test_diff(self):\n+        x = KerasTensor((None, 3))\n+        self.assertEqual(knp.diff(x).shape, (None, 2))\n+        self.assertEqual(knp.diff(x, n=2).shape, (None, 1))\n+        self.assertEqual(knp.diff(x, n=3).shape, (None, 0))\n+        self.assertEqual(knp.diff(x, n=4).shape, (None, 0))\n+\n+        self.assertEqual(knp.diff(x, axis=0).shape, (None, 3))\n+        self.assertEqual(knp.diff(x, n=2, axis=0).shape, (None, 3))\n+\n     def test_dot(self):\n         x = KerasTensor((None, 3))\n         y = KerasTensor((3, 2))\n@@ -1610,6 +1620,17 @@ class NumpyOneInputOpsStaticShapeTest(testing.TestCase):\n             x = KerasTensor((3,))\n             knp.diagonal(x)\n \n+    def test_diff(self):\n+        x = KerasTensor((2, 3))\n+        self.assertEqual(knp.diff(x).shape, (2, 2))\n+        self.assertEqual(knp.diff(x, n=2).shape, (2, 1))\n+        self.assertEqual(knp.diff(x, n=3).shape, (2, 0))\n+        self.assertEqual(knp.diff(x, n=4).shape, (2, 0))\n+\n+        self.assertEqual(knp.diff(x, axis=0).shape, (1, 3))\n+        self.assertEqual(knp.diff(x, n=2, axis=0).shape, (0, 3))\n+        self.assertEqual(knp.diff(x, n=3, axis=0).shape, (0, 3))\n+\n     def test_dot(self):\n         x = KerasTensor((2, 3))\n         y = KerasTensor((3, 2))\n@@ -3230,6 +3251,18 @@ class NumpyOneInputOpsCorrectnessTest(testing.TestCase, parameterized.TestCase):\n             np.diagonal(x, offset=-1, axis1=2, axis2=3),\n         )\n \n+    def test_diff(self):\n+        x = np.array([1, 2, 4, 7, 0])\n+        self.assertAllClose(knp.diff(x), np.diff(x))\n+        self.assertAllClose(knp.diff(x, n=2), np.diff(x, n=2))\n+        self.assertAllClose(knp.diff(x, n=3), np.diff(x, n=3))\n+\n+        x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n+        self.assertAllClose(knp.diff(x), np.diff(x))\n+        self.assertAllClose(knp.diff(x, axis=0), np.diff(x, axis=0))\n+        self.assertAllClose(knp.diff(x, n=2, axis=0), np.diff(x, n=2, axis=0))\n+        self.assertAllClose(knp.diff(x, n=2, axis=1), np.diff(x, n=2, axis=1))\n+\n     def test_dot(self):\n         x = np.arange(24).reshape([2, 3, 4]).astype(\"float32\")\n         y = np.arange(12).reshape([4, 3]).astype(\"float32\")\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0d01c882a7ca8fe59011a0ab8ccb087a0bf48493", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 4 | Files Changed: 3 | Hunks: 7 | Methods Changed: 1 | Complexity Î” (Sum/Max): 2/2 | Churn Î”: 10 | Churn Cumulative: 3708 | Contributors (this commit): 19 | Commits (past 90d): 10 | Contributors (cumulative): 23 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: Image Super-Resolution using an Efficient Sub-Pixel CNN\n Author: [Xingyu Long](https://github.com/xingyu-long)\n-Converted to Keras 3 by: [Md Awsfalur Rahman](https://awsaf49.github.io)\n Date created: 2020/07/28\n Last modified: 2020/08/27\n Description: Implementing Super-Resolution using Efficient sub-pixel model on BSDS500.\n Accelerator: GPU\n+Converted to Keras 3 by: [Md Awsfalur Rahman](https://awsaf49.github.io)\n \"\"\"\n \"\"\"\n ## Introduction\n@@ -35,6 +35,7 @@ from keras.utils import img_to_array\n from keras.preprocessing import image_dataset_from_directory\n import tensorflow as tf  #  only for data preprocessing\n \n+import os\n import math\n import numpy as np\n \n@@ -48,8 +49,7 @@ from IPython.display import display\n We use the built-in `keras.utils.get_file` utility to retrieve the dataset.\n \"\"\"\n \n-dataset_url =\n-\"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n+dataset_url = \"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\"\n data_dir = keras.utils.get_file(origin=dataset_url, fname=\"BSR\", untar=True)\n root_dir = os.path.join(data_dir, \"BSDS500/data\")\n \n\n@@ -24,7 +24,7 @@ class GroupNormalization(Layer):\n     Relation to Instance Normalization:\n     If the number of groups is set to the input dimension (number of groups is\n     equal to number of channels), then this operation becomes identical to\n-    Instance Normalization.\n+    Instance Normalization. You can achieve this via `groups=-1`.\n \n     Args:\n         groups: Integer, the number of groups for Group Normalization. Can be in\n\n@@ -697,10 +697,12 @@ def get_training_or_validation_split(samples, labels, validation_split, subset):\n             f\"Using {len(samples) - num_val_samples} \" f\"files for training.\"\n         )\n         samples = samples[:-num_val_samples]\n+        if labels:\n             labels = labels[:-num_val_samples]\n     elif subset == \"validation\":\n         io_utils.print_msg(f\"Using {num_val_samples} files for validation.\")\n         samples = samples[-num_val_samples:]\n+        if labels:\n             labels = labels[-num_val_samples:]\n     else:\n         raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#080bca82c129188fdcc392d1c09abccbc6af55c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 4 | Churn Cumulative: 2741 | Contributors (this commit): 17 | Commits (past 90d): 6 | Contributors (cumulative): 17 | DMM Complexity: None\n\nDIFF:\n@@ -697,12 +697,12 @@ def get_training_or_validation_split(samples, labels, validation_split, subset):\n             f\"Using {len(samples) - num_val_samples} \" f\"files for training.\"\n         )\n         samples = samples[:-num_val_samples]\n-        if labels:\n+        if labels is not None:\n             labels = labels[:-num_val_samples]\n     elif subset == \"validation\":\n         io_utils.print_msg(f\"Using {num_val_samples} files for validation.\")\n         samples = samples[-num_val_samples:]\n-        if labels:\n+        if labels is not None:\n             labels = labels[-num_val_samples:]\n     else:\n         raise ValueError(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4466e8e9c8cfd2db921006bd0f15dc7288841f17", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 311 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: Few-Shot learning with Reptile\n Author: [ADMoreau](https://github.com/ADMoreau)\n-Converted to Keras 3 By: [Muhammad Anas Raza](https://anasrz.com)\n Date created: 2020/05/21\n Last modified: 2023/07/20\n Description: Few-shot classification on the Omniglot dataset using Reptile.\n Accelerator: GPU\n+Converted to Keras 3 By: [Muhammad Anas Raza](https://anasrz.com)\n \"\"\"\n \n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7d2560781e334f198b81748d1de06a296a35d110", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 1 | Churn Cumulative: 571 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -127,7 +127,6 @@ def convert_string_data_to_values(value_string):\n eeg[\"raw_values\"] = eeg[\"raw_values\"].apply(convert_string_data_to_values)\n \n eeg = eeg.loc[eeg[\"signal_quality\"] < QUALITY_THRESHOLD]\n-print(eeg.shape)\n eeg.head()\n \n \"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#aa6e54a1ff44ffe228a4500103e6c0be26a1c2c3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 2 | Churn Cumulative: 529 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -1,11 +1,11 @@\n \"\"\"\n Title: Speaker Recognition\n Author: [Fadi Badine](https://twitter.com/fadibadine)\n-Converted to Keras 3 by: [Fadi Badine](https://twitter.com/fadibadine)\n Date created: 14/06/2020\n Last modified: 19/07/2023\n Description: Classify speakers using Fast Fourier Transform (FFT) and a 1D Convnet.\n Accelerator: GPU\n+Converted to Keras 3 by: [Fadi Badine](https://twitter.com/fadibadine)\n \"\"\"\n \"\"\"\n ## Introduction\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#85be593e9e810497484d8a3ed2250f75257f89ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 36 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Î” (Sum/Max): 2/1 | Churn Î”: 38 | Churn Cumulative: 2636 | Contributors (this commit): 10 | Commits (past 90d): 6 | Contributors (cumulative): 16 | DMM Complexity: 0.6551724137931034\n\nDIFF:\n@@ -252,12 +252,22 @@ def _clone_functional_model(model, input_tensors=None, clone_function=None):\n         )\n \n     if input_tensors is not None:\n-        input_tensors = tree.flatten(input_tensors)\n-        if not all(isinstance(x, backend.KerasTensor) for x in input_tensors):\n+        if not all(\n+            isinstance(x, backend.KerasTensor)\n+            for x in tree.flatten(input_tensors)\n+        ):\n             raise ValueError(\n                 \"All entries in `input_tensors` must be KerasTensors. \"\n                 f\"Received invalid values: inputs_tensors={input_tensors}\"\n             )\n+        try:\n+            tree.assert_same_structure(input_tensors, model.input)\n+        except TypeError as e:\n+            raise ValueError(\n+                \"`input_tensors` must have the same structure as model.input\"\n+                f\"\\nReference structure: {model.input}\"\n+                f\"\\nReceived structure: {input_tensors}\"\n+            ) from e\n     else:\n         input_tensors = tree.map_structure(\n             lambda x: Input(batch_shape=x.shape, dtype=x.dtype, name=x.name),\n\n@@ -1,5 +1,6 @@\n import numpy as np\n import pytest\n+import tree\n from absl.testing import parameterized\n \n from keras import layers\n@@ -97,3 +98,26 @@ class CloneModelTest(testing.TestCase, parameterized.TestCase):\n         model = get_mlp_functional_model(shared_layers=True)\n         new_model = clone_model(model)\n         self.assertLen(new_model.layers, 4)\n+\n+    def test_structured_io_cloning(self):\n+        x = layers.Input((3,))\n+        y = layers.Input((3,))\n+        z1 = x + y\n+        z2 = layers.Dense(5)(z1)\n+        inputs = dict(x=x, y=y)\n+        outputs = dict(z1=z1, z2=z2)\n+        model0 = models.Model(inputs, outputs)\n+\n+        model = clone_model(model0)\n+        tree.assert_same_structure(model.input, inputs)\n+        tree.assert_same_structure(model.output, outputs)\n+\n+        model = clone_model(model0, input_tensors=inputs)\n+        tree.assert_same_structure(model.input, inputs)\n+        tree.assert_same_structure(model.output, outputs)\n+\n+        with self.assertRaisesRegex(\n+            ValueError,\n+            \"`input_tensors` must have the same structure as model.input\",\n+        ):\n+            model = clone_model(model0, input_tensors=(x, y))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c5f166347d654b681e33c2986c3129efdcbb7ae", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Î” (Sum/Max): 0/0 | Churn Î”: 12 | Churn Cumulative: 541 | Contributors (this commit): 3 | Commits (past 90d): 4 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -52,10 +52,16 @@ import keras\n from pathlib import Path\n from IPython.display import display, Audio\n \n-# Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/download\n-# and save it to the 'Downloads' folder in your HOME directory\n+# Get the data from https://www.kaggle.com/kongaevans/speaker-recognition-dataset/\n+# and save it to ~/speaker-recognition-dataset.zip\n+# then unzip it to ~/16000_pcm_speeches\n+\"\"\"shell\n+kaggle datasets download -d kongaevans/speaker-recognition-dataset\n+unzip ~/speaker-recognition-dataset.zip -qq\n+\"\"\"\n+\n DATASET_ROOT = os.path.join(\n-    os.path.expanduser(\"~\"), \"Downloads/16000_pcm_speeches\"\n+    os.path.expanduser(\"~\"), \"16000_pcm_speeches\"\n )\n \n # The folders in which we will put the audio samples and the noise samples\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
