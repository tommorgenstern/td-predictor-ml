{"custom_id": "keras#894501ac460723d1d7dcc1c0168876537f0be452", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 20 | Files Changed: 1 | Hunks: 12 | Methods Changed: 10 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 62 | Churn Cumulative: 7145 | Contributors (this commit): 18 | Commits (past 90d): 15 | Contributors (cumulative): 18 | DMM Complexity: 0.05\n\nDIFF:\n@@ -23,6 +23,7 @@ import collections\n import copy\n import functools\n import itertools\n+import textwrap\n import threading\n import warnings\n import weakref\n@@ -640,8 +641,9 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         # When `getter` is specified, it's possibly fine for `initializer` to be\n         # None since it's up to the custom `getter` to raise error in case it\n         # indeed needs `initializer`.\n-        raise ValueError('An initializer for variable %s of type %s is required'\n-                         ' for layer %s' % (name, dtype.base_dtype, self.name))\n+        raise ValueError(f'An initializer for variable {name} of type '\n+                         f'{dtype.base_dtype} is required for layer '\n+                         f'{self.name}. Received: {initializer}.')\n \n     getter = kwargs.pop('getter', base_layer_utils.make_variable)\n     if (autocast and\n@@ -741,9 +743,26 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     # Check that either the only argument in the `__init__` is  `self`,\n     # or that `get_config` has been overridden:\n     if len(extra_args) > 1 and hasattr(self.get_config, '_is_default'):\n-      raise NotImplementedError(f'Layer {self.__class__.__name__} '\n-                                'has arguments in `__init__)_` and '\n-                                'therefore must override `get_config()`.')\n+      raise NotImplementedError(textwrap.dedent(f\"\"\"\n+          Layer {self.__class__.__name__} has arguments {extra_args}\n+          in `__init__` and therefore must override `get_config()`.\n+\n+          Example:\n+\n+          class CustomLayer(keras.layers.Layer):\n+              def __init__(self, arg1, arg2):\n+                  super().__init__()\n+                  self.arg1 = arg1\n+                  self.arg2 = arg2\n+\n+              def get_config(self):\n+                  config = super().get_config()\n+                  config.update({{\n+                      \"arg1\": self.arg1,\n+                      \"arg2\": self.arg2,\n+                  }})\n+                  return config\"\"\"))\n+\n     return config\n \n   @classmethod\n@@ -834,8 +853,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     \"\"\"\n     def check_type_return_shape(s):\n       if not isinstance(s, tf.TensorSpec):\n-        raise TypeError('Only TensorSpec signature types are supported, '\n-                        'but saw signature entry: {}.'.format(s))\n+        raise TypeError('Only TensorSpec signature types are supported. '\n+                        f'Received: {s}.')\n       return s.shape\n     input_shape = tf.nest.map_structure(check_type_return_shape, input_signature)\n     output_shape = self.compute_output_shape(input_shape)\n@@ -1651,7 +1670,8 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n     kwargs_keys = list(kwargs.keys())\n     if (len(kwargs_keys) > 1 or\n         (len(kwargs_keys) == 1 and kwargs_keys[0] != 'aggregation')):\n-      raise TypeError('Unknown keyword arguments: ', str(kwargs.keys()))\n+      raise TypeError(f'Unknown keyword arguments: {kwargs.keys()}. '\n+                      'Expected `aggregation`.')\n \n     from_metric_obj = hasattr(value, '_metric_obj')\n     is_symbolic = isinstance(value, keras_tensor.KerasTensor)\n@@ -1827,8 +1847,9 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         ref_shape = param.shape\n         if not ref_shape.is_compatible_with(weight_shape):\n           raise ValueError(\n-              'Layer weight shape %s not compatible with provided weight '\n-              'shape %s' % (ref_shape, weight_shape))\n+              f'Layer {self.name} weight shape {ref_shape} '\n+              'is not compatible with provided weight '\n+              f'shape {weight_shape}.')\n         weight_value_tuples.append((param, weight))\n         weight_index += 1\n \n@@ -2144,7 +2165,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         RuntimeError: if called in Eager mode.\n     \"\"\"\n     if not self._inbound_nodes:\n-      raise AttributeError('The layer has never been called '\n+      raise AttributeError(f'The layer \"{self.name}\" has never been called '\n                            'and thus has no defined input shape.')\n     all_input_shapes = set(\n         [str(node.input_shapes) for node in self._inbound_nodes])\n@@ -2174,10 +2195,11 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         with tf_utils.maybe_init_scope(self):\n           self._maybe_build(self.inputs)\n       else:\n-        raise ValueError('You tried to call `count_params` on ' + self.name +\n+        raise ValueError('You tried to call `count_params` '\n+                         f'on layer {self.name}'\n                          ', but the layer isn\\'t built. '\n-                         'You can build it manually via: `' + self.name +\n-                         '.build(batch_input_shape)`.')\n+                         'You can build it manually via: '\n+                         f'`{self.name}.build(batch_input_shape)`.')\n     return layer_utils.count_params(self.weights)\n \n   @property\n@@ -2197,7 +2219,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         RuntimeError: if called in Eager mode.\n     \"\"\"\n     if not self._inbound_nodes:\n-      raise AttributeError('The layer has never been called '\n+      raise AttributeError(f'The layer \"{self.name}\" has never been called '\n                            'and thus has no defined output shape.')\n     all_output_shapes = set(\n         [str(node.output_shapes) for node in self._inbound_nodes])\n@@ -2648,12 +2670,12 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         ValueError: If the index provided does not match any node.\n     \"\"\"\n     if not self._inbound_nodes:\n-      raise RuntimeError('The layer has never been called '\n-                         'and thus has no defined ' + attr_name + '.')\n+      raise RuntimeError(f'The layer {self.name} has never been called '\n+                         'and thus has no defined {attr_name}.')\n     if not len(self._inbound_nodes) > node_index:\n-      raise ValueError('Asked to get ' + attr_name + ' at node ' +\n-                       str(node_index) + ', but the layer has only ' +\n-                       str(len(self._inbound_nodes)) + ' inbound nodes.')\n+      raise ValueError(f'Asked to get {attr_name} at node '\n+                       f'{node_index}, but the layer has only '\n+                       f'{len(self._inbound_nodes)} inbound nodes.')\n     values = getattr(self._inbound_nodes[node_index], attr)\n     if isinstance(values, list) and len(values) == 1:\n       return values[0]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3df49f8ae0ff467ff60c2f5c5b2945d4460e9381", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 234 | Contributors (this commit): 5 | Commits (past 90d): 4 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -153,12 +153,11 @@ class LinearModel(training.Model):\n       different_keys = set(names) - set(inputs.keys())\n       if different_keys:\n         raise ValueError(\n-            'The input dictionary does not match '\n+            'The `inputs` dictionary does not match '\n             'the structure expected by the model.'\n-            '\\n\\tExpected keys: {}'\n-            '\\n\\tReceived keys: {}'\n-            '\\n\\tMissing keys: {}'.format(set(names), set(inputs.keys()),\n-                                          different_keys))\n+            f'\\n\\tExpected keys: {set(names)}'\n+            f'\\n\\tReceived keys: {set(inputs.keys())}'\n+            f'\\n\\tMissing keys: {different_keys}')\n       inputs = [inputs[name] for name in names]\n       for inp, layer in zip(inputs, self.dense_layers):\n         output = layer(inp)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#05048b7c0d56c4c3c90460c31b5fa2406a0ea1e2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 121 | Lines Deleted: 28 | Files Changed: 4 | Hunks: 29 | Methods Changed: 25 | Complexity Δ (Sum/Max): 13/6 | Churn Δ: 149 | Churn Cumulative: 10500 | Contributors (this commit): 7 | Commits (past 90d): 56 | Contributors (cumulative): 20 | DMM Complexity: 0.696969696969697\n\nDIFF:\n@@ -145,9 +145,9 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       padded to `max_tokens` even if the number of unique tokens in the\n       vocabulary is less than max_tokens, resulting in a tensor of shape\n       [batch_size, max_tokens] regardless of vocabulary size. Defaults to False.\n-    sparse: Boolean. Only applicable to `\"multi_hot\"` and `\"count\"` output\n-      modes. If True, returns a `SparseTensor` instead of a dense `Tensor`.\n-      Defaults to False.\n+    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`\n+      and `\"tf-idf\"` output modes. If True, returns a `SparseTensor` instead of\n+      a dense `Tensor`. Defaults to False.\n   \"\"\"\n \n   def __init__(self,\n@@ -164,16 +164,16 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n     # If max_tokens is set, the value must be greater than 1 - otherwise we\n     # are creating a 0-element vocab, which doesn't make sense.\n     if max_tokens is not None and max_tokens <= 1:\n-      raise ValueError(\"If set, `max_tokens` must be greater than 1. \"\n-                       \"You passed `max_tokens={}`\".format(max_tokens))\n+      raise ValueError(f\"If set, `max_tokens` must be greater than 1. \"\n+                       f\"Received: max_tokens={max_tokens}\")\n \n     if pad_to_max_tokens and max_tokens is None:\n-      raise ValueError(\"If pad_to_max_tokens is True, must set `max_tokens`. \"\n-                       \"You passed `max_tokens={}`\".format(max_tokens))\n+      raise ValueError(f\"If pad_to_max_tokens is True, must set `max_tokens`. \"\n+                       f\"Received: max_tokens={max_tokens}\")\n \n     if num_oov_indices < 0:\n-      raise ValueError(\"`num_oov_indices` must be greater than or equal to 0. \"\n-                       \"You passed {}\".format(num_oov_indices))\n+      raise ValueError(f\"`num_oov_indices` must be greater than or equal to 0. \"\n+                       f\"Received: num_oov_indices={num_oov_indices}\")\n \n     # Support deprecated names for output_modes.\n     if output_mode == \"binary\":\n@@ -188,8 +188,14 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n         arg_name=\"output_mode\")\n \n     if invert and output_mode != INT:\n-      raise ValueError(\"`output_mode` must be {} when `invert` is true. You \"\n-                       \"passed {}\".format(INT, output_mode))\n+      raise ValueError(f\"`output_mode` must be `'int'` when `invert` is true. \"\n+                       f\"Received: output_mode={output_mode}\")\n+\n+    if sparse and output_mode == INT:\n+      raise ValueError(f\"`sparse` must not be true if `output_mode` is \"\n+                       f\"`'one_hot'`, `'multi_hot'`, `'count'` or `'tf_idf'`. \"\n+                       f\"Received: sparse={sparse} and \"\n+                       f\"output_mode={output_mode}\")\n \n     self.invert = invert\n     self.max_tokens = max_tokens\n@@ -369,8 +375,9 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       RuntimeError: If a tensor vocabulary is passed outside of eager execution.\n     \"\"\"\n     if self.output_mode != TF_IDF and idf_weights is not None:\n-      raise ValueError(\"`idf_weights` should only be set if output_mode is \"\n-                       \"TF_IDF. output_mode is {}.\".format(self.output_mode))\n+      raise ValueError(f\"`idf_weights` should only be set if output_mode is \"\n+                       f\"`'tf_idf'`. Received: output_mode={self.output_mode} \"\n+                       f\"and idf_weights={idf_weights}\")\n \n     if isinstance(vocabulary, str):\n       if not tf.io.gfile.exists(vocabulary):\n\n@@ -1899,7 +1899,7 @@ class IndexLookupInverseVocabularyTest(\n           invert=True)\n \n   def test_non_int_output_fails(self):\n-    with self.assertRaisesRegex(ValueError, \"`output_mode` must be int\"):\n+    with self.assertRaisesRegex(ValueError, \"`output_mode` must be `'int'`\"):\n       _ = index_lookup.IndexLookup(\n           max_tokens=None,\n           num_oov_indices=1,\n\n@@ -160,6 +160,12 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       tensor containing the string vocbulary terms. If passing a file path, the\n       file should contain one line per term in the vocabulary. If this argument\n       is set, there is no need to `adapt` the layer.\n+    ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns a\n+      `RaggedTensor` instead of a dense `Tensor`, where each sequence may have a\n+      different length after string splitting. Defaults to False.\n+    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n+      `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n+      dense `Tensor`. Defaults to False.\n \n   Example:\n \n@@ -236,6 +242,8 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n                output_sequence_length=None,\n                pad_to_max_tokens=False,\n                vocabulary=None,\n+               sparse=False,\n+               ragged=False,\n                **kwargs):\n \n     # This layer only applies to string processing, and so should only have\n@@ -283,22 +291,32 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n             isinstance(ngrams, int) or\n             isinstance(ngrams, tuple) and\n             all(isinstance(item, int) for item in ngrams)):\n-      raise ValueError((\"`ngrams` must be None, an integer, or a tuple of \"\n-                        \"integers. Got %s\") % (ngrams,))\n+      raise ValueError(f\"`ngrams` must be None, an integer, or a tuple of \"\n+                       f\"integers. Received: ngrams={ngrams}\")\n \n     # 'output_sequence_length' must be one of (None, int) and is only\n     # set if output_mode is INT.\n     if (output_mode == INT and not (isinstance(output_sequence_length, int) or\n                                     (output_sequence_length is None))):\n-      raise ValueError(\"`output_sequence_length` must be either None or an \"\n-                       \"integer when `output_mode` is 'int'. \"\n-                       \"Got %s\" % output_sequence_length)\n+      raise ValueError(f\"`output_sequence_length` must be either None or an \"\n+                       f\"integer when `output_mode` is 'int'. Received: \"\n+                       f\"output_sequence_length={output_sequence_length}\")\n \n     if output_mode != INT and output_sequence_length is not None:\n       raise ValueError(\n           f\"`output_sequence_length` must not be set if `output_mode` is not \"\n           f\"'int'. Received output_sequence_length={output_sequence_length}.\")\n \n+    if ragged and output_mode != INT:\n+      raise ValueError(f\"`ragged` must not be true if `output_mode` is \"\n+                       f\"`'int'`. Received: ragged={ragged} and \"\n+                       f\"output_mode={output_mode}\")\n+\n+    if ragged and output_sequence_length is not None:\n+      raise ValueError(f\"`output_sequence_length` must not be set if ragged \"\n+                       f\"is True. Received: ragged={ragged} and \"\n+                       f\"output_sequence_length={output_sequence_length}\")\n+\n     self._max_tokens = max_tokens\n     self._standardize = standardize\n     self._split = split\n@@ -307,6 +325,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n       self._ngrams = tuple(range(1, ngrams + 1))\n     else:\n       self._ngrams = ngrams\n+    self._ragged = ragged\n \n     self._output_mode = output_mode\n     self._output_sequence_length = output_sequence_length\n@@ -330,6 +349,7 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n         pad_to_max_tokens=pad_to_max_tokens,\n         mask_token=\"\",\n         output_mode=output_mode if output_mode is not None else INT,\n+        sparse=sparse,\n         has_input_vocabulary=self._has_input_vocabulary)\n \n   def compute_output_shape(self, input_shape):\n@@ -387,6 +407,8 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n         \"output_mode\": self._output_mode,\n         \"output_sequence_length\": self._output_sequence_length,\n         \"pad_to_max_tokens\": self._lookup_layer.pad_to_max_tokens,\n+        \"sparse\": self._lookup_layer.sparse,\n+        \"ragged\": self._ragged,\n         \"vocabulary\": utils.listify_tensors(vocab),\n     }\n     base_config = super(TextVectorization, self).get_config()\n@@ -500,6 +522,9 @@ class TextVectorization(base_preprocessing_layer.PreprocessingLayer):\n     if self._output_mode is not INT:\n       return lookup_data\n \n+    if self._ragged:\n+      return lookup_data\n+\n     # If we have a ragged tensor, we can pad during the conversion to dense.\n     if tf_utils.is_ragged(lookup_data):\n       shape = lookup_data.shape.as_list()\n\n@@ -880,6 +880,31 @@ class TextVectorizationOutputTest(\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n+  def test_int_output_ragged(self):\n+    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    # Create an input array that has 5 elements in the first example and 4 in\n+    # the second.\n+    input_array = np.array([[\"earth wind and also fire\"],\n+                            [\"fire and earth michigan\"]])\n+    expected_output = tf.ragged.constant([[2, 3, 4, 1, 5], [5, 4, 2, 1]])\n+    expected_output_shape = [None, None]\n+\n+    # The input shape here is explicitly 1 because we're tokenizing.\n+    input_data = keras.Input(shape=(1,), dtype=tf.string)\n+    layer = text_vectorization.TextVectorization(\n+        max_tokens=None,\n+        standardize=None,\n+        split=text_vectorization.SPLIT_ON_WHITESPACE,\n+        output_mode=text_vectorization.INT,\n+        ragged=True)\n+    layer.set_vocabulary(vocab_data)\n+    int_data = layer(input_data)\n+    self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n+\n+    model = keras.Model(inputs=input_data, outputs=int_data)\n+    output_dataset = model.predict(input_array)\n+    self.assertAllEqual(expected_output, output_dataset)\n+\n   def test_int_output_densifies_with_zeros_and_pads(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     # Create an input array that has 5 elements in the first example and 4 in\n@@ -970,7 +995,11 @@ class TextVectorizationOutputTest(\n     output_dataset = model.predict(input_array_2)\n     self.assertAllEqual(expected_output_2, output_dataset)\n \n-  def test_binary_output_hard_maximum(self):\n+  @parameterized.parameters(\n+      {\"sparse\": True},\n+      {\"sparse\": False},\n+  )\n+  def test_multi_hot_output_hard_maximum(self, sparse):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n@@ -988,16 +1017,26 @@ class TextVectorizationOutputTest(\n         standardize=None,\n         split=None,\n         output_mode=text_vectorization.MULTI_HOT,\n-        pad_to_max_tokens=True)\n+        pad_to_max_tokens=True,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n     model = keras.Model(inputs=input_data, outputs=int_data)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      expected_output = tf.sparse.from_dense(tf.constant(expected_output))\n+      self.assertAllEqual(expected_output.indices, output_dataset.indices)\n+      self.assertAllEqual(expected_output.values, output_dataset.values)\n+    else:\n       self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_binary_output_soft_maximum(self):\n+  @parameterized.parameters(\n+      {\"sparse\": True},\n+      {\"sparse\": False},\n+  )\n+  def test_multi_hot_output_soft_maximum(self, sparse):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n@@ -1015,16 +1054,22 @@ class TextVectorizationOutputTest(\n         standardize=None,\n         split=None,\n         output_mode=text_vectorization.MULTI_HOT,\n-        pad_to_max_tokens=False)\n+        pad_to_max_tokens=False,\n+        sparse=sparse)\n     layer.set_vocabulary(vocab_data)\n     int_data = layer(input_data)\n     self.assertAllEqual(expected_output_shape, int_data.shape.as_list())\n \n     model = keras.Model(inputs=input_data, outputs=int_data)\n     output_dataset = model.predict(input_array)\n+    if sparse:\n+      expected_output = tf.sparse.from_dense(tf.constant(expected_output))\n+      self.assertAllEqual(expected_output.indices, output_dataset.indices)\n+      self.assertAllEqual(expected_output.values, output_dataset.values)\n+    else:\n       self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_bag_output_hard_maximum_set_vocabulary_after_build(self):\n+  def test_multi_hot_output_hard_maximum_set_vocabulary_after_build(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n@@ -1051,7 +1096,7 @@ class TextVectorizationOutputTest(\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_bag_output_hard_maximum_adapt_after_build(self):\n+  def test_multi_hot_output_hard_maximum_adapt_after_build(self):\n     vocab_data = np.array([\n         \"earth\", \"earth\", \"earth\", \"earth\", \"wind\", \"wind\", \"wind\", \"and\",\n         \"and\", \"fire\"\n@@ -1081,7 +1126,7 @@ class TextVectorizationOutputTest(\n     output_dataset = model.predict(input_array)\n     self.assertAllEqual(expected_output, output_dataset)\n \n-  def test_bag_output_hard_maximum_multiple_adapts(self):\n+  def test_multi_hot_output_hard_maximum_multiple_adapts(self):\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n     adapt_data = [\"earth\", \"earth\", \"earth\", \"earth\", \"wind\", \"wind\", \"wind\"]\n@@ -1119,7 +1164,7 @@ class TextVectorizationOutputTest(\n     self.assertAllEqual(first_expected_output, first_output)\n     self.assertAllEqual(second_expected_output, second_output)\n \n-  def test_bag_output_soft_maximum_set_state_after_build(self):\n+  def test_multi_hot_output_soft_maximum_set_state_after_build(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\"],\n                             [\"ohio\", \"and\", \"earth\", \"michigan\"]])\n@@ -1525,12 +1570,28 @@ class TextVectorizationErrorTest(keras_parameterized.TestCase,\n       _ = text_vectorization.TextVectorization(\n           output_mode=\"int\", output_sequence_length=2.0)\n \n-  def test_non_none_output_sequence_length_fails_if_output_type_not_int(self):\n+  def test_non_none_output_sequence_length_fails_if_output_mode_not_int(self):\n     with self.assertRaisesRegex(ValueError,\n                                 \"`output_sequence_length` must not be set\"):\n       _ = text_vectorization.TextVectorization(\n           output_mode=\"count\", output_sequence_length=2)\n \n+  def test_non_none_output_sequence_length_fails_if_ragged_true(self):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"`output_sequence_length` must not be set\"):\n+      _ = text_vectorization.TextVectorization(\n+          ragged=True, output_sequence_length=2)\n+\n+  def test_ragged_true_fails_if_output_mode_not_int(self):\n+    with self.assertRaisesRegex(ValueError, \"`ragged` must not be true if\"):\n+      _ = text_vectorization.TextVectorization(\n+          ragged=True, output_mode=text_vectorization.MULTI_HOT)\n+\n+  def test_sparse_true_fails_if_output_mode_is_int(self):\n+    with self.assertRaisesRegex(ValueError, \"`sparse` must not be true if\"):\n+      _ = text_vectorization.TextVectorization(\n+          sparse=True, output_mode=text_vectorization.INT)\n+\n \n # Custom functions for the custom callable serialization test. Declared here\n # to avoid multiple registrations from run_all_keras_modes().\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0c095d5694f010704bbf780dab618794da94b71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 15813 | Contributors (this commit): 109 | Commits (past 90d): 36 | Contributors (cumulative): 109 | DMM Complexity: None\n\nDIFF:\n@@ -932,7 +932,8 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         epochs: Integer. Number of epochs to train the model.\n             An epoch is an iteration over the entire `x` and `y`\n             data provided \n-            (unless the steps_per_epoch flag is set to something other than None).\n+            (unless the `steps_per_epoch` flag is set to \n+            something other than None).\n             Note that in conjunction with `initial_epoch`,\n             `epochs` is to be understood as \"final epoch\".\n             The model is not trained for a number of iterations\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e77dbe84a0e10b7d8cf0ea03d4c7f9604ee05cf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 19159 | Contributors (this commit): 79 | Commits (past 90d): 19 | Contributors (cumulative): 79 | DMM Complexity: None\n\nDIFF:\n@@ -579,8 +579,8 @@ class Conv2D(Conv):\n       value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n     padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n       `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n-      to the left/right or up/down of the input. When padding=\"same\" and \n-      strides=1, the output has the same size as the input.\n+      to the left/right or up/down of the input. When `padding=\"same\"` and \n+      `strides=1`, the output has the same size as the input.\n     data_format: A string, one of `channels_last` (default) or `channels_first`.\n       The ordering of the dimensions in the inputs. `channels_last` corresponds\n       to inputs with shape `(batch_size, height, width, channels)` while\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c3cea7a7428890d0c25a32f498727d179a135017", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 15818 | Contributors (this commit): 110 | Commits (past 90d): 37 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -437,8 +437,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         inputs: Input tensor, or dict/list/tuple of input tensors.\n         training: Boolean or boolean scalar tensor, indicating whether to run\n           the `Network` in training mode or inference mode.\n-        mask: A mask or list of masks. A mask can be\n-            either a tensor or None (no mask).\n+        mask: A mask or list of masks. A mask can be either a tensor or\n+            None (no mask). For more details, check the guide\n+            [here](https://www.tensorflow.org/guide/keras/masking_and_padding)\n \n     Returns:\n         A tensor if there is a single output, or\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fa332c92bb6957c87eb314df2caa7c7264f5ae13", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 15820 | Contributors (this commit): 110 | Commits (past 90d): 38 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -422,7 +422,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n \n   @doc_controls.doc_in_current_and_subclasses\n   def call(self, inputs, training=None, mask=None):\n-    \"\"\"Calls the model on new inputs.\n+    \"\"\"Calls the model on new inputs and returns the outputs as tensors.\n \n     In this case `call()` just reapplies\n     all ops in the graph to the new inputs\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83ac1ed7f8293c1921996a7ddd61fe7e8e66c5ca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 9 | Files Changed: 2 | Hunks: 5 | Methods Changed: 3 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 16 | Churn Cumulative: 6721 | Contributors (this commit): 5 | Commits (past 90d): 33 | Contributors (cumulative): 9 | DMM Complexity: 0.0\n\nDIFF:\n@@ -721,10 +721,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       initializer = tf.lookup.KeyValueTensorInitializer(keys, values,\n                                                         self._key_dtype,\n                                                         self._value_dtype)\n-      table = tf.lookup.StaticHashTable(initializer, self._default_value)\n-      if not tf.compat.v1.executing_eagerly_outside_functions():\n-        backend.get_session().run(initializer.initialize(table))\n-      return table\n+      return tf.lookup.StaticHashTable(initializer, self._default_value)\n \n   def _lookup_table_from_file(self, filename):\n     if self.invert:\n@@ -741,10 +738,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n           value_dtype=self._value_dtype,\n           value_index=value_index,\n           value_index_offset=self._token_start_index())\n-      table = tf.lookup.StaticHashTable(initializer, self._default_value)\n-      if not tf.compat.v1.executing_eagerly_outside_functions():\n-        backend.get_session().run(initializer.initialize(table))\n-      return table\n+      return tf.lookup.StaticHashTable(initializer, self._default_value)\n \n   def _standardize_inputs(self, inputs, dtype):\n     if isinstance(inputs, (list, tuple, np.ndarray)):\n\n@@ -2381,7 +2381,6 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     self.assertAllEqual(new_output_dataset, expected_output)\n \n \n-@keras_parameterized.run_all_keras_modes(always_skip_eager=True)\n class EagerExecutionDisabled(keras_parameterized.TestCase,\n                              preprocessing_test_utils.PreprocessingLayerTest):\n \n@@ -2389,6 +2388,8 @@ class EagerExecutionDisabled(keras_parameterized.TestCase,\n     # We need this test for model_to_estimator followed by export_saved_model,\n     # which will call the layer in a legacy session. This could also happen\n     # directly if a user calls disable_v2_behavior or disable_eager_execution.\n+    with tf.compat.v1.Session():\n+      with testing_utils.run_eagerly_scope(False):\n         vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n         input_array = np.array([\"earth\", \"wind\", \"and\", \"fire\"])\n         expected_output = [1, 2, 3, 4]\n@@ -2403,6 +2404,9 @@ class EagerExecutionDisabled(keras_parameterized.TestCase,\n             vocabulary=vocab_data)\n         int_data = layer(input_data)\n         model = keras.Model(inputs=input_data, outputs=int_data)\n+        # In a TF1 session the user will need to make sure all tables are\n+        # initialized themselves.\n+        tf.compat.v1.tables_initializer().run()\n         output_dataset = model(input_array)\n         self.assertAllEqual(output_dataset, expected_output)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a59f2f1406fb5544956b132013833aa0bd22c864", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 15824 | Contributors (this commit): 110 | Commits (past 90d): 39 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -437,9 +437,9 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         inputs: Input tensor, or dict/list/tuple of input tensors.\n         training: Boolean or boolean scalar tensor, indicating whether to run\n           the `Network` in training mode or inference mode.\n-        mask: A mask or list of masks. A mask can be either a tensor or\n+        mask: A mask or list of masks. A mask can be either a a boolean tensor or\n             None (no mask). For more details, check the guide\n-            [here](https://www.tensorflow.org/guide/keras/masking_and_padding)\n+            [here](https://www.tensorflow.org/guide/keras/masking_and_padding).\n \n     Returns:\n         A tensor if there is a single output, or\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#df1bf35e9688b9d8245870c49b8caa38d0900aec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 15826 | Contributors (this commit): 110 | Commits (past 90d): 40 | Contributors (cumulative): 110 | DMM Complexity: None\n\nDIFF:\n@@ -437,7 +437,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         inputs: Input tensor, or dict/list/tuple of input tensors.\n         training: Boolean or boolean scalar tensor, indicating whether to run\n           the `Network` in training mode or inference mode.\n-        mask: A mask or list of masks. A mask can be either a a boolean tensor or\n+        mask: A mask or list of masks. A mask can be either a boolean tensor or\n             None (no mask). For more details, check the guide\n             [here](https://www.tensorflow.org/guide/keras/masking_and_padding).\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b9df30b4ef2137ca6c10bddfe32661f21c67fbf8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 7195 | Contributors (this commit): 95 | Commits (past 90d): 9 | Contributors (cumulative): 95 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -1798,6 +1798,7 @@ class EarlyStopping(Callback):\n     self.stopped_epoch = 0\n     self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n     self.best_weights = None\n+    self.best_epoch = 0\n \n   def on_epoch_end(self, epoch, logs=None):\n     current = self.get_monitor_value(logs)\n@@ -1810,6 +1811,7 @@ class EarlyStopping(Callback):\n     self.wait += 1\n     if self._is_improvement(current, self.best):\n       self.best = current\n+      self.best_epoch = epoch\n       if self.restore_best_weights:\n         self.best_weights = self.model.get_weights()\n       # Only restart wait if we beat both the baseline and our previous best.\n@@ -1822,7 +1824,8 @@ class EarlyStopping(Callback):\n       self.model.stop_training = True\n       if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n-          print('Restoring model weights from the end of the best epoch.')\n+          print('Restoring model weights from the end of the best epoch (%s).'\n+                % (self.best_epoch + 1))\n         self.model.set_weights(self.best_weights)\n \n   def on_train_end(self, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#13ebcf4879fce046ab6206076f7329ad2fff5f70", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 50 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 50 | Churn Cumulative: 1762 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,49 @@\n+# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"RaggedKerasTensor tests.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+\n+from absl.testing import parameterized\n+from keras import keras_parameterized\n+from keras import layers\n+from keras.engine import training\n+\n+\n+class SparseKerasTensorTest(keras_parameterized.TestCase):\n+  @parameterized.parameters(\n+      {'property_name': 'values'},\n+      {'property_name': 'indices'},\n+      {'property_name': 'dense_shape'},\n+  )\n+  def test_instance_property(self, property_name):\n+    inp = layers.Input(shape=[3], sparse=True)\n+    out = getattr(inp, property_name)\n+    model = training.Model(inp, out)\n+\n+    x = tf.SparseTensor([[0, 0], [0, 1], [1, 1], [1, 2]], [1, 2, 3, 4], [2, 3])\n+    expected_property = getattr(x, property_name)\n+    self.assertAllEqual(model(x), expected_property)\n+\n+    # Test that it works with serialization and deserialization as well\n+    model_config = model.get_config()\n+    model2 = training.Model.from_config(model_config)\n+    self.assertAllEqual(model2(x), expected_property)\n+\n+\n+if __name__ == '__main__':\n+  tf.compat.v1.enable_eager_execution()\n+  tf.compat.v1.enable_v2_tensorshape()\n+  tf.test.main()\n\n@@ -403,6 +403,7 @@ for ragged_method_name in [\n for sparse_property in [\n     'indices',\n     'values',\n+    'dense_shape',\n ]:\n   _delegate_property(keras_tensor.SparseKerasTensor, sparse_property)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79e9e20d8b95f043cd8a3a240b70928d468a60ac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 686 | Contributors (this commit): 5 | Commits (past 90d): 6 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -240,7 +240,7 @@ class KerasTensor:\n   # with ndarrays.\n   __array_priority__ = 100\n \n-  def __array__(self):\n+  def __array__(self, dtype=None):\n     raise TypeError(\n         'Cannot convert a symbolic Keras input/output to a numpy array. '\n         'This error may indicate that you\\'re trying to pass a symbolic value '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9554eed59cec929c71a0b91dc0f57f5a77824bac", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1013 | Contributors (this commit): 20 | Commits (past 90d): 3 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -162,7 +162,7 @@ def model_to_dot(model,\n     dot.set('dpi', dpi)\n     dot.set_node_defaults(shape='record')\n \n-  if layer_range:\n+  if layer_range is not None:\n     if len(layer_range) != 2:\n       raise ValueError(\n           'layer_range must be of shape (2,). Received: '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d9a5caefbee4635d830f2f4f8325c3843282779c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 7199 | Contributors (this commit): 95 | Commits (past 90d): 10 | Contributors (cumulative): 95 | DMM Complexity: None\n\nDIFF:\n@@ -1824,8 +1824,8 @@ class EarlyStopping(Callback):\n       self.model.stop_training = True\n       if self.restore_best_weights and self.best_weights is not None:\n         if self.verbose > 0:\n-          print('Restoring model weights from the end of the best epoch (%s).' %\n-                (self.best_epoch + 1))\n+          print('Restoring model weights from the end of the best epoch: '\n+                f\"{self.best_epoch + 1}.\")\n         self.model.set_weights(self.best_weights)\n \n   def on_train_end(self, logs=None):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cbe49cfeed63938b0357f692a920c6a03fc11961", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 1523 | Contributors (this commit): 3 | Commits (past 90d): 8 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -652,7 +652,8 @@ class VariableScopeTest(tf.test.TestCase):\n           with tf.compat.v1.variable_scope(\"_\"):\n             pass\n \n-    self.assertRaisesRegex(ValueError, \"'_' is not a valid scope name\", f)\n+    self.assertRaisesRegex(ValueError,\n+                           \"'_' is not a valid (?:root )?scope name\", f)\n \n \n class VariableScopeWithCustomGetterTest(tf.test.TestCase):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6638ce76b1d414b33393f00cdde13b78c3774a43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 15828 | Contributors (this commit): 111 | Commits (past 90d): 41 | Contributors (cumulative): 111 | DMM Complexity: None\n\nDIFF:\n@@ -462,7 +462,7 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n     Example:\n \n     ```python\n-    model.compile(optimizer=tf.keras.optimizer.Adam(learning_rate=1e-3),\n+    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n                   loss=tf.keras.losses.BinaryCrossentropy(),\n                   metrics=[tf.keras.metrics.BinaryAccuracy(),\n                            tf.keras.metrics.FalseNegatives()])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1c106b5113722c0829d57a244add32ca6601cd0a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 19 | Churn Cumulative: 705 | Contributors (this commit): 6 | Commits (past 90d): 7 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -242,14 +242,17 @@ class KerasTensor:\n \n   def __array__(self):\n     raise TypeError(\n-        'Cannot convert a symbolic Keras input/output to a numpy array. '\n-        'This error may indicate that you\\'re trying to pass a symbolic value '\n-        'to a NumPy call, which is not supported. Or, '\n-        'you may be trying to pass Keras symbolic inputs/outputs '\n-        'to a TF API that does not register dispatching, '\n-        'preventing Keras from automatically '\n-        'converting the API call to a lambda layer '\n-        'in the Functional Model.')\n+        f'You are passing {self}, an intermediate Keras symbolic input/output, '\n+        'to a TF API that does not allow registering custom dispatchers, such '\n+        'as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. '\n+        'Keras Functional model construction only supports '\n+        'TF API calls that *do* support dispatching, such as `tf.math.add` or '\n+        '`tf.reshape`. '\n+        'Other APIs cannot be called directly on symbolic Keras'\n+        'inputs/outputs. You can work around '\n+        'this limitation by putting the operation in a custom Keras layer '\n+        '`call` and calling that layer '\n+        'on this symbolic input/output.')\n \n   @property\n   def is_tensor_like(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d3e67af9c958260a1e88f5879cc010542305bc90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1332 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1005,7 +1005,7 @@ class CroppingTest(keras_parameterized.TestCase):\n     with self.cached_session():\n       testing_utils.layer_test(\n           keras.layers.Cropping1D,\n-          kwargs={'cropping': (2, 2)},\n+          kwargs={'cropping': (1, 1)},\n           input_shape=inputs.shape)\n \n     # test incorrect use\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca9d4bad7e0b9db2391bbcc8873feb59435cde9c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 23 | Churn Cumulative: 1036 | Contributors (this commit): 20 | Commits (past 90d): 4 | Contributors (cumulative): 20 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -21,6 +21,7 @@ import tensorflow.compat.v2 as tf\n import os\n import sys\n import re\n+from keras import activations\n from keras.utils.io_utils import path_to_string\n from tensorflow.python.util.tf_export import keras_export\n \n@@ -100,7 +101,8 @@ def model_to_dot(model,\n                  expand_nested=False,\n                  dpi=96,\n                  subgraph=False,\n-                 layer_range=None):\n+                 layer_range=None,\n+                 show_layer_activations=False):\n   \"\"\"Convert a Keras model to dot format.\n \n   Args:\n@@ -240,11 +242,18 @@ def model_to_dot(model,\n       dot.add_subgraph(submodel_not_wrapper)\n \n     # Create node's label.\n-    if show_layer_names:\n-      label = '{}: {}'.format(layer_name, class_name)\n-    else:\n     label = class_name\n     \n+    # Rebuild the label as a table including the layer's activation.\n+    if (\n+        show_layer_activations and hasattr(layer, 'activation')\n+        and layer.activation is not None):\n+      label = '{%s|%s}' % (label, activations.serialize(layer.activation))\n+      \n+    # Rebuild the label as a table including the layer's name.\n+    if show_layer_names:\n+      label = '%s|%s' % (layer_name, label)\n+\n     # Rebuild the label as a table including the layer's dtype.\n     if show_dtype:\n \n@@ -342,7 +351,8 @@ def plot_model(model,\n                rankdir='TB',\n                expand_nested=False,\n                dpi=96,\n-               layer_range=None):\n+               layer_range=None,\n+               show_layer_activations=False):\n   \"\"\"Converts a Keras model to dot format and save to a file.\n \n   Example:\n@@ -395,7 +405,8 @@ def plot_model(model,\n       rankdir=rankdir,\n       expand_nested=expand_nested,\n       dpi=dpi,\n-      layer_range=layer_range)\n+      layer_range=layer_range,\n+      show_layer_activations=show_layer_activations)\n   to_file = path_to_string(to_file)\n   if dot is None:\n     return\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
