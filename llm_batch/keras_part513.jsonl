{"custom_id": "keras#c3dfc347128d8c7baa6a846773d5aebcbee2e325", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3146 | Contributors (this commit): 8 | Commits (past 90d): 3 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -525,10 +525,10 @@ def ConvNeXt(\n         cur += depths[i]\n \n     if include_top:\n+        imagenet_utils.validate_activation(classifier_activation, weights)\n         x = Head(num_classes=classes,\n                  classifier_activation=classifier_activation,\n                  name=model_name)(x)\n-        imagenet_utils.validate_activation(classifier_activation, weights)\n \n     else:\n         if pooling == \"avg\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#71eaa698e8f94cc411e658a7ea6eef43bed73dce", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 10 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): -1/0 | Churn Δ: 13 | Churn Cumulative: 442 | Contributors (this commit): 11 | Commits (past 90d): 2 | Contributors (cumulative): 11 | DMM Complexity: 0.0\n\nDIFF:\n@@ -193,10 +193,9 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n     @parameterized.parameters(MODEL_LIST)\n     def test_application_classifier_activation(self, app):\n-        last_activation = _get_last_layer_activation(\n-            lambda: app(weights=None, include_top=True, classifier_activation=\"softmax\")\n-        )\n-        self.assertEqual(last_activation, \"softmax\")\n+        model = app(weights=None, include_top=True, classifier_activation=\"softmax\")\n+        last_layer_act = model.layers[-1].activation.__name__\n+        self.assertEqual(last_layer_act, \"softmax\")\n \n     @parameterized.parameters(*MODEL_LIST_NO_NASNET)\n     def test_application_variable_input_channels(self, app, last_dim):\n@@ -242,11 +241,5 @@ def _get_output_shape(model_fn):\n     return model.output_shape\n \n \n-def _get_last_layer_activation(model_fn):\n-    model = model_fn()\n-    return model.layers[-1].activation.__name__\n-\n-\n if __name__ == \"__main__\":\n     tf.test.main()\n-    \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d2a6b9e0efdd01dd1bc6cf0bb52336d0009aba6c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 410 | Files Changed: 4 | Hunks: 4 | Methods Changed: 26 | Complexity Δ (Sum/Max): -36/0 | Churn Δ: 410 | Churn Cumulative: 1317 | Contributors (this commit): 6 | Commits (past 90d): 12 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,72 +0,0 @@\n-\"\"\"Test Model.fit with a PyMetric.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-from absl.testing import parameterized\n-\n-from keras import Sequential\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras.testing_infra import test_combinations\n-\n-\n-def get_dataset(num_batches=5, batch_size=2):\n-    x = tf.random.uniform((num_batches * batch_size, 100))\n-    y = tf.random.uniform((num_batches * batch_size, 2))\n-    dataset = (\n-        tf.data.Dataset.from_tensor_slices((x, y))\n-        .prefetch(batch_size * 2)\n-        .batch(batch_size)\n-    )\n-    return dataset\n-\n-\n-class CountingPyMetric(metrics.PyMetric):\n-    \"\"\"A test-only PyMetric which simply counts how many results it's seen.\"\"\"\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.y_pred.append(y_pred)\n-\n-    def reset_state(self):\n-        self.y_pred = []\n-\n-    def result(self):\n-        return len(self.y_pred)\n-\n-\n-class PyMetricTest(test_combinations.TestCase):\n-    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n-    def test_fit(self, run_eagerly):\n-        num_batches = 5\n-        dataset = get_dataset(num_batches=num_batches)\n-\n-        counting_metric = CountingPyMetric()\n-\n-        model = Sequential(layers.Dense(2))\n-        model.compile(\n-            loss=losses.BinaryCrossentropy(),\n-            metrics=[counting_metric],\n-            run_eagerly=run_eagerly,\n-        )\n-        model.fit(dataset, epochs=1)\n-\n-        self.assertEqual(counting_metric.result(), num_batches)\n-\n-    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n-    def test_evaluate(self, run_eagerly):\n-        num_batches = 5\n-        dataset = get_dataset(num_batches=num_batches)\n-\n-        model = Sequential(layers.Dense(2))\n-        model.compile(\n-            loss=losses.BinaryCrossentropy(),\n-            metrics=[CountingPyMetric()],\n-            run_eagerly=run_eagerly,\n-        )\n-        loss, count = model.evaluate(dataset)\n-\n-        self.assertEqual(count, num_batches)\n-\n-\n-if __name__ == \"__main__\":\n-    tf.test.main()\n\n@@ -33,8 +33,6 @@ from keras.saving.legacy import serialization as legacy_serialization\n from keras.saving.legacy.serialization import deserialize_keras_object\n from keras.saving.legacy.serialization import serialize_keras_object\n \n-from keras.metrics.py_metric import PyMetric\n-\n # Individual metric classes\n \n # Accuracy metrics\n\n@@ -1,191 +0,0 @@\n-# Copyright 2023 The Keras Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Base class for Python-based metrics\"\"\"\n-\n-import types\n-\n-import tensorflow.compat.v2 as tf\n-from tensorflow.python.util.tf_export import keras_export\n-\n-from keras.metrics import base_metric\n-\n-\n-@keras_export(\"keras.metrics.experimental.PyMetric\", v1=[])\n-class PyMetric(base_metric.Metric):\n-    \"\"\"Metric which runs in Python, compiled outside of the TensorFlow graph.\n-\n-    Args:\n-      name: (Optional) string name of the PyMetric instance.\n-      dtype: (Optional) data type of the PyMetric result.\n-      **kwargs: Additional layer keywords arguments.\n-\n-    Usage of `PyMetric` is generally identical to `keras.metrics.Metric`.\n-    It can be used in isolation, or in tandem with the `compile()` API. For more\n-    information about the usage of `PyMetric`, see `keras.metrics.Metric`.\n-\n-    Unlike regular metrics, `PyMetric` instances are outside-compiled\n-    with respect to the TensorFlow graph during training or evaluation.\n-    They have access to the same\n-    inputs of a standard in-graph metric, but they run in a Python interpreter\n-    on the host CPU. Any data stored in a `PyMetric` is located on the main\n-    memory of the host CPU, and any TensorFlow ops used in a PyMetric are\n-    run eagerly on the host CPU.\n-\n-    As a result, `PyMetric` instances are generally not as performant\n-    as in-graph metrics, and should only be used in cases where computing\n-    the metric inside of the TensorFlow graph is either impossible\n-    or prohibitively expensive.\n-\n-    **Note:** Due to the use of `tf.py_function`, PyMetrics\n-    are incompatible with XLA and therefore TPUs.\n-\n-    Methods to be implemented by subclasses:\n-\n-    * `update_state()`: Handles updates to internal state variables\n-    * `result()`: Computes and returns a scalar value or a dict of scalar values\n-      for the metric from the state variables.\n-    * `reset_state()`: Computes and returns a scalar value for the metric from\n-      the state variables.\n-\n-    This subclass implementation is similar to that of `keras.metrics.Metric`,\n-    with two notable differences:\n-\n-    * Inputs to `update_state()` in a `PyMetric` are eager tensors, and both\n-    `update_state()` and `result()` run outside of the TensorFlow graph,\n-    executing any TensorFlow ops eagerly.\n-    * `reset_state()` is also called at initialization time to initialize the\n-    Python state of the metric.\n-    * `result()` can only return a single scalar. It does not support returning\n-    a dictionary of results like `keras.metrics.Metric`.\n-\n-    Example subclass implementation using sklearn's Jaccard Score:\n-\n-    ```python\n-    from sklearn.metrics import jaccard_score\n-    import tensorflow as tf\n-\n-    class JaccardScore(tf.keras.metrics.experimental.PyMetric):\n-\n-      def __init__(self, name='jaccard_score', **kwargs):\n-        super().__init__(name=name, **kwargs)\n-\n-      def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.jaccard_sum += jaccard_score(y_pred, y_true, average=\"macro\")\n-        self.count += 1\n-\n-      def reset_state(self):\n-        self.jaccard_sum = 0.\n-        self.count = 0.\n-\n-      def result(self):\n-        return self.jaccard_sum / self.count\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name=None, dtype=None, **kwargs):\n-        super().__init__(name=name, dtype=dtype, **kwargs)\n-        self.reset_state()\n-\n-    def __new__(cls, *args, **kwargs):\n-        obj = super(base_metric.Metric, cls).__new__(cls)\n-\n-        # Wrap the update_state function in a py_function and scope it to /cpu:0\n-        obj_update_state = obj.update_state\n-\n-        def update_state_on_cpu(y_true, y_pred, sample_weight=None):\n-            with tf.device(\"/cpu:0\"):\n-                return obj_update_state(y_true, y_pred, sample_weight)\n-\n-        obj.update_state_on_cpu = update_state_on_cpu\n-\n-        def update_state_fn(self, y_true, y_pred, sample_weight=None):\n-            eager_inputs = [y_true, y_pred]\n-            if sample_weight is not None:\n-                eager_inputs.append(sample_weight)\n-            return tf.py_function(\n-                func=self.update_state_on_cpu, inp=eager_inputs, Tout=[]\n-            )\n-\n-        obj.update_state = types.MethodType(update_state_fn, obj)\n-\n-        # Wrap the result function in a py_function and scope it to /cpu:0\n-        obj_result = obj.result\n-\n-        def result_on_host_cpu():\n-            with tf.device(\"/cpu:0\"):\n-                return obj_result()\n-\n-        obj.result_on_host_cpu = result_on_host_cpu\n-\n-        def result_fn(self):\n-            return tf.py_function(\n-                self.result_on_host_cpu, inp=[], Tout=obj.dtype\n-            )\n-\n-        obj.result = types.MethodType(result_fn, obj)\n-\n-        return obj\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates statistics for the metric.\n-\n-        **Note:** This function is executed outside of the TensorFlow graph\n-        on the CPU host.\n-\n-        This means:\n-\n-        a) Inputs are eager tensors.\n-        b) Any TensorFlow ops run in this method are run eagerly.\n-        c) Any Tensors created are allocated to the CPU's main memory.\n-\n-        Args:\n-          y_true: Target output\n-          y_pred: Predicted output\n-          sample_weight: (Optional) weights for the individual samples in\n-            `y_true` and `y_pred`\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `update_state`\")\n-\n-    def merge_state(self, metrics):\n-        \"\"\"Merges the state from one or more metrics.\n-\n-        `PyMetric` instances that intend to support merging state must override\n-         this method, as the default implementation\n-        in `keras.metrics.Metric` does not apply to `PyMetric`.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `merge_state`\")\n-\n-    def reset_state(self):\n-        \"\"\"Resets all of the metric state variables.\n-\n-        This function is called between epochs when a metric is evaluated during\n-        training. It's also called when the metric is initialized.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `reset_state`\")\n-\n-    def result(self):\n-        \"\"\"Computes and returns the scalar metric value.\n-\n-        **Note:** This function is executed outside of the TensorFlow graph\n-         on the CPU host. This means any TensorFlow ops run in this method\n-         are run eagerly.\n-\n-        Result computation is an idempotent operation that simply calculates the\n-        metric value using the state variables.\n-\n-        Returns:\n-            A Python scalar.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `result`\")\n\n@@ -1,145 +0,0 @@\n-# Copyright 2023 The Keras Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Tests for Keras PyMetric classes.\"\"\"\n-\n-\n-import tensorflow.compat.v2 as tf\n-\n-from keras import metrics\n-from keras.testing_infra import test_combinations\n-\n-\n-class KTrimmedMean(metrics.PyMetric):\n-    \"\"\"An example PyMetric which computes the trimmed mean of `y_pred`.\"\"\"\n-\n-    def __init__(self, k=0.1, name=\"k_trimmed_mean\", **kwargs):\n-        super().__init__(name=name, **kwargs)\n-        self.k = k\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        y_true = y_true.numpy()\n-\n-        if sample_weight is not None:\n-            y_true *= sample_weight.numpy()\n-\n-        # Insert y_pred into our values list (keeping the list sorted)\n-        index = 0\n-        for i, element in enumerate(self.values):\n-            if y_true > element:\n-                index = i\n-                break\n-        self.values = self.values[:index] + [y_true] + self.values[index:]\n-\n-    def reset_state(self):\n-        self.values = []\n-\n-    def result(self):\n-        k = int(self.k * len(self.values))\n-        return tf.reduce_mean(self.values[k:-k])\n-\n-    def get_config(self):\n-        config = super().get_config()\n-        config.update({\"k\": self.k})\n-        return config\n-\n-\n-class Mean(metrics.PyMetric):\n-    \"\"\"An example PyMetric which computes the mean of `y_pred`.\"\"\"\n-\n-    def __init__(self, name=\"mean\", **kwargs):\n-        super().__init__(name=name, **kwargs)\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.values.append(y_true)\n-\n-    def reset_state(self):\n-        self.values = []\n-\n-    def result(self):\n-        return tf.reduce_mean(tf.concat(self.values, axis=0))\n-\n-\n-@test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n-class PyMetricsTest(tf.test.TestCase):\n-    def test_config(self):\n-        ktm_object = KTrimmedMean(name=\"ktm\", k=0.2, dtype=tf.float16)\n-        self.assertEqual(ktm_object.name, \"ktm\")\n-        self.assertEqual(ktm_object.k, 0.2)\n-        self.assertEqual(ktm_object.dtype, tf.float16)\n-\n-        # Check save and restore config\n-        ktm_object2 = KTrimmedMean.from_config(ktm_object.get_config())\n-        self.assertEqual(ktm_object2.name, \"ktm\")\n-        self.assertEqual(ktm_object.k, 0.2)\n-        self.assertEqual(ktm_object2.dtype, tf.float16)\n-\n-    def test_unweighted(self):\n-        ktm_object = KTrimmedMean(k=0.2)\n-\n-        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n-            self.evaluate(\n-                ktm_object.update_state(\n-                    tf.constant(y_true, dtype=tf.float32),\n-                    y_pred=tf.constant(0, dtype=tf.float32),\n-                )\n-            )\n-\n-        result = ktm_object.result()\n-        self.assertEqual(3.5, self.evaluate(result))\n-\n-    def test_weighted(self):\n-        ktm_object = KTrimmedMean(k=0.2)\n-\n-        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n-            self.evaluate(\n-                ktm_object.update_state(\n-                    tf.constant(y_true, dtype=tf.float32),\n-                    y_pred=tf.constant(0, dtype=tf.float32),\n-                    sample_weight=tf.constant(2, dtype=tf.float32),\n-                )\n-            )\n-\n-        result = ktm_object.result()\n-        self.assertEqual(7, self.evaluate(result))\n-\n-    def test_state_stored_on_cpu_host(self):\n-        with tf.device(\"/device:GPU:0\"):\n-            mean_obj = Mean()\n-\n-            y_true_0 = tf.constant([0, 1, 2], dtype=tf.float32)\n-            y_true_1 = tf.constant([3, 4], dtype=tf.float32)\n-            self.evaluate(\n-                mean_obj.update_state(\n-                    y_true=y_true_0, y_pred=tf.constant(0, dtype=tf.float32)\n-                )\n-            )\n-            self.evaluate(\n-                mean_obj.update_state(\n-                    y_true=y_true_1, y_pred=tf.constant(0, dtype=tf.float32)\n-                )\n-            )\n-\n-        self.assertEqual(2, self.evaluate(mean_obj.result()))\n-\n-        if not tf.executing_eagerly():\n-            self.assertEndsWith(y_true_0.device, \"/device:GPU:0\")\n-            self.assertEndsWith(y_true_1.device, \"/device:GPU:0\")\n-\n-        self.assertEndsWith(mean_obj.values[0].device, \"/device:CPU:0\")\n-        self.assertEndsWith(mean_obj.values[1].device, \"/device:CPU:0\")\n-\n-\n-if __name__ == \"__main__\":\n-    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ebd6940d446672781679aea786ffa59aeba91a20", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 11 | Lines Deleted: 5 | Files Changed: 2 | Hunks: 5 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 3604 | Contributors (this commit): 15 | Commits (past 90d): 7 | Contributors (cumulative): 21 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -193,7 +193,9 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n     @parameterized.parameters(MODEL_LIST)\n     def test_application_classifier_activation(self, app):\n-        model = app(weights=None, include_top=True, classifier_activation=\"softmax\")\n+        model = app(\n+            weights=None, include_top=True, classifier_activation=\"softmax\"\n+        )\n         last_layer_act = model.layers[-1].activation.__name__\n         self.assertEqual(last_layer_act, \"softmax\")\n \n\n@@ -343,9 +343,11 @@ def Head(num_classes=1000, classifier_activation=None, name=None):\n         x = layers.LayerNormalization(\n             epsilon=1e-6, name=name + \"_head_layernorm\"\n         )(x)\n-        x = layers.Dense(num_classes,\n+        x = layers.Dense(\n+            num_classes,\n             activation=classifier_activation,\n-                         name=name + \"_head_dense\")(x)\n+            name=name + \"_head_dense\",\n+        )(x)\n         return x\n \n     return apply\n@@ -526,9 +528,11 @@ def ConvNeXt(\n \n     if include_top:\n         imagenet_utils.validate_activation(classifier_activation, weights)\n-        x = Head(num_classes=classes,\n+        x = Head(\n+            num_classes=classes,\n             classifier_activation=classifier_activation,\n-                 name=model_name)(x)\n+            name=model_name,\n+        )(x)\n \n     else:\n         if pooling == \"avg\":\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2dfadaf68aa9ea697cfcbda7394c349bbd25d397", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1162 | Contributors (this commit): 13 | Commits (past 90d): 2 | Contributors (cumulative): 13 | DMM Complexity: None\n\nDIFF:\n@@ -35,7 +35,7 @@ class StringLookup(index_lookup.IndexLookup):\n     This layer translates a set of arbitrary strings into integer output via a\n     table-based vocabulary lookup. This layer will perform no splitting or\n     transformation of input strings. For a layer than can split and tokenize\n-    natural language, see the [TextVectorization](https://keras.io/api/layers/preprocessing_layers/text/text_vectorization/#textvectorization-class) layer.\n+    natural language, see the `tf.keras.layers.TextVectorization` layer.\n \n     The vocabulary for the layer must be either supplied on construction or\n     learned via `adapt()`. During `adapt()`, the layer will analyze a data set,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c6a0a2a96e255794dab9d403152b91b6bc7d64e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 3 | Churn Cumulative: 3161 | Contributors (this commit): 10 | Commits (past 90d): 5 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -218,7 +218,8 @@ class LayerScale(layers.Layer):\n \n     def build(self, input_shape):\n         self.gamma = tf.Variable(\n-            self.init_values * tf.ones((self.projection_dim,))\n+            self.init_values * tf.ones((self.projection_dim,)),\n+            dtype=self._compute_dtype_object\n         )\n \n     def call(self, x):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f294f5e0cf70573d599209a9d22cae2db3941f5e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 410 | Lines Deleted: 0 | Files Changed: 4 | Hunks: 4 | Methods Changed: 26 | Complexity Δ (Sum/Max): 36/19 | Churn Δ: 410 | Churn Cumulative: 1727 | Contributors (this commit): 6 | Commits (past 90d): 16 | Contributors (cumulative): 12 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,72 @@\n+\"\"\"Test Model.fit with a PyMetric.\"\"\"\n+\n+import tensorflow.compat.v2 as tf\n+from absl.testing import parameterized\n+\n+from keras import Sequential\n+from keras import layers\n+from keras import losses\n+from keras import metrics\n+from keras.testing_infra import test_combinations\n+\n+\n+def get_dataset(num_batches=5, batch_size=2):\n+    x = tf.random.uniform((num_batches * batch_size, 100))\n+    y = tf.random.uniform((num_batches * batch_size, 2))\n+    dataset = (\n+        tf.data.Dataset.from_tensor_slices((x, y))\n+        .prefetch(batch_size * 2)\n+        .batch(batch_size)\n+    )\n+    return dataset\n+\n+\n+class CountingPyMetric(metrics.PyMetric):\n+    \"\"\"A test-only PyMetric which simply counts how many results it's seen.\"\"\"\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.y_pred.append(y_pred)\n+\n+    def reset_state(self):\n+        self.y_pred = []\n+\n+    def result(self):\n+        return len(self.y_pred)\n+\n+\n+class PyMetricTest(test_combinations.TestCase):\n+    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n+    def test_fit(self, run_eagerly):\n+        num_batches = 5\n+        dataset = get_dataset(num_batches=num_batches)\n+\n+        counting_metric = CountingPyMetric()\n+\n+        model = Sequential(layers.Dense(2))\n+        model.compile(\n+            loss=losses.BinaryCrossentropy(),\n+            metrics=[counting_metric],\n+            run_eagerly=run_eagerly,\n+        )\n+        model.fit(dataset, epochs=1)\n+\n+        self.assertEqual(counting_metric.result(), num_batches)\n+\n+    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n+    def test_evaluate(self, run_eagerly):\n+        num_batches = 5\n+        dataset = get_dataset(num_batches=num_batches)\n+\n+        model = Sequential(layers.Dense(2))\n+        model.compile(\n+            loss=losses.BinaryCrossentropy(),\n+            metrics=[CountingPyMetric()],\n+            run_eagerly=run_eagerly,\n+        )\n+        loss, count = model.evaluate(dataset)\n+\n+        self.assertEqual(count, num_batches)\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n@@ -33,6 +33,8 @@ from keras.saving.legacy import serialization as legacy_serialization\n from keras.saving.legacy.serialization import deserialize_keras_object\n from keras.saving.legacy.serialization import serialize_keras_object\n \n+from keras.metrics.py_metric import PyMetric\n+\n # Individual metric classes\n \n # Accuracy metrics\n\n@@ -0,0 +1,191 @@\n+# Copyright 2023 The Keras Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Base class for Python-based metrics\"\"\"\n+\n+import types\n+\n+import tensorflow.compat.v2 as tf\n+from tensorflow.python.util.tf_export import keras_export\n+\n+from keras.metrics import base_metric\n+\n+\n+@keras_export(\"keras.metrics.experimental.PyMetric\", v1=[])\n+class PyMetric(base_metric.Metric):\n+    \"\"\"Metric which runs in Python, compiled outside of the TensorFlow graph.\n+\n+    Args:\n+      name: (Optional) string name of the PyMetric instance.\n+      dtype: (Optional) data type of the PyMetric result.\n+      **kwargs: Additional layer keywords arguments.\n+\n+    Usage of `PyMetric` is generally identical to `keras.metrics.Metric`.\n+    It can be used in isolation, or in tandem with the `compile()` API. For more\n+    information about the usage of `PyMetric`, see `keras.metrics.Metric`.\n+\n+    Unlike regular metrics, `PyMetric` instances are outside-compiled\n+    with respect to the TensorFlow graph during training or evaluation.\n+    They have access to the same\n+    inputs of a standard in-graph metric, but they run in a Python interpreter\n+    on the host CPU. Any data stored in a `PyMetric` is located on the main\n+    memory of the host CPU, and any TensorFlow ops used in a PyMetric are\n+    run eagerly on the host CPU.\n+\n+    As a result, `PyMetric` instances are generally not as performant\n+    as in-graph metrics, and should only be used in cases where computing\n+    the metric inside of the TensorFlow graph is either impossible\n+    or prohibitively expensive.\n+\n+    **Note:** Due to the use of `tf.py_function`, PyMetrics\n+    are incompatible with XLA and therefore TPUs.\n+\n+    Methods to be implemented by subclasses:\n+\n+    * `update_state()`: Handles updates to internal state variables\n+    * `result()`: Computes and returns a scalar value or a dict of scalar values\n+      for the metric from the state variables.\n+    * `reset_state()`: Computes and returns a scalar value for the metric from\n+      the state variables.\n+\n+    This subclass implementation is similar to that of `keras.metrics.Metric`,\n+    with two notable differences:\n+\n+    * Inputs to `update_state()` in a `PyMetric` are eager tensors, and both\n+    `update_state()` and `result()` run outside of the TensorFlow graph,\n+    executing any TensorFlow ops eagerly.\n+    * `reset_state()` is also called at initialization time to initialize the\n+    Python state of the metric.\n+    * `result()` can only return a single scalar. It does not support returning\n+    a dictionary of results like `keras.metrics.Metric`.\n+\n+    Example subclass implementation using sklearn's Jaccard Score:\n+\n+    ```python\n+    from sklearn.metrics import jaccard_score\n+    import tensorflow as tf\n+\n+    class JaccardScore(tf.keras.metrics.experimental.PyMetric):\n+\n+      def __init__(self, name='jaccard_score', **kwargs):\n+        super().__init__(name=name, **kwargs)\n+\n+      def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.jaccard_sum += jaccard_score(y_pred, y_true, average=\"macro\")\n+        self.count += 1\n+\n+      def reset_state(self):\n+        self.jaccard_sum = 0.\n+        self.count = 0.\n+\n+      def result(self):\n+        return self.jaccard_sum / self.count\n+    ```\n+    \"\"\"\n+\n+    def __init__(self, name=None, dtype=None, **kwargs):\n+        super().__init__(name=name, dtype=dtype, **kwargs)\n+        self.reset_state()\n+\n+    def __new__(cls, *args, **kwargs):\n+        obj = super(base_metric.Metric, cls).__new__(cls)\n+\n+        # Wrap the update_state function in a py_function and scope it to /cpu:0\n+        obj_update_state = obj.update_state\n+\n+        def update_state_on_cpu(y_true, y_pred, sample_weight=None):\n+            with tf.device(\"/cpu:0\"):\n+                return obj_update_state(y_true, y_pred, sample_weight)\n+\n+        obj.update_state_on_cpu = update_state_on_cpu\n+\n+        def update_state_fn(self, y_true, y_pred, sample_weight=None):\n+            eager_inputs = [y_true, y_pred]\n+            if sample_weight is not None:\n+                eager_inputs.append(sample_weight)\n+            return tf.py_function(\n+                func=self.update_state_on_cpu, inp=eager_inputs, Tout=[]\n+            )\n+\n+        obj.update_state = types.MethodType(update_state_fn, obj)\n+\n+        # Wrap the result function in a py_function and scope it to /cpu:0\n+        obj_result = obj.result\n+\n+        def result_on_host_cpu():\n+            with tf.device(\"/cpu:0\"):\n+                return obj_result()\n+\n+        obj.result_on_host_cpu = result_on_host_cpu\n+\n+        def result_fn(self):\n+            return tf.py_function(\n+                self.result_on_host_cpu, inp=[], Tout=obj.dtype\n+            )\n+\n+        obj.result = types.MethodType(result_fn, obj)\n+\n+        return obj\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        \"\"\"Accumulates statistics for the metric.\n+\n+        **Note:** This function is executed outside of the TensorFlow graph\n+        on the CPU host.\n+\n+        This means:\n+\n+        a) Inputs are eager tensors.\n+        b) Any TensorFlow ops run in this method are run eagerly.\n+        c) Any Tensors created are allocated to the CPU's main memory.\n+\n+        Args:\n+          y_true: Target output\n+          y_pred: Predicted output\n+          sample_weight: (Optional) weights for the individual samples in\n+            `y_true` and `y_pred`\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `update_state`\")\n+\n+    def merge_state(self, metrics):\n+        \"\"\"Merges the state from one or more metrics.\n+\n+        `PyMetric` instances that intend to support merging state must override\n+         this method, as the default implementation\n+        in `keras.metrics.Metric` does not apply to `PyMetric`.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `merge_state`\")\n+\n+    def reset_state(self):\n+        \"\"\"Resets all of the metric state variables.\n+\n+        This function is called between epochs when a metric is evaluated during\n+        training. It's also called when the metric is initialized.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `reset_state`\")\n+\n+    def result(self):\n+        \"\"\"Computes and returns the scalar metric value.\n+\n+        **Note:** This function is executed outside of the TensorFlow graph\n+         on the CPU host. This means any TensorFlow ops run in this method\n+         are run eagerly.\n+\n+        Result computation is an idempotent operation that simply calculates the\n+        metric value using the state variables.\n+\n+        Returns:\n+            A Python scalar.\n+        \"\"\"\n+        raise NotImplementedError(\"Subclasses should implement `result`\")\n\n@@ -0,0 +1,145 @@\n+# Copyright 2023 The Keras Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Tests for Keras PyMetric classes.\"\"\"\n+\n+\n+import tensorflow.compat.v2 as tf\n+\n+from keras import metrics\n+from keras.testing_infra import test_combinations\n+\n+\n+class KTrimmedMean(metrics.PyMetric):\n+    \"\"\"An example PyMetric which computes the trimmed mean of `y_pred`.\"\"\"\n+\n+    def __init__(self, k=0.1, name=\"k_trimmed_mean\", **kwargs):\n+        super().__init__(name=name, **kwargs)\n+        self.k = k\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        y_true = y_true.numpy()\n+\n+        if sample_weight is not None:\n+            y_true *= sample_weight.numpy()\n+\n+        # Insert y_pred into our values list (keeping the list sorted)\n+        index = 0\n+        for i, element in enumerate(self.values):\n+            if y_true > element:\n+                index = i\n+                break\n+        self.values = self.values[:index] + [y_true] + self.values[index:]\n+\n+    def reset_state(self):\n+        self.values = []\n+\n+    def result(self):\n+        k = int(self.k * len(self.values))\n+        return tf.reduce_mean(self.values[k:-k])\n+\n+    def get_config(self):\n+        config = super().get_config()\n+        config.update({\"k\": self.k})\n+        return config\n+\n+\n+class Mean(metrics.PyMetric):\n+    \"\"\"An example PyMetric which computes the mean of `y_pred`.\"\"\"\n+\n+    def __init__(self, name=\"mean\", **kwargs):\n+        super().__init__(name=name, **kwargs)\n+\n+    def update_state(self, y_true, y_pred, sample_weight=None):\n+        self.values.append(y_true)\n+\n+    def reset_state(self):\n+        self.values = []\n+\n+    def result(self):\n+        return tf.reduce_mean(tf.concat(self.values, axis=0))\n+\n+\n+@test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n+class PyMetricsTest(tf.test.TestCase):\n+    def test_config(self):\n+        ktm_object = KTrimmedMean(name=\"ktm\", k=0.2, dtype=tf.float16)\n+        self.assertEqual(ktm_object.name, \"ktm\")\n+        self.assertEqual(ktm_object.k, 0.2)\n+        self.assertEqual(ktm_object.dtype, tf.float16)\n+\n+        # Check save and restore config\n+        ktm_object2 = KTrimmedMean.from_config(ktm_object.get_config())\n+        self.assertEqual(ktm_object2.name, \"ktm\")\n+        self.assertEqual(ktm_object.k, 0.2)\n+        self.assertEqual(ktm_object2.dtype, tf.float16)\n+\n+    def test_unweighted(self):\n+        ktm_object = KTrimmedMean(k=0.2)\n+\n+        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n+            self.evaluate(\n+                ktm_object.update_state(\n+                    tf.constant(y_true, dtype=tf.float32),\n+                    y_pred=tf.constant(0, dtype=tf.float32),\n+                )\n+            )\n+\n+        result = ktm_object.result()\n+        self.assertEqual(3.5, self.evaluate(result))\n+\n+    def test_weighted(self):\n+        ktm_object = KTrimmedMean(k=0.2)\n+\n+        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n+            self.evaluate(\n+                ktm_object.update_state(\n+                    tf.constant(y_true, dtype=tf.float32),\n+                    y_pred=tf.constant(0, dtype=tf.float32),\n+                    sample_weight=tf.constant(2, dtype=tf.float32),\n+                )\n+            )\n+\n+        result = ktm_object.result()\n+        self.assertEqual(7, self.evaluate(result))\n+\n+    def test_state_stored_on_cpu_host(self):\n+        with tf.device(\"/device:GPU:0\"):\n+            mean_obj = Mean()\n+\n+            y_true_0 = tf.constant([0, 1, 2], dtype=tf.float32)\n+            y_true_1 = tf.constant([3, 4], dtype=tf.float32)\n+            self.evaluate(\n+                mean_obj.update_state(\n+                    y_true=y_true_0, y_pred=tf.constant(0, dtype=tf.float32)\n+                )\n+            )\n+            self.evaluate(\n+                mean_obj.update_state(\n+                    y_true=y_true_1, y_pred=tf.constant(0, dtype=tf.float32)\n+                )\n+            )\n+\n+        self.assertEqual(2, self.evaluate(mean_obj.result()))\n+\n+        if not tf.executing_eagerly():\n+            self.assertEndsWith(y_true_0.device, \"/device:GPU:0\")\n+            self.assertEndsWith(y_true_1.device, \"/device:GPU:0\")\n+\n+        self.assertEndsWith(mean_obj.values[0].device, \"/device:CPU:0\")\n+        self.assertEndsWith(mean_obj.values[1].device, \"/device:CPU:0\")\n+\n+\n+if __name__ == \"__main__\":\n+    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0dbf691632d390af683b94f7e2bb9483741b997a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 109 | Contributors (this commit): 4 | Commits (past 90d): 9 | Contributors (cumulative): 4 | DMM Complexity: 0.0\n\nDIFF:\n@@ -636,7 +636,9 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n                 # issues.\n                 self.build(trainable_variables)\n             grads_and_vars = list(zip(grads, trainable_variables))\n-        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n+            grads_and_vars = optimizer_utils.filter_empty_gradients(\n+                grads_and_vars\n+            )\n             if len(list(grads_and_vars)) == 0:\n                 # Check again after filtering gradients.\n                 return self._iterations\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#919418de5db9f9cb3a797a242da61319ed7e47d2", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 410 | Files Changed: 4 | Hunks: 4 | Methods Changed: 26 | Complexity Δ (Sum/Max): -36/0 | Churn Δ: 410 | Churn Cumulative: 2137 | Contributors (this commit): 6 | Commits (past 90d): 20 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1,72 +0,0 @@\n-\"\"\"Test Model.fit with a PyMetric.\"\"\"\n-\n-import tensorflow.compat.v2 as tf\n-from absl.testing import parameterized\n-\n-from keras import Sequential\n-from keras import layers\n-from keras import losses\n-from keras import metrics\n-from keras.testing_infra import test_combinations\n-\n-\n-def get_dataset(num_batches=5, batch_size=2):\n-    x = tf.random.uniform((num_batches * batch_size, 100))\n-    y = tf.random.uniform((num_batches * batch_size, 2))\n-    dataset = (\n-        tf.data.Dataset.from_tensor_slices((x, y))\n-        .prefetch(batch_size * 2)\n-        .batch(batch_size)\n-    )\n-    return dataset\n-\n-\n-class CountingPyMetric(metrics.PyMetric):\n-    \"\"\"A test-only PyMetric which simply counts how many results it's seen.\"\"\"\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.y_pred.append(y_pred)\n-\n-    def reset_state(self):\n-        self.y_pred = []\n-\n-    def result(self):\n-        return len(self.y_pred)\n-\n-\n-class PyMetricTest(test_combinations.TestCase):\n-    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n-    def test_fit(self, run_eagerly):\n-        num_batches = 5\n-        dataset = get_dataset(num_batches=num_batches)\n-\n-        counting_metric = CountingPyMetric()\n-\n-        model = Sequential(layers.Dense(2))\n-        model.compile(\n-            loss=losses.BinaryCrossentropy(),\n-            metrics=[counting_metric],\n-            run_eagerly=run_eagerly,\n-        )\n-        model.fit(dataset, epochs=1)\n-\n-        self.assertEqual(counting_metric.result(), num_batches)\n-\n-    @parameterized.named_parameters((\"eager\", True), (\"graph\", False))\n-    def test_evaluate(self, run_eagerly):\n-        num_batches = 5\n-        dataset = get_dataset(num_batches=num_batches)\n-\n-        model = Sequential(layers.Dense(2))\n-        model.compile(\n-            loss=losses.BinaryCrossentropy(),\n-            metrics=[CountingPyMetric()],\n-            run_eagerly=run_eagerly,\n-        )\n-        loss, count = model.evaluate(dataset)\n-\n-        self.assertEqual(count, num_batches)\n-\n-\n-if __name__ == \"__main__\":\n-    tf.test.main()\n\n@@ -33,8 +33,6 @@ from keras.saving.legacy import serialization as legacy_serialization\n from keras.saving.legacy.serialization import deserialize_keras_object\n from keras.saving.legacy.serialization import serialize_keras_object\n \n-from keras.metrics.py_metric import PyMetric\n-\n # Individual metric classes\n \n # Accuracy metrics\n\n@@ -1,191 +0,0 @@\n-# Copyright 2023 The Keras Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Base class for Python-based metrics\"\"\"\n-\n-import types\n-\n-import tensorflow.compat.v2 as tf\n-from tensorflow.python.util.tf_export import keras_export\n-\n-from keras.metrics import base_metric\n-\n-\n-@keras_export(\"keras.metrics.experimental.PyMetric\", v1=[])\n-class PyMetric(base_metric.Metric):\n-    \"\"\"Metric which runs in Python, compiled outside of the TensorFlow graph.\n-\n-    Args:\n-      name: (Optional) string name of the PyMetric instance.\n-      dtype: (Optional) data type of the PyMetric result.\n-      **kwargs: Additional layer keywords arguments.\n-\n-    Usage of `PyMetric` is generally identical to `keras.metrics.Metric`.\n-    It can be used in isolation, or in tandem with the `compile()` API. For more\n-    information about the usage of `PyMetric`, see `keras.metrics.Metric`.\n-\n-    Unlike regular metrics, `PyMetric` instances are outside-compiled\n-    with respect to the TensorFlow graph during training or evaluation.\n-    They have access to the same\n-    inputs of a standard in-graph metric, but they run in a Python interpreter\n-    on the host CPU. Any data stored in a `PyMetric` is located on the main\n-    memory of the host CPU, and any TensorFlow ops used in a PyMetric are\n-    run eagerly on the host CPU.\n-\n-    As a result, `PyMetric` instances are generally not as performant\n-    as in-graph metrics, and should only be used in cases where computing\n-    the metric inside of the TensorFlow graph is either impossible\n-    or prohibitively expensive.\n-\n-    **Note:** Due to the use of `tf.py_function`, PyMetrics\n-    are incompatible with XLA and therefore TPUs.\n-\n-    Methods to be implemented by subclasses:\n-\n-    * `update_state()`: Handles updates to internal state variables\n-    * `result()`: Computes and returns a scalar value or a dict of scalar values\n-      for the metric from the state variables.\n-    * `reset_state()`: Computes and returns a scalar value for the metric from\n-      the state variables.\n-\n-    This subclass implementation is similar to that of `keras.metrics.Metric`,\n-    with two notable differences:\n-\n-    * Inputs to `update_state()` in a `PyMetric` are eager tensors, and both\n-    `update_state()` and `result()` run outside of the TensorFlow graph,\n-    executing any TensorFlow ops eagerly.\n-    * `reset_state()` is also called at initialization time to initialize the\n-    Python state of the metric.\n-    * `result()` can only return a single scalar. It does not support returning\n-    a dictionary of results like `keras.metrics.Metric`.\n-\n-    Example subclass implementation using sklearn's Jaccard Score:\n-\n-    ```python\n-    from sklearn.metrics import jaccard_score\n-    import tensorflow as tf\n-\n-    class JaccardScore(tf.keras.metrics.experimental.PyMetric):\n-\n-      def __init__(self, name='jaccard_score', **kwargs):\n-        super().__init__(name=name, **kwargs)\n-\n-      def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.jaccard_sum += jaccard_score(y_pred, y_true, average=\"macro\")\n-        self.count += 1\n-\n-      def reset_state(self):\n-        self.jaccard_sum = 0.\n-        self.count = 0.\n-\n-      def result(self):\n-        return self.jaccard_sum / self.count\n-    ```\n-    \"\"\"\n-\n-    def __init__(self, name=None, dtype=None, **kwargs):\n-        super().__init__(name=name, dtype=dtype, **kwargs)\n-        self.reset_state()\n-\n-    def __new__(cls, *args, **kwargs):\n-        obj = super(base_metric.Metric, cls).__new__(cls)\n-\n-        # Wrap the update_state function in a py_function and scope it to /cpu:0\n-        obj_update_state = obj.update_state\n-\n-        def update_state_on_cpu(y_true, y_pred, sample_weight=None):\n-            with tf.device(\"/cpu:0\"):\n-                return obj_update_state(y_true, y_pred, sample_weight)\n-\n-        obj.update_state_on_cpu = update_state_on_cpu\n-\n-        def update_state_fn(self, y_true, y_pred, sample_weight=None):\n-            eager_inputs = [y_true, y_pred]\n-            if sample_weight is not None:\n-                eager_inputs.append(sample_weight)\n-            return tf.py_function(\n-                func=self.update_state_on_cpu, inp=eager_inputs, Tout=[]\n-            )\n-\n-        obj.update_state = types.MethodType(update_state_fn, obj)\n-\n-        # Wrap the result function in a py_function and scope it to /cpu:0\n-        obj_result = obj.result\n-\n-        def result_on_host_cpu():\n-            with tf.device(\"/cpu:0\"):\n-                return obj_result()\n-\n-        obj.result_on_host_cpu = result_on_host_cpu\n-\n-        def result_fn(self):\n-            return tf.py_function(\n-                self.result_on_host_cpu, inp=[], Tout=obj.dtype\n-            )\n-\n-        obj.result = types.MethodType(result_fn, obj)\n-\n-        return obj\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        \"\"\"Accumulates statistics for the metric.\n-\n-        **Note:** This function is executed outside of the TensorFlow graph\n-        on the CPU host.\n-\n-        This means:\n-\n-        a) Inputs are eager tensors.\n-        b) Any TensorFlow ops run in this method are run eagerly.\n-        c) Any Tensors created are allocated to the CPU's main memory.\n-\n-        Args:\n-          y_true: Target output\n-          y_pred: Predicted output\n-          sample_weight: (Optional) weights for the individual samples in\n-            `y_true` and `y_pred`\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `update_state`\")\n-\n-    def merge_state(self, metrics):\n-        \"\"\"Merges the state from one or more metrics.\n-\n-        `PyMetric` instances that intend to support merging state must override\n-         this method, as the default implementation\n-        in `keras.metrics.Metric` does not apply to `PyMetric`.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `merge_state`\")\n-\n-    def reset_state(self):\n-        \"\"\"Resets all of the metric state variables.\n-\n-        This function is called between epochs when a metric is evaluated during\n-        training. It's also called when the metric is initialized.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `reset_state`\")\n-\n-    def result(self):\n-        \"\"\"Computes and returns the scalar metric value.\n-\n-        **Note:** This function is executed outside of the TensorFlow graph\n-         on the CPU host. This means any TensorFlow ops run in this method\n-         are run eagerly.\n-\n-        Result computation is an idempotent operation that simply calculates the\n-        metric value using the state variables.\n-\n-        Returns:\n-            A Python scalar.\n-        \"\"\"\n-        raise NotImplementedError(\"Subclasses should implement `result`\")\n\n@@ -1,145 +0,0 @@\n-# Copyright 2023 The Keras Authors. All Rights Reserved.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"Tests for Keras PyMetric classes.\"\"\"\n-\n-\n-import tensorflow.compat.v2 as tf\n-\n-from keras import metrics\n-from keras.testing_infra import test_combinations\n-\n-\n-class KTrimmedMean(metrics.PyMetric):\n-    \"\"\"An example PyMetric which computes the trimmed mean of `y_pred`.\"\"\"\n-\n-    def __init__(self, k=0.1, name=\"k_trimmed_mean\", **kwargs):\n-        super().__init__(name=name, **kwargs)\n-        self.k = k\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        y_true = y_true.numpy()\n-\n-        if sample_weight is not None:\n-            y_true *= sample_weight.numpy()\n-\n-        # Insert y_pred into our values list (keeping the list sorted)\n-        index = 0\n-        for i, element in enumerate(self.values):\n-            if y_true > element:\n-                index = i\n-                break\n-        self.values = self.values[:index] + [y_true] + self.values[index:]\n-\n-    def reset_state(self):\n-        self.values = []\n-\n-    def result(self):\n-        k = int(self.k * len(self.values))\n-        return tf.reduce_mean(self.values[k:-k])\n-\n-    def get_config(self):\n-        config = super().get_config()\n-        config.update({\"k\": self.k})\n-        return config\n-\n-\n-class Mean(metrics.PyMetric):\n-    \"\"\"An example PyMetric which computes the mean of `y_pred`.\"\"\"\n-\n-    def __init__(self, name=\"mean\", **kwargs):\n-        super().__init__(name=name, **kwargs)\n-\n-    def update_state(self, y_true, y_pred, sample_weight=None):\n-        self.values.append(y_true)\n-\n-    def reset_state(self):\n-        self.values = []\n-\n-    def result(self):\n-        return tf.reduce_mean(tf.concat(self.values, axis=0))\n-\n-\n-@test_combinations.generate(test_combinations.combine(mode=[\"graph\", \"eager\"]))\n-class PyMetricsTest(tf.test.TestCase):\n-    def test_config(self):\n-        ktm_object = KTrimmedMean(name=\"ktm\", k=0.2, dtype=tf.float16)\n-        self.assertEqual(ktm_object.name, \"ktm\")\n-        self.assertEqual(ktm_object.k, 0.2)\n-        self.assertEqual(ktm_object.dtype, tf.float16)\n-\n-        # Check save and restore config\n-        ktm_object2 = KTrimmedMean.from_config(ktm_object.get_config())\n-        self.assertEqual(ktm_object2.name, \"ktm\")\n-        self.assertEqual(ktm_object.k, 0.2)\n-        self.assertEqual(ktm_object2.dtype, tf.float16)\n-\n-    def test_unweighted(self):\n-        ktm_object = KTrimmedMean(k=0.2)\n-\n-        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n-            self.evaluate(\n-                ktm_object.update_state(\n-                    tf.constant(y_true, dtype=tf.float32),\n-                    y_pred=tf.constant(0, dtype=tf.float32),\n-                )\n-            )\n-\n-        result = ktm_object.result()\n-        self.assertEqual(3.5, self.evaluate(result))\n-\n-    def test_weighted(self):\n-        ktm_object = KTrimmedMean(k=0.2)\n-\n-        for y_true in [-100, -10, 1, 2, 3, 4, 5, 6, 14, 9001]:\n-            self.evaluate(\n-                ktm_object.update_state(\n-                    tf.constant(y_true, dtype=tf.float32),\n-                    y_pred=tf.constant(0, dtype=tf.float32),\n-                    sample_weight=tf.constant(2, dtype=tf.float32),\n-                )\n-            )\n-\n-        result = ktm_object.result()\n-        self.assertEqual(7, self.evaluate(result))\n-\n-    def test_state_stored_on_cpu_host(self):\n-        with tf.device(\"/device:GPU:0\"):\n-            mean_obj = Mean()\n-\n-            y_true_0 = tf.constant([0, 1, 2], dtype=tf.float32)\n-            y_true_1 = tf.constant([3, 4], dtype=tf.float32)\n-            self.evaluate(\n-                mean_obj.update_state(\n-                    y_true=y_true_0, y_pred=tf.constant(0, dtype=tf.float32)\n-                )\n-            )\n-            self.evaluate(\n-                mean_obj.update_state(\n-                    y_true=y_true_1, y_pred=tf.constant(0, dtype=tf.float32)\n-                )\n-            )\n-\n-        self.assertEqual(2, self.evaluate(mean_obj.result()))\n-\n-        if not tf.executing_eagerly():\n-            self.assertEndsWith(y_true_0.device, \"/device:GPU:0\")\n-            self.assertEndsWith(y_true_1.device, \"/device:GPU:0\")\n-\n-        self.assertEndsWith(mean_obj.values[0].device, \"/device:CPU:0\")\n-        self.assertEndsWith(mean_obj.values[1].device, \"/device:CPU:0\")\n-\n-\n-if __name__ == \"__main__\":\n-    tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
