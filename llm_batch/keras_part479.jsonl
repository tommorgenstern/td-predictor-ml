{"custom_id": "keras#8cdcea772b474dcacba1a149472117d7b5993d47", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 10781 | Contributors (this commit): 19 | Commits (past 90d): 28 | Contributors (cumulative): 24 | DMM Complexity: None\n\nDIFF:\n@@ -1815,7 +1815,7 @@ def identity(x, name=None):\n # tf.random.Generator to generate random numbers.\n # The legacy behavior is to use TF's legacy stateful RNG ops like\n # tf.random.uniform.\n-_USE_GENERATOR_FOR_RNG = True\n+_USE_GENERATOR_FOR_RNG = False\n \n # The global generator to create the seed when initializing the\n # tf.random.Genrator used by RandomGenerator. When tf.random.Generator becomes\n\n@@ -43,7 +43,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     `trainable` does not affect the layer's behavior, as Dropout does\n     not have any variables/weights that can be frozen during training.)\n \n-    >>> tf.keras.utils.set_random_seed(0)\n+    >>> tf.random.set_seed(0)\n     >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n     >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n     >>> print(data)\n@@ -56,7 +56,7 @@ class Dropout(base_layer.BaseRandomLayer):\n     >>> print(outputs)\n     tf.Tensor(\n     [[ 0.    1.25]\n-     [ 0.    3.75]\n+     [ 2.5   3.75]\n      [ 5.    6.25]\n      [ 7.5   8.75]\n      [10.    0.  ]], shape=(5, 2), dtype=float32)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#f15bfd0e8087bf372f268a918ebc831d152388d5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 13 | Churn Cumulative: 180 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -94,6 +94,19 @@ class DropoutTest(test_combinations.TestCase):\n         for name in checkpoint_var_names:\n             self.assertNotIn(\"dropout\", name)\n \n+        # Make sure the checkpoint can be loaded\n+        clone_model = keras.models.clone_model(model)\n+        checkpoint = tf.train.Checkpoint(clone_model)\n+        status = checkpoint.restore(\n+            os.path.join(self.get_temp_dir(), \"checkpoint-1\")\n+        )\n+        self.assertTrue(status.assert_consumed())\n+        self.assertTrue(status.assert_existing_objects_matched())\n+        # Make sure the output is differnt from the original model, since\n+        # the StateVar is not preserved.\n+        train3 = clone_model(np.ones((20, 5, 10)), training=True)\n+        self.assertNotAllClose(train3, train2)\n+\n     @test_utils.run_v2_only\n     def test_state_variable_name(self):\n         inputs = keras.Input(shape=(5, 10))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dd369b62b7699f4ec5966edec65f1829f927030a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 486 | Contributors (this commit): 10 | Commits (past 90d): 8 | Contributors (cumulative): 14 | DMM Complexity: None\n\nDIFF:\n@@ -28,6 +28,6 @@ from keras.engine.training import Model\n from tensorflow.python import tf2\n from tensorflow.python.util.tf_export import keras_export\n \n-__version__ = \"2.10.0\"\n+__version__ = \"2.11.0\"\n \n keras_export(\"keras.__version__\").export_constant(__name__, \"__version__\")\n\n@@ -31,7 +31,7 @@ DOCLINES = __doc__.split(\"\\n\")\n # This version string is semver compatible, but incompatible with pip.\n # For pip, we will remove all '-' characters from this string, and use the\n # result for pip.\n-_VERSION = \"2.10.0\"\n+_VERSION = \"2.11.0\"\n \n REQUIRED_PACKAGES = [\n     # We depend on TensorFlow's declared pip dependencies.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dc01c981d7f67ad195bfc3ca983b316f1719ccc1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 15 | Lines Deleted: 2 | Files Changed: 4 | Hunks: 6 | Methods Changed: 5 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 17 | Churn Cumulative: 5200 | Contributors (this commit): 17 | Commits (past 90d): 52 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -929,7 +929,9 @@ class LossScaleOptimizer(\n                 )\n             config[\"inner_optimizer\"] = config.pop(\"optimizer\")\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"], custom_objects=custom_objects\n+            config[\"inner_optimizer\"],\n+            custom_objects=custom_objects,\n+            use_legacy_optimizer=True,\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n@@ -1366,7 +1368,9 @@ class LossScaleOptimizerV3(\n     def from_config(cls, config, custom_objects=None):\n         config = config.copy()  # Make a copy, since we mutate config\n         inner_optimizer = optimizers.deserialize(\n-            config[\"inner_optimizer\"], custom_objects=custom_objects\n+            config[\"inner_optimizer\"],\n+            custom_objects=custom_objects,\n+            use_legacy_optimizer=False,\n         )\n         del config[\"inner_optimizer\"]\n         return cls(inner_optimizer, **config)\n\n@@ -124,6 +124,12 @@ def deserialize(config, custom_objects=None, **kwargs):\n     )\n \n     use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    if len(config[\"config\"]) > 0:\n+        # If the optimizer config is not empty, then we use the value of\n+        # `is_legacy_optimizer` to override `use_legacy_optimizer`. If\n+        # `is_legacy_optimizer` does not exist in config, it means we are\n+        # using the legacy optimzier.\n+        use_legacy_optimizer = config[\"config\"].get(\"is_legacy_optimizer\", True)\n     if (\n         tf.__internal__.tf2.enabled()\n         and tf.executing_eagerly()\n\n@@ -97,6 +97,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n             )\n \n     def _process_kwargs(self, kwargs):\n+        kwargs.pop(\"is_legacy_optimizer\", None)\n         legacy_kwargs = {\n             \"lr\",\n             \"decay\",\n@@ -619,6 +620,7 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n             \"ema_momentum\": self.ema_momentum,\n             \"ema_overwrite_frequency\": self.ema_overwrite_frequency,\n             \"jit_compile\": self.jit_compile,\n+            \"is_legacy_optimizer\": False,\n         }\n         return config\n \n\n@@ -297,6 +297,7 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n             \"use_ema\": True,\n             \"ema_momentum\": 0.5,\n             \"ema_overwrite_frequency\": 50,\n+            \"is_legacy_optimizer\": False,\n         }\n         self.assertDictContainsSubset(expected_config, config)\n         restored_optimizer = adam_new.Adam.from_config(config)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4647e9901b4b2c947f9c3f3ab8c42f97522e0438", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 7 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 24 | Churn Cumulative: 6338 | Contributors (this commit): 10 | Commits (past 90d): 11 | Contributors (cumulative): 16 | DMM Complexity: 1.0\n\nDIFF:\n@@ -37,6 +37,9 @@ from keras.distribute.strategy_combinations import strategies_minus_tpu\n from keras.distribute.strategy_combinations import tpu_strategies\n from keras.engine import base_layer_utils\n from keras.mixed_precision import policy\n+from keras.optimizers.optimizer_experimental import (\n+    optimizer as optimizer_experimental,\n+)\n from keras.optimizers.optimizer_v2 import (\n     gradient_descent as gradient_descent_keras,\n )\n@@ -3028,7 +3031,7 @@ class TestModelCapturesStrategy(tf.test.TestCase, parameterized.TestCase):\n             )\n             model.compile(optimizer=\"adam\", loss=\"mse\")\n             model.build([None, 1])  # create weights.\n-            self.assertEmpty(model.optimizer.weights)\n+            self.assertEmpty(model.optimizer.variables())\n             return model\n \n         model = create_model()\n@@ -3039,10 +3042,12 @@ class TestModelCapturesStrategy(tf.test.TestCase, parameterized.TestCase):\n         with distribution.scope():\n             model = create_model()\n             model.load_weights(temp_dir)\n-            self.assertNotEmpty(model.optimizer.weights)\n+            if isinstance(model.optimizer, optimizer_experimental.Optimizer):\n+                model.optimizer.build(model.trainable_variables)\n+            self.assertNotEmpty(model.optimizer.variables())\n             self.assertTrue(\n                 distributed_training_utils.is_distributed_variable(\n-                    model.optimizer.weights[0]\n+                    model.optimizer.variables()[0]\n                 )\n             )\n \n@@ -3050,10 +3055,13 @@ class TestModelCapturesStrategy(tf.test.TestCase, parameterized.TestCase):\n             model = create_model()\n         # create/restore slot variables outside of scope is fine.\n         model.load_weights(temp_dir)\n-        self.assertNotEmpty(model.optimizer.weights)\n+        if isinstance(model.optimizer, optimizer_experimental.Optimizer):\n+            # Experimental optimizer has to restore variables in scope.\n+            return\n+        self.assertNotEmpty(model.optimizer.variables())\n         self.assertTrue(\n             distributed_training_utils.is_distributed_variable(\n-                model.optimizer.weights[0]\n+                model.optimizer.variables()[0]\n             )\n         )\n \n\n@@ -560,7 +560,11 @@ class KerasModelTest(test_combinations.TestCase):\n             model = models.Model(x, y)\n             model.compile(\"sgd\", \"mse\")\n             self.assertIsInstance(\n-                model.optimizer, loss_scale_optimizer.LossScaleOptimizer\n+                model.optimizer,\n+                (\n+                    loss_scale_optimizer.LossScaleOptimizer,\n+                    loss_scale_optimizer.LossScaleOptimizerV3,\n+                ),\n             )\n \n             # Test if an LSO is passed, optimizer is not automatically wrapped\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#102ab667f513956d89f55f2f9480b9cdc5372eef", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 198 | Lines Deleted: 62 | Files Changed: 6 | Hunks: 18 | Methods Changed: 35 | Complexity Δ (Sum/Max): 25/14 | Churn Δ: 260 | Churn Cumulative: 33350 | Contributors (this commit): 44 | Commits (past 90d): 60 | Contributors (cumulative): 92 | DMM Complexity: 1.0\n\nDIFF:\n@@ -36,6 +36,7 @@ from keras.utils import control_flow_util\n from keras.utils import object_identity\n from keras.utils import tf_contextlib\n from keras.utils import tf_inspect\n+from keras.utils import tf_utils\n \n # isort: off\n from tensorflow.core.protobuf import config_pb2\n@@ -1468,7 +1469,6 @@ def is_placeholder(x):\n     try:\n         if tf.compat.v1.executing_eagerly_outside_functions():\n             return hasattr(x, \"_is_backend_placeholder\")\n-        from keras.utils import tf_utils\n \n         if tf_utils.is_extension_type(x):\n             flat_components = tf.nest.flatten(x, expand_composites=True)\n@@ -1972,10 +1972,6 @@ class RandomGenerator(tf.__internal__.tracking.AutoTrackable):\n             self._seed = self._create_seed(self._seed)\n             self._generator = None\n         elif self._rng_type == self.RNG_STATEFUL:\n-            from keras.utils import (\n-                tf_utils,\n-            )\n-\n             with tf_utils.maybe_init_scope(self):\n                 seed = self._create_seed(self._seed)\n                 self._generator = tf.random.Generator.from_seed(seed)\n@@ -4407,11 +4403,13 @@ class GraphExecutionFunction:\n                 \"should be a list or tuple.\"\n             )\n \n-        self._inputs_structure = inputs\n-        self.inputs = tf.nest.flatten(inputs, expand_composites=True)\n-        self._outputs_structure = outputs\n-        self.outputs = cast_variables_to_tensor(\n-            tf.nest.flatten(outputs, expand_composites=True)\n+        self.inputs = tf.nest.flatten(\n+            tf_utils.convert_variables_to_tensors(inputs),\n+            expand_composites=True,\n+        )\n+        self._outputs_structure = tf_utils.convert_variables_to_tensors(outputs)\n+        self.outputs = tf.nest.flatten(\n+            self._outputs_structure, expand_composites=True\n         )\n         # TODO(b/127668432): Consider using autograph to generate these\n         # dependencies in call.\n@@ -4522,7 +4520,6 @@ class GraphExecutionFunction:\n         # the CompositeTensors. E.g., if output_structure contains a\n         # SparseTensor, then this ensures that we return its value as a\n         # SparseTensorValue rather than a SparseTensor.\n-        from keras.utils import tf_utils\n \n         if tf_utils.is_extension_type(tensor):\n             return self._session.run(tensor)\n@@ -4530,7 +4527,10 @@ class GraphExecutionFunction:\n             return tensor\n \n     def __call__(self, inputs):\n-        inputs = tf.nest.flatten(inputs, expand_composites=True)\n+        inputs = tf.nest.flatten(\n+            tf_utils.convert_variables_to_tensors(inputs),\n+            expand_composites=True,\n+        )\n \n         session = get_session(inputs)\n         feed_arrays = []\n@@ -4620,7 +4620,6 @@ def function(inputs, outputs, updates=None, name=None, **kwargs):\n                 \"eager execution. You passed: %s\" % (updates,)\n             )\n         from keras import models\n-        from keras.utils import tf_utils\n \n         model = models.Model(inputs=inputs, outputs=outputs)\n \n@@ -7244,15 +7243,6 @@ def is_tpu_strategy(strategy):\n     return _is_tpu_strategy_class(strategy.__class__)\n \n \n-def cast_variables_to_tensor(tensors):\n-    def _cast_variables_to_tensor(tensor):\n-        if isinstance(tensor, tf.Variable):\n-            return tf.identity(tensor)\n-        return tensor\n-\n-    return tf.nest.map_structure(_cast_variables_to_tensor, tensors)\n-\n-\n def _is_symbolic_tensor(x):\n     return tf.is_tensor(x) and not isinstance(x, tf.__internal__.EagerTensor)\n \n\n@@ -2599,6 +2599,63 @@ class FunctionTest(tf.test.TestCase):\n         results = f({\"x\": 2.0, \"y\": 3.0})\n         self.assertEqual(results[0], 6.0)\n \n+    def test_function_variable_inputs(self):\n+        placeholders = {\n+            \"x\": backend.placeholder(shape=()),\n+            \"y\": backend.placeholder(shape=()),\n+        }\n+        outputs = [placeholders[\"x\"] * placeholders[\"y\"]]\n+\n+        f = backend.function(inputs=placeholders, outputs=outputs)\n+        results = f({\"x\": backend.variable(2.0), \"y\": 3.0})\n+        self.assertEqual(results[0], 6.0)\n+\n+    def test_function_composite_variable_inputs(self):\n+        if context.executing_eagerly():\n+            self.skipTest(\n+                \"Only graph mode flattens composite tensor inputs into flat \"\n+                \"tensors.\"\n+            )\n+\n+        class Spec(tf.TypeSpec):\n+            value_type = property(lambda self: CompositeVariable)\n+\n+            def _serialize(self):\n+                pass\n+\n+            def _component_specs(self):\n+                pass\n+\n+            def _to_components(self, value):\n+                return value.variables\n+\n+            def _from_components(self, variable_list):\n+                return CompositeVariable(variable_list)\n+\n+        class CompositeVariable(tf.__internal__.CompositeTensor):\n+            def __init__(self, variable_list):\n+                self.variables = variable_list\n+\n+            @property\n+            def _type_spec(self):\n+                return Spec()\n+\n+            def _convert_variables_to_tensors(self):\n+                self.variables = tf.nest.map_structure(\n+                    tf_utils.convert_variables_to_tensors, self.variables\n+                )\n+                return self\n+\n+        placeholders = {\n+            \"x\": backend.placeholder(shape=()),\n+            \"y\": backend.placeholder(shape=()),\n+        }\n+        outputs = [placeholders[\"x\"] * placeholders[\"y\"]]\n+\n+        f = backend.function(inputs=placeholders, outputs=outputs)\n+        results = f({\"x\": CompositeVariable([backend.variable(2.0)]), \"y\": 3.0})\n+        self.assertEqual(results[0], 6.0)\n+\n     def test_function_single_input_output(self):\n         x_ph = backend.placeholder(shape=(), name=\"x\")\n         output = x_ph * x_ph\n\n@@ -3126,24 +3126,7 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n         # Append value to list of trainable / non-trainable weights if relevant\n         # TODO(b/125122625): This won't pick up on any variables added to a\n         # list/dict after creation.\n-        for val in tf.nest.flatten(value, expand_composites=True):\n-            if not isinstance(val, tf.Variable):\n-                continue\n-\n-            # Users may add extra weights/variables simply by assigning them to\n-            # attributes (invalid for graph networks)\n-            self._maybe_create_attribute(\"_trainable_weights\", [])\n-            self._maybe_create_attribute(\"_non_trainable_weights\", [])\n-            if val.trainable:\n-                if any(val is w for w in self._trainable_weights):\n-                    continue\n-                self._trainable_weights.append(val)\n-            else:\n-                if any(val is w for w in self._non_trainable_weights):\n-                    continue\n-                self._non_trainable_weights.append(val)\n-\n-            backend.track_variable(val)\n+        self._track_variables(value)\n \n         # TODO(b/180760306) Skip the auto trackable from tf.Module to keep\n         # status quo. See the comment at __delattr__.\n@@ -3151,6 +3134,34 @@ class Layer(tf.Module, version_utils.LayerVersionSelector):\n             name, value\n         )\n \n+    def _track_variables(self, value):\n+        \"\"\"Tracks `Variable`s including `Variable`s in `CompositeTensor`s.\"\"\"\n+        for val in tf.nest.flatten(value):\n+            if isinstance(val, tf.Variable):\n+                self._track_variable(val)\n+            elif tf_utils.is_extension_type(val):\n+                # Manually expand extension types to track resource variables.\n+                nested_vals = tf_utils.type_spec_from_value(val)._to_components(\n+                    val\n+                )\n+                self._track_variables(nested_vals)\n+\n+    def _track_variable(self, val):\n+        \"\"\"Tracks the given `tf.Variable`.\"\"\"\n+        # Users may add extra weights/variables simply by assigning them to\n+        # attributes (invalid for graph networks)\n+        self._maybe_create_attribute(\"_trainable_weights\", [])\n+        self._maybe_create_attribute(\"_non_trainable_weights\", [])\n+        if val.trainable:\n+            if any(val is w for w in self._trainable_weights):\n+                return\n+            self._trainable_weights.append(val)\n+        else:\n+            if any(val is w for w in self._non_trainable_weights):\n+                return\n+            self._non_trainable_weights.append(val)\n+        backend.track_variable(val)\n+\n     def _gather_children_attribute(self, attribute):\n         assert attribute in {\n             \"variables\",\n\n@@ -2708,33 +2708,25 @@ class Model(training_lib.Model):\n                 # here.\n                 x_shapes = x_shapes[0]\n         else:\n-            flat_inputs = tf.nest.flatten(x, expand_composites=False)\n-            flat_expected_inputs = tf.nest.flatten(\n-                self.inputs, expand_composites=False\n-            )\n+            flat_inputs = tf.nest.flatten(x)\n+            flat_expected_inputs = tf.nest.flatten(self.inputs)\n             converted_x = []\n             for (a, b) in zip(flat_inputs, flat_expected_inputs):\n                 converted_x.append(_convert_scipy_sparse_tensor(a, b))\n-            x = tf.nest.pack_sequence_as(\n-                x, converted_x, expand_composites=False\n+            x = tf.nest.pack_sequence_as(x, converted_x)\n+\n+            # Convert ResourceVariables to tensors so nest.assert_same_structure\n+            # below won't fail with Variable and Tensor.\n+            x_tensors = tf_utils.convert_variables_to_tensors(x)\n+            x_shapes = tf.nest.map_structure(\n+                tf_utils.type_spec_from_value, x_tensors\n             )\n \n-            def _type_spec_from_value(value):\n-                \"\"\"Grab type_spec without converting array-likes to tensors.\"\"\"\n-                if tf_utils.is_extension_type(value):\n-                    return value._type_spec\n-                # Get a TensorSpec for array-like data without\n-                # converting the data to a Tensor\n-                if hasattr(value, \"shape\") and hasattr(value, \"dtype\"):\n-                    return tf.TensorSpec(value.shape, value.dtype)\n-                else:\n-                    return tf.type_spec_from_value(value)\n-\n-            x_shapes = tf.nest.map_structure(_type_spec_from_value, x)\n-\n-        flat_inputs = tf.nest.flatten(x_shapes, expand_composites=False)\n+        flat_inputs = tf.nest.flatten(x_shapes)\n+        # Convert ResourceVariables to tensors so nest.assert_same_structure\n+        # below won't fail with Variable and Tensor.\n         flat_expected_inputs = tf.nest.flatten(\n-            self.inputs, expand_composites=False\n+            tf_utils.convert_variables_to_tensors(self.inputs)\n         )\n         for (a, b) in zip(flat_inputs, flat_expected_inputs):\n             tf.nest.assert_same_structure(a, b, expand_composites=True)\n@@ -2850,7 +2842,9 @@ class Model(training_lib.Model):\n         # don't try - users should explicitly add composite tensor inputs to\n         # their subclassed models.\n         for input_tensor in processed_inputs:\n-            if training_utils_v1.is_composite_or_composite_value(input_tensor):\n+            if training_utils_v1.is_composite_or_composite_value(\n+                input_tensor\n+            ) and not isinstance(input_tensor, tf.Variable):\n                 # TODO(b/132691975): Document subclass-model CT input handling.\n                 raise ValueError(\n                     \"All SparseTensor and RaggedTensor inputs must be \"\n\n@@ -490,6 +490,36 @@ def is_tensor_or_extension_type(x):\n     return tf.is_tensor(x) or is_extension_type(x)\n \n \n+def convert_variables_to_tensors(values):\n+    \"\"\"Converts `Variable`s in `values` to `Tensor`s.\n+\n+    This is a Keras version of `convert_variables_to_tensors` in TensorFlow\n+    variable_utils.py.\n+\n+    If an object in `values` is an `ExtensionType` and it overrides its\n+    `_convert_variables_to_tensors` method, its `ResourceVariable` components\n+    will also be converted to `Tensor`s. Objects other than `ResourceVariable`s\n+    in `values` will be returned unchanged.\n+\n+    Args:\n+        values: A nested structure of `ResourceVariable`s, or any other objects.\n+\n+    Returns:\n+        A new structure with `ResourceVariable`s in `values` converted to\n+        `Tensor`s.\n+    \"\"\"\n+\n+    def _convert_resource_variable_to_tensor(x):\n+        if isinstance(x, tf.Variable):\n+            return tf.convert_to_tensor(x)\n+        elif is_extension_type(x):\n+            return x._convert_variables_to_tensors()\n+        else:\n+            return x\n+\n+    return tf.nest.map_structure(_convert_resource_variable_to_tensor, values)\n+\n+\n def assert_no_legacy_layers(layers):\n     \"\"\"Prevent tf.layers.Layers from being used with Keras.\n \n\n@@ -309,6 +309,60 @@ class TestIsTensorOrExtensionType(tf.test.TestCase):\n         self.assertFalse(tf_utils.is_tensor_or_extension_type([1.0, 2.0, 3.0]))\n \n \n+@test_combinations.generate(test_combinations.combine(mode=[\"eager\"]))\n+class TestConvertVariablesToTensors(tf.test.TestCase):\n+    def test_convert_variables_to_tensors(self):\n+        x = tf.Variable([1.0])\n+        result = tf_utils.convert_variables_to_tensors(x)\n+        self.assertIsInstance(result, tf.Tensor)\n+        self.assertAllEqual(result, [1.0])\n+\n+    def test_convert_variables_in_list_to_tensors(self):\n+        x = [tf.Variable([1.0]), tf.constant([2.0])]\n+        result = tf_utils.convert_variables_to_tensors(x)\n+        self.assertLen(result, 2)\n+        self.assertIsInstance(result[0], tf.Tensor)\n+        self.assertAllEqual(result[0], [1.0])\n+        self.assertIs(result[1], x[1])\n+\n+    def test_convert_variables_in_composite_tensor_to_tensors(self):\n+        class Spec(tf.TypeSpec):\n+            value_type = property(lambda self: CompositeVariable)\n+\n+            def _serialize(self):\n+                pass\n+\n+            def _component_specs(self):\n+                pass\n+\n+            def _to_components(self, value):\n+                return value.variables\n+\n+            def _from_components(self, variable_list):\n+                return CompositeVariable(variable_list)\n+\n+        class CompositeVariable(tf.__internal__.CompositeTensor):\n+            def __init__(self, variable_list):\n+                self.variables = variable_list\n+\n+            @property\n+            def _type_spec(self):\n+                return Spec()\n+\n+            def _convert_variables_to_tensors(self):\n+                self.variables = tf.nest.map_structure(\n+                    tf_utils.convert_variables_to_tensors, self.variables\n+                )\n+                return self\n+\n+        cv = CompositeVariable([tf.Variable([1.0])])\n+        self.assertIsInstance(cv.variables[0], tf.Variable)\n+        result = tf_utils.convert_variables_to_tensors(cv)\n+        self.assertLen(result.variables, 1)\n+        self.assertIsInstance(result.variables[0], tf.Tensor)\n+        self.assertAllEqual(result.variables[0], [1.0])\n+\n+\n class TestRandomSeedSetting(tf.test.TestCase):\n     def test_seeds(self):\n         if not tf.__internal__.tf2.enabled():\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a9475b4b8028771346af33de5513f354914749c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 5 | Files Changed: 4 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 28 | Churn Cumulative: 9967 | Contributors (this commit): 24 | Commits (past 90d): 35 | Contributors (cumulative): 44 | DMM Complexity: 0.13333333333333333\n\nDIFF:\n@@ -366,7 +366,7 @@ class KerasCallbacksTest(test_combinations.TestCase):\n             model.compile(\"sgd\", \"mse\")\n             cbk = BackupAndRestore(self.get_temp_dir())\n             model.fit(\n-                np.ones((10, 1)), np.ones((10, 1)), epochs=0, callbacks=[cbk]\n+                np.ones((10, 1)), np.ones((10, 1)), epochs=1, callbacks=[cbk]\n             )\n \n     def test_backup_restore_train_counter(self):\n\n@@ -22,6 +22,7 @@ from absl.testing import parameterized\n \n import keras\n from keras import backend\n+from keras.optimizers.optimizer_experimental import adam\n from keras.saving.experimental import saving_lib\n from keras.saving.saved_model import json_utils\n from keras.utils import generic_utils\n@@ -88,7 +89,7 @@ class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n     def _get_subclassed_model(self):\n         subclassed_model = CustomModelX()\n         subclassed_model.compile(\n-            optimizer=\"adam\",\n+            optimizer=adam.Adam(),\n             loss=[\n                 \"mse\",\n                 keras.losses.mean_squared_error,\n@@ -126,7 +127,7 @@ class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n         for model in [subclassed_model, loaded_model]:\n             self.assertIs(\n                 model.optimizer.__class__,\n-                keras.optimizers.optimizer_v2.adam.Adam,\n+                adam.Adam,\n             )\n             self.assertIs(\n                 model.compiled_loss.__class__,\n@@ -185,7 +186,7 @@ class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n         for model in [subclassed_model, loaded_model]:\n             self.assertIs(\n                 model.optimizer.__class__,\n-                keras.optimizers.optimizer_v2.adam.Adam,\n+                adam.Adam,\n             )\n             self.assertIs(\n                 model.compiled_loss.__class__,\n@@ -255,7 +256,7 @@ class NewSavingTest(tf.test.TestCase, parameterized.TestCase):\n         self.assertIsNone(config_dict[\"config\"][\"optimizer\"][\"module\"])\n         self.assertEqual(\n             config_dict[\"config\"][\"optimizer\"][\"class_name\"],\n-            \"keras.optimizers.Adam\",\n+            \"keras.optimizers.experimental.Adam\",\n         )\n         self.assertEqual(\n             config_dict[\"config\"][\"loss\"][\"module\"],\n\n@@ -86,6 +86,8 @@ class TestPickleProtocol(test_combinations.TestCase):\n         model = serializer(original_model)\n         # compile\n         model.compile(optimizer=\"sgd\", loss=\"sparse_categorical_crossentropy\")\n+        if hasattr(model.optimizer, \"_distribution_strategy\"):\n+            model.optimizer._distribution_strategy = None\n         # roundtrip compiled but not trained\n         model = serializer(model)\n \n\n@@ -480,6 +480,21 @@ class TestWholeModelSaving(test_combinations.TestCase):\n                 # TODO(b/153110928): Keras TF format doesn't restore optimizer\n                 # weights currently.\n                 return\n+            if isinstance(\n+                loaded_model.optimizer,\n+                keras.optimizers.optimizer_experimental.Optimizer,\n+            ):\n+                loaded_model.optimizer.build(loaded_model.trainable_variables)\n+                save_format = test_utils.get_save_format()\n+                if save_format == \"h5\":\n+                    # Experimental optimizer does not restore weights if saved\n+                    # in h5 format.\n+                    return\n+                self.assertAllClose(\n+                    model.optimizer.variables(),\n+                    loaded_model.optimizer.variables(),\n+                )\n+            else:\n                 self.assertAllClose(\n                     model.optimizer.weights, loaded_model.optimizer.weights\n                 )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#59805d04bece2d609e44de5f07f9942adf3e24c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 14 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 3/2 | Churn Δ: 14 | Churn Cumulative: 1221 | Contributors (this commit): 7 | Commits (past 90d): 32 | Contributors (cumulative): 12 | DMM Complexity: 0.0\n\nDIFF:\n@@ -525,6 +525,10 @@ class _BaseOptimizer(tf.__internal__.tracking.AutoTrackable):\n         grads_and_vars = list(zip(grads, trainable_variables))\n         self._internal_apply_gradients(grads_and_vars)\n \n+        for variable in trainable_variables:\n+            if variable.constraint is not None:\n+                variable.assign(variable.constraint(variable))\n+\n     def _internal_apply_gradients(self, grads_and_vars):\n         \"\"\"Helper function of apply gradients.\n \n\n@@ -236,6 +236,16 @@ class OptimizerFuntionalityTest(tf.test.TestCase, parameterized.TestCase):\n         with self.assertRaisesRegex(RuntimeError, \"Cannot set*\"):\n             optimizer.iterations = 2\n \n+    def testVariableConstraints(self):\n+        optimizer = adam_new.Adam()\n+        inputs = keras.layers.Input(shape=[1])\n+        outputs = keras.layers.Dense(1, kernel_constraint=\"NonNeg\")(inputs)\n+        model = keras.models.Model(inputs=inputs, outputs=outputs)\n+        model.trainable_variables[0] = -999999  # Set as a negative number.\n+        grads = [tf.zeros(1, 1), tf.zeros(1)]\n+        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n+        self.assertEqual(model.trainable_variables[0], 0.0)\n+\n     def testNoGradients(self):\n         optimizer = adam_new.Adam(jit_compile=False)\n         optimizer.apply_gradients(zip([], []))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#377b5b5234f80244f3baa90c14ca1baec92d1fee", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 295 | Contributors (this commit): 9 | Commits (past 90d): 11 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,7 @@ def deserialize(config, custom_objects=None, **kwargs):\n         loss_scale_optimizer,\n     )\n \n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n     if len(config[\"config\"]) > 0:\n         # If the optimizer config is not empty, then we use the value of\n         # `is_legacy_optimizer` to override `use_legacy_optimizer`. If\n@@ -204,7 +204,7 @@ def get(identifier, **kwargs):\n     Raises:\n         ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n     if isinstance(\n         identifier,\n         (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#72263fd719680f687f2c4028e32a1e3850950ba9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 299 | Contributors (this commit): 10 | Commits (past 90d): 12 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -123,7 +123,7 @@ def deserialize(config, custom_objects=None, **kwargs):\n         loss_scale_optimizer,\n     )\n \n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n     if len(config[\"config\"]) > 0:\n         # If the optimizer config is not empty, then we use the value of\n         # `is_legacy_optimizer` to override `use_legacy_optimizer`. If\n@@ -204,7 +204,7 @@ def get(identifier, **kwargs):\n     Raises:\n         ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n     if isinstance(\n         identifier,\n         (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#78d190dd03c5576e5cfd20b9e26b0d6b56430dfb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 10 | Churn Cumulative: 737 | Contributors (this commit): 7 | Commits (past 90d): 8 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -209,7 +209,7 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n     ```python\n     from PIL import Image\n     img = np.random.random(size=(100, 100, 3))\n-    pil_img = tf.keras.preprocessing.image.array_to_img(img)\n+    pil_img = tf.keras.utils.array_to_img(img)\n     ```\n \n \n@@ -290,8 +290,8 @@ def img_to_array(img, data_format=None, dtype=None):\n     ```python\n     from PIL import Image\n     img_data = np.random.random(size=(100, 100, 3))\n-    img = tf.keras.preprocessing.image.array_to_img(img_data)\n-    array = tf.keras.preprocessing.image.img_to_array(img)\n+    img = tf.keras.utils.array_to_img(img_data)\n+    array = tf.keras.utils.image.img_to_array(img)\n     ```\n \n \n@@ -375,8 +375,8 @@ def load_img(\n     Usage:\n \n     ```\n-    image = tf.keras.preprocessing.image.load_img(image_path)\n-    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n+    image = tf.keras.utils.load_img(image_path)\n+    input_arr = tf.keras.utils.img_to_array(image)\n     input_arr = np.array([input_arr])  # Convert single image to a batch.\n     predictions = model.predict(input_arr)\n     ```\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8daeb5b309f1454b43f2d2df3f293f4a5dcfc011", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 92 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/3 | Churn Δ: 92 | Churn Cumulative: 628 | Contributors (this commit): 10 | Commits (past 90d): 20 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -77,6 +77,7 @@ from keras.optimizers.optimizer_v2.gradient_descent import SGD\n from keras.optimizers.optimizer_v2.nadam import Nadam\n from keras.optimizers.optimizer_v2.rmsprop import RMSprop\n from keras.utils.generic_utils import deserialize_keras_object\n+from keras.utils.generic_utils import get_registered_name\n from keras.utils.generic_utils import serialize_keras_object\n \n # isort: off\n@@ -186,6 +187,46 @@ def deserialize(config, custom_objects=None, **kwargs):\n     )\n \n \n+@keras_export(\n+    \"keras.__internal__.optimizers.convert_to_legacy_optimizer\", v1=[]\n+)\n+def convert_to_legacy_optimizer(optimizer):\n+    \"\"\"Convert experimental optimizer to legacy optimizer.\n+\n+    This function takes in a `tf.keras.optimizers.experimental.Optimizer`\n+    instance and converts it to the corresponding\n+    `tf.keras.optimizer.legacy.Optimizer` instance.\n+    For example, `tf.keras.optimizers.experimental.Adam(...)` to\n+    `tf.keras.optimizers.legacy.Adam(...)`.\n+\n+    Args:\n+        optimizer: An instance of `tf.keras.optimizers.experimental.Optimizer`.\n+    \"\"\"\n+    if not isinstance(optimizer, optimizer_experimental.Optimizer):\n+        raise ValueError(\n+            \"`convert_to_legacy_optimizer` should only be called \"\n+            \"on instances of `tf.keras.optimizers.Optimizer`, but \"\n+            f\"received {optimizer} of type {type(optimizer)}.\"\n+        )\n+    optimizer_name = optimizer.__class__.__name__.lower()\n+    config = optimizer.get_config()\n+    # Remove fields that only exist in experimental optimizer.\n+    keys_to_remove = [\n+        \"use_ema\",\n+        \"ema_momentum\",\n+        \"ema_overwrite_frequency\",\n+        \"jit_compile\",\n+        \"is_legacy_optimizer\",\n+    ]\n+    for key in keys_to_remove:\n+        config.pop(key, None)\n+    legacy_optimizer_config = {\n+        \"class_name\": optimizer_name,\n+        \"config\": config,\n+    }\n+    return deserialize(legacy_optimizer_config, use_legacy_optimizer=True)\n+\n+\n @keras_export(\"keras.optimizers.get\")\n def get(identifier, **kwargs):\n     \"\"\"Retrieves a Keras Optimizer instance.\n\n@@ -22,6 +22,8 @@ import tensorflow.compat.v2 as tf\n \n import keras\n from keras.optimizers import optimizer_v1\n+from keras.optimizers.optimizer_experimental import adam as adam_experimental\n+from keras.optimizers.schedules import learning_rate_schedule\n from keras.testing_infra import test_combinations\n from keras.testing_infra import test_utils\n from keras.utils import np_utils\n@@ -299,6 +301,55 @@ class KerasOptimizersTest(test_combinations.TestCase):\n         ):\n             keras.optimizers.get(0)\n \n+    @test_utils.run_v2_only\n+    def test_convert_to_legacy_optimizer(self):\n+        if not tf.executing_eagerly():\n+            # The conversion could only happen in eager mode.\n+            return\n+        optimizer_list = [\n+            \"adadelta\",\n+            \"adagrad\",\n+            \"adam\",\n+            \"adamax\",\n+            \"nadam\",\n+            \"rmsprop\",\n+            \"sgd\",\n+            \"ftrl\",\n+        ]\n+        # Test conversion does not throw errors.\n+        for name in optimizer_list:\n+            experimental_optimizer = keras.optimizers.get(\n+                name, use_legacy_optimizer=False\n+            )\n+            reference_legacy_optimizer = keras.optimizers.get(\n+                name, use_legacy_optimizer=True\n+            )\n+            converted_legacy_optimizer = (\n+                keras.optimizers.convert_to_legacy_optimizer(\n+                    experimental_optimizer\n+                )\n+            )\n+            self.assertEqual(\n+                type(reference_legacy_optimizer),\n+                type(converted_legacy_optimizer),\n+            )\n+            self.assertDictEqual(\n+                reference_legacy_optimizer.get_config(),\n+                converted_legacy_optimizer.get_config(),\n+            )\n+\n+        lr_schedule = learning_rate_schedule.ExponentialDecay(\n+            initial_learning_rate=1e-2, decay_steps=10000, decay_rate=0.9\n+        )\n+        optimizer = adam_experimental.Adam(learning_rate=lr_schedule)\n+        legacy_optimizer = keras.optimizers.convert_to_legacy_optimizer(\n+            optimizer\n+        )\n+        self.assertDictEqual(\n+            optimizer.get_config()[\"learning_rate\"],\n+            legacy_optimizer.get_config()[\"learning_rate\"],\n+        )\n+\n \n if __name__ == \"__main__\":\n     tf.test.main()\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#08350fa3baa6e11a9be0781c9160d8488acecb56", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 870 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -326,7 +326,7 @@ class TestConvUtils(tf.test.TestCase, parameterized.TestCase):\n             ):\n                 p = list(p)\n                 p[d] = slice(None)\n-                mask[p * 2] = True\n+                mask[tuple(p * 2)] = True\n \n             mask = np.take(mask, range(0, min(1, input_shape[d])), ndims + d)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e7fdcb137dea16a285684535ad2bcebe6de3f433", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 344 | Contributors (this commit): 10 | Commits (past 90d): 14 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -124,7 +124,7 @@ def deserialize(config, custom_objects=None, **kwargs):\n         loss_scale_optimizer,\n     )\n \n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n     if len(config[\"config\"]) > 0:\n         # If the optimizer config is not empty, then we use the value of\n         # `is_legacy_optimizer` to override `use_legacy_optimizer`. If\n@@ -245,7 +245,7 @@ def get(identifier, **kwargs):\n     Raises:\n         ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n     if isinstance(\n         identifier,\n         (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66a30d2a319025ef05bf075eab339d6b7394bba6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 19772 | Contributors (this commit): 132 | Commits (past 90d): 31 | Contributors (cumulative): 132 | DMM Complexity: None\n\nDIFF:\n@@ -3803,7 +3803,7 @@ def reduce_per_replica(values, strategy, reduction=\"auto\"):\n     \"\"\"\n \n     if reduction == \"auto\":\n-        reduction = \"first\" if _is_tpu_multi_host(strategy) else \"sum\"\n+        reduction = \"first\" if backend.is_tpu_strategy(strategy) else \"sum\"\n \n     def _reduce(v):\n         \"\"\"Reduce a single `PerReplica` object.\"\"\"\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#db2aba0168d5481e6c78cb90f5652a116b0ada40", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 19780 | Contributors (this commit): 132 | Commits (past 90d): 32 | Contributors (cumulative): 132 | DMM Complexity: None\n\nDIFF:\n@@ -934,9 +934,11 @@ class Model(base_layer.Layer, version_utils.ModelVersionSelector):\n         \"\"\"Settable attribute indicating how the model should reduce\n         loss and metric values from replicas.\n \n-        Default: `\"auto\"`. This should be good for all cases.\n-        It boils down to using `\"sum\"` or `\"first\"` conditioned on\n-        whether TPU is used.\n+        Default: `\"auto\"`. This should be good for general use cases.\n+        It boils down to using `\"sum\"` or `\"first\"` conditioned on the \n+        specific implementation of the `tf.distribute` strategy.\n+        In case of a `tf.distribute.MirroredStrategy` it boils down to `\"sum\"`\n+        to account for the case of custom training loops.\n         \"\"\"\n         return self._distribute_reduction_method or \"auto\"\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#30bf872258415cd4a83ac1a33b031cc804981a9c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 348 | Contributors (this commit): 11 | Commits (past 90d): 15 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -124,7 +124,7 @@ def deserialize(config, custom_objects=None, **kwargs):\n         loss_scale_optimizer,\n     )\n \n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n     if len(config[\"config\"]) > 0:\n         # If the optimizer config is not empty, then we use the value of\n         # `is_legacy_optimizer` to override `use_legacy_optimizer`. If\n@@ -245,7 +245,7 @@ def get(identifier, **kwargs):\n     Raises:\n         ValueError: If `identifier` cannot be interpreted.\n     \"\"\"\n-    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", False)\n+    use_legacy_optimizer = kwargs.pop(\"use_legacy_optimizer\", True)\n     if isinstance(\n         identifier,\n         (\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
