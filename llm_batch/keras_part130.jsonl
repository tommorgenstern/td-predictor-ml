{"custom_id": "keras#d517b5557681d1d0097c0a2d91e181723799c994", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 130 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 10 | Methods Changed: 9 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 132 | Churn Cumulative: 262 | Contributors (this commit): 7 | Commits (past 90d): 4 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -13,6 +13,15 @@ _LEGACY_WEIGHT_ORDERING = False\n def epsilon():\n     '''Returns the value of the fuzz\n     factor used in numeric expressions.\n+\n+    # Returns\n+        A float.\n+\n+    # Example\n+    ```python\n+        >>> keras.backend.epsilon()\n+        1e-08\n+    ```\n     '''\n     return _EPSILON\n \n@@ -20,6 +29,19 @@ def epsilon():\n def set_epsilon(e):\n     '''Sets the value of the fuzz\n     factor used in numeric expressions.\n+\n+    # Arguments\n+        e: float. New value of epsilon.\n+\n+    # Example\n+    ```python\n+        >>> from keras import backend as K\n+        >>> K.epsilon()\n+        1e-08\n+        >>> K.set_epsilon(1e-05)\n+        >>> K.epsilon()\n+        1e-05\n+    ```\n     '''\n     global _EPSILON\n     _EPSILON = e\n@@ -28,11 +50,35 @@ def set_epsilon(e):\n def floatx():\n     '''Returns the default float type, as a string\n     (e.g. 'float16', 'float32', 'float64').\n+\n+    # Returns\n+        String, the current default float type.\n+\n+    # Example\n+    ```python\n+        >>> keras.backend.floatx()\n+        'float32'\n+    ```\n     '''\n     return _FLOATX\n \n \n def set_floatx(floatx):\n+    '''Sets the default float type.\n+\n+    # Arguments\n+        String: 'float16', 'float32', or 'float64'.\n+\n+    # Example\n+    ```python\n+        >>> from keras import backend as K\n+        >>> K.floatx()\n+        'float32'\n+        >>> K.set_floatx('float16')\n+        >>> K.floatx()\n+        'float16'\n+    ```\n+    '''\n     global _FLOATX\n     if floatx not in {'float16', 'float32', 'float64'}:\n         raise Exception('Unknown floatx type: ' + str(floatx))\n@@ -40,14 +86,44 @@ def set_floatx(floatx):\n \n \n def cast_to_floatx(x):\n-    '''Cast a Numpy array to floatx.\n+    '''Cast a Numpy array to the default Keras float type.\n+\n+    # Arguments\n+        x: Numpy array.\n+\n+    # Returns\n+        The same Numpy array, cast to its new type.\n+\n+    # Example\n+    ```python\n+        >>> from keras import backend as K\n+        >>> K.floatx()\n+        'float32'\n+        >>> arr = numpy.array([1.0, 2.0], dtype='float64')\n+        >>> arr.dtype\n+        dtype('float64')\n+        >>> new_arr = K.cast_to_floatx(arr)\n+        >>> new_arr\n+        array([ 1.,  2.], dtype=float32)\n+        >>> new_arr.dtype\n+        dtype('float32')\n+    ```\n     '''\n     return np.asarray(x, dtype=_FLOATX)\n \n \n def image_dim_ordering():\n-    '''Returns the image dimension ordering\n+    '''Returns the default image dimension ordering\n     convention ('th' or 'tf').\n+\n+    # Returns\n+        A string, either `'th'` or `'tf'`\n+\n+    # Example\n+    ```python\n+        >>> keras.backend.image_dim_ordering()\n+        'th'\n+    ```\n     '''\n     return _IMAGE_DIM_ORDERING\n \n@@ -55,6 +131,19 @@ def image_dim_ordering():\n def set_image_dim_ordering(dim_ordering):\n     '''Sets the value of the image dimension\n     ordering convention ('th' or 'tf').\n+\n+    # Arguments\n+        dim_ordering: string. `'th'` or `'tf'`.\n+\n+    # Example\n+    ```python\n+        >>> from keras import backend as K\n+        >>> K.image_dim_ordering()\n+        'th'\n+        >>> K.set_image_dim_ordering('tf')\n+        >>> K.image_dim_ordering()\n+        'tf'\n+    ```\n     '''\n     global _IMAGE_DIM_ORDERING\n     if dim_ordering not in {'tf', 'th'}:\n@@ -63,6 +152,23 @@ def set_image_dim_ordering(dim_ordering):\n \n \n def get_uid(prefix=''):\n+    '''Provides a unique UID given a string prefix.\n+\n+    # Arguments\n+        prefix: string.\n+\n+    # Returns\n+        An integer.\n+\n+    # Example\n+    ```\n+        >>> keras.backend.get_uid('dense')\n+        >>> 1\n+        >>> keras.backend.get_uid('dense')\n+        >>> 2\n+    ```\n+\n+    '''\n     _UID_PREFIXES[prefix] += 1\n     return _UID_PREFIXES[prefix]\n \n@@ -73,6 +179,28 @@ def reset_uids():\n \n \n def is_keras_tensor(x):\n+    '''Returns whether `x` is a Keras tensor.\n+\n+    # Arguments\n+        x: a potential tensor.\n+\n+    # Returns\n+        A boolean: whether the argument is a Keras tensor.\n+\n+    # Examples\n+    ```python\n+        >>> from keras import backend as K\n+        >>> np_var = numpy.array([1, 2])\n+        >>> K.is_keras_tensor(np_var)\n+        False\n+        >>> keras_var = K.variable(np_var)\n+        >>> K.is_keras_tensor(keras_var)  # A variable is not a Tensor.\n+        False\n+        >>> keras_placeholder = K.placeholder(shape=(2, 4, 5))\n+        >>> K.is_keras_tensor(keras_placeholder)  # A placeholder is a Tensor.\n+        True\n+    ```\n+    '''\n     if hasattr(x, '_keras_shape'):\n         return True\n     else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cc6e65d145ca16fb47e168d17aa58657ccfe0a8f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 61 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 10 | Methods Changed: 5 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 69 | Churn Cumulative: 1916 | Contributors (this commit): 22 | Commits (past 90d): 10 | Contributors (cumulative): 27 | DMM Complexity: 1.0\n\nDIFF:\n@@ -195,8 +195,9 @@ def load_img(path, grayscale=False, target_size=None):\n \n \n def list_pictures(directory, ext='jpg|jpeg|bmp|png'):\n-    return [os.path.join(directory, f) for f in sorted(os.listdir(directory))\n-            if os.path.isfile(os.path.join(directory, f)) and re.match('([\\w]+\\.(?:' + ext + '))', f)]\n+    return [os.path.join(root, f)\n+            for root, dirs, files in os.walk(directory) for f in files\n+            if re.match('([\\w]+\\.(?:' + ext + '))', f)]\n \n \n class ImageDataGenerator(object):\n@@ -300,14 +301,16 @@ class ImageDataGenerator(object):\n                             target_size=(256, 256), color_mode='rgb',\n                             classes=None, class_mode='categorical',\n                             batch_size=32, shuffle=True, seed=None,\n-                            save_to_dir=None, save_prefix='', save_format='jpeg'):\n+                            save_to_dir=None, save_prefix='', save_format='jpeg',\n+                            follow_links=False):\n         return DirectoryIterator(\n             directory, self,\n             target_size=target_size, color_mode=color_mode,\n             classes=classes, class_mode=class_mode,\n             dim_ordering=self.dim_ordering,\n             batch_size=batch_size, shuffle=shuffle, seed=seed,\n-            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n+            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format,\n+            follow_links=follow_links)\n \n     def standardize(self, x):\n         if self.preprocessing_function:\n@@ -589,7 +592,8 @@ class DirectoryIterator(Iterator):\n                  dim_ordering='default',\n                  classes=None, class_mode='categorical',\n                  batch_size=32, shuffle=True, seed=None,\n-                 save_to_dir=None, save_prefix='', save_format='jpeg'):\n+                 save_to_dir=None, save_prefix='', save_format='jpeg',\n+                 follow_links=False):\n         if dim_ordering == 'default':\n             dim_ordering = K.image_dim_ordering()\n         self.directory = directory\n@@ -633,9 +637,13 @@ class DirectoryIterator(Iterator):\n         self.nb_class = len(classes)\n         self.class_indices = dict(zip(classes, range(len(classes))))\n \n+        def _recursive_list(subpath):\n+            return sorted(os.walk(subpath, followlinks=follow_links), key=lambda tpl: tpl[0])\n+\n         for subdir in classes:\n             subpath = os.path.join(directory, subdir)\n-            for fname in sorted(os.listdir(subpath)):\n+            for root, dirs, files in _recursive_list(subpath):\n+                for fname in files:\n                     is_valid = False\n                     for extension in white_list_formats:\n                         if fname.lower().endswith('.' + extension):\n@@ -651,7 +659,8 @@ class DirectoryIterator(Iterator):\n         i = 0\n         for subdir in classes:\n             subpath = os.path.join(directory, subdir)\n-            for fname in sorted(os.listdir(subpath)):\n+            for root, dirs, files in _recursive_list(subpath):\n+                for fname in files:\n                     is_valid = False\n                     for extension in white_list_formats:\n                         if fname.lower().endswith('.' + extension):\n@@ -659,8 +668,10 @@ class DirectoryIterator(Iterator):\n                             break\n                     if is_valid:\n                         self.classes[i] = self.class_indices[subdir]\n-                    self.filenames.append(os.path.join(subdir, fname))\n                         i += 1\n+                        # add filename relative to directory\n+                        absolute_path = os.path.join(root, fname)\n+                        self.filenames.append(os.path.relpath(absolute_path, directory))\n         super(DirectoryIterator, self).__init__(self.nb_sample, batch_size, shuffle, seed)\n \n     def next(self):\n\n@@ -118,6 +118,48 @@ class TestImage:\n         x = np.random.random((32, 3, 10, 10))\n         generator.fit(x)\n \n+    def test_directory_iterator(self):\n+        num_classes = 2\n+        tmp_folder = tempfile.mkdtemp(prefix='test_images')\n+\n+        # create folders and subfolders\n+        paths = []\n+        for cl in range(num_classes):\n+            class_directory = 'class-{}'.format(cl)\n+            classpaths = [\n+                class_directory,\n+                os.path.join(class_directory, 'subfolder-1'),\n+                os.path.join(class_directory, 'subfolder-2'),\n+                os.path.join(class_directory, 'subfolder-1', 'sub-subfolder')\n+            ]\n+            for path in classpaths:\n+                os.mkdir(os.path.join(tmp_folder, path))\n+            paths.append(classpaths)\n+\n+        # save the images in the paths\n+        count = 0\n+        filenames = []\n+        for test_images in self.all_test_images:\n+            for im in test_images:\n+                # rotate image class\n+                im_class = count % num_classes\n+                # rotate subfolders\n+                classpaths = paths[im_class]\n+                filename = os.path.join(classpaths[count % len(classpaths)], 'image-{}.jpg'.format(count))\n+                filenames.append(filename)\n+                im.save(os.path.join(tmp_folder, filename))\n+                count += 1\n+\n+        # create iterator\n+        generator = image.ImageDataGenerator()\n+        dir_iterator = generator.flow_from_directory(tmp_folder)\n+\n+        # check number of classes and images\n+        assert(len(dir_iterator.class_indices) == num_classes)\n+        assert(len(dir_iterator.classes) == count)\n+        assert(sorted(dir_iterator.filenames) == sorted(filenames))\n+        shutil.rmtree(tmp_folder)\n+\n     def test_img_utils(self):\n         height, width = 10, 8\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#757ae95cca29293d25d03b65ca03c88683e3e46f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 2912 | Contributors (this commit): 45 | Commits (past 90d): 16 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -279,8 +279,11 @@ def prod(x, axis=None, keepdims=False):\n \n \n def mean(x, axis=None, keepdims=False):\n+    '''Mean of a tensor, alongside the specified axis.\n+    '''\n     dtype = None\n-    if 'int' in x.dtype:\n+    # bool is available since theano v0.9dev\n+    if 'int' in x.dtype or x.dtype == 'bool':\n         dtype = _FLOATX\n     return T.mean(x, axis=axis, keepdims=keepdims, dtype=dtype)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e587fb17a0ac37f2edab3c7fe407f34e8fce560", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 4501 | Contributors (this commit): 51 | Commits (past 90d): 30 | Contributors (cumulative): 61 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1541,9 +1541,11 @@ def pool2d(x, pool_size, strides=(1, 1), border_mode='valid',\n     if dim_ordering not in {'th', 'tf'}:\n         raise Exception('Unknown dim_ordering ' + str(dim_ordering))\n \n+    assert pool_size[0] >= 1 and pool_size[1] >= 1\n+\n     if border_mode == 'same':\n-        w_pad = pool_size[0] - 2 if pool_size[0] % 2 == 1 else pool_size[0] - 1\n-        h_pad = pool_size[1] - 2 if pool_size[1] % 2 == 1 else pool_size[1] - 1\n+        w_pad = pool_size[0] - 2 if pool_size[0] > 2 and pool_size[0] % 2 == 1 else pool_size[0] - 1\n+        h_pad = pool_size[1] - 2 if pool_size[1] > 2 and pool_size[1] % 2 == 1 else pool_size[1] - 1\n         padding = (w_pad, h_pad)\n     elif border_mode == 'valid':\n         padding = (0, 0)\n\n@@ -84,10 +84,11 @@ def test_atrous_conv_1d():\n \n @keras_test\n def test_maxpooling_1d():\n+    for border_mode in ['valid', 'same']:\n         for stride in [1, 2]:\n             layer_test(convolutional.MaxPooling1D,\n                        kwargs={'stride': stride,\n-                           'border_mode': 'valid'},\n+                               'border_mode': border_mode},\n                        input_shape=(3, 5, 4))\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e8939f43a6df0df76dc6e0e0e97aaeca664a2d19", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 3471 | Contributors (this commit): 45 | Commits (past 90d): 24 | Contributors (cumulative): 45 | DMM Complexity: None\n\nDIFF:\n@@ -361,7 +361,7 @@ def update_sub(x, decrement):\n \n def moving_average_update(variable, value, momentum):\n     return moving_averages.assign_moving_average(\n-        variable, value, momentum)\n+        variable, value, momentum, zero_debias=False)\n \n \n # LINEAR ALGEBRA\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d244d380474d815a1ebd7829d2ffd1542bd54f50", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 4 | Churn Cumulative: 3479 | Contributors (this commit): 46 | Commits (past 90d): 26 | Contributors (cumulative): 46 | DMM Complexity: 1.0\n\nDIFF:\n@@ -360,8 +360,12 @@ def update_sub(x, decrement):\n \n \n def moving_average_update(variable, value, momentum):\n+    try:\n         return moving_averages.assign_moving_average(\n             variable, value, momentum, zero_debias=False)\n+    except TypeError:\n+        return moving_averages.assign_moving_average(\n+            variable, value, momentum)\n \n \n # LINEAR ALGEBRA\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7e2e7a5e5a43443122df0b497f88dd77fd3bfc7c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 1946 | Contributors (this commit): 34 | Commits (past 90d): 12 | Contributors (cumulative): 34 | DMM Complexity: 1.0\n\nDIFF:\n@@ -556,6 +556,8 @@ class TensorBoard(Callback):\n             summary_value.tag = name\n             self.writer.add_summary(summary, epoch)\n         self.writer.flush()\n+\n+    def on_train_end(self, _):\n         self.writer.close()\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7c4f033c6a7a3a6d157045bb69b0dd1f22ff4ab3", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 407 | Contributors (this commit): 8 | Commits (past 90d): 2 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -13,7 +13,6 @@ from keras.preprocessing.image import ImageDataGenerator\n from keras.models import Sequential\n from keras.layers import Dense, Dropout, Activation, Flatten\n from keras.layers import Convolution2D, MaxPooling2D\n-from keras.optimizers import SGD\n from keras.utils import np_utils\n \n batch_size = 32\n@@ -60,10 +59,9 @@ model.add(Dropout(0.5))\n model.add(Dense(nb_classes))\n model.add(Activation('softmax'))\n \n-# Let's train the model using SGD + momentum:\n-sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n+# Let's train the model using RMSprop\n model.compile(loss='categorical_crossentropy',\n-              optimizer=sgd,\n+              optimizer='rmsprop',\n               metrics=['accuracy'])\n \n X_train = X_train.astype('float32')\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9f33f8af5f678a24e1585fdde893f1d7041640d4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 6 | Hunks: 6 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 1470 | Contributors (this commit): 2 | Commits (past 90d): 23 | Contributors (cumulative): 7 | DMM Complexity: None\n\nDIFF:\n@@ -271,7 +271,7 @@ def InceptionV3(include_top=True, weights='imagenet',\n     else:\n         inputs = img_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='inception_v3')\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -135,7 +135,7 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     else:\n         inputs = melgram_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='music_tagger_crnn')\n \n     if weights is None:\n         return model\n\n@@ -202,7 +202,7 @@ def ResNet50(include_top=True, weights='imagenet',\n     else:\n         inputs = img_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='resnet50')\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -119,7 +119,7 @@ def VGG16(include_top=True, weights='imagenet',\n     else:\n         inputs = img_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='vgg16')\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -122,7 +122,7 @@ def VGG19(include_top=True, weights='imagenet',\n     else:\n         inputs = img_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='vgg19')\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -198,7 +198,7 @@ def Xception(include_top=True, weights='imagenet',\n     else:\n         inputs = img_input\n     # Create model.\n-    model = Model(inputs, x)\n+    model = Model(inputs, x, name='xception')\n \n     # load weights\n     if weights == 'imagenet':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8d0199ed42b46ca65506249c26116e4d50458103", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 11 | Churn Cumulative: 1957 | Contributors (this commit): 35 | Commits (past 90d): 13 | Contributors (cumulative): 35 | DMM Complexity: 0.0\n\nDIFF:\n@@ -517,14 +517,23 @@ class TensorBoard(Callback):\n                 if hasattr(layer, 'output'):\n                     tf.histogram_summary('{}_out'.format(layer.name),\n                                          layer.output)\n+        if parse_version(tf.__version__) >= parse_version('0.12.0'):\n+            self.merged = tf.summary.merge_all()\n+        else:\n             self.merged = tf.merge_all_summaries()\n         if self.write_graph:\n-            if parse_version(tf.__version__) >= parse_version('0.8.0'):\n+            if parse_version(tf.__version__) >= parse_version('0.12.0'):\n+                self.writer = tf.summary.FileWriter(self.log_dir,\n+                                                    self.sess.graph)\n+            elif parse_version(tf.__version__) >= parse_version('0.8.0'):\n                 self.writer = tf.train.SummaryWriter(self.log_dir,\n                                                      self.sess.graph)\n             else:\n                 self.writer = tf.train.SummaryWriter(self.log_dir,\n                                                      self.sess.graph_def)\n+        else:\n+            if parse_version(tf.__version__) >= parse_version('0.12.0'):\n+                self.writer = tf.summary.FileWriter(self.log_dir)\n             else:\n                 self.writer = tf.train.SummaryWriter(self.log_dir)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#bd404b1c882ea649c17b9e26eadcc1978df21fdc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 178 | Contributors (this commit): 2 | Commits (past 90d): 1 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -44,7 +44,6 @@ Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n https://arxiv.org/abs/1603.05027v3\r\n \r\n '''\r\n-\r\n from __future__ import print_function\r\n import numpy as np\r\n np.random.seed(1337)  # for reproducibility\r\n@@ -76,6 +75,16 @@ def getwhere(x):\n     y_prepool, y_postpool = x\r\n     return K.gradients(K.sum(y_postpool), y_prepool)\r\n \r\n+if K.backend() == 'tensorflow':\r\n+    raise Exception('This example can only run with the '\r\n+                    'Theano backend for the time being, '\r\n+                    'because it requires taking the gradient '\r\n+                    'of a gradient, which isn\\'t '\r\n+                    'supported for all TF ops.')\r\n+\r\n+# This example assume 'th' dim ordering.\r\n+K.set_image_dim_ordering('th')\r\n+\r\n # input image dimensions\r\n img_rows, img_cols = 28, 28\r\n \r\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4aa8aa100b00756c862c93ec4d0f8f44f091f48c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 60 | Lines Deleted: 58 | Files Changed: 1 | Hunks: 56 | Methods Changed: 20 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 118 | Churn Cumulative: 2386 | Contributors (this commit): 29 | Commits (past 90d): 13 | Contributors (cumulative): 29 | DMM Complexity: 0.0\n\nDIFF:\n@@ -32,7 +32,7 @@ def standardize_input_data(data, names, shapes=None,\n     arrays (same order as `names`), while checking that the provided\n     arrays have shapes that match the network's expectations.\n     '''\n-    if type(data) is dict:\n+    if isinstance(data, dict):\n         arrays = []\n         for name in names:\n             if name not in data:\n@@ -40,7 +40,7 @@ def standardize_input_data(data, names, shapes=None,\n                                 name + '\". Need data for each key in: ' +\n                                 str(data.keys()))\n             arrays.append(data[name])\n-    elif type(data) is list:\n+    elif isinstance(data, list):\n         if len(data) != len(names):\n             if len(data) > 0 and hasattr(data[0], 'shape'):\n                 raise Exception('Error when checking ' + exception_prefix +\n@@ -116,13 +116,13 @@ def standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n     if x_weight is None or len(x_weight) == 0:\n         return [None for _ in output_names]\n     if len(output_names) == 1:\n-        if type(x_weight) is list and len(x_weight) == 1:\n+        if isinstance(x_weight, list) and len(x_weight) == 1:\n             return x_weight\n-        if type(x_weight) is dict and output_names[0] in x_weight:\n+        if isinstance(x_weight, dict) and output_names[0] in x_weight:\n             return [x_weight[output_names[0]]]\n         else:\n             return [x_weight]\n-    if type(x_weight) is list:\n+    if isinstance(x_weight, list):\n         if len(x_weight) != len(output_names):\n             raise Exception('Provided `' + weight_type + '` was a list of ' +\n                             str(len(x_weight)) +\n@@ -131,7 +131,7 @@ def standardize_sample_or_class_weights(x_weight, output_names, weight_type):\n                             'You should provide one `' + weight_type + '`'\n                             'array per model output.')\n         return x_weight\n-    if type(x_weight) is dict:\n+    if isinstance(x_weight, dict):\n         x_weights = []\n         for name in output_names:\n             x_weights.append(x_weight.get(name))\n@@ -221,19 +221,19 @@ def check_loss_and_target_compatibility(targets, losses, output_shapes):\n def collect_metrics(metrics, output_names):\n     if not metrics:\n         return [[] for _ in output_names]\n-    if type(metrics) is list:\n+    if isinstance(metrics, list):\n         # we then apply all metrics to all outputs.\n         return [copy.copy(metrics) for _ in output_names]\n-    elif type(metrics) is dict:\n+    elif isinstance(metrics, dict):\n         nested_metrics = []\n         for name in output_names:\n             output_metrics = metrics.get(name, [])\n-            if type(output_metrics) is not list:\n+            if not isinstance(output_metrics, list):\n                 output_metrics = [output_metrics]\n             nested_metrics.append(output_metrics)\n         return nested_metrics\n     else:\n-        raise Exception('Type of `metrics` argument not understood. '\n+        raise TypeError('Type of `metrics` argument not understood. '\n                         'Expected a list or dictionary, found: ' +\n                         str(metrics))\n \n@@ -276,7 +276,7 @@ def slice_X(X, start=None, stop=None):\n         stop: integer (stop index); should be None if\n             `start` was a list.\n     '''\n-    if type(X) == list:\n+    if isinstance(X, list):\n         if hasattr(start, '__len__'):\n             # hdf5 datasets only support list objects as indices\n             if hasattr(start, 'shape'):\n@@ -468,45 +468,46 @@ class Model(Container):\n         # prepare loss weights\n         if loss_weights is None:\n             loss_weights_list = [1. for _ in range(len(self.outputs))]\n-        elif type(loss_weights) is dict:\n+        elif isinstance(loss_weights, dict):\n             for name in loss_weights:\n                 if name not in self.output_names:\n-                    raise Exception('Unknown entry in loss_weights '\n+                    raise ValueError('Unknown entry in loss_weights '\n                                      'dictionary: \"' + name + '\". '\n                                      'Only expected the following keys: ' +\n                                      str(self.output_names))\n             loss_weights_list = []\n             for name in self.output_names:\n                 loss_weights_list.append(loss_weights.get(name, 1.))\n-        elif type(loss_weights) is list:\n+        elif isinstance(loss_weights, list):\n             if len(loss_weights) != len(self.outputs):\n-                raise Exception('When passing a list as loss_weights, '\n+                raise ValueError('When passing a list as loss_weights, '\n                                  'it should have one entry per model outputs. '\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed loss_weights=' +\n                                  str(loss_weights))\n             loss_weights_list = loss_weights\n         else:\n-            raise Exception('Could not interpret loss_weights argument: ' +\n-                            str(loss_weights))\n+            raise TypeError('Could not interpret loss_weights argument: ' +\n+                            str(loss_weights) +\n+                            ' - expected a list of dicts.')\n \n         # prepare loss functions\n-        if type(loss) is dict:\n+        if isinstance(loss, dict):\n             for name in loss:\n                 if name not in self.output_names:\n-                    raise Exception('Unknown entry in loss '\n+                    raise ValueError('Unknown entry in loss '\n                                      'dictionary: \"' + name + '\". '\n                                      'Only expected the following keys: ' +\n                                      str(self.output_names))\n             loss_functions = []\n             for name in self.output_names:\n                 if name not in loss:\n-                    raise Exception('Output \"' + name +\n-                                    '\" missing from loss dictionary')\n+                    raise ValueError('Output \"' + name +\n+                                     '\" missing from loss dictionary.')\n                 loss_functions.append(objectives.get(loss[name]))\n-        elif type(loss) is list:\n+        elif isinstance(loss, list):\n             if len(loss) != len(self.outputs):\n-                raise Exception('When passing a list as loss, '\n+                raise ValueError('When passing a list as loss, '\n                                  'it should have one entry per model outputs. '\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed loss=' +\n@@ -522,14 +523,14 @@ class Model(Container):\n         masks = self.compute_mask(self.inputs, mask=None)\n         if masks is None:\n             masks = [None for _ in self.outputs]\n-        if type(masks) is not list:\n+        if not isinstance(masks, list):\n             masks = [masks]\n \n         # prepare sample weights\n-        if type(sample_weight_mode) is dict:\n+        if isinstance(sample_weight_mode, dict):\n             for name in sample_weight_mode:\n                 if name not in self.output_names:\n-                    raise Exception('Unknown entry in '\n+                    raise ValueError('Unknown entry in '\n                                      'sample_weight_mode dictionary: \"' +\n                                      name + '\". '\n                                      'Only expected the following keys: ' +\n@@ -538,7 +539,7 @@ class Model(Container):\n             sample_weight_modes = []\n             for name in self.output_names:\n                 if name not in sample_weight_mode:\n-                    raise Exception('Output \"' + name +\n+                    raise ValueError('Output \"' + name +\n                                      '\" missing from sample_weight_modes '\n                                      'dictionary')\n                 if sample_weight_mode.get(name) == 'temporal':\n@@ -548,9 +549,9 @@ class Model(Container):\n                     weight = K.placeholder(ndim=1, name=name + '_sample_weights')\n                     sample_weight_modes.append(None)\n                 sample_weights.append(weight)\n-        elif type(sample_weight_mode) is list:\n+        elif isinstance(sample_weight_mode, list):\n             if len(sample_weight_mode) != len(self.outputs):\n-                raise Exception('When passing a list as sample_weight_mode, ' +\n+                raise ValueError('When passing a list as sample_weight_mode, '\n                                  'it should have one entry per model outputs. '\n                                  'The model has ' + str(len(self.outputs)) +\n                                  ' outputs, but you passed sample_weight_mode=' +\n@@ -686,7 +687,7 @@ class Model(Container):\n         if not hasattr(self, 'train_function'):\n             raise Exception('You must compile your model before using it.')\n         if self.train_function is None:\n-            if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n             else:\n                 inputs = self.inputs + self.targets + self.sample_weights\n@@ -706,7 +707,7 @@ class Model(Container):\n         if not hasattr(self, 'test_function'):\n             raise Exception('You must compile your model before using it.')\n         if self.test_function is None:\n-            if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 inputs = self.inputs + self.targets + self.sample_weights + [K.learning_phase()]\n             else:\n                 inputs = self.inputs + self.targets + self.sample_weights\n@@ -721,7 +722,7 @@ class Model(Container):\n         if not hasattr(self, 'predict_function'):\n             self.predict_function = None\n         if self.predict_function is None:\n-            if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 inputs = self.inputs + [K.learning_phase()]\n             else:\n                 inputs = self.inputs\n@@ -810,7 +811,7 @@ class Model(Container):\n             for batch_index, (batch_start, batch_end) in enumerate(batches):\n                 batch_ids = index_array[batch_start:batch_end]\n                 try:\n-                    if type(ins[-1]) is float:\n+                    if isinstance(ins[-1], float):\n                         # do not slice the training phase flag\n                         ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]\n                     else:\n@@ -824,7 +825,7 @@ class Model(Container):\n                 batch_logs['size'] = len(batch_ids)\n                 callbacks.on_batch_begin(batch_index, batch_logs)\n                 outs = f(ins_batch)\n-                if type(outs) != list:\n+                if not isinstance(outs, list):\n                     outs = [outs]\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n@@ -838,7 +839,7 @@ class Model(Container):\n                         val_outs = self._test_loop(val_f, val_ins,\n                                                    batch_size=batch_size,\n                                                    verbose=0)\n-                        if type(val_outs) != list:\n+                        if not isinstance(val_outs, list):\n                             val_outs = [val_outs]\n                         # same labels assumed\n                         for l, o in zip(out_labels, val_outs):\n@@ -871,14 +872,14 @@ class Model(Container):\n         index_array = np.arange(nb_sample)\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             batch_ids = index_array[batch_start:batch_end]\n-            if type(ins[-1]) is float:\n+            if isinstance(ins[-1], float):\n                 # do not slice the training phase flag\n                 ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]\n             else:\n                 ins_batch = slice_X(ins, batch_ids)\n \n             batch_outs = f(ins_batch)\n-            if type(batch_outs) != list:\n+            if not isinstance(batch_outs, list):\n                 batch_outs = [batch_outs]\n             if batch_index == 0:\n                 for batch_out in batch_outs:\n@@ -916,14 +917,14 @@ class Model(Container):\n         index_array = np.arange(nb_sample)\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             batch_ids = index_array[batch_start:batch_end]\n-            if type(ins[-1]) is float:\n+            if isinstance(ins[-1], float):\n                 # do not slice the training phase flag\n                 ins_batch = slice_X(ins[:-1], batch_ids) + [ins[-1]]\n             else:\n                 ins_batch = slice_X(ins, batch_ids)\n \n             batch_outs = f(ins_batch)\n-            if type(batch_outs) == list:\n+            if isinstance(batch_outs, list):\n                 if batch_index == 0:\n                     for batch_out in enumerate(batch_outs):\n                         outs.append(0.)\n@@ -1052,7 +1053,7 @@ class Model(Container):\n                                                                            batch_size=batch_size)\n             self._make_test_function()\n             val_f = self.test_function\n-            if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 val_ins = val_x + val_y + val_sample_weights + [0.]\n             else:\n                 val_ins = val_x + val_y + val_sample_weights\n@@ -1063,10 +1064,11 @@ class Model(Container):\n             x, val_x = (slice_X(x, 0, split_at), slice_X(x, split_at))\n             y, val_y = (slice_X(y, 0, split_at), slice_X(y, split_at))\n             sample_weights, val_sample_weights = (\n-                slice_X(sample_weights, 0, split_at), slice_X(sample_weights, split_at))\n+                slice_X(sample_weights, 0, split_at),\n+                slice_X(sample_weights, split_at))\n             self._make_test_function()\n             val_f = self.test_function\n-            if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+            if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n                 val_ins = val_x + val_y + val_sample_weights + [0.]\n             else:\n                 val_ins = val_x + val_y + val_sample_weights\n@@ -1076,7 +1078,7 @@ class Model(Container):\n             val_ins = None\n \n         # prepare input arrays and training function\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [1.]\n         else:\n             ins = x + y + sample_weights\n@@ -1137,7 +1139,7 @@ class Model(Container):\n                                                            check_batch_dim=False,\n                                                            batch_size=batch_size)\n         # prepare inputs, delegate logic to _test_loop\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n             ins = x + y + sample_weights + [0.]\n         else:\n             ins = x + y + sample_weights\n@@ -1174,7 +1176,7 @@ class Model(Container):\n                                 'Batch size: ' + str(batch_size) + '.')\n \n         # prepare inputs, delegate logic to _predict_loop\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n             ins = x + [0.]\n         else:\n             ins = x\n@@ -1218,7 +1220,7 @@ class Model(Container):\n                                                            sample_weight=sample_weight,\n                                                            class_weight=class_weight,\n                                                            check_batch_dim=True)\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n             ins = x + y + sample_weights + [1.]\n         else:\n             ins = x + y + sample_weights\n@@ -1256,7 +1258,7 @@ class Model(Container):\n         x, y, sample_weights = self._standardize_user_data(x, y,\n                                                            sample_weight=sample_weight,\n                                                            check_batch_dim=True)\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n             ins = x + y + sample_weights + [0.]\n         else:\n             ins = x + y + sample_weights\n@@ -1271,7 +1273,7 @@ class Model(Container):\n         '''\n         x = standardize_input_data(x, self.input_names,\n                                    self.internal_input_shapes)\n-        if self.uses_learning_phase and type(K.learning_phase()) is not int:\n+        if self.uses_learning_phase and not isinstance(K.learning_phase, int):\n             ins = x + [0.]\n         else:\n             ins = x\n@@ -1435,9 +1437,9 @@ class Model(Container):\n                                     'or (x, y). Found: ' + str(generator_output))\n                 # build batch logs\n                 batch_logs = {}\n-                if type(x) is list:\n+                if isinstance(x, list):\n                     batch_size = x[0].shape[0]\n-                elif type(x) is dict:\n+                elif isinstance(x, dict):\n                     batch_size = list(x.values())[0].shape[0]\n                 else:\n                     batch_size = x.shape[0]\n@@ -1453,7 +1455,7 @@ class Model(Container):\n                     _stop.set()\n                     raise\n \n-                if type(outs) != list:\n+                if not isinstance(outs, list):\n                     outs = [outs]\n                 for l, o in zip(out_labels, outs):\n                     batch_logs[l] = o\n@@ -1486,7 +1488,7 @@ class Model(Container):\n                                                  batch_size=batch_size,\n                                                  sample_weight=val_sample_weights,\n                                                  verbose=0)\n-                    if type(val_outs) is not list:\n+                    if not isinstance(val_outs, list):\n                         val_outs = [val_outs]\n                     # same labels assumed\n                     for l, o in zip(out_labels, val_outs):\n@@ -1570,9 +1572,9 @@ class Model(Container):\n                 _stop.set()\n                 raise\n \n-            if type(x) is list:\n+            if isinstance(x, list):\n                 nb_samples = len(x[0])\n-            elif type(x) is dict:\n+            elif isinstance(x, dict):\n                 nb_samples = len(list(x.values())[0])\n             else:\n                 nb_samples = len(x)\n@@ -1588,7 +1590,7 @@ class Model(Container):\n                 if p.is_alive():\n                     p.terminate()\n             data_gen_queue.close()\n-        if type(outs) is not list:\n+        if not isinstance(outs, list):\n             return np.average(np.asarray(all_outs),\n                               weights=weights)\n         else:\n@@ -1654,14 +1656,14 @@ class Model(Container):\n                 _stop.set()\n                 raise\n \n-            if type(x) is list:\n+            if isinstance(x, list):\n                 nb_samples = len(x[0])\n-            elif type(x) is dict:\n+            elif isinstance(x, dict):\n                 nb_samples = len(list(x.values())[0])\n             else:\n                 nb_samples = len(x)\n \n-            if type(outs) != list:\n+            if not isinstance(outs, list):\n                 outs = [outs]\n \n             if len(all_outs) == 0:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#22d3c8810cc2c80bc5778e8101ec193199ae7069", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 68 | Lines Deleted: 56 | Files Changed: 1 | Hunks: 38 | Methods Changed: 12 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 124 | Churn Cumulative: 4205 | Contributors (this commit): 25 | Commits (past 90d): 17 | Contributors (cumulative): 25 | DMM Complexity: 0.0\n\nDIFF:\n@@ -23,7 +23,7 @@ def to_list(x):\n     If a tensor is passed, we return\n     a list of size 1 containing the tensor.\n     '''\n-    if type(x) is list:\n+    if isinstance(x, list):\n         return x\n     return [x]\n \n@@ -37,7 +37,7 @@ class InputSpec(object):\n     a None shape is compatible with any shape.\n     '''\n     def __init__(self, dtype=None, shape=None, ndim=None):\n-        if type(ndim) is str:\n+        if isinstance(ndim, str):\n             if '+' not in ndim:\n                 raise ValueError('When passing a str \"ndim\", '\n                                  'it should have the form \"2+\", \"3+\", etc.')\n@@ -380,13 +380,14 @@ class Layer(object):\n         '''\n         if not self.input_spec:\n             return True\n-        assert type(self.input_spec) is list, ('input_spec must be a list of ' +\n+        if not isinstance(self.input_spec, list):\n+            raise TypeError('input_spec must be a list of '\n                             'InputSpec instances. Found: ' +\n                             str(self.input_spec))\n         inputs = to_list(input)\n         if len(self.input_spec) > 1:\n             if len(inputs) != len(self.input_spec):\n-                raise Exception('Layer ' + self.name + ' expects ' +\n+                raise ValueError('Layer ' + self.name + ' expects ' +\n                                  str(len(self.input_spec)) + ' inputs, '\n                                  'but it received ' + str(len(inputs)) +\n                                  ' input tensors. Input received: ' +\n@@ -397,25 +398,25 @@ class Layer(object):\n \n             # Check ndim.\n             if spec.ndim is not None:\n-                if type(spec.ndim) is str:\n+                if isinstance(spec.ndim, str):\n                     int_ndim = spec.ndim[:spec.ndim.find('+')]\n                     ndim = int(int_ndim)\n                     if K.ndim(x) < ndim:\n-                        raise Exception('Input ' + str(input_index) +\n+                        raise ValueError('Input ' + str(input_index) +\n                                          ' is incompatible with layer ' +\n                                          self.name + ': expected ndim >= ' +\n                                          str(ndim) + ', found ndim=' +\n                                          str(K.ndim(x)))\n                 else:\n                     if K.ndim(x) != spec.ndim:\n-                        raise Exception('Input ' + str(input_index) +\n+                        raise ValueError('Input ' + str(input_index) +\n                                          ' is incompatible with layer ' +\n                                          self.name + ': expected ndim=' +\n                                          str(spec.ndim) + ', found ndim=' +\n                                          str(K.ndim(x)))\n             if spec.dtype is not None:\n                 if K.dtype(x) != spec.dtype:\n-                    raise Exception('Input ' + str(input_index) +\n+                    raise ValueError('Input ' + str(input_index) +\n                                      ' is incompatible with layer ' +\n                                      self.name + ': expected dtype=' +\n                                      str(spec.dtype) + ', found dtype=' +\n@@ -431,7 +432,8 @@ class Layer(object):\n                 for spec_dim, dim in zip(spec.shape, x_shape):\n                     if spec_dim is not None:\n                         if spec_dim != dim:\n-                            raise Exception('Input ' + str(input_index) +\n+                            raise ValueError(\n+                                'Input ' + str(input_index) +\n                                 ' is incompatible with layer ' +\n                                 self.name + ': expected shape=' +\n                                 str(spec.shape) + ', found shape=' +\n@@ -597,13 +599,17 @@ class Layer(object):\n         '''\n         if not hasattr(self, 'supports_masking') or not self.supports_masking:\n             if input_mask is not None:\n-                if type(input_mask) is list:\n+                if isinstance(input_mask, list):\n                     if any(input_mask):\n-                        raise Exception('Layer ' + self.name + ' does not support masking, ' +\n-                                        'but was passed an input_mask: ' + str(input_mask))\n+                        raise ValueError('Layer ' + self.name +\n+                                         ' does not support masking, ' +\n+                                         'but was passed an input_mask: ' +\n+                                         str(input_mask))\n                 else:\n-                    raise Exception('Layer ' + self.name + ' does not support masking, ' +\n-                                    'but was passed an input_mask: ' + str(input_mask))\n+                    raise ValueError('Layer ' + self.name +\n+                                     ' does not support masking, ' +\n+                                     'but was passed an input_mask: ' +\n+                                     str(input_mask))\n             # masking not explicitly supported: return None as mask\n             return None\n         # if masking is explictly supported, by default\n@@ -1178,12 +1184,13 @@ class Merge(Layer):\n         '''Validates user-passed arguments and raises exceptions\n         as appropriate.\n         '''\n-        if not hasattr(mode, '__call__'):\n+        if not callable(mode):\n             if mode not in {'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'}:\n-                raise Exception('Invalid merge mode: ' + str(mode))\n-        if type(layers) not in {list, tuple} or len(layers) < 2:\n-            raise Exception('A Merge should only be applied to a list of '\n-                            'layers with at least 2 elements. Found: ' + str(layers))\n+                raise ValueError('Invalid merge mode: ' + str(mode))\n+        if not isinstance(layers, (list, tuple)) or len(layers) < 2:\n+            raise TypeError('A Merge should only be applied to a list of '\n+                            'layers with at least 2 elements. Found: ' +\n+                            str(layers))\n \n         if tensor_indices is None:\n             tensor_indices = [None for _ in range(len(layers))]\n@@ -1191,7 +1198,7 @@ class Merge(Layer):\n         input_shapes = []\n         for i, layer in enumerate(layers):\n             layer_output_shape = layer.get_output_shape_at(node_indices[i])\n-            if type(layer_output_shape) is list:\n+            if isinstance(layer_output_shape, list):\n                 # Case: the layer has multiple output tensors\n                 # and we only need a specific one.\n                 layer_output_shape = layer_output_shape[tensor_indices[i]]\n@@ -1200,29 +1207,32 @@ class Merge(Layer):\n         if mode in {'sum', 'mul', 'ave', 'cos', 'max'}:\n             input_shapes_set = set(input_shapes)\n             if len(input_shapes_set) > 1:\n-                raise Exception('Only layers of same output shape can '\n+                raise ValueError('Only layers of same output shape can '\n                                  'be merged using ' + mode + ' mode. ' +\n                                  'Layer shapes: %s' % input_shapes)\n         if mode in {'cos', 'dot'}:\n             if len(layers) > 2:\n-                raise Exception(mode + ' merge takes exactly 2 layers')\n+                raise ValueError(mode + ' merge takes exactly 2 layers')\n             shape1 = input_shapes[0]\n             shape2 = input_shapes[1]\n             n1 = len(shape1)\n             n2 = len(shape2)\n-            if type(dot_axes) == int:\n+            if isinstance(dot_axes, int):\n                 if dot_axes < 0:\n                     self.dot_axes = [dot_axes % n1, dot_axes % n2]\n                 else:\n                     self.dot_axes = [dot_axes, ] * 2\n-            if type(self.dot_axes) not in [list, tuple]:\n-                raise Exception('Invalid type for dot_axes - should be a list.')\n+            if not isinstance(self.dot_axes, (list, tuple)):\n+                raise TypeError('Invalid type for dot_axes - '\n+                                'should be a list.')\n             if len(self.dot_axes) != 2:\n-                raise Exception('Invalid format for dot_axes - should contain two elements.')\n-            if type(self.dot_axes[0]) is not int or type(self.dot_axes[1]) is not int:\n-                raise Exception('Invalid format for dot_axes - list elements should be \"int\".')\n+                raise ValueError('Invalid format for dot_axes - '\n+                                 'should contain two elements.')\n+            if not isinstance(self.dot_axes[0], int) or not isinstance(self.dot_axes[1], int):\n+                raise ValueError('Invalid format for dot_axes - '\n+                                 'list elements should be \"int\".')\n             if shape1[self.dot_axes[0]] != shape2[self.dot_axes[1]]:\n-                raise Exception('Dimension incompatibility using dot mode: ' +\n+                raise ValueError('Dimension incompatibility using dot mode: '\n                                  '%s != %s. ' % (shape1[self.dot_axes[0]], shape2[self.dot_axes[1]]) +\n                                  'Layer shapes: %s, %s' % (shape1, shape2))\n         elif mode == 'concat':\n@@ -1232,16 +1242,17 @@ class Merge(Layer):\n                 del reduced_inputs_shapes[i][self.concat_axis]\n                 shape_set.add(tuple(reduced_inputs_shapes[i]))\n             if len(shape_set) > 1:\n-                raise Exception('\"concat\" mode can only merge layers with matching ' +\n-                                'output shapes except for the concat axis. ' +\n+                raise ValueError('\"concat\" mode can only merge '\n+                                 'layers with matching '\n+                                 'output shapes except for the concat axis. '\n                                  'Layer shapes: %s' % (input_shapes))\n \n     def call(self, inputs, mask=None):\n-        if type(inputs) is not list or len(inputs) <= 1:\n-            raise Exception('Merge must be called on a list of tensors '\n+        if not isinstance(inputs, list) or len(inputs) <= 1:\n+            raise TypeError('Merge must be called on a list of tensors '\n                             '(at least 2). Got: ' + str(inputs))\n         # Case: \"mode\" is a lambda or function.\n-        if hasattr(self.mode, '__call__'):\n+        if callable(self.mode):\n             arguments = self.arguments\n             arg_spec = inspect.getargspec(self.mode)\n             if 'mask' in arg_spec.args:\n@@ -1285,7 +1296,7 @@ class Merge(Layer):\n             output = K.expand_dims(output, 1)\n             return output\n         else:\n-            raise Exception('Unknown merge mode.')\n+            raise ValueError('Unknown merge mode.')\n \n     def __call__(self, inputs, mask=None):\n         '''We disable successive calls to __call__ for Merge layers.\n@@ -1293,8 +1304,8 @@ class Merge(Layer):\n         making it possible to __call__ a Merge instance many times\n         (it is just a layer), it would make for a rather inelegant API.\n         '''\n-        if type(inputs) is not list:\n-            raise Exception('Merge can only be called on a list of tensors, '\n+        if not isinstance(inputs, list):\n+            raise TypeError('Merge can only be called on a list of tensors, '\n                             'not a single tensor. Received: ' + str(inputs))\n         if self.built:\n             raise Exception('A Merge layer cannot be used more than once, '\n@@ -1329,21 +1340,24 @@ class Merge(Layer):\n             return self.call(inputs, mask)\n \n     def get_output_shape_for(self, input_shape):\n-        assert type(input_shape) is list  # Must have multiple input shape tuples.\n+        # Must have multiple input shape tuples.\n+        assert isinstance(input_shape, list)\n         # Case: callable self._output_shape.\n-        if hasattr(self.mode, '__call__'):\n-            if hasattr(self._output_shape, '__call__'):\n+        if callable(self.mode):\n+            if callable(self._output_shape):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n             elif self._output_shape is not None:\n                 return (input_shape[0][0],) + tuple(self._output_shape)\n             else:\n                 # TODO: consider shape auto-inference with TF.\n-                raise Exception('The Merge layer ' + self.name +\n-                                ' has a callable `mode` argument, ' +\n-                                'and we cannot infer its output shape because ' +\n-                                'no `output_shape` argument was provided. ' +\n-                                'Make sure to pass a shape tuple (or a callable) ' +\n+                raise ValueError('The Merge layer ' + self.name +\n+                                 ' has a callable `mode` argument, '\n+                                 'and we cannot infer its output shape '\n+                                 'because no `output_shape` '\n+                                 'argument was provided. '\n+                                 'Make sure to pass a shape tuple '\n+                                 '(or callable) '\n                                  '`output_shape` to Merge.')\n         # Pre-defined merge modes.\n         input_shapes = input_shape\n@@ -1395,14 +1409,14 @@ class Merge(Layer):\n             return K.all(concatenated, axis=-1, keepdims=False)\n         elif self.mode in ['cos', 'dot']:\n             return None\n-        elif hasattr(self.mode, '__call__'):\n-            if hasattr(self._output_mask, '__call__'):\n+        elif callable(self.mode):\n+            if callable(self._output_mask):\n                 return self._output_mask(mask)\n             else:\n                 return self._output_mask\n         else:\n             # This should have been caught earlier.\n-            raise Exception('Invalid merge mode: {}'.format(self.mode))\n+            raise ValueError('Invalid merge mode: {}'.format(self.mode))\n \n     def get_config(self):\n         if isinstance(self.mode, python_types.LambdaType):\n@@ -1598,11 +1612,11 @@ class Container(Layer):\n         self.trainable = True\n \n         # Container-specific properties.\n-        if type(input) in {list, tuple}:\n+        if isinstance(input, (list, tuple)):\n             self.inputs = list(input)  # Tensor or list of tensors.\n         else:\n             self.inputs = [input]\n-        if type(output) in {list, tuple}:\n+        if isinstance(output, (list, tuple)):\n             self.outputs = list(output)\n         else:\n             self.outputs = [output]\n@@ -2033,8 +2047,8 @@ class Container(Layer):\n             if layer.input_spec is None:\n                 specs.append(None)\n             else:\n-                if type(layer.input_spec) is not list:\n-                    raise Exception('Layer ' + layer.name +\n+                if not isinstance(layer.input_spec, list):\n+                    raise TypeError('Layer ' + layer.name +\n                                     ' has an input_spec attribute that '\n                                     'is not a list. We expect a list. '\n                                     'Found input_spec = ' +\n@@ -2102,7 +2116,7 @@ class Container(Layer):\n         cache_key = ','.join([str(x) for x in input_shapes])\n         if cache_key in self._output_shape_cache:\n             output_shapes = self._output_shape_cache[cache_key]\n-            if type(output_shapes) is list and len(output_shapes) == 1:\n+            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                 return output_shapes[0]\n             return output_shapes\n         else:\n@@ -2166,7 +2180,7 @@ class Container(Layer):\n                 output_shapes.append(layers_to_output_shapes[key])\n             # Store in cache.\n             self._output_shape_cache[cache_key] = output_shapes\n-            if type(output_shapes) is list and len(output_shapes) == 1:\n+            if isinstance(output_shapes, list) and len(output_shapes) == 1:\n                 return output_shapes[0]\n             return output_shapes\n \n@@ -2184,10 +2198,8 @@ class Container(Layer):\n         # Returns\n             Three lists: output_tensors, output_masks, output_shapes\n         '''\n-        assert type(inputs) is list\n         if masks is None:\n             masks = [None for _ in range(len(inputs))]\n-        assert type(masks) is list\n \n         # Dictionary mapping reference tensors to tuples (computed tensor, compute mask)\n         # we assume a 1:1 mapping from tensor to mask\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
