{"custom_id": "keras#02fb8a0113adcda3a89bb3713ff7f97be7602b43", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 26 | Lines Deleted: 151 | Files Changed: 3 | Hunks: 22 | Methods Changed: 14 | Complexity Δ (Sum/Max): -11/0 | Churn Δ: 177 | Churn Cumulative: 2019 | Contributors (this commit): 5 | Commits (past 90d): 12 | Contributors (cumulative): 9 | DMM Complexity: 0.2702702702702703\n\nDIFF:\n@@ -17,21 +17,14 @@\n # pylint: disable=g-classes-have-attributes\n # pylint: disable=g-direct-tensorflow-import\n \n-from keras import backend\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import preprocessing_utils as utils\n-from keras.utils import layer_utils\n from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n-INT = utils.INT\n-MULTI_HOT = utils.MULTI_HOT\n-ONE_HOT = utils.ONE_HOT\n-COUNT = utils.COUNT\n-\n \n def summarize(values, epsilon):\n   \"\"\"Reduce a 1D sequence of values to a summary.\n@@ -156,25 +149,6 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       0.01). Higher values of epsilon increase the quantile approximation, and\n       hence result in more unequal buckets, but could improve performance\n       and resource consumption.\n-    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n-      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"`\n-      configuring the layer as follows:\n-        - `\"int\"`: Return the discritized bin indices directly.\n-        - `\"one_hot\"`: Encodes each individual element in the input into an\n-          array the same size as `num_bins`, containing a 1 at the input's bin\n-          index. If the last dimension is size 1, will encode on that dimension.\n-          If the last dimension is not size 1, will append a new dimension for\n-          the encoded output.\n-        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n-          the same size as `num_bins`, containing a 1 for each bin index\n-          index present in the sample. Treats the last dimension as the sample\n-          dimension, if input shape is `(..., sample_length)`, output shape will\n-          be `(..., num_tokens)`.\n-        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n-          number of times the bin index appeared in the sample.\n-    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n-      and `\"count\"` output modes. If True, returns a `SparseTensor` instead of\n-      a dense `Tensor`. Defaults to False.\n \n   Examples:\n \n@@ -200,8 +174,6 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n                bin_boundaries=None,\n                num_bins=None,\n                epsilon=0.01,\n-               output_mode=\"int\",\n-               sparse=False,\n                **kwargs):\n     # bins is a deprecated arg for setting bin_boundaries or num_bins that still\n     # has some usage.\n@@ -213,34 +185,9 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       elif bin_boundaries is None:\n         bin_boundaries = kwargs[\"bins\"]\n       del kwargs[\"bins\"]\n-\n-    # By default, output int64 when output_mode='int' and floats otherwise.\n-    if \"dtype\" not in kwargs:\n-      kwargs[\"dtype\"] = tf.int64 if output_mode == INT else backend.floatx()\n-\n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\"Discretization\").set(\n         True)\n-\n-    # Check dtype only after base layer parses it; dtype parsing is complex.\n-    if output_mode == INT and not tf.as_dtype(self.compute_dtype).is_integer:\n-      input_dtype = kwargs[\"dtype\"]\n-      raise ValueError(\"When `output_mode='int'`, `dtype` should be an integer \"\n-                       f\"type. Received: dtype={input_dtype}\")\n-\n-    # 'output_mode' must be one of (INT, ONE_HOT, MULTI_HOT, COUNT)\n-    layer_utils.validate_string_arg(\n-        output_mode,\n-        allowable_strings=(INT, ONE_HOT, MULTI_HOT, COUNT),\n-        layer_name=self.__class__.__name__,\n-        arg_name=\"output_mode\")\n-\n-    if sparse and output_mode == INT:\n-      raise ValueError(f\"`sparse` may only be true if `output_mode` is \"\n-                       f\"`'one_hot'`, `'multi_hot'`, or `'count'`. \"\n-                       f\"Received: sparse={sparse} and \"\n-                       f\"output_mode={output_mode}\")\n-\n     if num_bins is not None and num_bins < 0:\n       raise ValueError(\"`num_bins` must be greater than or equal to 0. \"\n                        \"You passed `num_bins={}`\".format(num_bins))\n@@ -253,8 +200,6 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n     self.bin_boundaries = bin_boundaries if bin_boundaries is not None else []\n     self.num_bins = num_bins\n     self.epsilon = epsilon\n-    self.output_mode = output_mode\n-    self.sparse = sparse\n \n   def build(self, input_shape):\n     super().build(input_shape)\n@@ -307,8 +252,6 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n         \"bin_boundaries\": self.input_bin_boundaries,\n         \"num_bins\": self.num_bins,\n         \"epsilon\": self.epsilon,\n-        \"output_mode\": self.output_mode,\n-        \"sparse\": self.sparse,\n     })\n     return config\n \n@@ -317,28 +260,30 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape.as_list())\n+    output_dtype = tf.int64\n     if isinstance(input_spec, tf.SparseTensorSpec):\n       return tf.SparseTensorSpec(\n-          shape=output_shape, dtype=self.compute_dtype)\n-    return tf.TensorSpec(shape=output_shape, dtype=self.compute_dtype)\n+          shape=output_shape, dtype=output_dtype)\n+    return tf.TensorSpec(shape=output_shape, dtype=output_dtype)\n \n   def call(self, inputs):\n     def bucketize(inputs):\n-      return tf.raw_ops.Bucketize(input=inputs, boundaries=self.bin_boundaries)\n+      outputs = tf.raw_ops.Bucketize(\n+          input=inputs, boundaries=self.bin_boundaries)\n+      # All other preprocessing layers use int64 for int output, so we conform\n+      # here. Sadly the underlying op only supports int32, so we need to cast.\n+      return tf.cast(outputs, tf.int64)\n \n     if tf_utils.is_ragged(inputs):\n-      indices = tf.ragged.map_flat_values(bucketize, inputs)\n+      integer_buckets = tf.ragged.map_flat_values(bucketize, inputs)\n+      # Ragged map_flat_values doesn't touch the non-values tensors in the\n+      # ragged composite tensor. If this op is the only op a Keras model,\n+      # this can cause errors in Graph mode, so wrap the tensor in an identity.\n+      return tf.identity(integer_buckets)\n     elif tf_utils.is_sparse(inputs):\n-      indices = tf.SparseTensor(\n+      return tf.SparseTensor(\n           indices=tf.identity(inputs.indices),\n           values=bucketize(inputs.values),\n           dense_shape=tf.identity(inputs.dense_shape))\n     else:\n-      indices = bucketize(inputs)\n-\n-    return utils.encode_categorical_inputs(\n-        indices,\n-        output_mode=self.output_mode,\n-        depth=len(self.bin_boundaries) + 1,\n-        sparse=self.sparse,\n-        dtype=self.compute_dtype)\n+      return bucketize(inputs)\n\n@@ -14,9 +14,11 @@\n # ==============================================================================\n \"\"\"Tests for Keras discretization preprocessing layer.\"\"\"\n \n+\n import os\n \n from absl.testing import parameterized\n+\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n@@ -119,89 +121,17 @@ class DiscretizationTest(keras_parameterized.TestCase,\n     self.assertAllEqual(indices, output_dataset.indices)\n     self.assertAllEqual(expected_output, output_dataset.values)\n \n-  def test_one_hot_output(self):\n-    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n-\n-    expected_output = [[1., 0., 0., 0.],\n-                       [0., 0., 1., 0.],\n-                       [0., 0., 0., 1.],\n-                       [0., 0., 0., 1.]]\n-    expected_output_shape = [None, 4]\n-\n-    inputs = keras.Input(shape=(1,))\n-    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n-                                          output_mode=\"one_hot\")\n-    outputs = layer(inputs)\n-    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n-\n-    model = keras.Model(inputs, outputs)\n-    output_data = model(input_data)\n-    self.assertAllEqual(expected_output, output_data)\n-\n-  def test_multi_hot_output(self):\n-    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n-\n-    expected_output = [1., 0., 1., 1.]\n-    expected_output_shape = [None, 4]\n-\n-    inputs = keras.Input(shape=(4,))\n-    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n-                                          output_mode=\"multi_hot\")\n-    outputs = layer(inputs)\n-    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n-\n-    model = keras.Model(inputs, outputs)\n-    output_data = model(input_data)\n-    self.assertAllEqual(expected_output, output_data)\n-\n-  def test_count_output(self):\n-    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n-\n-    expected_output = [1., 0., 1., 2.]\n-    expected_output_shape = [None, 4]\n-\n-    inputs = keras.Input(shape=(4,))\n-    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n-                                          output_mode=\"count\")\n-    outputs = layer(inputs)\n-    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n-\n-    model = keras.Model(inputs, outputs)\n-    output_data = model(input_data)\n-    self.assertAllEqual(expected_output, output_data)\n-\n   def test_output_shape(self):\n-    inputs = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n+    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n     layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n-    outputs = layer(inputs)\n-    self.assertAllEqual(outputs.shape.as_list(), [16, 4])\n+    output = layer(input_data)\n+    self.assertAllEqual(output.shape.as_list(), [16, 4])\n \n-  @parameterized.named_parameters(\n-      (\"int32\", tf.int32),\n-      (\"int64\", tf.int64),\n-  )\n-  def test_output_dtype(self, dtype):\n-    inputs = keras.Input(batch_size=16, shape=(4,), dtype=\"float32\")\n-    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n-                                          dtype=dtype)\n-    outputs = layer(inputs)\n-    self.assertAllEqual(outputs.dtype, dtype)\n-\n-  def test_int_output_float_dtype_fails(self):\n-    with self.assertRaisesRegex(ValueError, \"`dtype` should be an integer\"):\n-      discretization.Discretization(bin_boundaries=[-.5], dtype=\"float32\")\n-\n-  @parameterized.named_parameters(\n-      (\"float32\", tf.float32),\n-      (\"float64\", tf.float64),\n-  )\n-  def test_one_hot_output_dtype(self, dtype):\n-    inputs = keras.Input(batch_size=16, shape=(1,), dtype=\"float32\")\n-    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n-                                          output_mode=\"one_hot\",\n-                                          dtype=dtype)\n-    outputs = layer(inputs)\n-    self.assertAllEqual(outputs.dtype, dtype)\n+  def test_output_dtype(self):\n+    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n+    output = layer(input_data)\n+    self.assertAllEqual(output.dtype, tf.int64)\n \n   def test_num_bins_negative_fails(self):\n     with self.assertRaisesRegex(ValueError, \"`num_bins` must be.*num_bins=-7\"):\n\n@@ -88,7 +88,7 @@ def encode_categorical_inputs(inputs,\n                               idf_weights=None):\n   \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n   if output_mode == INT:\n-    return tf.identity(tf.cast(inputs, dtype))\n+    return tf.cast(inputs, dtype)\n \n   original_shape = inputs.shape\n   # In all cases, we should uprank scalar input to a single sample.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c807dff3d23a1c4e06dbb478f98a9d4a84320bd", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 25 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 25 | Churn Cumulative: 7488 | Contributors (this commit): 7 | Commits (past 90d): 22 | Contributors (cumulative): 13 | DMM Complexity: 1.0\n\nDIFF:\n@@ -363,6 +363,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n         \"oov_token\": self.oov_token,\n         \"mask_token\": self.mask_token,\n         \"output_mode\": self.output_mode,\n+        \"sparse\": self.sparse,\n         \"pad_to_max_tokens\": self.pad_to_max_tokens,\n         \"vocabulary\": utils.listify_tensors(self.input_vocabulary),\n         \"vocabulary_dtype\": self.vocabulary_dtype,\n\n@@ -2365,6 +2365,30 @@ class IndexLookupSavingTest(keras_parameterized.TestCase,\n     new_output_dataset = model.predict(input_array)\n     self.assertAllEqual(new_output_dataset, expected_output)\n \n+  def test_sparse_output_across_saving(self):\n+    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n+    input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n+                            [\"fire\", \"and\", \"earth\", \"michigan\"]])\n+\n+    expected_output = [[0., 1., 1., 1., 1.], [1., 1., 0., 1., 1.]]\n+\n+    layer_cls = index_lookup.IndexLookup\n+    layer = layer_cls(\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        mask_token=\"\",\n+        oov_token=\"[OOV]\",\n+        vocabulary_dtype=tf.string,\n+        vocabulary=vocab_data,\n+        output_mode=\"multi_hot\",\n+        sparse=True)\n+    config = layer.get_config()\n+    layer = layer_cls.from_config(config)\n+\n+    output = layer(input_array)\n+    self.assertIsInstance(output, tf.SparseTensor)\n+    self.assertAllEqual(tf.sparse.to_dense(output), expected_output)\n+\n \n class EagerExecutionDisabled(keras_parameterized.TestCase,\n                              preprocessing_test_utils.PreprocessingLayerTest):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#753880ec2a0103c3ee01d9a9e923160e9c7e0e1a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1276 | Contributors (this commit): 4 | Commits (past 90d): 1 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -174,7 +174,7 @@ class PreprocessingLayer(Layer, metaclass=abc.ABCMeta):\n \n     `tf.keras.Model` example with multiple adapts:\n \n-    >>> layer = tf.keras.layers.experimental.preprocessing.Normalization(\n+    >>> layer = tf.keras.layers.Normalization(\n     ...     axis=None)\n     >>> layer.adapt([0, 2])\n     >>> model = tf.keras.Sequential(layer)\n@@ -187,7 +187,7 @@ class PreprocessingLayer(Layer, metaclass=abc.ABCMeta):\n \n     `tf.data.Dataset` example with multiple adapts:\n \n-    >>> layer = tf.keras.layers.experimental.preprocessing.Normalization(\n+    >>> layer = tf.keras.layers.Normalization(\n     ...     axis=None)\n     >>> layer.adapt([0, 2])\n     >>> input_ds = tf.data.Dataset.range(3)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#466fccbb1eddc0aba4463ce791d17f86e6ade168", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 42 | Lines Deleted: 17 | Files Changed: 2 | Hunks: 15 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 59 | Churn Cumulative: 987 | Contributors (this commit): 6 | Commits (past 90d): 10 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -48,8 +48,8 @@ MODEL_LIST_NO_NASNET = [\n     (inception_resnet_v2.InceptionResNetV2, 1536),\n     (mobilenet.MobileNet, 1024),\n     (mobilenet_v2.MobileNetV2, 1280),\n-    (mobilenet_v3.MobileNetV3Small, 1024),\n-    (mobilenet_v3.MobileNetV3Large, 1280),\n+    (mobilenet_v3.MobileNetV3Small, 576),\n+    (mobilenet_v3.MobileNetV3Large, 960),\n     (densenet.DenseNet121, 1024),\n     (densenet.DenseNet169, 1664),\n     (densenet.DenseNet201, 1920),\n@@ -70,6 +70,23 @@ NASNET_LIST = [\n \n MODEL_LIST = MODEL_LIST_NO_NASNET + NASNET_LIST\n \n+# Parameters for loading weights for MobileNetV3.\n+# (class, alpha, minimalistic, include_top)\n+MOBILENET_V3_FOR_WEIGHTS = [\n+    (mobilenet_v3.MobileNetV3Large, 0.75, False, False),\n+    (mobilenet_v3.MobileNetV3Large, 1.0, False, False),\n+    (mobilenet_v3.MobileNetV3Large, 1.0, True, False),\n+    (mobilenet_v3.MobileNetV3Large, 0.75, False, True),\n+    (mobilenet_v3.MobileNetV3Large, 1.0, False, True),\n+    (mobilenet_v3.MobileNetV3Large, 1.0, True, True),\n+    (mobilenet_v3.MobileNetV3Small, 0.75, False, False),\n+    (mobilenet_v3.MobileNetV3Small, 1.0, False, False),\n+    (mobilenet_v3.MobileNetV3Small, 1.0, True, False),\n+    (mobilenet_v3.MobileNetV3Small, 0.75, False, True),\n+    (mobilenet_v3.MobileNetV3Small, 1.0, False, True),\n+    (mobilenet_v3.MobileNetV3Small, 1.0, True, True),\n+]\n+\n \n class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n@@ -93,7 +110,7 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n \n   @parameterized.parameters(*MODEL_LIST)\n   def test_application_notop(self, app, last_dim):\n-    if 'NASNet' or 'MobileNetV3' in app.__name__:\n+    if 'NASNet' in app.__name__:\n       only_check_last_dim = True\n     else:\n       only_check_last_dim = False\n@@ -119,9 +136,6 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 1)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n-    if 'MobileNetV3' in app.__name__:\n-      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n-    else:\n     self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n@@ -131,12 +145,23 @@ class ApplicationsTest(tf.test.TestCase, parameterized.TestCase):\n       input_shape = (None, None, 4)\n     output_shape = _get_output_shape(\n         lambda: app(weights=None, include_top=False, input_shape=input_shape))\n-    if 'MobileNetV3' in app.__name__:\n-      self.assertShapeEqual(output_shape, (None, 1, 1, last_dim))\n-    else:\n     self.assertShapeEqual(output_shape, (None, None, None, last_dim))\n     backend.clear_session()\n \n+  @parameterized.parameters(*MOBILENET_V3_FOR_WEIGHTS)\n+  def test_mobilenet_v3_load_weights(\n+      self,\n+      mobilenet_class,\n+      alpha,\n+      minimalistic,\n+      include_top):\n+    mobilenet_class(\n+        input_shape=(224, 224, 3),\n+        weights='imagenet',\n+        alpha=alpha,\n+        minimalistic=minimalistic,\n+        include_top=include_top)\n+\n \n def _get_output_shape(model_fn):\n   model = model_fn()\n\n@@ -33,17 +33,17 @@ BASE_WEIGHT_PATH = ('https://storage.googleapis.com/tensorflow/'\n                     'keras-applications/mobilenet_v3/')\n WEIGHTS_HASHES = {\n     'large_224_0.75_float': ('765b44a33ad4005b3ac83185abf1d0eb',\n-                             'e7b4d1071996dd51a2c2ca2424570e20'),\n+                             '40af19a13ebea4e2ee0c676887f69a2e'),\n     'large_224_1.0_float': ('59e551e166be033d707958cf9e29a6a7',\n-                            '037116398e07f018c0005ffcb0406831'),\n+                            '07fb09a5933dd0c8eaafa16978110389'),\n     'large_minimalistic_224_1.0_float': ('675e7b876c45c57e9e63e6d90a36599c',\n-                                         'a2c33aed672524d1d0b4431808177695'),\n+                                         'ec5221f64a2f6d1ef965a614bdae7973'),\n     'small_224_0.75_float': ('cb65d4e5be93758266aa0a7f2c6708b7',\n-                             '4d2fe46f1c1f38057392514b0df1d673'),\n+                             'ebdb5cc8e0b497cd13a7c275d475c819'),\n     'small_224_1.0_float': ('8768d4c2e7dee89b9d02b2d03d65d862',\n-                            'be7100780f875c06bcab93d76641aa26'),\n+                            'd3e8ec802a04aa4fc771ee12a9a9b836'),\n     'small_minimalistic_224_1.0_float': ('99cd97fb2fcdad2bf028eb838de69e37',\n-                                         '20d4e357df3f7a6361f3a288857b1051'),\n+                                         'cde8136e733e811080d9fcd8a252f7e4'),\n }\n \n layers = VersionAwareLayers()\n@@ -310,6 +310,7 @@ def MobileNetV3(stack_fn,\n       axis=channel_axis, epsilon=1e-3,\n       momentum=0.999, name='Conv_1/BatchNorm')(x)\n   x = activation(x)\n+  if include_top:\n     x = layers.GlobalAveragePooling2D(keepdims=True)(x)\n     x = layers.Conv2D(\n         last_point_ch,\n@@ -319,7 +320,6 @@ def MobileNetV3(stack_fn,\n         name='Conv_2')(x)\n     x = activation(x)\n \n-  if include_top:\n     if dropout_rate > 0:\n       x = layers.Dropout(dropout_rate)(x)\n     x = layers.Conv2D(classes, kernel_size=1, padding='same', name='Logits')(x)\n@@ -350,7 +350,7 @@ def MobileNetV3(stack_fn,\n       file_name = 'weights_mobilenet_v3_' + model_name + '.h5'\n       file_hash = WEIGHTS_HASHES[model_name][0]\n     else:\n-      file_name = 'weights_mobilenet_v3_' + model_name + '_no_top.h5'\n+      file_name = 'weights_mobilenet_v3_' + model_name + '_no_top_v2.h5'\n       file_hash = WEIGHTS_HASHES[model_name][1]\n     weights_path = data_utils.get_file(\n         file_name,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2e7ebd9647cc061a6f4a1eca4932b6dc4b5d4c08", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/1 | Churn Δ: 27 | Churn Cumulative: 4520 | Contributors (this commit): 28 | Commits (past 90d): 4 | Contributors (cumulative): 31 | DMM Complexity: 1.0\n\nDIFF:\n@@ -508,6 +508,10 @@ class Bidirectional(Wrapper):\n     self._num_constants = 0\n     self.input_spec = layer.input_spec\n \n+  @property\n+  def _use_input_spec_as_call_signature(self):\n+    return self.layer._use_input_spec_as_call_signature\n+\n   def _verify_layer_config(self):\n     \"\"\"Ensure the forward and backward layers have valid common property.\"\"\"\n     if self.forward_layer.go_backwards == self.backward_layer.go_backwards:\n\n@@ -819,6 +819,29 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     self.assertAllClose(layer.states, loaded_layer.states)\n     self.assertAllClose(model(input_arr), loaded(input_arr))\n \n+  def testSaveBidirectionalLSTM(self):\n+    # Make sure that the input spec of an unrolled RNN is not used when wrapped\n+    # in a Bidirectional layer. https://github.com/keras-team/keras/issues/15454\n+    input_layer = keras.Input(\n+        batch_input_shape=(1, 15, 128), name='input', dtype=tf.float32)\n+    lstm_layer = keras.layers.Bidirectional(\n+        keras.layers.LSTM(\n+            units=64,\n+            name='lstm',\n+            dropout=0.2,\n+            trainable=False,\n+            unroll=True,\n+        )\n+    )\n+    output_layer = lstm_layer(input_layer)\n+    model = keras.Model(input_layer, output_layer)\n+    saved_model_dir = self._save_model_dir()\n+    self.evaluate(tf.compat.v1.variables_initializer(model.variables))\n+    model.save(saved_model_dir, save_format='tf')\n+    loaded = keras_load.load(saved_model_dir)\n+    input_arr = np.random.random((1, 15, 128)).astype('float32')\n+    self.assertAllClose(model(input_arr), loaded(input_arr))\n+\n   @parameterized.named_parameters([('stateful', True), ('stateless', False)])\n   def testSaveConvLSTM2D(self, stateful):\n     data_format = 'channels_first'\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#66290dec4381ebd9f618aa4d43360fd10866a9ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 66 | Lines Deleted: 221 | Files Changed: 2 | Hunks: 13 | Methods Changed: 15 | Complexity Δ (Sum/Max): -1/2 | Churn Δ: 287 | Churn Cumulative: 7775 | Contributors (this commit): 7 | Commits (past 90d): 24 | Contributors (cumulative): 13 | DMM Complexity: 0.0\n\nDIFF:\n@@ -518,7 +518,7 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n           idf_weights, (front_padding, back_padding),\n           \"constant\",\n           constant_values=(front_padding_value, back_padding_value))\n-      weights = tf.convert_to_tensor(weights, dtype=backend.floatx())\n+      weights = tf.convert_to_tensor(weights, dtype=self.compute_dtype)\n       self.idf_weights.assign(weights)\n       self.idf_weights_const = self.idf_weights.value()\n \n@@ -530,9 +530,10 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n \n     data = self._standardize_inputs(data, self.vocabulary_dtype)\n     if data.shape.rank == 0:\n-      data = tf.expand_dims(data, -1)\n+      data = tf.expand_dims(data, 0)\n     if data.shape.rank == 1:\n-      data = tf.expand_dims(data, -1)\n+      # Expand dims on axis 0 for tf-idf. A 1-d tensor is a single document.\n+      data = tf.expand_dims(data, 0)\n \n     tokens, counts = self._num_tokens(data)\n     self.token_counts.insert(tokens, counts + self.token_counts.lookup(tokens))\n@@ -581,12 +582,17 @@ class IndexLookup(base_preprocessing_layer.PreprocessingLayer):\n       token_document_counts = self.token_document_counts.lookup(tokens)\n       idf_weights = self._inverse_document_frequency(token_document_counts,\n                                                      self.num_documents)\n-      idf_weights = tf.cast(idf_weights, backend.floatx())\n+      idf_weights = tf.cast(idf_weights, self.compute_dtype)\n       # Pad the front of idf_weights with the average idf weight for OOV tokens.\n       # We cannot compute the real idf weight of OOV in a single pass.\n       idf_weights = tf.pad(\n           idf_weights, [[self._token_start_index(), 0]],\n           constant_values=tf.reduce_mean(idf_weights))\n+      if self.pad_to_max_tokens and self.max_tokens is not None:\n+        # Pad the back of idf_weights with zeros.\n+        idf_weights = tf.pad(\n+            idf_weights, [[0, self.max_tokens - tf.size(idf_weights)]],\n+            constant_values=0)\n       self.idf_weights.assign(idf_weights)\n       self.idf_weights_const = self.idf_weights.value()\n \n\n@@ -15,6 +15,7 @@\n \"\"\"Tests for Keras text vectorization preprocessing layer.\"\"\"\n \n import itertools\n+import math\n import os\n import random\n import string\n@@ -979,51 +980,71 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     outputs = layer(inputs)\n     self.assertAllEqual(outputs.shape.as_list(), [16, 2])\n \n-  @parameterized.named_parameters(\n-      (\"float32\", tf.float32),\n-      (\"float64\", tf.float64),\n+  @parameterized.product(\n+      sparse=[True, False],\n+      adapt=[True, False],\n+      pad_to_max=[True, False],\n+      mode=[\"multi_hot\", \"count\", \"tf_idf\"],\n+      dtype=[tf.float32, tf.float64],\n   )\n-  def test_one_hot_output_dtype(self, dtype):\n-    inputs = keras.Input(batch_size=16, shape=(1,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        vocabulary=[\"earth\"],\n-        max_tokens=2,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.ONE_HOT,\n-        vocabulary_dtype=tf.string,\n-        dtype=dtype)\n-    outputs = layer(inputs)\n-    self.assertAllEqual(outputs.dtype, dtype)\n+  def test_binned_output(self, sparse, adapt, pad_to_max, mode, dtype):\n+    \"\"\"Check \"multi_hot\", \"count\", and \"tf_idf\" output.\"\"\"\n+    # Adapt breaks ties with sort order.\n+    vocab_data = [\"wind\", \"fire\", \"earth\", \"and\"]\n+    # IDF weight for a term in 1 out of 1 document is log(1 + 1/2).\n+    idf_data = [math.log(1.5)] * 4\n+    input_data = np.array([[\"and\", \"earth\", \"fire\", \"and\", \"\"],\n+                           [\"michigan\", \"wind\", \"and\", \"ohio\", \"\"]])\n \n-  def test_multi_hot_output_hard_maximum(self):\n-    \"\"\"Check binary output when pad_to_max_tokens=True.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\", \"\"],\n-                            [\"fire\", \"fire\", \"and\", \"earth\", \"michigan\"]])\n-    expected_output = [\n-        [0, 1, 1, 1, 1, 0],\n-        [1, 1, 0, 1, 1, 0],\n-    ]\n+    if mode == \"count\":\n+      expected_output = np.array([\n+          [0, 0, 1, 1, 2],\n+          [2, 1, 0, 0, 1],\n+      ])\n+    elif mode == \"tf_idf\":\n+      expected_output = np.array([\n+          [0, 0, 1, 1, 2],\n+          [2, 1, 0, 0, 1],\n+      ]) * math.log(1.5)\n+    else:\n+      expected_output = np.array([\n+          [0, 0, 1, 1, 1],\n+          [1, 1, 0, 0, 1],\n+      ])\n+    expected_output_shape = [None, 5]\n+    if pad_to_max:\n+      expected_output = np.concatenate((expected_output, [[0], [0]]), axis=1)\n+      expected_output_shape = [None, 6]\n \n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n+    inputs = keras.Input(shape=(None,), dtype=tf.string)\n     layer = index_lookup.IndexLookup(\n         max_tokens=6,\n         num_oov_indices=1,\n         mask_token=\"\",\n         oov_token=\"[OOV]\",\n-        output_mode=index_lookup.MULTI_HOT,\n-        pad_to_max_tokens=True,\n-        vocabulary_dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n-    binary_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=binary_data)\n-    output_dataset = model.predict(input_array)\n-    self.assertAllEqual(expected_output, output_dataset)\n+        output_mode=mode,\n+        pad_to_max_tokens=pad_to_max,\n+        vocabulary_dtype=tf.string,\n+        sparse=sparse,\n+        vocabulary=None if adapt else vocab_data,\n+        idf_weights=None if adapt or mode != \"tf_idf\" else idf_data,\n+        dtype=dtype)\n+    if adapt:\n+      layer.adapt(vocab_data)\n+    outputs = layer(inputs)\n+    model = keras.Model(inputs, outputs)\n+    output_data = model.predict(input_data)\n+    if sparse:\n+      output_data = tf.sparse.to_dense(output_data)\n+    # Check output data.\n+    self.assertAllClose(expected_output, output_data)\n+    # Check symbolic output shape.\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+    # Check output dtype.\n+    self.assertAllEqual(dtype, output_data.dtype)\n \n   def test_multi_hot_output_no_oov(self):\n-    \"\"\"Check binary output when pad_to_max_tokens=True.\"\"\"\n+    \"\"\"Check multi hot output when num_oov_indices=0.\"\"\"\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     valid_input = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n                             [\"fire\", \"and\", \"earth\", \"\"]])\n@@ -1092,188 +1113,6 @@ class IndexLookupOutputTest(keras_parameterized.TestCase,\n     self.assertAllEqual(first_expected_output, first_output)\n     self.assertAllEqual(second_expected_output, second_output)\n \n-  def test_multi_hot_output_soft_maximum(self):\n-    \"\"\"Check multi_hot output when pad_to_max_tokens=False.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\", \"\"],\n-                            [\"fire\", \"and\", \"earth\", \"michigan\", \"\"]])\n-    expected_output = [\n-        [0, 1, 1, 1, 1],\n-        [1, 1, 0, 1, 1],\n-    ]\n-\n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=None,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.MULTI_HOT,\n-        vocabulary_dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n-    binary_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=binary_data)\n-    output_dataset = model.predict(input_array)\n-    self.assertAllEqual(expected_output, output_dataset)\n-\n-  def test_multi_hot_output_shape(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=2,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.MULTI_HOT,\n-        vocabulary=[\"foo\"],\n-        vocabulary_dtype=tf.string)\n-    binary_data = layer(input_data)\n-    self.assertAllEqual(binary_data.shape.as_list(), [16, 2])\n-\n-  def test_count_output_hard_maxiumum(self):\n-    \"\"\"Check count output when pad_to_max_tokens=True.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"wind\", \"\"],\n-                            [\"fire\", \"fire\", \"fire\", \"michigan\", \"\"]])\n-    expected_output = [\n-        [0, 1, 2, 1, 0, 0],\n-        [1, 0, 0, 0, 3, 0],\n-    ]\n-\n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=6,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.COUNT,\n-        pad_to_max_tokens=True,\n-        vocabulary_dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n-    count_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=count_data)\n-    output_dataset = model.predict(input_array)\n-    self.assertAllEqual(expected_output, output_dataset)\n-\n-  def test_count_output_soft_maximum(self):\n-    \"\"\"Check count output when pad_to_max_tokens=False.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"wind\", \"\"],\n-                            [\"fire\", \"fire\", \"fire\", \"michigan\", \"\"]])\n-    expected_output = [\n-        [0, 1, 2, 1, 0],\n-        [1, 0, 0, 0, 3],\n-    ]\n-\n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=None,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.COUNT,\n-        vocabulary_dtype=tf.string)\n-    layer.set_vocabulary(vocab_data)\n-    count_data = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=count_data)\n-    output_dataset = model.predict(input_array)\n-    self.assertAllEqual(expected_output, output_dataset)\n-\n-  def test_count_output_shape(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=2,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.COUNT,\n-        vocabulary=[\"foo\"],\n-        vocabulary_dtype=tf.string)\n-    count_data = layer(input_data)\n-    self.assertAllEqual(count_data.shape.as_list(), [16, 2])\n-\n-  @parameterized.named_parameters(\n-      (\"sparse\", True),\n-      (\"dense\", False),\n-  )\n-  def test_ifidf_output_hard_maximum(self, sparse):\n-    \"\"\"Check tf-idf output when pad_to_max_tokens=True.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n-    idf_weights = [.4, .25, .75, .6]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\", \"\"],\n-                            [\"ohio\", \"fire\", \"earth\", \"michigan\", \"\"]])\n-    expected_output = [\n-        [0.00, 0.80, 0.25, 0.75, 0.00, 0.00],\n-        [1.00, 0.40, 0.00, 0.00, 0.60, 0.00],\n-    ]\n-\n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=6,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.TF_IDF,\n-        pad_to_max_tokens=True,\n-        vocabulary_dtype=tf.string,\n-        sparse=sparse,\n-        vocabulary=vocab_data,\n-        idf_weights=idf_weights)\n-    layer_output = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=layer_output)\n-    output_dataset = model.predict(input_array)\n-    if sparse:\n-      output_dataset = tf.sparse.to_dense(output_dataset)\n-    self.assertAllClose(expected_output, output_dataset)\n-\n-  @parameterized.named_parameters(\n-      (\"sparse\", True),\n-      (\"dense\", False),\n-  )\n-  def test_ifidf_output_soft_maximum(self, sparse):\n-    \"\"\"Check tf-idf output when pad_to_max_tokens=False.\"\"\"\n-    vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n-    # OOV idf weight (bucket 0) should 0.5, the average of passed weights.\n-    idf_weights = [.4, .25, .75, .6]\n-    input_array = np.array([[\"earth\", \"wind\", \"and\", \"earth\", \"\"],\n-                            [\"ohio\", \"fire\", \"earth\", \"michigan\", \"\"]])\n-    expected_output = [\n-        [0.00, 0.80, 0.25, 0.75, 0.00],\n-        [1.00, 0.40, 0.00, 0.00, 0.60],\n-    ]\n-\n-    input_data = keras.Input(shape=(None,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=None,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.TF_IDF,\n-        vocabulary_dtype=tf.string,\n-        sparse=sparse,\n-        vocabulary=vocab_data,\n-        idf_weights=idf_weights)\n-    layer_output = layer(input_data)\n-    model = keras.Model(inputs=input_data, outputs=layer_output)\n-    output_dataset = model.predict(input_array)\n-    if sparse:\n-      output_dataset = tf.sparse.to_dense(output_dataset)\n-    self.assertAllClose(expected_output, output_dataset)\n-\n-  def test_ifidf_output_shape(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.string)\n-    layer = index_lookup.IndexLookup(\n-        max_tokens=2,\n-        num_oov_indices=1,\n-        mask_token=\"\",\n-        oov_token=\"[OOV]\",\n-        output_mode=index_lookup.TF_IDF,\n-        vocabulary_dtype=tf.string,\n-        vocabulary=[\"foo\"],\n-        idf_weights=[1.0])\n-    layer_output = layer(input_data)\n-    self.assertAllEqual(layer_output.shape.as_list(), [16, 2])\n-\n   def test_int_output_file_vocab(self):\n     vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n     input_array = np.array([[\"earth\", \"wind\", \"and\", \"fire\"],\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5817ec5745a844a924065c19f4a9ee1cc4a5c66e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 7 | Churn Cumulative: 9303 | Contributors (this commit): 25 | Commits (past 90d): 5 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -121,7 +121,7 @@ class Metric(base_layer.Layer, metaclass=abc.ABCMeta):\n     calling `self.add_weight()` like: `self.var = self.add_weight(...)`\n   * `update_state()`: Has all updates to the state variables like:\n     self.var.assign_add(...).\n-  * `result()`: Computes and returns a value for the metric\n+  * `result()`: Computes and returns a scalar value for the metric\n     from the state variables.\n \n   Example subclass implementation:\n@@ -323,10 +323,13 @@ class Metric(base_layer.Layer, metaclass=abc.ABCMeta):\n \n   @abc.abstractmethod\n   def result(self):\n-    \"\"\"Computes and returns the metric value tensor.\n+    \"\"\"Computes and returns the scalar metric value tensor.\n \n     Result computation is an idempotent operation that simply calculates the\n     metric value using the state variables.\n+\n+    Returns:\n+      A scalar tensor, or a dictionary of scalar tensors.\n     \"\"\"\n     raise NotImplementedError('Must be implemented in subclasses.')\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9b920a8ebdb42b5a518b33fac7eee5ce5519bab1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 7 | Methods Changed: 1 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 9 | Churn Cumulative: 7284 | Contributors (this commit): 97 | Commits (past 90d): 14 | Contributors (cumulative): 97 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1253,6 +1253,9 @@ class ModelCheckpoint(Callback):\n       options: Optional `tf.train.CheckpointOptions` object if\n         `save_weights_only` is true or optional `tf.saved_model.SaveOptions`\n         object if `save_weights_only` is false.\n+      initial_best: Initial best value of the metric to be monitored before\n+        training begins. Only overwrites the model weights already saved, if the\n+        performance of current model is better than the previous saved model.\n       **kwargs: Additional arguments for backwards compatibility. Possible key\n         is `period`.\n   \"\"\"\n@@ -1266,6 +1269,7 @@ class ModelCheckpoint(Callback):\n                mode='auto',\n                save_freq='epoch',\n                options=None,\n+               initial_best= None,\n                **kwargs):\n     super(ModelCheckpoint, self).__init__()\n     self._supports_tf_logs = True\n@@ -1278,6 +1282,7 @@ class ModelCheckpoint(Callback):\n     self.epochs_since_last_save = 0\n     self._batches_seen_since_last_saving = 0\n     self._last_batch_seen = 0\n+    self.best= initial_best\n \n     if save_weights_only:\n       if options is None or isinstance(\n@@ -1322,16 +1327,20 @@ class ModelCheckpoint(Callback):\n \n     if mode == 'min':\n       self.monitor_op = np.less\n+      if self.best is None:\n         self.best = np.Inf\n     elif mode == 'max':\n       self.monitor_op = np.greater\n+      if self.best is None:\n         self.best = -np.Inf\n     else:\n       if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n         self.monitor_op = np.greater\n+        if self.best is None:\n           self.best = -np.Inf\n       else:\n         self.monitor_op = np.less\n+        if self.best is None:\n           self.best = np.Inf\n \n     if self.save_freq != 'epoch' and not isinstance(self.save_freq, int):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d50204860d11ede18ee9ce809f908f5be8a7df69", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 13 | Files Changed: 4 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): -14/0 | Churn Δ: 30 | Churn Cumulative: 6122 | Contributors (this commit): 36 | Commits (past 90d): 15 | Contributors (cumulative): 48 | DMM Complexity: 0.5\n\nDIFF:\n@@ -186,7 +186,8 @@ class PreprocessingLayerTest(keras_parameterized.TestCase):\n     output_path = os.path.join(self.get_temp_dir(), \"tf_keras_saved_model\")\n     model.save(output_path, save_format=\"tf\")\n \n-    with self.assertRaisesRegex(RuntimeError, \"Unable to restore a layer of\"):\n+    with self.assertRaisesRegex(ValueError,\n+                                \"Unknown layer: AddingPreprocessingLayer\"):\n       _ = keras.models.load_model(output_path)\n \n   def test_adapt_sets_input_shape_rank(self):\n\n@@ -538,16 +538,9 @@ class KerasObjectLoader:\n             '`keras.utils.CustomObjectScope` that wraps this load call.') from e\n       else:\n         raise\n-    except ValueError:\n+    except ValueError as e:\n       if must_restore_from_config:\n-        raise RuntimeError(\n-            f'Unable to restore a layer of class {class_name}. Layers of '\n-            f'class {class_name} require that the class be provided to '\n-            'the model loading code, either by registering the '\n-            'class using `@keras.utils.register_keras_serializable` '\n-            'on the class def and including that file in your '\n-            'program, or by passing the class in a '\n-            '`keras.utils.CustomObjectScope` that wraps this load call.')\n+        raise e\n       else:\n         return None\n \n\n@@ -386,7 +386,8 @@ class TestSavedModelFormatAllModes(keras_parameterized.TestCase):\n     model = testing_utils.get_model_from_layers(\n         [layer], input_shape=[3], model_type='functional')\n     model.save(saved_model_dir, save_format='tf')\n-    with self.assertRaisesRegex(RuntimeError, 'Unable to restore a layer of'):\n+    with self.assertRaisesRegex(ValueError,\n+                                'Unknown layer: LayerThatShouldFailIfNotAdded'):\n       _ = keras_load.load(saved_model_dir)\n \n   def test_must_restore_from_config_custom_object_scope(self):\n\n@@ -80,9 +80,18 @@ def validate_string_arg(input_data,\n     allowed_args = '`None`, ' if allow_none else ''\n     allowed_args += 'a `Callable`, ' if allow_callables else ''\n     allowed_args += 'or one of the following values: %s' % (allowable_strings,)\n+    if allow_callables:\n+      callable_note = (\n+          f'If restoring a model and `{arg_name}` is a custom callable, '\n+          'please ensure the callable is registered as a custom object. '\n+          'See https://www.tensorflow.org/guide/keras/save_and_serialize'\n+          '#registering_the_custom_object for details. ')\n+    else:\n+      callable_note = ''\n     raise ValueError(\n-        f'The `{arg_name}` argument of layer {layer_name} received an invalid '\n-        f'value `{input_data}`. Allowed values are: {allowed_args}.')\n+        f'Unkown value for `{arg_name}` argument of layer {layer_name}. '\n+        f'{callable_note}Allowed values are: {allowed_args}. Received: '\n+        f'{input_data}')\n \n \n def count_params(weights):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#abcbc40b0c2a5a065d2c60682f2c46aa1f59085a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 2 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 11 | Churn Cumulative: 1303 | Contributors (this commit): 6 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: 0.5\n\nDIFF:\n@@ -167,6 +167,9 @@ class Hashing(base_layer.Layer):\n     # By default, output int64 when output_mode='int' and floats otherwise.\n     if 'dtype' not in kwargs:\n       kwargs['dtype'] = tf.int64 if output_mode == INT else backend.floatx()\n+    elif output_mode == 'int' and not tf.as_dtype(kwargs['dtype']).is_integer:\n+      # Compat for when dtype was alwyas floating and ingored by the layer.\n+      kwargs['dtype'] = tf.int64\n \n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell('Hashing').set(True)\n\n@@ -313,9 +313,11 @@ class HashingTest(keras_parameterized.TestCase):\n     output = layer(input_data)\n     self.assertAllEqual(output.dtype, dtype)\n \n-  def test_int_output_float_dtype_fails(self):\n-    with self.assertRaisesRegex(ValueError, '`dtype` should be an integer'):\n-      hashing.Hashing(num_bins=3, dtype='string')\n+  def test_legacy_dtype_compat(self):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype='string')\n+    layer = hashing.Hashing(num_bins=3, dtype='float32')\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, tf.int64)\n \n   @parameterized.named_parameters(\n       ('float32', tf.float32),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3a60098e8de2fcef86aecec84c9a35c847a1ab18", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 158 | Lines Deleted: 27 | Files Changed: 3 | Hunks: 21 | Methods Changed: 14 | Complexity Δ (Sum/Max): 13/8 | Churn Δ: 185 | Churn Cumulative: 2204 | Contributors (this commit): 5 | Commits (past 90d): 15 | Contributors (cumulative): 9 | DMM Complexity: 0.7215189873417721\n\nDIFF:\n@@ -17,14 +17,21 @@\n # pylint: disable=g-classes-have-attributes\n # pylint: disable=g-direct-tensorflow-import\n \n+from keras import backend\n from keras.engine import base_preprocessing_layer\n from keras.layers.preprocessing import preprocessing_utils as utils\n+from keras.utils import layer_utils\n from keras.utils import tf_utils\n import numpy as np\n import tensorflow.compat.v2 as tf\n from tensorflow.python.platform import tf_logging as logging\n from tensorflow.python.util.tf_export import keras_export\n \n+INT = utils.INT\n+MULTI_HOT = utils.MULTI_HOT\n+ONE_HOT = utils.ONE_HOT\n+COUNT = utils.COUNT\n+\n \n def summarize(values, epsilon):\n   \"\"\"Reduce a 1D sequence of values to a summary.\n@@ -149,6 +156,25 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       0.01). Higher values of epsilon increase the quantile approximation, and\n       hence result in more unequal buckets, but could improve performance\n       and resource consumption.\n+    output_mode: Specification for the output of the layer. Defaults to `\"int\"`.\n+      Values can be `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, or `\"count\"`\n+      configuring the layer as follows:\n+        - `\"int\"`: Return the discritized bin indices directly.\n+        - `\"one_hot\"`: Encodes each individual element in the input into an\n+          array the same size as `num_bins`, containing a 1 at the input's bin\n+          index. If the last dimension is size 1, will encode on that dimension.\n+          If the last dimension is not size 1, will append a new dimension for\n+          the encoded output.\n+        - `\"multi_hot\"`: Encodes each sample in the input into a single array\n+          the same size as `num_bins`, containing a 1 for each bin index\n+          index present in the sample. Treats the last dimension as the sample\n+          dimension, if input shape is `(..., sample_length)`, output shape will\n+          be `(..., num_tokens)`.\n+        - `\"count\"`: As `\"multi_hot\"`, but the int array contains a count of the\n+          number of times the bin index appeared in the sample.\n+    sparse: Boolean. Only applicable to `\"one_hot\"`, `\"multi_hot\"`,\n+      and `\"count\"` output modes. If True, returns a `SparseTensor` instead of\n+      a dense `Tensor`. Defaults to False.\n \n   Examples:\n \n@@ -174,6 +200,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n                bin_boundaries=None,\n                num_bins=None,\n                epsilon=0.01,\n+               output_mode=\"int\",\n+               sparse=False,\n                **kwargs):\n     # bins is a deprecated arg for setting bin_boundaries or num_bins that still\n     # has some usage.\n@@ -185,9 +213,37 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n       elif bin_boundaries is None:\n         bin_boundaries = kwargs[\"bins\"]\n       del kwargs[\"bins\"]\n+\n+    # By default, output int64 when output_mode='int' and floats otherwise.\n+    if \"dtype\" not in kwargs:\n+      kwargs[\"dtype\"] = tf.int64 if output_mode == INT else backend.floatx()\n+    elif output_mode == \"int\" and not tf.as_dtype(kwargs[\"dtype\"]).is_integer:\n+      # Compat for when dtype was alwyas floating and ingored by the layer.\n+      kwargs[\"dtype\"] = tf.int64\n+\n     super().__init__(**kwargs)\n     base_preprocessing_layer.keras_kpl_gauge.get_cell(\"Discretization\").set(\n         True)\n+\n+    # Check dtype only after base layer parses it; dtype parsing is complex.\n+    if output_mode == INT and not tf.as_dtype(self.compute_dtype).is_integer:\n+      input_dtype = kwargs[\"dtype\"]\n+      raise ValueError(\"When `output_mode='int'`, `dtype` should be an integer \"\n+                       f\"type. Received: dtype={input_dtype}\")\n+\n+    # 'output_mode' must be one of (INT, ONE_HOT, MULTI_HOT, COUNT)\n+    layer_utils.validate_string_arg(\n+        output_mode,\n+        allowable_strings=(INT, ONE_HOT, MULTI_HOT, COUNT),\n+        layer_name=self.__class__.__name__,\n+        arg_name=\"output_mode\")\n+\n+    if sparse and output_mode == INT:\n+      raise ValueError(f\"`sparse` may only be true if `output_mode` is \"\n+                       f\"`'one_hot'`, `'multi_hot'`, or `'count'`. \"\n+                       f\"Received: sparse={sparse} and \"\n+                       f\"output_mode={output_mode}\")\n+\n     if num_bins is not None and num_bins < 0:\n       raise ValueError(\"`num_bins` must be greater than or equal to 0. \"\n                        \"You passed `num_bins={}`\".format(num_bins))\n@@ -200,6 +256,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n     self.bin_boundaries = bin_boundaries if bin_boundaries is not None else []\n     self.num_bins = num_bins\n     self.epsilon = epsilon\n+    self.output_mode = output_mode\n+    self.sparse = sparse\n \n   def build(self, input_shape):\n     super().build(input_shape)\n@@ -252,6 +310,8 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n         \"bin_boundaries\": self.input_bin_boundaries,\n         \"num_bins\": self.num_bins,\n         \"epsilon\": self.epsilon,\n+        \"output_mode\": self.output_mode,\n+        \"sparse\": self.sparse,\n     })\n     return config\n \n@@ -260,30 +320,28 @@ class Discretization(base_preprocessing_layer.PreprocessingLayer):\n \n   def compute_output_signature(self, input_spec):\n     output_shape = self.compute_output_shape(input_spec.shape.as_list())\n-    output_dtype = tf.int64\n     if isinstance(input_spec, tf.SparseTensorSpec):\n       return tf.SparseTensorSpec(\n-          shape=output_shape, dtype=output_dtype)\n-    return tf.TensorSpec(shape=output_shape, dtype=output_dtype)\n+          shape=output_shape, dtype=self.compute_dtype)\n+    return tf.TensorSpec(shape=output_shape, dtype=self.compute_dtype)\n \n   def call(self, inputs):\n     def bucketize(inputs):\n-      outputs = tf.raw_ops.Bucketize(\n-          input=inputs, boundaries=self.bin_boundaries)\n-      # All other preprocessing layers use int64 for int output, so we conform\n-      # here. Sadly the underlying op only supports int32, so we need to cast.\n-      return tf.cast(outputs, tf.int64)\n+      return tf.raw_ops.Bucketize(input=inputs, boundaries=self.bin_boundaries)\n \n     if tf_utils.is_ragged(inputs):\n-      integer_buckets = tf.ragged.map_flat_values(bucketize, inputs)\n-      # Ragged map_flat_values doesn't touch the non-values tensors in the\n-      # ragged composite tensor. If this op is the only op a Keras model,\n-      # this can cause errors in Graph mode, so wrap the tensor in an identity.\n-      return tf.identity(integer_buckets)\n+      indices = tf.ragged.map_flat_values(bucketize, inputs)\n     elif tf_utils.is_sparse(inputs):\n-      return tf.SparseTensor(\n+      indices = tf.SparseTensor(\n           indices=tf.identity(inputs.indices),\n           values=bucketize(inputs.values),\n           dense_shape=tf.identity(inputs.dense_shape))\n     else:\n-      return bucketize(inputs)\n+      indices = bucketize(inputs)\n+\n+    return utils.encode_categorical_inputs(\n+        indices,\n+        output_mode=self.output_mode,\n+        depth=len(self.bin_boundaries) + 1,\n+        sparse=self.sparse,\n+        dtype=self.compute_dtype)\n\n@@ -14,11 +14,9 @@\n # ==============================================================================\n \"\"\"Tests for Keras discretization preprocessing layer.\"\"\"\n \n-\n import os\n \n from absl.testing import parameterized\n-\n import keras\n from keras import keras_parameterized\n from keras import testing_utils\n@@ -121,17 +119,92 @@ class DiscretizationTest(keras_parameterized.TestCase,\n     self.assertAllEqual(indices, output_dataset.indices)\n     self.assertAllEqual(expected_output, output_dataset.values)\n \n-  def test_output_shape(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n-    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n-    output = layer(input_data)\n-    self.assertAllEqual(output.shape.as_list(), [16, 4])\n+  def test_one_hot_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n \n-  def test_output_dtype(self):\n-    input_data = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n+    expected_output = [[1., 0., 0., 0.],\n+                       [0., 0., 1., 0.],\n+                       [0., 0., 0., 1.],\n+                       [0., 0., 0., 1.]]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(1,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"one_hot\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_multi_hot_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n+\n+    expected_output = [1., 0., 1., 1.]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(4,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"multi_hot\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_count_output(self):\n+    input_data = np.array([-1.5, 1.0, 3.4, 3.5])\n+\n+    expected_output = [1., 0., 1., 2.]\n+    expected_output_shape = [None, 4]\n+\n+    inputs = keras.Input(shape=(4,))\n+    layer = discretization.Discretization(bin_boundaries=[0., 1., 2.],\n+                                          output_mode=\"count\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(expected_output_shape, outputs.shape.as_list())\n+\n+    model = keras.Model(inputs, outputs)\n+    output_data = model(input_data)\n+    self.assertAllEqual(expected_output, output_data)\n+\n+  def test_output_shape(self):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype=tf.int64)\n     layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5])\n-    output = layer(input_data)\n-    self.assertAllEqual(output.dtype, tf.int64)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.shape.as_list(), [16, 4])\n+\n+  @parameterized.named_parameters(\n+      (\"int32\", tf.int32),\n+      (\"int64\", tf.int64),\n+  )\n+  def test_output_dtype(self, dtype):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype=\"float32\")\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n+                                          dtype=dtype)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, dtype)\n+\n+  def test_legacy_dtype_compat(self):\n+    inputs = keras.Input(batch_size=16, shape=(4,), dtype=\"float32\")\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n+                                          dtype=\"float32\")\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, tf.int64)\n+\n+  @parameterized.named_parameters(\n+      (\"float32\", tf.float32),\n+      (\"float64\", tf.float64),\n+  )\n+  def test_one_hot_output_dtype(self, dtype):\n+    inputs = keras.Input(batch_size=16, shape=(1,), dtype=\"float32\")\n+    layer = discretization.Discretization(bin_boundaries=[-.5, 0.5, 1.5],\n+                                          output_mode=\"one_hot\",\n+                                          dtype=dtype)\n+    outputs = layer(inputs)\n+    self.assertAllEqual(outputs.dtype, dtype)\n \n   def test_num_bins_negative_fails(self):\n     with self.assertRaisesRegex(ValueError, \"`num_bins` must be.*num_bins=-7\"):\n\n@@ -88,7 +88,7 @@ def encode_categorical_inputs(inputs,\n                               idf_weights=None):\n   \"\"\"Encodes categoical inputs according to output_mode.\"\"\"\n   if output_mode == INT:\n-    return tf.cast(inputs, dtype)\n+    return tf.identity(tf.cast(inputs, dtype))\n \n   original_shape = inputs.shape\n   # In all cases, we should uprank scalar input to a single sample.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
