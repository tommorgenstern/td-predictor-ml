{"custom_id": "keras#19e1eabde4e6bb6d7145b8dfb301c1344fc5a310", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 272 | Lines Deleted: 4 | Files Changed: 4 | Hunks: 5 | Methods Changed: 12 | Complexity Δ (Sum/Max): 25/18 | Churn Δ: 276 | Churn Cumulative: 367 | Contributors (this commit): 4 | Commits (past 90d): 13 | Contributors (cumulative): 7 | DMM Complexity: 0.8087431693989071\n\nDIFF:\n@@ -6,5 +6,6 @@ from keras_core.callbacks.history import History\n from keras_core.callbacks.lambda_callback import LambdaCallback\n from keras_core.callbacks.learning_rate_scheduler import LearningRateScheduler\n from keras_core.callbacks.progbar_logger import ProgbarLogger\n+from keras_core.callbacks.reduce_lr_on_plateau import ReduceLROnPlateau\n from keras_core.callbacks.remote_monitor import RemoteMonitor\n from keras_core.callbacks.terminate_on_nan import TerminateOnNaN\n\n@@ -1,6 +1,5 @@\n import numpy as np\n \n-from keras_core import backend\n from keras_core.api_export import keras_core_export\n from keras_core.callbacks.callback import Callback\n from keras_core.utils import io_utils\n@@ -54,9 +53,7 @@ class LearningRateScheduler(Callback):\n             raise ValueError('Optimizer must have a \"learning_rate\" attribute.')\n \n         try:  # new API\n-            learning_rate = backend.Variable(\n-                self.model.optimizer.learning_rate\n-            ).numpy()\n+            learning_rate = float(np.array(self.model.optimizer.learning_rate))\n             learning_rate = self.schedule(epoch, learning_rate)\n         except TypeError:  # Support for old API for backward compatibility\n             learning_rate = self.schedule(epoch)\n\n@@ -0,0 +1,143 @@\n+import warnings\n+\n+import numpy as np\n+\n+from keras_core.api_export import keras_core_export\n+from keras_core.callbacks.callback import Callback\n+from keras_core.utils import io_utils\n+\n+\n+@keras_core_export(\"keras_core.callbacks.ReduceLROnPlateau\")\n+class ReduceLROnPlateau(Callback):\n+    \"\"\"Reduce learning rate when a metric has stopped improving.\n+\n+    Models often benefit from reducing the learning rate by a factor\n+    of 2-10 once learning stagnates. This callback monitors a\n+    quantity and if no improvement is seen for a 'patience' number\n+    of epochs, the learning rate is reduced.\n+\n+    Example:\n+\n+    ```python\n+    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n+                                  patience=5, min_lr=0.001)\n+    model.fit(x_train, y_train, callbacks=[reduce_lr])\n+    ```\n+\n+    Args:\n+        monitor: String. Quantity to be monitored.\n+        factor: Float. Factor by which the learning rate will be reduced.\n+            `new_lr = lr * factor`.\n+        patience: Integer. Number of epochs with no improvement after which\n+            learning rate will be reduced.\n+        verbose: Integer. 0: quiet, 1: update messages.\n+        mode: String. One of `{'auto', 'min', 'max'}`. In `'min'` mode,\n+            the learning rate will be reduced when the\n+            quantity monitored has stopped decreasing; in `'max'` mode it will\n+            be reduced when the quantity monitored has stopped increasing; in\n+            `'auto'` mode, the direction is automatically inferred from the name\n+            of the monitored quantity.\n+        min_delta: Float. Threshold for measuring the new optimum, to only focus\n+            on significant changes.\n+        cooldown: Integer. Number of epochs to wait before resuming normal\n+            operation after the learning rate has been reduced.\n+        min_lr: Float. Lower bound on the learning rate.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        monitor=\"val_loss\",\n+        factor=0.1,\n+        patience=10,\n+        verbose=0,\n+        mode=\"auto\",\n+        min_delta=1e-4,\n+        cooldown=0,\n+        min_lr=0,\n+        **kwargs,\n+    ):\n+        super().__init__()\n+\n+        self.monitor = monitor\n+        if factor >= 1.0:\n+            raise ValueError(\n+                \"ReduceLROnPlateau does not support a factor >= 1.0. \"\n+                f\"Received factor={factor}\"\n+            )\n+\n+        self.factor = factor\n+        self.min_lr = min_lr\n+        self.min_delta = min_delta\n+        self.patience = patience\n+        self.verbose = verbose\n+        self.cooldown = cooldown\n+        self.cooldown_counter = 0  # Cooldown counter.\n+        self.wait = 0\n+        self.best = 0\n+        self.mode = mode\n+        self.monitor_op = None\n+        self._reset()\n+\n+    def _reset(self):\n+        \"\"\"Resets wait counter and cooldown counter.\"\"\"\n+        if self.mode not in {\"auto\", \"min\", \"max\"}:\n+            warnings.warn(\n+                f\"Learning rate reduction mode {self.mode} is unknown, \"\n+                \"fallback to auto mode.\",\n+                stacklevel=2,\n+            )\n+            self.mode = \"auto\"\n+        if self.mode == \"min\" or (\n+            self.mode == \"auto\" and \"acc\" not in self.monitor\n+        ):\n+            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n+            self.best = np.Inf\n+        else:\n+            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n+            self.best = -np.Inf\n+        self.cooldown_counter = 0\n+        self.wait = 0\n+\n+    def on_train_begin(self, logs=None):\n+        self._reset()\n+\n+    def on_epoch_end(self, epoch, logs=None):\n+        logs = logs or {}\n+        logs[\"lr\"] = float(np.array(self.model.optimizer.learning_rate))\n+        current = logs.get(self.monitor)\n+\n+        if current is None:\n+            print(\"tacos\")\n+            warnings.warn(\n+                \"Learning rate reduction is conditioned on metric \"\n+                f\"`{self.monitor}` which is not available. Available metrics \"\n+                f\"are: {','.join(list(logs.keys()))}.\",\n+                stacklevel=2,\n+            )\n+        else:\n+            if self.in_cooldown():\n+                self.cooldown_counter -= 1\n+                self.wait = 0\n+\n+            if self.monitor_op(current, self.best):\n+                self.best = current\n+                self.wait = 0\n+            elif not self.in_cooldown():\n+                self.wait += 1\n+                if self.wait >= self.patience:\n+                    old_lr = float(np.array(self.model.optimizer.learning_rate))\n+                    if old_lr > np.float32(self.min_lr):\n+                        new_lr = old_lr * self.factor\n+                        new_lr = max(new_lr, self.min_lr)\n+                        self.model.optimizer.learning_rate = new_lr\n+                        if self.verbose > 0:\n+                            io_utils.print_msg(\n+                                f\"\\nEpoch {epoch +1}: \"\n+                                \"ReduceLROnPlateau reducing \"\n+                                f\"learning rate to {new_lr}.\"\n+                            )\n+                        self.cooldown_counter = self.cooldown\n+                        self.wait = 0\n+\n+    def in_cooldown(self):\n+        return self.cooldown_counter > 0\n\n@@ -0,0 +1,127 @@\n+from keras_core import callbacks\n+from keras_core import layers\n+from keras_core import optimizers\n+from keras_core import testing\n+from keras_core.models import Sequential\n+from keras_core.testing import test_utils\n+from keras_core.utils import io_utils\n+from keras_core.utils import numerical_utils\n+\n+\n+class ReduceLROnPlateauTest(testing.TestCase):\n+    def setUp(self):\n+        (x_train, y_train), (x_test, y_test) = test_utils.get_test_data(\n+            train_samples=10,\n+            test_samples=10,\n+            input_shape=(3,),\n+            num_classes=2,\n+        )\n+        y_test = numerical_utils.to_categorical(y_test)\n+        y_train = numerical_utils.to_categorical(y_train)\n+\n+        model = Sequential([layers.Dense(5), layers.Dense(2)])\n+\n+        model.compile(\n+            loss=\"mse\",\n+            optimizer=optimizers.Adam(0.1),\n+        )\n+\n+        self.model = model\n+        self.x_train = x_train\n+        self.x_test = x_test\n+        self.y_train = y_train\n+        self.y_test = y_test\n+\n+    def test_reduces_lr_with_model_fit(self):\n+        reduce_lr = callbacks.ReduceLROnPlateau(\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+        )\n+\n+        self.model.fit(\n+            self.x_train,\n+            self.y_train,\n+            validation_data=(self.x_test, self.y_test),\n+            callbacks=[reduce_lr],\n+            epochs=2,\n+        )\n+\n+        self.assertEqual(self.model.optimizer.learning_rate.value, 0.01)\n+\n+    def test_throws_when_optimizer_has_schedule(self):\n+        reduce_lr = callbacks.ReduceLROnPlateau(\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10\n+        )\n+\n+        self.model.compile(\n+            loss=\"mse\",\n+            optimizer=optimizers.Adam(\n+                optimizers.schedules.PolynomialDecay(\n+                    initial_learning_rate=0.1, decay_steps=10\n+                )\n+            ),\n+        )\n+\n+        with self.assertRaisesRegex(\n+            TypeError,\n+            \"This optimizer was created with a `LearningRateSchedule`\",\n+        ):\n+            self.model.fit(\n+                self.x_train,\n+                self.y_train,\n+                validation_data=(self.x_test, self.y_test),\n+                callbacks=[reduce_lr],\n+                epochs=2,\n+            )\n+\n+    def test_verbose_logging(self):\n+        reduce_lr = callbacks.ReduceLROnPlateau(\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, verbose=1\n+        )\n+        io_utils.disable_interactive_logging()\n+\n+        with self.assertLogs(level=\"INFO\") as logs:\n+            self.model.fit(\n+                self.x_train,\n+                self.y_train,\n+                validation_data=(self.x_test, self.y_test),\n+                callbacks=[reduce_lr],\n+                epochs=2,\n+            )\n+            expected_log = \"ReduceLROnPlateau reducing learning rate to 0.01\"\n+            self.assertTrue(any(expected_log in log for log in logs.output))\n+\n+    def test_honors_min_lr(self):\n+        reduce_lr = callbacks.ReduceLROnPlateau(\n+            patience=1,\n+            factor=0.1,\n+            monitor=\"val_loss\",\n+            min_delta=10,\n+            min_lr=0.005,\n+        )\n+\n+        self.model.fit(\n+            self.x_train,\n+            self.y_train,\n+            validation_data=(self.x_test, self.y_test),\n+            callbacks=[reduce_lr],\n+            epochs=4,\n+        )\n+\n+        self.assertEqual(self.model.optimizer.learning_rate.value, 0.005)\n+\n+    def test_cooldown(self):\n+        reduce_lr = callbacks.ReduceLROnPlateau(\n+            patience=1, factor=0.1, monitor=\"val_loss\", min_delta=10, cooldown=2\n+        )\n+\n+        self.model.fit(\n+            self.x_train,\n+            self.y_train,\n+            validation_data=(self.x_test, self.y_test),\n+            callbacks=[reduce_lr],\n+            epochs=4,\n+        )\n+\n+        # With a cooldown of 2 epochs, we should only reduce the LR every other\n+        # epoch, so after 4 epochs we will have reduced 2 times.\n+        self.assertAllClose(self.model.optimizer.learning_rate.value, 0.001)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#870f6b198fa9faeed248fe6b430e0d1667142b9b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 23 | Lines Deleted: 34 | Files Changed: 8 | Hunks: 14 | Methods Changed: 9 | Complexity Δ (Sum/Max): -10/3 | Churn Δ: 57 | Churn Cumulative: 2222 | Contributors (this commit): 6 | Commits (past 90d): 40 | Contributors (cumulative): 23 | DMM Complexity: 0.6153846153846154\n\nDIFF:\n@@ -19,6 +19,7 @@ from keras_core.backend.config import image_data_format\n from keras_core.backend.config import set_epsilon\n from keras_core.backend.config import set_floatx\n from keras_core.backend.config import set_image_data_format\n+from keras_core.backend.config import standardize_data_format\n from keras_core.utils.io_utils import print_msg\n \n # Import backend functions.\n\n@@ -152,6 +152,18 @@ def set_image_data_format(data_format):\n     _IMAGE_DATA_FORMAT = str(data_format)\n \n \n+def standardize_data_format(data_format):\n+    if data_format is None:\n+        return image_data_format()\n+    data_format = data_format.lower()\n+    if data_format not in {\"channels_first\", \"channels_last\"}:\n+        raise ValueError(\n+            \"The `data_format` argument must be one of \"\n+            f\"'channels_first', 'channels_last'. Received: {data_format}\"\n+        )\n+    return data_format\n+\n+\n # Set Keras base dir path given KERAS_HOME env variable, if applicable.\n # Otherwise either ~/.keras or /tmp.\n if \"KERAS_HOME\" in os.environ:\n\n@@ -5,7 +5,7 @@ from keras_core import constraints\n from keras_core import initializers\n from keras_core import operations as ops\n from keras_core import regularizers\n-from keras_core.backend import image_data_format\n+from keras_core.backend import standardize_data_format\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n from keras_core.operations.operation_utils import compute_conv_output_shape\n@@ -117,9 +117,7 @@ class BaseConv(Layer):\n         self.dilation_rate = dilation_rate\n \n         self.padding = padding\n-        self.data_format = (\n-            image_data_format() if data_format is None else data_format\n-        )\n+        self.data_format = standardize_data_format(data_format)\n         self.activation = activations.get(activation)\n         self.use_bias = use_bias\n         self.kernel_initializer = initializers.get(kernel_initializer)\n\n@@ -46,7 +46,7 @@ class CenterCrop(Layer):\n         super().__init__(**kwargs)\n         self.height = height\n         self.width = width\n-        self.data_format = data_format or backend.image_data_format()\n+        self.data_format = backend.standardize_data_format(data_format)\n \n     def call(self, inputs):\n         if self.data_format == \"channels_first\":\n\n@@ -62,7 +62,7 @@ class Resizing(Layer):\n         self.height = height\n         self.width = width\n         self.interpolation = interpolation\n-        self.data_format = data_format or backend.image_data_format()\n+        self.data_format = backend.standardize_data_format(data_format)\n         self.crop_to_aspect_ratio = crop_to_aspect_ratio\n \n     def call(self, inputs):\n\n@@ -112,13 +112,7 @@ class SpatialDropout2D(BaseSpatialDropout):\n         self, rate, data_format=None, seed=None, name=None, dtype=None\n     ):\n         super().__init__(rate, seed=seed, name=name, dtype=dtype)\n-        data_format = data_format or backend.image_data_format()\n-        if data_format not in {\"channels_last\", \"channels_first\"}:\n-            raise ValueError(\n-                '`data_format` must be \"channels_last\" or \"channels_first\". '\n-                f\"Received: data_format={data_format}.\"\n-            )\n-        self.data_format = data_format\n+        self.data_format = backend.standardize_data_format(data_format)\n         self.input_spec = InputSpec(ndim=4)\n \n     def _get_noise_shape(self, inputs):\n@@ -180,13 +174,7 @@ class SpatialDropout3D(BaseSpatialDropout):\n         self, rate, data_format=None, seed=None, name=None, dtype=None\n     ):\n         super().__init__(rate, seed=seed, name=name, dtype=dtype)\n-        data_format = data_format or backend.image_data_format()\n-        if data_format not in {\"channels_last\", \"channels_first\"}:\n-            raise ValueError(\n-                '`data_format` must be \"channels_last\" or \"channels_first\". '\n-                f\"Received: data_format={data_format}.\"\n-            )\n-        self.data_format = data_format\n+        self.data_format = backend.standardize_data_format(data_format)\n         self.input_spec = InputSpec(ndim=5)\n \n     def _get_noise_shape(self, inputs):\n\n@@ -32,9 +32,7 @@ class Flatten(Layer):\n \n     def __init__(self, data_format=None, name=None, dtype=None):\n         super().__init__(name=name, dtype=dtype)\n-        self.data_format = (\n-            backend.image_data_format() if data_format is None else data_format\n-        )\n+        self.data_format = backend.standardize_data_format(data_format)\n         self.input_spec = InputSpec(min_ndim=1)\n         self._channels_first = self.data_format == \"channels_first\"\n \n\n@@ -66,8 +66,7 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n         A PIL Image instance.\n     \"\"\"\n \n-    if data_format is None:\n-        data_format = backend.image_data_format()\n+    data_format = backend.standardize_data_format(data_format)\n     if dtype is None:\n         dtype = backend.floatx()\n     if pil_image is None:\n@@ -82,9 +81,6 @@ def array_to_img(x, data_format=None, scale=True, dtype=None):\n             f\"Got array with shape: {x.shape}\"\n         )\n \n-    if data_format not in {\"channels_first\", \"channels_last\"}:\n-        raise ValueError(f\"Invalid data_format: {data_format}\")\n-\n     # Original NumPy array x has format (height, width, channel)\n     # or (channel, height, width)\n     # but target PIL image has format (width, height, channel)\n@@ -144,12 +140,9 @@ def img_to_array(img, data_format=None, dtype=None):\n         A 3D NumPy array.\n     \"\"\"\n \n-    if data_format is None:\n-        data_format = backend.image_data_format()\n+    data_format = backend.standardize_data_format(data_format)\n     if dtype is None:\n         dtype = backend.floatx()\n-    if data_format not in {\"channels_first\", \"channels_last\"}:\n-        raise ValueError(f\"Unknown data_format: {data_format}\")\n     # NumPy array x has format (height, width, channel)\n     # or (channel, height, width)\n     # but original PIL image has format (width, height, channel)\n@@ -184,8 +177,7 @@ def save_img(path, x, data_format=None, file_format=None, scale=True, **kwargs):\n         scale: Whether to rescale image values to be within `[0, 255]`.\n         **kwargs: Additional keyword arguments passed to `PIL.Image.save()`.\n     \"\"\"\n-    if data_format is None:\n-        data_format = backend.image_data_format()\n+    data_format = backend.standardize_data_format(data_format)\n     img = array_to_img(x, data_format=data_format, scale=scale)\n     if img.mode == \"RGBA\" and (file_format == \"jpg\" or file_format == \"jpeg\"):\n         warnings.warn(\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0f1a13b80b587ba442aea06350e1a2d5850d1b82", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 5 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 16 | Churn Cumulative: 381 | Contributors (this commit): 5 | Commits (past 90d): 9 | Contributors (cumulative): 5 | DMM Complexity: 1.0\n\nDIFF:\n@@ -143,23 +143,25 @@ def set_image_data_format(data_format):\n     >>> keras_core.config.set_image_data_format('channels_last')\n     \"\"\"\n     global _IMAGE_DATA_FORMAT\n-    accepted_formats = {\"channels_last\", \"channels_first\"}\n-    if data_format not in accepted_formats:\n+    data_format = str(data_format).lower()\n+    if data_format not in {\"channels_first\", \"channels_last\"}:\n         raise ValueError(\n-            f\"Unknown `data_format`: {data_format}. \"\n-            f\"Expected one of {accepted_formats}\"\n+            \"The `data_format` argument must be one of \"\n+            \"{'channels_first', 'channels_last'}. \"\n+            f\"Received: data_format={data_format}\"\n         )\n-    _IMAGE_DATA_FORMAT = str(data_format)\n+    _IMAGE_DATA_FORMAT = data_format\n \n \n def standardize_data_format(data_format):\n     if data_format is None:\n         return image_data_format()\n-    data_format = data_format.lower()\n+    data_format = str(data_format).lower()\n     if data_format not in {\"channels_first\", \"channels_last\"}:\n         raise ValueError(\n             \"The `data_format` argument must be one of \"\n-            f\"'channels_first', 'channels_last'. Received: {data_format}\"\n+            \"{'channels_first', 'channels_last'}. \"\n+            f\"Received: data_format={data_format}\"\n         )\n     return data_format\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0a1f3da5a97a59906b0a2324ec3370dae41a45fb", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 18 | Lines Deleted: 12 | Files Changed: 3 | Hunks: 8 | Methods Changed: 7 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 30 | Churn Cumulative: 1898 | Contributors (this commit): 8 | Commits (past 90d): 95 | Contributors (cumulative): 14 | DMM Complexity: 0.0\n\nDIFF:\n@@ -74,9 +74,8 @@ def train_step(data):\n     with tf.GradientTape() as tape:\n         y_pred = model(x)\n         loss = loss_fn(y, y_pred)\n-    # !! Glitch to be resolved !!\n     gradients = tape.gradient(\n-        loss, [v.value for v in model.trainable_variables]\n+        loss, model.trainable_variables\n     )\n     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n     return loss\n\n@@ -19,6 +19,12 @@ DYNAMIC_SHAPES_OK = True\n \n \n class Variable(KerasVariable, tf.__internal__.types.Tensor):\n+    _should_act_as_resource_variable = True\n+\n+    @property\n+    def handle(self):\n+        return self.value.handle\n+\n     def _initialize(self, value):\n         self._value = tf.Variable(\n             value, dtype=self._dtype, trainable=self.trainable\n\n@@ -433,6 +433,8 @@ class Layer(Operation):\n                         outputs = super().__call__(*args, **kwargs)\n                 else:\n                     outputs = super().__call__(*args, **kwargs)\n+                if not self.built:\n+                    self.built = True\n                 # Record activity regularizer loss.\n                 if self.activity_regularizer is not None:\n                     for output in nest.flatten(outputs):\n@@ -763,6 +765,9 @@ class Layer(Operation):\n                                 f\"{list(shapes_dict.keys())}\"\n                             )\n             if failure:\n+                if call_spec.eager:\n+                    # Will let the actual eager call do the state-building\n+                    return\n                 raise ValueError(\n                     f\"Layer '{self.name}' looks like it has \"\n                     \"unbuilt state, but Keras is not able to \"\n@@ -797,11 +802,7 @@ class Layer(Operation):\n         try:\n             backend.compute_output_spec(self.call, input_tensors)\n             return True\n-        except Exception as e:\n-            warnings.warn(\n-                \"Error when attempting to automatically build \"\n-                f\"the layer by tracing it: {e}\"\n-            )\n+        except:\n             return False\n \n     def _build_by_run_for_kwargs(self, shapes_dict):\n@@ -816,11 +817,7 @@ class Layer(Operation):\n             try:\n                 backend.compute_output_spec(self.call, **input_tensors)\n                 return True\n-            except Exception as e:\n-                warnings.warn(\n-                    \"Error when attempting to automatically build \"\n-                    f\"the layer by tracing it: {e}\"\n-                )\n+            except:\n                 return False\n         else:\n             # Not supported: nested input keyword arguments.\n@@ -962,6 +959,10 @@ class CallSpec:\n         self.tensor_arguments_names = tensor_arg_names\n         self.nested_tensor_argument_names = nested_tensor_arg_names\n         self.first_arg = arg_dict[arg_names[0]]\n+        if all(backend.is_tensor(x) for x in self.tensor_arguments_dict.values()):\n+            self.eager = True\n+        else:\n+            self.eager = False\n \n \n def get_arguments_dict(fn, args, kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a11e205fe7d80c49af2886c15ec8415ba64343be", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 1182 | Contributors (this commit): 6 | Commits (past 90d): 61 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -74,9 +74,7 @@ def train_step(data):\n     with tf.GradientTape() as tape:\n         y_pred = model(x)\n         loss = loss_fn(y, y_pred)\n-    gradients = tape.gradient(\n-        loss, model.trainable_variables\n-    )\n+    gradients = tape.gradient(loss, model.trainable_variables)\n     optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n     return loss\n \n\n@@ -959,7 +959,9 @@ class CallSpec:\n         self.tensor_arguments_names = tensor_arg_names\n         self.nested_tensor_argument_names = nested_tensor_arg_names\n         self.first_arg = arg_dict[arg_names[0]]\n-        if all(backend.is_tensor(x) for x in self.tensor_arguments_dict.values()):\n+        if all(\n+            backend.is_tensor(x) for x in self.tensor_arguments_dict.values()\n+        ):\n             self.eager = True\n         else:\n             self.eager = False\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bf3c24aa8cb0a3637377fe8a7a9587104c33e71", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 104 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 8 | Complexity Δ (Sum/Max): 10/6 | Churn Δ: 104 | Churn Cumulative: 202 | Contributors (this commit): 7 | Commits (past 90d): 45 | Contributors (cumulative): 9 | DMM Complexity: 1.0\n\nDIFF:\n@@ -75,6 +75,7 @@ from keras_core.layers.regularization.spatial_dropout import SpatialDropout1D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout2D\n from keras_core.layers.regularization.spatial_dropout import SpatialDropout3D\n from keras_core.layers.reshaping.flatten import Flatten\n+from keras_core.layers.reshaping.permute import Permute\n from keras_core.layers.reshaping.repeat_vector import RepeatVector\n from keras_core.layers.reshaping.reshape import Reshape\n from keras_core.layers.reshaping.up_sampling1d import UpSampling1D\n\n@@ -0,0 +1,53 @@\n+from keras_core import operations as ops\n+from keras_core.layers.input_spec import InputSpec\n+from keras_core.layers.layer import Layer\n+\n+\n+class Permute(Layer):\n+    \"\"\"Permutes the dimensions of the input according to a given pattern.\n+\n+    Useful e.g. connecting RNNs and convnets.\n+\n+    Args:\n+        dims: Tuple of integers. Permutation pattern does not include the\n+            batch dimension. Indexing starts at 1.\n+            For instance, `(2, 1)` permutes the first and second dimensions\n+            of the input.\n+    Input shape:\n+        Arbitrary.\n+    Output shape:\n+        Same as the input shape, but with the dimensions re-ordered according\n+        to the specified pattern.\n+\n+    Example:\n+\n+    >>> x = keras_core.Input(shape=(10, 64))\n+    >>> y = keras_core.layers.Permute((2, 1))(x)\n+    >>> y.shape\n+    (None, 64, 10)\n+    \"\"\"\n+\n+    def __init__(self, dims, name=None, dtype=None):\n+        super().__init__(name=name, dtype=dtype)\n+        self.dims = tuple(dims)\n+        if sorted(dims) != list(range(1, len(dims) + 1)):\n+            raise ValueError(\n+                \"Invalid permutation argument `dims` for Permute Layer. \"\n+                \"The set of indices in `dims` must be consecutive and start \"\n+                f\"from 1. Received dims={dims}\"\n+            )\n+        self.input_spec = InputSpec(ndim=len(self.dims) + 1)\n+\n+    def compute_output_shape(self, input_shape):\n+        output_shape = [input_shape[0]]\n+        for dim in self.dims:\n+            output_shape.append(input_shape[dim])\n+        return tuple(output_shape)\n+\n+    def call(self, inputs):\n+        return ops.transpose(inputs, axes=(0,) + self.dims)\n+\n+    def get_config(self):\n+        config = {\"dims\": self.dims}\n+        base_config = super().get_config()\n+        return {**base_config, **config}\n\n@@ -0,0 +1,50 @@\n+import numpy as np\n+import pytest\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import operations as ops\n+from keras_core import testing\n+\n+\n+class PermuteTest(testing.TestCase):\n+    def test_permute(self):\n+        inputs = np.random.random((2, 3, 5)).astype(\"float32\")\n+        expected_output = ops.convert_to_tensor(\n+            np.transpose(inputs, axes=(0, 2, 1))\n+        )\n+        self.run_layer_test(\n+            layers.Permute,\n+            init_kwargs={\"dims\": (2, 1)},\n+            input_data=inputs,\n+            expected_output=expected_output,\n+        )\n+\n+    @pytest.mark.skipif(\n+        not backend.DYNAMIC_SHAPES_OK,\n+        reason=\"Backend does not support dynamic shapes\",\n+    )\n+    def test_permute_with_dynamic_batch_size(self):\n+        input_layer = layers.Input(batch_shape=(None, 3, 5))\n+        permuted = layers.Permute((2, 1))(input_layer)\n+        self.assertEqual(permuted.shape, (None, 5, 3))\n+\n+    def test_permute_errors_on_invalid_starting_dims_index(self):\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Invalid permutation .*dims.*\"\n+        ):\n+            self.run_layer_test(\n+                layers.Permute,\n+                init_kwargs={\"dims\": (0, 1, 2)},\n+                input_shape=(3, 2, 4),\n+            )\n+\n+    def test_permute_errors_on_invalid_set_of_dims_indices(self):\n+        with self.assertRaisesRegex(\n+            ValueError, r\"Invalid permutation .*dims.*\"\n+        ):\n+            self.run_layer_test(\n+                layers.Permute,\n+                init_kwargs={\"dims\": (1, 4, 2)},\n+                input_shape=(3, 2, 4),\n+            )\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a506d262e87571e08f39696d3f6b4fa6feee5641", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 2 | Files Changed: 5 | Hunks: 15 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 18 | Churn Cumulative: 595 | Contributors (this commit): 4 | Commits (past 90d): 16 | Contributors (cumulative): 11 | DMM Complexity: None\n\nDIFF:\n@@ -2,10 +2,12 @@ import math\n \n from keras_core import backend\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n \n+@keras_core_export(\"keras_core.layers.Flatten\")\n class Flatten(Layer):\n     \"\"\"Flattens the input. Does not affect the batch size.\n \n\n@@ -1,8 +1,10 @@\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n \n+@keras_core_export(\"keras_core.layers.Permute\")\n class Permute(Layer):\n     \"\"\"Permutes the dimensions of the input according to a given pattern.\n \n@@ -13,8 +15,10 @@ class Permute(Layer):\n             batch dimension. Indexing starts at 1.\n             For instance, `(2, 1)` permutes the first and second dimensions\n             of the input.\n+\n     Input shape:\n         Arbitrary.\n+\n     Output shape:\n         Same as the input shape, but with the dimensions re-ordered according\n         to the specified pattern.\n\n@@ -1,8 +1,10 @@\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n \n+@keras_core_export(\"keras_core.layers.RepeatVector\")\n class RepeatVector(Layer):\n     \"\"\"Repeats the input n times.\n \n@@ -15,10 +17,12 @@ class RepeatVector(Layer):\n \n     Args:\n         n: Integer, repetition factor.\n+\n     Input shape:\n-        2D tensor of shape `(batch_size, features)`.\n+        2D tensor with shape `(batch_size, features)`.\n+\n     Output shape:\n-        3D tensor of shape `(batch_size, n, features)`.\n+        3D tensor with shape `(batch_size, n, features)`.\n     \"\"\"\n \n     def __init__(self, n, name=None, dtype=None):\n\n@@ -1,8 +1,10 @@\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n from keras_core.layers.layer import Layer\n from keras_core.operations import operation_utils\n \n \n+@keras_core_export(\"keras_core.layers.Reshape\")\n class Reshape(Layer):\n     \"\"\"Layer that reshapes inputs into the given shape.\n \n\n@@ -1,8 +1,10 @@\n from keras_core import operations as ops\n+from keras_core.api_export import keras_core_export\n from keras_core.layers.input_spec import InputSpec\n from keras_core.layers.layer import Layer\n \n \n+@keras_core_export(\"keras_core.layers.UpSampling1D\")\n class UpSampling1D(Layer):\n     \"\"\"Upsampling layer for 1D inputs.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0c8ca79f50865555ff70be0ca4d2365ca58d325e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 1079 | Contributors (this commit): 6 | Commits (past 90d): 56 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -17,7 +17,6 @@ And some more magic:\n \"\"\"\n import collections\n import inspect\n-import warnings\n \n import numpy as np\n from tensorflow import nest\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e715d9fb8afd5e3b8cf1661451995e81c3ec5572", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1021 | Lines Deleted: 10 | Files Changed: 8 | Hunks: 16 | Methods Changed: 42 | Complexity Δ (Sum/Max): 49/22 | Churn Δ: 1031 | Churn Cumulative: 1755 | Contributors (this commit): 7 | Commits (past 90d): 57 | Contributors (cumulative): 14 | DMM Complexity: 1.0\n\nDIFF:\n@@ -61,9 +61,11 @@ from keras_core.layers.pooling.max_pooling3d import MaxPooling3D\n from keras_core.layers.preprocessing.center_crop import CenterCrop\n from keras_core.layers.preprocessing.discretization import Discretization\n from keras_core.layers.preprocessing.hashing import Hashing\n+from keras_core.layers.preprocessing.integer_lookup import IntegerLookup\n from keras_core.layers.preprocessing.normalization import Normalization\n from keras_core.layers.preprocessing.rescaling import Rescaling\n from keras_core.layers.preprocessing.resizing import Resizing\n+from keras_core.layers.preprocessing.string_lookup import StringLookup\n from keras_core.layers.preprocessing.text_vectorization import TextVectorization\n from keras_core.layers.regularization.activity_regularization import (\n     ActivityRegularization,\n\n@@ -141,7 +141,8 @@ class Discretization(Layer):\n \n         Arguments:\n             data: The data to train on. It can be passed either as a\n-                batched `tf.data.Dataset`, or as a numpy array.\n+                batched `tf.data.Dataset`,\n+                or as a NumPy array.\n             batch_size: Integer or `None`.\n                 Number of samples per state update.\n                 If unspecified, `batch_size` will default to 32.\n@@ -155,10 +156,10 @@ class Discretization(Layer):\n                 the number of samples in your dataset divided by\n                 the batch size, or 1 if that cannot be determined.\n                 If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n-                the epoch will run until the input dataset is exhausted.\n+                `adapt()` will run until the input dataset is exhausted.\n                 When passing an infinitely\n                 repeating dataset, you must specify the `steps` argument. This\n-                argument is not supported with array inputs.\n+                argument is not supported with array inputs or list inputs.\n         \"\"\"\n         self.layer.adapt(data, batch_size=batch_size, steps=steps)\n \n\n@@ -0,0 +1,456 @@\n+import numpy as np\n+import tensorflow as tf\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.IntegerLookup\")\n+class IntegerLookup(Layer):\n+    \"\"\"A preprocessing layer that maps integers to (possibly encoded) indices.\n+\n+    This layer maps a set of arbitrary integer input tokens into indexed integer\n+    output via a table-based vocabulary lookup. The layer's output indices will\n+    be contiguously arranged up to the maximum vocab size, even if the input\n+    tokens are non-continguous or unbounded. The layer supports multiple options\n+    for encoding the output via `output_mode`, and has optional support for\n+    out-of-vocabulary (OOV) tokens and masking.\n+\n+    The vocabulary for the layer must be either supplied on construction or\n+    learned via `adapt()`. During `adapt()`, the layer will analyze a data set,\n+    determine the frequency of individual integer tokens, and create a\n+    vocabulary from them. If the vocabulary is capped in size, the most frequent\n+    tokens will be used to create the vocabulary and all others will be treated\n+    as OOV.\n+\n+    There are two possible output modes for the layer.  When `output_mode` is\n+    `\"int\"`, input integers are converted to their index in the vocabulary (an\n+    integer).  When `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`,\n+    input integers are encoded into an array where each dimension corresponds to\n+    an element in the vocabulary.\n+\n+    The vocabulary can optionally contain a mask token as well as an OOV token\n+    (which can optionally occupy multiple indices in the vocabulary, as set\n+    by `num_oov_indices`).\n+    The position of these tokens in the vocabulary is fixed. When `output_mode`\n+    is `\"int\"`, the vocabulary will begin with the mask token at index 0,\n+    followed by OOV indices, followed by the rest of the vocabulary. When\n+    `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will\n+    begin with OOV indices and instances of the mask token will be dropped.\n+\n+    **Note:** This layer wraps `tf.keras.layers.IntegerLookup`. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n+\n+    Args:\n+        max_tokens: Maximum size of the vocabulary for this layer. This should\n+            only be specified when adapting the vocabulary or when setting\n+            `pad_to_max_tokens=True`. If None, there is no cap on the size of\n+            the vocabulary. Note that this size includes the OOV\n+            and mask tokens. Defaults to `None`.\n+        num_oov_indices: The number of out-of-vocabulary tokens to use.\n+            If this value is more than 1, OOV inputs are modulated to\n+            determine their OOV value.\n+            If this value is 0, OOV inputs will cause an error when calling\n+            the layer. Defaults to 1.\n+        mask_token: An integer token that represents masked inputs. When\n+            `output_mode` is `\"int\"`, the token is included in vocabulary\n+            and mapped to index 0. In other output modes,\n+            the token will not appear in the vocabulary and instances\n+            of the mask token in the input will be dropped.\n+            If set to None, no mask term will be added. Defaults to `None`.\n+        oov_token: Only used when `invert` is `True`. The token to return\n+            for OOV indices. Defaults to -1.\n+        vocabulary: Optional. Either an array of integers or a string path to a\n+            text file. If passing an array, can pass a tuple, list,\n+            1D NumPy array, or 1D tensor containing the integer vocbulary terms.\n+            If passing a file path, the file should contain one line per term\n+            in the vocabulary. If this argument is set,\n+            there is no need to `adapt()` the layer.\n+        vocabulary_dtype: The dtype of the vocabulary terms, for example\n+            `\"int64\"` or `\"int32\"`. Defaults to `\"int64\"`.\n+        idf_weights: Only valid when `output_mode` is `\"tf_idf\"`.\n+            A tuple, list, 1D NumPy array, or 1D tensor or the same length\n+            as the vocabulary, containing the floating point inverse document\n+            frequency weights, which will be multiplied by per sample term\n+            counts for the final TF-IDF weight.\n+            If the `vocabulary` argument is set, and `output_mode` is\n+            `\"tf_idf\"`, this argument must be supplied.\n+        invert: Only valid when `output_mode` is `\"int\"`.\n+            If `True`, this layer will map indices to vocabulary items\n+            instead of mapping vocabulary items to indices.\n+            Defaults to `False`.\n+        output_mode: Specification for the output of the layer. Values can be\n+            `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`\n+            configuring the layer as follows:\n+            - `\"int\"`: Return the vocabulary indices of the input tokens.\n+            - `\"one_hot\"`: Encodes each individual element in the input into an\n+                array the same size as the vocabulary,\n+                containing a 1 at the element index. If the last dimension\n+                is size 1, will encode on that dimension.\n+                If the last dimension is not size 1, will append a new\n+                dimension for the encoded output.\n+            - `\"multi_hot\"`: Encodes each sample in the input into a single\n+                array the same size as the vocabulary,\n+                containing a 1 for each vocabulary term present in the sample.\n+                Treats the last dimension as the sample dimension,\n+                if input shape is `(..., sample_length)`,\n+                output shape will be `(..., num_tokens)`.\n+            - `\"count\"`: As `\"multi_hot\"`, but the int array contains\n+                a count of the number of times the token at that index\n+                appeared in the sample.\n+            - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is\n+                applied to find the value in each token slot.\n+            For `\"int\"` output, any shape of input and output is supported.\n+            For all other output modes, currently only output up to rank 2\n+            is supported. Defaults to `\"int\"`.\n+        pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n+            `\"count\"`, or `\"tf_idf\"`. If `True`, the output will have\n+            its feature axis padded to `max_tokens` even if the number\n+            of unique tokens in the vocabulary is less than `max_tokens`,\n+            resulting in a tensor of shape `(batch_size, max_tokens)`\n+            regardless of vocabulary size. Defaults to `False`.\n+        sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n+            `\"tf_idf\"` output modes. Only supported with TensorFlow\n+            backend. If `True`, returns a `SparseTensor`\n+            instead of a dense `Tensor`. Defaults to `False`.\n+\n+    Examples:\n+\n+    **Creating a lookup layer with a known vocabulary**\n+\n+    This example creates a lookup layer with a pre-existing vocabulary.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens\n+    >>> layer = IntegerLookup(vocabulary=vocab)\n+    >>> layer(data)\n+    array([[1, 3, 4],\n+           [4, 0, 2]])\n+\n+    **Creating a lookup layer with an adapted vocabulary**\n+\n+    This example creates a lookup layer and generates the vocabulary by\n+    analyzing the dataset.\n+\n+    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n+    >>> layer = IntegerLookup()\n+    >>> layer.adapt(data)\n+    >>> layer.get_vocabulary()\n+    [-1, 42, 1138, 1000, 36, 12]\n+\n+    Note that the OOV token -1 have been added to the vocabulary. The remaining\n+    tokens are sorted by frequency (42, which has 2 occurrences, is first) then\n+    by inverse sort order.\n+\n+    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n+    >>> layer = IntegerLookup()\n+    >>> layer.adapt(data)\n+    >>> layer(data)\n+    array([[5, 2, 1],\n+           [1, 3, 4]])\n+\n+    **Lookups with multiple OOV indices**\n+\n+    This example demonstrates how to use a lookup layer with multiple OOV\n+    indices.  When a layer is created with more than one OOV index, any OOV\n+    tokens are hashed into the number of OOV buckets, distributing OOV tokens in\n+    a deterministic fashion across the set.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[12, 1138, 42], [37, 1000, 36]])\n+    >>> layer = IntegerLookup(vocabulary=vocab, num_oov_indices=2)\n+    >>> layer(data)\n+    array([[2, 4, 5],\n+           [1, 0, 3]])\n+\n+    Note that the output for OOV token 37 is 1, while the output for OOV token\n+    1000 is 0. The in-vocab terms have their output index increased by 1 from\n+    earlier examples (12 maps to 2, etc) in order to make space for the extra\n+    OOV token.\n+\n+    **One-hot output**\n+\n+    Configure the layer with `output_mode='one_hot'`. Note that the first\n+    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([12, 36, 1138, 42, 7])  # Note OOV tokens\n+    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n+    >>> layer(data)\n+    array([[0., 1., 0., 0., 0.],\n+            [0., 0., 1., 0., 0.],\n+            [0., 0., 0., 1., 0.],\n+            [0., 0., 0., 0., 1.],\n+            [1., 0., 0., 0., 0.]], dtype=float32)\n+\n+    **Multi-hot output**\n+\n+    Configure the layer with `output_mode='multi_hot'`. Note that the first\n+    `num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[12, 1138, 42, 42],\n+    ...                  [42,    7, 36,  7]])  # Note OOV tokens\n+    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='multi_hot')\n+    >>> layer(data)\n+    array([[0., 1., 0., 1., 1.],\n+           [1., 0., 1., 0., 1.]], dtype=float32)\n+\n+    **Token count output**\n+\n+    Configure the layer with `output_mode='count'`. As with multi_hot output,\n+    the first `num_oov_indices` dimensions in the output represent OOV tokens.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[12, 1138, 42, 42],\n+    ...                  [42,    7, 36,  7]])  # Note OOV tokens\n+    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='count')\n+    >>> layer(data)\n+    array([[0., 1., 0., 1., 2.],\n+           [2., 0., 1., 0., 1.]], dtype=float32)\n+\n+    **TF-IDF output**\n+\n+    Configure the layer with `output_mode='tf_idf'`. As with multi_hot output,\n+    the first `num_oov_indices` dimensions in the output represent OOV tokens.\n+\n+    Each token bin will output `token_count * idf_weight`, where the idf weights\n+    are the inverse document frequency weights per token. These should be\n+    provided along with the vocabulary. Note that the `idf_weight` for OOV\n+    tokens will default to the average of all idf weights passed in.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n+    >>> data = np.array([[12, 1138, 42, 42],\n+    ...                  [42,    7, 36,  7]])  # Note OOV tokens\n+    >>> layer = IntegerLookup(\n+    ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)\n+    >>> layer(data)\n+    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n+            [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n+\n+    To specify the idf weights for oov tokens, you will need to pass the entire\n+    vocabularly including the leading oov token.\n+\n+    >>> vocab = [-1, 12, 36, 1138, 42]\n+    >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n+    >>> data = np.array([[12, 1138, 42, 42],\n+    ...                  [42,    7, 36,  7]])  # Note OOV tokens\n+    >>> layer = IntegerLookup(\n+    ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)\n+    >>> layer(data)\n+    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n+            [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n+\n+    When adapting the layer in `\"tf_idf\"` mode, each input sample will\n+    be considered a document, and IDF weight per token will be\n+    calculated as:\n+    `log(1 + num_documents / (1 + token_document_count))`.\n+\n+    **Inverse lookup**\n+\n+    This example demonstrates how to map indices to tokens using this layer.\n+    (You can also use `adapt()` with `inverse=True`, but for simplicity we'll\n+    pass the vocab in this example.)\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[1, 3, 4], [4, 0, 2]])\n+    >>> layer = IntegerLookup(vocabulary=vocab, invert=True)\n+    >>> layer(data)\n+    array([[  12, 1138,   42],\n+           [  42,   -1,   36]])\n+\n+    Note that the first index correspond to the oov token by default.\n+\n+    **Forward and inverse lookup pairs**\n+\n+    This example demonstrates how to use the vocabulary of a standard lookup\n+    layer to create an inverse lookup layer.\n+\n+    >>> vocab = [12, 36, 1138, 42]\n+    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])\n+    >>> layer = IntegerLookup(vocabulary=vocab)\n+    >>> i_layer = IntegerLookup(\n+    ...     vocabulary=layer.get_vocabulary(), invert=True)\n+    >>> int_data = layer(data)\n+    >>> i_layer(int_data)\n+    array([[  12, 1138,   42],\n+           [  42,   -1,   36]])\n+\n+    In this example, the input token 1000 resulted in an output of -1, since\n+    1000 was not in the vocabulary - it got represented as an OOV, and all OOV\n+    tokens are returned as -1 in the inverse layer. Also, note that for the\n+    inverse to work, you must have already set the forward layer vocabulary\n+    either directly or via `adapt()` before calling `get_vocabulary()`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        mask_token=None,\n+        oov_token=-1,\n+        vocabulary=None,\n+        vocabulary_dtype=\"int64\",\n+        idf_weights=None,\n+        invert=False,\n+        output_mode=\"int\",\n+        sparse=False,\n+        pad_to_max_tokens=False,\n+        name=None,\n+        **kwargs,\n+    ):\n+        super().__init__(name=name)\n+        if sparse and backend.backend() != \"tensorflow\":\n+            raise ValueError(\n+                \"`sparse` can only be set to True with the \"\n+                \"TensorFlow backend.\"\n+            )\n+        self.layer = tf.keras.layers.IntegerLookup(\n+            max_tokens=max_tokens,\n+            num_oov_indices=num_oov_indices,\n+            mask_token=mask_token,\n+            oov_token=oov_token,\n+            vocabulary=vocabulary,\n+            vocabulary_dtype=vocabulary_dtype,\n+            idf_weights=idf_weights,\n+            invert=invert,\n+            output_mode=output_mode,\n+            sparse=sparse,\n+            pad_to_max_tokens=pad_to_max_tokens,\n+            name=name,\n+            **kwargs,\n+        )\n+        self._allow_non_tensor_positional_args = True\n+\n+    def adapt(self, data, batch_size=None, steps=None):\n+        \"\"\"Computes a vocabulary of interger terms from tokens in a dataset.\n+\n+        Calling `adapt()` on an `IntegerLookup` layer is an alternative to\n+        passing in a precomputed vocabulary  on construction via the\n+        `vocabulary` argument.  An `IntegerLookup` layer should always be either\n+        adapted over a dataset or supplied with a vocabulary.\n+\n+        During `adapt()`, the layer will build a vocabulary of all integer\n+        tokens seen in the dataset, sorted by occurrence count, with ties broken\n+        by sort order of the tokens (high to low). At the end of `adapt()`, if\n+        `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n+        size. For example, adapting a layer with `max_tokens=1000` will compute\n+        the 1000 most frequent tokens occurring in the input dataset. If\n+        `output_mode='tf-idf'`, `adapt()` will also learn the document\n+        frequencies of each token in the input dataset.\n+\n+        Arguments:\n+            data: The data to train on. It can be passed either as a\n+                batched `tf.data.Dataset`, as a list of integers,\n+                or as a NumPy array.\n+            batch_size: Integer or `None`.\n+                Number of samples per state update.\n+                If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` if your data is in the\n+                form of a `tf.data.Dataset`\n+                (it is expected to be already batched).\n+            steps: Integer or `None`.\n+                Total number of steps (batches of samples)\n+                When training with input tensors such as\n+                the default `None` is equal to\n+                the number of samples in your dataset divided by\n+                the batch size, or 1 if that cannot be determined.\n+                If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n+                `adapt()` will run until the input dataset is exhausted.\n+                When passing an infinitely\n+                repeating dataset, you must specify the `steps` argument. This\n+                argument is not supported with array inputs or list inputs.\n+        \"\"\"\n+        self.layer.adapt(data, batch_size=batch_size, steps=steps)\n+\n+    def update_state(self, data):\n+        self.layer.update_state(data)\n+\n+    def finalize_state(self):\n+        self.layer.finalize_state()\n+\n+    def reset_state(self):\n+        self.layer.reset_state()\n+\n+    def get_vocabulary(self, include_special_tokens=True):\n+        \"\"\"Returns the current vocabulary of the layer.\n+\n+        Args:\n+            include_special_tokens: If `True`, the returned vocabulary\n+                will include the padding and OOV tokens,\n+                and a term's index in the vocabulary will equal\n+                the term's index when calling the layer. If `False`, the\n+                returned vocabulary will not include any padding\n+                or OOV tokens.\n+        \"\"\"\n+        return self.layer.get_vocabulary(\n+            include_special_tokens=include_special_tokens\n+        )\n+\n+    def vocabulary_size(self):\n+        \"\"\"Gets the current size of the layer's vocabulary.\n+\n+        Returns:\n+            The integer size of the vocabulary, including optional\n+            mask and OOV indices.\n+        \"\"\"\n+        return self.layer.vocabulary_size()\n+\n+    def get_config(self):\n+        config = self.layer.get_config()\n+        if config[\"oov_token\"] is not None:\n+            config[\"oov_token\"] = int(config[\"oov_token\"])\n+        if config[\"mask_token\"] is not None:\n+            config[\"mask_token\"] = int(config[\"mask_token\"])\n+        if config[\"vocabulary\"] is not None:\n+            config[\"vocabulary\"] = [int(v) for v in config[\"vocabulary\"]]\n+        return config\n+\n+    def set_vocabulary(self, vocabulary, idf_weights=None):\n+        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n+\n+        This method sets the vocabulary and IDF weights for this layer directly,\n+        instead of analyzing a dataset through `adapt()`. It should be used\n+        whenever the vocab (and optionally document frequency) information is\n+        already known. If vocabulary data is already present in the layer, this\n+        method will replace it.\n+\n+        Args:\n+            vocabulary: Either an array or a string path to a text file.\n+                If passing an array, can pass a tuple, list, 1D NumPy array,\n+                or 1D tensor containing the vocbulary terms.\n+                If passing a file path, the file should contain one line\n+                per term in the vocabulary.\n+            idf_weights: A tuple, list, 1D NumPy array, or 1D tensor of inverse\n+                document frequency weights with equal length to vocabulary.\n+                Must be set if `output_mode` is `\"tf_idf\"`.\n+                Should not be set otherwise.\n+        \"\"\"\n+        self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n+\n+    def call(self, inputs):\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n+            inputs = tf.convert_to_tensor(np.array(inputs))\n+        outputs = self.layer.call(inputs)\n+        if backend.backend() != \"tensorflow\":\n+            outputs = backend.convert_to_tensor(outputs)\n+        return outputs\n+\n+    def save_own_variables(self, store):\n+        self.layer.save_own_variables(store)\n+\n+    def load_own_variables(self, store):\n+        self.layer.load_own_variables(store)\n+\n+    def save_assets(self, dir_path):\n+        self.layer.save_assets(dir_path)\n+\n+    def load_assets(self, dir_path):\n+        self.layer.load_assets(dir_path)\n\n@@ -0,0 +1,46 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class IntegerLookupTest(testing.TestCase):\n+    def test_config(self):\n+        layer = layers.IntegerLookup(\n+            output_mode=\"int\",\n+            vocabulary=[1, 2, 3],\n+            oov_token=1,\n+            mask_token=0,\n+        )\n+        self.run_class_serialization_test(layer)\n+\n+    def test_adapt_flow(self):\n+        layer = layers.IntegerLookup(\n+            output_mode=\"int\",\n+        )\n+        layer.adapt([1, 1, 1, 1, 2, 2, 2, 3, 3, 4])\n+        input_data = [2, 3, 4, 5]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 4, 0]))\n+\n+    def test_fixed_vocabulary(self):\n+        layer = layers.IntegerLookup(\n+            output_mode=\"int\",\n+            vocabulary=[1, 2, 3, 4],\n+        )\n+        input_data = [2, 3, 4, 5]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 4, 0]))\n+\n+    def test_set_vocabulary(self):\n+        layer = layers.IntegerLookup(\n+            output_mode=\"int\",\n+        )\n+        layer.set_vocabulary([1, 2, 3, 4])\n+        input_data = [2, 3, 4, 5]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 4, 0]))\n\n@@ -0,0 +1,446 @@\n+import numpy as np\n+import tensorflow as tf\n+\n+from keras_core import backend\n+from keras_core.api_export import keras_core_export\n+from keras_core.layers.layer import Layer\n+\n+\n+@keras_core_export(\"keras_core.layers.StringLookup\")\n+class StringLookup(Layer):\n+    \"\"\"A preprocessing layer that maps strings to (possibly encoded) indices.\n+\n+    This layer translates a set of arbitrary strings into integer output via a\n+    table-based vocabulary lookup. This layer will perform no splitting or\n+    transformation of input strings. For a layer than can split and tokenize\n+    natural language, see the `keras_core.layers.TextVectorization` layer.\n+\n+    The vocabulary for the layer must be either supplied on construction or\n+    learned via `adapt()`. During `adapt()`, the layer will analyze a data set,\n+    determine the frequency of individual strings tokens, and create a\n+    vocabulary from them. If the vocabulary is capped in size, the most frequent\n+    tokens will be used to create the vocabulary and all others will be treated\n+    as out-of-vocabulary (OOV).\n+\n+    There are two possible output modes for the layer.\n+    When `output_mode` is `\"int\"`,\n+    input strings are converted to their index in the vocabulary (an integer).\n+    When `output_mode` is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`, input strings\n+    are encoded into an array where each dimension corresponds to an element in\n+    the vocabulary.\n+\n+    The vocabulary can optionally contain a mask token as well as an OOV token\n+    (which can optionally occupy multiple indices in the vocabulary, as set\n+    by `num_oov_indices`).\n+    The position of these tokens in the vocabulary is fixed. When `output_mode`\n+    is `\"int\"`, the vocabulary will begin with the mask token (if set), followed\n+    by OOV indices, followed by the rest of the vocabulary. When `output_mode`\n+    is `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"` the vocabulary will begin with\n+    OOV indices and instances of the mask token will be dropped.\n+\n+    **Note:** This layer wraps `tf.keras.layers.StringLookup`. It cannot\n+    be used as part of the compiled computation graph of a model with\n+    any backend other than TensorFlow.\n+    It can however be used with any backend when running eagerly.\n+    It can also always be used as part of an input preprocessing pipeline\n+    with any backend (outside the model itself), which is how we recommend\n+    to use this layer.\n+\n+    Args:\n+        max_tokens: Maximum size of the vocabulary for this layer. This should\n+            only be specified when adapting the vocabulary or when setting\n+            `pad_to_max_tokens=True`. If None, there is no cap on the size of\n+            the vocabulary. Note that this size includes the OOV\n+            and mask tokens. Defaults to `None`.\n+        num_oov_indices: The number of out-of-vocabulary tokens to use.\n+            If this value is more than 1, OOV inputs are modulated to\n+            determine their OOV value.\n+            If this value is 0, OOV inputs will cause an error when calling\n+            the layer. Defaults to 1.\n+        mask_token: A token that represents masked inputs. When `output_mode` is\n+            `\"int\"`, the token is included in vocabulary and mapped to index 0.\n+            In other output modes, the token will not appear\n+            in the vocabulary and instances of the mask token\n+            in the input will be dropped. If set to `None`,\n+            no mask term will be added. Defaults to `None`.\n+        oov_token: Only used when `invert` is True. The token to return for OOV\n+            indices. Defaults to `\"[UNK]\"`.\n+        vocabulary: Optional. Either an array of integers or a string path to a\n+            text file. If passing an array, can pass a tuple, list,\n+            1D NumPy array, or 1D tensor containing the integer vocbulary terms.\n+            If passing a file path, the file should contain one line per term\n+            in the vocabulary. If this argument is set,\n+            there is no need to `adapt()` the layer.\n+        vocabulary_dtype: The dtype of the vocabulary terms, for example\n+            `\"int64\"` or `\"int32\"`. Defaults to `\"int64\"`.\n+        idf_weights: Only valid when `output_mode` is `\"tf_idf\"`.\n+            A tuple, list, 1D NumPy array, or 1D tensor or the same length\n+            as the vocabulary, containing the floating point inverse document\n+            frequency weights, which will be multiplied by per sample term\n+            counts for the final TF-IDF weight.\n+            If the `vocabulary` argument is set, and `output_mode` is\n+            `\"tf_idf\"`, this argument must be supplied.\n+        invert: Only valid when `output_mode` is `\"int\"`.\n+            If `True`, this layer will map indices to vocabulary items\n+            instead of mapping vocabulary items to indices.\n+            Defaults to `False`.\n+        output_mode: Specification for the output of the layer. Values can be\n+            `\"int\"`, `\"one_hot\"`, `\"multi_hot\"`, `\"count\"`, or `\"tf_idf\"`\n+            configuring the layer as follows:\n+            - `\"int\"`: Return the vocabulary indices of the input tokens.\n+            - `\"one_hot\"`: Encodes each individual element in the input into an\n+                array the same size as the vocabulary,\n+                containing a 1 at the element index. If the last dimension\n+                is size 1, will encode on that dimension.\n+                If the last dimension is not size 1, will append a new\n+                dimension for the encoded output.\n+            - `\"multi_hot\"`: Encodes each sample in the input into a single\n+                array the same size as the vocabulary,\n+                containing a 1 for each vocabulary term present in the sample.\n+                Treats the last dimension as the sample dimension,\n+                if input shape is `(..., sample_length)`,\n+                output shape will be `(..., num_tokens)`.\n+            - `\"count\"`: As `\"multi_hot\"`, but the int array contains\n+                a count of the number of times the token at that index\n+                appeared in the sample.\n+            - `\"tf_idf\"`: As `\"multi_hot\"`, but the TF-IDF algorithm is\n+                applied to find the value in each token slot.\n+            For `\"int\"` output, any shape of input and output is supported.\n+            For all other output modes, currently only output up to rank 2\n+            is supported. Defaults to `\"int\"`.\n+        pad_to_max_tokens: Only applicable when `output_mode` is `\"multi_hot\"`,\n+            `\"count\"`, or `\"tf_idf\"`. If `True`, the output will have\n+            its feature axis padded to `max_tokens` even if the number\n+            of unique tokens in the vocabulary is less than `max_tokens`,\n+            resulting in a tensor of shape `(batch_size, max_tokens)`\n+            regardless of vocabulary size. Defaults to `False`.\n+        sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n+            `\"tf_idf\"` output modes. Only supported with TensorFlow\n+            backend. If `True`, returns a `SparseTensor`\n+            instead of a dense `Tensor`. Defaults to `False`.\n+        encoding: Optional. The text encoding to use to interpret the input\n+            strings. Defaults to `\"utf-8\"`.\n+\n+    Examples:\n+\n+    **Creating a lookup layer with a known vocabulary**\n+\n+    This example creates a lookup layer with a pre-existing vocabulary.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n+    >>> layer = StringLookup(vocabulary=vocab)\n+    >>> layer(data)\n+    array([[1, 3, 4],\n+           [4, 0, 2]])\n+\n+    **Creating a lookup layer with an adapted vocabulary**\n+\n+    This example creates a lookup layer and generates the vocabulary by\n+    analyzing the dataset.\n+\n+    >>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n+    >>> layer = StringLookup()\n+    >>> layer.adapt(data)\n+    >>> layer.get_vocabulary()\n+    ['[UNK]', 'd', 'z', 'c', 'b', 'a']\n+\n+    Note that the OOV token `\"[UNK]\"` has been added to the vocabulary.\n+    The remaining tokens are sorted by frequency\n+    (`\"d\"`, which has 2 occurrences, is first) then by inverse sort order.\n+\n+    >>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n+    >>> layer = StringLookup()\n+    >>> layer.adapt(data)\n+    >>> layer(data)\n+    array([[5, 3, 1],\n+           [1, 2, 4]])\n+\n+    **Lookups with multiple OOV indices**\n+\n+    This example demonstrates how to use a lookup layer with multiple OOV\n+    indices.  When a layer is created with more than one OOV index, any OOV\n+    values are hashed into the number of OOV buckets, distributing OOV values in\n+    a deterministic fashion across the set.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[\"a\", \"c\", \"d\"], [\"m\", \"z\", \"b\"]]\n+    >>> layer = StringLookup(vocabulary=vocab, num_oov_indices=2)\n+    >>> layer(data)\n+    array([[2, 4, 5],\n+           [0, 1, 3]])\n+\n+    Note that the output for OOV value 'm' is 0, while the output for OOV value\n+    `\"z\"` is 1. The in-vocab terms have their output index increased by 1 from\n+    earlier examples (a maps to 2, etc) in order to make space for the extra OOV\n+    value.\n+\n+    **One-hot output**\n+\n+    Configure the layer with `output_mode='one_hot'`. Note that the first\n+    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [\"a\", \"b\", \"c\", \"d\", \"z\"]\n+    >>> layer = StringLookup(vocabulary=vocab, output_mode='one_hot')\n+    >>> layer(data)\n+    array([[0., 1., 0., 0., 0.],\n+           [0., 0., 1., 0., 0.],\n+           [0., 0., 0., 1., 0.],\n+           [0., 0., 0., 0., 1.],\n+           [1., 0., 0., 0., 0.]], dtype=float32)\n+\n+    **Multi-hot output**\n+\n+    Configure the layer with `output_mode='multi_hot'`. Note that the first\n+    `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n+    >>> layer = StringLookup(vocabulary=vocab, output_mode='multi_hot')\n+    >>> layer(data)\n+    array([[0., 1., 0., 1., 1.],\n+           [1., 0., 1., 0., 1.]], dtype=float32)\n+\n+    **Token count output**\n+\n+    Configure the layer with `output_mode='count'`. As with multi_hot output,\n+    the first `num_oov_indices` dimensions in the output represent OOV values.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n+    >>> layer = StringLookup(vocabulary=vocab, output_mode='count')\n+    >>> layer(data)\n+    array([[0., 1., 0., 1., 2.],\n+           [2., 0., 1., 0., 1.]], dtype=float32)\n+\n+    **TF-IDF output**\n+\n+    Configure the layer with `output_mode=\"tf_idf\"`. As with multi_hot output,\n+    the first `num_oov_indices` dimensions in the output represent OOV values.\n+\n+    Each token bin will output `token_count * idf_weight`, where the idf weights\n+    are the inverse document frequency weights per token. These should be\n+    provided along with the vocabulary. Note that the `idf_weight` for OOV\n+    values will default to the average of all idf weights passed in.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> idf_weights = [0.25, 0.75, 0.6, 0.4]\n+    >>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n+    >>> layer = StringLookup(output_mode=\"tf_idf\")\n+    >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n+    >>> layer(data)\n+    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n+           [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n+\n+    To specify the idf weights for oov values, you will need to pass the entire\n+    vocabularly including the leading oov token.\n+\n+    >>> vocab = [\"[UNK]\", \"a\", \"b\", \"c\", \"d\"]\n+    >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]\n+    >>> data = [[\"a\", \"c\", \"d\", \"d\"], [\"d\", \"z\", \"b\", \"z\"]]\n+    >>> layer = StringLookup(output_mode=\"tf_idf\")\n+    >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)\n+    >>> layer(data)\n+    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],\n+           [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)\n+\n+    When adapting the layer in `\"tf_idf\"` mode, each input sample will be\n+    considered a document, and IDF weight per token will be calculated as\n+    `log(1 + num_documents / (1 + token_document_count))`.\n+\n+    **Inverse lookup**\n+\n+    This example demonstrates how to map indices to strings using this layer.\n+    (You can also use `adapt()` with `inverse=True`, but for simplicity we'll\n+    pass the vocab in this example.)\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[1, 3, 4], [4, 0, 2]]\n+    >>> layer = StringLookup(vocabulary=vocab, invert=True)\n+    >>> layer(data)\n+    array([[b'a', b'c', b'd'],\n+           [b'd', b'[UNK]', b'b']], dtype=object)\n+\n+    Note that the first index correspond to the oov token by default.\n+\n+\n+    **Forward and inverse lookup pairs**\n+\n+    This example demonstrates how to use the vocabulary of a standard lookup\n+    layer to create an inverse lookup layer.\n+\n+    >>> vocab = [\"a\", \"b\", \"c\", \"d\"]\n+    >>> data = [[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]]\n+    >>> layer = StringLookup(vocabulary=vocab)\n+    >>> i_layer = StringLookup(vocabulary=vocab, invert=True)\n+    >>> int_data = layer(data)\n+    >>> i_layer(int_data)\n+    array([[b'a', b'c', b'd'],\n+           [b'd', b'[UNK]', b'b']], dtype=object)\n+\n+    In this example, the input value `\"z\"` resulted in an output of `\"[UNK]\"`,\n+    since 1000 was not in the vocabulary - it got represented as an OOV, and all\n+    OOV values are returned as `\"[UNK]\"` in the inverse layer. Also, note that\n+    for the inverse to work, you must have already set the forward layer\n+    vocabulary either directly or via `adapt()` before calling\n+    `get_vocabulary()`.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        max_tokens=None,\n+        num_oov_indices=1,\n+        mask_token=None,\n+        oov_token=\"[UNK]\",\n+        vocabulary=None,\n+        idf_weights=None,\n+        invert=False,\n+        output_mode=\"int\",\n+        pad_to_max_tokens=False,\n+        sparse=False,\n+        encoding=\"utf-8\",\n+        name=None,\n+        **kwargs\n+    ):\n+        super().__init__(name=name)\n+        if sparse and backend.backend() != \"tensorflow\":\n+            raise ValueError(\n+                \"`sparse` can only be set to True with the \"\n+                \"TensorFlow backend.\"\n+            )\n+        self.layer = tf.keras.layers.StringLookup(\n+            max_tokens=max_tokens,\n+            num_oov_indices=num_oov_indices,\n+            mask_token=mask_token,\n+            oov_token=oov_token,\n+            vocabulary=vocabulary,\n+            idf_weights=idf_weights,\n+            invert=invert,\n+            output_mode=output_mode,\n+            pad_to_max_tokens=pad_to_max_tokens,\n+            sparse=sparse,\n+            encoding=encoding,\n+            name=name,\n+            **kwargs,\n+        )\n+        self._allow_non_tensor_positional_args = True\n+\n+    def adapt(self, data, batch_size=None, steps=None):\n+        \"\"\"Computes a vocabulary of interger terms from tokens in a dataset.\n+\n+        Calling `adapt()` on a `StringLookup` layer is an alternative to passing\n+        in a precomputed vocabulary on construction via the `vocabulary`\n+        argument. A `StringLookup` layer should always be either adapted over a\n+        dataset or supplied with a vocabulary.\n+\n+        During `adapt()`, the layer will build a vocabulary of all string tokens\n+        seen in the dataset, sorted by occurrence count, with ties broken by\n+        sort order of the tokens (high to low). At the end of `adapt()`, if\n+        `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\n+        size. For example, adapting a layer with `max_tokens=1000` will compute\n+        the 1000 most frequent tokens occurring in the input dataset. If\n+        `output_mode='tf-idf'`, `adapt()` will also learn the document\n+        frequencies of each token in the input dataset.\n+\n+        Arguments:\n+            data: The data to train on. It can be passed either as a\n+                batched `tf.data.Dataset`, as a list of strings,\n+                or as a NumPy array.\n+            batch_size: Integer or `None`.\n+                Number of samples per state update.\n+                If unspecified, `batch_size` will default to 32.\n+                Do not specify the `batch_size` if your data is in the\n+                form of a `tf.data.Dataset`\n+                (it is expected to be already batched).\n+            steps: Integer or `None`.\n+                Total number of steps (batches of samples)\n+                When training with input tensors such as\n+                the default `None` is equal to\n+                the number of samples in your dataset divided by\n+                the batch size, or 1 if that cannot be determined.\n+                If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n+                `adapt()` will run until the input dataset is exhausted.\n+                When passing an infinitely\n+                repeating dataset, you must specify the `steps` argument. This\n+                argument is not supported with array inputs or list inputs.\n+        \"\"\"\n+        self.layer.adapt(data, batch_size=batch_size, steps=steps)\n+\n+    def update_state(self, data):\n+        self.layer.update_state(data)\n+\n+    def finalize_state(self):\n+        self.layer.finalize_state()\n+\n+    def reset_state(self):\n+        self.layer.reset_state()\n+\n+    def get_vocabulary(self, include_special_tokens=True):\n+        \"\"\"Returns the current vocabulary of the layer.\n+\n+        Args:\n+            include_special_tokens: If `True`, the returned vocabulary\n+                will include the padding and OOV tokens,\n+                and a term's index in the vocabulary will equal\n+                the term's index when calling the layer. If `False`, the\n+                returned vocabulary will not include any padding\n+                or OOV tokens.\n+        \"\"\"\n+        return self.layer.get_vocabulary(\n+            include_special_tokens=include_special_tokens\n+        )\n+\n+    def vocabulary_size(self):\n+        \"\"\"Gets the current size of the layer's vocabulary.\n+\n+        Returns:\n+            The integer size of the vocabulary, including optional\n+            mask and OOV indices.\n+        \"\"\"\n+        return self.layer.vocabulary_size()\n+\n+    def get_config(self):\n+        return self.layer.get_config()\n+\n+    def set_vocabulary(self, vocabulary, idf_weights=None):\n+        \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n+\n+        This method sets the vocabulary and IDF weights for this layer directly,\n+        instead of analyzing a dataset through `adapt()`. It should be used\n+        whenever the vocab (and optionally document frequency) information is\n+        already known. If vocabulary data is already present in the layer, this\n+        method will replace it.\n+\n+        Args:\n+            vocabulary: Either an array or a string path to a text file.\n+                If passing an array, can pass a tuple, list, 1D NumPy array,\n+                or 1D tensor containing the vocbulary terms.\n+                If passing a file path, the file should contain one line\n+                per term in the vocabulary.\n+            idf_weights: A tuple, list, 1D NumPy array, or 1D tensor of inverse\n+                document frequency weights with equal length to vocabulary.\n+                Must be set if `output_mode` is `\"tf_idf\"`.\n+                Should not be set otherwise.\n+        \"\"\"\n+        self.layer.set_vocabulary(vocabulary, idf_weights=idf_weights)\n+\n+    def call(self, inputs):\n+        if not isinstance(inputs, (tf.Tensor, np.ndarray, list, tuple)):\n+            inputs = tf.convert_to_tensor(np.array(inputs))\n+        outputs = self.layer.call(inputs)\n+        if backend.backend() != \"tensorflow\":\n+            outputs = backend.convert_to_tensor(outputs)\n+        return outputs\n+\n+    def save_own_variables(self, store):\n+        self.layer.save_own_variables(store)\n+\n+    def load_own_variables(self, store):\n+        self.layer.load_own_variables(store)\n+\n+    def save_assets(self, dir_path):\n+        self.layer.save_assets(dir_path)\n+\n+    def load_assets(self, dir_path):\n+        self.layer.load_assets(dir_path)\n\n@@ -0,0 +1,46 @@\n+import numpy as np\n+\n+from keras_core import backend\n+from keras_core import layers\n+from keras_core import testing\n+\n+\n+class StringLookupTest(testing.TestCase):\n+    def test_config(self):\n+        layer = layers.StringLookup(\n+            output_mode=\"int\",\n+            vocabulary=[\"a\", \"b\", \"c\"],\n+            oov_token=\"[OOV]\",\n+            mask_token=\"[MASK]\",\n+        )\n+        self.run_class_serialization_test(layer)\n+\n+    def test_adapt_flow(self):\n+        layer = layers.StringLookup(\n+            output_mode=\"int\",\n+        )\n+        layer.adapt([\"a\", \"a\", \"a\", \"b\", \"b\", \"c\"])\n+        input_data = [\"b\", \"c\", \"d\"]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 0]))\n+\n+    def test_fixed_vocabulary(self):\n+        layer = layers.StringLookup(\n+            output_mode=\"int\",\n+            vocabulary=[\"a\", \"b\", \"c\"],\n+        )\n+        input_data = [\"b\", \"c\", \"d\"]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 0]))\n+\n+    def test_set_vocabulary(self):\n+        layer = layers.StringLookup(\n+            output_mode=\"int\",\n+        )\n+        layer.set_vocabulary([\"a\", \"b\", \"c\"])\n+        input_data = [\"b\", \"c\", \"d\"]\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([2, 3, 0]))\n\n@@ -275,7 +275,7 @@ class TextVectorization(Layer):\n                 the number of samples in your dataset divided by\n                 the batch size, or 1 if that cannot be determined.\n                 If `data` is a `tf.data.Dataset`, and `steps` is `None`,\n-                the epoch will run until the input dataset is exhausted.\n+                `adapt()` will run until the input dataset is exhausted.\n                 When passing an infinitely\n                 repeating dataset, you must specify the `steps` argument. This\n                 argument is not supported with array inputs or list inputs.\n@@ -333,7 +333,7 @@ class TextVectorization(Layer):\n     def set_vocabulary(self, vocabulary, idf_weights=None):\n         \"\"\"Sets vocabulary (and optionally document frequency) for this layer.\n \n-        This method sets the vocabulary and idf weights for this layer directly,\n+        This method sets the vocabulary and IDF weights for this layer directly,\n         instead of analyzing a dataset through `adapt()`. It should be used\n         whenever the vocab (and optionally document frequency) information is\n         already known. If vocabulary data is already present in the layer, this\n\n@@ -17,27 +17,41 @@ class TextVectorizationTest(testing.TestCase):\n     def test_adapt_flow(self):\n         max_tokens = 5000\n         max_len = 4\n-        vectorize_layer = layers.TextVectorization(\n+        layer = layers.TextVectorization(\n             max_tokens=max_tokens,\n             output_mode=\"int\",\n             output_sequence_length=max_len,\n         )\n-        vectorize_layer.adapt([\"foo bar\", \"bar baz\", \"baz bada boom\"])\n+        layer.adapt([\"foo bar\", \"bar baz\", \"baz bada boom\"])\n         input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n-        output = vectorize_layer(input_data)\n+        output = layer(input_data)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n \n     def test_fixed_vocabulary(self):\n         max_tokens = 5000\n         max_len = 4\n-        vectorize_layer = layers.TextVectorization(\n+        layer = layers.TextVectorization(\n             max_tokens=max_tokens,\n             output_mode=\"int\",\n             output_sequence_length=max_len,\n             vocabulary=[\"baz\", \"bar\", \"foo\"],\n         )\n         input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n-        output = vectorize_layer(input_data)\n+        output = layer(input_data)\n+        self.assertTrue(backend.is_tensor(output))\n+        self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n+\n+    def test_set_vocabulary(self):\n+        max_tokens = 5000\n+        max_len = 4\n+        layer = layers.TextVectorization(\n+            max_tokens=max_tokens,\n+            output_mode=\"int\",\n+            output_sequence_length=max_len,\n+        )\n+        layer.set_vocabulary([\"baz\", \"bar\", \"foo\"])\n+        input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n+        output = layer(input_data)\n         self.assertTrue(backend.is_tensor(output))\n         self.assertAllClose(output, np.array([[4, 1, 3, 0], [1, 2, 0, 0]]))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
