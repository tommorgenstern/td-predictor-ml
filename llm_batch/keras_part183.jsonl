{"custom_id": "keras#ac6fde801c6b39588aae8e8660e5bbbbf0542110", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 20 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/4 | Churn Δ: 20 | Churn Cumulative: 7648 | Contributors (this commit): 70 | Commits (past 90d): 68 | Contributors (cumulative): 76 | DMM Complexity: 0.2\n\nDIFF:\n@@ -902,6 +902,16 @@ def batch_dot(x, y, axes=None):\n     \"\"\"\n     if isinstance(axes, int):\n         axes = (axes, axes)\n+    x_ndim = ndim(x)\n+    y_ndim = ndim(y)\n+    if x_ndim > y_ndim:\n+        diff = x_ndim - y_ndim\n+        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n+    elif y_ndim > x_ndim:\n+        diff = y_ndim - x_ndim\n+        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n+    else:\n+        diff = 0\n     if ndim(x) == 2 and ndim(y) == 2:\n         if axes[0] == axes[1]:\n             out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n@@ -915,6 +925,12 @@ def batch_dot(x, y, axes=None):\n             adj_x = None\n             adj_y = None\n         out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n+    if diff:\n+        if x_ndim > y_ndim:\n+            idx = x_ndim + y_ndim - 3\n+        else:\n+            idx = x_ndim - 1\n+        out = tf.squeeze(out, list(range(idx, idx + diff)))\n     if ndim(out) == 1:\n         out = expand_dims(out, 1)\n     return out\n\n@@ -83,6 +83,10 @@ class TestBackend(object):\n \n         check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 5, 3),\n                                    axes=(2, 2))\n+        check_two_tensor_operation('batch_dot', (4, 2, 3), (4, 3),\n+                                   axes=(2, 1))\n+        check_two_tensor_operation('batch_dot', (4, 2), (4, 2, 3),\n+                                   axes=(1, 1))\n         check_two_tensor_operation('batch_dot', (32, 20), (32, 20), axes=1)\n         check_two_tensor_operation('batch_dot', (32, 20), (32, 20), axes=(1, 1))\n         check_single_tensor_operation('transpose', (4, 2))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9adb43e44b46a287db94370d5081c542bf91f5db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 16 | Lines Deleted: 18 | Files Changed: 1 | Hunks: 16 | Methods Changed: 6 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 34 | Churn Cumulative: 4245 | Contributors (this commit): 39 | Commits (past 90d): 39 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -1126,7 +1126,7 @@ class Model(Container):\n                 batch_ids = index_array[batch_start:batch_end]\n                 try:\n                     if isinstance(ins[-1], float):\n-                        # do not slice the training phase flag\n+                        # Do not slice the training phase flag.\n                         ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n                     else:\n                         ins_batch = _slice_arrays(ins, batch_ids)\n@@ -1146,16 +1146,14 @@ class Model(Container):\n \n                 callbacks.on_batch_end(batch_index, batch_logs)\n \n-                if batch_index == len(batches) - 1:  # last batch\n-                    # validation\n+                if batch_index == len(batches) - 1:  # Last batch.\n                     if do_validation:\n-                        # replace with self._evaluate\n                         val_outs = self._test_loop(val_f, val_ins,\n                                                    batch_size=batch_size,\n                                                    verbose=0)\n                         if not isinstance(val_outs, list):\n                             val_outs = [val_outs]\n-                        # same labels assumed\n+                        # Same labels assumed.\n                         for l, o in zip(out_labels, val_outs):\n                             epoch_logs['val_' + l] = o\n             callbacks.on_epoch_end(epoch, epoch_logs)\n@@ -1195,7 +1193,7 @@ class Model(Container):\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             batch_ids = index_array[batch_start:batch_end]\n             if ins and isinstance(ins[-1], float):\n-                # do not slice the training phase flag\n+                # Do not slice the training phase flag.\n                 ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n             else:\n                 ins_batch = _slice_arrays(ins, batch_ids)\n@@ -1249,7 +1247,7 @@ class Model(Container):\n         for batch_index, (batch_start, batch_end) in enumerate(batches):\n             batch_ids = index_array[batch_start:batch_end]\n             if isinstance(ins[-1], float):\n-                # do not slice the training phase flag\n+                # Do not slice the training phase flag.\n                 ins_batch = _slice_arrays(ins[:-1], batch_ids) + [ins[-1]]\n             else:\n                 ins_batch = _slice_arrays(ins, batch_ids)\n@@ -1397,14 +1395,14 @@ class Model(Container):\n         if kwargs:\n             raise TypeError('Unrecognized keyword arguments: ' + str(kwargs))\n \n-        # validate user data\n+        # Validate user data.\n         x, y, sample_weights = self._standardize_user_data(\n             x, y,\n             sample_weight=sample_weight,\n             class_weight=class_weight,\n             check_batch_axis=False,\n             batch_size=batch_size)\n-        # prepare validation data\n+        # Prepare validation data.\n         if validation_data:\n             do_validation = True\n             if len(validation_data) == 2:\n@@ -1450,7 +1448,7 @@ class Model(Container):\n             val_f = None\n             val_ins = None\n \n-        # prepare input arrays and training function\n+        # Prepare input arrays and training function.\n         if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [1.]\n         else:\n@@ -1458,11 +1456,11 @@ class Model(Container):\n         self._make_train_function()\n         f = self.train_function\n \n-        # prepare display labels\n+        # Prepare display labels.\n         out_labels = self.metrics_names\n \n-        # rename duplicated metrics name\n-        # (can happen with an output layer shared among multiple dataflows)\n+        # Rename duplicated metrics name\n+        # (can happen with an output layer shared among multiple dataflows).\n         deduped_out_labels = []\n         for i, label in enumerate(out_labels):\n             new_label = label\n@@ -1477,7 +1475,7 @@ class Model(Container):\n         else:\n             callback_metrics = copy.copy(out_labels)\n \n-        # delegate logic to _fit_loop\n+        # Delegate logic to `_fit_loop`.\n         return self._fit_loop(f, ins, out_labels=out_labels,\n                               batch_size=batch_size, epochs=epochs,\n                               verbose=verbose, callbacks=callbacks,\n@@ -1512,13 +1510,13 @@ class Model(Container):\n             and/or metrics). The attribute `model.metrics_names` will give you\n             the display labels for the scalar outputs.\n         \"\"\"\n-        # validate user data\n+        # Validate user data.\n         x, y, sample_weights = self._standardize_user_data(\n             x, y,\n             sample_weight=sample_weight,\n             check_batch_axis=False,\n             batch_size=batch_size)\n-        # prepare inputs, delegate logic to _test_loop\n+        # Prepare inputs, delegate logic to `_test_loop`.\n         if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + y + sample_weights + [0.]\n         else:\n@@ -1549,7 +1547,7 @@ class Model(Container):\n                 or in case a stateful model receives a number of samples\n                 that is not a multiple of the batch size.\n         \"\"\"\n-        # validate user data\n+        # Validate user data.\n         x = _standardize_input_data(x, self._feed_input_names,\n                                     self._feed_input_shapes,\n                                     check_batch_axis=False)\n@@ -1562,7 +1560,7 @@ class Model(Container):\n                                  str(x[0].shape[0]) + ' samples. '\n                                  'Batch size: ' + str(batch_size) + '.')\n \n-        # prepare inputs, delegate logic to _predict_loop\n+        # Prepare inputs, delegate logic to `_predict_loop`.\n         if self.uses_learning_phase and not isinstance(K.learning_phase(), int):\n             ins = x + [0.]\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#172397ebf45d58ba256c10004c6fce8b40df286b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 34 | Churn Cumulative: 988 | Contributors (this commit): 18 | Commits (past 90d): 15 | Contributors (cumulative): 18 | DMM Complexity: 1.0\n\nDIFF:\n@@ -111,7 +111,10 @@ def print_summary(model, line_length=None, positions=None):\n         else:\n             print('_' * line_length)\n \n-    trainable_count, non_trainable_count = count_total_params(layers, layer_set=None)\n+    trainable_count = int(\n+        np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n+    non_trainable_count = int(\n+        np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n \n     print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n     print('Trainable params: {:,}'.format(trainable_count))\n@@ -119,35 +122,6 @@ def print_summary(model, line_length=None, positions=None):\n     print('_' * line_length)\n \n \n-def count_total_params(layers, layer_set=None):\n-    \"\"\"Counts the number of parameters in a list of layers.\n-\n-    # Arguments\n-        layers: list of layers.\n-        layer_set: set of layers already seen\n-            (so that we don't count their weights twice).\n-\n-    # Returns\n-        A tuple (count of trainable weights, count of non-trainable weights.)\n-    \"\"\"\n-    if layer_set is None:\n-        layer_set = set()\n-    trainable_count = 0\n-    non_trainable_count = 0\n-    for layer in layers:\n-        if layer in layer_set:\n-            continue\n-        layer_set.add(layer)\n-        if hasattr(layer, 'layers'):\n-            t, nt = count_total_params(layer.layers, layer_set)\n-            trainable_count += t\n-            non_trainable_count += nt\n-        else:\n-            trainable_count += np.sum([K.count_params(p) for p in layer.trainable_weights])\n-            non_trainable_count += np.sum([K.count_params(p) for p in layer.non_trainable_weights])\n-    return int(trainable_count), int(non_trainable_count)\n-\n-\n def convert_all_kernels_in_model(model):\n     \"\"\"Converts all convolution kernels in a model from Theano to TensorFlow.\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b558a7e97c93d80b21f577d67b3418139f7f7146", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 8 | Churn Cumulative: 262 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 2 | DMM Complexity: 1.0\n\nDIFF:\n@@ -57,6 +57,14 @@ def test_dropout(layer_class):\n                        'dropout': 0.1,\n                        'recurrent_dropout': 0.1},\n                input_shape=(num_samples, timesteps, embedding_dim))\n+    # Test that dropout is not applied during testing\n+    x = np.random.random((num_samples, timesteps, embedding_dim))\n+    layer = layer_class(units, dropout=0.5, recurrent_dropout=0.5,\n+                        input_shape=(timesteps, embedding_dim))\n+    model = Sequential([layer])\n+    y1 = model.predict(x)\n+    y2 = model.predict(x)\n+    assert_allclose(y1, y2)\n \n \n @rnn_test\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#52b1377fe691eff7419b5168a2fdbc93a57d96ea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 267 | Contributors (this commit): 8 | Commits (past 90d): 6 | Contributors (cumulative): 8 | DMM Complexity: None\n\nDIFF:\n@@ -24,7 +24,7 @@ from keras import backend as K\n \n def euclidean_distance(vects):\n     x, y = vects\n-    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n+    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n \n \n def eucl_dist_output_shape(shapes):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#17ef113ed76cd646622acd7eabeea473c5a59f86", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 38 | Lines Deleted: 0 | Files Changed: 3 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 5/3 | Churn Δ: 38 | Churn Cumulative: 20170 | Contributors (this commit): 109 | Commits (past 90d): 156 | Contributors (cumulative): 165 | DMM Complexity: 0.26666666666666666\n\nDIFF:\n@@ -626,6 +626,18 @@ def ones_like(x, dtype=None, name=None):\n     return tf.ones_like(x, dtype=dtype, name=name)\n \n \n+def identity(x):\n+    \"\"\"Returns a tensor with the same content as the input tensor.\n+\n+    # Arguments\n+        x: The input tensor.\n+\n+    # Returns\n+        A tensor of the same shape, type and content.\n+    \"\"\"\n+    return tf.identity(x)\n+\n+\n def random_uniform_variable(shape, low, high, dtype=None,\n                             name=None, seed=None):\n     \"\"\"Instantiates a variable with values drawn from a uniform distribution.\n\n@@ -258,6 +258,18 @@ def zeros_like(x, dtype=None, name=None):\n     return T.zeros_like(x, dtype=dtype)\n \n \n+def identity(x):\n+    \"\"\"Returns a tensor with the same content as the input tensor.\n+\n+    # Arguments\n+        x: The input tensor.\n+\n+    # Returns\n+        A tensor of the same shape, type and content.\n+    \"\"\"\n+    return x.copy()\n+\n+\n def random_uniform_variable(shape, low, high, dtype=None, name=None):\n     return variable(np.random.uniform(low=low, high=high, size=shape),\n                     dtype=dtype, name=name)\n\n@@ -578,6 +578,20 @@ class Layer(object):\n             output = self.call(inputs, **kwargs)\n             output_mask = self.compute_mask(inputs, previous_mask)\n \n+            # If the layer returns tensors from its inputs, unmodified,\n+            # we copy them to avoid loss of tensor metadata.\n+            output_ls = _to_list(output)\n+            inputs_ls = _to_list(inputs)\n+            output_ls_copy = []\n+            for x in output_ls:\n+                if x in inputs_ls:\n+                    x = K.identity(x)\n+                output_ls_copy.append(x)\n+            if len(output_ls_copy) == 1:\n+                output = output_ls_copy[0]\n+            else:\n+                output = output_ls_copy\n+\n             # Infering the output shape is only relevant for Theano.\n             if all([s is not None for s in _to_list(input_shape)]):\n                 output_shape = self.compute_output_shape(input_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2f0dd4cb2eba673c25742c87d78b895af1a9c53", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 7 | Files Changed: 1 | Hunks: 8 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 20 | Churn Cumulative: 4265 | Contributors (this commit): 39 | Commits (past 90d): 40 | Contributors (cumulative): 39 | DMM Complexity: 0.0\n\nDIFF:\n@@ -50,6 +50,8 @@ def _standardize_input_data(data, names, shapes=None,\n     # Raises\n         ValueError: in case of improperly formatted user-provided data.\n     \"\"\"\n+    if not names:\n+        return []\n     if data is None:\n         return [None for _ in range(len(names))]\n     if isinstance(data, dict):\n@@ -63,7 +65,8 @@ def _standardize_input_data(data, names, shapes=None,\n     elif isinstance(data, list):\n         if len(data) != len(names):\n             if data and hasattr(data[0], 'shape'):\n-                raise ValueError('Error when checking ' + exception_prefix +\n+                raise ValueError('Error when checking model ' +\n+                                 exception_prefix +\n                                  ': the list of Numpy arrays '\n                                  'that you are passing to your model '\n                                  'is not the size the model expected. '\n@@ -77,7 +80,8 @@ def _standardize_input_data(data, names, shapes=None,\n                     data = [np.asarray(data)]\n                 else:\n                     raise ValueError(\n-                        'Error when checking ' + exception_prefix +\n+                        'Error when checking model ' +\n+                        exception_prefix +\n                         ': you are passing a list as '\n                         'input to your model, '\n                         'but the model expects '\n@@ -88,15 +92,17 @@ def _standardize_input_data(data, names, shapes=None,\n         arrays = data\n     else:\n         if not hasattr(data, 'shape'):\n-            raise TypeError('Error when checking ' + exception_prefix +\n+            raise TypeError('Error when checking model ' +\n+                            exception_prefix +\n                             ': data should be a Numpy array, '\n                             'or list/dict of Numpy arrays. '\n                             'Found: ' + str(data)[:200] + '...')\n-        if len(names) != 1:\n+        if len(names) > 1:\n             # Case: model expects multiple inputs but only received\n             # a single Numpy array.\n             raise ValueError('The model expects ' + str(len(names)) +\n-                             ' input arrays, but only received one array. '\n+                             exception_prefix +\n+                             ' arrays, but only received one array. '\n                              'Found: array with shape ' + str(data.shape))\n         arrays = [data]\n \n@@ -1291,11 +1297,11 @@ class Model(Container):\n         x = _standardize_input_data(x, self._feed_input_names,\n                                     self._feed_input_shapes,\n                                     check_batch_axis=False,\n-                                    exception_prefix='model input')\n+                                    exception_prefix='input')\n         y = _standardize_input_data(y, self._feed_output_names,\n                                     output_shapes,\n                                     check_batch_axis=False,\n-                                    exception_prefix='model target')\n+                                    exception_prefix='target')\n         sample_weights = _standardize_sample_weights(sample_weight,\n                                                      self._feed_output_names)\n         class_weights = _standardize_class_weights(class_weight,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4aa41625bf0e32eecf96b825db2d8f273fa40183", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 23 | Files Changed: 2 | Hunks: 8 | Methods Changed: 4 | Complexity Δ (Sum/Max): -2/0 | Churn Δ: 35 | Churn Cumulative: 683 | Contributors (this commit): 10 | Commits (past 90d): 9 | Contributors (cumulative): 15 | DMM Complexity: 0.0\n\nDIFF:\n@@ -42,11 +42,6 @@ h_decoded = decoder_h(z)\n x_decoded_mean = decoder_mean(h_decoded)\n \n \n-# placeholder loss\n-def zero_loss(y_true, y_pred):\n-    return K.zeros_like(y_pred)\n-\n-\n # Custom loss layer\n class CustomVariationalLayer(Layer):\n     def __init__(self, **kwargs):\n@@ -63,12 +58,12 @@ class CustomVariationalLayer(Layer):\n         x_decoded_mean = inputs[1]\n         loss = self.vae_loss(x, x_decoded_mean)\n         self.add_loss(loss, inputs=inputs)\n-        # we don't use this output, but it has to have the correct shape:\n-        return K.ones_like(x)\n+        # We won't actually use the output.\n+        return x\n \n-loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n-vae = Model(x, [loss_layer])\n-vae.compile(optimizer='rmsprop', loss=[zero_loss])\n+y = CustomVariationalLayer()([x, x_decoded_mean])\n+vae = Model(x, y)\n+vae.compile(optimizer='rmsprop', loss=None)\n \n \n # train the VAE on MNIST digits\n@@ -79,7 +74,7 @@ x_test = x_test.astype('float32') / 255.\n x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n \n-vae.fit(x_train, x_train,\n+vae.fit(x_train,\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n\n@@ -106,11 +106,6 @@ x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n \n \n-# placeholder loss\n-def zero_loss(y_true, y_pred):\n-    return K.zeros_like(y_pred)\n-\n-\n # Custom loss layer\n class CustomVariationalLayer(Layer):\n     def __init__(self, **kwargs):\n@@ -129,14 +124,13 @@ class CustomVariationalLayer(Layer):\n         x_decoded_mean_squash = inputs[1]\n         loss = self.vae_loss(x, x_decoded_mean_squash)\n         self.add_loss(loss, inputs=inputs)\n-        # we don't use this output, but it has to have the correct shape:\n-        return K.ones_like(x)\n+        # We don't use this output.\n+        return x\n \n \n-loss_layer = CustomVariationalLayer()([x, x_decoded_mean_squash])\n-\n-vae = Model(x, [loss_layer])\n-vae.compile(optimizer='rmsprop', loss=zero_loss)\n+y = CustomVariationalLayer()([x, x_decoded_mean_squash])\n+vae = Model(x, y)\n+vae.compile(optimizer='rmsprop', loss=None)\n vae.summary()\n \n # train the VAE on MNIST digits\n@@ -149,7 +143,7 @@ x_test = x_test.reshape((x_test.shape[0],) + original_img_size)\n \n print('x_train.shape:', x_train.shape)\n \n-vae.fit(x_train, x_train,\n+vae.fit(x_train,\n         shuffle=True,\n         epochs=epochs,\n         batch_size=batch_size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5bd3976e790e6f0b23d372ca2ae01f1f4dfef73f", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 1 | Hunks: 6 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 466 | Contributors (this commit): 10 | Commits (past 90d): 7 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -78,7 +78,7 @@ INVERT = True\n \n # Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n # int is DIGITS.\n-MAxLEN = DIGITS + 1 + DIGITS\n+MAXLEN = DIGITS + 1 + DIGITS\n \n # All the numbers, plus sign and space for padding.\n chars = '0123456789+ '\n@@ -98,9 +98,9 @@ while len(questions) < TRAINING_SIZE:\n     if key in seen:\n         continue\n     seen.add(key)\n-    # Pad the data with spaces such that it is always MAxLEN.\n+    # Pad the data with spaces such that it is always MAXLEN.\n     q = '{}+{}'.format(a, b)\n-    query = q + ' ' * (MAxLEN - len(q))\n+    query = q + ' ' * (MAXLEN - len(q))\n     ans = str(a + b)\n     # Answers can be of maximum size DIGITS + 1.\n     ans += ' ' * (DIGITS + 1 - len(ans))\n@@ -113,10 +113,10 @@ while len(questions) < TRAINING_SIZE:\n print('Total addition questions:', len(questions))\n \n print('Vectorization...')\n-x = np.zeros((len(questions), MAxLEN, len(chars)), dtype=np.bool)\n+x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n for i, sentence in enumerate(questions):\n-    x[i] = ctable.encode(sentence, MAxLEN)\n+    x[i] = ctable.encode(sentence, MAXLEN)\n for i, sentence in enumerate(expected):\n     y[i] = ctable.encode(sentence, DIGITS + 1)\n \n@@ -151,7 +151,7 @@ model = Sequential()\n # \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n # Note: In a situation where your input sequences have a variable length,\n # use input_shape=(None, num_feature).\n-model.add(RNN(HIDDEN_SIZE, input_shape=(MAxLEN, len(chars))))\n+model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n # As the decoder RNN's input, repeatedly provide with the last hidden state of\n # RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n # length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dcacdd3747df334452ff6361938726d31002c473", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 9097 | Contributors (this commit): 62 | Commits (past 90d): 31 | Contributors (cumulative): 62 | DMM Complexity: None\n\nDIFF:\n@@ -1033,8 +1033,8 @@ class Sequential(Model):\n                 - a tuple (inputs, targets, sample_weights).\n                 All arrays should contain the same number of samples.\n                 The generator is expected to loop over its data\n-                indefinitely. An epoch finishes when `samples_per_epoch`\n-                samples have been seen by the model.\n+                indefinitely. An epoch finishes when `steps_per_epoch`\n+                batches have been seen by the model.\n             steps_per_epoch: Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n@@ -1087,7 +1087,7 @@ class Sequential(Model):\n                         f.close()\n \n             model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n-                                samples_per_epoch=10000, epochs=10)\n+                                steps_per_epoch=1000, epochs=10)\n         ```\n         \"\"\"\n         if self.model is None:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#90758c3f4ed2208b053ef8b7ecc3e0721d9d83ec", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 9099 | Contributors (this commit): 63 | Commits (past 90d): 32 | Contributors (cumulative): 63 | DMM Complexity: None\n\nDIFF:\n@@ -295,7 +295,7 @@ def model_from_config(config, custom_objects=None):\n         A Keras model instance (uncompiled).\n     \"\"\"\n     if isinstance(config, list):\n-        raise TypeError('`model_fom_config` expects a dictionary, not a list. '\n+        raise TypeError('`model_from_config` expects a dictionary, not a list. '\n                         'Maybe you meant to use '\n                         '`Sequential.from_config(config)`?')\n     return layer_module.deserialize(config, custom_objects=custom_objects)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2c284017d48ab0534905f0d287f801db8ba2f673", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 13 | Files Changed: 1 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 30 | Churn Cumulative: 4295 | Contributors (this commit): 40 | Commits (past 90d): 41 | Contributors (cumulative): 40 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1322,6 +1322,20 @@ class Model(Container):\n                                  str(x[0].shape[0]) + ' samples')\n         return x, y, sample_weights\n \n+    def _get_deduped_metrics_names(self):\n+        out_labels = self.metrics_names\n+\n+        # Rename duplicated metrics name\n+        # (can happen with an output layer shared among multiple dataflows).\n+        deduped_out_labels = []\n+        for i, label in enumerate(out_labels):\n+            new_label = label\n+            if out_labels.count(label) > 1:\n+                dup_idx = out_labels[:i].count(label)\n+                new_label += '_' + str(dup_idx + 1)\n+            deduped_out_labels.append(new_label)\n+        return deduped_out_labels\n+\n     def fit(self, x=None,\n             y=None,\n             batch_size=32,\n@@ -1463,18 +1477,7 @@ class Model(Container):\n         f = self.train_function\n \n         # Prepare display labels.\n-        out_labels = self.metrics_names\n-\n-        # Rename duplicated metrics name\n-        # (can happen with an output layer shared among multiple dataflows).\n-        deduped_out_labels = []\n-        for i, label in enumerate(out_labels):\n-            new_label = label\n-            if out_labels.count(label) > 1:\n-                dup_idx = out_labels[:i].count(label)\n-                new_label += '_' + str(dup_idx + 1)\n-            deduped_out_labels.append(new_label)\n-        out_labels = deduped_out_labels\n+        out_labels = self._get_deduped_metrics_names()\n \n         if do_validation:\n             callback_metrics = copy.copy(out_labels) + ['val_' + n for n in out_labels]\n@@ -1789,7 +1792,8 @@ class Model(Container):\n                              'you must specify a value for '\n                              '`validation_steps`.')\n \n-        out_labels = self.metrics_names\n+        # Prepare display labels.\n+        out_labels = self._get_deduped_metrics_names()\n         callback_metrics = out_labels + ['val_' + n for n in out_labels]\n \n         # prepare callbacks\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2a675067287428bd0d6c2c968bac4d0e17e2356d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 6526 | Contributors (this commit): 39 | Commits (past 90d): 28 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -705,7 +705,7 @@ class GRU(Recurrent):\n         if self.use_bias:\n             self.bias = self.add_weight((self.units * 3,),\n                                         name='bias',\n-                                        initializer='zero',\n+                                        initializer=self.bias_initializer,\n                                         regularizer=self.bias_regularizer,\n                                         constraint=self.bias_constraint)\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cd6bbe72908ad6ac144ec9a3647318381b642354", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 9034 | Contributors (this commit): 39 | Commits (past 90d): 93 | Contributors (cumulative): 42 | DMM Complexity: None\n\nDIFF:\n@@ -1263,6 +1263,7 @@ class InputLayer(Layer):\n         name: Name of the layer (string).\n     \"\"\"\n \n+    @interfaces.legacy_input_support\n     def __init__(self, input_shape=None, batch_size=None,\n                  batch_input_shape=None,\n                  dtype=None, input_tensor=None, sparse=False, name=None):\n\n@@ -602,3 +602,7 @@ legacy_model_constructor_support = generate_legacy_interface(\n     allowed_positional_args=None,\n     conversions=[('input', 'inputs'),\n                  ('output', 'outputs')])\n+\n+legacy_input_support = generate_legacy_interface(\n+    allowed_positional_args=None,\n+    conversions=[('input_dtype', 'dtype')])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#707534e46e2db973621858cbe0bfbd31ab2c62a4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 80 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 6/4 | Churn Δ: 80 | Churn Cumulative: 9118 | Contributors (this commit): 34 | Commits (past 90d): 62 | Contributors (cumulative): 37 | DMM Complexity: 0.7377049180327869\n\nDIFF:\n@@ -2762,6 +2762,25 @@ def preprocess_weights_for_loading(layer, weights,\n         A list of weights values (Numpy arrays).\n     \"\"\"\n     if original_keras_version == '1':\n+        if layer.__class__.__name__ == 'Bidirectional':\n+            num_weights_per_layer = len(weights) // 2\n+\n+            forward_weights = preprocess_weights_for_loading(layer.forward_layer,\n+                                                             weights[:num_weights_per_layer],\n+                                                             original_keras_version,\n+                                                             original_backend)\n+            backward_weights = preprocess_weights_for_loading(layer.backward_layer,\n+                                                              weights[num_weights_per_layer:],\n+                                                              original_keras_version,\n+                                                              original_backend)\n+            weights = forward_weights + backward_weights\n+\n+        if layer.__class__.__name__ == 'TimeDistributed':\n+            weights = preprocess_weights_for_loading(layer.layer,\n+                                                     weights,\n+                                                     original_keras_version,\n+                                                     original_backend)\n+\n         if layer.__class__.__name__ == 'Conv1D':\n             shape = weights[0].shape\n             # Handle Keras 1.1 format\n\n@@ -490,6 +490,67 @@ def test_recursion():\n \n \n @keras_test\n+def test_load_layers():\n+    from keras.layers import ConvLSTM2D, TimeDistributed, Bidirectional, Conv2D, Input\n+    from keras.models import Model\n+    from keras.engine.topology import preprocess_weights_for_loading\n+\n+    if K.backend() == 'tensorflow':\n+        inputs = Input(shape=(10, 20, 20, 1))\n+    else:\n+        inputs = Input(shape=(10, 1, 20, 20))\n+    td_conv = TimeDistributed(Conv2D(15, (5, 5)))(inputs)\n+    bi_convlstm2d = Bidirectional(ConvLSTM2D(10, (3, 3)), merge_mode='concat')(td_conv)\n+    model = Model(inputs=inputs, outputs=bi_convlstm2d)\n+\n+    weight_value_tuples = []\n+\n+    # TimeDistributed Conv2D layer\n+    # use 'channels_first' data format to check that the function is being called correctly for Conv2D\n+    # old: (filters, stack_size, kernel_rows, kernel_cols)\n+    # new: (kernel_rows, kernel_cols, stack_size, filters)\n+    weight_tensor_td_conv_old = list()\n+    weight_tensor_td_conv_old.append(np.zeros((15, 1, 5, 5)))\n+    weight_tensor_td_conv_old.append(np.zeros((15,)))\n+    td_conv_layer = model.layers[1]\n+    td_conv_layer.layer.data_format = 'channels_first'\n+    weight_tensor_td_conv_new = preprocess_weights_for_loading(td_conv_layer,\n+                                                               weight_tensor_td_conv_old,\n+                                                               original_keras_version='1')\n+    symbolic_weights = td_conv_layer.weights\n+    assert (len(symbolic_weights) == len(weight_tensor_td_conv_new))\n+    weight_value_tuples += zip(symbolic_weights, weight_tensor_td_conv_new)\n+\n+    # Bidirectional ConvLSTM2D layer\n+    # old ConvLSTM2D took a list of 12 weight tensors, returns a list of 3 concatenated larger tensors.\n+    weight_tensor_bi_convlstm_old = []\n+    for j in range(2):  # bidirectional\n+        for i in range(4):\n+            weight_tensor_bi_convlstm_old.append(np.zeros((3, 3, 15, 10)))  # kernel\n+            weight_tensor_bi_convlstm_old.append(np.zeros((3, 3, 10, 10)))  # recurrent kernel\n+            weight_tensor_bi_convlstm_old.append(np.zeros((10,)))  # bias\n+\n+    bi_convlstm_layer = model.layers[2]\n+    weight_tensor_bi_convlstm_new = preprocess_weights_for_loading(bi_convlstm_layer,\n+                                                                   weight_tensor_bi_convlstm_old,\n+                                                                   original_keras_version='1')\n+\n+    symbolic_weights = bi_convlstm_layer.weights\n+    assert (len(symbolic_weights) == len(weight_tensor_bi_convlstm_new))\n+    weight_value_tuples += zip(symbolic_weights, weight_tensor_bi_convlstm_new)\n+\n+    K.batch_set_value(weight_value_tuples)\n+\n+    assert np.all(K.eval(model.layers[1].weights[0]) == weight_tensor_td_conv_new[0])\n+    assert np.all(K.eval(model.layers[1].weights[1]) == weight_tensor_td_conv_new[1])\n+    assert np.all(K.eval(model.layers[2].weights[0]) == weight_tensor_bi_convlstm_new[0])\n+    assert np.all(K.eval(model.layers[2].weights[1]) == weight_tensor_bi_convlstm_new[1])\n+    assert np.all(K.eval(model.layers[2].weights[2]) == weight_tensor_bi_convlstm_new[2])\n+    assert np.all(K.eval(model.layers[2].weights[3]) == weight_tensor_bi_convlstm_new[3])\n+    assert np.all(K.eval(model.layers[2].weights[4]) == weight_tensor_bi_convlstm_new[4])\n+    assert np.all(K.eval(model.layers[2].weights[5]) == weight_tensor_bi_convlstm_new[5])\n+\n+\n def test_recursion_with_bn_and_loss():\n     model1 = Sequential([\n         layers.Dense(5, input_dim=5, activity_regularizer='l1'),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#53bee2064751cba8baa609bdcb4d3abaace50993", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 4897 | Contributors (this commit): 64 | Commits (past 90d): 41 | Contributors (cumulative): 64 | DMM Complexity: None\n\nDIFF:\n@@ -1,6 +1,7 @@\n from collections import defaultdict\n from contextlib import contextmanager\n import theano\n+from theano import ifelse\n from theano import tensor as T\n from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n from theano.tensor.signal import pool\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73bf06fb023a8b37ddf2e2a168bbf920c7a6c766", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 12 | Churn Cumulative: 9726 | Contributors (this commit): 75 | Commits (past 90d): 46 | Contributors (cumulative): 79 | DMM Complexity: None\n\nDIFF:\n@@ -744,7 +744,7 @@ class Sequential(Model):\n             optimizer: str (name of optimizer) or optimizer object.\n                 See [optimizers](/optimizers).\n             loss: str (name of objective function) or objective function.\n-                See [objectives](/objectives).\n+                See [losses](/losses).\n             metrics: list of metrics to be evaluated by the model\n                 during training and testing.\n                 Typically you will use `metrics=['accuracy']`.\n\n@@ -27,8 +27,8 @@ class CustomObjectScope(object):\n     Consider a custom object `MyObject`\n \n     ```python\n-        with CustomObjectScope({\"MyObject\":MyObject}):\n-            layer = Dense(..., W_regularizer=\"MyObject\")\n+        with CustomObjectScope({'MyObject':MyObject}):\n+            layer = Dense(..., kernel_regularizer='MyObject')\n             # save, load, etc. will recognize custom object by name\n     ```\n     \"\"\"\n@@ -63,8 +63,8 @@ def custom_object_scope(*args):\n     Consider a custom object `MyObject`\n \n     ```python\n-        with custom_object_scope({\"MyObject\":MyObject}):\n-            layer = Dense(..., W_regularizer=\"MyObject\")\n+        with custom_object_scope({'MyObject':MyObject}):\n+            layer = Dense(..., kernel_regularizer='MyObject')\n             # save, load, etc. will recognize custom object by name\n     ```\n \n@@ -89,7 +89,7 @@ def get_custom_objects():\n \n     ```python\n         get_custom_objects().clear()\n-        get_custom_objects()[\"MyObject\"] = MyObject\n+        get_custom_objects()['MyObject'] = MyObject\n     ```\n \n     # Returns\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e0697c3768a53c7b6744e2eab253667d7a42e040", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 997 | Contributors (this commit): 19 | Commits (past 90d): 14 | Contributors (cumulative): 19 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,6 +21,7 @@ def print_summary(model, line_length=None, positions=None):\n         for v in model.nodes_by_depth.values():\n             if len(v) > 1:\n                 sequential_like = False\n+                break\n \n     if sequential_like:\n         line_length = line_length or 65\n@@ -75,11 +76,9 @@ def print_summary(model, line_length=None, positions=None):\n         except AttributeError:\n             output_shape = 'multiple'\n         connections = []\n-        for node_index, node in enumerate(layer.inbound_nodes):\n-            if relevant_nodes:\n-                node_key = layer.name + '_ib-' + str(node_index)\n-                if node_key not in relevant_nodes:\n-                    # node is node part of the current network\n+        for node in layer.inbound_nodes:\n+            if relevant_nodes and node not in relevant_nodes:\n+                # node is not part of the current network\n                 continue\n             for i in range(len(node.inbound_layers)):\n                 inbound_layer = node.inbound_layers[i].name\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#73a620b6e875a2f153cb5acea194d89e845dc726", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2539 | Contributors (this commit): 43 | Commits (past 90d): 12 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -578,7 +578,7 @@ class TensorBoard(Callback):\n     tensorboard --logdir=/full_path_to_your_logs\n     ```\n     You can find more information about TensorBoard\n-    [here](https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html).\n+    [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n \n     # Arguments\n         log_dir: the path of the directory where to save the log\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fc4874f82cda48e0928f9eb730a270f49034883e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 9 | Churn Cumulative: 235 | Contributors (this commit): 8 | Commits (past 90d): 4 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -62,9 +62,14 @@ class HDF5Matrix(object):\n         return self.end - self.start\n \n     def __getitem__(self, key):\n+        start, stop = key.start, key.stop\n         if isinstance(key, slice):\n-            if key.stop + self.start <= self.end:\n-                idx = slice(key.start + self.start, key.stop + self.start)\n+            if start is None:\n+                start = 0\n+            if stop is None:\n+                stop = self.data.shape[0]\n+            if stop + self.start <= self.end:\n+                idx = slice(start + self.start, stop + self.start)\n             else:\n                 raise IndexError\n         elif isinstance(key, int):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#562860ca42d8dd65e87e3f0b8e76b811a718a9a5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 9 | Churn Cumulative: 177 | Contributors (this commit): 11 | Commits (past 90d): 3 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,7 +1,9 @@\n from __future__ import absolute_import\n import six\n+import warnings\n from . import backend as K\n from .utils.generic_utils import deserialize_keras_object\n+from .engine import Layer\n \n \n def softmax(x, axis=-1):\n@@ -78,6 +80,13 @@ def get(identifier):\n         identifier = str(identifier)\n         return deserialize(identifier)\n     elif callable(identifier):\n+        if isinstance(identifier, Layer):\n+            warnings.warn((\n+                'Do not pass a layer instance (such as {identifier}) as the '\n+                'activation argument of another layer. Instead, advanced '\n+                'activation layers should be used just like any other '\n+                'layer in a model.'\n+            ).format(identifier=identifier.__class__.__name__))\n         return identifier\n     else:\n         raise ValueError('Could not interpret '\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#d89afdfd82e6e27b850d910890f4a4059ddea331", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4297 | Contributors (this commit): 41 | Commits (past 90d): 41 | Contributors (cumulative): 41 | DMM Complexity: None\n\nDIFF:\n@@ -1720,7 +1720,7 @@ class Model(Container):\n                 All arrays should contain the same number of samples.\n                 The generator is expected to loop over its data\n                 indefinitely. An epoch finishes when `steps_per_epoch`\n-                samples have been seen by the model.\n+                batches have been seen by the model.\n             steps_per_epoch: Total number of steps (batches of samples)\n                 to yield from `generator` before declaring one epoch\n                 finished and starting the next epoch. It should typically\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
