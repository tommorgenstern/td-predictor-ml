{"custom_id": "keras#6279544dc306f9eff6debb2b17b9e278a69b8ced", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 4 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 150 | Contributors (this commit): 8 | Commits (past 90d): 7 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1 +1 @@\n-__version__ = '0.3.1'\r\n+__version__ = '0.3.2'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='0.3.1',\n-      description='Theano-based Deep Learning library',\n+      version='0.3.2',\n+      description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/0.3.1',\n+      download_url='https://github.com/fchollet/keras/tarball/0.3.2',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7b72163073d8672358ec8c67d1bbb0fbcbf82f3b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 30 | Lines Deleted: 15 | Files Changed: 3 | Hunks: 12 | Methods Changed: 2 | Complexity Δ (Sum/Max): -4/0 | Churn Δ: 45 | Churn Cumulative: 1400 | Contributors (this commit): 11 | Commits (past 90d): 54 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -593,16 +593,20 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n \n     if _on_gpu() and dnn.dnn_available():\n         if border_mode == 'same':\n-            assert(strides == (1, 1))\n+            np_kernel = kernel.eval()\n+            assert strides[0] <= np_kernel.shape[2], 'strides should be smaller than the convolution window.'\n+            assert strides[1] <= np_kernel.shape[3], 'strides should be smaller than the convolution window.'\n             conv_out = dnn.dnn_conv(img=x,\n                                     kerns=kernel,\n                                     border_mode='full')\n-            np_kernel = kernel.eval()\n-            shift_x = (np_kernel.shape[2] - 1) // 2\n-            shift_y = (np_kernel.shape[3] - 1) // 2\n+            shift_x = (np_kernel.shape[2] - strides[0]) // 2\n+            shift_y = (np_kernel.shape[3] - strides[1]) // 2\n+            expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n+            expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n+\n             conv_out = conv_out[:, :,\n-                                shift_x:x.shape[2] + shift_x,\n-                                shift_y:x.shape[3] + shift_y]\n+                                shift_x: shift_x + expected_width,\n+                                shift_y: shift_y + expected_height]\n         else:\n             conv_out = dnn.dnn_conv(img=x,\n                                     kerns=kernel,\n@@ -611,7 +615,9 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n     else:\n         if border_mode == 'same':\n             th_border_mode = 'full'\n-            assert(strides == (1, 1))\n+            np_kernel = kernel.eval()\n+            assert strides[0] <= np_kernel.shape[2], 'strides should be smaller than the convolution window.'\n+            assert strides[1] <= np_kernel.shape[3], 'strides should be smaller than the convolution window.'\n         elif border_mode == 'valid':\n             th_border_mode = 'valid'\n         else:\n@@ -623,12 +629,14 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n                                       image_shape=image_shape,\n                                       filter_shape=filter_shape)\n         if border_mode == 'same':\n-            np_kernel = kernel.eval()\n-            shift_x = (np_kernel.shape[2] - 1) // 2\n-            shift_y = (np_kernel.shape[3] - 1) // 2\n+            shift_x = (np_kernel.shape[2] - strides[0]) // 2\n+            shift_y = (np_kernel.shape[3] - strides[1]) // 2\n+            expected_width = (x.shape[2] + strides[0] - 1) // strides[0]\n+            expected_height = (x.shape[3] + strides[1] - 1) // strides[1]\n+\n             conv_out = conv_out[:, :,\n-                                shift_x:x.shape[2] + shift_x,\n-                                shift_y:x.shape[3] + shift_y]\n+                                shift_x: shift_x + expected_width,\n+                                shift_y: shift_y + expected_height]\n     if dim_ordering == 'tf':\n         conv_out = conv_out.dimshuffle((0, 2, 3, 1))\n     return conv_out\n\n@@ -1,3 +1,4 @@\n+import pytest\n import numpy as np\n \n from keras import objectives\n@@ -29,3 +30,7 @@ def test_objective_shapes_2d():\n     for obj in allobj:\n         objective_output = obj(y_a, y_b)\n         assert K.eval(objective_output).shape == (6,)\n+\n+\n+if __name__ == \"__main__\":\n+    pytest.main([__file__])\n\n@@ -15,6 +15,7 @@ def check_layer_output_shape(layer, input_data):\n \n     function = K.function([layer.input], [layer.get_output()])\n     output = function([input_data])[0]\n+\n     assert output.shape[1:] == expected_output_shape\n \n \n@@ -36,6 +37,7 @@ def test_Reshape():\n     layer = Reshape(dims=(2, -1))\n     check_layer_output_shape(layer, input_data)\n \n+\n def test_Permute():\n     layer = Permute(dims=(1, 3, 2))\n     input_data = np.random.random((2, 2, 4, 3))\n@@ -87,10 +89,10 @@ def test_Convolution1D():\n def test_Convolution2D():\n     for border_mode in ['same', 'valid']:\n         for nb_row, nb_col in [(2, 2), (3, 3)]:\n-            for subsample in [(1, 1), (2, 2)]:\n-                if (subsample[0] > 1 or subsample[1] > 1) and border_mode == 'same':\n+            for subsample in [(1, 1), (2, 2), (3, 3)]:\n+                if (subsample[0] > nb_row or subsample[1] > nb_col) and border_mode == 'same':\n                     continue\n-                for input_data_shape in [(2, 1, 3, 3), (2, 1, 4, 4)]:\n+                for input_data_shape in [(2, 1, 4, 4), (2, 1, 5, 5)]:\n                     layer = Convolution2D(nb_filter=1, nb_row=nb_row,\n                                           nb_col=nb_row,\n                                           border_mode=border_mode,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#23147de72bfef95045aa82ea16f705624d2c7fa1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 296 | Contributors (this commit): 3 | Commits (past 90d): 9 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -88,11 +88,11 @@ def test_Convolution1D():\n \n def test_Convolution2D():\n     for border_mode in ['same', 'valid']:\n-        for nb_row, nb_col in [(2, 2), (3, 3)]:\n+        for nb_row, nb_col in [(3, 3), (4, 4)]:\n             for subsample in [(1, 1), (2, 2), (3, 3)]:\n                 if (subsample[0] > nb_row or subsample[1] > nb_col) and border_mode == 'same':\n                     continue\n-                for input_data_shape in [(2, 1, 4, 4), (2, 1, 5, 5)]:\n+                for input_data_shape in [(2, 1, 5, 5), (2, 1, 6, 6)]:\n                     layer = Convolution2D(nb_filter=1, nb_row=nb_row,\n                                           nb_col=nb_row,\n                                           border_mode=border_mode,\n@@ -101,7 +101,7 @@ def test_Convolution2D():\n                     input_data = np.random.random(input_data_shape)\n                     check_layer_output_shape(layer, input_data)\n \n-                for input_data_shape in [(2, 3, 3, 1)]:\n+                for input_data_shape in [(2, 5, 5, 1)]:\n                     layer = Convolution2D(nb_filter=1, nb_row=nb_row,\n                                           nb_col=nb_row,\n                                           border_mode=border_mode,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#209b42c5eec5fafa16e59f3882b563f27273c462", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 268 | Contributors (this commit): 3 | Commits (past 90d): 6 | Contributors (cumulative): 3 | DMM Complexity: None\n\nDIFF:\n@@ -130,8 +130,8 @@ def process_class_docstring(docstring):\n \n \n def process_method_docstring(docstring):\n-    docstring = re.sub(r'    # (.*)\\n',\n-                       r'    __\\1__\\n\\n',\n+    docstring = re.sub(r'\\n        # (.*)\\n',\n+                       r'\\n        __\\1__\\n\\n',\n                        docstring)\n \n     docstring = re.sub(r'    ([^\\s\\\\]+):(.*)\\n',\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9ad5ed81037480eece92a3d6f4f5825e084f3b16", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 272 | Contributors (this commit): 3 | Commits (past 90d): 7 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -124,6 +124,8 @@ def process_class_docstring(docstring):\n     docstring = re.sub(r'    ([^\\s\\\\]+):(.*)\\n',\n                        r'    - __\\1__:\\2\\n',\n                        docstring)\n+\n+    docstring = docstring.replace('    ' * 5, '\\t\\t')\n     docstring = docstring.replace('    ' * 3, '\\t')\n     docstring = docstring.replace('    ', '')\n     return docstring\n@@ -137,6 +139,8 @@ def process_method_docstring(docstring):\n     docstring = re.sub(r'    ([^\\s\\\\]+):(.*)\\n',\n                        r'    - __\\1__:\\2\\n',\n                        docstring)\n+\n+    docstring = docstring.replace('    ' * 6, '\\t\\t')\n     docstring = docstring.replace('    ' * 4, '\\t')\n     docstring = docstring.replace('    ', '')\n     return docstring\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#6429a57a3cc1e13c5a5e09af57e85bf6cf8c637b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 13 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 5 | Methods Changed: 5 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 14 | Churn Cumulative: 8795 | Contributors (this commit): 42 | Commits (past 90d): 107 | Contributors (cumulative): 57 | DMM Complexity: 0.0\n\nDIFF:\n@@ -21,6 +21,7 @@ class Sequential(Layer):\n     def __init__(self, layers=[]):\n         self.layers = []\n         self.layer_cache = {}\n+        self.shape_cache = {}\n         for layer in layers:\n             self.add(layer)\n         self._cache_enabled = True\n@@ -63,6 +64,7 @@ class Sequential(Layer):\n \n     def add(self, layer):\n         layer.layer_cache = self.layer_cache\n+        layer.shape_cache = self.shape_cache\n         self.layers.append(layer)\n         if len(self.layers) > 1:\n             self.layers[-1].set_previous(self.layers[-2])\n@@ -188,6 +190,7 @@ class Graph(Layer):\n         self.output_config = []  # dicts\n         self.node_config = []  # dicts\n         self.layer_cache = {}\n+        self.shape_cache = {}\n \n     @property\n     def nb_input(self):\n@@ -374,6 +377,7 @@ class Graph(Layer):\n \n         self.namespace.add(name)\n         layer.layer_cache = self.layer_cache\n+        layer.shape_cache = self.shape_cache\n         self.nodes[name] = layer\n         self.node_config.append({'name': name,\n                                  'input': input,\n\n@@ -137,7 +137,15 @@ class Layer(object):\n         # if layer is not connected (e.g. input layer),\n         # input shape can be set manually via _input_shape attribute.\n         if hasattr(self, 'previous'):\n-            return self.previous.output_shape\n+            if hasattr(self, 'shape_cache') and self.cache_enabled:\n+                previous_layer_id = id(self.previous)\n+                if previous_layer_id in self.shape_cache:\n+                    return self.shape_cache[previous_layer_id]\n+            previous_size = self.previous.output_shape\n+            if hasattr(self, 'shape_cache') and self.cache_enabled:\n+                previous_layer_id = id(self.previous)\n+                self.shape_cache[previous_layer_id] = previous_size\n+            return previous_size\n         elif hasattr(self, '_input_shape'):\n             return self._input_shape\n         else:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#8e591d228c135eaac2c42f5a69e09549a45aeadc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 9 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 14 | Churn Cumulative: 272 | Contributors (this commit): 8 | Commits (past 90d): 10 | Contributors (cumulative): 8 | DMM Complexity: 0.0\n\nDIFF:\n@@ -28,18 +28,14 @@ def random_rotation(x, rg, fill_mode=\"nearest\", cval=0.):\n \n \n def random_shift(x, wrg, hrg, fill_mode=\"nearest\", cval=0.):\n-    crop_left_pixels = 0\n-    crop_top_pixels = 0\n+    shift_x = shift_y = 0\n     \n     if wrg:\n-        crop = random.uniform(0., wrg)\n-        split = random.uniform(0, 1)\n-        crop_left_pixels = int(split*crop*x.shape[1])\n+        shift_x = random.uniform(-wrg, wrg) * x.shape[2]\n     if hrg:\n-        crop = random.uniform(0., hrg)\n-        split = random.uniform(0, 1)\n-        crop_top_pixels = int(split*crop*x.shape[2])\n-    x = ndimage.interpolation.shift(x, (0, crop_left_pixels, crop_top_pixels),\n+        shift_y = random.uniform(-hrg, hrg) * x.shape[1]\n+        \n+    x = ndimage.interpolation.shift(x, (0, shift_y, shift_x),\n                                     order=0,\n                                     mode=fill_mode,\n                                     cval=cval)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4d3ee897da3b9072494c112d9a9c6cc97596a0f9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): -5/0 | Churn Δ: 4 | Churn Cumulative: 7639 | Contributors (this commit): 39 | Commits (past 90d): 72 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -526,8 +526,8 @@ class Merge(Layer):\n             return output\n         elif self.mode == 'cos':\n             if K._BACKEND != 'theano':\n-                raise Exception('\"dot\" merge mode will only work with Theano.')\n-            import theano\n+                raise Exception('\"cos\" merge mode will only work with Theano.')\n+            from theano import tensor as T\n             l1 = self.layers[0].get_output(train)\n             l2 = self.layers[1].get_output(train)\n             output = T.batched_tensordot(l1, l2, self.dot_axes) / T.sqrt(T.batched_tensordot(l1, l1, self.dot_axes) * T.batched_tensordot(l2, l2, self.dot_axes))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0bf2b1b075223d9e53bc16e63e2ee11fa839508e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 940 | Contributors (this commit): 6 | Commits (past 90d): 34 | Contributors (cumulative): 6 | DMM Complexity: None\n\nDIFF:\n@@ -500,7 +500,9 @@ def switch(condition, then_expression, else_expression):\n def relu(x, alpha=0., max_value=None):\n     '''ReLU.\n \n+    # Arguments\n         alpha: slope of negative section.\n+        max_value: saturation threshold.\n     '''\n     negative_part = tf.nn.relu(-x)\n     x = tf.nn.relu(x)\n@@ -584,8 +586,9 @@ def l2_normalize(x, axis):\n \n def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n            image_shape=None, filter_shape=None):\n-    '''\n-    Run on cuDNN if available.\n+    '''Runs on cuDNN if available.\n+\n+    # Arguments\n         border_mode: string, \"same\" or \"valid\".\n         dim_ordering: whether to use Theano or TensorFlow dimension ordering\n         in inputs/kernels/ouputs.\n@@ -628,6 +631,7 @@ def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th',\n def pool2d(x, pool_size, strides=(1, 1),\n            border_mode='valid', dim_ordering='th', pool_mode='max'):\n     '''\n+    # Arguments\n         pool_size: tuple of 2 integers.\n         strides: tuple of 2 integers.\n         border_mode: one of \"valid\", \"same\".\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#1e46a5d3ec173b3f5f264a080bd29901c3839bd7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 7641 | Contributors (this commit): 39 | Commits (past 90d): 73 | Contributors (cumulative): 39 | DMM Complexity: None\n\nDIFF:\n@@ -230,7 +230,7 @@ class Layer(object):\n                                              str(len(weights)) + ' provided weights)')\n         for p, w in zip(params, weights):\n             if K.get_value(p).shape != w.shape:\n-                raise Exception('Layer shape %s not compatible with weight shape %s.' % (K.get_value(p).shape, w.shape))\n+                raise Exception('Layer weight shape %s not compatible with provided weight shape %s.' % (K.get_value(p).shape, w.shape))\n             K.set_value(p, w)\n \n     def get_weights(self):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#27dd1e939c03325e3b414dacb9d83cd7d3f07dea", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 57 | Churn Cumulative: 622 | Contributors (this commit): 5 | Commits (past 90d): 17 | Contributors (cumulative): 7 | DMM Complexity: 1.0\n\nDIFF:\n@@ -113,6 +113,38 @@ def test_convolution_2d():\n                             layer.get_config()\n \n \n+def test_convolution_2d_dim_ordering():\n+    nb_filter = 4\n+    nb_row = 3\n+    nb_col = 2\n+    stack_size = 3\n+\n+    np.random.seed(1337)\n+    weights = [np.random.random((nb_filter, stack_size, nb_row, nb_col)),\n+               np.random.random(nb_filter)]\n+    input = np.random.random((1, stack_size, 10, 10))\n+\n+    layer = convolutional.Convolution2D(\n+        nb_filter, nb_row, nb_col,\n+        weights=weights,\n+        input_shape=input.shape[1:],\n+        dim_ordering='th')\n+    layer.input = K.variable(input)\n+    out_th = K.eval(layer.get_output(False))\n+\n+    input = np.transpose(input, (0, 2, 3, 1))\n+    weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n+    layer = convolutional.Convolution2D(\n+        nb_filter, nb_row, nb_col,\n+        weights=weights,\n+        input_shape=input.shape[1:],\n+        dim_ordering='tf')\n+    layer.input = K.variable(input)\n+    out_tf = K.eval(layer.get_output(False))\n+\n+    assert_allclose(out_tf, np.transpose(out_th, (0, 2, 3, 1)), atol=1e-05)\n+\n+\n def test_maxpooling_2d():\n     nb_samples = 9\n     stack_size = 7\n@@ -131,6 +163,29 @@ def test_maxpooling_2d():\n         layer.get_config()\n \n \n+def test_maxpooling_2d_dim_ordering():\n+    stack_size = 3\n+\n+    input = np.random.random((1, stack_size, 10, 10))\n+\n+    layer = convolutional.MaxPooling2D(\n+        (2, 2),\n+        input_shape=input.shape[1:],\n+        dim_ordering='th')\n+    layer.input = K.variable(input)\n+    out_th = K.eval(layer.get_output(False))\n+\n+    input = np.transpose(input, (0, 2, 3, 1))\n+    layer = convolutional.MaxPooling2D(\n+        (2, 2),\n+        input_shape=input.shape[1:],\n+        dim_ordering='tf')\n+    layer.input = K.variable(input)\n+    out_tf = K.eval(layer.get_output(False))\n+\n+    assert_allclose(out_tf, np.transpose(out_th, (0, 2, 3, 1)), atol=1e-05)\n+\n+\n def test_averagepooling_2d():\n     nb_samples = 9\n     stack_size = 7\n\n@@ -88,7 +88,7 @@ def test_Convolution1D():\n \n def test_Convolution2D():\n     for border_mode in ['same', 'valid']:\n-        for nb_row, nb_col in [(3, 3), (4, 4)]:\n+        for nb_row, nb_col in [(3, 3), (4, 4), (3, 4)]:\n             for subsample in [(1, 1), (2, 2), (3, 3)]:\n                 if (subsample[0] > nb_row or subsample[1] > nb_col) and border_mode == 'same':\n                     continue\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#20728c95fad32072470645c3c34c2044cdc1557b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 945 | Contributors (this commit): 6 | Commits (past 90d): 35 | Contributors (cumulative): 6 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,5 +1,6 @@\n import tensorflow as tf\n import numpy as np\n+import os\n from .common import _FLOATX, _EPSILON\n \n # INTERNAL UTILS\n@@ -10,7 +11,11 @@ _SESSION = None\n def _get_session():\n     global _SESSION\n     if _SESSION is None:\n+        if not os.environ.get('OMP_NUM_THREADS'):\n             _SESSION = tf.Session('')\n+        else:\n+            nb_thread = int(os.environ.get('OMP_NUM_THREADS'))\n+            _SESSION = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=nb_thread))\n     return _SESSION\n \n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3925eabaaf2522aa285f8395f6e84ceb5ddb7c3e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 78 | Lines Deleted: 2 | Files Changed: 3 | Hunks: 4 | Methods Changed: 6 | Complexity Δ (Sum/Max): 8/4 | Churn Δ: 80 | Churn Cumulative: 1638 | Contributors (this commit): 14 | Commits (past 90d): 49 | Contributors (cumulative): 20 | DMM Complexity: 1.0\n\nDIFF:\n@@ -505,7 +505,8 @@ def switch(condition, then_expression, else_expression):\n def relu(x, alpha=0., max_value=None):\n     '''ReLU.\n \n-    # Arguments\n+    Parameters\n+    ----------\n         alpha: slope of negative section.\n         max_value: saturation threshold.\n     '''\n@@ -514,7 +515,9 @@ def relu(x, alpha=0., max_value=None):\n     if max_value is not None:\n         x = tf.clip_by_value(x, tf.cast(0., dtype=_FLOATX),\n                              tf.cast(max_value, dtype=_FLOATX))\n-    x -= tf.constant(alpha, dtype=_FLOATX) * negative_part\n+    if isinstance(alpha, (tuple, list, np.ndarray)) or np.isscalar(alpha):\n+        alpha = tf.constant(alpha, dtype=_FLOATX)\n+    x -= alpha * negative_part\n     return x\n \n \n\n@@ -222,3 +222,58 @@ class ThresholdedReLU(MaskedLayer):\n                   \"theta\": self.theta}\n         base_config = super(ThresholdedReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n+\n+\n+class SReLU(MaskedLayer):\n+    '''SReLU\n+\n+    # Input shape\n+        Arbitrary. Use the keyword argument `input_shape`\n+        (tuple of integers, does not include the samples axis)\n+        when using this layer as the first layer in a model.\n+\n+    # Output shape\n+        Same shape as the input.\n+\n+    # Arguments\n+        t_left_init: initialization function for the left part intercept\n+        a_left_init: initialization function for the left part slope\n+        t_right_init: initialization function for the right part intercept\n+        a_right_init: initialization function for the right part slope\n+\n+    # References\n+        [Deep Learning with S-shaped Rectified Linear Activation Units](http://arxiv.org/abs/1512.07030)\n+    '''\n+    def __init__(self, t_left_init='zero', a_left_init='glorot_uniform',\n+                 t_right_init='glorot_uniform', a_right_init='one', **kwargs):\n+        self.t_left_init = t_left_init\n+        self.a_left_init = a_left_init\n+        self.t_right_init = t_right_init\n+        self.a_right_init = a_right_init\n+        super(SReLU, self).__init__(**kwargs)\n+\n+    def build(self):\n+        params_shape = self.input_shape[1:]\n+        self.t_left = initializations.get(self.t_left_init)(params_shape)\n+        self.a_left = initializations.get(self.a_left_init)(params_shape)\n+        self.t_right = initializations.get(self.t_right_init)(params_shape)\n+        self.a_right = initializations.get(self.a_right_init)(params_shape)\n+        # ensure the the right part is always to the right of the left\n+        self.t_right_actual = self.t_left + abs(self.t_right)\n+        self.trainable_weights = [self.t_left, self.a_left, self.t_right, self.a_right]\n+\n+    def get_output(self, train=False):\n+        X = self.get_input(train)\n+        Y_left_and_center = self.t_left + K.relu(X - self.t_left, self.a_left, self.t_right_actual - self.t_left)\n+        Y_right = K.relu(X - self.t_right_actual) * self.a_right\n+        return Y_left_and_center + Y_right\n+\n+    def get_config(self):\n+        return {\n+            \"name\": self.__class__.__name__,\n+            \"input_shape\": self.input_shape,\n+            \"t_left_init\": self.t_left_init,\n+            \"a_left_init\": self.a_left_init,\n+            \"t_right_init\": self.t_right_init,\n+            \"a_right_init\": self.a_right_init\n+        }\n\n@@ -159,5 +159,23 @@ def test_thresholded_relu():\n         assert config['theta'] == theta\n \n \n+def test_srelu():\n+    from keras.layers.advanced_activations import SReLU\n+    np.random.seed(1337)\n+    inp = np.array([-2, -1., -0.5, 0., 0.5, 1., 2.])\n+    out = np.array([-1.5, -1., -0.5, 0., 0.5, 1., 3.])\n+    input_size = len(inp)\n+    for train in [True, False]:\n+        layer = SReLU(input_shape=inp.flatten().shape)\n+        ones_proto = np.ones(input_size)\n+        layer.set_weights([ones_proto * -1., ones_proto * 0.5, ones_proto * 2., ones_proto * 2.])\n+\n+        layer.input = K.variable(inp)\n+        outp = K.eval(layer.get_output(train))\n+        assert_allclose(out, outp)\n+\n+        layer.get_config()\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#61800be9a034b10bb35715adb314225d7b40b77c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 34 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 7/7 | Churn Δ: 39 | Churn Cumulative: 103 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: 0.7391304347826086\n\nDIFF:\n@@ -3,14 +3,37 @@ from __future__ import print_function\n \n import tarfile\n import os\n-from six.moves.urllib.request import FancyURLopener\n+import sys\n+from six.moves.urllib.request import urlopen, build_opener, install_opener\n+from six.moves.urllib.error import URLError, HTTPError\n \n from ..utils.generic_utils import Progbar\n \n \n-class ParanoidURLopener(FancyURLopener):\n-    def http_error_default(self, url, fp, errcode, errmsg, headers):\n-        raise Exception('URL fetch failure on {}: {} -- {}'.format(url, errcode, errmsg))\n+# Under Python 2, 'urlretrieve' relies on FancyURLopener from legacy\n+# urllib module, known to have issues with proxy management\n+if sys.version_info[0] == 2:\n+    def urlretrieve(url, filename, reporthook=None, data=None):\n+        def chunk_read(response, chunk_size=8192, reporthook=None):\n+            total_size = response.info().get('Content-Length').strip()\n+            total_size = int(total_size)\n+            bytes_so_far = 0\n+            count = 0\n+            while 1:\n+                chunk = response.read(chunk_size)\n+                if not chunk:\n+                    break\n+                count += 1\n+                if reporthook:\n+                    reporthook(count, chunk_size, total_size)\n+                yield chunk\n+\n+        response = urlopen(url, data)\n+        with open(filename, 'wb') as fd:\n+            for chunk in chunk_read(response, reporthook=reporthook):\n+                fd.write(chunk)\n+else:\n+    from six.moves.urllib.request import urlretrieve\n \n \n def get_file(fname, origin, untar=False):\n@@ -39,7 +62,13 @@ def get_file(fname, origin, untar=False):\n             else:\n                 progbar.update(count*block_size)\n \n-        ParanoidURLopener().retrieve(origin, fpath, dl_progress)\n+        error_msg = 'URL fetch failure on {}: {} -- {}'\n+        try:\n+            urlretrieve(origin, fpath, dl_progress)\n+        except URLError as e:\n+            raise Exception(error_msg.format(url, e.errno, e.reason))\n+        except HTTPError as e:\n+            raise Exception(error_msg.format(url, e.code, e.msg))\n         progbar = None\n \n     if untar:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b78ade7e36a9ae002b8c50c0262a6dfdad6c4075", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 5/5 | Churn Δ: 3 | Churn Cumulative: 7644 | Contributors (this commit): 40 | Commits (past 90d): 73 | Contributors (cumulative): 40 | DMM Complexity: None\n\nDIFF:\n@@ -357,11 +357,12 @@ class Merge(Layer):\n     '''Merge the output of a list of layers or containers into a single tensor.\n \n     # Arguments\n-        mode: one of {sum, mul, concat, ave, dot}.\n+        mode: one of {sum, mul, concat, ave, join, cos, dot}.\n             sum: sum the outputs (shapes must match)\n             mul: multiply the outputs element-wise (shapes must match)\n             concat: concatenate the outputs along the axis specified by `concat_axis`\n             ave: average the outputs (shapes must match)\n+            join: places the outputs in an OrderedDict (inputs must be named)\n         concat_axis: axis to use in `concat` mode.\n         dot_axes: axis or axes to use in `dot` mode\n             (see [the Numpy documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.tensordot.html) for more details).\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c23579e059c9cd88a956b7eac9a69f7d7e276fc8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 4290 | Contributors (this commit): 36 | Commits (past 90d): 33 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -845,7 +845,7 @@ class Sequential(Model, containers.Sequential):\n         '''Load all layer weights from a HDF5 save file.\n         '''\n         import h5py\n-        f = h5py.File(filepath)\n+        f = h5py.File(filepath,mode=\"r\")\n         for k in range(f.attrs['nb_layers']):\n             # This method does not make use of Sequential.set_weights()\n             # for backwards compatibility.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#44e0a7bbf9316c39afd5b49e09b668ef2dbb706e", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 37 | Lines Deleted: 33 | Files Changed: 3 | Hunks: 15 | Methods Changed: 7 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 70 | Churn Cumulative: 1708 | Contributors (this commit): 14 | Commits (past 90d): 50 | Contributors (cumulative): 20 | DMM Complexity: 0.0\n\nDIFF:\n@@ -91,10 +91,13 @@ def transpose(x):\n \n \n def gather(reference, indices):\n-    '''reference: a tensor.\n+    '''\n+    # Arguments\n+        reference: a tensor.\n         indices: an int tensor of indices.\n \n-    Return: a tensor of same type as reference.\n+    # Returns\n+        a tensor of same type as `reference`.\n     '''\n     return tf.gather(reference, indices)\n \n@@ -247,7 +250,8 @@ def reshape(x, shape):\n def permute_dimensions(x, pattern):\n     '''Transpose dimensions.\n \n-    pattern should be a tuple or list of\n+    # Arguments\n+        pattern: should be a tuple or list of\n             dimension indices, e.g. [0, 2, 1].\n     '''\n     return tf.transpose(x, perm=pattern)\n@@ -398,8 +402,7 @@ def rnn(step_function, inputs, initial_states,\n         go_backwards=False, mask=None):\n     '''Iterates over the time dimension of a tensor.\n \n-    Parameters\n-    ----------\n+    # Arguments\n         inputs: tensor of temporal data of shape (samples, time, ...)\n             (at least 3D).\n         step_function:\n@@ -420,8 +423,7 @@ def rnn(step_function, inputs, initial_states,\n         mask: binary tensor with shape (samples, time, 1),\n             with a zero for every element that is masked.\n \n-    Returns\n-    -------\n+    # Returns\n         A tuple (last_output, outputs, new_states).\n             last_output: the latest output of the rnn, of shape (samples, ...)\n             outputs: tensor with shape (samples, time, ...) where each\n@@ -493,7 +495,12 @@ def rnn(step_function, inputs, initial_states,\n \n \n def switch(condition, then_expression, else_expression):\n-    '''condition: scalar tensor.\n+    '''Switch between two operations depending on a scalar value.\n+\n+    # Arguments\n+        condition: scalar tensor.\n+        then_expression: TensorFlow operation.\n+        else_expression: TensorFlow operation.\n     '''\n     return tf.python.control_flow_ops.cond(condition,\n                                            lambda: then_expression,\n@@ -505,8 +512,7 @@ def switch(condition, then_expression, else_expression):\n def relu(x, alpha=0., max_value=None):\n     '''ReLU.\n \n-    Parameters\n-    ----------\n+    # Arguments\n         alpha: slope of negative section.\n         max_value: saturation threshold.\n     '''\n\n@@ -29,8 +29,8 @@ class LeakyReLU(MaskedLayer):\n         return K.relu(X, alpha=self.alpha)\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"alpha\": self.alpha}\n+        config = {'name': self.__class__.__name__,\n+                  'alpha': self.alpha}\n         base_config = super(LeakyReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -73,8 +73,8 @@ class PReLU(MaskedLayer):\n         return pos + neg\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"init\": self.init.__name__}\n+        config = {'name': self.__class__.__name__,\n+                  'init': self.init.__name__}\n         base_config = super(PReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -106,8 +106,8 @@ class ELU(MaskedLayer):\n         return pos + self.alpha * (K.exp(neg) - 1.)\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"alpha\": self.alpha}\n+        config = {'name': self.__class__.__name__,\n+                  'alpha': self.alpha}\n         base_config = super(ELU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -153,9 +153,9 @@ class ParametricSoftplus(MaskedLayer):\n         return K.softplus(self.betas * X) * self.alphas\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"alpha_init\": self.alpha_init,\n-                  \"beta_init\": self.beta_init}\n+        config = {'name': self.__class__.__name__,\n+                  'alpha_init': self.alpha_init,\n+                  'beta_init': self.beta_init}\n         base_config = super(ParametricSoftplus, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -186,8 +186,8 @@ class ThresholdedLinear(MaskedLayer):\n         return K.switch(K.abs(X) < self.theta, 0, X)\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"theta\": self.theta}\n+        config = {'name': self.__class__.__name__,\n+                  'theta': self.theta}\n         base_config = super(ThresholdedLinear, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -218,8 +218,8 @@ class ThresholdedReLU(MaskedLayer):\n         return K.switch(X > self.theta, X, 0)\n \n     def get_config(self):\n-        config = {\"name\": self.__class__.__name__,\n-                  \"theta\": self.theta}\n+        config = {'name': self.__class__.__name__,\n+                  'theta': self.theta}\n         base_config = super(ThresholdedReLU, self).get_config()\n         return dict(list(base_config.items()) + list(config.items()))\n \n@@ -269,11 +269,9 @@ class SReLU(MaskedLayer):\n         return Y_left_and_center + Y_right\n \n     def get_config(self):\n-        return {\n-            \"name\": self.__class__.__name__,\n-            \"input_shape\": self.input_shape,\n-            \"t_left_init\": self.t_left_init,\n-            \"a_left_init\": self.a_left_init,\n-            \"t_right_init\": self.t_right_init,\n-            \"a_right_init\": self.a_right_init\n-        }\n+        return {'name': self.__class__.__name__,\n+                'input_shape': self.input_shape,\n+                't_left_init': self.t_left_init,\n+                'a_left_init': self.a_left_init,\n+                't_right_init': self.t_right_init,\n+                'a_right_init': self.a_right_init}\n\n@@ -168,8 +168,8 @@ def test_srelu():\n     for train in [True, False]:\n         layer = SReLU(input_shape=inp.flatten().shape)\n         ones_proto = np.ones(input_size)\n-        layer.set_weights([ones_proto * -1., ones_proto * 0.5, ones_proto * 2., ones_proto * 2.])\n-\n+        layer.set_weights([ones_proto * -1., ones_proto * 0.5,\n+                           ones_proto * 2., ones_proto * 2.])\n         layer.input = K.variable(inp)\n         outp = K.eval(layer.get_output(train))\n         assert_allclose(out, outp)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5b23dd8a2fcfdaf8e2860933a2b49e8b4a723a90", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4294 | Contributors (this commit): 36 | Commits (past 90d): 34 | Contributors (cumulative): 36 | DMM Complexity: None\n\nDIFF:\n@@ -845,7 +845,7 @@ class Sequential(Model, containers.Sequential):\n         '''Load all layer weights from a HDF5 save file.\n         '''\n         import h5py\n-        f = h5py.File(filepath,mode=\"r\")\n+        f = h5py.File(filepath, mode='r')\n         for k in range(f.attrs['nb_layers']):\n             # This method does not make use of Sequential.set_weights()\n             # for backwards compatibility.\n@@ -1327,7 +1327,7 @@ class Graph(Model, containers.Graph):\n         '''Load weights from a HDF5 file.\n         '''\n         import h5py\n-        f = h5py.File(filepath)\n+        f = h5py.File(filepath, mode='r')\n         g = f['graph']\n         weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n         self.set_weights(weights)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#46a5b3cb365d8cd1e92ea934778e08cdba0df852", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 48 | Lines Deleted: 1 | Files Changed: 2 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 4/3 | Churn Δ: 49 | Churn Cumulative: 306 | Contributors (this commit): 9 | Commits (past 90d): 7 | Contributors (cumulative): 12 | DMM Complexity: 0.7272727272727273\n\nDIFF:\n@@ -35,7 +35,15 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n     if maxlen is None:\n         maxlen = np.max(lengths)\n \n-    x = (np.ones((nb_samples, maxlen)) * value).astype(dtype)\n+    # take the sample shape from the first non empty sequence\n+    # checking for consistency in the main loop below.\n+    sample_shape = tuple()\n+    for s in sequences:\n+        if len(s) > 0:\n+            sample_shape = np.asarray(s).shape[1:]\n+            break\n+\n+    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n     for idx, s in enumerate(sequences):\n         if len(s) == 0:\n             continue # empty list was found\n@@ -46,6 +54,12 @@ def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncati\n         else:\n             raise ValueError(\"Truncating type '%s' not understood\" % padding)\n \n+        # check `trunc` has expected shape\n+        trunc = np.asarray(trunc, dtype=dtype)\n+        if trunc.shape[1:] != sample_shape:\n+            raise ValueError(\"Shape of sample %s of sequence at position %s is different from expected shape %s\"\n+                             % (trunc.shape[1:], idx, sample_shape))\n+\n         if padding == 'post':\n             x[idx, :len(trunc)] = trunc\n         elif padding == 'pre':\n\n@@ -28,6 +28,39 @@ def test_pad_sequences():\n     assert_allclose(b, [[1, 1, 1], [1, 1, 2], [1, 2, 3]])\n \n \n+def test_pad_sequences_vector():\n+    a = [[[1, 1]],\n+         [[2, 1], [2, 2]],\n+         [[3, 1], [3, 2], [3, 3]]]\n+\n+    # test padding\n+    b = pad_sequences(a, maxlen=3, padding='pre')\n+    assert_allclose(b, [[[0, 0], [0, 0], [1, 1]],\n+                        [[0, 0], [2, 1], [2, 2]],\n+                        [[3, 1], [3, 2], [3, 3]]])\n+    b = pad_sequences(a, maxlen=3, padding='post')\n+    assert_allclose(b, [[[1, 1], [0, 0], [0, 0]],\n+                        [[2, 1], [2, 2], [0, 0]],\n+                        [[3, 1], [3, 2], [3, 3]]])\n+\n+    # test truncating\n+    b = pad_sequences(a, maxlen=2, truncating='pre')\n+    assert_allclose(b, [[[0, 0], [1, 1]],\n+                        [[2, 1], [2, 2]],\n+                        [[3, 2], [3, 3]]])\n+\n+    b = pad_sequences(a, maxlen=2, truncating='post')\n+    assert_allclose(b, [[[0, 0], [1, 1]],\n+                        [[2, 1], [2, 2]],\n+                        [[3, 1], [3, 2]]])\n+\n+    # test value\n+    b = pad_sequences(a, maxlen=3, value=1)\n+    assert_allclose(b, [[[1, 1], [1, 1], [1, 1]],\n+                        [[1, 1], [2, 1], [2, 2]],\n+                        [[3, 1], [3, 2], [3, 3]]])\n+\n+\n def test_make_sampling_table():\n     a = make_sampling_table(3)\n     assert_allclose(a, np.asarray([0.00315225,  0.00315225,  0.00547597]),\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c9642571c23004a10e8bca1a5b1446af399f80db", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 32 | Lines Deleted: 66 | Files Changed: 2 | Hunks: 14 | Methods Changed: 4 | Complexity Δ (Sum/Max): -11/0 | Churn Δ: 98 | Churn Cumulative: 5632 | Contributors (this commit): 42 | Commits (past 90d): 46 | Contributors (cumulative): 49 | DMM Complexity: 0.45714285714285713\n\nDIFF:\n@@ -92,7 +92,8 @@ class Callback(object):\n     will include the following quantities in the `logs` that\n     it passes to its callbacks:\n \n-        on_epoch_end: logs optionally include `val_loss`\n+        on_epoch_end: logs include `acc` and `loss`, and\n+            optionally include `val_loss`\n             (if validation is enabled in `fit`), and `val_acc`\n             (if validation and accuracy monitoring are enabled).\n         on_batch_begin: logs include `size`,\n@@ -129,11 +130,35 @@ class Callback(object):\n \n \n class BaseLogger(Callback):\n-    '''Callback that prints events to the standard output.\n+    '''Callback that accumulates epoch averages of\n+    the metrics being monitored.\n \n     This callback is automatically applied to\n-    every Keras model (it is the basis of the verbosity modes\n-    in models).\n+    every Keras model.\n+    '''\n+    def on_epoch_begin(self, epoch, logs={}):\n+        self.seen = 0\n+        self.totals = {}\n+\n+    def on_batch_end(self, batch, logs={}):\n+        batch_size = logs.get('size', 0)\n+        self.seen += batch_size\n+\n+        for k, v in logs.items():\n+            if k in self.totals:\n+                self.totals[k] += v * batch_size\n+            else:\n+                self.totals[k] = v * batch_size\n+\n+    def on_epoch_end(self, epoch, logs={}):\n+        for k in self.params['metrics']:\n+            if k in self.totals:\n+                # make value available to next callbacks\n+                logs[k] = self.totals[k] / self.seen\n+\n+\n+class ProgbarLogger(Callback):\n+    '''Callback that prints metrics to stdout.\n     '''\n     def on_train_begin(self, logs={}):\n         self.verbose = self.params['verbose']\n@@ -145,7 +170,6 @@ class BaseLogger(Callback):\n             self.progbar = Progbar(target=self.params['nb_sample'],\n                                    verbose=self.verbose)\n         self.seen = 0\n-        self.totals = {}\n \n     def on_batch_begin(self, batch, logs={}):\n         if self.seen < self.params['nb_sample']:\n@@ -155,11 +179,6 @@ class BaseLogger(Callback):\n         batch_size = logs.get('size', 0)\n         self.seen += batch_size\n \n-        for k, v in logs.items():\n-            if k in self.totals:\n-                self.totals[k] += v * batch_size\n-            else:\n-                self.totals[k] = v * batch_size\n         for k in self.params['metrics']:\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n@@ -171,8 +190,6 @@ class BaseLogger(Callback):\n \n     def on_epoch_end(self, epoch, logs={}):\n         for k in self.params['metrics']:\n-            if k in self.totals:\n-                self.log_values.append((k, self.totals[k] / self.seen))\n             if k in logs:\n                 self.log_values.append((k, logs[k]))\n         if self.verbose:\n@@ -191,26 +208,8 @@ class History(Callback):\n         self.epoch = []\n         self.history = {}\n \n-    def on_epoch_begin(self, epoch, logs={}):\n-        self.seen = 0\n-        self.totals = {}\n-\n-    def on_batch_end(self, batch, logs={}):\n-        batch_size = logs.get('size', 0)\n-        self.seen += batch_size\n-        for k, v in logs.items():\n-            if k in self.totals:\n-                self.totals[k] += v * batch_size\n-            else:\n-                self.totals[k] = v * batch_size\n-\n     def on_epoch_end(self, epoch, logs={}):\n         self.epoch.append(epoch)\n-        for k, v in self.totals.items():\n-            if k not in self.history:\n-                self.history[k] = []\n-            self.history[k].append(v / self.seen)\n-\n         for k, v in logs.items():\n             if k not in self.history:\n                 self.history[k] = []\n@@ -373,26 +372,10 @@ class RemoteMonitor(Callback):\n     def __init__(self, root='http://localhost:9000'):\n         self.root = root\n \n-    def on_epoch_begin(self, epoch, logs={}):\n-        self.seen = 0\n-        self.totals = {}\n-\n-    def on_batch_end(self, batch, logs={}):\n-        batch_size = logs.get('size', 0)\n-        self.seen += batch_size\n-        for k, v in logs.items():\n-            if k in self.totals:\n-                self.totals[k] += v * batch_size\n-            else:\n-                self.totals[k] = v * batch_size\n-\n     def on_epoch_end(self, epoch, logs={}):\n         import requests\n         send = {}\n         send['epoch'] = epoch\n-\n-        for k, v in self.totals.items():\n-            send[k] = v / self.seen\n         for k, v in logs.items():\n             send[k] = v\n \n@@ -486,19 +469,6 @@ class TensorBoard(Callback):\n         self.writer = tf.train.SummaryWriter(self.log_dir,\n                                              self.sess.graph_def)\n \n-    def on_epoch_begin(self, epoch, logs={}):\n-        self.seen = 0\n-        self.totals = {}\n-\n-    def on_batch_end(self, batch, logs={}):\n-        batch_size = logs.get('size', 0)\n-        self.seen += batch_size\n-        for k, v in logs.items():\n-            if k in self.totals:\n-                self.totals[k] += v * batch_size\n-            else:\n-                self.totals[k] = v * batch_size\n-\n     def on_epoch_end(self, epoch, logs={}):\n         import tensorflow as tf\n \n@@ -514,10 +484,7 @@ class TensorBoard(Callback):\n                 summary_str = result[0]\n                 self.writer.add_summary(summary_str, epoch)\n \n-        all_values = self.totals.copy()\n-        all_values.update(logs)\n-\n-        for name, value in all_values.items():\n+        for name, value in logs.items():\n             if name in ['batch', 'size']:\n                 continue\n             summary = tf.Summary()\n\n@@ -239,10 +239,9 @@ class Model(object):\n         index_array = np.arange(nb_train_sample)\n \n         history = cbks.History()\n+        callbacks = [cbks.BaseLogger()] + callbacks + [history]\n         if verbose:\n-            callbacks = [history, cbks.BaseLogger()] + callbacks\n-        else:\n-            callbacks = [history] + callbacks\n+            callbacks += [cbks.ProgbarLogger()]\n         callbacks = cbks.CallbackList(callbacks)\n \n         callbacks._set_model(self)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
