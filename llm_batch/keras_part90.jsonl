{"custom_id": "keras#c1c2b330a104ceb7d641613a70cc3f2d70e547f7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 45 | Lines Deleted: 6 | Files Changed: 2 | Hunks: 6 | Methods Changed: 3 | Complexity Δ (Sum/Max): 6/5 | Churn Δ: 51 | Churn Cumulative: 2002 | Contributors (this commit): 2 | Commits (past 90d): 23 | Contributors (cumulative): 3 | DMM Complexity: 0.5172413793103449\n\nDIFF:\n@@ -224,6 +224,22 @@ def collect_metrics(metrics, output_names):\n                         str(metrics))\n \n \n+def collect_trainable_weights(layer):\n+    trainable = getattr(layer, 'trainable', True)\n+    if not trainable:\n+        return []\n+    weights = []\n+    if layer.__class__.__name__ in ['Sequential', 'Model']:\n+        for sublayer in layer.layers:\n+            weights += collect_trainable_weights(sublayer)\n+    elif layer.__class__.__name__ == 'Graph':\n+        for sublayer in layer._graph_nodes.values():\n+            weights += collect_trainable_weights(sublayer)\n+    else:\n+        weights += layer.trainable_weights\n+    return weights\n+\n+\n def batch_shuffle(index_array, batch_size):\n     '''This shuffles an array in a batch-wise fashion.\n     Useful for shuffling HDF5 arrays\n@@ -622,13 +638,10 @@ class Model(Container):\n             else:\n                 inputs = self.inputs + self.targets + self.sample_weights\n \n-            # dedupe trainable weights\n-            trainable_weights_set = set()\n+            # get trainable weights\n             trainable_weights = []\n-            for w in self.trainable_weights:\n-                if w not in trainable_weights_set:\n-                    trainable_weights_set.add(w)\n-                    trainable_weights.append(w)\n+            for layer in self.layers:\n+                trainable_weights += collect_trainable_weights(layer)\n \n             training_updates = self.optimizer.get_updates(trainable_weights, self.constraints, self.total_loss)\n             updates = self.updates + training_updates\n\n@@ -1,9 +1,11 @@\n import pytest\n import numpy as np\n+from numpy.testing import assert_allclose\n \n from keras.layers import Dense, Dropout\n from keras.engine.topology import merge, Input\n from keras.engine.training import Model\n+from keras.models import Sequential, Graph\n from keras import backend as K\n \n \n@@ -153,5 +155,29 @@ def test_model_methods():\n     out = model.predict([input_a_np, input_b_np], batch_size=4)\n \n \n+def test_trainable_argument():\n+    x = np.random.random((5, 3))\n+    y = np.random.random((5, 2))\n+\n+    model = Sequential()\n+    model.add(Dense(2, input_dim=3, trainable=False))\n+    model.compile('rmsprop', 'mse')\n+    out = model.predict(x)\n+    model.train_on_batch(x, y)\n+    out_2 = model.predict(x)\n+    assert_allclose(out, out_2)\n+\n+    # test with nesting\n+    input = Input(shape=(3,))\n+    output = model(input)\n+    model = Model(input, output)\n+    model.compile('rmsprop', 'mse')\n+    out = model.predict(x)\n+    model.train_on_batch(x, y)\n+    out_2 = model.predict(x)\n+    assert_allclose(out, out_2)\n+\n+\n+\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#4f5f88b9bab58e363b95ddc1931f2036d13d14e6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 27 | Lines Deleted: 18 | Files Changed: 3 | Hunks: 22 | Methods Changed: 15 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 45 | Churn Cumulative: 10167 | Contributors (this commit): 45 | Commits (past 90d): 70 | Contributors (cumulative): 51 | DMM Complexity: 0.6666666666666666\n\nDIFF:\n@@ -385,7 +385,7 @@ def standardize_weights(y, sample_weight=None, class_weight=None,\n def generator_queue(generator, max_q_size=10,\n                     wait_time=0.05, nb_worker=1):\n     '''Builds a threading queue out of a data generator.\n-    Used in `fit_generator`, `evaluate_generator`.\n+    Used in `fit_generator`, `evaluate_generator`, `predict_generator`.\n     '''\n     q = queue.Queue()\n     _stop = threading.Event()\n@@ -1203,7 +1203,7 @@ class Model(Container):\n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight={}):\n+                      class_weight={}, max_q_size=10):\n         '''Fits the model on data generated batch-by-batch by\n         a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n@@ -1233,6 +1233,7 @@ class Model(Container):\n                 at the end of every epoch.\n             class_weight: dictionary mapping class indices to a weight\n                 for the class.\n+            max_q_size: maximum size for the generator queue\n \n         # Returns\n             A `History` object.\n@@ -1311,7 +1312,7 @@ class Model(Container):\n             self.validation_data = None\n \n         # start generator thread storing batches into a queue\n-        data_gen_queue, _stop = generator_queue(generator)\n+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)\n \n         callback_model.stop_training = False\n         while epoch < nb_epoch:\n@@ -1384,7 +1385,8 @@ class Model(Container):\n                 if samples_seen >= samples_per_epoch and do_validation:\n                     if val_gen:\n                         val_outs = self.evaluate_generator(validation_data,\n-                                                           nb_val_samples)\n+                                                           nb_val_samples,\n+                                                           max_q_size=max_q_size)\n                     else:\n                         # no need for try/except because\n                         # data has already been validated\n@@ -1406,7 +1408,7 @@ class Model(Container):\n         callbacks.on_train_end()\n         return self.history\n \n-    def evaluate_generator(self, generator, val_samples):\n+    def evaluate_generator(self, generator, val_samples, max_q_size=10):\n         '''Evaluates the model on a data generator. The generator should\n         return the same kind of data as accepted by `test_on_batch`.\n \n@@ -1417,6 +1419,7 @@ class Model(Container):\n             val_samples:\n                 total number of samples to generate from `generator`\n                 before returning.\n+            max_q_size: maximum size for the generator queue\n \n         # Returns\n             Scalar test loss (if the model has a single output and no metrics)\n@@ -1430,7 +1433,7 @@ class Model(Container):\n         wait_time = 0.01\n         all_outs = []\n         weights = []\n-        data_gen_queue, _stop = generator_queue(generator)\n+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)\n \n         while processed_samples < val_samples:\n             generator_output = None\n@@ -1484,7 +1487,7 @@ class Model(Container):\n                                 weights=weights))\n             return averages\n \n-    def predict_generator(self, generator, val_samples):\n+    def predict_generator(self, generator, val_samples, max_q_size=10):\n         '''Generates predictions for the input samples from a data generator.\n         The generator should return the same kind of data as accepted by\n         `predict_on_batch`.\n@@ -1493,6 +1496,7 @@ class Model(Container):\n             generator: generator yielding batches of input samples.\n             val_samples: total number of samples to generate from `generator`\n                 before returning.\n+            max_q_size: maximum size for the generator queue\n \n         # Returns\n             Numpy array(s) of predictions.\n@@ -1502,7 +1506,7 @@ class Model(Container):\n         processed_samples = 0\n         wait_time = 0.01\n         all_outs = []\n-        data_gen_queue, _stop = generator_queue(generator)\n+        data_gen_queue, _stop = generator_queue(generator, max_q_size=max_q_size)\n \n         while processed_samples < val_samples:\n             generator_output = None\n\n@@ -565,8 +565,7 @@ class Sequential(Model):\n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight=None,\n-                      **kwargs):\n+                      class_weight=None, max_q_size=10, **kwargs):\n         '''Fits the model on data generated batch-by-batch by\n         a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n@@ -596,6 +595,7 @@ class Sequential(Model):\n                 at the end of every epoch.\n             class_weight: dictionary mapping class indices to a weight\n                 for the class.\n+            max_q_size: maximum size for the generator queue\n \n         # Returns\n             A `History` object.\n@@ -644,10 +644,10 @@ class Sequential(Model):\n                                         callbacks=callbacks,\n                                         validation_data=validation_data,\n                                         nb_val_samples=nb_val_samples,\n-                                        class_weight=class_weight)\n+                                        class_weight=class_weight,\n+                                        max_q_size=max_q_size)\n \n-    def evaluate_generator(self, generator, val_samples,\n-                           **kwargs):\n+    def evaluate_generator(self, generator, val_samples, max_q_size=10, **kwargs):\n         '''Evaluates the model on a data generator. The generator should\n         return the same kind of data as accepted by `test_on_batch`.\n \n@@ -658,6 +658,7 @@ class Sequential(Model):\n             val_samples:\n                 total number of samples to generate from `generator`\n                 before returning.\n+            max_q_size: maximum size for the generator queue\n         '''\n         if self.model is None:\n             raise Exception('The model needs to be compiled before being used.')\n@@ -675,9 +676,10 @@ class Sequential(Model):\n             raise Exception('Received unknown keyword arguments: ' +\n                             str(kwargs))\n         return self.model.evaluate_generator(generator,\n-                                             val_samples)\n+                                             val_samples,\n+                                             max_q_size=max_q_size)\n \n-    def predict_generator(self, generator, val_samples):\n+    def predict_generator(self, generator, val_samples, max_q_size=10):\n         '''Generates predictions for the input samples from a data generator.\n         The generator should return the same kind of data as accepted by\n         `predict_on_batch`.\n@@ -686,13 +688,15 @@ class Sequential(Model):\n             generator: generator yielding batches of input samples.\n             val_samples: total number of samples to generate from `generator`\n                 before returning.\n+            max_q_size: maximum size for the generator queue\n \n         # Returns\n             A Numpy array of predictions.\n         '''\n         if self.model is None:\n             raise Exception('The model needs to be compiled before being used.')\n-        return self.model.predict_generator(generator, val_samples)\n+        return self.model.predict_generator(generator, val_samples,\n+                                            max_q_size=max_q_size)\n \n     def get_config(self):\n         '''Returns the model configuration\n\n@@ -66,6 +66,7 @@ def test_sequential_fit_generator():\n     model.fit_generator(data_generator(True), len(X_train), nb_epoch, validation_data=(X_test, y_test))\n     model.fit_generator(data_generator(True), len(X_train), nb_epoch,\n                         validation_data=data_generator(False), nb_val_samples=batch_size * 3)\n+    model.fit_generator(data_generator(True), len(X_train), nb_epoch, max_q_size=2)\n \n     loss = model.evaluate(X_train, y_train)\n \n@@ -100,8 +101,8 @@ def test_sequential():\n \n     loss = model.evaluate(X_test, y_test)\n \n-    prediction = model.predict_generator(data_generator(X_test, y_test), X_test.shape[0])\n-    gen_loss = model.evaluate_generator(data_generator(X_test, y_test, 50), X_test.shape[0])\n+    prediction = model.predict_generator(data_generator(X_test, y_test), X_test.shape[0], max_q_size=2)\n+    gen_loss = model.evaluate_generator(data_generator(X_test, y_test, 50), X_test.shape[0], max_q_size=2)\n     pred_loss = K.eval(K.mean(objectives.get(model.loss)(K.variable(y_test), K.variable(prediction))))\n \n     assert(np.isclose(pred_loss, loss))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57ea065db795d8451ad5fbdf84e8b262276d8690", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 10 | Lines Deleted: 8 | Files Changed: 2 | Hunks: 3 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 18 | Churn Cumulative: 1923 | Contributors (this commit): 14 | Commits (past 90d): 15 | Contributors (cumulative): 16 | DMM Complexity: 0.0\n\nDIFF:\n@@ -467,8 +467,14 @@ class TensorBoard(Callback):\n             if epoch % self.histogram_freq == 0:\n                 # TODO: implement batched calls to sess.run\n                 # (current call will likely go OOM on GPU)\n-                feed_dict = dict(zip(self.model.inputs,\n-                                     self.model.validation_data))\n+                if self.model.uses_learning_phase:\n+                    cut_v_data = len(self.model.inputs)\n+                    val_data = self.model.validation_data[:cut_v_data] + [0]\n+                    tensors = self.model.inputs + [K.learning_phase()]\n+                else:\n+                    val_data = self.model.validation_data\n+                    tensors = self.model.inputs\n+                feed_dict = dict(zip(tensors, val_data))\n                 result = self.sess.run([self.merged], feed_dict=feed_dict)\n                 summary_str = result[0]\n                 self.writer.add_summary(summary_str, epoch)\n\n@@ -126,7 +126,7 @@ def test_LearningRateScheduler():\n     assert (float(K.get_value(model.optimizer.lr)) - 0.2) < K.epsilon()\n \n \n-@pytest.mark.skipif((K._BACKEND != 'tensorflow') or (sys.version_info[0] == 3),\n+@pytest.mark.skipif((K._BACKEND != 'tensorflow'),\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard():\n     import shutil\n@@ -252,8 +252,4 @@ def test_TensorBoard():\n     KTF.set_session(old_session)\n \n if __name__ == '__main__':\n-    # pytest.main([__file__])\n-    # test_ModelCheckpoint()\n-    # test_EarlyStopping()\n-    # test_LearningRateScheduler()\n-    test_TensorBoard()\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cba3ea9d9069458c40a1cb588d3cd361ad702c12", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 0 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 240 | Contributors (this commit): 1 | Commits (past 90d): 4 | Contributors (cumulative): 1 | DMM Complexity: None\n\nDIFF:\n@@ -178,6 +178,5 @@ def test_trainable_argument():\n     assert_allclose(out, out_2)\n \n \n-\n if __name__ == '__main__':\n     pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3b961a6b7bb1422197f2204170f03848f2e93865", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 4 | Files Changed: 1 | Hunks: 4 | Methods Changed: 4 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 11 | Churn Cumulative: 805 | Contributors (this commit): 1 | Commits (past 90d): 5 | Contributors (cumulative): 1 | DMM Complexity: 0.3333333333333333\n\nDIFF:\n@@ -533,7 +533,8 @@ class Graph(Model):\n     def fit_generator(self, generator, samples_per_epoch, nb_epoch,\n                       verbose=1, callbacks=[],\n                       validation_data=None, nb_val_samples=None,\n-                      class_weight={}, **kwargs):\n+                      class_weight={},\n+                      max_q_size=10, **kwargs):\n         '''Fits a model on data generated batch-by-batch by a Python generator.\n         The generator is run in parallel to the model, for efficiency.\n         For instance, this allows you to do real-time data augmentation\n@@ -641,13 +642,14 @@ class Graph(Model):\n                                                    callbacks=callbacks,\n                                                    validation_data=validation_data,\n                                                    nb_val_samples=nb_val_samples,\n-                                                   class_weight=class_weight)\n+                                                   class_weight=class_weight,\n+                                                   max_q_size=max_q_size)\n         self.train_on_batch = self._train_on_batch\n         self.evaluate = self._evaluate\n         return history\n \n     def evaluate_generator(self, generator, val_samples,\n-                           verbose=1, **kwargs):\n+                           verbose=1, max_q_size=10, **kwargs):\n         '''Evaluates the model on a generator. The generator should\n         return the same kind of data with every yield as accepted\n         by `evaluate`.\n@@ -700,7 +702,8 @@ class Graph(Model):\n \n         generator = fixed_generator()\n         history = super(Graph, self).evaluate_generator(generator,\n-                                                        val_samples)\n+                                                        val_samples,\n+                                                        max_q_size=max_q_size)\n         self.test_on_batch = self._test_on_batch\n         return history\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#cb5d69c76954544abe094f565272839aea7fdbca", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 2 | Churn Cumulative: 2612 | Contributors (this commit): 5 | Commits (past 90d): 23 | Contributors (cumulative): 5 | DMM Complexity: 0.0\n\nDIFF:\n@@ -1259,6 +1259,8 @@ class Merge(Layer):\n             if hasattr(self._output_shape, '__call__'):\n                 output_shape = self._output_shape(input_shape)\n                 return output_shape\n+            elif self._output_shape is not None:\n+                return self._output_shape\n             else:\n                 # TODO: consider shape auto-inference with TF\n                 raise Exception('The Merge layer ' + self.name +\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2cc9ebf28bef640043fc9abc2c61a421ffded792", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 5 | Churn Cumulative: 1537 | Contributors (this commit): 15 | Commits (past 90d): 43 | Contributors (cumulative): 15 | DMM Complexity: 1.0\n\nDIFF:\n@@ -21,6 +21,11 @@ def learning_phase():\n     return _LEARNING_PHASE\n \n \n+def set_learning_phase(value):\n+    global _LEARNING_PHASE\n+    _LEARNING_PHASE = tf.constant(value, name='keras_learning_phase')\n+\n+\n def get_session():\n     '''Returns the TF session in use by the backend.\n     '''\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#85f80714c29d6bd8c8cde9138f0369f5df1b9a33", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 21 | Lines Deleted: 14 | Files Changed: 1 | Hunks: 11 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 35 | Churn Cumulative: 114 | Contributors (this commit): 3 | Commits (past 90d): 3 | Contributors (cumulative): 3 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,9 @@\n '''This example demonstrates the use of Convolution1D for text classification.\n \n-Gets to 0.835 test accuracy after 2 epochs. 100s/epoch on K520 GPU.\n+Gets to 0.88 test accuracy after 2 epochs. \n+90s/epoch on Intel i5 2.4Ghz CPU.\n+10s/epoch on Tesla K40 GPU.\n+\n '''\n \n from __future__ import print_function\n@@ -9,17 +12,18 @@ np.random.seed(1337)  # for reproducibility\n \n from keras.preprocessing import sequence\n from keras.models import Sequential\n-from keras.layers.core import Dense, Dropout, Activation, Flatten\n+from keras.layers.core import Dense, Dropout, Activation, Lambda\n from keras.layers.embeddings import Embedding\n-from keras.layers.convolutional import Convolution1D, MaxPooling1D\n+from keras.layers.convolutional import Convolution1D\n from keras.datasets import imdb\n+from keras import backend as K\n \n \n # set parameters:\n max_features = 5000\n-maxlen = 100\n+maxlen = 400\n batch_size = 32\n-embedding_dims = 100\n+embedding_dims = 50\n nb_filter = 250\n filter_length = 3\n hidden_dims = 250\n@@ -42,8 +46,10 @@ model = Sequential()\n \n # we start off with an efficient embedding layer which maps\n # our vocab indices into embedding_dims dimensions\n-model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n-model.add(Dropout(0.25))\n+model.add(Embedding(max_features,\n+                    embedding_dims,\n+                    input_length=maxlen,\n+                    dropout=0.2))\n \n # we add a Convolution1D, which will learn nb_filter\n # word group filters of size filter_length:\n@@ -52,16 +58,17 @@ model.add(Convolution1D(nb_filter=nb_filter,\n                         border_mode='valid',\n                         activation='relu',\n                         subsample_length=1))\n-# we use standard max pooling (halving the output of the previous layer):\n-model.add(MaxPooling1D(pool_length=2))\n \n-# We flatten the output of the conv layer,\n-# so that we can add a vanilla dense layer:\n-model.add(Flatten())\n+# we use max over time pooling by defining a python function to use\n+# in a Lambda layer\n+def max_1d(X):\n+    return K.max(X, axis=1)\n+\n+model.add(Lambda(max_1d, output_shape=(nb_filter,)))\n \n # We add a vanilla hidden layer:\n model.add(Dense(hidden_dims))\n-model.add(Dropout(0.25))\n+model.add(Dropout(0.2))\n model.add(Activation('relu'))\n \n # We project onto a single unit output layer, and squash it with a sigmoid:\n@@ -69,7 +76,7 @@ model.add(Dense(1))\n model.add(Activation('sigmoid'))\n \n model.compile(loss='binary_crossentropy',\n-              optimizer='rmsprop',\n+              optimizer='adam',\n               metrics=['accuracy'])\n model.fit(X_train, y_train,\n           batch_size=batch_size,\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b8059aeaba0c65ee57276e3949015909cb205af5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 7 | Lines Deleted: 5 | Files Changed: 1 | Hunks: 3 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 12 | Churn Cumulative: 313 | Contributors (this commit): 4 | Commits (past 90d): 6 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -7,9 +7,10 @@ import shutil\n \n \n def setup_function(func):\n-    os.mkdir('test_images')\n-    os.mkdir('test_images/rgb')\n-    os.mkdir('test_images/gsc')\n+    paths = ['test_images', 'test_images/rgb', 'test_images/gsc']\n+    for path in paths:\n+        if not os.path.exists(path):\n+            os.mkdir(path)\n \n     img_w = img_h = 20\n     for n in range(8):\n@@ -55,6 +56,7 @@ def test_image_data_generator():\n             assert x.shape[1:] == images.shape[1:]\n             break\n \n+\n def test_img_flip():\n     x = np.array(range(4)).reshape([1, 1, 2, 2])\n     assert (flip_axis(x, 0) == x).all()\n@@ -79,8 +81,8 @@ def test_img_flip():\n             dim_ordering=dim_ordering).flow(x, [1])\n         for i in range(10):\n             potentially_flipped_x, _ = next(image_generator_th)\n-            assert (potentially_flipped_x==x).all() or \\\n-                   (potentially_flipped_x==flip_axis(x, col_index)).all()\n+            assert ((potentially_flipped_x == x).all() or\n+                    (potentially_flipped_x == flip_axis(x, col_index)).all())\n \n \n if __name__ == '__main__':\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#fe9b797a46810b6f8d327756fdf286c17239ad41", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 4 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 8 | Churn Cumulative: 490 | Contributors (this commit): 10 | Commits (past 90d): 15 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -16,7 +16,8 @@ from six.moves import range\n import threading\n \n \n-def random_rotation(x, rg, fill_mode='nearest', cval=0., axes=(1,2)):\n+def random_rotation(x, rg, fill_mode='nearest',\n+                    cval=0., axes=(1, 2)):\n     angle = np.random.uniform(-rg, rg)\n     x = ndimage.interpolation.rotate(x, angle,\n                                      axes=axes,\n@@ -26,7 +27,8 @@ def random_rotation(x, rg, fill_mode='nearest', cval=0., axes=(1,2)):\n     return x\n \n \n-def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0., row_index=1, col_index=2):\n+def random_shift(x, wrg, hrg, fill_mode='nearest',\n+                 cval=0., row_index=1, col_index=2):\n     shift_x = shift_y = 0\n     if wrg:\n         shift_x = np.random.uniform(-wrg, wrg) * x.shape[col_index]\n@@ -38,12 +40,14 @@ def random_shift(x, wrg, hrg, fill_mode='nearest', cval=0., row_index=1, col_ind\n                                     cval=cval)\n     return x\n \n+\n def flip_axis(x, axis):\n     x = np.asarray(x).swapaxes(axis, 0)\n     x = x[::-1, ...]\n     x = x.swapaxes(0, axis)\n     return x\n \n+\n def random_barrel_transform(x, intensity):\n     # TODO\n     pass\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ca7437502bc3a282cb9051e8eb5d92199c97d3df", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 6 | Churn Cumulative: 579 | Contributors (this commit): 11 | Commits (past 90d): 13 | Contributors (cumulative): 11 | DMM Complexity: 1.0\n\nDIFF:\n@@ -116,7 +116,11 @@ class Embedding(Layer):\n             return K.not_equal(x, 0)\n \n     def get_output_shape_for(self, input_shape):\n-        return (input_shape[0], self.input_length, self.output_dim)\n+        if not self.input_length:\n+            input_length = input_shape[1]\n+        else:\n+            input_length = self.input_length\n+        return (input_shape[0], input_length, self.output_dim)\n \n     def call(self, x, mask=None):\n         if 0. < self.dropout < 1.:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b32248d615abfd7835886a0f50962856f7d7c986", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1787 | Contributors (this commit): 4 | Commits (past 90d): 22 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -31,8 +31,8 @@ def standardize_input_data(data, names, shapes=None, check_batch_dim=True,\n         arrays = []\n         for name in names:\n             if name not in data:\n-                raise Exception('No data provided for input \"' +\n-                                name + '\". Input data keys: ' +\n+                raise Exception('No data provided for \"' +\n+                                name + '\". Need data for each key in: ' +\n                                 str(data.keys()))\n             arrays.append(data[name])\n     elif type(data) is list:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#090a46763ea5768a063e69bebb9349dd42915f1d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 17 | Lines Deleted: 0 | Files Changed: 2 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 1/1 | Churn Δ: 17 | Churn Cumulative: 267 | Contributors (this commit): 2 | Commits (past 90d): 7 | Contributors (cumulative): 4 | DMM Complexity: 1.0\n\nDIFF:\n@@ -8,3 +8,8 @@ def binary_accuracy(y_true, y_pred):\n def categorical_accuracy(y_true, y_pred):\n     return K.mean(K.equal(K.argmax(y_true, axis=-1),\n                   K.argmax(y_pred, axis=-1)))\n+\n+\n+from .utils.generic_utils import get_from_module\n+def get(identifier):\n+    return get_from_module(identifier, globals(), 'metric')\n\n@@ -144,6 +144,18 @@ def test_model_methods():\n                               [output_a_np, output_b_np])\n     assert len(out) == 2\n \n+    # test with a custom metric function\n+    mse = lambda y_true, y_pred: K.mean(K.pow(y_true - y_pred, 2))\n+    model.compile(optimizer, loss, metrics=[mse],\n+                  sample_weight_mode=None)\n+\n+    out = model.train_on_batch([input_a_np, input_b_np],\n+                               [output_a_np, output_b_np])\n+    assert len(out) == 3\n+    out = model.test_on_batch([input_a_np, input_b_np],\n+                              [output_a_np, output_b_np])\n+    assert len(out) == 3\n+\n     input_a_np = np.random.random((10, 3))\n     input_b_np = np.random.random((10, 3))\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#ed0cd2c60db98e6f4a315c420e1fed9968fe34d7", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 71 | Lines Deleted: 30 | Files Changed: 2 | Hunks: 11 | Methods Changed: 4 | Complexity Δ (Sum/Max): 11/7 | Churn Δ: 101 | Churn Cumulative: 700 | Contributors (this commit): 14 | Commits (past 90d): 16 | Contributors (cumulative): 15 | DMM Complexity: 0.6530612244897959\n\nDIFF:\n@@ -50,3 +50,27 @@ def probas_to_classes(y_pred):\n \n def categorical_probas_to_classes(p):\n     return np.argmax(p, axis=1)\n+\n+\n+def convert_kernel(kernel, dim_ordering='th'):\n+    '''Converts a kernel matrix (numpy array)\n+    from Theano format to TensorFlow format\n+    (or reciprocally, since the transformation\n+    is its own inverse).\n+    '''\n+    new_kernel = np.copy(kernel)\n+    if dim_ordering == 'th':\n+        w = kernel.shape[2]\n+        h = kernel.shape[3]\n+        for i in range(w):\n+            for j in range(h):\n+                new_kernel[:, :, i, j] = kernel[:, :, w - i - 1, h - j - 1]\n+    elif dim_ordering == 'tf':\n+        w = kernel.shape[0]\n+        h = kernel.shape[1]\n+        for i in range(w):\n+            for j in range(h):\n+                new_kernel[i, j, :, :] = kernel[w - i - 1, h - j - 1, :, :]\n+    else:\n+        raise Exception('Invalid dim_ordering: ' + str(dim_ordering))\n+    return new_kernel\n\n@@ -5,6 +5,7 @@ import numpy as np\n \n from keras.backend import theano_backend as KTH\n from keras.backend import tensorflow_backend as KTF\n+from keras.utils.np_utils import convert_kernel\n \n \n def check_single_tensor_operation(function_name, input_shape, **kwargs):\n@@ -22,10 +23,12 @@ def check_single_tensor_operation(function_name, input_shape, **kwargs):\n def check_two_tensor_operation(function_name, x_input_shape,\n                                y_input_shape, **kwargs):\n     xval = np.random.random(x_input_shape) - 0.5\n+\n     xth = KTH.variable(xval)\n     xtf = KTF.variable(xval)\n \n     yval = np.random.random(y_input_shape) - 0.5\n+\n     yth = KTH.variable(yval)\n     ytf = KTF.variable(yval)\n \n@@ -369,42 +372,56 @@ class TestBackend(object):\n         check_single_tensor_operation('l2_normalize', (4, 3), axis=-1)\n         check_single_tensor_operation('l2_normalize', (4, 3), axis=1)\n \n-    # def test_conv2d(self):\n-    #     '''conv2d works \"properly\" with Theano and TF but outputs different\n-    #     values in each case. Cause unclear (input / kernel shape format?)\n-    #     '''\n-    #     # TH kernel shape: (depth, input_depth, rows, cols)\n-    #     check_two_tensor_operation('conv2d', (5, 3, 10, 12), (4, 3, 2, 2),\n-    #                                strides=(1, 1), border_mode='valid')\n-    #     check_two_tensor_operation('conv2d', (5, 3, 10, 12), (4, 3, 2, 2),\n-    #                                strides=(1, 1), border_mode='same')\n+    def test_conv2d(self):\n+        # TH kernel shape: (depth, input_depth, rows, cols)\n+        # TF kernel shape: (rows, cols, input_depth, depth)\n \n-    #     # TF kernel shape: (rows, cols, input_depth, depth)\n-    #     check_two_tensor_operation('conv2d', (5, 10, 12, 3), (2, 2, 3, 4),\n-    #                                strides=(1, 1), border_mode='valid', dim_ordering='tf')\n-    #     check_two_tensor_operation('conv2d', (5, 10, 12, 3), (2, 2, 3, 4),\n-    #                                strides=(1, 1), border_mode='same', dim_ordering='tf')\n+        for input_shape in [(2, 3, 4, 5), (2, 3, 5, 6)]:\n+            for kernel_shape in [(4, 3, 2, 2), (4, 3, 3, 4)]:\n+                xval = np.random.random(input_shape)\n \n-    #     check_two_tensor_operation('conv2d', (5, 3, 10, 12), (4, 3, 3, 3),\n-    #                                strides=(1, 1), border_mode='valid')\n-    #     check_two_tensor_operation('conv2d', (5, 3, 10, 12), (4, 3, 3, 3),\n-    #                                strides=(1, 1), border_mode='same')\n+                xth = KTH.variable(xval)\n+                xtf = KTF.variable(xval)\n \n-    #     check_two_tensor_operation('conv2d', (5, 3, 10, 12), (4, 3, 3, 3),\n-    #                                strides=(2, 2), border_mode='valid')\n+                kernel_val = np.random.random(kernel_shape) - 0.5\n \n-    # def test_pool2d(self):\n-    #     '''pool2d works \"properly\" with Theano and TF but outputs different\n-    #     values in each case. Cause unclear (input shape format?)\n-    #     '''\n-    #     check_single_tensor_operation('pool2d', (5, 3, 10, 12), pool_size=(2, 2),\n-    #                                   strides=(1, 1), border_mode='valid')\n+                kernel_th = KTH.variable(convert_kernel(kernel_val))\n+                kernel_tf = KTF.variable(kernel_val)\n \n-    #     check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 2),\n-    #                                   strides=(1, 1), border_mode='valid')\n+                zth = KTH.eval(KTH.conv2d(xth, kernel_th))\n+                ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf))\n \n-    #     check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 3),\n-    #                                   strides=(1, 1), border_mode='valid')\n+                assert zth.shape == ztf.shape\n+                assert_allclose(zth, ztf, atol=1e-05)\n+\n+        input_shape = (1, 6, 5, 3)\n+        kernel_shape = (3, 3, 3, 2)\n+\n+        xval = np.random.random(input_shape)\n+\n+        xth = KTH.variable(xval)\n+        xtf = KTF.variable(xval)\n+\n+        kernel_val = np.random.random(kernel_shape) - 0.5\n+\n+        kernel_th = KTH.variable(convert_kernel(kernel_val, dim_ordering='tf'))\n+        kernel_tf = KTF.variable(kernel_val)\n+\n+        zth = KTH.eval(KTH.conv2d(xth, kernel_th, dim_ordering='tf'))\n+        ztf = KTF.eval(KTF.conv2d(xtf, kernel_tf, dim_ordering='tf'))\n+\n+        assert zth.shape == ztf.shape\n+        assert_allclose(zth, ztf, atol=1e-05)\n+\n+    def test_pool2d(self):\n+        check_single_tensor_operation('pool2d', (5, 3, 10, 12), pool_size=(2, 2),\n+                                      strides=(1, 1), border_mode='valid')\n+\n+        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 2),\n+                                      strides=(1, 1), border_mode='valid')\n+\n+        check_single_tensor_operation('pool2d', (5, 3, 9, 11), pool_size=(2, 3),\n+                                      strides=(1, 1), border_mode='valid')\n \n     def test_random_normal(self):\n         mean = 0.\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#5dad3786f6a34c15ce11ee862bab7a59ed713d68", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 40 | Lines Deleted: 3 | Files Changed: 3 | Hunks: 6 | Methods Changed: 4 | Complexity Δ (Sum/Max): 7/3 | Churn Δ: 43 | Churn Cumulative: 5876 | Contributors (this commit): 25 | Commits (past 90d): 111 | Contributors (cumulative): 40 | DMM Complexity: 0.4230769230769231\n\nDIFF:\n@@ -565,6 +565,17 @@ def set_value(x, value):\n     tf.assign(x, np.asarray(value)).op.run(session=get_session())\n \n \n+def batch_set_value(tuples):\n+    '''Sets the values of many tensor variables at once.\n+\n+    # Arguments\n+        tuples: a list of tuples `(tensor, value)`.\n+            `value` should be a Numpy array.\n+    '''\n+    if tuples:\n+        ops = [tf.assign(x, np.asarray(value)) for x, value in tuples]\n+        get_session().run(ops)\n+\n # GRAPH MANIPULATION\n \n class Function(object):\n\n@@ -473,6 +473,11 @@ def set_value(x, value):\n     x.set_value(np.asarray(value, dtype=x.dtype))\n \n \n+def batch_set_value(tuples):\n+    for x, value in tuples:\n+        x.set_value(np.asarray(value, dtype=x.dtype))\n+\n+\n # GRAPH MANIPULATION\n \n class Function(object):\n\n@@ -844,13 +844,17 @@ class Layer(object):\n                             '\" with a  weight list of length ' + str(len(weights)) +\n                             ', but the layer was expecting ' + str(len(params)) +\n                             ' weights. Provided weights: ' + str(weights))\n+        if not params:\n+            return\n+        weight_value_tuples = []\n         for p, w in zip(params, weights):\n             if K.get_value(p).shape != w.shape:\n                 raise Exception('Layer weight shape ' +\n                                 str(K.get_value(p).shape) +\n                                 ' not compatible with '\n                                 'provided weight shape ' + str(w.shape))\n-            K.set_value(p, w)\n+            weight_value_tuples.append((p, w))\n+        K.batch_set_value(weight_value_tuples)\n \n     def get_weights(self):\n         '''Returns the current weights of the layer,\n@@ -2287,12 +2291,29 @@ class Container(Layer):\n                                 ' layers into a model with ' +\n                                 str(len(flattened_layers)) + ' layers.')\n \n+            # we batch weight value assignments in a single backend call\n+            # which provides a speedup in TensorFlow.\n+            weight_value_tuples = []\n             for k, name in enumerate(layer_names):\n                 g = f[name]\n                 weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n                 if len(weight_names):\n-                    weights = [g[weight_name] for weight_name in weight_names]\n-                    flattened_layers[k].set_weights(weights)\n+                    weight_values = [g[weight_name] for weight_name in weight_names]\n+                    layer = flattened_layers[k]\n+                    symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n+                    if len(weight_values) != len(symbolic_weights):\n+                        raise Exception('Layer #' + str(k) +\n+                                        ' (named \"' + layer.name +\n+                                        '\" in the current model) was found to '\n+                                        'correspond to layer ' + name +\n+                                        ' in the save file. '\n+                                        'However the new layer ' + layer.name +\n+                                        ' expects ' + str(len(symbolic_weights)) +\n+                                        ' weights, but the saved weights have ' +\n+                                        str(len(weight_values)) +\n+                                        ' elements.')\n+                    weight_value_tuples += zip(symbolic_weights, weight_values)\n+            K.batch_set_value(weight_value_tuples)\n         f.close()\n \n     def to_json(self, **kwargs):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#e341e73c6ae89cb2fedfa5051ea7ed6c1651c6dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 8 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 8 | Methods Changed: 3 | Complexity Δ (Sum/Max): -3/0 | Churn Δ: 16 | Churn Cumulative: 4016 | Contributors (this commit): 21 | Commits (past 90d): 32 | Contributors (cumulative): 21 | DMM Complexity: None\n\nDIFF:\n@@ -549,17 +549,17 @@ class GRU(Recurrent):\n         if 0 < self.dropout_U < 1:\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * self.output_dim, 1)\n-            B_U = [K.dropout(ones, self.dropout_U) for _ in range(3)]\n+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(3)]\n             constants.append(B_U)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n \n-        if self.consume_less == 'cpu' and 0 < self.dropout_W < 1:\n+        if 0 < self.dropout_W < 1:\n             input_shape = self.input_spec[0].shape\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * input_dim, 1)\n-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(3)]\n+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(3)]\n             constants.append(B_W)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n@@ -715,9 +715,9 @@ class LSTM(Recurrent):\n             self.states = [K.zeros((input_shape[0], self.output_dim)),\n                            K.zeros((input_shape[0], self.output_dim))]\n \n-    def preprocess_input(self, x, train=False):\n+    def preprocess_input(self, x):\n         if self.consume_less == 'cpu':\n-            if train and (0 < self.dropout_W < 1):\n+            if 0 < self.dropout_W < 1:\n                 dropout = self.dropout_W\n             else:\n                 dropout = 0\n@@ -767,17 +767,17 @@ class LSTM(Recurrent):\n         if 0 < self.dropout_U < 1:\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * self.output_dim, 1)\n-            B_U = [K.dropout(ones, self.dropout_U) for _ in range(4)]\n+            B_U = [K.in_train_phase(K.dropout(ones, self.dropout_U), ones) for _ in range(4)]\n             constants.append(B_U)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n \n-        if self.consume_less == 'cpu' and 0 < self.dropout_W < 1:\n+        if 0 < self.dropout_W < 1:\n             input_shape = self.input_spec[0].shape\n             input_dim = input_shape[-1]\n             ones = K.ones_like(K.reshape(x[:, 0, 0], (-1, 1)))\n             ones = K.concatenate([ones] * input_dim, 1)\n-            B_W = [K.dropout(ones, self.dropout_W) for _ in range(4)]\n+            B_W = [K.in_train_phase(K.dropout(ones, self.dropout_W), ones) for _ in range(4)]\n             constants.append(B_W)\n         else:\n             constants.append([K.cast_to_floatx(1.) for _ in range(4)])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9d60126661fc91fdbe6e882d8b6a0603a47161b9", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1538 | Contributors (this commit): 15 | Commits (past 90d): 12 | Contributors (cumulative): 15 | DMM Complexity: None\n\nDIFF:\n@@ -446,7 +446,7 @@ class TensorBoard(Callback):\n \n         self.model = model\n         self.sess = KTF.get_session()\n-        if self.histogram_freq and not self.merged:\n+        if self.histogram_freq and self.merged is None:\n             layers = self.model.layers\n             for layer in layers:\n                 if hasattr(layer, 'W'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7a12fd0f8597760cf8e1238a9b021e247693517b", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 168 | Contributors (this commit): 8 | Commits (past 90d): 8 | Contributors (cumulative): 9 | DMM Complexity: None\n\nDIFF:\n@@ -1 +1 @@\n-__version__ = '1.0.0'\r\n+__version__ = '1.0.1'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.0.0',\n+      version='1.0.1',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.0.0',\n+      download_url='https://github.com/fchollet/keras/tarball/1.0.1',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55159cf451cfe621745e5a0a7f96391f8994cdc5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 2641 | Contributors (this commit): 5 | Commits (past 90d): 25 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -1169,7 +1169,7 @@ class Merge(Layer):\n                     raise Exception('Invalid format for dot_axes - list elements should be \"int\".')\n                 if shape1[dot_axes[0]] != shape2[dot_axes[1]]:\n                     raise Exception('Dimension incompatibility using dot mode: ' +\n-                                    '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1][i]]) +\n+                                    '%s != %s. ' % (shape1[dot_axes[0]], shape2[dot_axes[1]]) +\n                                     'Layer shapes: %s, %s' % (shape1, shape2))\n         elif mode == 'concat':\n             reduced_inputs_shapes = [list(shape) for shape in input_shapes]\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#7ce144881a1dad0bde8f5ff481155f4408de70c4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 1691 | Contributors (this commit): 20 | Commits (past 90d): 42 | Contributors (cumulative): 20 | DMM Complexity: None\n\nDIFF:\n@@ -576,7 +576,7 @@ def rnn(step_function, inputs, initial_states,\n             successive_states = []\n             states = initial_states\n             for i in indices:\n-                output, new_states = step_function(inputs[i], states)\n+                output, new_states = step_function(inputs[i], states + constants)\n \n                 if len(successive_outputs) == 0:\n                     prev_output = zeros_like(output)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
