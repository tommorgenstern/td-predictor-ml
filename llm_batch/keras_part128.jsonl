{"custom_id": "keras#c5cc96a4f4973c75e2eb533c3c88a234fbc333e4", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 9 | Lines Deleted: 30 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): -6/0 | Churn Δ: 39 | Churn Cumulative: 2268 | Contributors (this commit): 29 | Commits (past 90d): 13 | Contributors (cumulative): 29 | DMM Complexity: 1.0\n\nDIFF:\n@@ -238,35 +238,6 @@ def collect_metrics(metrics, output_names):\n                         str(metrics))\n \n \n-def collect_trainable_weights(layer):\n-    '''Collects all `trainable_weights` attributes,\n-    excluding any sublayers where `trainable` is set the `False`.\n-    '''\n-    trainable = getattr(layer, 'trainable', True)\n-    if not trainable:\n-        return []\n-    weights = []\n-    if layer.__class__.__name__ == 'Sequential':\n-        for sublayer in layer.flattened_layers:\n-            weights += collect_trainable_weights(sublayer)\n-    elif layer.__class__.__name__ == 'Model':\n-        for sublayer in layer.layers:\n-            weights += collect_trainable_weights(sublayer)\n-    else:\n-        weights += layer.trainable_weights\n-    # dedupe weights\n-    weights = list(set(weights))\n-    # TF variables have auto-generated the name, while Theano has auto-generated the auto_name variable.\n-    # name in Theano is sometimes None.\n-    # However, to work save_model() and load_model() properly, weights must be sorted by names.\n-    if weights:\n-        if K.backend() == 'theano':\n-            weights.sort(key=lambda x: x.name if x.name else x.auto_name)\n-        else:\n-            weights.sort(key=lambda x: x.name)\n-    return weights\n-\n-\n def batch_shuffle(index_array, batch_size):\n     '''This shuffles an array in a batch-wise fashion.\n     Useful for shuffling HDF5 arrays\n@@ -701,7 +672,15 @@ class Model(Container):\n         self.test_function = None\n         self.predict_function = None\n \n-        self._collected_trainable_weights = collect_trainable_weights(self)\n+        # collected trainable weights and sort them deterministically.\n+        trainable_weights = self.trainable_weights\n+        # Sort weights by name\n+        if trainable_weights:\n+            if K.backend() == 'theano':\n+                trainable_weights.sort(key=lambda x: x.name if x.name else x.auto_name)\n+            else:\n+                trainable_weights.sort(key=lambda x: x.name)\n+        self._collected_trainable_weights = trainable_weights\n \n     def _make_train_function(self):\n         if not hasattr(self, 'train_function'):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#703d5a1298befcdcc2f87cbe3080f18fb866b63d", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 114 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 3 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 114 | Churn Cumulative: 114 | Contributors (this commit): 1 | Commits (past 90d): 1 | Contributors (cumulative): 1 | DMM Complexity: 1.0\n\nDIFF:\n@@ -0,0 +1,114 @@\n+from __future__ import absolute_import\n+from __future__ import print_function\n+import pytest\n+\n+from keras.utils.test_utils import keras_test\n+from keras.models import Model, Sequential\n+from keras.layers import Dense, Input\n+\n+\n+@keras_test\n+def test_layer_trainability_switch():\n+    # with constructor argument, in Sequential\n+    model = Sequential()\n+    model.add(Dense(2, trainable=False, input_dim=1))\n+    assert model.trainable_weights == []\n+\n+    # by setting the `trainable` argument, in Sequential\n+    model = Sequential()\n+    layer = Dense(2, input_dim=1)\n+    model.add(layer)\n+    assert model.trainable_weights == layer.trainable_weights\n+    layer.trainable = False\n+    assert model.trainable_weights == []\n+\n+    # with constructor argument, in Model\n+    x = Input(shape=(1,))\n+    y = Dense(2, trainable=False)(x)\n+    model = Model(x, y)\n+    assert model.trainable_weights == []\n+\n+    # by setting the `trainable` argument, in Model\n+    x = Input(shape=(1,))\n+    layer = Dense(2)\n+    y = layer(x)\n+    model = Model(x, y)\n+    assert model.trainable_weights == layer.trainable_weights\n+    layer.trainable = False\n+    assert model.trainable_weights == []\n+\n+\n+@keras_test\n+def test_model_trainability_switch():\n+    # a non-trainable model has no trainable weights\n+    x = Input(shape=(1,))\n+    y = Dense(2)(x)\n+    model = Model(x, y)\n+    model.trainable = False\n+    assert model.trainable_weights == []\n+\n+    # same for Sequential\n+    model = Sequential()\n+    model.add(Dense(2, input_dim=1))\n+    model.trainable = False\n+    assert model.trainable_weights == []\n+\n+\n+@keras_test\n+def test_nested_model_trainability():\n+    # a Sequential inside a Model\n+    inner_model = Sequential()\n+    inner_model.add(Dense(2, input_dim=1))\n+\n+    x = Input(shape=(1,))\n+    y = inner_model(x)\n+    outer_model = Model(x, y)\n+    assert outer_model.trainable_weights == inner_model.trainable_weights\n+    inner_model.trainable = False\n+    assert outer_model.trainable_weights == []\n+    inner_model.trainable = True\n+    inner_model.layers[-1].trainable = False\n+    assert outer_model.trainable_weights == []\n+\n+    # a Sequential inside a Sequential\n+    inner_model = Sequential()\n+    inner_model.add(Dense(2, input_dim=1))\n+    outer_model = Sequential()\n+    outer_model.add(inner_model)\n+    assert outer_model.trainable_weights == inner_model.trainable_weights\n+    inner_model.trainable = False\n+    assert outer_model.trainable_weights == []\n+    inner_model.trainable = True\n+    inner_model.layers[-1].trainable = False\n+    assert outer_model.trainable_weights == []\n+\n+    # a Model inside a Model\n+    x = Input(shape=(1,))\n+    y = Dense(2)(x)\n+    inner_model = Model(x, y)\n+    x = Input(shape=(1,))\n+    y = inner_model(x)\n+    outer_model = Model(x, y)\n+    assert outer_model.trainable_weights == inner_model.trainable_weights\n+    inner_model.trainable = False\n+    assert outer_model.trainable_weights == []\n+    inner_model.trainable = True\n+    inner_model.layers[-1].trainable = False\n+    assert outer_model.trainable_weights == []\n+\n+    # a Model inside a Sequential\n+    x = Input(shape=(1,))\n+    y = Dense(2)(x)\n+    inner_model = Model(x, y)\n+    outer_model = Sequential()\n+    outer_model.add(inner_model)\n+    assert outer_model.trainable_weights == inner_model.trainable_weights\n+    inner_model.trainable = False\n+    assert outer_model.trainable_weights == []\n+    inner_model.trainable = True\n+    inner_model.layers[-1].trainable = False\n+    assert outer_model.trainable_weights == []\n+\n+\n+if __name__ == '__main__':\n+    pytest.main([__file__])\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#c0b32a9a04c761e03e082d4ff955702c6aa17003", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 51 | Files Changed: 1 | Hunks: 5 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 53 | Churn Cumulative: 572 | Contributors (this commit): 6 | Commits (past 90d): 5 | Contributors (cumulative): 6 | DMM Complexity: 0.0\n\nDIFF:\n@@ -186,13 +186,12 @@ def test_ReduceLROnPlateau():\n     assert np.allclose(float(K.get_value(model.optimizer.lr)), 0.1, atol=K.epsilon())\n \n \n-@pytest.mark.skipif((K._BACKEND != 'tensorflow'),\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard():\n     import shutil\n     import tensorflow as tf\n     import keras.backend.tensorflow_backend as KTF\n-    old_session = KTF.get_session()\n     filepath = './logs'\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n                                                          nb_test=test_samples,\n@@ -224,10 +223,6 @@ def test_TensorBoard():\n                 yield {'X_vars': X_test, 'output': y_test}\n \n     # case 1 Sequential\n-\n-    with tf.Graph().as_default():\n-        session = tf.Session('')\n-        KTF.set_session(session)\n     model = Sequential()\n     model.add(Dense(nb_hidden, input_dim=input_dim, activation='relu'))\n     model.add(Dense(nb_class, activation='softmax'))\n@@ -267,50 +262,6 @@ def test_TensorBoard():\n     assert os.path.exists(filepath)\n     shutil.rmtree(filepath)\n \n-    # case 2 Graph\n-\n-    with tf.Graph().as_default():\n-        session = tf.Session('')\n-        KTF.set_session(session)\n-        model = Graph()\n-        model.add_input(name='X_vars', input_shape=(input_dim,))\n-\n-        model.add_node(Dense(nb_hidden, activation=\"sigmoid\"),\n-                       name='Dense1', input='X_vars')\n-        model.add_node(Dense(nb_class, activation=\"softmax\"),\n-                       name='last_dense',\n-                       input='Dense1')\n-        model.add_output(name='output', input='last_dense')\n-        model.compile(optimizer='sgd', loss={'output': 'mse'})\n-\n-        tsb = callbacks.TensorBoard(log_dir=filepath, histogram_freq=1)\n-        cbks = [tsb]\n-\n-        # fit with validation\n-        model.fit({'X_vars': X_train, 'output': y_train},\n-                  batch_size=batch_size,\n-                  validation_data={'X_vars': X_test, 'output': y_test},\n-                  callbacks=cbks, nb_epoch=2)\n-\n-        # fit wo validation\n-        model.fit({'X_vars': X_train, 'output': y_train},\n-                  batch_size=batch_size,\n-                  callbacks=cbks, nb_epoch=2)\n-\n-        # fit generator with validation\n-        model.fit_generator(data_generator_graph(True), 1000, nb_epoch=2,\n-                            validation_data={'X_vars': X_test, 'output': y_test},\n-                            callbacks=cbks)\n-\n-        # fit generator wo validation\n-        model.fit_generator(data_generator_graph(True), 1000, nb_epoch=2,\n-                            callbacks=cbks)\n-\n-        assert os.path.exists(filepath)\n-        shutil.rmtree(filepath)\n-\n-    KTF.set_session(old_session)\n-\n \n def test_LambdaCallback():\n     (X_train, y_train), (X_test, y_test) = get_test_data(nb_train=train_samples,\n@@ -343,7 +294,7 @@ def test_LambdaCallback():\n     assert not p.is_alive()\n \n \n-@pytest.mark.skipif((K._BACKEND != 'tensorflow'),\n+@pytest.mark.skipif((K.backend() != 'tensorflow'),\n                     reason=\"Requires tensorflow backend\")\n def test_TensorBoard_with_ReduceLROnPlateau():\n     import shutil\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#0a9c0ca461f280c988e252baaf5b13a12f6204f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 12 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 3 | Methods Changed: 4 | Complexity Δ (Sum/Max): 3/3 | Churn Δ: 13 | Churn Cumulative: 7947 | Contributors (this commit): 52 | Commits (past 90d): 11 | Contributors (cumulative): 52 | DMM Complexity: 1.0\n\nDIFF:\n@@ -250,7 +250,7 @@ class Sequential(Model):\n         self.model = None  # internal Model instance\n         self.inputs = []  # tensors\n         self.outputs = []  # tensors (length 1)\n-        self.trainable = True\n+        self._trainable = True\n \n         # model attributes\n         self.inbound_nodes = []\n@@ -383,6 +383,7 @@ class Sequential(Model):\n                             ' Add some layers first.')\n         # actually create the model\n         self.model = Model(self.inputs, self.outputs[0], name=self.name + '_model')\n+        self.model.trainable = self.trainable\n \n         # mirror model attributes\n         self.supports_masking = self.model.supports_masking\n@@ -454,6 +455,16 @@ class Sequential(Model):\n                              list(layer_dict.items()))\n         return all_attrs\n \n+    @property\n+    def trainable(self):\n+        return self._trainable\n+\n+    @trainable.setter\n+    def trainable(self, value):\n+        if self.model:\n+            self.model.trainable = value\n+        self._trainable = value\n+\n     @property\n     def trainable_weights(self):\n         if not self.trainable:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b2aebb30bfc113f82da4236bf0f3712b1d8c3429", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 6 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 4 | Methods Changed: 3 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 6 | Churn Cumulative: 1932 | Contributors (this commit): 32 | Commits (past 90d): 11 | Contributors (cumulative): 32 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1,6 +1,7 @@\n from __future__ import absolute_import\n from __future__ import print_function\n \n+import os\n import csv\n \n import numpy as np\n@@ -683,10 +684,14 @@ class CSVLogger(Callback):\n         self.append = append\n         self.writer = None\n         self.keys = None\n+        self.append_header = True\n         super(CSVLogger, self).__init__()\n \n     def on_train_begin(self, logs={}):\n         if self.append:\n+            if os.path.exists(self.filename):\n+                with open(self.filename) as f:\n+                    self.append_header = len(f.readline()) == 0\n             self.csv_file = open(self.filename, 'a')\n         else:\n             self.csv_file = open(self.filename, 'w')\n@@ -702,6 +707,7 @@ class CSVLogger(Callback):\n         if not self.writer:\n             self.keys = sorted(logs.keys())\n             self.writer = csv.DictWriter(self.csv_file, fieldnames=['epoch'] + self.keys)\n+            if self.append_header:\n                 self.writer.writeheader()\n \n         row_dict = OrderedDict({'epoch': epoch})\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#2ddd2bd557bd20e2f6856621bf22e8da8cb6acc8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 3 | Lines Deleted: 3 | Files Changed: 2 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 6 | Churn Cumulative: 246 | Contributors (this commit): 9 | Commits (past 90d): 6 | Contributors (cumulative): 10 | DMM Complexity: None\n\nDIFF:\n@@ -15,4 +15,4 @@ from . import objectives\n from . import optimizers\r\n from . import regularizers\r\n \r\n-__version__ = '1.1.1'\r\n+__version__ = '1.1.2'\r\n\n@@ -3,12 +3,12 @@ from setuptools import find_packages\n \n \n setup(name='Keras',\n-      version='1.1.1',\n+      version='1.1.2',\n       description='Deep Learning for Python',\n       author='Francois Chollet',\n       author_email='francois.chollet@gmail.com',\n       url='https://github.com/fchollet/keras',\n-      download_url='https://github.com/fchollet/keras/tarball/1.1.1',\n+      download_url='https://github.com/fchollet/keras/tarball/1.1.2',\n       license='MIT',\n       install_requires=['theano', 'pyyaml', 'six'],\n       extras_require={\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#dfeca151a2bf99686e0e9cecba8ba4bad79ed1f6", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 113 | Lines Deleted: 55 | Files Changed: 6 | Hunks: 22 | Methods Changed: 11 | Complexity Δ (Sum/Max): 7/20 | Churn Δ: 168 | Churn Cumulative: 1313 | Contributors (this commit): 2 | Commits (past 90d): 16 | Contributors (cumulative): 7 | DMM Complexity: 0.0\n\nDIFF:\n@@ -49,3 +49,46 @@ def decode_predictions(preds, top=5):\n         result.sort(key=lambda x: x[2], reverse=True)\n         results.append(result)\n     return results\n+\n+\n+def _obtain_input_shape(input_shape, default_size, min_size, dim_ordering, include_top):\n+    if dim_ordering == 'th':\n+        default_shape = (3, default_size, default_size)\n+    else:\n+        default_shape = (default_size, default_size, 3)\n+    if include_top:\n+        if input_shape is not None:\n+            if input_shape != default_shape:\n+                raise ValueError('When setting`include_top=True`, '\n+                                 '`input_shape` should be ' + str(default_shape) + '.')\n+        input_shape = default_shape\n+    else:\n+        if dim_ordering == 'th':\n+            if input_shape is not None:\n+                if len(input_shape) != 3:\n+                    raise ValueError('`input_shape` must be a tuple of three integers.')\n+                if input_shape[1] != 3:\n+                    raise ValueError('The input must have 3 channels; got '\n+                                     '`input_shape=' + str(input_shape) + '`')\n+                if ((input_shape[1] is not None and input_shape[1] < min_size) or\n+                   (input_shape[2] is not None and input_shape[2] < min_size)):\n+                    raise ValueError('Input size must be at least ' +\n+                                     str(min_size) + 'x' + str(min_size) + ', got '\n+                                     '`input_shape=' + str(input_shape) + '`')\n+            else:\n+                input_shape = (3, None, None)\n+        else:\n+            if input_shape is not None:\n+                if len(input_shape) != 3:\n+                    raise ValueError('`input_shape` must be a tuple of three integers.')\n+                if input_shape[-1] != 3:\n+                    raise ValueError('The input must have 3 channels; got '\n+                                     '`input_shape=' + str(input_shape) + '`')\n+                if ((input_shape[0] is not None and input_shape[0] < min_size) or\n+                   (input_shape[1] is not None and input_shape[1] < min_size)):\n+                    raise ValueError('Input size must be at least ' +\n+                                     str(min_size) + 'x' + str(min_size) + ', got '\n+                                     '`input_shape=' + str(input_shape) + '`')\n+            else:\n+                input_shape = (None, None, 3)\n+    return input_shape\n\n@@ -26,7 +26,7 @@ from ..layers import Convolution2D, MaxPooling2D, AveragePooling2D\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions\n+from .imagenet_utils import decode_predictions, _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/inception_v3_weights_th_dim_ordering_th_kernels.h5'\n@@ -60,7 +60,7 @@ def conv2d_bn(x, nb_filter, nb_row, nb_col,\n \n \n def InceptionV3(include_top=True, weights='imagenet',\n-                input_tensor=None):\n+                input_tensor=None, input_shape=None):\n     '''Instantiate the Inception v3 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -82,6 +82,13 @@ def InceptionV3(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n+        inputs_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(299, 299, 3)` (with `tf` dim ordering)\n+            or `(3, 299, 299)` (with `th` dim ordering).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 139.\n+            E.g. `(150, 150, 3)` would be one valid value.\n \n     # Returns\n         A Keras model instance.\n@@ -91,16 +98,11 @@ def InceptionV3(include_top=True, weights='imagenet',\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n     # Determine proper input shape\n-    if K.image_dim_ordering() == 'th':\n-        if include_top:\n-            input_shape = (3, 299, 299)\n-        else:\n-            input_shape = (3, None, None)\n-    else:\n-        if include_top:\n-            input_shape = (299, 299, 3)\n-        else:\n-            input_shape = (None, None, 3)\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=299,\n+                                      min_size=139,\n+                                      dim_ordering=K.image_dim_ordering(),\n+                                      include_top=include_top)\n \n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n\n@@ -20,7 +20,7 @@ from ..models import Model\n from .. import backend as K\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n-from .imagenet_utils import decode_predictions, preprocess_input\n+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels.h5'\n@@ -108,7 +108,7 @@ def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2))\n \n \n def ResNet50(include_top=True, weights='imagenet',\n-             input_tensor=None):\n+             input_tensor=None, input_shape=None):\n     '''Instantiate the ResNet50 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -126,8 +126,15 @@ def ResNet50(include_top=True, weights='imagenet',\n             layers at the top of the network.\n         weights: one of `None` (random initialization)\n             or \"imagenet\" (pre-training on ImageNet).\n-        input_tensor: optional Keras tensor (i.e. xput of `layers.Input()`)\n+        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n+        inputs_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `tf` dim ordering)\n+            or `(3, 224, 244)` (with `th` dim ordering).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 197.\n+            E.g. `(200, 200, 3)` would be one valid value.\n \n     # Returns\n         A Keras model instance.\n@@ -137,16 +144,11 @@ def ResNet50(include_top=True, weights='imagenet',\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n     # Determine proper input shape\n-    if K.image_dim_ordering() == 'th':\n-        if include_top:\n-            input_shape = (3, 224, 224)\n-        else:\n-            input_shape = (3, None, None)\n-    else:\n-        if include_top:\n-            input_shape = (224, 224, 3)\n-        else:\n-            input_shape = (None, None, 3)\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=197,\n+                                      dim_ordering=K.image_dim_ordering(),\n+                                      include_top=include_top)\n \n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n\n@@ -17,7 +17,7 @@ from ..layers import Convolution2D, MaxPooling2D\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, preprocess_input\n+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5'\n@@ -27,7 +27,7 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def VGG16(include_top=True, weights='imagenet',\n-          input_tensor=None):\n+          input_tensor=None, input_shape=None):\n     '''Instantiate the VGG16 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -47,6 +47,13 @@ def VGG16(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n+        inputs_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `tf` dim ordering)\n+            or `(3, 224, 244)` (with `th` dim ordering).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 48.\n+            E.g. `(200, 200, 3)` would be one valid value.\n \n     # Returns\n         A Keras model instance.\n@@ -56,16 +63,11 @@ def VGG16(include_top=True, weights='imagenet',\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n     # Determine proper input shape\n-    if K.image_dim_ordering() == 'th':\n-        if include_top:\n-            input_shape = (3, 224, 224)\n-        else:\n-            input_shape = (3, None, None)\n-    else:\n-        if include_top:\n-            input_shape = (224, 224, 3)\n-        else:\n-            input_shape = (None, None, 3)\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=48,\n+                                      dim_ordering=K.image_dim_ordering(),\n+                                      include_top=include_top)\n \n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n\n@@ -17,7 +17,7 @@ from ..layers import Convolution2D, MaxPooling2D\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions, preprocess_input\n+from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n \n \n TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_th_dim_ordering_th_kernels.h5'\n@@ -27,7 +27,7 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def VGG19(include_top=True, weights='imagenet',\n-          input_tensor=None):\n+          input_tensor=None, input_shape=None):\n     '''Instantiate the VGG19 architecture,\n     optionally loading weights pre-trained\n     on ImageNet. Note that when using TensorFlow,\n@@ -47,6 +47,13 @@ def VGG19(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n+        inputs_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(224, 224, 3)` (with `tf` dim ordering)\n+            or `(3, 224, 244)` (with `th` dim ordering).\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 48.\n+            E.g. `(200, 200, 3)` would be one valid value.\n \n     # Returns\n         A Keras model instance.\n@@ -56,16 +63,11 @@ def VGG19(include_top=True, weights='imagenet',\n                          '`None` (random initialization) or `imagenet` '\n                          '(pre-training on ImageNet).')\n     # Determine proper input shape\n-    if K.image_dim_ordering() == 'th':\n-        if include_top:\n-            input_shape = (3, 224, 224)\n-        else:\n-            input_shape = (3, None, None)\n-    else:\n-        if include_top:\n-            input_shape = (224, 224, 3)\n-        else:\n-            input_shape = (None, None, 3)\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=224,\n+                                      min_size=48,\n+                                      dim_ordering=K.image_dim_ordering(),\n+                                      include_top=include_top)\n \n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n\n@@ -27,7 +27,7 @@ from ..layers import Dense, Input, BatchNormalization, Activation, merge\n from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\n from ..utils.data_utils import get_file\n from .. import backend as K\n-from .imagenet_utils import decode_predictions\n+from .imagenet_utils import decode_predictions, _obtain_input_shape\n \n \n TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels.h5'\n@@ -35,7 +35,7 @@ TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/relea\n \n \n def Xception(include_top=True, weights='imagenet',\n-             input_tensor=None):\n+             input_tensor=None, input_shape=None):\n     '''Instantiate the Xception architecture,\n     optionally loading weights pre-trained\n     on ImageNet. This model is available for TensorFlow only,\n@@ -53,6 +53,12 @@ def Xception(include_top=True, weights='imagenet',\n             or \"imagenet\" (pre-training on ImageNet).\n         input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n             to use as image input for the model.\n+        inputs_shape: optional shape tuple, only to be specified\n+            if `include_top` is False (otherwise the input shape\n+            has to be `(299, 299, 3)`.\n+            It should have exactly 3 inputs channels,\n+            and width and height should be no smaller than 71.\n+            E.g. `(150, 150, 3)` would be one valid value.\n \n     # Returns\n         A Keras model instance.\n@@ -80,10 +86,11 @@ def Xception(include_top=True, weights='imagenet',\n         old_dim_ordering = None\n \n     # Determine proper input shape\n-    if include_top:\n-        input_shape = (299, 299, 3)\n-    else:\n-        input_shape = (None, None, 3)\n+    input_shape = _obtain_input_shape(input_shape,\n+                                      default_size=299,\n+                                      min_size=71,\n+                                      dim_ordering=K.image_dim_ordering(),\n+                                      include_top=include_top)\n \n     if input_tensor is None:\n         img_input = Input(shape=input_shape)\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#57f2f1100586bf55000490b86c8af25107d5447a", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 4062 | Contributors (this commit): 25 | Commits (past 90d): 22 | Contributors (cumulative): 25 | DMM Complexity: None\n\nDIFF:\n@@ -903,14 +903,14 @@ class Layer(object):\n         composing the weights of the layer.\n         '''\n         if not self.built:\n-            if self.__class__.__name__ in {'Sequential'}:\n+            if self.__class__.__name__ == 'Sequential':\n                 self.build()\n             else:\n                 raise Exception('You tried to call `count_params` on ' +\n                                 self.name + ', but the layer isn\\'t built. '\n                                 'You can build it manually via: `' +\n                                 self.name + '.build(batch_input_shape)`.')\n-        return sum([K.count_params(p) for p in self.trainable_weights])\n+        return sum([K.count_params(p) for p in self.weights])\n \n \n class InputLayer(Layer):\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#83b90c172c60074c3c6dcaa8256d6d19ca093dda", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 1 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 145 | Contributors (this commit): 5 | Commits (past 90d): 3 | Contributors (cumulative): 5 | DMM Complexity: None\n\nDIFF:\n@@ -86,7 +86,7 @@ def save_array(array, name):\n     import tables\n     f = tables.open_file(name, 'w')\n     atom = tables.Atom.from_dtype(array.dtype)\n-    ds = f.createCArray(f.root, 'data', atom, array.shape)\n+    ds = f.create_carray(f.root, 'data', atom, array.shape)\n     ds[:] = array\n     f.close()\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#24d6cca275ea7e47664901fbfb59f033af901242", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 4 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 2/2 | Churn Δ: 4 | Churn Cumulative: 3405 | Contributors (this commit): 44 | Commits (past 90d): 25 | Contributors (cumulative): 44 | DMM Complexity: 1.0\n\nDIFF:\n@@ -1284,6 +1284,8 @@ def rnn(step_function, inputs, initial_states,\n                 output, new_states = step_function(current_input,\n                                                    tuple(states) +\n                                                    tuple(constants))\n+                for state, new_state in zip(states, new_states):\n+                    new_state.set_shape(state.get_shape())\n                 tiled_mask_t = tf.tile(mask_t, tf.pack([1, tf.shape(output)[1]]))\n                 output = tf.select(tiled_mask_t, output, states[0])\n                 new_states = [tf.select(tiled_mask_t, new_states[i], states[i]) for i in range(len(states))]\n@@ -1295,6 +1297,8 @@ def rnn(step_function, inputs, initial_states,\n                 output, new_states = step_function(current_input,\n                                                    tuple(states) +\n                                                    tuple(constants))\n+                for state, new_state in zip(states, new_states):\n+                    new_state.set_shape(state.get_shape())\n                 output_ta_t = output_ta_t.write(time, output)\n                 return (time + 1, output_ta_t) + tuple(new_states)\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#79ec9b8079e926104b444239cc9642cb269492dc", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 8 | Files Changed: 1 | Hunks: 3 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 9 | Churn Cumulative: 341 | Contributors (this commit): 2 | Commits (past 90d): 3 | Contributors (cumulative): 2 | DMM Complexity: None\n\nDIFF:\n@@ -160,8 +160,6 @@ if __name__ == '__main__':\n         loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n     )\n \n-    discriminator.trainable = True\n-\n     # get our mnist data, and force it to be of shape (..., 1, 28, 28) with\n     # range [-1, 1]\n     (X_train, y_train), (X_test, y_test) = mnist.load_data()\n@@ -217,10 +215,7 @@ if __name__ == '__main__':\n             noise = np.random.uniform(-1, 1, (2 * batch_size, latent_size))\n             sampled_labels = np.random.randint(0, 10, 2 * batch_size)\n \n-            # we want to fix the discriminator and let the generator train to\n-            # trick it\n-            discriminator.trainable = False\n-\n+            # we want to train the genrator to trick the discriminator\n             # For the generator, we want all the {fake, not-fake} labels to say\n             # not-fake\n             trick = np.ones(2 * batch_size)\n@@ -228,8 +223,6 @@ if __name__ == '__main__':\n             epoch_gen_loss.append(combined.train_on_batch(\n                 [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n \n-            discriminator.trainable = True\n-\n         print('\\nTesting for epoch {}:'.format(epoch + 1))\n \n         # evaluate the testing loss here\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#b23e873e0fcca3aab6eec829caa43d4bff5a9379", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 1936 | Contributors (this commit): 33 | Commits (past 90d): 11 | Contributors (cumulative): 33 | DMM Complexity: None\n\nDIFF:\n@@ -671,7 +671,7 @@ class CSVLogger(Callback):\n             model.fit(X_train, Y_train, callbacks=[csv_logger])\n         ```\n \n-    Arguments\n+    # Arguments\n         filename: filename of the csv file, e.g. 'run/log.csv'.\n         separator: string used to separate elements in the csv file.\n         append: True: append if file exists (useful for continuing\n@@ -723,7 +723,7 @@ class LambdaCallback(Callback):\n     \"\"\"Callback for creating simple, custom callbacks on-the-fly.\n \n     This callback is constructed with anonymous functions that will be called\n-    at the appropiate time. Note that the callbacks expects positional\n+    at the appropriate time. Note that the callbacks expects positional\n     arguments, as:\n      - `on_epoch_begin` and `on_epoch_end` expect two positional arguments: `epoch`, `logs`\n      - `on_batch_begin` and `on_batch_end` expect two positional arguments: `batch`, `logs`\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#9bfbe6ae3e3d516bbb44871d1451a775795784b8", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 1 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 1 | Churn Cumulative: 148 | Contributors (this commit): 10 | Commits (past 90d): 4 | Contributors (cumulative): 10 | DMM Complexity: 1.0\n\nDIFF:\n@@ -16,6 +16,7 @@ def to_categorical(y, nb_classes=None):\n     # Returns\n         A binary matrix representation of the input.\n     '''\n+    y = np.array(y, dtype='int')\n     if not nb_classes:\n         nb_classes = np.max(y)+1\n     Y = np.zeros((len(y), nb_classes))\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#55163b599971553725b892f641023cd286712c03", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 5 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 1 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 5 | Churn Cumulative: 10630 | Contributors (this commit): 55 | Commits (past 90d): 5 | Contributors (cumulative): 55 | DMM Complexity: 0.0\n\nDIFF:\n@@ -566,6 +566,11 @@ class Lambda(Layer):\n                 else:\n                     return K.int_shape(x)\n             # otherwise, we default to the input shape\n+            warnings.warn('`output_shape` argument not specified for layer {} '\n+                          'and cannot be automatically inferred with the Theano backend. '\n+                          'Defaulting to output shape `{}` (same as input shape). '\n+                          'If the expected output shape is different, specify it via the `output_shape` argument.'\n+                          .format(self.name, input_shape))\n             return input_shape\n         elif type(self._output_shape) in {tuple, list}:\n             if type(input_shape) is list:\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#3bf913dc35596015c736e56458042be65859e682", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 0 | Files Changed: 1 | Hunks: 1 | Methods Changed: 0 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 2 | Churn Cumulative: 50 | Contributors (this commit): 4 | Commits (past 90d): 3 | Contributors (cumulative): 4 | DMM Complexity: None\n\nDIFF:\n@@ -1,5 +1,7 @@\n from __future__ import print_function\n import pytest\n+import numpy as np\n+np.random.seed(1337)\n \n from keras.utils.test_utils import get_test_data\n from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#68af216772980a7c8811bc1ad5421970fb6a978c", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 56 | Lines Deleted: 12 | Files Changed: 7 | Hunks: 13 | Methods Changed: 7 | Complexity Δ (Sum/Max): 6/1 | Churn Δ: 68 | Churn Cumulative: 5522 | Contributors (this commit): 26 | Commits (past 90d): 37 | Contributors (cumulative): 32 | DMM Complexity: 0.0\n\nDIFF:\n@@ -23,6 +23,7 @@ import warnings\n from ..models import Model\n from ..layers import Flatten, Dense, Input, BatchNormalization, merge\n from ..layers import Convolution2D, MaxPooling2D, AveragePooling2D\n+from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n@@ -263,8 +264,14 @@ def InceptionV3(include_top=True, weights='imagenet',\n         x = Flatten(name='flatten')(x)\n         x = Dense(1000, activation='softmax', name='predictions')(x)\n \n-    # Create model\n-    model = Model(img_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Model(inputs, x)\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -18,6 +18,7 @@ from ..layers.convolutional import MaxPooling2D, ZeroPadding2D\n from ..layers.normalization import BatchNormalization\n from ..layers.advanced_activations import ELU\n from ..layers.recurrent import GRU\n+from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from ..utils.layer_utils import convert_all_kernels_in_model\n from .audio_conv_utils import decode_predictions, preprocess_input\n@@ -127,8 +128,15 @@ def MusicTaggerCRNN(weights='msd', input_tensor=None,\n     if include_top:\n         x = Dense(50, activation='sigmoid', name='output')(x)\n \n-    # Create model\n-    model = Model(melgram_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = melgram_input\n+    # Create model.\n+    model = Model(inputs, x)\n+\n     if weights is None:\n         return model\n     else:\n\n@@ -18,6 +18,7 @@ from ..layers import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2\n from ..layers import BatchNormalization\n from ..models import Model\n from .. import backend as K\n+from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .imagenet_utils import decode_predictions, preprocess_input, _obtain_input_shape\n@@ -194,7 +195,14 @@ def ResNet50(include_top=True, weights='imagenet',\n         x = Flatten()(x)\n         x = Dense(1000, activation='softmax', name='fc1000')(x)\n \n-    model = Model(img_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Model(inputs, x)\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -14,6 +14,7 @@ import warnings\n from ..models import Model\n from ..layers import Flatten, Dense, Input\n from ..layers import Convolution2D, MaxPooling2D\n+from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n@@ -111,8 +112,14 @@ def VGG16(include_top=True, weights='imagenet',\n         x = Dense(4096, activation='relu', name='fc2')(x)\n         x = Dense(1000, activation='softmax', name='predictions')(x)\n \n-    # Create model\n-    model = Model(img_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Model(inputs, x)\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -14,6 +14,7 @@ import warnings\n from ..models import Model\n from ..layers import Flatten, Dense, Input\n from ..layers import Convolution2D, MaxPooling2D\n+from ..engine.topology import get_source_inputs\n from ..utils.layer_utils import convert_all_kernels_in_model\n from ..utils.data_utils import get_file\n from .. import backend as K\n@@ -114,8 +115,14 @@ def VGG19(include_top=True, weights='imagenet',\n         x = Dense(4096, activation='relu', name='fc2')(x)\n         x = Dense(1000, activation='softmax', name='predictions')(x)\n \n-    # Create model\n-    model = Model(img_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Model(inputs, x)\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -25,6 +25,7 @@ import warnings\n from ..models import Model\n from ..layers import Dense, Input, BatchNormalization, Activation, merge\n from ..layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\n+from ..engine.topology import get_source_inputs\n from ..utils.data_utils import get_file\n from .. import backend as K\n from .imagenet_utils import decode_predictions, _obtain_input_shape\n@@ -190,8 +191,14 @@ def Xception(include_top=True, weights='imagenet',\n         x = GlobalAveragePooling2D(name='avg_pool')(x)\n         x = Dense(1000, activation='softmax', name='predictions')(x)\n \n-    # Create model\n-    model = Model(img_input, x)\n+    # Ensure that the model takes into account\n+    # any potential predecessors of `input_tensor`.\n+    if input_tensor is not None:\n+        inputs = get_source_inputs(input_tensor)\n+    else:\n+        inputs = img_input\n+    # Create model.\n+    model = Model(inputs, x)\n \n     # load weights\n     if weights == 'imagenet':\n\n@@ -2725,7 +2725,7 @@ def get_source_inputs(tensor, layer=None, node_index=None):\n         node_index: Origin node index of the tensor.\n     '''\n     if not hasattr(tensor, '_keras_history'):\n-        raise Exception('Tensor must be a Keras tensor. Found: ' + str(tensor))\n+        return tensor\n \n     if layer is None or node_index:\n         layer, node_index, _ = tensor._keras_history\n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
{"custom_id": "keras#a081e049db8b62b66d98639fbac8f16fe4c8d8b5", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "user", "content": "You are a senior reviewer.\n\nCommit Summary:\nLines Added: 2 | Lines Deleted: 2 | Files Changed: 1 | Hunks: 2 | Methods Changed: 2 | Complexity Δ (Sum/Max): 0/0 | Churn Δ: 4 | Churn Cumulative: 2893 | Contributors (this commit): 43 | Commits (past 90d): 14 | Contributors (cumulative): 43 | DMM Complexity: None\n\nDIFF:\n@@ -1008,7 +1008,7 @@ def in_train_phase(x, alt):\n         return x\n     elif _LEARNING_PHASE is 0:\n         return alt\n-    x = T.switch(_LEARNING_PHASE, x, alt)\n+    x = theano.ifelse.ifelse(_LEARNING_PHASE, x, alt)\n     x._uses_learning_phase = True\n     return x\n \n@@ -1018,7 +1018,7 @@ def in_test_phase(x, alt):\n         return alt\n     elif _LEARNING_PHASE is 0:\n         return x\n-    x = T.switch(_LEARNING_PHASE, alt, x)\n+    x = theano.ifelse.ifelse(_LEARNING_PHASE, alt, x)\n     x._uses_learning_phase = True\n     return x\n \n\n\nQuestion: Does this commit introduce technical debt? Answer yes or no."}], "max_tokens": 1, "temperature": 0}}
